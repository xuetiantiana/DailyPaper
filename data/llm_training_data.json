{
  "data": [
    {
      "id": "2507.13508",
      "abstract": "The \"Fake or Real\" competition hosted on Kaggle (https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt ) is the second part of a series of follow-up competitions and hackathons related to the \"Assurance for Space Domain AI Applications\" project funded by the European Space Agency (https://assurance-ai.space-codev.org/ ). The competition idea is based on two real-life AI security threats identified within the project -- data poisoning and overreliance in Large Language Models. The task is to distinguish between the proper output from LLM and the output generated under malicious modification of the LLM. As this problem was not extensively researched, participants are required to develop new techniques to address this issue or adjust already existing ones to this problem's statement.",
      "authors": [
        "Agata Kaczmarek",
        "Dawid P{\\l}udowski",
        "Piotr Wilczy\\'nski",
        "Przemys{\\l}aw Biecek",
        "Krzysztof Kotowski",
        "Ramez Shendy",
        "Jakub Nalepa",
        "Artur Janicki",
        "Evridiki Ntagiou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T19:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.13508v1",
          "size": "114kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:07:17+00:00",
          "link": "https://arxiv.org/abs/2507.13508v2",
          "size": "114kb",
          "version": "v2"
        }
      ],
      "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13508",
        "PDF": "https://arxiv.org/pdf/2507.13508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The competition focuses on distinguishing between outputs from LLMs affected by data poisoning versus authentic outputs, with no new contributions to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13704",
      "abstract": "Multi-objective Bayesian optimization (MOBO) provides a principled framework for navigating trade-offs in molecular design. However, its empirical advantages over scalarized alternatives remain underexplored. We benchmark a simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) -- against a simple fixed-weight scalarized baseline using Expected Improvement (EI), under a tightly controlled setup with identical Gaussian Process surrogates and molecular representations. Across three molecular optimization tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front coverage, convergence speed, and chemical diversity. While scalarization encompasses flexible variants -- including random or adaptive schemes -- our results show that even strong deterministic instantiations can underperform in low-data regimes. These findings offer concrete evidence for the practical advantages of Pareto-aware acquisition in de novo molecular optimization, especially when evaluation budgets are limited and trade-offs are nontrivial.",
      "authors": [
        "Anabel Yong",
        "Austin Tripp",
        "Layla Hosseini-Gerami",
        "Brooks Paige"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T07:12:19+00:00",
          "link": "https://arxiv.org/abs/2507.13704v1",
          "size": "124kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:52:25+00:00",
          "link": "https://arxiv.org/abs/2507.13704v2",
          "size": "124kb",
          "version": "v2"
        }
      ],
      "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13704",
        "HTML": "https://arxiv.org/html/2507.13704v1",
        "PDF": "https://arxiv.org/pdf/2507.13704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores Bayesian optimization in the context of molecular design and discusses multi-objective optimization strategies. It does not address LLM training data processing or any related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13773",
      "abstract": "In visual question answering (VQA) context, users often pose ambiguous questions to visual language models (VLMs) due to varying expression habits. Existing research addresses such ambiguities primarily by rephrasing questions. These approaches neglect the inherently interactive nature of user interactions with VLMs, where ambiguities can be clarified through user feedback. However, research on interactive clarification faces two major challenges: (1) Benchmarks are absent to assess VLMs' capacity for resolving ambiguities through interaction; (2) VLMs are trained to prefer answering rather than asking, preventing them from seeking clarification. To overcome these challenges, we introduce \\textbf{ClearVQA} benchmark, which targets three common categories of ambiguity in VQA context, and encompasses various VQA scenarios.",
      "authors": [
        "Pu Jian",
        "Donglei Yu",
        "Wen Yang",
        "Shuo Ren",
        "Jiajun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T09:31:43+00:00",
          "link": "https://arxiv.org/abs/2507.13773v1",
          "size": "6600kb",
          "version": "v1"
        }
      ],
      "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13773",
        "PDF": "https://arxiv.org/pdf/2507.13773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with resolving ambiguities in visual questions using VLMs and introduces a benchmark called ClearVQA. It does not involve training data processing for LLMs or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13792",
      "abstract": "We extend the semantics and type system of a lambda calculus equipped with common constructs to be resource-aware. That is, the semantics keep tracks of the usage of resources, and is stuck, besides in case of type errors, if either a needed resource is exhausted, or a provided resource would be wasted. In such way, the type system guarantees, besides standard soundness, that for well-typed programs there is a computation where no resource gets either exhausted or wasted.\n  The no-waste extension is parametric on an arbitrary grade algebra, modeling an arbitrary assortment of possible usages, and does not require ad-hoc changes to the underlying language. To this end, the semantics needs to be formalized in big-step style; as a consequence, expressing and proving (resource-aware) soundness is challenging, and is achieved by applying recent techniques based on coinductive reasoning.",
      "authors": [
        "Riccardo Bianchini",
        "Francesco Dagnino",
        "Paola Giannini",
        "Elena Zucca"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T10:06:08+00:00",
          "link": "https://arxiv.org/abs/2507.13792v1",
          "size": "69kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:17:14+00:00",
          "link": "https://arxiv.org/abs/2507.13792v2",
          "size": "69kb",
          "version": "v2"
        }
      ],
      "title": "Don't exhaust, don't waste",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13792",
        "HTML": "https://arxiv.org/html/2507.13792v1",
        "PDF": "https://arxiv.org/pdf/2507.13792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research extends the semantics and type systems in lambda calculus for resource-aware computing. It does not concern itself with LLM training data processing or relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13861",
      "abstract": "Recent subject-driven image customization has achieved significant advancements in fidelity, yet fine-grained entity-level spatial control remains elusive, hindering the broader real-world application. This limitation is mainly attributed to scalable datasets that bind identity with precise positional cues are absent. To this end, we introduce PositionIC, a unified framework that enforces position and identity consistency for multi-subject customization. We construct a scalable synthesis pipeline that employs a bidirectional generation paradigm to eliminate subject drift and maintain semantic coherence. On top of these data, we design a lightweight positional modulation layer that decouples spatial embeddings among subjects, enabling independent, accurate placement while preserving visual fidelity. Extensive experiments demonstrate that our approach can achieve precise spatial control while maintaining high consistency in image customization task. PositionIC paves the way for controllable, high-fidelity image customization in open-world, multi-entity scenarios and will be released to foster further research.",
      "authors": [
        "Junjie Hu",
        "Tianyang Han",
        "Kai Ma",
        "Jialin Gao",
        "Hao Dou",
        "Song Yang",
        "Xianhua He",
        "Jianhui Zhang",
        "Junfeng Luo",
        "Xiaoming Wei",
        "Wenqiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:35:47+00:00",
          "link": "https://arxiv.org/abs/2507.13861v1",
          "size": "3858kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:21:15+00:00",
          "link": "https://arxiv.org/abs/2507.13861v2",
          "size": "3858kb",
          "version": "v2"
        }
      ],
      "title": "PositionIC: Unified Position and Identity Consistency for Image Customization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13861",
        "HTML": "https://arxiv.org/html/2507.13861v1",
        "PDF": "https://arxiv.org/pdf/2507.13861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper on PositionIC addresses issues in image customization with a focus on positional and identity consistency. It does not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13891",
      "abstract": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing attention due to its remarkable performance in reconstructing high-quality 3D scenes from unposed images or videos. However, it often struggles to handle scenes with complex camera trajectories as featured by drastic rotation and translation across adjacent camera views, leading to degraded estimation of camera poses and further local minima in joint optimization of camera poses and 3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that achieves superior 3D scene modeling and camera pose estimation via camera pose co-regularization. PCR-GS achieves regularization from two perspectives. The first is feature reprojection regularization which extracts view-robust DINO features from adjacent camera views and aligns their semantic information for camera pose regularization. The second is wavelet-based frequency regularization which exploits discrepancy in high-frequency details to further optimize the rotation matrix in camera poses. Extensive experiments over multiple real-world scenes show that the proposed PCR-GS achieves superior pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.",
      "authors": [
        "Yu Wei",
        "Jiahui Zhang",
        "Xiaoqin Zhang",
        "Ling Shao",
        "Shijian Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:09:33+00:00",
          "link": "https://arxiv.org/abs/2507.13891v1",
          "size": "6146kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.13891v2",
          "size": "6146kb",
          "version": "v2"
        }
      ],
      "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13891",
        "HTML": "https://arxiv.org/html/2507.13891v1",
        "PDF": "https://arxiv.org/pdf/2507.13891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D scene modeling and camera pose estimation using a new COLMAP-free 3D Gaussian Splatting technique. It does not relate to LLM training data processing or any data engineering operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13899",
      "abstract": "Recent advances in foundation models have opened up new possibilities for enhancing 3D perception. In particular, DepthAnything offers dense and reliable geometric priors from monocular RGB images, which can complement sparse LiDAR data in autonomous driving scenarios. However, such priors remain underutilized in LiDAR-based 3D object detection. In this paper, we address the limited expressiveness of raw LiDAR point features, especially the weak discriminative capability of the reflectance attribute, by introducing depth priors predicted by DepthAnything. These priors are fused with the original LiDAR attributes to enrich each point's representation. To leverage the enhanced point features, we propose a point-wise feature extraction module. Then, a Dual-Path RoI feature extraction framework is employed, comprising a voxel-based branch for global semantic context and a point-based branch for fine-grained structural details. To effectively integrate the complementary RoI features, we introduce a bidirectional gated RoI feature fusion module that balances global and local cues. Extensive experiments on the KITTI benchmark show that our method consistently improves detection accuracy, demonstrating the value of incorporating visual foundation model priors into LiDAR-based 3D object detection.",
      "authors": [
        "Yujian Mo and Yan Wu and Junqiao Zhao and Jijun Wang and Yinghao Hu and Jun Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:24:32+00:00",
          "link": "https://arxiv.org/abs/2507.13899v1",
          "size": "1389kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13899",
        "HTML": "https://arxiv.org/html/2507.13899v1",
        "PDF": "https://arxiv.org/pdf/2507.13899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper discusses enhancing LiDAR point features for 3D object detection using foundation model priors, it does not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14000",
      "abstract": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM (PFA), a photonic-enabled switch and memory subsystem that delivers low latency, high bandwidth, and low per-bit energy. By integrating high-bandwidth HBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D electro-optical system-in-package, the PFA offers up to 32 TB of shared memory alongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM enables distributed AI training and inference to execute parallelism strategies more efficiently. The Photonic Fabric removes the silicon beachfront constraint that limits the fixed memory-to-compute ratio observed in virtually all current XPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet that connects to the Photonic Fabric increases its memory capacity and correspondingly its memory bandwidth by offering a flexible path to scaling well beyond the limitations of on-package HBM alone. We introduce CelestiSim, a lightweight analytical simulator validated on NVIDIA H100 and H200 systems. It is used to evaluate the performance of LLM reference and energy savings on PFA, without any significant change to the GPU core design. With the PFA, the simulation results show that up to 3.66x throughput and 1.40x latency improvements in LLM inference at 405B parameters, up to 7.04x throughput and 1.41x latency improvements at 1T parameters, and 60-90% energy savings in data movement for heavy collective operations in all LLM training scenarios. While these results are shown for NVIDIA GPUs, they can be applied similarly to other AI accelerator designs (XPUs) that share the same fundamental limitation of fixed memory to compute.",
      "authors": [
        "Jing Ding and Trung Diep"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:14:56+00:00",
          "link": "https://arxiv.org/abs/2507.14000v1",
          "size": "2241kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:03:27+00:00",
          "link": "https://arxiv.org/abs/2507.14000v2",
          "size": "2239kb",
          "version": "v2"
        }
      ],
      "title": "Photonic Fabric Platform for AI Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14000",
        "PDF": "https://arxiv.org/pdf/2507.14000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a photonic fabric platform for AI accelerators, focusing on hardware design and AI training performance improvements. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14111",
      "abstract": "The exponential growth in demand for GPU computing resources, driven by the rapid advancement of Large Language Models, has created an urgent need for automated CUDA optimization strategies. While recent advances in LLMs show promise for code generation, current SOTA models (e.g. R1, o1) achieve low success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an automated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task: trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250 CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the model also demonstrates excellent portability across GPU architectures, achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40, x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100. Beyond these benchmark results, CUDA-L1 demonstrates several remarkable properties: 1) Discovers a variety of CUDA optimization techniques and learns to combine them strategically to achieve optimal performance; 2) Uncovers fundamental principles of CUDA optimization; 3) Identifies non-obvious performance bottlenecks and rejects seemingly beneficial optimizations that harm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can transform an initially poor-performing LLM into an effective CUDA optimizer through speedup-based reward signals alone, without human expertise or domain knowledge. More importantly, the trained RL model extend the acquired reasoning abilities to new kernels. This paradigm opens possibilities for automated optimization of CUDA operations, and holds promise to substantially promote GPU efficiency and alleviate the rising pressure on GPU computing resources.",
      "authors": [
        "Xiaoya Li",
        "Xiaofei Sun",
        "Albert Wang",
        "Jiwei Li and Chris Shum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:43:56+00:00",
          "link": "https://arxiv.org/abs/2507.14111v1",
          "size": "7482kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:28:22+00:00",
          "link": "https://arxiv.org/abs/2507.14111v2",
          "size": "8504kb",
          "version": "v2"
        }
      ],
      "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14111",
        "PDF": "https://arxiv.org/pdf/2507.14111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents CUDA-L1, a reinforcement learning framework for optimizing CUDA operations, mainly addressing GPU performance enhancements rather than any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13626",
      "abstract": "Speech Quality Assessment (SQA) and Continuous Speech Emotion Recognition (CSER) are two key tasks in speech technology, both relying on listener ratings. However, these ratings are inherently biased due to individual listener factors. Previous approaches have introduced a mean listener scoring scale and modeled all listener scoring scales in the training set. However, the mean listener approach is prone to distortion from averaging ordinal data, leading to potential biases. Moreover, learning multiple listener scoring scales while inferring based only on the mean listener scale limits effectiveness. In contrast, our method focuses on modeling a unified listener scoring scale, using comparison scores to correctly capture the scoring relationships between utterances. Experimental results show that our method effectively improves prediction performance in both SQA and CSER tasks, proving its effectiveness and robustness.",
      "authors": [
        "Cheng-Hung Hu",
        "Yusuke Yasuda",
        "Akifumi Yoshimoto",
        "Tomoki Toda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T03:39:48+00:00",
          "link": "https://arxiv.org/abs/2507.13626v1",
          "size": "114kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:12:36+00:00",
          "link": "https://arxiv.org/abs/2507.13626v2",
          "size": "114kb",
          "version": "v2"
        }
      ],
      "title": "Unifying Listener Scoring Scales: Comparison Learning Framework for Speech Quality Assessment and Continuous Speech Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13626",
        "HTML": "https://arxiv.org/html/2507.13626v1",
        "PDF": "https://arxiv.org/pdf/2507.13626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for unifying listener scoring scales in speech technology, specifically for Speech Quality Assessment and Continuous Speech Emotion Recognition. It does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.07053",
      "abstract": "Metaphors are a ubiquitous but often overlooked part of everyday language. As a complex cognitive-linguistic phenomenon, they provide a valuable means to evaluate whether language models can capture deeper aspects of meaning, including semantic, pragmatic, and cultural context. In this work, we present Meta4XNLI, the first parallel dataset for Natural Language Inference (NLI) newly annotated for metaphor detection and interpretation in both English and Spanish. Meta4XNLI facilitates the comparison of encoder- and decoder-based models in detecting and understanding metaphorical language in multilingual and cross-lingual settings. Our results show that fine-tuned encoders outperform decoders-only LLMs in metaphor detection. Metaphor interpretation is evaluated via the NLI framework with comparable performance of masked and autoregressive models, which notably decreases when the inference is affected by metaphorical language. Our study also finds that translation plays an important role in the preservation or loss of metaphors across languages, introducing shifts that might impact metaphor occurrence and model performance. These findings underscore the importance of resources like Meta4XNLI for advancing the analysis of the capabilities of language models and improving our understanding of metaphor processing across languages. Furthermore, the dataset offers previously unavailable opportunities to investigate metaphor interpretation, cross-lingual metaphor transferability, and the impact of translation on the development of multilingual annotated resources.",
      "authors": [
        "Elisa Sanchez-Bayona",
        "Rodrigo Agerri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T14:44:48+00:00",
          "link": "https://arxiv.org/abs/2404.07053v1",
          "size": "150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T15:03:29+00:00",
          "link": "https://arxiv.org/abs/2404.07053v2",
          "size": "1847kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T08:12:47+00:00",
          "link": "https://arxiv.org/abs/2404.07053v3",
          "size": "1847kb",
          "version": "v3"
        }
      ],
      "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07053",
        "HTML": "https://arxiv.org/html/2404.07053v2",
        "PDF": "https://arxiv.org/pdf/2404.07053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Meta4XNLI, a dataset annotated for metaphor detection, which can aid in understanding language in LLMs. However, its primary focus is elsewhere, such as metaphor interpretation and cross-lingual analysis, rather than on LLM data processing."
      },
      "models": [
        {
          "model_path": "HiTZ/mdeberta-metaphor-detection-multilang-es_en",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/mdeberta-metaphor-detection-multilang-es_en"
        },
        {
          "model_path": "HiTZ/xlm-roberta-large-metaphor-interpretationNLI-es",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/xlm-roberta-large-metaphor-interpretationNLI-es"
        },
        {
          "model_path": "HiTZ/xlm-roberta-large-metaphor-interpretationNLI-en",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HiTZ/xlm-roberta-large-metaphor-interpretationNLI-en"
        }
      ],
      "datasets": [
        {
          "dataset_name": "HiTZ/meta4xnli",
          "downloads": "22",
          "likes": "1",
          "link": "https://huggingface.co/datasets/HiTZ/meta4xnli"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/elisanchez-beep/meta4xnli"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18749",
      "abstract": "Training deep learning models is a repetitive and resource-intensive process. Data scientists often train several models before landing on a set of parameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural architecture search), among other things that yield the highest accuracy. The computational efficiency of these training tasks depends highly on how well the training data is supplied to the training process. The repetitive nature of these tasks results in the same data processing pipelines running over and over, exacerbating the need for and costs of computational resources. In this paper, we present TensorSocket to reduce the computational needs of deep learning training by enabling simultaneous training processes to share the same data loader. TensorSocket mitigates CPU-side bottlenecks in cases where the collocated training workloads have high throughput on GPU, but are held back by lower data-loading throughput on CPU. TensorSocket achieves this by reducing redundant computations and data duplication across collocated training processes and leveraging modern GPU-GPU interconnects. While doing so, TensorSocket is able to train and balance differently-sized models and serve multiple batch sizes simultaneously and is hardware- and pipeline-agnostic in nature. Our evaluation shows that TensorSocket enables scenarios that are infeasible without data sharing, increases training throughput by up to 100%, and when utilizing cloud instances, achieves cost savings of 50% by reducing the hardware resource needs on the CPU side. Furthermore, TensorSocket outperforms the state-of-the-art solutions for shared data loading such as CoorDL and Joader; it is easier to deploy and maintain and either achieves higher or matches their throughput while requiring fewer CPU resources.",
      "authors": [
        "Ties Robroek (IT University of Copenhagen)",
        "Neil Kim Nielsen (IT University of Copenhagen)",
        "P{\\i}nar T\\\"oz\\\"un (IT University of Copenhagen)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T13:39:47+00:00",
          "link": "https://arxiv.org/abs/2409.18749v1",
          "size": "1864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T13:46:14+00:00",
          "link": "https://arxiv.org/abs/2409.18749v2",
          "size": "403kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2409.18749v3",
          "size": "403kb",
          "version": "v3"
        }
      ],
      "title": "TensorSocket: Shared Data Loading for Deep Learning Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18749",
        "HTML": "https://arxiv.org/html/2409.18749v2",
        "PDF": "https://arxiv.org/pdf/2409.18749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework to improve computational efficiency in shared data loading for deep learning training, without a direct contribution to LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Deep Learning",
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04287",
      "abstract": "Uncertainties in renewable energy resources (RES) and load variations can lead to elevated system operational costs. Moreover, the emergence of large-scale distributed threats, such as load-altering attacks (LAAs), can induce substantial load variations, further exacerbating these costs. Although traditional defense measures can reduce the likelihood of such attacks, considerable residual risks remain. Thus, this paper proposes a cyber insurance framework designed to hedge against additional operational costs resulting from LAAs and substantial load variations in renewable-rich grids. The insurance framework determines both the insurance coverage and premium based on the Value at Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated using the system failure probability and the probability density function (PDF) of the system operation cost. The system failure probability is assessed through a semi-Markov process (SMP), while the cost distribution is estimated through a cost minimization model of a distribution grid combined with a Monte-Carlo simulation to capture load variability. Furthermore, we employ a bi-level optimization scheme that identifies the specific load distribution leading to the maximum system cost, thereby enhancing the accuracy of the operation cost PDF estimation. The effectiveness and scalability of the proposed cyber insurance policy are evaluated considering a modified IEEE-118 test bus system and the IEEE European low-voltage (LV) test feeders model. The case study shows that with a relatively low premium, the network operator can hedge against additional operational costs caused by malicious load manipulations.",
      "authors": [
        "Shijie Pan",
        "Zaint A. Alexakis",
        "S Subhash Lakshminarayana",
        "Charalambos Konstantinou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T21:35:04+00:00",
          "link": "https://arxiv.org/abs/2504.04287v1",
          "size": "4720kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:25:20+00:00",
          "link": "https://arxiv.org/abs/2504.04287v2",
          "size": "1059kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:34:24+00:00",
          "link": "https://arxiv.org/abs/2504.04287v3",
          "size": "1059kb",
          "version": "v3"
        }
      ],
      "title": "A Cyber Insurance Policy for Hedging Against Load-Altering Attacks and Extreme Load Variations in Distribution Grids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04287",
        "HTML": "https://arxiv.org/html/2504.04287v2",
        "PDF": "https://arxiv.org/pdf/2504.04287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a cyber insurance framework for distribution grids, which does not involve any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.01454",
      "abstract": "Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy, yet it faces significant challenges in communication efficiency and vulnerability to poisoning attacks. While sparsification techniques mitigate communication overhead by transmitting only critical model parameters, they inadvertently amplify security risks: adversarial clients can exploit sparse updates to evade detection and degrade model performance. Existing defense mechanisms, designed for standard FL communication scenarios, are ineffective in addressing these vulnerabilities within sparsified FL. To bridge this gap, we propose FLARE, a novel federated learning framework that integrates sparse index mask inspection and model update sign similarity analysis to detect and mitigate poisoning attacks in sparsified FL. Extensive experiments across multiple datasets and adversarial scenarios demonstrate that FLARE significantly outperforms existing defense strategies, effectively securing sparsified FL against poisoning attacks while maintaining communication efficiency.",
      "authors": [
        "Zhiyong Jin",
        "Runhua Xu",
        "Chao Li",
        "Yizhong Liu",
        "Jianxin Li",
        "James Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T14:59:13+00:00",
          "link": "https://arxiv.org/abs/2505.01454v1",
          "size": "6340kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T13:27:29+00:00",
          "link": "https://arxiv.org/abs/2505.01454v2",
          "size": "6340kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T13:54:51+00:00",
          "link": "https://arxiv.org/abs/2505.01454v3",
          "size": "7999kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T14:15:12+00:00",
          "link": "https://arxiv.org/abs/2505.01454v4",
          "size": "7999kb",
          "version": "v4"
        }
      ],
      "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01454",
        "HTML": "https://arxiv.org/html/2505.01454v3",
        "PDF": "https://arxiv.org/pdf/2505.01454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with improving federated learning systems' security against poisoning attacks, particularly in a sparsified framework, not concerning LLM training data processing."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03532",
      "abstract": "Digital pathology has seen the advent of a wealth of foundational models (FM), yet to date their performance on cell phenotyping has not been benchmarked in a unified manner. We therefore propose PhenoBench: A comprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E) stained histopathology images. We provide both PhenoCell, a new H&E dataset featuring 14 granular cell types identified by using multiplexed imaging, and ready-to-use fine-tuning and benchmarking code that allows the systematic evaluation of multiple prominent pathology FMs in terms of dense cell phenotype predictions in different generalization scenarios. We perform extensive benchmarking of existing FMs, providing insights into their generalization behavior under technical vs. medical domain shifts. Furthermore, while FMs achieve macro F1 scores > 0.70 on previously established benchmarks such as Lizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This indicates a much more challenging task not captured by previous benchmarks, establishing PhenoCell as a prime asset for future benchmarking of FMs and supervised models alike. Code and data are available on GitHub.",
      "authors": [
        "Fabian H. Reith",
        "Claudia Winklmayr",
        "Jerome Luescher",
        "Nora Koreuber",
        "Jannik Franzen",
        "Elias Baumann",
        "Christian M. Schuerch",
        "Dagmar Kainmueller",
        "Josef Lorenz Rumberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:37:57+00:00",
          "link": "https://arxiv.org/abs/2507.03532v1",
          "size": "4535kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T08:29:03+00:00",
          "link": "https://arxiv.org/abs/2507.03532v2",
          "size": "4523kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T06:42:01+00:00",
          "link": "https://arxiv.org/abs/2507.03532v3",
          "size": "4523kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T05:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.03532v4",
          "size": "4523kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T10:34:09+00:00",
          "link": "https://arxiv.org/abs/2507.03532v5",
          "size": "4535kb",
          "version": "v5"
        }
      ],
      "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03532",
        "HTML": "https://arxiv.org/html/2507.03532v4",
        "PDF": "https://arxiv.org/pdf/2507.03532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces PhenoBench, a comprehensive benchmark for evaluating cell phenotyping with models in digital pathology rather than LLM training data processing. It may involve dataset creation but is unrelated to LLM-specific tasks or data preprocessing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.14816",
      "abstract": "We consider the nonlinear Schr{\\\"o}dinger equation with a potential, also known as Gross-Pitaevskii equation. By introducing a suitable spectral localization, we prove low regularity error estimates for the time discretization corresponding to an adapted Lie-Trotter splitting scheme. The proof is based on tools from spectral theory and pseudodifferential calculus in order to obtain various estimates on the spectral localization, including discrete Strichartz estimates which support the nonlinear analysis.",
      "authors": [
        "R\\'emi Carles (IRMAR)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-27T06:55:31+00:00",
          "link": "https://arxiv.org/abs/2408.14816v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2024-08-30T09:12:42+00:00",
          "link": "https://arxiv.org/abs/2408.14816v2",
          "size": "38kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T09:29:08+00:00",
          "link": "https://arxiv.org/abs/2408.14816v3",
          "size": "40kb",
          "version": "v3"
        }
      ],
      "title": "Time splitting and error estimates for nonlinear Schrodinger equations with a potential",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14816",
        "PDF": "https://arxiv.org/pdf/2408.14816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on time splitting and error estimates for a specific mathematical equation. This work does not pertain to LLM or its training data processing, but is related to computational methods in physics."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21787",
      "abstract": "We present an explicit closed-form formula for the vertices of the classical cut polytope $\\operatorname{CUT}(n)$, defined as the convex hull of cut vectors of the complete graph $K_n$. Our derivation proceeds via a related polytope, denoted $\\mathbf{1}$-$\\operatorname{CUT}(n)$, whose vertices are obtained by flipping all bits of the $\\operatorname{CUT}(n)$ vertices. This polytope arises naturally in a probabilistic context involving agreement probabilities among symmetric Bernoulli random variables which serves as the starting point of this work.\n  Our approach constructs the vertex set recursively via a binary encoding that stems from this probabilistic perspective. We prove that the resulting sequence of encoded integers, when appropriately scaled, exhibits an almost-linear behavior closely approximating the line $y = x - \\frac{1}{2}$. This structure motivates the introduction of the alternating cycle function, an integer-valued map whose key property is power-of-two composition invariance. The function serves as the foundation for our closed-form enumeration formula.\n  The result provides a rare instance of explicit vertex characterization for a $0$/$1$-polytope and offers a transparent combinatorial construction independent of enumeration algorithms.",
      "authors": [
        "Nevena Mari\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:02:54+00:00",
          "link": "https://arxiv.org/abs/2506.21787v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T22:18:58+00:00",
          "link": "https://arxiv.org/abs/2506.21787v2",
          "size": "37kb",
          "version": "v2"
        }
      ],
      "title": "An Explicit Formula for Vertex Enumeration in the CUT(n) Polytope via Probabilistic Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21787",
        "HTML": "https://arxiv.org/html/2506.21787",
        "PDF": "https://arxiv.org/pdf/2506.21787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on an explicit formula for vertex enumeration in the CUT(n) polytope using probabilistic methods, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14184",
      "abstract": "We present a novel and interpretable framework for electrocardiogram (ECG)-based disease detection that combines hyperdimensional computing (HDC) with learnable neural encoding. Unlike conventional HDC approaches that rely on static, random projections, our method introduces a rhythm-aware and trainable encoding pipeline based on RR intervals, a physiological signal segmentation strategy that aligns with cardiac cycles. The core of our design is a neural-distilled HDC architecture, featuring a learnable RR-block encoder and a BinaryLinear hyperdimensional projection layer, optimized jointly with cross-entropy and proxy-based metric loss. This hybrid framework preserves the symbolic interpretability of HDC while enabling task-adaptive representation learning. Experiments on Apnea-ECG and PTB-XL demonstrate that our model significantly outperforms traditional HDC and classical ML baselines, achieving 73.09\\% precision and an F1 score of 0.626 on Apnea-ECG, with comparable robustness on PTB-XL. Our framework offers an efficient and scalable solution for edge-compatible ECG classification, with strong potential for interpretable and personalized health monitoring.",
      "authors": [
        "ZhengXiao He",
        "Jinghao Wen",
        "Huayu Li",
        "Ao Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T20:22:48+00:00",
          "link": "https://arxiv.org/abs/2507.14184v1",
          "size": "731kb",
          "version": "v1"
        }
      ],
      "title": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14184",
        "HTML": "https://arxiv.org/html/2507.14184",
        "PDF": "https://arxiv.org/pdf/2507.14184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on a framework for ECG-based disease detection using a neural-distilled hyperdimensional model, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14919",
      "abstract": "One of the key obstacles in traditional deep learning is the reduction in model transparency caused by increasingly intricate model functions, which can lead to problems such as overfitting and excessive confidence in predictions. With the advent of quantum machine learning offering possible advances in computational power and latent space complexity, we notice the same opaque behavior. Despite significant research in classical contexts, there has been little advancement in addressing the black-box nature of quantum machine learning. Consequently, we approach this gap by building upon existing work in classical uncertainty quantification and initial explorations in quantum Bayesian modeling to theoretically develop and empirically evaluate techniques to map classical uncertainty quantification methods to the quantum machine learning domain. Our findings emphasize the necessity of leveraging classical insights into uncertainty quantification to include uncertainty awareness in the process of designing new quantum machine learning models.",
      "authors": [
        "Maximilian Wendlinger",
        "Kilian Tscharke",
        "Pascal Debus"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:16:56+00:00",
          "link": "https://arxiv.org/abs/2507.14919v1",
          "size": "869kb",
          "version": "v1"
        }
      ],
      "title": "Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14919",
        "HTML": "https://arxiv.org/html/2507.14919",
        "PDF": "https://arxiv.org/pdf/2507.14919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper delves into uncertainty quantification in quantum machine learning, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15283",
      "abstract": "The resilient consensus problem is investigated in this paper for a class of networked Euler-Lagrange systems with event-triggered communication in the presence of Byzantine attacks. One challenge that we face in addressing the considered problem is the inapplicability of existing resilient decision algorithms designed for one-dimensional multi-agent systems. This is because the networked Euler-Lagrange systems fall into the category of multi-dimensional multi-agent systems with coupling among state vector components. To address this problem, we propose a new resilient decision algorithm. This algorithm constructs auxiliary variables related to the coordinative objectives for each normal agent, and transforms the considered resilient consensus problem into the consensus problem of the designed auxiliary variables. Furthermore, to relax the constraints imposed on Byzantine agent behavior patterns within continuous-time scenarios, the event-triggered communication scheme is adopted. Finally, the effectiveness of the proposed algorithm is demonstrated through case studies.",
      "authors": [
        "Yuliang Fu",
        "Guanghui Wen",
        "Dan Zhao",
        "Wei Xing Zheng",
        "Xiaolei Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:31:41+00:00",
          "link": "https://arxiv.org/abs/2507.15283v1",
          "size": "1603kb",
          "version": "v1"
        }
      ],
      "title": "Event-Triggered Resilient Consensus of Networked Euler-Lagrange Systems Under Byzantine Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15283",
        "HTML": "https://arxiv.org/html/2507.15283",
        "PDF": "https://arxiv.org/pdf/2507.15283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses consensus algorithms in networked systems under attacks and does not relate to LLM training data processing, pretraining, or fine-tuning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15782",
      "abstract": "Household robots have been a longstanding research topic, but they still lack human-like intelligence, particularly in manipulating open-set objects and navigating large environments efficiently and accurately. To push this boundary, we consider a generalized multi-object collection problem in large scene graphs, where the robot needs to pick up and place multiple objects across multiple locations in a long mission of multiple human commands. This problem is extremely challenging since it requires long-horizon planning in a vast action-state space under high uncertainties. To this end, we propose a novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a multimodal action cost similarity function, our algorithm can both reflect the history and look into the future to optimize plans, striking a good balance of quality and efficiency. Simulation experiments demonstrate that compared with latest works, our algorithm improves the overall mission performance by 30% in terms of fulfilling human commands, maximizing mission success rates, and minimizing mission costs.",
      "authors": [
        "Ruochu Yang",
        "Yu Zhou",
        "Fumin Zhang",
        "Mengxue Hou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:37:50+00:00",
          "link": "https://arxiv.org/abs/2507.15782v1",
          "size": "8086kb",
          "version": "v1"
        }
      ],
      "title": "Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15782",
        "HTML": "https://arxiv.org/html/2507.15782",
        "PDF": "https://arxiv.org/pdf/2507.15782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for integrating LLM and motion planning for household robots to collect objects, focusing on robotics and planning rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1611.04175",
      "abstract": "We introduce and study the weakly single-crossing domain on trees which is a generalization of the well-studied single-crossing domain in social choice theory. We design a polynomial-time algorithm for recognizing preference profiles which belong to this domain. We then develop an efficient elicitation algorithm for this domain which works even if the preferences can be accessed only sequentially and the underlying single-crossing tree structure is not known beforehand. We also prove matching lower bound on the query complexity of our elicitation algorithm when the number of voters is large compared to the number of candidates. We also prove a lower bound of $\\Omega(m^2\\log n)$ on the number of queries that any algorithm needs to ask to elicit single crossing profile when random queries are allowed. This resolves an open question in an earlier paper and proves optimality of their preference elicitation algorithm when random queries are allowed.",
      "authors": [
        "Palash Dey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2016-11-13T19:35:52+00:00",
          "link": "https://arxiv.org/abs/1611.04175v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2022-02-18T13:31:30+00:00",
          "link": "https://arxiv.org/abs/1611.04175v2",
          "size": "46kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T11:23:26+00:00",
          "link": "https://arxiv.org/abs/1611.04175v3",
          "size": "49kb",
          "version": "v3"
        }
      ],
      "title": "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/1611.04175",
        "HTML": "https://arxiv.org/html/1611.04175",
        "PDF": "https://arxiv.org/pdf/1611.04175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about algorithms for recognizing and eliciting preference profiles in social choice theory, not related to LLM training data processing operations or dataset creation."
      },
      "tasks": [
        "Open-Ended Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08272",
      "abstract": "We study weighted pseudorandom generators (WPRGs) and derandomizations for read-once branching programs (ROBPs). Denote $n$ and $w$ as the length and the width of a ROBP. We have the following results.\n  For standard ROBPs, we give an explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left(\\frac{\\log n\\log (nw)}{\\max\\left\\{1,\\log\\log w-\\log\\log n\\right\\}}+\\log w \\left(\\log\\log\\log w-\\log\\log\\max\\left\\{2,\\frac{\\log w}{\\log \\frac{n}{\\varepsilon}}\\right\\}\\right)+\\log\\frac{1}{\\varepsilon}\\right).$$\n  For permutation ROBPs with unbounded widths and single accept nodes, we give an explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left( \\log n\\left( \\log\\log n + \\sqrt{\\log(1/\\varepsilon)} \\right)+\\log(1/\\varepsilon)\\right). $$\n  We also give a new Nisan-Zuckerman style derandomization for regular ROBPs with width $w$, length $n = 2^{O(\\sqrt{\\log w})}$, and multiple accept nodes. We attain optimal space complexity $O(\\log w)$ for arbitrary approximation error $\\varepsilon = 1/\\text{poly} (w)$.\n  All our results are based on iterative weighted pseudorandom reductions, which can iteratively reduce fooling long ROBPs to fooling short ones.",
      "authors": [
        "Kuan Cheng",
        "Ruiyang Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T10:27:18+00:00",
          "link": "https://arxiv.org/abs/2502.08272v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T02:41:37+00:00",
          "link": "https://arxiv.org/abs/2502.08272v2",
          "size": "294kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:59:20+00:00",
          "link": "https://arxiv.org/abs/2502.08272v3",
          "size": "111kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T13:15:56+00:00",
          "link": "https://arxiv.org/abs/2502.08272v4",
          "size": "111kb",
          "version": "v4"
        }
      ],
      "title": "Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08272",
        "PDF": "https://arxiv.org/pdf/2502.08272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about pseudorandom generators for read-once branching programs, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14175",
      "abstract": "Background: Mental illnesses such as depression and anxiety require improved methods for early detection and personalized intervention. Traditional predictive models often rely on unimodal data or early fusion strategies that fail to capture the complex, multimodal nature of psychiatric data. Advanced integration techniques, such as intermediate (latent space) fusion, may offer better accuracy and clinical utility. Methods: Using data from the BRIGHTEN clinical trial, we evaluated intermediate (latent space) fusion for predicting daily depressive symptoms (PHQ-2 scores). We compared early fusion implemented with a Random Forest (RF) model and intermediate fusion implemented via a Combined Model (CM) using autoencoders and a neural network. The dataset included behavioral (smartphone-based), demographic, and clinical features. Experiments were conducted across multiple temporal splits and data stream combinations. Performance was evaluated using mean squared error (MSE) and coefficient of determination (R2). Results: The CM outperformed both RF and Linear Regression (LR) baselines across all setups, achieving lower MSE (0.4985 vs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed signs of overfitting, with a large gap between training and test performance, while the CM maintained consistent generalization. Performance was best when integrating all data modalities in the CM (in contradistinction to RF), underscoring the value of latent space fusion for capturing non-linear interactions in complex psychiatric datasets. Conclusion: Latent space fusion offers a robust alternative to traditional fusion methods for prediction with multimodal mental health data. Future work should explore model interpretability and individual-level prediction for clinical deployment.",
      "authors": [
        "Youcef Barkat",
        "Dylan Hamitouche",
        "Deven Parekh",
        "Ivy Guo",
        "David Benrimoh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T18:10:46+00:00",
          "link": "https://arxiv.org/abs/2507.14175v1",
          "size": "669kb",
          "version": "v1"
        }
      ],
      "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14175",
        "PDF": "https://arxiv.org/pdf/2507.14175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses multimodal mental health data fusion techniques, which do not pertain to LLM training data processing or data engineering operations for language model development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14450",
      "abstract": "With the increasing integration of renewable energy, the reliability and resilience of modern power systems are of vital significance. However, large-scale blackouts caused by natural disasters or equipment failures remain a significant threat, necessitating effective restoration strategies. This study proposes novel black start models for modern power systems that integrate fuel cells and battery storage, recognizing their distinct characteristics and contributions to grid resilience. These models specifically address the restoration of electrical grids, including the energization paths and time of the transmission network, while accounting for the unique power output traits of fuel cells and the energy storage capacity of batteries as black start resources. Black start simulations, comparing the generator startup sequence (GSUS) with fuel cell versus battery systems, are performed on the IEEE 39-bus system. We conduct sensitivity analyses on fuel cell capacity, battery storage capacity, initial state of charge (SOC), and resource locations to identify optimal scenarios for black start operations.",
      "authors": [
        "Jin Lu",
        "Linhan Fang",
        "Fan Jiang",
        "Xingpeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:53:39+00:00",
          "link": "https://arxiv.org/abs/2507.14450v1",
          "size": "421kb",
          "version": "v1"
        }
      ],
      "title": "A Black Start Strategy for Hydrogen-integrated Renewable Grids with Energy Storage Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14450",
        "PDF": "https://arxiv.org/pdf/2507.14450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses power grid restoration strategies and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14496",
      "abstract": "Quantum state preparation is a fundamental task in quantum computing and quantum information processing. With the rapid advancement of quantum technologies, efficient quantum state preparation has become increasingly important. This paper proposes a novel approach for quantum state preparation based on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD combines the advantages of tensor networks and decision diagrams, enabling efficient representation and manipulation of quantum states. Compared with the state-of-the-art quantum state preparation method, LimTDD demonstrates substantial improvements in efficiency when dealing with complex quantum states, while also reducing the complexity of quantum circuits. Examples indicate that, in the best-case scenario, our method can achieve exponential efficiency gains over existing methods. This study not only highlights the potential of LimTDD in quantum state preparation but also provides a robust theoretical and practical foundation for the future development of quantum computing technologies.",
      "authors": [
        "Xin Hong",
        "Chenjian Li",
        "Aochu Dai",
        "Sanjiang Li",
        "Shenggang Ying and Mingsheng Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.14496v1",
          "size": "541kb",
          "version": "v1"
        }
      ],
      "title": "Quantum State Preparation Based on LimTDD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14496",
        "HTML": "https://arxiv.org/html/2507.14496",
        "PDF": "https://arxiv.org/pdf/2507.14496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel approach for quantum state preparation using LimTDD, which is unrelated to LLM training data processing or data engineering operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14725",
      "abstract": "Prompt-based continual learning (CL) offers a parameter-efficient way to adapt large language models (LLMs) across task sequences. However, most existing methods assume task-aware inference and maintain a growing list of task-specific prompts, which limits scalability and hides latent forgetting. In this work, we introduce GRID, a unified framework that addresses two key limitations: (1) latent forgetting under task-agnostic inference, and (2) prompt memory explosion as task sequences grow. GRID integrates a task-aware decoding mechanism that improves backward transfer by leveraging representative inputs, automatic task identification, and constrained decoding. Additionally, we propose a gradient-based prompt selection strategy that compresses less informative prompts into a single aggregated representation, enabling scalable and memory-efficient lifelong learning. Extensive experiments across short-sequence, long-sequence, and negative transfer benchmarks show that GRID significantly improves backward transfer, achieves competitive forward transfer, and reduces forgotten tasks by up to 80\\%, outperforming state-of-the-art methods on T5 and Flan-T5 backbones.",
      "authors": [
        "Anushka Tiwari",
        "Sayantan Pal",
        "Rohini K. Srihari",
        "Kaiyi Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:15:03+00:00",
          "link": "https://arxiv.org/abs/2507.14725v1",
          "size": "578kb",
          "version": "v1"
        }
      ],
      "title": "Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14725",
        "HTML": "https://arxiv.org/html/2507.14725",
        "PDF": "https://arxiv.org/pdf/2507.14725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt-based continual learning for LLMs, focusing on model adaptation and scalability rather than data processing. The mention of a gradient-based prompt selection strategy touches on data selection but the primary focus is on learning strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14850",
      "abstract": "We address the problem of safe policy learning in multi-agent safety-critical autonomous systems. In such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent level conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves learning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state of the art methods, our approach significantly improves the safety achieving near perfect (within 5%) success/safety rate while also improving performance across all the environments.",
      "authors": [
        "H. M. Sabbir Ahmad",
        "Ehsan Sabouni",
        "Alexander Wasilkoff",
        "Param Budhraja",
        "Zijian Guo",
        "Songyuan Zhang",
        "Chuchu Fan",
        "Christos Cassandras",
        "Wenchao Li"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:43:18+00:00",
          "link": "https://arxiv.org/abs/2507.14850v1",
          "size": "5064kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14850",
        "HTML": "https://arxiv.org/html/2507.14850",
        "PDF": "https://arxiv.org/pdf/2507.14850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around hierarchical multi-agent reinforcement learning with control barrier functions for safety in autonomous systems. It does not address any aspect of data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15017",
      "abstract": "In numeric-intensive computations, it is well known that the execution of floating-point programs is imprecise as floating point arithmetics (e.g., addition, subtraction, multiplication, division, etc.) incurs rounding errors. Albeit the rounding error is small for every single floating-point operation, the aggregation of such error in multiple operations may be dramatic and cause catastrophic program failures. Therefore, to ensure the correctness of floating-point programs, the effect of floating point error needs to be carefully taken into account. In this work, we consider the invariant generation for floating point programs, whose aim is to generate tight invariants under the perturbation of floating point errors. Our main contribution is a theoretical framework on how to apply constraint solving methods to address the invariant generation problem. In our framework, we propose a novel combination between the first-order differential characterization by FPTaylor (TOPLAS 2018) and constraint solving methods, aiming to reduce the computational burden of constraint solving. Moreover, we devise two polynomial invariant generation algorithms to instantiate the framework. The first algorithm is applicable to a wide range of floating-point operations but requires an initial (coarse) invariant as external input, while the second does not require an initial invariant but is limited to polynomial programs. Furthermore, we show how conditional branches, a difficult issue in floating-point analysis, can be handled in our framework. Experimental results show that our algorithms outperform SOTA approaches in both the time efficiency and the precision of the generated invariants over a variety of benchmarks.",
      "authors": [
        "Xuran Cai",
        "Liqian Chen",
        "Hongfei Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:02:17+00:00",
          "link": "https://arxiv.org/abs/2507.15017v1",
          "size": "78kb",
          "version": "v1"
        }
      ],
      "title": "Invariant Generation for Floating-Point Programs via Constraint Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15017",
        "HTML": "https://arxiv.org/html/2507.15017",
        "PDF": "https://arxiv.org/pdf/2507.15017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses invariant generation for floating-point programs and applies constraint solving; however, it lacks any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15145",
      "abstract": "This paper proposes a communication-efficient, event-triggered inference framework for cooperative edge AI systems comprising multiple user devices and edge servers. Building upon dual-threshold early-exit strategies for rare-event detection, the proposed approach extends classical single-device inference to a distributed, multi-device setting while incorporating proportional fairness constraints across users. A joint optimization framework is formulated to maximize classification utility under communication, energy, and fairness constraints. To solve the resulting problem efficiently, we exploit the monotonicity of the utility function with respect to the confidence thresholds and apply alternating optimization with Benders decomposition. Experimental results show that the proposed framework significantly enhances system-wide performance and fairness in resource allocation compared to single-device baselines.",
      "authors": [
        "Thai T. Vu and John Le"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:38:41+00:00",
          "link": "https://arxiv.org/abs/2507.15145v1",
          "size": "851kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Machine Learning for Secure Cooperative Multi-Layer Edge AI with Proportional Fairness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15145",
        "HTML": "https://arxiv.org/html/2507.15145",
        "PDF": "https://arxiv.org/pdf/2507.15145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for cooperative edge AI systems and does not involve LLM training data processing or relevant data operations for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15692",
      "abstract": "Multimodal large language models (MLLMs) provide new opportunities for blind and low vision (BLV) people to access visual information in their daily lives. However, these models often produce errors that are difficult to detect without sight, posing safety and social risks in scenarios from medication identification to outfit selection. While BLV MLLM users use creative workarounds such as cross-checking between tools and consulting sighted individuals, these approaches are often time-consuming and impractical. We explore how systematically surfacing variations across multiple MLLM responses can support BLV users to detect unreliable information without visually inspecting the image. We contribute a design space for eliciting and presenting variations in MLLM descriptions, a prototype system implementing three variation presentation styles, and findings from a user study with 15 BLV participants. Our results demonstrate that presenting variations significantly increases users' ability to identify unreliable claims (by 4.9x using our approach compared to single descriptions) and significantly decreases perceived reliability of MLLM responses. 14 of 15 participants preferred seeing variations of MLLM responses over a single description, and all expressed interest in using our system for tasks from understanding a tornado's path to posting an image on social media.",
      "authors": [
        "Meng Chen",
        "Akhil Iyer",
        "Amy Pavel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:59:50+00:00",
          "link": "https://arxiv.org/abs/2507.15692v1",
          "size": "5060kb",
          "version": "v1"
        }
      ],
      "title": "Surfacing Variations to Calibrate Perceived Reliability of MLLM-generated Image Descriptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15692",
        "HTML": "https://arxiv.org/html/2507.15692",
        "PDF": "https://arxiv.org/pdf/2507.15692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on improving perceived reliability of MLLM-generated image descriptions for users, without addressing any aspect of training data processing or improvements in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15777",
      "abstract": "Rich and accurate medical image segmentation is poised to underpin the next generation of AI-defined clinical practice by delineating critical anatomy for pre-operative planning, guiding real-time intra-operative navigation, and supporting precise post-operative assessment. However, commonly used learning methods for medical and surgical imaging segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the labels space. This becomes particularly problematic as the cardinality and richness of labels increases to include subtly different classes. In this work, we propose two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations to extend the applicability of our proposed losses. Extensive experiments are reported on two medical and surgical image segmentation tasks, namely head MRI for whole brain parcellation (WBP) with full supervision and neurosurgical hyperspectral imaging (HSI) for scene understanding with sparse annotations. Results demonstrate that our proposed method reaches state-of-the-art performance in both cases.",
      "authors": [
        "Junwen Wang",
        "Oscar MacCormac",
        "William Rochford",
        "Aaron Kujawa",
        "Jonathan Shapey",
        "and Tom Vercauteren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:32:48+00:00",
          "link": "https://arxiv.org/abs/2507.15777v1",
          "size": "16787kb",
          "version": "v1"
        }
      ],
      "title": "Label tree semantic losses for rich multi-class medical image segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15777",
        "HTML": "https://arxiv.org/html/2507.15777",
        "PDF": "https://arxiv.org/pdf/2507.15777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses new loss functions for medical image segmentation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13242",
      "abstract": "The quest for non-commutative matrix multiplication algorithms in small dimensions has seen a lot of recent improvements recently. In particular, the number of scalar multiplications required to multiply two $4\\times4$ matrices was first reduced in \\cite{Fawzi:2022aa} from 49 (two recursion levels of Strassen's algorithm) to 47 but only in characteristic 2 or more recently to 48 in \\cite{alphaevolve} but over complex numbers. We propose an algorithm in 48 multiplications with only rational coefficients, hence removing the complex number requirement. It was derived from the latter one, under the action of an isotropy which happen to project the algorithm on the field of rational numbers. We also produce a straight line program of this algorithm, reducing the leading constant in the complexity, as well as an alternative basis variant of it, leading to an algorithm running in $\\frac{19}{16} n^{2+\\frac{\\log_2 3}{2}} +o\\left(n^{2+\\frac{log_2 3}{2}}\\right)$ operations over any ring containing an inverse of 2.",
      "authors": [
        "Jean-Guillaume Dumas (CASC)",
        "Cl\\'ement Pernet (CASC)",
        "Alexandre Sedoglavic (CRIStAL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:42:15+00:00",
          "link": "https://arxiv.org/abs/2506.13242v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T08:51:21+00:00",
          "link": "https://arxiv.org/abs/2506.13242v2",
          "size": "16kb",
          "version": "v2"
        },
        {
          "date": "2025-06-24T08:34:48+00:00",
          "link": "https://arxiv.org/abs/2506.13242v3",
          "size": "17kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T09:00:56+00:00",
          "link": "https://arxiv.org/abs/2506.13242v4",
          "size": "17kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T09:18:59+00:00",
          "link": "https://arxiv.org/abs/2506.13242v5",
          "size": "18kb",
          "version": "v5"
        }
      ],
      "title": "A non-commutative algorithm for multiplying 4x4 matrices using 48 non-complex multiplications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13242",
        "PDF": "https://arxiv.org/pdf/2506.13242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on algorithms for non-commutative matrix multiplication, which is unrelated to LLM training data processing activities such as data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14587",
      "abstract": "Medical imaging plays a vital role in early disease diagnosis and monitoring. Specifically, blood microscopy offers valuable insights into blood cell morphology and the detection of hematological disorders. In recent years, deep learning-based automated classification systems have demonstrated high potential in enhancing the accuracy and efficiency of blood image analysis. However, a detailed performance analysis of specific deep learning frameworks appears to be lacking. This paper compares the performance of three popular deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in classifying blood cell images from the publicly available BloodMNIST dataset. The study primarily focuses on inference time differences, but also classification performance for different image sizes. The results reveal variations in performance across frameworks, influenced by factors such as image resolution and framework-specific optimizations. Classification accuracy for JAX and PyTorch was comparable to current benchmarks, showcasing the efficiency of these frameworks for medical image classification.",
      "authors": [
        "Merjem Be\\'cirovi\\'c",
        "Amina Kurtovi\\'c",
        "Nordin Smajlovi\\'c",
        "Medina Kapo",
        "and Amila Akagi\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:05:14+00:00",
          "link": "https://arxiv.org/abs/2507.14587v1",
          "size": "1024kb",
          "version": "v1"
        }
      ],
      "title": "Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14587",
        "HTML": "https://arxiv.org/html/2507.14587",
        "PDF": "https://arxiv.org/pdf/2507.14587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study compares deep learning frameworks for medical image classification and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14765",
      "abstract": "In this paper, we mainly focus on the problem of multi-target observability, focusing on the unique state estimation criteria for multiple targets. We derive the condition which is necessary as well as sufficient for observability using bearing angles with multiple higher-order dynamics observed by a single observer. We then establish an alternative notion of observability by analyzing ambiguous target trajectories and deriving the condition which is NECNDSUF (Nec. and Suff.) for multi-target observability, considering three types of measurements: Doppler-only, bearing-only, and combined Doppler and bearing measurements, which offers insights that can improve target distinguishability, trajectory reconstruction, and overall tracking accuracy.",
      "authors": [
        "Debadrita Banerjee",
        "Debjani Mitra",
        "Rajesh Dey",
        "Mudassir Khan",
        "Lalan Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T22:39:36+00:00",
          "link": "https://arxiv.org/abs/2507.14765v1",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "title": "Multi Target Observability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14765",
        "HTML": "https://arxiv.org/html/2507.14765",
        "PDF": "https://arxiv.org/pdf/2507.14765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-target observability using specific measurement techniques for state estimation and trajectory reconstruction, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14796",
      "abstract": "Trusted Execution Environments (TEEs) are designed to protect the privacy and integrity of data in use. They enable secure data processing and sharing in peer-to-peer networks, such as vehicular ad hoc networks of autonomous vehicles, without compromising confidentiality. In these networks, nodes must establish mutual trust to collaborate securely. TEEs can achieve this through remote attestation, where a prover presents evidence of its trustworthiness to a verifier, which then decides whether or not to trust the prover. However, a naive peer-to-peer attestation approach, where every TEE directly attests every other TEE, results in quadratic communication overhead. This is inefficient in dynamic environments, where nodes frequently join and leave the network.\n  To address this, we present Careful Whisper, a gossip-based protocol that disseminates trust efficiently, reducing attestation overhead to linear complexity under ideal conditions. It enables interoperability by enabling transitive trust across heterogeneous networks, and supports trust establishment with offline nodes via relayed attestations. Using a custom discrete-event simulator, we show that Careful Whisper propagates trust both faster and more widely than naive approaches across various network topologies. Our results demonstrate that our protocol is resource efficient, sending ~21.5 KiB and requiring 0.158 seconds per round in a 200-node network, and that our protocol is resilient to attestation failures across various network topologies.",
      "authors": [
        "Ceren Kocao\\u{g}ullar",
        "Gustavo Petri",
        "Dominic P. Mulligan",
        "Derek Miller",
        "Hugo J. M. Vincent",
        "Shale Xiong",
        "Alastair R. Beresford"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:57:34+00:00",
          "link": "https://arxiv.org/abs/2507.14796v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "Careful Whisper: Attestation for peer-to-peer Confidential Computing networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14796",
        "HTML": "https://arxiv.org/html/2507.14796",
        "PDF": "https://arxiv.org/pdf/2507.14796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a protocol for secure data processing and trust in peer-to-peer networks using Trusted Execution Environments, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05375",
      "abstract": "Current automated fact-checking (AFC) approaches typically evaluate evidence either implicitly via the predicted verdicts or through exact matches with predefined closed knowledge sources, such as Wikipedia. However, these methods are limited due to their reliance on evaluation metrics originally designed for other purposes and constraints from closed knowledge sources. In this work, we introduce \\textbf{\\textcolor{skyblue}{Ev\\textsuperscript{2}}\\textcolor{orangebrown}{R}} which combines the strengths of reference-based evaluation and verdict-level proxy scoring. Ev\\textsuperscript{2}R jointly assesses how well the evidence aligns with the gold references and how reliably it supports the verdict, addressing the shortcomings of prior methods. We evaluate Ev\\textsuperscript{2}R against three types of evidence evaluation approaches: reference-based, proxy-reference, and reference-less baselines. Assessments against human ratings and adversarial tests demonstrate that Ev\\textsuperscript{2}R consistently outperforms existing scoring approaches in accuracy and robustness. It achieves stronger correlation with human judgments and greater robustness to adversarial perturbations, establishing it as a reliable metric for evidence evaluation in AFC.\\footnote{Code is available at \\href{https://github.com/mubasharaak/fc-evidence-evaluation}{https://github.com/mubasharaak/fc-evidence-evaluation}.}",
      "authors": [
        "Mubashara Akhtar",
        "Michael Schlichtkrull",
        "Andreas Vlachos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T07:05:06+00:00",
          "link": "https://arxiv.org/abs/2411.05375v1",
          "size": "9350kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T14:38:50+00:00",
          "link": "https://arxiv.org/abs/2411.05375v2",
          "size": "9288kb",
          "version": "v2"
        }
      ],
      "title": "Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05375",
        "HTML": "https://arxiv.org/html/2411.05375",
        "PDF": "https://arxiv.org/pdf/2411.05375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the study is on developing a metric for evaluating evidence retrieval in automated fact-checking, and it does not discuss LLM training data processing."
      },
      "tasks": [
        "Fact Checking",
        "nlg evaluation",
        "Retrieval",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09763",
      "abstract": "Scientists often infer abstract procedures from specific instances of problems and use the abstractions to generate new, related instances. For example, programs encoding the formal rules and properties of a system have been useful in fields ranging from reinforcement learning (procedural environments) to physics (simulation engines). These programs can be seen as functions which execute to different outputs based on their parameterizations (e.g., gridworld configuration or initial physical conditions). We introduce the term EFA (Executable Functional Abstraction) to denote such programs for math problems. EFA-like constructs have been shown to be useful for mathematical reasoning as problem generators for stress-testing models. However, prior work has been limited to automatically constructing abstractions for grade-school math (whose simple rules are easy to encode in programs), while generating EFAs for advanced math has thus far required human engineering. We explore the automatic construction of EFAs for advanced mathematics problems by developing EFAGen, which operationalizes the task of automatically inferring an EFA for a given seed problem and solution as a program synthesis task. We first formalize the properties of any valid EFA as executable unit tests. Using execution feedback from the unit tests, we search over candidate programs sampled from a LLM to find EFA programs that are faithful to the generalized problem and solution class underlying the seed problem. We then apply the tests as a reward signal, training LLMs to become better writers of EFAs. We show that EFAs inferred by EFAGen are faithful to the seed problems, produce learnable problem variations, and that EFAGen can infer EFAs across diverse sources of competition-level math problems. Finally, we show uses of model-written EFAs e.g., finding harder/easier problem variants, as well as data generation.",
      "authors": [
        "Zaid Khan",
        "Elias Stengel-Eskin",
        "Archiki Prasad",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T00:06:48+00:00",
          "link": "https://arxiv.org/abs/2504.09763v1",
          "size": "1412kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:41:39+00:00",
          "link": "https://arxiv.org/abs/2504.09763v2",
          "size": "1667kb",
          "version": "v2"
        }
      ],
      "title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09763",
        "PDF": "https://arxiv.org/pdf/2504.09763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions generating problem data for testing models through Executable Functional Abstractions (EFAs), which involves some data generation, but its main focus is on program synthesis rather than data processing for LLM training."
      },
      "models": [
        {
          "model_path": "codezakh/EFAGen-Llama-3.1-Instruct-8B",
          "downloads": "0",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/codezakh/EFAGen-Llama-3.1-Instruct-8B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "codezakh/EFAGen-Llama-3.1-8B-Instruct-Training-Data",
          "downloads": "26",
          "likes": "1",
          "link": "https://huggingface.co/datasets/codezakh/EFAGen-Llama-3.1-8B-Instruct-Training-Data"
        },
        {
          "dataset_name": "codezakh/NuminaMath-1.5-EFA-Subset",
          "downloads": "35",
          "likes": "1",
          "link": "https://huggingface.co/datasets/codezakh/NuminaMath-1.5-EFA-Subset"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13275",
      "abstract": "The ability to explain complex information from chart images is vital for effective data-driven decision-making. In this work, we address the challenge of generating detailed explanations alongside answering questions about charts. We present ChartQA-X, a comprehensive dataset comprising 30,299 chart samples across four chart types, each paired with contextually relevant questions, answers, and explanations. Explanations are generated and selected based on metrics such as faithfulness, informativeness, coherence, and perplexity. Our human evaluation with 245 participants shows that model-generated explanations in ChartQA-X surpass human-written explanations in accuracy and logic and are comparable in terms of clarity and overall quality. Moreover, models fine-tuned on ChartQA-X show substantial improvements across various metrics, including absolute gains of up to 24.57 points in explanation quality, 18.96 percentage points in question-answering accuracy, and 14.75 percentage points on unseen benchmarks for the same task. By integrating explanatory narratives with answers, our approach enables agents to communicate complex visual information more effectively, improving comprehension and fostering greater trust in the generated responses.",
      "authors": [
        "Shamanthak Hegde",
        "Pooyan Fazli",
        "Hasti Seifi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T18:36:57+00:00",
          "link": "https://arxiv.org/abs/2504.13275v1",
          "size": "11263kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T22:19:51+00:00",
          "link": "https://arxiv.org/abs/2504.13275v2",
          "size": "4372kb",
          "version": "v2"
        }
      ],
      "title": "ChartQA-X: Generating Explanations for Visual Chart Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13275",
        "HTML": "https://arxiv.org/html/2504.13275",
        "PDF": "https://arxiv.org/pdf/2504.13275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents ChartQA-X, a dataset designed for generating explanations in chart reasoning tasks. This involves creating new datasets that can improve the quality of data for training and fine-tuning, making it relevant to LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Explanation Generation",
        "Informativeness",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12555",
      "abstract": "Although existing models can interact with humans and provide satisfactory responses, they lack the ability to act autonomously or engage in independent reasoning. Furthermore, input data in these models is typically provided as explicit queries, even when some sensory data is already acquired.\n  In addition, AI agents, which are computational entities designed to perform tasks and make decisions autonomously based on their programming, data inputs, and learned knowledge, have shown significant progress. However, they struggle with integrating knowledge across multiple domains, unlike humans.\n  Mental imagery plays a fundamental role in the brain's thinking process, which involves performing tasks based on internal multisensory data, planned actions, needs, and reasoning capabilities. In this paper, we investigate how to integrate mental imagery into a machine thinking framework and how this could be beneficial in initiating the thinking process. Our proposed machine thinking framework integrates a Cognitive thinking unit supported by three auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery Unit. Within this framework, data is represented as natural language sentences or drawn sketches, serving both informative and decision-making purposes. We conducted validation tests for this framework, and the results are presented and discussed.",
      "authors": [
        "Slimane Larabi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.12555v1",
          "size": "3305kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:39:29+00:00",
          "link": "https://arxiv.org/abs/2507.12555v2",
          "size": "3305kb",
          "version": "v2"
        }
      ],
      "title": "Can Mental Imagery Improve the Thinking Capabilities of AI Systems?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12555",
        "HTML": "https://arxiv.org/html/2507.12555",
        "PDF": "https://arxiv.org/pdf/2507.12555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating mental imagery into AI systems for independent reasoning and decision-making, without any specific contribution to LLM training data processing or data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14217",
      "abstract": "We address the pattern explosion problem in pattern mining by proposing an interactive learning framework that combines nonlinear utility aggregation with geometry-aware query selection. Our method models user preferences through a Choquet integral over multiple interestingness measures and exploits the geometric structure of the version space to guide the selection of informative comparisons. A branch-and-bound strategy with tight distance bounds enables efficient identification of queries near the decision boundary. Experiments on UCI datasets show that our approach outperforms existing methods such as ChoquetRank, achieving better ranking accuracy with fewer user interactions.",
      "authors": [
        "Tudor Matei Opran",
        "Samir Loudni"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:41:45+00:00",
          "link": "https://arxiv.org/abs/2507.14217v1",
          "size": "505kb",
          "version": "v1"
        }
      ],
      "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14217",
        "HTML": "https://arxiv.org/html/2507.14217",
        "PDF": "https://arxiv.org/pdf/2507.14217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes an interactive learning framework for pattern mining by querying user preferences, which is not related to LLM training data processing strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15169",
      "abstract": "Despite the growing emphasis on intelligent buildings as a cornerstone of sustainable urban development, significant energy inefficiencies persist due to suboptimal design, material choices, and user behavior. The applicability of integrated Building Information Modeling (BIM) and solarpowered environmental monitoring systems for energy optimization in low-carbon smart buildings remains underexplored. Can BIM-driven design improvements, combined with photovoltaic systems, achieve substantial energy savings while enabling self-powered environmental monitoring? This study conducts a case analysis on a retrofitted primary school building in Guangdong, China, utilizing BIM-based energy simulations, material optimization, and solar technology integration. The outcomes reveal that the proposed approach reduced annual energy consumption by 40.68%, with lighting energy use decreasing by 36.59%. A rooftop photovoltaic system demonstrated a payback period of 7.46 years while powering environmental sensors autonomously. Hardware system integrates sensors and an ARDUINO-based controller to detect environmental factors like rainfall, temperature, and air quality. It is powered by a 6W solar panel and a 2200 mAh/7.4 V lithium battery to ensure stable operation. This study underscores the potential of BIM and solar energy integration to transform traditional buildings into energy-efficient, self-sustaining smart structures. Further research can expand the scalability of these methods across diverse climates and building typologies.",
      "authors": [
        "Yuhan Dai",
        "Mingtong Chen and Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T00:59:18+00:00",
          "link": "https://arxiv.org/abs/2507.15169v1",
          "size": "1641kb",
          "version": "v1"
        }
      ],
      "title": "Energy consumption optimization and self-powered environmental monitoring design for low-carbon smart buildings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15169",
        "HTML": "https://arxiv.org/html/2507.15169",
        "PDF": "https://arxiv.org/pdf/2507.15169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses energy consumption optimization and environmental monitoring for smart buildings, which is unrelated to LLM training data processing or any associated techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14209",
      "abstract": "As a leading research institute in software-intensive systems, fortiss is actively shaping the vision of Sixth Generation Mobile Communication (6G). Our mission is to ensure that 6G technologies go beyond technical advancements and are aligned with societal needs. fortiss plays a key role in 6G initiatives worldwide, including contributions to standardization bodies and collaborative Research and Development programs. We focus on software-defined, AI-enabled, and sustainable communication services that prioritize human values and long-term impact. 6G will redefine digital connectivity through cognitive intelligence, decentralized orchestration, and sustainability-oriented architectures. As expectations rise for ultra-reliable low-latency communication (URLLC) and personalized digital services, 6G must outperform prior generations. It will rely on AI-native networking, Edge-Cloud resource orchestration, and energy-aware data frameworks, ensuring both technical performance and societal relevance. This white paper presents the fortiss vision for a human-centric, sustainable, and AI-integrated 6G network. It outlines key research domains such as semantic communication, green orchestration, and distributed AI, all linked to societal and technological challenges. The white paper is aimed at researchers, industry experts, policymakers, and developers. It articulates the strategic direction and contributions of fortiss to 6G, emphasizing responsible innovation and interdisciplinary collaboration toward a meaningful 2030 vision.",
      "authors": [
        "Rute C. Sofia",
        "Hao Shen",
        "Yuanting Liu",
        "Severin Kacianka",
        "Holger Pfeifer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:39:47+00:00",
          "link": "https://arxiv.org/abs/2507.14209v1",
          "size": "1359kb",
          "version": "v1"
        }
      ],
      "title": "White paper: Towards Human-centric and Sustainable 6G Services -- the fortiss Research Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14209",
        "HTML": "https://arxiv.org/html/2507.14209",
        "PDF": "https://arxiv.org/pdf/2507.14209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This white paper discusses the future of 6G technologies, emphasizing AI-enabled communication services and sustainability, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14346",
      "abstract": "Phonetic error detection, a core subtask of automatic pronunciation assessment, identifies pronunciation deviations at the phoneme level. Speech variability from accents and dysfluencies challenges accurate phoneme recognition, with current models failing to capture these discrepancies effectively. We propose a verbatim phoneme recognition framework using multi-task training with novel phoneme similarity modeling that transcribes what speakers actually say rather than what they're supposed to say. We develop and open-source \\textit{VCTK-accent}, a simulated dataset containing phonetic errors, and propose two novel metrics for assessing pronunciation differences. Our work establishes a new benchmark for phonetic error detection.",
      "authors": [
        "Xuanru Zhou",
        "Jiachen Lian",
        "Cheol Jun Cho",
        "Tejas Prabhune",
        "Shuhe Li",
        "William Li",
        "Rodrigo Ortiz",
        "Zoe Ezzes",
        "Jet Vonk",
        "Brittany Morin",
        "Rian Bogley",
        "Lisa Wauters",
        "Zachary Miller",
        "Maria Gorno-Tempini",
        "Gopala Anumanchipalli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:51:56+00:00",
          "link": "https://arxiv.org/abs/2507.14346v1",
          "size": "665kb",
          "version": "v1"
        }
      ],
      "title": "Towards Accurate Phonetic Error Detection Through Phoneme Similarity Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14346",
        "HTML": "https://arxiv.org/html/2507.14346",
        "PDF": "https://arxiv.org/pdf/2507.14346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is focused on phonetic error detection through phoneme similarity modeling in speech recognition, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.20090",
      "abstract": "Multimodal Large Language Models (MLLMs) demonstrate exceptional performance in cross-modality interaction, yet they also suffer adversarial vulnerabilities. In particular, the transferability of adversarial examples remains an ongoing challenge. In this paper, we specifically analyze the manifestation of adversarial transferability among MLLMs and identify the key factors that influence this characteristic. We discover that the transferability of MLLMs exists in cross-LLM scenarios with the same vision encoder and indicate \\underline{\\textit{two key Factors}} that may influence transferability. We provide two semantic-level data augmentation methods, Adding Image Patch (AIP) and Typography Augment Transferability Method (TATM), which boost the transferability of adversarial examples across MLLMs. To explore the potential impact in the real world, we utilize two tasks that can have both negative and positive societal impacts: \\ding{182} Harmful Content Insertion and \\ding{183} Information Protection.",
      "authors": [
        "Hao Cheng",
        "Erjia Xiao",
        "Jiayan Yang",
        "Jinhao Duan",
        "Yichi Wang",
        "Jiahang Cao",
        "Qiang Zhang",
        "Le Yang",
        "Kaidi Xu",
        "Jindong Gu",
        "Renjing Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-30T14:27:20+00:00",
          "link": "https://arxiv.org/abs/2405.20090v1",
          "size": "8956kb",
          "version": "v1"
        },
        {
          "date": "2024-09-19T03:31:48+00:00",
          "link": "https://arxiv.org/abs/2405.20090v2",
          "size": "8957kb",
          "version": "v2"
        },
        {
          "date": "2024-10-22T17:36:30+00:00",
          "link": "https://arxiv.org/abs/2405.20090v3",
          "size": "14977kb",
          "version": "v3"
        },
        {
          "date": "2025-07-07T16:28:58+00:00",
          "link": "https://arxiv.org/abs/2405.20090v4",
          "size": "14978kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T08:41:47+00:00",
          "link": "https://arxiv.org/abs/2405.20090v5",
          "size": "5355kb",
          "version": "v5"
        }
      ],
      "title": "Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.20090",
        "HTML": "https://arxiv.org/html/2405.20090",
        "PDF": "https://arxiv.org/pdf/2405.20090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing and boosting adversarial transferability across multimodal large language models, specifically through data augmentation methods for adversarial examples. It does not address LLM training data processing for pretraining or fine-tuning."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00651",
      "abstract": "This paper presents an innovative pedagogical framework employing tangible interactive games to enhance artificial intelligence (AI) knowledge and literacy among elementary education students. Recognizing the growing importance of AI competencies in the 21st century, this study addresses the critical need for age-appropriate, experiential learning tools that demystify core AI concepts for young learners. The proposed approach integrates physical role-playing activities that embody fundamental AI principles, including neural networks, decision-making, machine learning, and pattern recognition. Through carefully designed game mechanics, students actively engage in collaborative problem solving, fostering deeper conceptual understanding and critical thinking skills. The framework further supports educators by providing detailed guidance on implementation and pedagogical objectives, thus facilitating effective AI education in early childhood settings. Empirical insights and theoretical grounding demonstrate the potential of tangible interactive games to bridge the gap between abstract AI theories and practical comprehension, ultimately promoting AI literacy at foundational educational levels. The study contributes to the growing discourse on AI education by offering scalable and adaptable strategies that align with contemporary curricular demands and prepare young learners for a technologically driven future.",
      "authors": [
        "Nikolaos Sampanis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T17:40:30+00:00",
          "link": "https://arxiv.org/abs/2506.00651v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Innovative Tangible Interactive Games for Enhancing Artificial Intelligence Knowledge and Literacy in Elementary Education: A Pedagogical Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00651",
        "HTML": "https://arxiv.org/html/2506.00651",
        "PDF": "https://arxiv.org/pdf/2506.00651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a pedagogical framework using interactive games to teach AI concepts to elementary students. It does not pertain to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08297",
      "abstract": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage. Notably, KAT outperforms all open-source models and even surpasses o3-mini on the leakage-controlled LiveCodeBench Pro. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishou's internal coding assistant), where it improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) model with 40B active parameters, and early results already show significant gains, further demonstrating the scalability of the AutoThink paradigm.",
      "authors": [
        "Zizheng Zhan",
        "Ken Deng",
        "Huaixi Tang",
        "Wen Xiang",
        "Kun Wu",
        "Weihao Li",
        "Wenqiang Zhu",
        "Jingxuan Xu",
        "Lecheng Huang",
        "Zongxian Feng",
        "Shaojie Wang",
        "Shangpeng Yan",
        "Xuxing Chen",
        "Jiaheng Liu",
        "Zhongyuan Peng",
        "Zuchen Gao",
        "Haoyang Huang",
        "Xiaojiang Zhang",
        "Jinghui Wang",
        "Zheng Lin",
        "Mengtong Li",
        "Huiming Wang",
        "Ziqi Zhan",
        "Yanan Wu",
        "Yuanxing Zhang",
        "Jian Yang",
        "Guang Chen",
        "Haotian Zhang",
        "Bin Chen",
        "Bing Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.08297v1",
          "size": "14313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:04:21+00:00",
          "link": "https://arxiv.org/abs/2507.08297v2",
          "size": "14313kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:37:40+00:00",
          "link": "https://arxiv.org/abs/2507.08297v3",
          "size": "14390kb",
          "version": "v3"
        }
      ],
      "title": "KAT-V1: Kwai-AutoThink Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08297",
        "HTML": "https://arxiv.org/html/2507.08297",
        "PDF": "https://arxiv.org/pdf/2507.08297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses Kwaipilot-AutoThink, a model that incorporates a dataset for reasoning tasks. Although it mentions data construction, the main focus is on model reasoning and performance rather than direct contributions to LLM training data processing."
      },
      "models": [
        {
          "model_path": "Kwaipilot/KAT-V1-40B",
          "downloads": "0",
          "likes": "11",
          "trending_score": "11.0",
          "link": "https://huggingface.co/Kwaipilot/KAT-V1-40B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14632",
      "abstract": "Recent advances in generative AI have dramatically improved image and video synthesis capabilities, significantly increasing the risk of misinformation through sophisticated fake content. In response, detection methods have evolved from traditional approaches to multimodal large language models (MLLMs), offering enhanced transparency and interpretability in identifying synthetic media. However, current detection systems remain fundamentally limited by their single-modality design. These approaches analyze images or videos separately, making them ineffective against synthetic content that combines multiple media formats. To address these challenges, we introduce \\textbf{BusterX++}, a novel framework designed specifically for cross-modal detection and explanation of synthetic media. Our approach incorporates an advanced reinforcement learning (RL) post-training strategy that eliminates cold-start. Through Multi-stage Training, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and substantial performance improvements. To enable comprehensive evaluation, we also present \\textbf{GenBuster++}, a cross-modal benchmark leveraging state-of-the-art image and video generation techniques. This benchmark comprises 4,000 images and video clips, meticulously curated by human experts using a novel filtering methodology to ensure high quality, diversity, and real-world applicability. Extensive experiments demonstrate the effectiveness and generalizability of our approach.",
      "authors": [
        "Haiquan Wen",
        "Tianxiao Li",
        "Zhenglin Huang",
        "Yiwei He",
        "Guangliang Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.14632v1",
          "size": "27224kb",
          "version": "v1"
        }
      ],
      "title": "BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14632",
        "HTML": "https://arxiv.org/html/2507.14632",
        "PDF": "https://arxiv.org/pdf/2507.14632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with cross-modal AI-generated content detection and explanation, which is not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15418",
      "abstract": "Surgical phase recognition plays a crucial role in surgical workflow analysis, enabling various applications such as surgical monitoring, skill assessment, and workflow optimization. Despite significant advancements in deep learning-based surgical phase recognition, these models remain inherently opaque, making it difficult to understand how they make decisions. This lack of interpretability hinders trust and makes it challenging to debug the model. To address this challenge, we propose SurgX, a novel concept-based explanation framework that enhances the interpretability of surgical phase recognition models by associating neurons with relevant concepts. In this paper, we introduce the process of selecting representative example sequences for neurons, constructing a concept set tailored to the surgical video dataset, associating neurons with concepts and identifying neurons crucial for predictions. Through extensive experiments on two surgical phase recognition models, we validate our method and analyze the explanation for prediction. This highlights the potential of our method in explaining surgical phase recognition. The code is available at https://github.com/ailab-kyunghee/SurgX",
      "authors": [
        "Ka Young Kim",
        "Hyeon Bae Kim",
        "Seong Tae Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:19:34+00:00",
          "link": "https://arxiv.org/abs/2507.15418v1",
          "size": "2541kb",
          "version": "v1"
        }
      ],
      "title": "SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15418",
        "HTML": "https://arxiv.org/html/2507.15418",
        "PDF": "https://arxiv.org/pdf/2507.15418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around explainable surgical phase recognition and does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09516",
      "abstract": "Efficiently acquiring external knowledge and up-to-date information is essential for effective reasoning and text generation in large language models (LLMs). Prompting advanced LLMs with reasoning capabilities to use search engines during inference is often suboptimal, as the LLM might not fully possess the capability on how to interact optimally with the search engine. This paper introduces Search-R1, an extension of reinforcement learning (RL) for reasoning frameworks where the LLM learns to autonomously generate (multiple) search queries during step-by-step reasoning with real-time retrieval. Search-R1 optimizes LLM reasoning trajectories with multi-turn search interactions, leveraging retrieved token masking for stable RL training and a simple outcome-based reward function. Experiments on seven question-answering datasets show that Search-R1 improves performance by 41% (Qwen2.5-7B) and 20% (Qwen2.5-3B) over various RAG baselines under the same setting. This paper further provides empirical insights into RL optimization methods, LLM choices, and response length dynamics in retrieval-augmented reasoning. The code and model checkpoints are available at https://github.com/PeterGriffinJin/Search-R1.",
      "authors": [
        "Bowen Jin",
        "Hansi Zeng",
        "Zhenrui Yue",
        "Jinsung Yoon",
        "Sercan Arik",
        "Dong Wang",
        "Hamed Zamani",
        "Jiawei Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T16:26:39+00:00",
          "link": "https://arxiv.org/abs/2503.09516v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T21:40:12+00:00",
          "link": "https://arxiv.org/abs/2503.09516v2",
          "size": "195kb",
          "version": "v2"
        },
        {
          "date": "2025-04-08T14:03:26+00:00",
          "link": "https://arxiv.org/abs/2503.09516v3",
          "size": "310kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T03:50:13+00:00",
          "link": "https://arxiv.org/abs/2503.09516v4",
          "size": "250kb",
          "version": "v4"
        }
      ],
      "title": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09516",
        "HTML": "https://arxiv.org/html/2503.09516",
        "PDF": "https://arxiv.org/pdf/2503.09516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces reinforcement learning for enabling LLMs to utilize search engines effectively during reasoning and text generation. It does not focus on data processing or dataset creation for LLM training."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Reinforcement Learning (RL)",
        "Retrieval",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/petergriffinjin/search-r1",
        "https://github.com/ruc-nlpir/flashrag",
        "https://github.com/terrierteam/pyterrier_rag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23898",
      "abstract": "Accurate evaluation of regional lung ventilation is essential for the management and treatment of lung cancer patients, supporting assessments of pulmonary function, optimization of therapeutic strategies, and monitoring of treatment response. Currently, ventilation scintigraphy using nuclear medicine techniques is widely employed in clinical practice; however, it is often time-consuming, costly, and entails additional radiation exposure. In this study, we propose an explainable neural radiomic sequence model to identify regions of compromised pulmonary ventilation based on four-dimensional computed tomography (4DCT). A cohort of 45 lung cancer patients from the VAMPIRE dataset was analyzed. For each patient, lung volumes were segmented from 4DCT, and voxel-wise radiomic features (56-dimensional) were extracted across the respiratory cycle to capture local intensity and texture dynamics, forming temporal radiomic sequences. Ground truth ventilation defects were delineated voxel-wise using Galligas-PET and DTPA-SPECT. To identify compromised regions, we developed a temporal saliency-enhanced explainable long short-term memory (LSTM) network trained on the radiomic sequences. Temporal saliency maps were generated to highlight key features contributing to the model's predictions. The proposed model demonstrated robust performance, achieving average (range) Dice similarity coefficients of 0.78 (0.74-0.79) for 25 PET cases and 0.78 (0.74-0.82) for 20 SPECT cases. The temporal saliency map explained three key radiomic sequences in ventilation quantification: during lung exhalation, compromised pulmonary function region typically exhibits (1) an increasing trend of intensity and (2) a decreasing trend of homogeneity, in contrast to healthy lung tissue.",
      "authors": [
        "Rihui Zhang",
        "Haiming Zhu",
        "Jingtong Zhao",
        "Lei Zhang",
        "Fang-Fang Yin",
        "Chunhao Wang and Zhenyu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T09:47:03+00:00",
          "link": "https://arxiv.org/abs/2503.23898v1",
          "size": "3422kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T06:25:05+00:00",
          "link": "https://arxiv.org/abs/2503.23898v2",
          "size": "4118kb",
          "version": "v2"
        }
      ],
      "title": "An Explainable Neural Radiomic Sequence Model with Spatiotemporal Continuity for Quantifying 4DCT-based Pulmonary Ventilation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23898",
        "PDF": "https://arxiv.org/pdf/2503.23898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a neural radiomic sequence model for quantifying pulmonary ventilation based on 4DCT, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.16582",
      "abstract": "We study randomized quasi-Monte Carlo (RQMC) estimation of a multivariate integral where one of the variables takes only a finite number of values. This problem arises when the variable of integration is drawn from a mixture distribution as is common in importance sampling and also arises in some recent work on transport maps. We find that when integration error decreases at an RQMC rate that it is then beneficial to oversample the smallest mixture components instead of using a proportional allocation. The optimal allocations depend on the possibly unknown convergence rates. Designing the sample with an incorrect assumption on the rate still attains that convergence rate, with an inferior implied constant. The penalty for using a pessimistic rate is typically higher than for using an optimistic one. We also find that for the most accurate RQMC sampling methods, it is advantageous to arrange that our $n=2^m$ randomized Sobol' points split into subsample sizes that are also powers of $2$.",
      "authors": [
        "Valerie N. P. Ho and Art B. Owen and Zexin Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T20:15:43+00:00",
          "link": "https://arxiv.org/abs/2506.16582v1",
          "size": "786kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:24:44+00:00",
          "link": "https://arxiv.org/abs/2506.16582v2",
          "size": "784kb",
          "version": "v2"
        }
      ],
      "title": "Quasi-Monte Carlo with one categorical variable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16582",
        "HTML": "https://arxiv.org/html/2506.16582",
        "PDF": "https://arxiv.org/pdf/2506.16582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses randomized quasi-Monte Carlo methods for multivariate integrals, with no relation to LLM training data processing or any relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14681",
      "abstract": "Background: Medical coding structures healthcare data for research, quality monitoring, and policy. This study assesses the potential of large language models (LLMs) to assign ICPC-2 codes using the output of a domain-specific search engine.\n  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's text-embedding-3-large) retrieved candidates from 73,563 labeled concepts. Thirty-three LLMs were prompted with each query and retrieved results to select the best-matching ICPC-2 code. Performance was evaluated using F1-score, along with token usage, cost, response time, and format adherence.\n  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever optimization can improve performance by up to 4 points. Most models returned valid codes in the expected format, with reduced hallucinations. Smaller models (<3B) struggled with formatting and input length.\n  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even without fine-tuning. This work offers a benchmark and highlights challenges, but findings are limited by dataset scope and setup. Broader, multilingual, end-to-end evaluations are needed for clinical validation.",
      "authors": [
        "Vinicius Anjos de Almeida",
        "Vinicius de Camargo",
        "Raquel G\\'omez-Bravo",
        "Egbert van der Haring",
        "Kees van Boven",
        "Marcelo Finger",
        "Luis Fernandez Lopez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:11:10+00:00",
          "link": "https://arxiv.org/abs/2507.14681v1",
          "size": "2035kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14681",
        "HTML": "https://arxiv.org/html/2507.14681",
        "PDF": "https://arxiv.org/pdf/2507.14681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the application of LLMs for medical code selection using a dataset specific to Brazilian Portuguese clinical expressions, without discussing contributions to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14705",
      "abstract": "Large-language-model (LLM) agents exhibit complex, context-sensitive behaviour that quickly renders static benchmarks and ad-hoc manual testing obsolete.\n  We present Neo, a configurable, multi-agent framework that automates realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question Generation Agent and an Evaluation Agent through a shared context-hub, allowing domain prompts, scenario controls and dynamic feedback to be composed modularly. Test inputs are sampled from a probabilistic state model spanning dialogue flow, user intent and emotional tone, enabling diverse, human-like conversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i) uncovered edge-case failures across five attack categories with a 3.3% break rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered 10-12X higher throughput, generating 180 coherent test questions in around 45 mins versus 16h of human effort. Beyond security probing, Neo's stochastic policies balanced topic coverage and conversational depth, yielding broader behavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent interfaces, state controller and feedback loops are model-agnostic and extensible to richer factual-grounding and policy-compliance checks. We release the framework to facilitate reproducible, high-fidelity testing of emerging agentic systems.",
      "authors": [
        "Sai Wang",
        "Senthilnathan Subramanian",
        "Mudit Sahni",
        "Praneeth Gone",
        "Lingjie Meng",
        "Xiaochen Wang",
        "Nicolas Ferradas Bertoli",
        "Tingxian Cheng",
        "Jun Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:51:25+00:00",
          "link": "https://arxiv.org/abs/2507.14705v1",
          "size": "853kb",
          "version": "v1"
        }
      ],
      "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14705",
        "HTML": "https://arxiv.org/html/2507.14705",
        "PDF": "https://arxiv.org/pdf/2507.14705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents the Neo framework for testing LLM-based agents but does not address any aspects of LLM training data processing such as data collection or generation for model pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14852",
      "abstract": "The maximum achievable capacity from source to destination in a network is limited by the min-cut max-flow bound; this serves as a converse limit. In practice, link capacities often fluctuate due to dynamic network conditions. In this work, we introduce a novel analytical framework that leverages tools from computational geometry to analyze throughput in heterogeneous networks with variable link capacities in a finite regime. Within this model, we derive new performance bounds and demonstrate that increasing the number of links can reduce throughput variability by nearly $90\\%$. We formally define a notion of network stability and show that an unstable graph can have an exponential number of different min-cut sets, up to $O(2^{|E|})$. To address this complexity, we propose an algorithm that enforces stability with time complexity $O(|E|^2 + |V|)$, and further suggest mitigating the delay-throughput tradeoff using adaptive rateless random linear network coding (AR-RLNC).",
      "authors": [
        "Rivka Gitik and Alejandro Cohen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Computational Geometry (cs.CG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:46:37+00:00",
          "link": "https://arxiv.org/abs/2507.14852v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14852",
        "HTML": "https://arxiv.org/html/2507.14852",
        "PDF": "https://arxiv.org/pdf/2507.14852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for analyzing network throughput involving dynamic link capacities, which is not related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15025",
      "abstract": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to revolutionize many industrial areas by reducing the amount of human intervention needed and effort for handling complex underlying processes. Automotive software development is considered to be a significant area for GenAI adoption, taking into account lengthy and expensive procedures, resulting from the amount of requirements and strict standardization. In this paper, we explore the adoption of GenAI for various steps of automotive software development, mainly focusing on requirements handling, compliance aspects and code generation. Three GenAI-related technologies are covered within the state-of-art: Large Language Models (LLMs), Retrieval Augmented Generation (RAG), Vision Language Models (VLMs), as well as overview of adopted prompting techniques in case of code generation. Additionally, we also derive a generalized GenAI-aided automotive software development workflow based on our findings from this literature review. Finally, we include a summary of a survey outcome, which was conducted among our automotive industry partners regarding the type of GenAI tools used for their daily work activities.",
      "authors": [
        "Nenad Petrovic",
        "Vahid Zolfaghari",
        "Andre Schamschurko",
        "Sven Kirchner",
        "Fengjunjie Pan",
        "Chengdng Wu",
        "Nils Purschke",
        "Aleksei Velsh",
        "Krzysztof Lebioda",
        "Yinglei Song",
        "Yi Zhang",
        "Lukasz Mazur",
        "Alois Knoll"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:21:51+00:00",
          "link": "https://arxiv.org/abs/2507.15025v1",
          "size": "1163kb",
          "version": "v1"
        }
      ],
      "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15025",
        "HTML": "https://arxiv.org/html/2507.15025",
        "PDF": "https://arxiv.org/pdf/2507.15025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the adoption of Generative AI in automotive software development, specifically addressing requirements handling, compliance, and code generation. It does not contribute to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15116",
      "abstract": "Faster-than-Nyquist signaling serves as a promising solution for improving spectral efficiency in future generations of communications. However, its nature of fast acceleration brings highly overlapped pulses that lead to worse peak-to-average power ratio (PAPR) performance. In this paper, we investigate the PAPR behavior of MIMO FTN using Gaussian symbols under optimal power allocation for two power constraints: fixed transmit power and fixed received signal-to-noise-ratio (SNR). Our findings reveal that PAPR is mainly determined by the acceleration factor and the power constraint, but power allocation optimization does not change the PAPR behavior for Gaussian signaling.",
      "authors": [
        "Zichao Zhang",
        "Melda Yuksel",
        "Gokhan M. Guvensen and Halim Yanikomeroglu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:31:20+00:00",
          "link": "https://arxiv.org/abs/2507.15116v1",
          "size": "446kb",
          "version": "v1"
        }
      ],
      "title": "PAPR Analysis for MIMO FTN Signaling with Gaussian Symbols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15116",
        "HTML": "https://arxiv.org/html/2507.15116",
        "PDF": "https://arxiv.org/pdf/2507.15116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the PAPR behavior of MIMO FTN signaling in communications, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15322",
      "abstract": "This work investigates the local convergence behavior of Anderson acceleration in solving nonlinear systems. We establish local R-linear convergence results for Anderson acceleration with general depth $m$ under the assumptions that the Jacobian of the nonlinear operator is H\\\"older continuous and the corresponding fixed-point function is contractive. In the Lipschitz continuous case, we obtain a sharper R-linear convergence factor. We also derive a refined residual bound for the depth $m = 1$ under the same assumptions used for the general depth results. Applications to a nonsymmetric Riccati equation from transport theory demonstrate that Anderson acceleration yields comparable results to several existing fixed-point methods for the regular cases, and that it brings significant reductions in both the number of iterations and computation time, even in challenging cases involving nearly singular or large-scale problems.",
      "authors": [
        "Yonghui Ling",
        "Zikang Xiong",
        "Juan Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:23:56+00:00",
          "link": "https://arxiv.org/abs/2507.15322v1",
          "size": "2915kb",
          "version": "v1"
        }
      ],
      "title": "Convergence analysis of Anderson acceleration for nonlinear equations with H\\\"older continuous derivatives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15322",
        "PDF": "https://arxiv.org/pdf/2507.15322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the convergence analysis of Anderson acceleration in solving nonlinear systems, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15470",
      "abstract": "In-vehicle emotion recognition underpins adaptive driver-assistance systems and, ultimately, occupant safety. However, practical deployment is hindered by (i) modality fragility - poor lighting and occlusions degrade vision-based methods; (ii) physiological variability - heart-rate and skin-conductance patterns differ across individuals; and (iii) privacy risk - centralized training requires transmission of sensitive data. To address these challenges, we present FedMultiEmo, a privacy-preserving framework that fuses two complementary modalities at the decision level: visual features extracted by a Convolutional Neural Network from facial images, and physiological cues (heart rate, electrodermal activity, and skin temperature) classified by a Random Forest. FedMultiEmo builds on three key elements: (1) a multimodal federated learning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud prototype on Raspberry Pi clients and a Flower server, and (3) a personalized Federated Averaging scheme that weights client updates by local data volume. Evaluated on FER2013 and a custom physiological dataset, the federated Convolutional Neural Network attains 77% accuracy, the Random Forest 74%, and their fusion 87%, matching a centralized baseline while keeping all raw data local. The developed system converges in 18 rounds, with an average round time of 120 seconds and a per-client memory footprint below 200 MB. These results indicate that FedMultiEmo offers a practical approach to real-time, privacy-aware emotion recognition in automotive settings.",
      "authors": [
        "Baran Can G\\\"ul",
        "Suraksha Nadig",
        "Stefanos Tziampazis",
        "Nasser Jazdi",
        "Michael Weyrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:21:48+00:00",
          "link": "https://arxiv.org/abs/2507.15470v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15470",
        "HTML": "https://arxiv.org/html/2507.15470",
        "PDF": "https://arxiv.org/pdf/2507.15470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on emotion recognition using federated learning in automotive settings, focusing on privacy and multimodal data fusion techniques, which are not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.08321",
      "abstract": "The iterated Arnoldi-Tikhonov (iAT) method is a regularization technique particularly suited for solving large-scale ill-posed linear inverse problems. Indeed, it reduces the computational complexity through the projection of the discretized problem into a lower-dimensional Krylov subspace, where the problem is then solved.\n  This paper studies iAT under an additional hypothesis on the discretized operator. It presents a theoretical analysis of the approximation errors, leading to an a posteriori rule for choosing the regularization parameter. Our proposed rule results in more accurate computed approximate solutions compared to the a posteriori rule recently proposed in arXiv:2311.11823. The numerical results confirm the theoretical analysis, providing accurate computed solutions even when the new assumption is not satisfied.",
      "authors": [
        "Marco Donatelli and Davide Furch\\`i"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-12T08:27:55+00:00",
          "link": "https://arxiv.org/abs/2404.08321v1",
          "size": "122kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:03:57+00:00",
          "link": "https://arxiv.org/abs/2404.08321v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Improved parameter selection strategy for the iterated Arnoldi-Tikhonov method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.08321",
        "HTML": "https://arxiv.org/html/2404.08321",
        "PDF": "https://arxiv.org/pdf/2404.08321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses parameter selection in the iterated Arnoldi-Tikhonov method, which is related to solving linear inverse problems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00286",
      "abstract": "Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to interpret and manage visual content in their daily lives. While such tools can enhance the accessibility of visual content and so enable greater user independence, they also introduce complex challenges around visual privacy. In this paper, we investigate the current practices and future design preferences of blind and low vision individuals through an interview study with 21 participants. Our findings reveal a range of current practices with GenAI that balance privacy, efficiency, and emotional agency, with users accounting for privacy risks across six key scenarios, such as self-presentation, indoor/outdoor spatial privacy, social sharing, and handling professional content. Our findings reveal design preferences, including on-device processing, zero-retention guarantees, sensitive content redaction, privacy-aware appearance indicators, and multimodal tactile mirrored interaction methods. We conclude with actionable design recommendations to support user-centered visual privacy through GenAI, expanding the notion of privacy and responsible handling of others data.",
      "authors": [
        "Tanusree Sharma",
        "Yu-Yun Tseng",
        "Lotus Zhang",
        "Ayae Ide",
        "Kelly Avery Mack",
        "Leah Findlater",
        "Danna Gurari",
        "Yang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T21:55:21+00:00",
          "link": "https://arxiv.org/abs/2507.00286v1",
          "size": "3283kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:31:05+00:00",
          "link": "https://arxiv.org/abs/2507.00286v2",
          "size": "3282kb",
          "version": "v2"
        }
      ],
      "title": "\"Before, I Asked My Mom, Now I Ask ChatGPT\": Visual Privacy Management with Generative AI for Blind and Low-Vision People",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00286",
        "HTML": "https://arxiv.org/html/2507.00286",
        "PDF": "https://arxiv.org/pdf/2507.00286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with visual privacy management using generative AI for blind and low-vision individuals, focusing on design preferences and privacy issues rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14952",
      "abstract": "This is an expository paper which discusses an approach to the LQG/LTR design problem for finite-dimensional SISO control systems. The approach is based on the utilisation of weighting augmentation for incorporating design specifications into the framework of the LTR technique for LQG compensator design. The LQG compensator is to simultaneously meet given analytical low- and high-frequency design specifications expressed in terms of desirable sensitivity and controller noise sensitivity functions. The paper is aimed at nonspecialists and, in particular, practitioners in finite-dimensional LQG theory interested in the design of feedback compensators for closed-loop performance and robustness shaping of SISO control systems in realistic situations. The proposed approach is illustrated by a detailed numerical example: the torque control of a current-controlled DC motor with an elastically mounted rotor.",
      "authors": [
        "Mahyar Mahinzaeim and Kamyar Mehran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:20:36+00:00",
          "link": "https://arxiv.org/abs/2507.14952v1",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "title": "An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14952",
        "HTML": "https://arxiv.org/html/2507.14952",
        "PDF": "https://arxiv.org/pdf/2507.14952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses LQG/LTR design for control systems, focusing on feedback compensator design with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15036",
      "abstract": "Underwater image enhancement is vital for marine conservation, particularly coral reef monitoring. However, AI-based enhancement models often face dataset bias, high computational costs, and lack of transparency, leading to potential misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware AI framework to address these challenges. EBA-AI leverages CLIP embeddings to detect and mitigate dataset bias, ensuring balanced representation across varied underwater environments. It also integrates adaptive processing to optimize energy efficiency, significantly reducing GPU usage while maintaining competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100 show that while PSNR drops by a controlled 1.0 dB, computational savings enable real-time feasibility for large-scale marine monitoring. Additionally, uncertainty estimation and explainability techniques enhance trust in AI-driven environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet, WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing efficiency, fairness, and interpretability in underwater image processing. By addressing key limitations of AI-driven enhancement, this work contributes to sustainable, bias-aware, and computationally efficient marine conservation efforts. For interactive visualizations, animations, source code, and access to the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/",
      "authors": [
        "Lyes Saad Saoud and Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:37:37+00:00",
          "link": "https://arxiv.org/abs/2507.15036v1",
          "size": "13465kb",
          "version": "v1"
        }
      ],
      "title": "EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15036",
        "HTML": "https://arxiv.org/html/2507.15036",
        "PDF": "https://arxiv.org/pdf/2507.15036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces EBA-AI for underwater image enhancement, focusing on dataset bias in AI models, but it does not relate to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15264",
      "abstract": "We study a nonsmooth nonconvex optimization problem defined over nonconvex constraints, where the feasible set is given by the intersection of the closure of an open set and a smooth manifold. By endowing the open set with a Riemannian metric induced by a barrier function, we obtain a Riemannian subgradient flow formulated as a differential inclusion, which remains strictly within the interior of the feasible set. This continuous dynamical system unifies two classes of iterative optimization methods, namely the Hessian barrier method and mirror descent scheme, by revealing that these methods can be interpreted as discrete approximations of the continuous flow. We explore the long-term behavior of the trajectories generated by this dynamical system and show that the existing deficient convergence properties of the Hessian barrier and mirror descent scheme can be unifily and more insightfully interpreted through these of the continuous trajectory. For instance, the notorious spurious stationary points \\cite{chen2024spurious} observed in Hessian barrier method and mirror descent scheme are interpreted as stable equilibria of the dynamical system that do not correspond to real stationary points of the original optimization problem. We provide two sufficient condition such that these spurious stationary points can be avoided if the strict complementarity conditions holds. In the absence of these regularity condition, we propose a random perturbation strategy that ensures the trajectory converges (subsequentially) to an approximate stationary point. Building on these insights, we introduce two iterative Riemannian subgradient methods, form of interior point methods, that generalizes the existing Hessian barrier method and mirror descent scheme for solving nonsmooth nonconvex optimization problems.",
      "authors": [
        "Kuangyu Ding and Kim-Chuan Toh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:58:52+00:00",
          "link": "https://arxiv.org/abs/2507.15264v1",
          "size": "169kb",
          "version": "v1"
        }
      ],
      "title": "On exploration of an interior mirror descent flow for stochastic nonconvex constrained problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15264",
        "HTML": "https://arxiv.org/html/2507.15264",
        "PDF": "https://arxiv.org/pdf/2507.15264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with optimization problems and the development of optimization methods. It does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01639",
      "abstract": "Deep Neural Networks (DNN) are crucial in approximating nonlinear functions across diverse applications, ranging from image classification to control. Verifying specific input-output properties can be a highly challenging task due to the lack of a single, self-contained framework that allows a complete range of verification types. To this end, we present \\texttt{ModelVerification.jl (MV)}, the first comprehensive, cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying different types of DNNs and safety specifications. This versatile toolbox is designed to empower developers and machine learning practitioners with robust tools for verifying and ensuring the trustworthiness of their DNN models.",
      "authors": [
        "Tianhao Wei",
        "Hanjiang Hu",
        "Luca Marzari",
        "Kai S. Yun",
        "Peizhi Niu",
        "Xusheng Luo",
        "and Changliu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-30T20:15:31+00:00",
          "link": "https://arxiv.org/abs/2407.01639v1",
          "size": "3160kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T19:00:22+00:00",
          "link": "https://arxiv.org/abs/2407.01639v2",
          "size": "3187kb",
          "version": "v2"
        }
      ],
      "title": "ModelVerification.jl: a Comprehensive Toolbox for Formally Verifying Deep Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01639",
        "HTML": "https://arxiv.org/html/2407.01639",
        "PDF": "https://arxiv.org/pdf/2407.01639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on verification of deep neural networks, providing tools for ensuring the trustworthiness of DNN models. It does not pertain to LLM training data processing or dataset creation."
      },
      "tasks": [
        "image-classification",
        "Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.10283",
      "abstract": "In the rapidly evolving field of vision-language navigation (VLN), ensuring safety for physical agents remains an open challenge. For a human-in-the-loop language-operated drone to navigate safely, it must understand natural language commands, perceive the environment, and simultaneously avoid hazards in real time. Control Barrier Functions (CBFs) are formal methods that enforce safe operating conditions. Model Predictive Control (MPC) is an optimization framework that plans a sequence of future actions over a prediction horizon, ensuring smooth trajectory tracking while obeying constraints. In this work, we consider a VLN-operated drone platform and enhance its safety by formulating a novel scene-aware CBF that leverages ego-centric observations from a camera which has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less baseline system uses a Vision-Language Encoder with cross-modal attention to convert commands into an ordered sequence of landmarks. An object detection model identifies and verifies these landmarks in the captured images to generate a planned path. To further enhance safety, an Adaptive Safety Margin Algorithm (ASMA) is proposed. ASMA tracks moving objects and performs scene-aware CBF evaluation on-the-fly, which serves as an additional constraint within the MPC framework. By continuously identifying potentially risky observations, the system performs prediction in real time about unsafe conditions and proactively adjusts its control actions to maintain safe navigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in the Gazebo environment using the Robot Operating System (ROS), ASMA achieves 64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in trajectory lengths compared to the baseline CBF-less VLN.",
      "authors": [
        "Sourav Sanyal and Kaushik Roy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Image and Video Processing (eess.IV)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T13:44:50+00:00",
          "link": "https://arxiv.org/abs/2409.10283v1",
          "size": "7721kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T21:51:26+00:00",
          "link": "https://arxiv.org/abs/2409.10283v2",
          "size": "19309kb",
          "version": "v2"
        },
        {
          "date": "2025-06-07T18:26:59+00:00",
          "link": "https://arxiv.org/abs/2409.10283v3",
          "size": "19355kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T18:48:48+00:00",
          "link": "https://arxiv.org/abs/2409.10283v4",
          "size": "9662kb",
          "version": "v4"
        }
      ],
      "title": "ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone Navigation via Scene-Aware Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10283",
        "HTML": "https://arxiv.org/html/2409.10283",
        "PDF": "https://arxiv.org/pdf/2409.10283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an adaptive safety margin algorithm for vision-language drone navigation, focusing on safety and control, without addressing LLM training data processing."
      },
      "tasks": [
        "Drone navigation",
        "Model Predictive Control",
        "Navigate",
        "Vision-Language Navigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean. We also provide a characterization for the case when $m=p=2$.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Theoretical Economics (econ.TH)",
        "Systems and Control (eess.SY)",
        "Combinatorics (math.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.05297v4",
          "size": "320kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T03:51:18+00:00",
          "link": "https://arxiv.org/abs/2507.05297v5",
          "size": "320kb",
          "version": "v5"
        }
      ],
      "title": "Continuous Classification Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses classification aggregation functions in fuzzy classification but does not contribute to or involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05470",
      "abstract": "We propose Temporal Conformal Prediction (TCP), a principled framework for constructing well-calibrated prediction intervals for non-stationary time series. TCP integrates a machine learning-based quantile forecaster with an online conformal calibration layer. This layer's thresholds are updated via a modified Robbins-Monro scheme, allowing the model to dynamically adapt to volatility clustering and regime shifts without rigid parametric assumptions. We benchmark TCP against GARCH, Historical Simulation, and static Quantile Regression across diverse financial assets. Our empirical results reveal a critical flaw in static methods: while sharp, Quantile Regression is poorly calibrated, systematically over-covering the nominal 95% target. In contrast, TCP's adaptive mechanism actively works to achieve the correct coverage level, successfully navigating the coverage-sharpness tradeoff. Visualizations during the 2020 market crash confirm TCP's superior adaptive response, and a comprehensive sensitivity analysis demonstrates the framework's robustness to hyperparameter choices. Overall, TCP offers a practical and theoretically-grounded solution to the central challenge of calibrated uncertainty quantification for time series under distribution shift, advancing the interface between statistical inference and machine learning.",
      "authors": [
        "Agnideep Aich",
        "Ashit Baran Aich",
        "Dipak C. Jain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:44:31+00:00",
          "link": "https://arxiv.org/abs/2507.05470v1",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T04:09:25+00:00",
          "link": "https://arxiv.org/abs/2507.05470v2",
          "size": "2991kb",
          "version": "v2"
        }
      ],
      "title": "Temporal Conformal Prediction (TCP): A Distribution-Free Statistical and Machine Learning Framework for Adaptive Risk Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05470",
        "HTML": "https://arxiv.org/html/2507.05470",
        "PDF": "https://arxiv.org/pdf/2507.05470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for constructing prediction intervals for time series analysis and does not address data processing for LLM training, focusing instead on statistical prediction methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14154",
      "abstract": "Artificial General Intelligence (AGI) research traditionally focuses on algorithms that optimize for specific goals under deterministic rules. Yet, human-like intelligence exhibits adaptive spontaneity - an ability to make unexpected choices or free decisions not strictly dictated by past data or immediate reward. This trait, often dubbed \"free will\" in a loose sense, might be crucial for creativity, robust adaptation, and avoiding ruts in problem-solving. This paper proposes a theoretical framework, called the Free Will Equation, that draws analogies from quantum field theory to endow AGI agents with a form of adaptive, controlled stochasticity in their decision-making process. The core idea is to treat an AI agent's cognitive state as a superposition of potential actions or thoughts, which collapses probabilistically into a concrete action when a decision is made - much like a quantum wavefunction collapsing upon measurement. By incorporating mechanisms analogous to quantum fields, along with intrinsic motivation terms, we aim to improve an agent's ability to explore novel strategies and adapt to unforeseen changes. Experiments in a non-stationary multi-armed bandit environment demonstrate that agents using this framework achieve higher rewards and policy diversity compared to baseline methods.",
      "authors": [
        "Rahul Kabali"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T10:25:52+00:00",
          "link": "https://arxiv.org/abs/2507.14154v1",
          "size": "691kb",
          "version": "v1"
        }
      ],
      "title": "The Free Will Equation: Quantum Field Analogies for AGI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14154",
        "HTML": "https://arxiv.org/html/2507.14154",
        "PDF": "https://arxiv.org/pdf/2507.14154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a theoretical framework for AGI inspired by quantum field analogies to enhance decision-making processes. It does not engage with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14186",
      "abstract": "The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer an opportunity for data-driven low-altitude coverage prediction. However, collecting extensive low-altitude road test data is cost-prohibitive, often yielding only sparse samples per BS. This scarcity results in two primary challenges: imbalanced feature sampling due to limited variability in high-dimensional operational parameters against the backdrop of substantial changes in low-dimensional sampling locations, and diminished generalizability stemming from insufficient data samples. To overcome these obstacles, we introduce a dual strategy comprising expert knowledge-based feature compression and disentangled representation learning. The former reduces feature space complexity by leveraging communications expertise, while the latter enhances model generalizability through the integration of propagation models and distinct subnetworks that capture and aggregate the semantic representations of latent features. Experimental evaluation confirms the efficacy of our framework, yielding a 7% reduction in error compared to the best baseline algorithm. Real-network validations further attest to its reliability, achieving practical prediction accuracy with MAE errors at the 5dB level.",
      "authors": [
        "Xiaojie Li",
        "Zhijie Cai",
        "Nan Qi",
        "Chao Dong",
        "Guangxu Zhu",
        "Haixia Ma",
        "Qihui Wu",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:31:35+00:00",
          "link": "https://arxiv.org/abs/2507.14186v1",
          "size": "3510kb",
          "version": "v1"
        }
      ],
      "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14186",
        "HTML": "https://arxiv.org/html/2507.14186",
        "PDF": "https://arxiv.org/pdf/2507.14186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with disentangled representation learning for predicting network coverage in low-altitude aerial contexts. It does not address LLM training data processing or the creation of datasets for language model purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14456",
      "abstract": "End-to-end autonomous driving requires adaptive and robust handling of complex and diverse traffic environments. However, prevalent single-mode planning methods attempt to learn an overall policy while struggling to acquire diversified driving skills to handle diverse scenarios. Therefore, this paper proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a Dual-aware Router. Specifically, the Global Expert is trained on the overall dataset, possessing robust performance. The Scene-Adaptive Experts are trained on corresponding scene subsets, achieving adaptive performance. The Dual-aware Router simultaneously considers scenario-level features and routing uncertainty to dynamically activate expert modules. Through the effective coupling of the Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router, GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS outperforms existing methods in the Bench2Drive closed-loop benchmark and achieves state-of-the-art performance in Driving Score and Success Rate, even with only monocular vision input. Furthermore, ablation studies demonstrate significant improvements over the original single-expert baseline: 7.67% in Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The code will be available at https://github.com/newbrains1/GEMINUS.",
      "authors": [
        "Chi Wan and Yixin Cui and Jiatong Du and Shuo Yang and Yulong Bai and Yanjun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:04:28+00:00",
          "link": "https://arxiv.org/abs/2507.14456v1",
          "size": "358kb",
          "version": "v1"
        }
      ],
      "title": "GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14456",
        "HTML": "https://arxiv.org/html/2507.14456",
        "PDF": "https://arxiv.org/pdf/2507.14456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a Mixture-of-Experts framework for autonomous driving and focuses on scene-adaptive planning methods, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14815",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has spurred significant progress in Large Speech-Language Models (LSLMs), enhancing their capabilities in both speech understanding and generation. While existing LSLMs often concentrate on augmenting speech generation or tackling a diverse array of short-speech tasks, the efficient processing of long-form speech remains a critical yet underexplored challenge. This gap is primarily attributed to the scarcity of long-speech training datasets and the high computational costs associated with long sequences. To address these limitations, we introduce FastLongSpeech, a novel framework designed to extend LSLM capabilities for efficient long-speech processing without necessitating dedicated long-speech training data. FastLongSpeech incorporates an iterative fusion strategy that can compress excessively long-speech sequences into manageable lengths. To adapt LSLMs for long-speech inputs, it introduces a dynamic compression training approach, which exposes the model to short-speech sequences at varying compression ratios, thereby transferring the capabilities of LSLMs to long-speech tasks. To assess the long-speech capabilities of LSLMs, we develop a long-speech understanding benchmark called LongSpeech-Eval. Experiments show that our method exhibits strong performance in both long-speech and short-speech tasks, while greatly improving inference efficiency.",
      "authors": [
        "Shoutao Guo",
        "Shaolei Zhang",
        "Qingkai Fang",
        "Zhengrui Ma",
        "Min Zhang",
        "Yang Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:11:06+00:00",
          "link": "https://arxiv.org/abs/2507.14815v1",
          "size": "912kb",
          "version": "v1"
        }
      ],
      "title": "FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14815",
        "HTML": "https://arxiv.org/html/2507.14815",
        "PDF": "https://arxiv.org/pdf/2507.14815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing Large Speech-Language Models (LSLMs) for processing long-form speech, which involves dynamic compression and fusion strategies. It does not address LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15081",
      "abstract": "Social isolation can lead to pervasive health issues like anxiety and loneliness. Previous work focused on physical interventions like exercise and teleconferencing, but overlooked the narrative potential of adaptive strategies. To address this, we designed a collaborative online storytelling experience in social VR, enabling participants in isolation to design an imaginary space journey as a metaphor for quarantine, in order to learn about their isolation adaptation strategies in the process. Eighteen individuals participated during real quarantine undertaken a virtual role-play experience, designing their own spaceship rooms and engaging in collaborative activities that revealed creative adaptative strategies. Qualitative analyses of participant designs, transcripts, and interactions revealed how they coped with isolation, and how the engagement unexpectedly influenced their adaptation process. This study shows how designing playful narrative experiences, rather than solution-driven approaches, can serve as probes to surface how people navigate social isolation.",
      "authors": [
        "Qi Gong",
        "Ximing Shen",
        "Ziyou Yin",
        "Yaning Li",
        "Ray Lc"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:31:22+00:00",
          "link": "https://arxiv.org/abs/2507.15081v1",
          "size": "8947kb",
          "version": "v1"
        }
      ],
      "title": "\"If I were in Space\": Understanding and Adapting to Social Isolation through Designing Collaborative Narratives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15081",
        "HTML": "https://arxiv.org/html/2507.15081",
        "PDF": "https://arxiv.org/pdf/2507.15081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is about designing collaborative narratives in social VR to cope with social isolation. It does not pertain to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15375",
      "abstract": "Spoken Language Models (SLMs) are designed to take speech inputs and produce spoken responses. However, current SLMs lack the ability to perform an internal, unspoken thinking process before responding. In contrast, humans typically engage in complex mental reasoning internally, enabling them to communicate ideas clearly and concisely. Thus, integrating an unspoken thought process into SLMs is highly desirable. While naively generating a complete chain-of-thought (CoT) reasoning before starting to talk can enable thinking for SLMs, this induces additional latency for the speech response, as the CoT reasoning can be arbitrarily long. To solve this issue, we propose Stitch, a novel generation method that alternates between the generation of unspoken reasoning chunks and spoken response chunks. Since the audio duration of a chunk of spoken response is much longer than the time to generate the tokens in a chunk of spoken response, we use the remaining free time to generate the unspoken reasoning tokens. When a chunk of audio is played to the user, the model continues to generate the next unspoken reasoning chunk, achieving simultaneous thinking and talking. Remarkably, Stitch matches the latency of baselines that cannot generate unspoken CoT by design while outperforming those baselines by 15% on math reasoning datasets; Stitch also performs equally well on non-reasoning datasets as those baseline models. Some animations and demonstrations are on the project page: https://d223302.github.io/STITCH.",
      "authors": [
        "Cheng-Han Chiang",
        "Xiaofei Wang",
        "Linjie Li",
        "Chung-Ching Lin",
        "Kevin Lin",
        "Shujie Liu",
        "Zhendong Wang",
        "Zhengyuan Yang",
        "Hung-yi Lee",
        "Lijuan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:30:03+00:00",
          "link": "https://arxiv.org/abs/2507.15375v1",
          "size": "294kb",
          "version": "v1"
        }
      ],
      "title": "STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15375",
        "HTML": "https://arxiv.org/html/2507.15375",
        "PDF": "https://arxiv.org/pdf/2507.15375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a method for integrating reasoning into spoken language models without latency, focused on spoken language generation rather than on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15455",
      "abstract": "We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.",
      "authors": [
        "Hee Jun Yang",
        "Min Jung Kim",
        "Yeoneung Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:06:53+00:00",
          "link": "https://arxiv.org/abs/2507.15455v1",
          "size": "1176kb",
          "version": "v1"
        }
      ],
      "title": "Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15455",
        "PDF": "https://arxiv.org/pdf/2507.15455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The content relates to solving nonconvex PDEs via PINN-based policy iteration, not pertaining to LLM training data processing procedures."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15460",
      "abstract": "Personalized News Recommendation systems (PNR) have emerged as a solution to information overload by predicting and suggesting news items tailored to individual user interests. However, traditional PNR systems face several challenges, including an overreliance on textual content, common neglect of short-term user interests, and significant privacy concerns due to centralized data storage. This paper addresses these issues by introducing a novel multimodal federated learning-based approach for news recommendation. First, it integrates both textual and visual features of news items using a multimodal model, enabling a more comprehensive representation of content. Second, it employs a time-aware model that balances users' long-term and short-term interests through multi-head self-attention networks, improving recommendation accuracy. Finally, to enhance privacy, a federated learning framework is implemented, enabling collaborative model training without sharing user data. The framework divides the recommendation model into a large server-maintained news model and a lightweight user model shared between the server and clients. The client requests news representations (vectors) and a user model from the central server, then computes gradients with user local data, and finally sends their locally computed gradients to the server for aggregation. The central server aggregates gradients to update the global user model and news model. The updated news model is further used to infer news representation by the server. To further safeguard user privacy, a secure aggregation algorithm based on Shamir's secret sharing is employed. Experiments on a real-world news dataset demonstrate strong performance compared to existing systems, representing a significant advancement in privacy-preserving personalized news recommendation.",
      "authors": [
        "Mehdi Khalaj",
        "Shahrzad Golestani Najafabadi",
        "Julita Vassileva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:14:00+00:00",
          "link": "https://arxiv.org/abs/2507.15460v1",
          "size": "1411kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Multimodal News Recommendation through Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15460",
        "HTML": "https://arxiv.org/html/2507.15460",
        "PDF": "https://arxiv.org/pdf/2507.15460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a personalized news recommendation system using multimodal federated learning to address privacy concerns, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15665",
      "abstract": "Koutschan, Krattenthaler and Schlosser recently considered a family of binomial determinants. In this work, we give combinatorial interpretations of two subclasses of these determinants in terms of domino tilings and nonintersecting lattice paths, thereby partially answering a question of theirs. Furthermore, the determinant evaluations established by Koutschan, Krattenthaler and Schlosser produce many product formulas for our weighted enumerations of domino tilings and nonintersecting lattice paths. However, there are still two enumerations left corresponding to conjectural formulas made by the three. We hereby prove the two conjectures using the principle of holonomic Ansatz plus the approach of modular reduction for creative telescoping, and hence fill the gap.",
      "authors": [
        "Qipin Chen",
        "Shane Chern",
        "Atsuro Yoshida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Symbolic Computation (cs.SC)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:26:10+00:00",
          "link": "https://arxiv.org/abs/2507.15665v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "Domino tilings, nonintersecting lattice paths and subclasses of Koutschan-Krattenthaler-Schlosser determinants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15665",
        "HTML": "https://arxiv.org/html/2507.15665",
        "PDF": "https://arxiv.org/pdf/2507.15665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with combinatorial interpretations of binomial determinants and does not relate to LLM training data processing or datasets for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "1906.04327",
      "abstract": "Low Rank Approximation (LRA) of a matrix is a hot research subject, fundamental for Matrix and Tensor Computations and Big Data Mining and Analysis. Computations with low rank matrices can be performed at sublinear cost -- by using much fewer floating-point operations (flops) than an input matrix has entries, but can we compute LRA at sublinear cost? This is routinely done in computational practice for a large class of inputs, even though any sublinear cost LRA algorithm fails most miserably on worst case matrices. To provide insight into this controversy we first accelerate some popular near-optimal random sketching LRA algorithms -- to run them at sublinear cost. Then we define two probabilistic structures in the space of input matrices and estimate that the expected spectral and Frobenius error norms for the output LRA of the accelerated algorithms stay within a reasonable factor from their optima under both models, and so these sublinear cost algorithms only fail for a very narrow input class. Our upper estimates for their output accuracy are still quite high, but under some additional semi-heuristic amendments the algorithms have consistently output accurate LRA of various synthetic and real-world matrices in our numerical tests.",
      "authors": [
        "Qi Luan",
        "Victor Y. Pan",
        "John Svadlenka and Liang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2019-06-11T00:16:48+00:00",
          "link": "https://arxiv.org/abs/1906.04327v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2019-07-06T11:18:55+00:00",
          "link": "https://arxiv.org/abs/1906.04327v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2019-07-20T17:35:19+00:00",
          "link": "https://arxiv.org/abs/1906.04327v3",
          "size": "28kb",
          "version": "v3"
        },
        {
          "date": "2019-12-30T15:49:37+00:00",
          "link": "https://arxiv.org/abs/1906.04327v4",
          "size": "29kb",
          "version": "v4"
        },
        {
          "date": "2020-06-23T19:31:40+00:00",
          "link": "https://arxiv.org/abs/1906.04327v5",
          "size": "27kb",
          "version": "v5"
        },
        {
          "date": "2021-03-31T21:08:28+00:00",
          "link": "https://arxiv.org/abs/1906.04327v6",
          "size": "31kb",
          "version": "v6"
        },
        {
          "date": "2021-04-22T16:24:33+00:00",
          "link": "https://arxiv.org/abs/1906.04327v7",
          "size": "48kb",
          "version": "v7"
        },
        {
          "date": "2025-07-20T23:22:43+00:00",
          "link": "https://arxiv.org/abs/1906.04327v8",
          "size": "35kb",
          "version": "v8"
        }
      ],
      "title": "Low Rank Approximation at Sublinear Cost",
      "links": {
        "Abstract": "https://arxiv.org/abs/1906.04327",
        "HTML": "https://arxiv.org/html/1906.04327",
        "PDF": "https://arxiv.org/pdf/1906.04327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around low rank approximation techniques for matrices and their computational cost. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.21314",
      "abstract": "Data assimilation has become a key technique for combining physical models with observational data to estimate state variables. However, classical assimilation algorithms often struggle with the high nonlinearity present in both physical and observational models. To address this challenge, a novel generative model, termed the State-Observation Augmented Diffusion (SOAD) model is proposed for data-driven assimilation. The marginal posterior associated with SOAD has been derived and then proved to match the true posterior distribution under mild assumptions, suggesting its theoretical advantages over previous score-based approaches. Experimental results also indicate that SOAD may offer improved performance compared to existing data-driven methods.",
      "authors": [
        "Zhuoyuan Li",
        "Bin Dong",
        "Pingwen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-31T03:47:20+00:00",
          "link": "https://arxiv.org/abs/2407.21314v1",
          "size": "40762kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T14:14:03+00:00",
          "link": "https://arxiv.org/abs/2407.21314v2",
          "size": "22249kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T15:04:25+00:00",
          "link": "https://arxiv.org/abs/2407.21314v3",
          "size": "23744kb",
          "version": "v3"
        }
      ],
      "title": "State-observation augmented diffusion model for nonlinear assimilation with unknown dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.21314",
        "HTML": "https://arxiv.org/html/2407.21314",
        "PDF": "https://arxiv.org/pdf/2407.21314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel generative model for data assimilation in physical systems, not on LLM training data processing."
      },
      "tasks": [
        "model"
      ],
      "repo_urls": [
        "https://github.com/zylipku/SOAD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05445",
      "abstract": "The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.",
      "authors": [
        "Chalamalasetti Kranti",
        "Sherzod Hakimov",
        "David Schlangen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T17:36:36+00:00",
          "link": "https://arxiv.org/abs/2505.05445v1",
          "size": "720kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:42:09+00:00",
          "link": "https://arxiv.org/abs/2505.05445v2",
          "size": "563kb",
          "version": "v2"
        }
      ],
      "title": "clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05445",
        "HTML": "https://arxiv.org/html/2505.05445",
        "PDF": "https://arxiv.org/pdf/2505.05445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper relates to benchmarking of task-oriented dialogue systems using LLMs. It uses datasets for evaluation but doesn't emphasize the creation or processing of these datasets, focusing instead on system evaluation and architecture impacts."
      },
      "tasks": [
        "Benchmarking",
        "Task-Oriented Dialogue Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10351",
      "abstract": "Physiological signals are often corrupted by motion artifacts, baseline drift, and other low-SNR disturbances, which pose significant challenges for analysis. Additionally, these signals exhibit strong non-stationarity, with sharp peaks and abrupt changes that evolve continuously, making them difficult to represent using traditional time-domain or filtering methods. To address these issues, a novel wavelet-based approach for physiological signal analysis is presented, aiming to capture multi-scale time-frequency features in various physiological signals. Leveraging this technique, two large-scale pretrained models specific to EMG and ECG are introduced for the first time, achieving superior performance and setting new baselines in downstream tasks. Additionally, a unified multi-modal framework is constructed by integrating pretrained EEG model, where each modality is guided through its dedicated branch and fused via learnable weighted fusion. This design effectively addresses challenges such as low signal-to-noise ratio, high inter-subject variability, and device mismatch, outperforming existing methods on multi-modal tasks. The proposed wavelet-based architecture lays a solid foundation for analysis of diverse physiological signals, while the multi-modal design points to next-generation physiological signal processing with potential impact on wearable health monitoring, clinical diagnostics, and broader biomedical applications.",
      "authors": [
        "Yanlong Chen",
        "Mattia Orlandi",
        "Pierangelo Maria Rapa",
        "Simone Benatti",
        "Luca Benini",
        "and Yawei Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T05:11:41+00:00",
          "link": "https://arxiv.org/abs/2506.10351v1",
          "size": "1170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T19:42:26+00:00",
          "link": "https://arxiv.org/abs/2506.10351v2",
          "size": "15102kb",
          "version": "v2"
        }
      ],
      "title": "PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10351",
        "HTML": "https://arxiv.org/html/2506.10351",
        "PDF": "https://arxiv.org/pdf/2506.10351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a wavelet-based approach for physiological signal analysis, introducing pretrained models for EMG and ECG signals. It does not provide any contributions or methodologies relevant to LLM training data processing."
      },
      "tasks": [
        "EEG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14141",
      "abstract": "Electroencephalography (EEG) is a non-invasive technique widely used in brain-computer interfaces and clinical applications, yet existing EEG foundation models face limitations in modeling spatio-temporal brain dynamics and lack channel permutation equivariance, preventing robust generalization across diverse electrode configurations. To address these challenges, we propose DIVER-0, a novel EEG foundation model that demonstrates how full spatio-temporal attention-rather than segregated spatial or temporal processing-achieves superior performance when properly designed with Rotary Position Embedding (RoPE) for temporal relationships and binary attention biases for channel differentiation. We also introduce Sliding Temporal Conditional Positional Encoding (STCPE), which improves upon existing conditional positional encoding approaches by maintaining both temporal translation equivariance and channel permutation equivariance, enabling robust adaptation to arbitrary electrode configurations unseen during pretraining. Experimental results demonstrate that DIVER-0 achieves competitive performance with only 10% of pretraining data while maintaining consistent results across all channel permutation conditions, validating its effectiveness for cross-dataset generalization and establishing key design principles for handling the inherent heterogeneity of neural recording setups.",
      "authors": [
        "Danny Dongyeop Han",
        "Ahhyun Lucy Lee",
        "Taeyang Lee",
        "Yonghyeon Gwon",
        "Sebin Lee",
        "Seongjin Lee",
        "David Keetae Park",
        "Shinjae Yoo",
        "Jiook Cha",
        "Chun Kee Chung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T04:17:15+00:00",
          "link": "https://arxiv.org/abs/2507.14141v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "DIVER-0 : A Fully Channel Equivariant EEG Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14141",
        "HTML": "https://arxiv.org/html/2507.14141",
        "PDF": "https://arxiv.org/pdf/2507.14141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel EEG foundation model for modeling spatio-temporal brain dynamics and channel permutation equivariance, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14238",
      "abstract": "Large language models (LLMs) are increasingly being used in user-facing applications, from providing medical consultations to job interview advice. Recent research suggests that these models are becoming increasingly proficient at inferring identity information about the author of a piece of text from linguistic patterns as subtle as the choice of a few words. However, little is known about how LLMs use this information in their decision-making in real-world applications. We perform the first comprehensive analysis of how identity markers present in a user's writing bias LLM responses across five different high-stakes LLM applications in the domains of medicine, law, politics, government benefits, and job salaries. We find that LLMs are extremely sensitive to markers of identity in user queries and that race, gender, and age consistently influence LLM responses in these applications. For instance, when providing medical advice, we find that models apply different standards of care to individuals of different ethnicities for the same symptoms; we find that LLMs are more likely to alter answers to align with a conservative (liberal) political worldview when asked factual questions by older (younger) individuals; and that LLMs recommend lower salaries for non-White job applicants and higher salaries for women compared to men. Taken together, these biases mean that the use of off-the-shelf LLMs for these applications may cause harmful differences in medical care, foster wage gaps, and create different political factual realities for people of different identities. Beyond providing an analysis, we also provide new tools for evaluating how subtle encoding of identity in users' language choices impacts model decisions. Given the serious implications of these findings, we recommend that similar thorough assessments of LLM use in user-facing applications are conducted before future deployment.",
      "authors": [
        "Matthew Kearney",
        "Reuben Binns and Yarin Gal"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:21:17+00:00",
          "link": "https://arxiv.org/abs/2507.14238v1",
          "size": "6003kb",
          "version": "v1"
        }
      ],
      "title": "Language Models Change Facts Based on the Way You Talk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14238",
        "HTML": "https://arxiv.org/html/2507.14238",
        "PDF": "https://arxiv.org/pdf/2507.14238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates biases in LLM responses due to identity markers in user queries across various applications but does not address training data processing aspects relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14697",
      "abstract": "Agricultural parcels serve as basic units for conducting agricultural practices and applications, which is vital for land ownership registration, food security assessment, soil erosion monitoring, etc. However, existing agriculture parcel extraction studies only focus on mid-resolution mapping or regular plain farmlands while lacking representation of complex terraced terrains due to the demands of precision agriculture.In this paper, we introduce a more fine-grained terraced parcel dataset named GTPBD (Global Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset covering major worldwide terraced regions with more than 200,000 complex terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution images with three-level labels, including pixel-level boundary labels, mask labels, and parcel labels. It covers seven major geographic zones in China and transcontinental climatic regions around the world.Compared to the existing datasets, the GTPBD dataset brings considerable challenges due to the: (1) terrain diversity; (2) complex and irregular parcel objects; and (3) multiple domain styles. Our proposed GTPBD dataset is suitable for four different tasks, including semantic segmentation, edge detection, terraced parcel extraction, and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the GTPBD dataset on eight semantic segmentation methods, four edge extraction methods, three parcel extraction methods, and five UDA methods, along with a multi-dimensional evaluation framework integrating pixel-level and object-level metrics. GTPBD fills a critical gap in terraced remote sensing research, providing a basic infrastructure for fine-grained agricultural terrain analysis and cross-scenario knowledge transfer.",
      "authors": [
        "Zhiwei Zhang",
        "Zi Ye",
        "Yibin Wen",
        "Shuai Yuan",
        "Haohuan Fu",
        "Jianxi Huang",
        "Juepeng Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:15:46+00:00",
          "link": "https://arxiv.org/abs/2507.14697v1",
          "size": "37571kb",
          "version": "v1"
        }
      ],
      "title": "GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14697",
        "HTML": "https://arxiv.org/html/2507.14697",
        "PDF": "https://arxiv.org/pdf/2507.14697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the GTPBD dataset for terraced parcel detection in agriculture and does not relate to LLM training data processing, focusing instead on geographic and agricultural data analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14957",
      "abstract": "We study the fair division of indivisible items and provide new insights into the EFX problem, which is widely regarded as the central open question in fair division, and the PMMS problem, a strictly stronger variant of EFX. Our first result constructs a three-agent instance with two monotone valuations and one additive valuation in which no PMMS allocation exists. Since EFX allocations are known to exist under these assumptions, this establishes a formal separation between EFX and PMMS.\n  We prove existence of fair allocations for three important special cases. We show that EFX allocations exist for personalized bivalued valuations, where for each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value $v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also prove that PMMS allocations exist for binary-valued MMS-feasible valuations, where each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result holds even without assuming monotonicity of valuations and thus applies to the fair division of chores and mixed manna. Finally, we study a class of valuations called pair-demand valuations, which extend the well-studied unit-demand valuations to the case where each agent derives value from at most two items, and we show that PMMS allocations exist in this setting. Our proofs are constructive, and we provide polynomial-time algorithms for all three existence results.",
      "authors": [
        "Jaros{\\l}aw Byrka",
        "Franciszek Malinka",
        "Tomasz Ponitka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:32:12+00:00",
          "link": "https://arxiv.org/abs/2507.14957v1",
          "size": "563kb",
          "version": "v1"
        }
      ],
      "title": "Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14957",
        "HTML": "https://arxiv.org/html/2507.14957",
        "PDF": "https://arxiv.org/pdf/2507.14957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fair division in discrete mathematics, specifically the EFX problem, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15233",
      "abstract": "Recommendation systems (RS) personalize content by analyzing user preferences, but typically require centralized collection of user data, raising privacy and scalability concerns. Federated Recommendation Systems (FRS) address these issues by enabling distributed, privacy-preserving model training across edge devices, keeping raw data on-device. Although existing FRS frameworks benefit from on-device feature extraction and privacy preservation, they suffer from heterogeneous device capabilities, non-independent and identically distributed (non-IID) data, and communication bottlenecks. To overcome these limitations, we propose a multi-objective reinforcement learning (RL) participant selection that jointly optimizes historical client performance reputation (CPR), data utility, and system efficiency. First, we define a composite client-utility function combining CPR, system capability, and data quality. Next, we embed this utility into a multi-armed bandit (MAB) framework and dynamically balance exploration-exploitation to select participants. Finally, we practically implement our approach using the PySyft framework on an edge-cloud testbed, and evaluate it on a multimodal movie-recommendation task built from the MovieLens-100K dataset. Across four different skewed data-partition scenarios, our MAB-based selection accelerates convergence by 32-50% in time-to-target AUC and reduces total wall-clock training time by up to 46%, while matching or slightly improving final AUC, NDCG@50, and Recall@50 compared to existing FRS baselines. Our results demonstrate that adaptive, reward-driven client sampling can substantially enhance both efficiency and fairness in real-world federated deployments.",
      "authors": [
        "Jintao Liu",
        "Mohammad Goudarzi",
        "and Adel Nadjaran Toosi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.15233v1",
          "size": "1310kb",
          "version": "v1"
        }
      ],
      "title": "An ML-Driven Participant Selection Technique for Federated Recommendation System in Edge-Cloud Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15233",
        "HTML": "https://arxiv.org/html/2507.15233",
        "PDF": "https://arxiv.org/pdf/2507.15233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated recommendation systems and a participant selection technique to enhance training efficiency in edge-cloud computing. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15469",
      "abstract": "The increasing demand for autonomous systems in complex and dynamic environments has driven significant research into intelligent path planning methodologies. For decades, graph-based search algorithms, linear programming techniques, and evolutionary computation methods have served as foundational approaches in this domain. Recently, deep reinforcement learning (DRL) has emerged as a powerful method for enabling autonomous agents to learn optimal navigation strategies through interaction with their environments. This survey provides a comprehensive overview of traditional approaches as well as the recent advancements in DRL applied to path planning tasks, focusing on autonomous vehicles, drones, and robotic platforms. Key algorithms across both conventional and learning-based paradigms are categorized, with their innovations and practical implementations highlighted. This is followed by a thorough discussion of their respective strengths and limitations in terms of computational efficiency, scalability, adaptability, and robustness. The survey concludes by identifying key open challenges and outlining promising avenues for future research. Special attention is given to hybrid approaches that integrate DRL with classical planning techniques to leverage the benefits of both learning-based adaptability and deterministic reliability, offering promising directions for robust and resilient autonomous navigation.",
      "authors": [
        "Thanh Thi Nguyen",
        "Saeid Nahavandi",
        "Imran Razzak",
        "Dung Nguyen",
        "Nhat Truong Pham",
        "Quoc Viet Hung Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:21:42+00:00",
          "link": "https://arxiv.org/abs/2507.15469v1",
          "size": "992kb",
          "version": "v1"
        }
      ],
      "title": "The Emergence of Deep Reinforcement Learning for Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15469",
        "HTML": "https://arxiv.org/html/2507.15469",
        "PDF": "https://arxiv.org/pdf/2507.15469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey addresses advancements in deep reinforcement learning for path planning, especially for autonomous systems, and does not involve LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15559",
      "abstract": "Multi-agent workflows have become an effective strategy for tackling complicated tasks by decomposing them into multiple sub-tasks and assigning them to specialized agents. However, designing optimal workflows remains challenging due to the vast and intricate design space. Current practices rely heavily on the intuition and expertise of practitioners, often resulting in design fixation or an unstructured, time-consuming exploration of trial-and-error. To address these challenges, this work introduces FLOWFORGE, an interactive visualization tool to facilitate the creation of multi-agent workflow through i) a structured visual exploration of the design space and ii) in-situ guidance informed by established design patterns. Based on formative studies and literature review, FLOWFORGE organizes the workflow design process into three hierarchical levels (i.e., task planning, agent assignment, and agent optimization), ranging from abstract to concrete. This structured visual exploration enables users to seamlessly move from high-level planning to detailed design decisions and implementations, while comparing alternative solutions across multiple performance metrics. Additionally, drawing from established workflow design patterns, FLOWFORGE provides context-aware, in-situ suggestions at each level as users navigate the design space, enhancing the workflow creation process with practical guidance. Use cases and user studies demonstrate the usability and effectiveness of FLOWFORGE, while also yielding valuable insights into how practitioners explore design spaces and leverage guidance during workflow development.",
      "authors": [
        "Pan Hao",
        "Dongyeop Kang",
        "Nicholas Hinds",
        "Qianwen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:39:08+00:00",
          "link": "https://arxiv.org/abs/2507.15559v1",
          "size": "5405kb",
          "version": "v1"
        }
      ],
      "title": "FlowForge: Guiding the Creation of Multi-agent Workflows with Design Space Visualization as a Thinking Scaffold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15559",
        "HTML": "https://arxiv.org/html/2507.15559",
        "PDF": "https://arxiv.org/pdf/2507.15559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an interactive tool for creating multi-agent workflows, which involves design space visualization and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15787",
      "abstract": "Although many problems in science and engineering are modelled by well-established PDEs, they often involve unknown or incomplete relationships, such as material constitutive laws or thermal response, that limit accuracy and generality. Existing surrogate-modelling approaches directly approximate PDE solutions but remain tied to a specific geometry, boundary conditions, and set of physical constraints. To address these limitations, we introduce a fully differentiable finite element-based machine learning (FEBML) framework that embeds trainable operators for unknown physics within a state-of-the-art, general FEM solver, enabling true end-to-end differentiation. At its core, FEBML represents each unknown operator as an encode-process-decode pipeline over finite-element degrees of freedom: field values are projected to nodal coefficients, transformed by a neural network, and then lifted back to a continuous FE function, ensuring the learned physics respects the variational structure. We demonstrate its versatility by recovering nonlinear stress-strain laws from laboratory tests, applying the learned model to a new mechanical scenario without retraining, and identifying temperature-dependent conductivity in transient heat flow.",
      "authors": [
        "Ado Farsi",
        "Nacime Bouziani",
        "David A Ham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:42:34+00:00",
          "link": "https://arxiv.org/abs/2507.15787v1",
          "size": "4379kb",
          "version": "v1"
        }
      ],
      "title": "Missing Physics Discovery through Fully Differentiable Finite Element-Based Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15787",
        "HTML": "https://arxiv.org/html/2507.15787",
        "PDF": "https://arxiv.org/pdf/2507.15787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a machine learning framework for discovering unknown physics in finite element models, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07007",
      "abstract": "The outer inverse of tensors plays increasingly significant roles in computational mathematics, numerical analysis, and other generalized inverses of tensors. In this paper, we compute outer inverses with prescribed ranges and kernels of a given tensor through tensor QR decomposition and hyperpower iterative method under the M-product structure, which is a family of tensor-tensor products, generalization of the t-product and c-product, allows us to suit the physical interpretations across those different modes. We discuss a theoretical analysis of the nineteen-order convergence of the proposed tensor-based iterative method. Further, we design effective tensor-based algorithms for computing outer inverses using M-QR decomposition and hyperpower iterative method. The theoretical results are validated with numerical examples demonstrating the appropriateness of the proposed methods.",
      "authors": [
        "Ratikanta Behera",
        "Krushnachandra Panigrahy",
        "Jajati Keshari Sahoo",
        "Yimin Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T04:41:15+00:00",
          "link": "https://arxiv.org/abs/2409.07007v1",
          "size": "310kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:10:03+00:00",
          "link": "https://arxiv.org/abs/2409.07007v2",
          "size": "11293kb",
          "version": "v2"
        }
      ],
      "title": "$M$-QR decomposition and hyperpower iterative methods for computing outer inverses of tensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07007",
        "HTML": "https://arxiv.org/html/2409.07007",
        "PDF": "https://arxiv.org/pdf/2409.07007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about computing outer inverses of tensors using tensor QR decomposition and hyperpower iterative methods, with no connection to data processing for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.05677",
      "abstract": "Estimates of heterogeneous treatment assignment effects can inform treatment decisions. Under the presence of non-adherence (e.g., patients do not adhere to their assigned treatment), both the standard backdoor adjustment (SBD) and the conditional front-door adjustment (CFD) can recover unbiased estimates of the treatment assignment effects. However, the estimation variance of these approaches may vary widely across settings, which remains underexplored in the literature. In this work, we demonstrate theoretically and empirically that CFD yields lower-variance estimates than SBD when the true effect of treatment assignment is small (i.e., assigning an intervention leads to small changes in patients' future outcome). Additionally, since CFD requires estimating multiple nuisance parameters, we introduce LobsterNet, a multi-task neural network that implements CFD with joint modeling of the nuisance parameters. Empirically, LobsterNet reduces estimation error across several semi-synthetic and real-world datasets compared to baselines. Our findings suggest CFD with shared nuisance parameter modeling can improve treatment assignment effect estimation under non-adherence.",
      "authors": [
        "Winston Chen",
        "Trenton Chang",
        "Jenna Wiens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T22:27:38+00:00",
          "link": "https://arxiv.org/abs/2505.05677v1",
          "size": "1138kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T15:19:03+00:00",
          "link": "https://arxiv.org/abs/2505.05677v2",
          "size": "5378kb",
          "version": "v2"
        },
        {
          "date": "2025-06-20T14:29:02+00:00",
          "link": "https://arxiv.org/abs/2505.05677v3",
          "size": "1142kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T00:13:07+00:00",
          "link": "https://arxiv.org/abs/2505.05677v4",
          "size": "1147kb",
          "version": "v4"
        }
      ],
      "title": "Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05677",
        "PDF": "https://arxiv.org/pdf/2505.05677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on treatment effect estimation in healthcare using front-door adjustments, which is outside the scope of LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mld3/lobsternet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14162",
      "abstract": "Amid accelerated digitalization, not only is the scale of data processing and storage increasing, but so too is the associated infrastructure load on the climate. Current climate models and environmental protocols almost entirely overlook the impact of information and communication technologies on the thermal and energy balance of the biosphere.\n  This paper proposes the theory of information and climate feedback (ICF) as a new nonlinear model describing the loop of digitalization, energy consumption, the thermal footprint, the climatic response, and the vulnerability of digital infrastructure. The system is formalized via differential equations with delays and parameters of sensitivity, greenness, and phase stability.\n  A multiscenario numerical analysis, phase reconstructions, and thermal cartography were conducted. Critical regimes, including digital overheating, fluctuational instability, and infrastructural collapse in the absence of adaptive measures, were identified.\n  The paper concludes with the proposal of an international agreement titled the Green Digital Accord and a set of metrics for sustainable digitalization. This work integrates climatology, information technologies, and the political economy of sustainability.",
      "authors": [
        "Eldar Knar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:27:15+00:00",
          "link": "https://arxiv.org/abs/2507.14162v1",
          "size": "921kb",
          "version": "v1"
        }
      ],
      "title": "Apology of Green Digitalization in the Context of Information and Climate Feedback Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14162",
        "PDF": "https://arxiv.org/pdf/2507.14162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the impact of digitalization on climate feedback without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14187",
      "abstract": "The impedance network (IN) model is gaining popularity in the oscillation analysis of wind farms. However, the construction of such an IN model requires impedance curves of each wind turbine under their respective operating conditions, making its online application difficult due to the transmission of numerous high-density impedance curves. To address this issue, this paper proposes an AI-based impedance encoding-decoding method to facilitate the online construction of IN model. First, an impedance encoder is trained to compress impedance curves by setting the number of neurons much smaller than that of frequency points. Then, the compressed data of each turbine are uploaded to the wind farm and an impedance decoder is trained to reconstruct original impedance curves. At last, based on the nodal admittance matrix (NAM) method, the IN model of the wind farm can be obtained. The proposed method is validated via model training and real-time simulations, demonstrating that the encoded impedance vectors enable fast transmission and accurate reconstruction of the original impedance curves.",
      "authors": [
        "Xiaojuan Zhang and Tianyu Jiang and Haoxiang Zong and Chen Zhang and Chendan Li and Marta Molinas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T05:49:43+00:00",
          "link": "https://arxiv.org/abs/2507.14187v1",
          "size": "1882kb",
          "version": "v1"
        }
      ],
      "title": "AI-Based Impedance Encoding-Decoding Method for Online Impedance Network Construction of Wind Farms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14187",
        "PDF": "https://arxiv.org/pdf/2507.14187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an AI-based encoding-decoding method for impedance networks in wind farms, which is unrelated to LLM training data processing or dataset generation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15349",
      "abstract": "Fine-tuning the large language models (LLMs) are prevented by the deficiency of centralized control and the massive computing and communication overhead on the decentralized schemes. While the typical standard federated learning (FL) supports data privacy, the central server requirement creates a single point of attack and vulnerability to poisoning attacks. Generalizing the result in this direction to 70B-parameter models in the heterogeneous, trustless environments has turned out to be a huge, yet unbroken bottleneck. This paper introduces FLock, a decentralized framework for secure and efficient collaborative LLM fine-tuning. Integrating a blockchain-based trust layer with economic incentives, FLock replaces the central aggregator with a secure, auditable protocol for cooperation among untrusted parties. We present the first empirical validation of fine-tuning a 70B LLM in a secure, multi-domain, decentralized setting. Our experiments show the FLock framework defends against backdoor poisoning attacks that compromise standard FL optimizers and fosters synergistic knowledge transfer. The resulting models show a >68% reduction in adversarial attack success rates. The global model also demonstrates superior cross-domain generalization, outperforming models trained in isolation on their own specialized data.",
      "authors": [
        "Zehua Cheng",
        "Rui Sun",
        "Jiahao Sun",
        "Yike Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:01:43+00:00",
          "link": "https://arxiv.org/abs/2507.15349v1",
          "size": "1281kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Decentralized Learning with FLock",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15349",
        "HTML": "https://arxiv.org/html/2507.15349",
        "PDF": "https://arxiv.org/pdf/2507.15349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on FLock, a decentralized framework for fine-tuning, which may involve data but primarily emphasizes secure collaboration and model optimization rather than data processing operations such as dataset creation or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.10081",
      "abstract": "In data-driven optimization, the sample performance of the obtained decision typically incurs an optimistic bias against the true performance, a phenomenon commonly known as the Optimizer's Curse and intimately related to overfitting in machine learning. Common techniques to correct this bias, such as cross-validation, require repeatedly solving additional optimization problems and are therefore computationally expensive. We develop a general bias correction approach, building on what we call Optimizer's Information Criterion (OIC), that directly approximates the first-order bias and does not require solving any additional optimization problems. Our OIC generalizes the celebrated Akaike Information Criterion to evaluate the objective performance in data-driven optimization, which crucially involves not only model fitting but also its interplay with the downstream optimization. As such it can be used for decision selection instead of only model selection. We apply our approach to a range of data-driven optimization formulations comprising empirical and parametric models, their regularized counterparts, and furthermore contextual optimization. Finally, we provide numerical validation on the superior performance of our approach under synthetic and real-world datasets.",
      "authors": [
        "Garud Iyengar",
        "Henry Lam",
        "Tianyu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-16T07:07:58+00:00",
          "link": "https://arxiv.org/abs/2306.10081v1",
          "size": "293kb",
          "version": "v1"
        },
        {
          "date": "2023-10-17T02:09:55+00:00",
          "link": "https://arxiv.org/abs/2306.10081v2",
          "size": "630kb",
          "version": "v2"
        },
        {
          "date": "2024-07-24T02:08:25+00:00",
          "link": "https://arxiv.org/abs/2306.10081v3",
          "size": "2470kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T16:50:57+00:00",
          "link": "https://arxiv.org/abs/2306.10081v4",
          "size": "646kb",
          "version": "v4"
        }
      ],
      "title": "Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.10081",
        "PDF": "https://arxiv.org/pdf/2306.10081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a bias correction method for data-driven optimization problems, focusing on performance evaluation and decision selection, but it does not touch on LLM training data processing."
      },
      "tasks": [
        "Model Selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07594",
      "abstract": "Subsonic missiles play an important role in modern air-to-air combat scenarios - utilized by the F-35 Lightning II - but require complex Guidance, Navigation and Control systems to manoeuvre with 30G's of acceleration to intercept successfully. Challenges with mathematically modelling and controlling such a dynamic system must be addressed, high frequency noise rejected, and actuator delay compensated for. This paper aims to investigate the control systems necessary for interception. It also proposes a subsonic design utilizing literature and prior research, suggests aerodynamic derivatives, and analyses a designed 2D reduced pitch autopilot control system response against performances. The pitch autopilot model contains an optimized PID controller, 2nd order actuator, lead compensator and Kalman Filter, that rejects time varying disturbances and high frequency noise expected during flight. Simulation results confirm the effectiveness of the proposed method through reduction in rise time (21%), settle time (10%), and highlighted its high frequency deficiency with respect to the compensator integration. The actuator delay of 100ms has been negated by the augmented compensator autopilot controller so that it exceeds system performance requirements (1) & (3). However, (2) is not satisfied as 370% overshoot exists. This research confirms the importance of a lead compensator in missile GNC systems and furthers control design application through a specific configuration. Future research should build upon methods and models presented to construct and test an interception scenario.",
      "authors": [
        "Rory Jenkins",
        "Xinhua Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T07:08:24+00:00",
          "link": "https://arxiv.org/abs/2411.07594v1",
          "size": "1470kb",
          "version": "v1"
        },
        {
          "date": "2024-12-14T22:23:24+00:00",
          "link": "https://arxiv.org/abs/2411.07594v2",
          "size": "1966kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T09:44:26+00:00",
          "link": "https://arxiv.org/abs/2411.07594v3",
          "size": "1471kb",
          "version": "v3"
        }
      ],
      "title": "Modelling and Control of Subsonic Missile for Air-to-Air Interception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07594",
        "PDF": "https://arxiv.org/pdf/2411.07594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses control systems for subsonic missiles and does not relate to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08006",
      "abstract": "The growing resolution and volume of climate data from remote sensing and simulations pose significant storage, processing, and computational challenges. Traditional compression or subsampling methods often compromise data fidelity, limiting scientific insights. We introduce a scalable ecosystem that integrates hierarchical multiresolution data management, intelligent transmission, and ML-assisted reconstruction to balance accuracy and efficiency. Our approach reduces storage and computational costs by 99\\%, lowering expenses from \\$100,000 to \\$24 while maintaining a Root Mean Square (RMS) error of 1.46 degrees Celsius. Our experimental results confirm that even with significant data reduction, essential features required for accurate climate analysis are preserved. Validated on petascale NASA climate datasets, this solution enables cost-effective, high-fidelity climate analysis for research and decision-making.",
      "authors": [
        "Aashish Panta",
        "Amy Gooch",
        "Giorgio Scorzelli",
        "Michela Taufer",
        "Valerio Pascucci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T17:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.08006v1",
          "size": "4014kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Climate Data Analysis: Balancing Petascale Fidelity and Computational Cost",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08006",
        "HTML": "https://arxiv.org/html/2507.08006",
        "PDF": "https://arxiv.org/pdf/2507.08006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on climate data analysis, emphasizing storage, processing, and computational efficiency for climate datasets. It does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08729",
      "abstract": "The multi-camera vehicle tracking (MCVT) framework holds significant potential for smart city applications, including anomaly detection, traffic density estimation, and suspect vehicle tracking. However, current publicly available datasets exhibit limitations, such as overly simplistic scenarios, low-resolution footage, and insufficiently diverse conditions, creating a considerable gap between academic research and real-world scenario. To fill this gap, we introduce RoundaboutHD, a comprehensive, high-resolution multi-camera vehicle tracking benchmark dataset specifically designed to represent real-world roundabout scenarios. RoundaboutHD provides a total of 40 minutes of labelled video footage captured by four non-overlapping, high-resolution (4K resolution, 15 fps) cameras. In total, 512 unique vehicle identities are annotated across different camera views, offering rich cross-camera association data. RoundaboutHD offers temporal consistency video footage and enhanced challenges, including increased occlusions and nonlinear movement inside the roundabout. In addition to the full MCVT dataset, several subsets are also available for object detection, single camera tracking, and image-based vehicle re-identification (ReID) tasks. Vehicle model information and camera modelling/ geometry information are also included to support further analysis. We provide baseline results for vehicle detection, single-camera tracking, image-based vehicle re-identification, and multi-camera tracking. The dataset and the evaluation code are publicly available at: https://github.com/siri-rouser/RoundaboutHD.git",
      "authors": [
        "Yuqiang Lin",
        "Sam Lockyer",
        "Mingxuan Sui",
        "Li Gan",
        "Florian Stanek",
        "Markus Zarbock",
        "Wenbin Li",
        "Adrian Evans",
        "Nic Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:30:27+00:00",
          "link": "https://arxiv.org/abs/2507.08729v1",
          "size": "1297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:26:42+00:00",
          "link": "https://arxiv.org/abs/2507.08729v2",
          "size": "1344kb",
          "version": "v2"
        }
      ],
      "title": "RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08729",
        "HTML": "https://arxiv.org/html/2507.08729",
        "PDF": "https://arxiv.org/pdf/2507.08729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the RoundaboutHD dataset for multi-camera vehicle tracking, which is linked to computer vision and not related to LLM training data processing. It is focused on vehicle tracking applications, not LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15261",
      "abstract": "Capturing target objects using the quadrotor has gained increasing popularity in recent years, but most studies focus on capturing lightweight objects. The instantaneous contact force generated when capturing objects of a certain mass, along with the payload uncertainty after attachment, will pose significant challenges to the quadrotor control. This paper proposes a novel control architecture, namely Dual-Channel Adaptive Nonlinear Model Predictive Control (DCA-NMPC), which cascades a nonlinear model predictive control with two lower-level model reference adaptive controllers and can resist drastic impact and adapt to uncertain inertial parameters. Numerical simulation experiments are performed for validation.",
      "authors": [
        "Xinqi Chen",
        "Xiuxian Li",
        "Min Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:54:56+00:00",
          "link": "https://arxiv.org/abs/2507.15261v1",
          "size": "304kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Channel Adaptive NMPC for Quadrotor under Instantaneous Impact and Payload Disturbances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15261",
        "HTML": "https://arxiv.org/html/2507.15261",
        "PDF": "https://arxiv.org/pdf/2507.15261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses control challenges for quadrotors during object capture, focusing on nonlinear model predictive control and adaptive control, but does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15675",
      "abstract": "Current large language model (LLM) applications often employ multi-component prompts, comprising both system and user prompts, to guide model behaviors. While recent advancements have demonstrated the efficacy of automatically optimizing either the system or user prompt to boost performance, such unilateral approaches often yield suboptimal outcomes due to the interdependent nature of these components. In this work, we introduce P3, a novel self-improvement framework that concurrently optimizes both system and user prompts through an iterative process. The offline optimized prompts are further leveraged to promote online prompting by performing query-dependent prompt optimization. Extensive experiments on general tasks (e.g., Arena-hard and Alpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3 achieves superior performance in the realm of automatic prompt optimization. Our results highlight the effectiveness of a holistic optimization strategy in enhancing LLM performance across diverse domains.",
      "authors": [
        "Xinyu Zhang",
        "Yuanquan Hu",
        "Fangchao Liu",
        "Zhicheng Dou"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:37:46+00:00",
          "link": "https://arxiv.org/abs/2507.15675v1",
          "size": "2671kb",
          "version": "v1"
        }
      ],
      "title": "P3: Prompts Promote Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15675",
        "PDF": "https://arxiv.org/pdf/2507.15675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on optimizing prompts for LLMs, not on training data processing directly, although it involves iterative optimization strategies which indirectly relate to how data might be structured for effective use."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15803",
      "abstract": "Pixel-level vision tasks, such as semantic segmentation, require extensive and high-quality annotated data, which is costly to obtain. Semi-supervised semantic segmentation (SSSS) has emerged as a solution to alleviate the labeling burden by leveraging both labeled and unlabeled data through self-training techniques. Meanwhile, the advent of foundational segmentation models pre-trained on massive data, has shown the potential to generalize across domains effectively. This work explores whether a foundational segmentation model can address label scarcity in the pixel-level vision task as an annotator for unlabeled images. Specifically, we investigate the efficacy of using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual input, to generate predictive masks for unlabeled data. To address the shortcomings of using SEEM-generated masks as supervision, we propose ConformalSAM, a novel SSSS framework which first calibrates the foundation model using the target domain's labeled data and then filters out unreliable pixel labels of unlabeled data so that only high-confidence labels are used as supervision. By leveraging conformal prediction (CP) to adapt foundation models to target data through uncertainty calibration, ConformalSAM exploits the strong capability of the foundational segmentation model reliably which benefits the early-stage learning, while a subsequent self-reliance training strategy mitigates overfitting to SEEM-generated masks in the later training stage. Our experiment demonstrates that, on three standard benchmarks of SSSS, ConformalSAM achieves superior performance compared to recent SSSS methods and helps boost the performance of those methods as a plug-in.",
      "authors": [
        "Danhui Chen",
        "Ziquan Liu",
        "Chuxi Yang",
        "Dan Wang",
        "Yan Yan",
        "Yi Xu",
        "Xiangyang Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.15803v1",
          "size": "993kb",
          "version": "v1"
        }
      ],
      "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15803",
        "HTML": "https://arxiv.org/html/2507.15803",
        "PDF": "https://arxiv.org/pdf/2507.15803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper explores semi-supervised semantic segmentation with foundation models, which involves data labeling techniques, its primary focus is not on LLM training data processing but rather on vision tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11136",
      "abstract": "A popular method for sampling from high-dimensional distributions is the \\emph{Gibbs sampler}, which iteratively resamples sites from the conditional distribution of the desired measure given the values of the other coordinates. It is natural to ask to what extent does the order of site updates matter in the mixing time? Two natural choices are (i) standard, or \\emph{random scan}, Glauber dynamics where the updated variable is chosen uniformly at random, and (ii) the \\emph{systematic scan} dynamics where variables are updated in a fixed, cyclic order. We first show that for systems of dimension $n$, one round of the systematic scan dynamics has spectral gap at most a factor of order $n$ worse than the corresponding spectral gap of a single step of Glauber dynamics, tightening existing bounds in the literature by He, et al. [NeurIPS '16] and Chlebicka, {\\L}atuszy\\'nski, and Miasodejow [Ann. Appl. Probab. '25]. The corresponding bound on mixing times is sharp even for simple spin systems by an explicit example of Roberts and Rosenthal [Int. J. Statist. Prob. '15]. We complement this with a converse statement: if all, or even just one scan order rapidly mixes, the Glauber dynamics has a polynomially related mixing time, resolving a question of Chlebicka, {\\L}atuszy\\'nski, and Miasodejow.",
      "authors": [
        "Jason Gaitonde and Elchanan Mossel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T23:17:47+00:00",
          "link": "https://arxiv.org/abs/2410.11136v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T01:54:46+00:00",
          "link": "https://arxiv.org/abs/2410.11136v2",
          "size": "29kb",
          "version": "v2"
        }
      ],
      "title": "Comparison Theorems for the Mixing Times of Systematic and Random Scan Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11136",
        "HTML": "https://arxiv.org/html/2410.11136",
        "PDF": "https://arxiv.org/pdf/2410.11136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses theoretical aspects of Gibbs samplers and systematic scan dynamics for sampling from high-dimensional distributions, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03021",
      "abstract": "Video Virtual Try-on aims to seamlessly transfer a reference garment onto a target person in a video while preserving both visual fidelity and temporal coherence. Existing methods typically rely on inpainting masks to define the try-on area, enabling accurate garment transfer for simple scenes (e.g., in-shop videos). However, these mask-based approaches struggle with complex real-world scenarios, as overly large and inconsistent masks often destroy spatial-temporal information, leading to distorted results. Mask-free methods alleviate this issue but face challenges in accurately determining the try-on area, especially for videos with dynamic body movements. To address these limitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video Virtual Try-On framework that leverages sparse point alignments to explicitly guide garment transfer. Our key innovation is the introduction of point-enhanced guidance, which provides flexible and reliable control over both spatial-level garment transfer and temporal-level video coherence. Specifically, we design a Point-Enhanced Transformer (PET) with two core components: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth point alignments to precisely guide garment transfer, and Point-Enhanced Temporal Attention (PTA), which leverages frame-frame point correspondences to enhance temporal coherence and ensure smooth transitions across frames. Extensive experiments demonstrate that our PEMF-VTO outperforms state-of-the-art methods, generating more natural, coherent, and visually appealing try-on videos, particularly for challenging in-the-wild scenarios. The link to our paper's homepage is https://pemf-vto.github.io/.",
      "authors": [
        "Tianyu Chang",
        "Xiaohao Chen",
        "Zhichao Wei",
        "Xuanpu Zhang",
        "Qing-Guo Chen",
        "Weihua Luo",
        "Peipei Song and Xun Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T04:24:15+00:00",
          "link": "https://arxiv.org/abs/2412.03021v1",
          "size": "37342kb",
          "version": "v1"
        },
        {
          "date": "2024-12-05T02:57:24+00:00",
          "link": "https://arxiv.org/abs/2412.03021v2",
          "size": "37342kb",
          "version": "v2"
        },
        {
          "date": "2025-03-13T14:22:12+00:00",
          "link": "https://arxiv.org/abs/2412.03021v3",
          "size": "29045kb",
          "version": "v3"
        },
        {
          "date": "2025-03-14T10:07:40+00:00",
          "link": "https://arxiv.org/abs/2412.03021v4",
          "size": "29045kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T07:46:16+00:00",
          "link": "https://arxiv.org/abs/2412.03021v5",
          "size": "11173kb",
          "version": "v5"
        }
      ],
      "title": "PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03021",
        "HTML": "https://arxiv.org/html/2412.03021",
        "PDF": "https://arxiv.org/pdf/2412.03021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for video virtual try-on, focusing on garment transfer using a point-enhanced mask-free approach. It does not involve any aspects of LLM training data processing or related data operations."
      },
      "tasks": [
        "Virtual Try-on"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06178",
      "abstract": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a classic NP-hard combinatorial optimization problem widely applied in logistics distribution and transportation management. Its complexity stems from the constraints of vehicle capacity and time windows, which pose significant challenges to traditional approaches. Advances in Large Language Models (LLMs) provide new possibilities for finding approximate solutions to CVRPTW. This paper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW with real-time emergency constraints. Our solution introduces an adaptive two-phase training mechanism that transitions from the LLM-guided exploration phase to the autonomous optimization phase of Q-network. To ensure reliability, we design a three-tier self-correction mechanism based on the Chain-of-Thought (CoT) for LLMs: syntactic validation, semantic verification, and physical constraint enforcement. In addition, we also prioritized replay of the experience generated by LLMs to amplify the regulatory role of LLMs in the architecture. Experimental results demonstrate that our framework achieves a 7.3\\% average reduction in cost compared to traditional Q-learning, with fewer training steps required for convergence.",
      "authors": [
        "Linjiang Cao",
        "Maonan Wang and Xi Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T16:45:43+00:00",
          "link": "https://arxiv.org/abs/2505.06178v1",
          "size": "1171kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:53:14+00:00",
          "link": "https://arxiv.org/abs/2505.06178v2",
          "size": "584kb",
          "version": "v2"
        }
      ],
      "title": "A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06178",
        "PDF": "https://arxiv.org/pdf/2505.06178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel LLM-enhanced framework for solving a combinatorial optimization problem (CVRPTW) and does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Q-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14467",
      "abstract": "In this paper we propose a novel neural network model for learning stochastic Hamiltonian systems (SHSs) from observational data, termed the stochastic generating function neural network (SGFNN). SGFNN preserves symplectic structure of the underlying stochastic Hamiltonian system and produces symplectic predictions. Our model utilizes the autoencoder framework to identify the randomness of the latent system by the encoder network, and detects the stochastic generating function of the system through the decoder network based on the random variables extracted from the encoder. Symplectic predictions can then be generated by the stochastic generating function. Numerical experiments are performed on several stochastic Hamiltonian systems, varying from additive to multiplicative, and from separable to non-separable SHSs with single or multiple noises. Compared with the benchmark stochastic flow map learning (sFML) neural network, our SGFNN model exhibits higher accuracy across various prediction metrics, especially in long-term predictions, with the property of maintaining the symplectic structure of the underlying SHSs.",
      "authors": [
        "Chen Chen",
        "Lijin Wang",
        "Yanzhao Cao",
        "Xupeng Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:59:04+00:00",
          "link": "https://arxiv.org/abs/2507.14467v1",
          "size": "1077kb",
          "version": "v1"
        }
      ],
      "title": "Learning Stochastic Hamiltonian Systems via Stochastic Generating Function Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14467",
        "HTML": "https://arxiv.org/html/2507.14467",
        "PDF": "https://arxiv.org/pdf/2507.14467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a neural network model for learning stochastic Hamiltonian systems, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14501",
      "abstract": "3D reconstruction and view synthesis are foundational problems in computer vision, graphics, and immersive technologies such as augmented reality (AR), virtual reality (VR), and digital twins. Traditional methods rely on computationally intensive iterative optimization in a complex chain, limiting their applicability in real-world scenarios. Recent advances in feed-forward approaches, driven by deep learning, have revolutionized this field by enabling fast and generalizable 3D reconstruction and view synthesis. This survey offers a comprehensive review of feed-forward techniques for 3D reconstruction and view synthesis, with a taxonomy according to the underlying representation architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural Radiance Fields (NeRF), etc. We examine key tasks such as pose-free reconstruction, dynamic 3D reconstruction, and 3D-aware image and video synthesis, highlighting their applications in digital humans, SLAM, robotics, and beyond. In addition, we review commonly used datasets with detailed statistics, along with evaluation protocols for various downstream tasks. We conclude by discussing open research challenges and promising directions for future work, emphasizing the potential of feed-forward approaches to advance the state of the art in 3D vision.",
      "authors": [
        "Jiahui Zhang and Yuelei Li and Anpei Chen and Muyu Xu and Kunhao Liu and Jianyuan Wang and Xiao-Xiao Long and Hanxue Liang and Zexiang Xu and Hao Su and Christian Theobalt and Christian Rupprecht and Andrea Vedaldi and Hanspeter Pfister and Shijian Lu and Fangneng Zhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:13:25+00:00",
          "link": "https://arxiv.org/abs/2507.14501v1",
          "size": "5518kb",
          "version": "v1"
        }
      ],
      "title": "Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14501",
        "HTML": "https://arxiv.org/html/2507.14501",
        "PDF": "https://arxiv.org/pdf/2507.14501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys feed-forward techniques for 3D reconstruction and view synthesis, focusing on computer vision and immersive technologies, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14956",
      "abstract": "We introduce the family of multi-modal logics of bounded density and with a tableau-like approach using finite \\emph{windows} which were introduced in \\cite{BalGasq25}, we prove that their satisfiability problem is PSPACE-complete. As a side effect, the monomodal logic of density is shown to be in para-PSPACE.",
      "authors": [
        "Olivier Gasquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:27:25+00:00",
          "link": "https://arxiv.org/abs/2507.14956v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "PSPACE-completeness of Grammar logics of bounded density",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14956",
        "HTML": "https://arxiv.org/html/2507.14956",
        "PDF": "https://arxiv.org/pdf/2507.14956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multi-modal logics of bounded density and proves satisfiability problems are PSPACE-complete. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15155",
      "abstract": "This letter introduces a novel learning-based modeling framework for a magnetically steerable soft suction device designed for endoscopic endonasal brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material, and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape feedback. Shape reconstruction is represented using four Bezier control points, enabling a compact and smooth model of the device's deformation. A data-driven model was trained on 5,097 experimental samples covering a range of magnetic field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical tip distances (90-100 mm), using both Neural Network (NN) and Random Forest (RF) architectures. The RF model outperformed the NN across all metrics, achieving a mean root mean square error of 0.087 mm in control point prediction and a mean shape reconstruction error of 0.064 mm. Feature importance analysis further revealed that magnetic field components predominantly influence distal control points, while frequency and distance affect the base configuration. This learning-based approach effectively models the complex nonlinear behavior of hyperelastic soft robots under magnetic actuation without relying on simplified physical assumptions. By enabling sub-millimeter shape prediction accuracy and real-time inference, this work represents an advancement toward the intelligent control of magnetically actuated soft robotic tools in minimally invasive neurosurgery.",
      "authors": [
        "Majid Roshanfar",
        "Alex Zhang",
        "Changyan He",
        "Amir Hooshiar",
        "Dale J. Podolsky",
        "Thomas Looi",
        "and Eric Diller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.15155v1",
          "size": "2790kb",
          "version": "v1"
        }
      ],
      "title": "Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15155",
        "HTML": "https://arxiv.org/html/2507.15155",
        "PDF": "https://arxiv.org/pdf/2507.15155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a learning-based modeling framework for a magnetically steerable soft suction device. It does not involve LLM or training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15272",
      "abstract": "We present a speaker conditioned text-to-speech (TTS) system aimed at addressing challenges in generating speech for unseen speakers and supporting diverse Indian languages. Our method leverages a diffusion-based TTS architecture, where a speaker encoder extracts embeddings from short reference audio samples to condition the DDPM decoder for multispeaker generation. To further enhance prosody and naturalness, we employ a cross-attention based duration prediction mechanism that utilizes reference audio, enabling more accurate and speaker consistent timing. This results in speech that closely resembles the target speaker while improving duration modeling and overall expressiveness. Additionally, to improve zero-shot generation, we employed classifier free guidance, allowing the system to generate speech more near speech for unknown speakers. Using this approach, we trained language-specific speaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian languages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and Tamil.",
      "authors": [
        "Ayush Singh Bhadoriya",
        "Abhishek Nikunj Shinde",
        "Isha Pandey",
        "Ganesh Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:20:27+00:00",
          "link": "https://arxiv.org/abs/2507.15272v1",
          "size": "720kb",
          "version": "v1"
        }
      ],
      "title": "A2TTS: TTS for Low Resource Indian Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15272",
        "HTML": "https://arxiv.org/html/2507.15272",
        "PDF": "https://arxiv.org/pdf/2507.15272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a TTS system for low-resource Indian languages, focusing on speaker embedding and prosody, without any direct involvement in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2102.02837",
      "abstract": "We propose perturbed proximal algorithms that can provably escape strict saddles for nonsmooth weakly convex functions. The main results are based on a novel characterization of $\\epsilon$-approximate local minimum for nonsmooth functions, and recent developments on perturbed gradient methods for escaping saddle points for smooth problems. Specifically, we show that under standard assumptions, the perturbed proximal point, perturbed proximal gradient and perturbed proximal linear algorithms find $\\epsilon$-approximate local minimum for nonsmooth weakly convex functions in $O(\\epsilon^{-2}\\log(d)^4)$ iterations, where $d$ is the dimension of the problem.",
      "authors": [
        "Minhui Huang",
        "Weiming Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2021-02-04T19:17:13+00:00",
          "link": "https://arxiv.org/abs/2102.02837v1",
          "size": "291kb",
          "version": "v1"
        },
        {
          "date": "2021-04-08T05:33:23+00:00",
          "link": "https://arxiv.org/abs/2102.02837v2",
          "size": "291kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T01:35:56+00:00",
          "link": "https://arxiv.org/abs/2102.02837v3",
          "size": "291kb",
          "version": "v3"
        }
      ],
      "title": "Escaping Saddle Points for Nonsmooth Weakly Convex Functions via Perturbed Proximal Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2102.02837",
        "HTML": "https://arxiv.org/html/2102.02837",
        "PDF": "https://arxiv.org/pdf/2102.02837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes algorithms to escape saddle points in optimization of nonsmooth weakly convex functions. It is concerned with optimization techniques rather than LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2401.00512",
      "abstract": "Semi-simplicial and semi-cubical sets are commonly defined as presheaves over respectively, the semi-simplex or semi-cube category. Homotopy Type Theory then popularized an alternative definition, where the set of n-simplices or n-cubes are instead regrouped into the families of the fibers over their faces, leading to a characterization we call indexed. Moreover, it is known that semi-simplicial and semi-cubical sets are related to iterated Reynolds parametricity, respectively in its unary and binary variants. We exploit this correspondence to develop an original uniform indexed definition of both augmented semi-simplicial and semi-cubical sets, and fully formalize it in Coq.",
      "authors": [
        "Hugo Herbelin",
        "Ramkumar Ramachandra"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-31T14:39:00+00:00",
          "link": "https://arxiv.org/abs/2401.00512v1",
          "size": "28kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:24:31+00:00",
          "link": "https://arxiv.org/abs/2401.00512v2",
          "size": "29kb",
          "version": "v2"
        }
      ],
      "title": "A parametricity-based formalization of semi-simplicial and semi-cubical sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.00512",
        "PDF": "https://arxiv.org/pdf/2401.00512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on the formalization of semi-simplicial and semi-cubical sets using Homotopy Type Theory, not related to LLM training data processing tasks like data collection or quality improvement."
      },
      "repo_urls": [
        "https://github.com/artagnon/bonak"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.06513",
      "abstract": "Robot navigation in dynamic, crowded environments poses a significant challenge due to the inherent uncertainties in the obstacle model. In this work, we propose a risk-adaptive approach based on the Conditional Value-at-Risk Barrier Function (CVaR-BF), where the risk level is automatically adjusted to accept the minimum necessary risk, achieving a good performance in terms of safety and optimization feasibility under uncertainty. Additionally, we introduce a dynamic zone-based barrier function which characterizes the collision likelihood by evaluating the relative state between the robot and the obstacle. By integrating risk adaptation with this new function, our approach adaptively expands the safety margin, enabling the robot to proactively avoid obstacles in highly dynamic environments. Comparisons and ablation studies demonstrate that our method outperforms existing social navigation approaches, and validate the effectiveness of our proposed framework.",
      "authors": [
        "Xinyi Wang",
        "Taekyung Kim",
        "Bardh Hoxha",
        "Georgios Fainekos and Dimitra Panagou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T01:23:44+00:00",
          "link": "https://arxiv.org/abs/2504.06513v1",
          "size": "1166kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T15:20:52+00:00",
          "link": "https://arxiv.org/abs/2504.06513v2",
          "size": "633kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T12:45:35+00:00",
          "link": "https://arxiv.org/abs/2504.06513v3",
          "size": "636kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T02:35:10+00:00",
          "link": "https://arxiv.org/abs/2504.06513v4",
          "size": "635kb",
          "version": "v4"
        }
      ],
      "title": "Safe Navigation in Uncertain Crowded Environments Using Risk Adaptive CVaR Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06513",
        "HTML": "https://arxiv.org/html/2504.06513",
        "PDF": "https://arxiv.org/pdf/2504.06513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for safe robot navigation in crowded environments, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09463",
      "abstract": "Flying multiple quadrotors in close proximity presents a significant challenge due to complex aerodynamic interactions, particularly downwash effects that are known to destabilize vehicles and degrade performance. Traditionally, multi-quadrotor systems rely on conservative strategies, such as collision avoidance zones around the robot volume, to circumvent this effect. This restricts their capabilities by requiring a large volume for the operation of a multi-quadrotor system, limiting their applicability in dense environments. This work provides a comprehensive, data-driven analysis of the downwash effect, with a focus on characterizing, analyzing, and understanding forces, moments, and velocities in both single and multi-quadrotor configurations. We use measurements of forces and torques to characterize vehicle interactions, and particle image velocimetry (PIV) to quantify the spatial features of the downwash wake for a single quadrotor and an interacting pair of quadrotors. This data can be used to inform physics-based strategies for coordination, leverage downwash for optimized formations, expand the envelope of operation, and improve the robustness of multi-quadrotor control.",
      "authors": [
        "Anoop Kiran",
        "Nora Ayanian",
        "Kenneth Breuer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:00:15+00:00",
          "link": "https://arxiv.org/abs/2507.09463v1",
          "size": "9185kb",
          "version": "v1"
        }
      ],
      "title": "Influence of Static and Dynamic Downwash Interactions on Multi-Quadrotor Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09463",
        "PDF": "https://arxiv.org/pdf/2507.09463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates aerodynamic interactions in multi-quadrotor systems, a topic that does not intersect with training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14167",
      "abstract": "Jamming devices disrupt signals from the global navigation satellite system (GNSS) and pose a significant threat by compromising the reliability of accurate positioning. Consequently, the detection and localization of these interference signals are essential to achieve situational awareness, mitigating their impact, and implementing effective counter-measures. Classical Angle of Arrival (AoA) methods exhibit reduced accuracy in multipath environments due to signal reflections and scattering, leading to localization errors. Additionally, AoA-based techniques demand substantial computational resources for array signal processing. In this paper, we propose a novel approach for detecting and classifying interference while estimating the distance, azimuth, and elevation of jamming sources. Our benchmark study evaluates 128 vision encoder and time-series models to identify the highest-performing methods for each task. We introduce an attention-based fusion framework that integrates in-phase and quadrature (IQ) samples with Fast Fourier Transform (FFT)-computed spectrograms while incorporating 22 AoA features to enhance localization accuracy. Furthermore, we present a novel dataset of moving jamming devices recorded in an indoor environment with dynamic multipath conditions and demonstrate superior performance compared to state-of-the-art methods.",
      "authors": [
        "Lucas Heublein and Christian Wielenberg and Thorsten Nowak and Tobias Feigl and Christopher Mutschler and Felix Ott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:49:11+00:00",
          "link": "https://arxiv.org/abs/2507.14167v1",
          "size": "3612kb",
          "version": "v1"
        }
      ],
      "title": "Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14167",
        "HTML": "https://arxiv.org/html/2507.14167",
        "PDF": "https://arxiv.org/pdf/2507.14167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for GNSS jammer localization using attention-based fusion techniques and discusses dataset creation related to GNSS signals. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14465",
      "abstract": "This study examines how TikTok refugees moved to Xiaohongshu after TikTok was about to be banned in the United States. It utilizes Foucault's idea of heterotopia to demonstrate how Xiaohongshu became a crisis space for cross-cultural discussions across the Great Firewall. Through Critical Discourse Analysis of 586 user comments, the study reveals how Chinese and international users collaboratively constructed and contested a new online order through language negotiation, identity positioning, and playful platform policing. The findings highlight distinct discursive strategies between domestic and overseas users, reflecting both cultural resistance and adaptation. This research contributes to the understanding of digital migration, heterotopic spaces in social media, and emerging dynamics of cross-cultural discourse during geopolitical crises.",
      "authors": [
        "Xiaoyu Xiong",
        "Yuting Peng",
        "Summer Kwong and Anqi Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:47:55+00:00",
          "link": "https://arxiv.org/abs/2507.14465v1",
          "size": "613kb",
          "version": "v1"
        }
      ],
      "title": "Discipline and Resistance: The Construction of a Digital Home for TikTok Refugees on Xiaohongshu",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14465",
        "PDF": "https://arxiv.org/pdf/2507.14465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines digital migration and cross-cultural discourse on social media platforms, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15037",
      "abstract": "Image-based Virtual Try-On (VTON) techniques rely on either supervised in-shop approaches, which ensure high fidelity but struggle with cross-domain generalization, or unsupervised in-the-wild methods, which improve adaptability but remain constrained by data biases and limited universality. A unified, training-free solution that works across both scenarios remains an open challenge. We propose OmniVTON, the first training-free universal VTON framework that decouples garment and pose conditioning to achieve both texture fidelity and pose consistency across diverse settings. To preserve garment details, we introduce a garment prior generation mechanism that aligns clothing with the body, followed by continuous boundary stitching technique to achieve fine-grained texture retention. For precise pose alignment, we utilize DDIM inversion to capture structural cues while suppressing texture interference, ensuring accurate body alignment independent of the original image textures. By disentangling garment and pose constraints, OmniVTON eliminates the bias inherent in diffusion models when handling multiple conditions simultaneously. Experimental results demonstrate that OmniVTON achieves superior performance across diverse datasets, garment types, and application scenarios. Notably, it is the first framework capable of multi-human VTON, enabling realistic garment transfer across multiple individuals in a single scene. Code is available at https://github.com/Jerome-Young/OmniVTON",
      "authors": [
        "Zhaotong Yang",
        "Yuhui Li",
        "Shengfeng He",
        "Xinzhe Li",
        "Yangyang Xu",
        "Junyu Dong",
        "Yong Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:37:53+00:00",
          "link": "https://arxiv.org/abs/2507.15037v1",
          "size": "5554kb",
          "version": "v1"
        }
      ],
      "title": "OmniVTON: Training-Free Universal Virtual Try-On",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15037",
        "HTML": "https://arxiv.org/html/2507.15037",
        "PDF": "https://arxiv.org/pdf/2507.15037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "OmniVTON is a training-free framework for virtual try-on, focusing on image processing rather than any aspect of LLM training data processing or dataset management for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15156",
      "abstract": "We investigate multi-label classification involving large sets of labels, where the output labels may be known to satisfy some logical constraints. We look at an architecture in which classifiers for individual labels are fed into an expressive sequential model, which produces a joint distribution. One of the potential advantages for such an expressive model is its ability to modelling correlations, as can arise from constraints. We empirically demonstrate the ability of the architecture both to exploit constraints in training and to enforce constraints at inference time.",
      "authors": [
        "Mykhailo Buleshnyi",
        "Anna Polova",
        "Zsolt Zombori",
        "Michael Benedikt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:31:36+00:00",
          "link": "https://arxiv.org/abs/2507.15156v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15156",
        "HTML": "https://arxiv.org/html/2507.15156",
        "PDF": "https://arxiv.org/pdf/2507.15156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-label classification and the use of a sequential model for exploiting logical constraints, without discussing training data processing specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15196",
      "abstract": "Let $\\phi(x,y)$ be a non-degenerate rational quadratic form. Let $X$ and $Y$ be independent $(s, C)$-Frostman random variables whose ranges are contained in $[-c_1, c_1]$, with $0<s<1$, $C,c_1\\geq 1$. We prove that there exist a positive constant $\\epsilon = \\epsilon(s,\\phi)$ and an integer $N=N(s,C,c_1,\\phi)$ such that\n  $$\\max\\left\\{H_n(X+Y),\\,H_n(\\phi(X,Y))\\right\\} \\ge n(s+\\epsilon)$$\n  for all $n>N$. The proof introduces a novel multi-step entropy framework, combining the submodularity formula, the discretized entropy Balog-Szemer\\'{e}di-Gowers theorem, and state-of-the-art results on the Falconer distance problem, to reduce general forms to a diagonal core case. As an application, we derive a result on a discretized sum-product type problem. In particular, for a $\\delta$-separated set $A\\subset [0, 1]$ of cardinality $\\delta^{-s}$, satisfying some non-concentration conditions, there exists $\\epsilon=\\epsilon(s, \\phi)>0$ such that $$E_\\delta(A+A) + E_\\delta(\\phi(A, A)) \\gg\\delta^{-\\epsilon}(\\#A) $$ for all $\\delta$ small enough. Here by $E_\\delta(A)$ we mean the $\\delta$-covering number of $A$.",
      "authors": [
        "Alex Iosevich",
        "Thang Pham",
        "Nguyen Dac Quan",
        "Steven Senger",
        "Boqing Xue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Classical Analysis and ODEs (math.CA)",
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:51:00+00:00",
          "link": "https://arxiv.org/abs/2507.15196v1",
          "size": "724kb",
          "version": "v1"
        }
      ],
      "title": "On an entropy inequality for quadratic forms and applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15196",
        "HTML": "https://arxiv.org/html/2507.15196",
        "PDF": "https://arxiv.org/pdf/2507.15196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an entropy inequality for quadratic forms and its applications, which is not related to LLM training data processing or any associated data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15325",
      "abstract": "In many game-theoretic settings, agents are challenged with taking decisions against the uncertain behavior exhibited by others. Often, this uncertainty arises from multiple sources, e.g., incomplete information, limited computation, bounded rationality. While it may be possible to guide the agents' decisions by modeling each source, their joint presence makes this task particularly daunting. Toward this goal, it is natural for agents to seek protection against deviations around the emergent behavior itself, which is ultimately impacted by all the above sources of uncertainty. To do so, we propose that each agent takes decisions in face of the worst-case behavior contained in an ambiguity set of tunable size, centered at the emergent behavior so implicitly defined. This gives rise to a novel equilibrium notion, which we call strategically robust equilibrium. Building on its definition, we show that, when judiciously operationalized via optimal transport, strategically robust equilibria (i) are guaranteed to exist under the same assumptions required for Nash equilibria; (ii) interpolate between Nash and security strategies; (iii) come at no additional computational cost compared to Nash equilibria. Through a variety of experiments, including bi-matrix games, congestion games, and Cournot competition, we show that strategic robustness protects against uncertainty in the opponents' behavior and, surprisingly, often results in higher equilibrium payoffs - an effect we refer to as coordination via robustification.",
      "authors": [
        "Nicolas Lanzetti",
        "Sylvain Fricker",
        "Saverio Bolognani",
        "Florian D\\\"orfler",
        "Dario Paccagnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:32:36+00:00",
          "link": "https://arxiv.org/abs/2507.15325v1",
          "size": "236kb",
          "version": "v1"
        }
      ],
      "title": "Strategically Robust Game Theory via Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15325",
        "PDF": "https://arxiv.org/pdf/2507.15325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with game theory and optimal transport to address uncertainty in strategic decisions, with no mention of LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15335",
      "abstract": "Industrial defect detection systems face critical limitations when confined to one-class anomaly detection paradigms, which assume uniform outlier distributions and struggle with data scarcity in realworld manufacturing environments. We present ExDD (Explicit Dual Distribution), a novel framework that transcends these limitations by explicitly modeling dual feature distributions. Our approach leverages parallel memory banks that capture the distinct statistical properties of both normality and anomalous patterns, addressing the fundamental flaw of uniform outlier assumptions. To overcome data scarcity, we employ latent diffusion models with domain-specific textual conditioning, generating in-distribution synthetic defects that preserve industrial context. Our neighborhood-aware ratio scoring mechanism elegantly fuses complementary distance metrics, amplifying signals in regions exhibiting both deviation from normality and similarity to known defect patterns. Experimental validation on KSDD2 demonstrates superior performance (94.2% I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.",
      "authors": [
        "Muhammad Aqeel",
        "Federico Leonardi",
        "Francesco Setti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:49:00+00:00",
          "link": "https://arxiv.org/abs/2507.15335v1",
          "size": "1187kb",
          "version": "v1"
        }
      ],
      "title": "ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15335",
        "HTML": "https://arxiv.org/html/2507.15335",
        "PDF": "https://arxiv.org/pdf/2507.15335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for surface defect detection in industrial contexts using diffusion synthesis, with no relevance to processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15570",
      "abstract": "The iterative nature of topology optimization, especially in combination with nonlinear state problems, often requires the solution of thousands of linear equation systems. Furthermore, due to the pixelated design representation, the use of a fine mesh is essential to obtain geometrically well-defined structures and to accurately compute response quantities such as the von Mises stress. Therefore, the computational cost of solving a fine-mesh topology optimization problem quickly adds up. To address this challenge, we consider a multi-level adaptive refinement and coarsening strategy based on configurational forces. Configurational forces based on the Eshelby stress predict configurational changes such as crack propagation or dislocation motion. Due to a relaxation in the calculation of (Eshelby) stresses with respect to the design variables, discrete configurational forces increase not only in highly stressed regions, but also in grey transition regions (design boundaries). For this reason they are an ideal criterion for mesh adaptivity in topology optimization, especially when avoiding stress failure is a priority. By using configurational forces for refinement, we obtain a high-resolution structure where the refined mesh is present along the design boundaries as well as in stress-critical regions. At the same time, multilevel coarsening using the same criterion drastically minimizes the computational effort.",
      "authors": [
        "Gabriel Stankiewicz",
        "Chaitanya Dev",
        "Paul Steinmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:52:21+00:00",
          "link": "https://arxiv.org/abs/2507.15570v1",
          "size": "4771kb",
          "version": "v1"
        }
      ],
      "title": "Configurational-force-driven adaptive refinement and coarsening in topology optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15570",
        "HTML": "https://arxiv.org/html/2507.15570",
        "PDF": "https://arxiv.org/pdf/2507.15570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses topology optimization strategies involving configurational forces, which are not related to any LLM training data processing operations or methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2006.13456",
      "abstract": "Gaussian process regression can flexibly represent the posterior distribution of an interest parameter given sufficient information on the likelihood. However, in some cases, we have little knowledge regarding the probability model. For example, when investing in a financial instrument, the probability model of cash flow is generally unknown. In this paper, we propose a novel framework called the likelihood-free Gaussian process (LFGP), which allows representation of the posterior distributions of interest parameters for scalable problems without directly setting their likelihood functions. The LFGP establishes clusters in which the value of the interest parameter can be considered approximately identical, and it approximates the likelihood of the interest parameter in each cluster to a Gaussian using the asymptotic normality of the maximum likelihood estimator. We expect that the proposed framework will contribute significantly to likelihood-free modeling, particularly by reducing the assumptions for the probability model and the computational costs for scalable problems.",
      "authors": [
        "Yuta Shikuri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2020-06-24T03:38:41+00:00",
          "link": "https://arxiv.org/abs/2006.13456v1",
          "size": "344kb",
          "version": "v1"
        },
        {
          "date": "2020-09-13T01:43:12+00:00",
          "link": "https://arxiv.org/abs/2006.13456v2",
          "size": "316kb",
          "version": "v2"
        },
        {
          "date": "2023-12-03T14:51:05+00:00",
          "link": "https://arxiv.org/abs/2006.13456v3",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "2024-05-23T02:48:08+00:00",
          "link": "https://arxiv.org/abs/2006.13456v4",
          "size": "0kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T01:05:12+00:00",
          "link": "https://arxiv.org/abs/2006.13456v5",
          "size": "0kb",
          "version": "v5"
        }
      ],
      "title": "Likelihood-Free Gaussian Process for Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2006.13456",
        "PDF": "https://arxiv.org/pdf/2006.13456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a likelihood-free Gaussian process framework for regression tasks, dealing primarily with probabilistic modeling and estimation. It does not discuss LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.15492",
      "abstract": "Dimension 4 isogenies have first been introduced in cryptography for the cryptanalysis of Supersingular Isogeny Diffie-Hellman (SIDH) and have been used constructively in several schemes, including SQIsignHD, a derivative of SQIsign isogeny based signature scheme. Unlike in dimensions 2 and 3, we can no longer rely on the Jacobian model and its derivatives to compute isogenies. In dimension 4 (and higher), we can only use theta-models. Previous works by Romain Cosset, David Lubicz and Damien Robert have focused on the computation of $\\ell$-isogenies in theta-models of level $n$ coprime to $\\ell$ (which requires to use $n^g$ coordinates in dimension $g$). For cryptographic applications, we need to compute chains of $2$-isogenies, requiring to use $\\geq 3^g$ coordinates in dimension $g$ with state of the art algorithms.\n  In this paper, we present algorithms to compute chains of $2$-isogenies between abelian varieties of dimension $g\\geq 1$ with theta-coordinates of level $n=2$, generalizing a previous work by Pierrick Dartois, Luciano Maino, Giacomo Pope and Damien Robert in dimension $g=2$. We propose an implementation of these algorithms in dimension $g=4$ to compute endomorphisms of elliptic curve products derived from Kani's lemma with applications to SQIsignHD and SIDH cryptanalysis. We are now able to run a complete key recovery attack on SIDH when the endomorphism ring of the starting curve is unknown within a few seconds on a laptop for all NIST SIKE parameters.",
      "authors": [
        "Pierrick Dartois"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-22T09:19:20+00:00",
          "link": "https://arxiv.org/abs/2407.15492v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:41:37+00:00",
          "link": "https://arxiv.org/abs/2407.15492v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "Fast computation of 2-isogenies in dimension 4 and cryptographic applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15492",
        "PDF": "https://arxiv.org/pdf/2407.15492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses algorithms for computing isogenies in dimension 4 with applications to cryptography, lacking any discussion of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/Pierrick-Dartois/SQISignHD-lib"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.14961",
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has emerged to mitigate the computational demands of large-scale models. Within computer vision, adapter-based PEFT methods are often favored over prompt-based approaches like Visual Prompt Tuning (VPT) due to the latter's performance and efficiency limitations. Our analysis reveals that VPT's shortcomings stem from its prompt deployment strategy, which can distort the model's inherent self-attention mechanism. To address this, we propose Cross Visual Prompt Tuning (CVPT). CVPT introduces a cross-attention module to directly model interactions between prompts and image tokens. This design decouples the prompts from the input sequence, preserving the original self-attention integrity while enabling efficient feature integration. Furthermore, we employ a weight-sharing mechanism for cross-attention initialization, which enhances representative capability without a large parameter overhead. Extensive experiments across 25 datasets show that CVPT significantly outperforms VPT. For instance, on the VTAB-1K benchmark, CVPT achieves over 4% higher average accuracy, rivaling leading adapter-based methods in both performance and efficiency. Our work confirms that prompt-based methods can achieve exceptional results in visual fine-tuning. The code is available at https://github.com/Lingyun0419/CVPT",
      "authors": [
        "Lingyun Huang",
        "Jianxu Mao",
        "Junfei Yi",
        "Ziming Tao",
        "Yaonan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-27T11:07:19+00:00",
          "link": "https://arxiv.org/abs/2408.14961v1",
          "size": "587kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:15:13+00:00",
          "link": "https://arxiv.org/abs/2408.14961v2",
          "size": "593kb",
          "version": "v2"
        }
      ],
      "title": "CVPT: Cross Visual Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14961",
        "HTML": "https://arxiv.org/html/2408.14961",
        "PDF": "https://arxiv.org/pdf/2408.14961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for visual prompt tuning in computer vision models. It does not discuss any aspects of training data processing for LLMs, and is centered on model efficiency and visual fine-tuning."
      },
      "tasks": [
        "parameter-efficient fine-tuning",
        "Visual Prompt Tuning"
      ],
      "repo_urls": [
        "https://github.com/xlgsyzp/cvpt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.02146",
      "abstract": "On-device computing, or edge computing, is becoming increasingly important for remote sensing, particularly in applications like deep network-based perception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these scenarios, two brain-like capabilities are crucial for remote sensing models: (1) high energy efficiency, allowing the model to operate on edge devices with limited computing resources, and (2) online adaptation, enabling the model to quickly adapt to environmental variations, weather changes, and sensor drift. This work addresses these needs by proposing an online adaptation framework based on spiking neural networks (SNNs) for remote sensing. Starting with a pretrained SNN model, we design an efficient, unsupervised online adaptation algorithm, which adopts an approximation of the BPTT algorithm and only involves forward-in-time computation that significantly reduces the computational complexity of SNN adaptation learning. Besides, we propose an adaptive activation scaling scheme to boost online SNN adaptation performance, particularly in low time-steps. Furthermore, for the more challenging remote sensing detection task, we propose a confidence-based instance weighting scheme, which substantially improves adaptation performance in the detection task. To our knowledge, this work is the first to address the online adaptation of SNNs. Extensive experiments on seven benchmark datasets across classification, segmentation, and detection tasks demonstrate that our proposed method significantly outperforms existing domain adaptation and domain generalization approaches under varying weather conditions. The proposed method enables energy-efficient and fast online adaptation on edge devices, and has much potential in applications such as remote perception on on-orbit satellites and UAV.",
      "authors": [
        "Dexin Duan",
        "Peilin liu",
        "Bingwei Hui",
        "Fei Wen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T08:47:53+00:00",
          "link": "https://arxiv.org/abs/2409.02146v1",
          "size": "18230kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:32:18+00:00",
          "link": "https://arxiv.org/abs/2409.02146v2",
          "size": "17732kb",
          "version": "v2"
        }
      ],
      "title": "Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02146",
        "HTML": "https://arxiv.org/html/2409.02146",
        "PDF": "https://arxiv.org/pdf/2409.02146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses online adaptation and energy efficiency in spiking neural networks for remote sensing, not related to LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation",
        "Domain Generalization",
        "Edge-computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03111",
      "abstract": "Rice is a staple food for a significant portion of the world's population, providing essential nutrients and serving as a versatile in-gredient in a wide range of culinary traditions. Recently, the use of deep learning has enabled automated classification of rice, im-proving accuracy and efficiency. However, classical models based on first-stage training may face difficulties in distinguishing between rice varieties with similar external characteristics, thus leading to misclassifications. Considering the transparency and feasibility of model, we selected and gradually improved pure fully connected neural network to achieve classification of rice grain. The dataset we used contains both global and domestic rice images obtained from websites and laboratories respectively. First, the training mode was changed from one-stage training to two-stage training, which significantly contributes to distinguishing two similar types of rice. Secondly, the preprocessing method was changed from random tilting to horizontal or vertical position cor-rection. After those two enhancements, the accuracy of our model increased notably from 97% to 99%. In summary, two subtle methods proposed in this study can remarkably enhance the classification ability of deep learning models in terms of the classification of rice grain.",
      "authors": [
        "Wanke Xia",
        "Ruoxin Peng",
        "Haoqi Chu",
        "Xinlei Zhu",
        "Zhiyu Yang",
        "Lili Yang",
        "Bo Lv",
        "Xunwen Xiang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T02:10:14+00:00",
          "link": "https://arxiv.org/abs/2503.03111v1",
          "size": "1071kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:13:30+00:00",
          "link": "https://arxiv.org/abs/2503.03111v2",
          "size": "721kb",
          "version": "v2"
        }
      ],
      "title": "An Improved Pure Fully Connected Neural Network for Rice Grain Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03111",
        "HTML": "https://arxiv.org/html/2503.03111",
        "PDF": "https://arxiv.org/pdf/2503.03111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the use of deep learning for rice grain classification and mentions dataset usage, but it does not contribute to the training data processing for LLMs in any capacity."
      },
      "tasks": [
        "Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02939",
      "abstract": "Spatiotemporal forecasting tasks, such as traffic flow, combustion dynamics, and weather forecasting, often require complex models that suffer from low training efficiency and high memory consumption. This paper proposes a lightweight framework, Spectral Decoupled Knowledge Distillation (termed SDKD), which transfers the multi-scale spatiotemporal representations from a complex teacher model to a more efficient lightweight student network. The teacher model follows an encoder-latent evolution-decoder architecture, where its latent evolution module decouples high-frequency details and low-frequency trends using convolution and Transformer (global low-frequency modeler). However, the multi-layer convolution and deconvolution structures result in slow training and high memory usage. To address these issues, we propose a frequency-aligned knowledge distillation strategy, which extracts multi-scale spectral features from the teacher's latent space, including both high and low frequency components, to guide the lightweight student model in capturing both local fine-grained variations and global evolution patterns. Experimental results show that SDKD significantly improves performance, achieving reductions of up to 81.3% in MSE and in MAE 52.3% on the Navier-Stokes equation dataset. The framework effectively captures both high-frequency variations and long-term trends while reducing computational complexity. Our codes are available at https://github.com/itsnotacie/SDKD",
      "authors": [
        "Yuqi Li",
        "Chuanguang Yang",
        "Hansheng Zeng",
        "Zeyu Dong",
        "Zhulin An",
        "Yongjun Xu",
        "Yingli Tian",
        "Hao Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:24:37+00:00",
          "link": "https://arxiv.org/abs/2507.02939v1",
          "size": "2762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T17:02:56+00:00",
          "link": "https://arxiv.org/abs/2507.02939v2",
          "size": "6170kb",
          "version": "v2"
        }
      ],
      "title": "Frequency-Aligned Knowledge Distillation for Lightweight Spatiotemporal Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02939",
        "HTML": "https://arxiv.org/html/2507.02939",
        "PDF": "https://arxiv.org/pdf/2507.02939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for knowledge distillation to reduce computational complexity in spatiotemporal forecasting, focusing on model efficiency rather than on training data processing tasks like dataset creation or quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14447",
      "abstract": "The deployment of agent systems in an enterprise environment is often hindered by several challenges: common models lack domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability. To address this, this paper introduces Routine, a multi-step agent planning framework designed with a clear structure, explicit instructions, and seamless parameter passing to guide the agent's execution module in performing multi-step tool-calling tasks with high stability. In evaluations conducted within a real-world enterprise scenario, Routine significantly increases the execution accuracy in model tool calls, increasing the performance of GPT-4o from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an accuracy increase to 88.2% on scenario-specific evaluations, indicating improved adherence to execution plans. In addition, we employed Routine-based distillation to create a scenario-specific, multi-step tool-calling dataset. Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%, approaching GPT-4o's performance. These results highlight Routine's effectiveness in distilling domain-specific tool-usage patterns and enhancing model adaptability to new scenarios. Our experimental results demonstrate that Routine provides a practical and accessible approach to building stable agent workflows, accelerating the deployment and adoption of agent systems in enterprise environments, and advancing the technical vision of AI for Process.",
      "authors": [
        "Guancheng Zeng",
        "Xueyi Chen",
        "Jiawang Hu",
        "Shaohua Qi",
        "Yaxuan Mao",
        "Zhantao Wang",
        "Yifan Nie",
        "Shuang Li",
        "Qiuyang Feng",
        "Pengxu Qiu",
        "Yujia Wang",
        "Wenqiang Han",
        "Linyan Huang",
        "Gang Li",
        "Jingjing Mo",
        "Haowen Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:46:19+00:00",
          "link": "https://arxiv.org/abs/2507.14447v1",
          "size": "1284kb",
          "version": "v1"
        }
      ],
      "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14447",
        "HTML": "https://arxiv.org/html/2507.14447",
        "PDF": "https://arxiv.org/pdf/2507.14447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces the Routine framework and a dataset for fine-tuning LLM agents, its primary focus is on enhancing execution accuracy and tool-calling capabilities, not directly on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15515",
      "abstract": "Movable-antennas (MAs) are revolutionizing spatial signal processing by providing flexible beamforming in next-generation wireless systems. This paper investigates an MA-empowered autonomous aerial vehicle (AAV) system in low-altitude wireless networks (LAWNs) for uplink data collection from ground users. We aim to maximize the sum achievable rate by jointly optimizing the AAV trajectory, receive beamforming, and MA positions. An efficient alternating optimization (AO) algorithm that incorporates successive convex approximation, weighted minimum mean square error, and particle swarm optimization is developed. The analysis of the computational complexity and convergence features is provided. Extensive simulations demonstrate superior performance in terms of the sum achievable rate and the service reliability comparing to several benchmark schemes. These results demonstrate the distinctive advantages of the proposed scheme: enhanced spectral efficiency via adaptive beam-user alignment and improved collection reliability through spatial interference management, highlighting the implementation potential of the MA-empowered LAWNs.",
      "authors": [
        "Xuhui Zhang and Wenchao Liu and Jinke Ren and Chunjie Wang and Huijun Xing and Yanyan Shen and Shuguang Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:30:29+00:00",
          "link": "https://arxiv.org/abs/2507.15515v1",
          "size": "201kb",
          "version": "v1"
        }
      ],
      "title": "Movable-Antenna Empowered AAV-Enabled Data Collection over Low-Altitude Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15515",
        "HTML": "https://arxiv.org/html/2507.15515",
        "PDF": "https://arxiv.org/pdf/2507.15515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the utilization of movable-antennas in autonomous aerial vehicles for data collection in wireless networks, rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15664",
      "abstract": "Large language models (LLMs) have demonstrated immense potential in computer-aided design (CAD), particularly for automated debugging and verification within electronic design automation (EDA) tools. However, Design for Testability (DFT) remains a relatively underexplored area. This paper presents VeriRAG, the first LLM-assisted DFT-EDA framework. VeriRAG leverages a Retrieval-Augmented Generation (RAG) approach to enable LLM to revise code to ensure DFT compliance. VeriRAG integrates (1) an autoencoder-based similarity measurement model for precise retrieval of reference RTL designs for the LLM, and (2) an iterative code revision pipeline that allows the LLM to ensure DFT compliance while maintaining synthesizability. To support VeriRAG, we introduce VeriDFT, a Verilog-based DFT dataset curated for DFT-aware RTL repairs. VeriRAG retrieves structurally similar RTL designs from VeriDFT, each paired with a rigorously validated correction, as references for code repair. With VeriRAG and VeriDFT, we achieve fully automated DFT correction -- resulting in a 7.72-fold improvement in successful repair rate compared to the zero-shot baseline (Fig. 5 in Section V). Ablation studies further confirm the contribution of each component of the VeriRAG framework. We open-source our data, models, and scripts at https://github.com/yuyangdu01/LLM4DFT.",
      "authors": [
        "Haomin Qi",
        "Yuyang Du",
        "Lihao Zhang",
        "Soung Chang Liew",
        "Kexin Chen",
        "Yining Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:25:52+00:00",
          "link": "https://arxiv.org/abs/2507.15664v1",
          "size": "2222kb",
          "version": "v1"
        }
      ],
      "title": "VeriRAG: A Retrieval-Augmented Framework for Automated RTL Testability Repair",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15664",
        "HTML": "https://arxiv.org/html/2507.15664",
        "PDF": "https://arxiv.org/pdf/2507.15664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces VeriDFT, a Verilog-based DFT dataset for a new LLM-augmented framework. While the focus is on DFT-EDA, it mentions dataset curation which partially aligns with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14582",
      "abstract": "In the field of Learning from Demonstration (LfD), enabling robots to generalize learned manipulation skills to novel scenarios for long-horizon tasks remains challenging. Specifically, it is still difficult for robots to adapt the learned skills to new environments with different task and motion requirements, especially in long-horizon, multi-stage scenarios with intricate constraints. This paper proposes a novel hierarchical framework, called BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and Dynamical Movement Primitives (DMPs) to address this problem. Within this framework, Signal Temporal Logic (STL) is employed to formally specify complex, long-horizon task requirements and constraints. These STL specifications are systematically transformed to generate reactive and modular BTs for high-level decision-making task structure. An STL-constrained DMP optimization method is proposed to optimize the DMP forcing term, allowing the learned motion primitives to adapt flexibly while satisfying intricate spatiotemporal requirements and, crucially, preserving the essential dynamics learned from demonstrations. The framework is validated through simulations demonstrating generalization capabilities under various STL constraints and real-world experiments on several long-horizon robotic manipulation tasks. The results demonstrate that the proposed framework effectively bridges the symbolic-motion gap, enabling more reliable and generalizable autonomous manipulation for complex robotic tasks.",
      "authors": [
        "Zezhi Liu",
        "Shizhen Wu",
        "Hanqian Luo",
        "Deyun Qin",
        "Yongchun Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T11:53:24+00:00",
          "link": "https://arxiv.org/abs/2507.14582v1",
          "size": "13436kb",
          "version": "v1"
        }
      ],
      "title": "BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14582",
        "HTML": "https://arxiv.org/html/2507.14582",
        "PDF": "https://arxiv.org/pdf/2507.14582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a framework for robotic manipulation tasks, combining Behavior Tree, Temporal Logic, and Dynamical Movement Primitives. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14805",
      "abstract": "We study subliminal learning, a surprising phenomenon where language models transmit behavioral traits via semantically unrelated data. In our main experiments, a \"teacher\" model with some trait T (such as liking owls or being misaligned) generates a dataset consisting solely of number sequences. Remarkably, a \"student\" model trained on this dataset learns T. This occurs even when the data is filtered to remove references to T. We observe the same effect when training on code or reasoning traces generated by the same teacher model. However, we do not observe the effect when the teacher and student have different base models. To help explain our findings, we prove a theoretical result showing that subliminal learning occurs in all neural networks under certain conditions, and demonstrate subliminal learning in a simple MLP classifier. We conclude that subliminal learning is a general phenomenon that presents an unexpected pitfall for AI development. Distillation could propagate unintended traits, even when developers try to prevent this via data filtering.",
      "authors": [
        "Alex Cloud",
        "Minh Le",
        "James Chua",
        "Jan Betley",
        "Anna Sztyber-Betley",
        "Jacob Hilton",
        "Samuel Marks",
        "Owain Evans"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:51:13+00:00",
          "link": "https://arxiv.org/abs/2507.14805v1",
          "size": "772kb",
          "version": "v1"
        }
      ],
      "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14805",
        "HTML": "https://arxiv.org/html/2507.14805",
        "PDF": "https://arxiv.org/pdf/2507.14805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies subliminal learning where LLMs transmit behavioral traits via data but does not address LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15143",
      "abstract": "This paper investigates the feasibility of human mobility in The Line, a proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess whether citizens can move freely within this unprecedented urban topology, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning, supervised learning, and graph neural networks. The simulation captures multi-modal transportation behaviors across 50 vertical levels and varying density scenarios using both synthetic data and real-world traces from high-density cities. Our experiments reveal that with the full AI-integrated architecture, agents achieved an average commute time of 7.8 to 8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index of over 91 percent, even during peak congestion periods. Ablation studies confirmed that the removal of intelligent modules such as reinforcement learning or graph neural networks significantly degrades performance, with commute times increasing by up to 85 percent and reachability falling below 70 percent. Environmental modeling further demonstrated low energy consumption and minimal CO2 emissions when electric modes are prioritized. The findings suggest that freedom of movement is not only conceptually achievable in The Line, but also operationally realistic if supported by adaptive AI systems, sustainable infrastructure, and real-time feedback loops.",
      "authors": [
        "Abderaouf Bahi and Amel Ourici"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:35:16+00:00",
          "link": "https://arxiv.org/abs/2507.15143v1",
          "size": "5121kb",
          "version": "v1"
        }
      ],
      "title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15143",
        "PDF": "https://arxiv.org/pdf/2507.15143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines human mobility in a linear smart city and uses AI technologies for simulation, but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15350",
      "abstract": "Hermite spectral method plays an important role in the numerical simulation of various partial differential equations (PDEs) on unbounded domains. In this work, we study the superconvergence properties of Hermite spectral interpolation, i.e., interpolation at the zeros of Hermite polynomials in the space spanned by Hermite functions. We identify the points at which the convergence rates of the first- and second-order derivatives of the interpolant converge faster. We further extend the analysis to the Hermite spectral collocation method in solving differential equations and identify the superconvergence points both for function and derivative values. Numerical examples are provided to confirm the analysis of superconvergence points.",
      "authors": [
        "Haiyong Wang and Zhimin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:01:46+00:00",
          "link": "https://arxiv.org/abs/2507.15350v1",
          "size": "882kb",
          "version": "v1"
        }
      ],
      "title": "Superconvergence points of Hermite spectral interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15350",
        "HTML": "https://arxiv.org/html/2507.15350",
        "PDF": "https://arxiv.org/pdf/2507.15350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Hermite spectral interpolation in the context of numerical simulation of PDEs, which is unrelated to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15484",
      "abstract": "This research was a part of a project that developed mobile robots that performed targeted pollen spraying and automated harvesting in pergola structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were designed and field testing of one of the concepts showed that the mechanism could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy, whereas the previous state of the art mechanism was only able to reach less than 70 percent of the fruit. Artificial pollination was performed by detecting flowers and then spraying pollen in solution onto the detected flowers from a line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the height of the canopy was measured and the spray boom was moved up and down to keep the boom close enough to the flowers for the spray to reach the flowers, while minimising collisions with the canopy. Mobile robot navigation was performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in kiwifruit orchards was more challenging because the pergola structure only provides a small amount of data for the direction of rows, compared to the amount of data from the overhead canopy, the undulating ground and other objects in the orchards. Multiple methods are presented here for extracting structure defining features from 3D lidar data in kiwifruit orchards. In addition, a 3D lidar navigation system -- which performed row following, row end detection and row end turns -- was tested for over 30 km of autonomous driving in kiwifruit orchards. Computer vision algorithms for row detection and row following were also tested. The computer vision algorithm worked as well as the 3D lidar row following method in testing.",
      "authors": [
        "Jamie Bell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:40:28+00:00",
          "link": "https://arxiv.org/abs/2507.15484v1",
          "size": "5569kb",
          "version": "v1"
        }
      ],
      "title": "Robots for Kiwifruit Harvesting and Pollination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15484",
        "PDF": "https://arxiv.org/pdf/2507.15484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about robotics for kiwifruit harvesting and pollination, including mobile robot navigation and detachment mechanisms. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15596",
      "abstract": "Programmable Logic Controllers (PLCs) are widely used in industrial automation to control physical systems. As PLC applications become increasingly complex, ensuring their correctness is crucial. Existing formal verification techniques focus on individual PLC programs in isolation, often neglecting interactions with physical environments and network communication between controllers. This limitation poses significant challenges in analyzing real-world industrial systems, where continuous dynamics and communication delays play a critical role. In this paper, we present a unified formal framework that integrates discrete PLC semantics, networked communication, and continuous physical behaviors. To mitigate state explosion, we apply partial order reduction, significantly reducing the number of explored states while maintaining correctness. Our framework enables precise analysis of PLC-driven systems with continuous dynamics and networked communication.",
      "authors": [
        "Jaeseo Lee",
        "Kyungmin Bae"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:18:50+00:00",
          "link": "https://arxiv.org/abs/2507.15596v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Formal Analysis of Networked PLC Controllers Interacting with Physical Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15596",
        "HTML": "https://arxiv.org/html/2507.15596",
        "PDF": "https://arxiv.org/pdf/2507.15596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses formal analysis of PLC controllers and does not involve any training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18214",
      "abstract": "Text-to-Image (T2I) Diffusion Models (DMs) have garnered widespread attention for their impressive advancements in image generation. However, their growing popularity has raised ethical and social concerns related to key non-functional properties of trustworthiness, such as robustness, fairness, security, privacy, factuality, and explainability, similar to those in traditional deep learning (DL) tasks. Conventional approaches for studying trustworthiness in DL tasks often fall short due to the unique characteristics of T2I DMs, e.g., the multi-modal nature. Given the challenge, recent efforts have been made to develop new methods for investigating trustworthiness in T2I DMs via various means, including falsification, enhancement, verification \\& validation and assessment. However, there is a notable lack of in-depth analysis concerning those non-functional properties and means. In this survey, we provide a timely and focused review of the literature on trustworthy T2I DMs, covering a concise-structured taxonomy from the perspectives of property, means, benchmarks and applications. Our review begins with an introduction to essential preliminaries of T2I DMs, and then we summarise key definitions/metrics specific to T2I tasks and analyses the means proposed in recent literature based on these definitions/metrics. Additionally, we review benchmarks and domain applications of T2I DMs. Finally, we highlight the gaps in current research, discuss the limitations of existing methods, and propose future research directions to advance the development of trustworthy T2I DMs. Furthermore, we keep up-to-date updates in this field to track the latest developments and maintain our GitHub repository at: https://github.com/wellzline/Trustworthy_T2I_DMs",
      "authors": [
        "Yi Zhang",
        "Zhen Chen",
        "Chih-Hong Cheng",
        "Wenjie Ruan",
        "Xiaowei Huang",
        "Dezong Zhao",
        "David Flynn",
        "Siddartha Khastgir",
        "Xingyu Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T18:46:47+00:00",
          "link": "https://arxiv.org/abs/2409.18214v1",
          "size": "3051kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:50:36+00:00",
          "link": "https://arxiv.org/abs/2409.18214v2",
          "size": "2945kb",
          "version": "v2"
        }
      ],
      "title": "Trustworthy Text-to-Image Diffusion Models: A Timely and Focused Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18214",
        "HTML": "https://arxiv.org/html/2409.18214",
        "PDF": "https://arxiv.org/pdf/2409.18214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey examines trustworthiness in text-to-image diffusion models, focusing on ethical and social concerns, not LLM training data processing operations."
      },
      "tasks": [
        "Fairness",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/wellzline/trustworthy_t2i_dms"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.09162",
      "abstract": "We consider the simulation of isentropic flow in pipelines and pipe networks. Standard operating conditions in pipe networks suggest an emphasis to simulate low Mach and high friction regimes -- however, the system is stiff in these regimes and conventional explicit approximation techniques prove quite costly and often impractical. To combat these inefficiencies, we develop a novel asymptotic-preserving scheme that is uniformly consistent and stable for all Mach regimes. The proposed method for a single pipeline follows the flux splitting suggested in [Haack et al., Commun. Comput. Phys., 12 (2012), pp. 955--980], in which the flux is separated into stiff and non-stiff portions then discretized in time using an implicit-explicit approach. The non-stiff part is advanced in time by an explicit hyperbolic solver; we opt for the second-order central-upwind finite volume scheme. The stiff portion is advanced in time implicitly using an approach based on Rosenbrock-type Runge-Kutta methods, which ultimately reduces this implicit stage to a discretization of a linear elliptic equation.\n  To extend to full pipe networks, the scheme on a single pipeline is paired with coupling conditions defined at pipe-to-pipe intersections to ensure a mathematically well-posed problem. We show that the coupling conditions remain well-posed in the low Mach/high friction limit -- which, when used to define the ghost cells of each pipeline, results in a method that is accurate across these intersections in all regimes. The proposed method is tested on several numerical examples and produces accurate, non-oscillatory results with run times independent of the Mach number.",
      "authors": [
        "Michael Redle and Michael Herty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T03:31:36+00:00",
          "link": "https://arxiv.org/abs/2411.09162v1",
          "size": "365kb",
          "version": "v1"
        }
      ],
      "title": "An Asymptotic-Preserving Scheme for Isentropic Flow in Pipe Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09162",
        "HTML": "https://arxiv.org/html/2411.09162",
        "PDF": "https://arxiv.org/pdf/2411.09162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new scheme for simulating isentropic flow in pipe networks, which is unrelated to processing training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03466",
      "abstract": "Retinal vascular morphology is crucial for diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and style augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to implement random photometric augmentations and introduce uncertainty perturbations, thereby enriching stylistic diversity and significantly enhancing the model's adaptability to varying imaging conditions. Our framework has been rigorously evaluated on four challenging datasets-DRIVE, CHASEDB, HRF, and STARE-demonstrating state-of-the-art performance that surpasses existing methods. This validates the effectiveness of our proposed approach, highlighting its potential for clinical application in automated retinal vessel analysis.",
      "authors": [
        "Bo Liu",
        "Yudong Zhang",
        "Shuihua Wang",
        "Siyue Li",
        "Jin Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T01:47:57+00:00",
          "link": "https://arxiv.org/abs/2501.03466v1",
          "size": "1105kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:09:10+00:00",
          "link": "https://arxiv.org/abs/2501.03466v2",
          "size": "2151kb",
          "version": "v2"
        }
      ],
      "title": "DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03466",
        "PDF": "https://arxiv.org/pdf/2501.03466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on medical image segmentation using structural and stylistic augmentation, and there's no connection to LLM training data processing."
      },
      "tasks": [
        "Domain Generalization",
        "Image Segmentation",
        "Retinal Vessel Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02311",
      "abstract": "Compute-in-memory (CIM) architecture has been widely\n  explored to address the von Neumann bottleneck in accelerating deep\n  neural networks (DNNs). However, its reliability remains largely understudied, particularly in the emerging domain of floating-point (FP)\n  CIM, which is crucial for speeding up high-precision inference and on device training. This paper introduces Unicorn-CIM, a framework to\n  uncover the vulnerability and improve the resilience of high-precision\n  CIM, built on static random-access memory (SRAM)-based FP CIM\n  architecture. Through the development of fault injection and extensive\n  characterizations across multiple DNNs, Unicorn-CIM reveals how soft\n  errors manifest in FP operations and impact overall model performance.\n  Specifically, we find that high-precision DNNs are extremely sensitive\n  to errors in the exponent part of FP numbers. Building on this insight,\n  Unicorn-CIM develops an efficient algorithm-hardware co-design method\n  that optimizes model exponent distribution through fine-tuning and\n  incorporates a lightweight Error Correcting Code (ECC) scheme to\n  safeguard high-precision DNNs on FP CIM. Comprehensive experiments\n  show that our approach introduces just an 8.98% minimal logic overhead\n  on the exponent processing path while providing robust error protection\n  and maintaining model accuracy. This work paves the way for developing\n  more reliable and efficient CIM hardware.",
      "authors": [
        "Qiufeng Li",
        "Yiwen Liang",
        "Weidong Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T22:59:49+00:00",
          "link": "https://arxiv.org/abs/2506.02311v1",
          "size": "5478kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:18:39+00:00",
          "link": "https://arxiv.org/abs/2506.02311v2",
          "size": "5478kb",
          "version": "v2"
        }
      ],
      "title": "Unicorn-CIM: Uncovering the Vulnerability and Improving the Resilience of High-Precision Compute-in-Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02311",
        "HTML": "https://arxiv.org/html/2506.02311",
        "PDF": "https://arxiv.org/pdf/2506.02311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the resilience and reliability of high-precision compute-in-memory architectures rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06114",
      "abstract": "This paper aims to numerically solve the two-dimensional electrical impedance tomography (EIT) with Cauchy data. This inverse problem is highly challenging due to its severe ill-posed nature and strong nonlinearity, which necessitates appropriate regularization strategies. Choosing a regularization approach that effectively incorporates the \\textit{a priori} information of the conductivity distribution (or its contrast) is therefore essential. In this work, we propose a deep learning-based method to capture the \\textit{a priori} information about the shape and location of the unknown contrast using Calder\\'on's method. The learned \\textit{a priori} information is then used to construct the regularization functional of the variational regularization method for solving the inverse problem. The resulting regularized variational problem for EIT reconstruction is then solved using the Gauss-Newton method. Extensive numerical experiments demonstrate that the proposed inversion algorithm achieves accurate reconstruction results, even in high-contrast cases, and exhibits strong generalization capabilities. Additionally, some stability and convergence analysis of the variational regularization method underscores the importance of incorporating \\textit{a priori} information about the support of the unknown contrast.",
      "authors": [
        "Kai Li",
        "Kwancheol Shin",
        "Zhi Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:55:22+00:00",
          "link": "https://arxiv.org/abs/2507.06114v1",
          "size": "12127kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:39:03+00:00",
          "link": "https://arxiv.org/abs/2507.06114v2",
          "size": "12086kb",
          "version": "v2"
        }
      ],
      "title": "Learning-Enhanced Variational Regularization for Electrical Impedance Tomography via Calder\\'on's Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06114",
        "HTML": "https://arxiv.org/html/2507.06114",
        "PDF": "https://arxiv.org/pdf/2507.06114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses solving Electrical Impedance Tomography with regularization methods and deep learning for inverse problems. It is unrelated to LLM training data processing, concentrating on numerical reconstruction, not data collection or dataset generation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08216",
      "abstract": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to process the input entities, while relying on a reasoner based on First-Order Logic to represent and process more complex relationships among the entities. A fundamental role for these methods is played by the process of logic grounding, which determines the relevant substitutions for the logic rules using a (sub)set of entities. Some NeSy methods use an exhaustive derivation of all possible substitutions, preserving the full expressive power of the logic knowledge. This leads to a combinatorial explosion in the number of ground formulas to consider and, therefore, strongly limits their scalability. Other methods rely on heuristic-based selective derivations, which are generally more computationally efficient, but lack a justification and provide no guarantees of preserving the information provided to and returned by the reasoner. Taking inspiration from multi-hop symbolic reasoning, this paper proposes a parametrized family of grounding methods generalizing classic Backward Chaining. Different selections within this family allow us to obtain commonly employed grounding methods as special cases, and to control the trade-off between expressiveness and scalability of the reasoner. The experimental results show that the selection of the grounding criterion is often as important as the NeSy method itself.",
      "authors": [
        "Rodrigo Castellano Ontiveros",
        "Francesco Giannini",
        "Marco Gori",
        "Giuseppe Marra and Michelangelo Diligenti"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:29:15+00:00",
          "link": "https://arxiv.org/abs/2507.08216v1",
          "size": "1657kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.08216v2",
          "size": "1657kb",
          "version": "v2"
        }
      ],
      "title": "Grounding Methods for Neural-Symbolic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08216",
        "HTML": "https://arxiv.org/html/2507.08216",
        "PDF": "https://arxiv.org/pdf/2507.08216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses logic grounding methods in Neural-Symbolic AI, focusing on logical reasoning and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14196",
      "abstract": "Background and Objective: Differentiating wide complex tachycardia (WCT) is clinically critical yet challenging due to morphological similarities in electrocardiogram (ECG) signals between life-threatening ventricular tachycardia (VT) and supraventricular tachycardia with aberrancy (SVT-A). Misdiagnosis carries fatal risks. We propose a computationally efficient deep learning solution to improve diagnostic accuracy and provide model interpretability for clinical deployment.\n  Methods: A novel lightweight parallel deep architecture is introduced. Each pipeline processes individual ECG leads using two 1D-CNN blocks to extract local features. Feature maps are concatenated across leads, followed by LSTM layers to capture temporal dependencies. Final classification employs fully connected layers. Explainability is achieved via Shapley Additive Explanations (SHAP) for local/global interpretation. The model was evaluated on a 35-subject ECG database using standard performance metrics.\n  Results: The model achieved $95.63\\%$ accuracy ($95\\%$ CI: $93.07-98.19\\%$), with sensitivity=$95.10\\%$, specificity=$96.06\\%$, and F1-score=$95.12\\%$. It outperformed state-of-the-art methods in both accuracy and computational efficiency, requiring minimal CNN blocks per pipeline. SHAP analysis demonstrated clinically interpretable feature contributions.\n  Conclusions: Our end-to-end framework delivers high-precision WCT classification with minimal computational overhead. The integration of SHAP enhances clinical trust by elucidating decision logic, supporting rapid, informed diagnosis. This approach shows significant promise for real-world ECG analysis tools.",
      "authors": [
        "Zahra Teimouri-Jervekani",
        "Fahimeh Nasimi",
        "Mohammadreza Yazdchi",
        "Ghazal MogharehZadeh",
        "Javad Tezerji",
        "Farzan Niknejad Mazandarani",
        "Maryam Mohebbi"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:12:34+00:00",
          "link": "https://arxiv.org/abs/2507.14196v1",
          "size": "1542kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Parallel CNN-LSTM Model for Differentiating Ventricular Tachycardia from Supraventricular Tachycardia with Aberrancy in 12-Lead ECGs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14196",
        "HTML": "https://arxiv.org/html/2507.14196",
        "PDF": "https://arxiv.org/pdf/2507.14196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a deep learning model for ECG signal classification, which is not related to LLM training data processing or relevant dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14472",
      "abstract": "Strategyproofness in network auctions requires that bidders not only report their valuations truthfully, but also do their best to invite neighbours from the social network. In contrast to canonical auctions, where the value-monotone allocation in Myerson's Lemma is a cornerstone, a general principle of allocation rules for strategyproof network auctions is still missing. We show that, due to the absence of such a principle, even extensions to multi-unit network auctions with single-unit demand present unexpected difficulties, and all pioneering researches fail to be strategyproof. For the first time in this field, we identify two categories of monotone allocation rules on networks: Invitation-Depressed Monotonicity (ID-MON) and Invitation-Promoted Monotonicity (IP-MON). They encompass all existing allocation rules of network auctions as specific instances. For any given ID-MON or IP-MON allocation rule, we characterize the existence and sufficient conditions for the strategyproof payment rules, and show that among all such payment rules, the revenue-maximizing one exists and is computationally feasible. With these results, the obstacle of combinatorial network auction with single-minded bidders is now resolved.",
      "authors": [
        "Yuhang Guo",
        "Dong Hao",
        "Bin Li",
        "Mingyu Xiao",
        "Bakh Khoussainov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:05:35+00:00",
          "link": "https://arxiv.org/abs/2507.14472v1",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "title": "Strategyproofness and Monotone Allocation of Auction in Social Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14472",
        "HTML": "https://arxiv.org/html/2507.14472",
        "PDF": "https://arxiv.org/pdf/2507.14472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with auction strategyproofness in social networks and identifies monotone allocation rules, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14685",
      "abstract": "The rapid growth and availability of event sequence data across domains requires effective analysis and exploration methods to facilitate decision-making. Visual analytics combines computational techniques with interactive visualizations, enabling the identification of patterns, anomalies, and attribute interactions. However, existing approaches frequently overlook the interplay between temporal and multivariate attributes. We introduce EventBox, a novel data representation and visual encoding approach for analyzing groups of events and their multivariate attributes. We have integrated EventBox into Sequen-C, a visual analytics system for the analysis of event sequences. To enable the agile creation of EventBoxes in Sequen-C, we have added user-driven transformations, including alignment, sorting, substitution and aggregation. To enhance analytical depth, we incorporate automatically generated statistical analyses, providing additional insight into the significance of attribute interactions. We evaluated our approach involving 21 participants (3 domain experts, 18 novice data analysts). We used the ICE-T framework to assess visualization value, user performance metrics completing a series of tasks, and interactive sessions with domain experts. We also present three case studies with real-world healthcare data demonstrating how EventBox and its integration into Sequen-C reveal meaningful patterns, anomalies, and insights. These results demonstrate that our work advances visual analytics by providing a flexible solution for exploring temporal and multivariate attributes in event sequences.",
      "authors": [
        "Luis Montana",
        "Jessica Magallanes",
        "Miguel Juarez",
        "Suzanne Mason",
        "Andrew Narracott",
        "Lindsey van Gemeren",
        "Steven Wood",
        "Maria-Cruz Villa-Uriol"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:28:37+00:00",
          "link": "https://arxiv.org/abs/2507.14685v1",
          "size": "6086kb",
          "version": "v1"
        }
      ],
      "title": "EventBox: A Novel Visual Encoding for Interactive Analysis of Temporal and Multivariate Attributes in Event Sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14685",
        "HTML": "https://arxiv.org/html/2507.14685",
        "PDF": "https://arxiv.org/pdf/2507.14685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on visual analytics and enhancing the analysis of temporal and multivariate attributes in event sequences, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14932",
      "abstract": "The Multiple Instance Learning (MIL) paradigm is attracting plenty of attention in medical imaging classification, where labeled data is scarce. MIL methods cast medical images as bags of instances (e.g. patches in whole slide images, or slices in CT scans), and only bag labels are required for training. Deep MIL approaches have obtained promising results by aggregating instance-level representations via an attention mechanism to compute the bag-level prediction. These methods typically capture both local interactions among adjacent instances and global, long-range dependencies through various mechanisms. However, they treat attention values deterministically, potentially overlooking uncertainty in the contribution of individual instances. In this work we propose a novel probabilistic framework that estimates a probability distribution over the attention values, and accounts for both global and local interactions. In a comprehensive evaluation involving {\\color{review} eleven} state-of-the-art baselines and three medical datasets, we show that our approach achieves top predictive performance in different metrics. Moreover, the probabilistic treatment of the attention provides uncertainty maps that are interpretable in terms of illness localization.",
      "authors": [
        "Francisco M. Castro-Mac\\'ias and Pablo Morales-\\'Alvarez and Yunan Wu and Rafael Molina and Aggelos K. Katsaggelos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:58:17+00:00",
          "link": "https://arxiv.org/abs/2507.14932v1",
          "size": "19743kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic smooth attention for deep multiple instance learning in medical imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14932",
        "HTML": "https://arxiv.org/html/2507.14932",
        "PDF": "https://arxiv.org/pdf/2507.14932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a probabilistic framework for attention in medical imaging with deep multiple instance learning, focusing on medical data, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14995",
      "abstract": "Real-time peer-to-peer (P2P) electricity markets dynamically adapt to fluctuations in renewable energy and variations in demand, maximizing economic benefits through instantaneous price responses while enhancing grid flexibility. However, scaling expert guidance for massive personalized prosumers poses critical challenges, including diverse decision-making demands and lack of customized modeling frameworks. This paper proposed an integrated large language model-multi-agent reinforcement learning (LLM-MARL) framework for real-time P2P energy trading to address challenges such as the limited technical capability of prosumers, the lack of expert experience, and security issues of distribution networks. LLMs are introduced as experts to generate personalized strategy, guiding MARL under the centralized training with decentralized execution (CTDE) paradigm through imitation learning. A differential attention-based critic network is designed to enhance convergence performance. Experimental results demonstrate that LLM generated strategies effectively substitute human experts. The proposed multi-agent imitation learning algorithms achieve significantly lower economic costs and voltage violation rates on test sets compared to baselines algorithms, while maintaining robust stability. This work provides an effective solution for real-time P2P electricity market decision-making by bridging expert knowledge with agent learning.",
      "authors": [
        "Chengwei Lou",
        "Zekai Jin",
        "Wei Tang",
        "Guangfei Geng",
        "Jin Yang",
        "and Lu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:59:18+00:00",
          "link": "https://arxiv.org/abs/2507.14995v1",
          "size": "7390kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14995",
        "HTML": "https://arxiv.org/html/2507.14995",
        "PDF": "https://arxiv.org/pdf/2507.14995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using LLMs for strategy generation in multi-agent reinforcement learning for energy trading. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15073",
      "abstract": "Flow-matching policies have emerged as a powerful paradigm for generalist robotics. These models are trained to imitate an action chunk, conditioned on sensor observations and textual instructions. Often, training demonstrations are generated by a suboptimal policy, such as a human operator. This work explores training flow-matching policies via reinforcement learning to surpass the original demonstration policy performance. We particularly note minimum-time control as a key application and present a simple scheme for variable-horizon flow-matching planning. We then introduce two families of approaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group Relative Policy Optimization (GRPO) approach with a learned reward surrogate. Our policies are trained on an illustrative suite of simulated unicycle dynamics tasks, and we show that both approaches dramatically improve upon the suboptimal demonstrator performance, with the GRPO approach in particular generally incurring between $50\\%$ and $85\\%$ less cost than a naive Imitation Learning Flow Matching (ILFM) approach.",
      "authors": [
        "Samuel Pfrommer",
        "Yixiao Huang",
        "Somayeh Sojoudi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:15:18+00:00",
          "link": "https://arxiv.org/abs/2507.15073v1",
          "size": "817kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning for Flow-Matching Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15073",
        "HTML": "https://arxiv.org/html/2507.15073",
        "PDF": "https://arxiv.org/pdf/2507.15073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses reinforcement learning applied to flow-matching policies in robotics, focusing on policy improvement. It does not relate to LLM training data processing or the creation of datasets for such models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15395",
      "abstract": "In real-world recommendation scenarios, users typically engage with platforms through multiple types of behavioral interactions. Multi-behavior recommendation algorithms aim to leverage various auxiliary user behaviors to enhance prediction for target behaviors of primary interest (e.g., buy), thereby overcoming performance limitations caused by data sparsity in target behavior records. Current state-of-the-art approaches typically employ hierarchical design following either cascading (e.g., view$\\rightarrow$cart$\\rightarrow$buy) or parallel (unified$\\rightarrow$behavior$\\rightarrow$specific components) paradigms, to capture behavioral relationships. However, these methods still face two critical challenges: (1) severe distribution disparities across behaviors, and (2) negative transfer effects caused by noise in auxiliary behaviors. In this paper, we propose a novel model-agnostic Hierarchical Graph Information Bottleneck (HGIB) framework for multi-behavior recommendation to effectively address these challenges. Following information bottleneck principles, our framework optimizes the learning of compact yet sufficient representations that preserve essential information for target behavior prediction while eliminating task-irrelevant redundancies. To further mitigate interaction noise, we introduce a Graph Refinement Encoder (GRE) that dynamically prunes redundant edges through learnable edge dropout mechanisms. We conduct comprehensive experiments on three real-world public datasets, which demonstrate the superior effectiveness of our framework. Beyond these widely used datasets in the academic community, we further expand our evaluation on several real industrial scenarios and conduct an online A/B testing, showing again a significant improvement in multi-behavior recommendations. The source code of our proposed HGIB is available at https://github.com/zhy99426/HGIB.",
      "authors": [
        "Hengyu Zhang",
        "Chunxu Shen",
        "Xiangguo Sun",
        "Jie Tan",
        "Yanchao Tan",
        "Yu Rong",
        "Hong Cheng and Lingling Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:53:49+00:00",
          "link": "https://arxiv.org/abs/2507.15395v1",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15395",
        "HTML": "https://arxiv.org/html/2507.15395",
        "PDF": "https://arxiv.org/pdf/2507.15395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a model for multi-behavior recommendation, focusing on improving recommendation systems, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.08938",
      "abstract": "In the past decade, motivated by the putative failure of naive self-play deep reinforcement learning (DRL) in adversarial imperfect-information games, researchers have developed numerous DRL algorithms based on fictitious play (FP), double oracle (DO), and counterfactual regret minimization (CFR). In light of recent results of the magnetic mirror descent algorithm, we hypothesize that simpler generic policy gradient methods like PPO are competitive with or superior to these FP-, DO-, and CFR-based DRL approaches. To facilitate the resolution of this hypothesis, we implement and release the first broadly accessible exact exploitability computations for four large games. Using these games, we conduct the largest-ever exploitability comparison of DRL algorithms for imperfect-information games. Over 5600 training runs, we find that FP-, DO-, and CFR-based approaches fail to outperform generic policy gradient methods. Code is available at https://github.com/nathanlct/IIG-RL-Benchmark and https://github.com/gabrfarina/exp-a-spiel .",
      "authors": [
        "Max Rudolph",
        "Nathan Lichtle",
        "Sobhan Mohammadpour",
        "Alexandre Bayen",
        "J. Zico Kolter",
        "Amy Zhang",
        "Gabriele Farina",
        "Eugene Vinitsky",
        "Samuel Sokota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T03:38:41+00:00",
          "link": "https://arxiv.org/abs/2502.08938v1",
          "size": "21685kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T19:56:04+00:00",
          "link": "https://arxiv.org/abs/2502.08938v2",
          "size": "1478kb",
          "version": "v2"
        }
      ],
      "title": "Reevaluating Policy Gradient Methods for Imperfect-Information Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08938",
        "HTML": "https://arxiv.org/html/2502.08938",
        "PDF": "https://arxiv.org/pdf/2502.08938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work evaluates policy gradient methods in imperfect-information games and focuses on deep reinforcement learning algorithms. It does not involve LLM training data processing or dataset engineering contributions."
      },
      "tasks": [
        "counterfactual",
        "Deep Reinforcement Learning",
        "Policy Gradient Methods"
      ],
      "repo_urls": [
        "https://github.com/gabrfarina/exp-a-spiel",
        "https://github.com/nathanlct/iig-rl-benchmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14507",
      "abstract": "Diffusion models, initially developed for image synthesis, demonstrate remarkable generative capabilities. Recently, their application has expanded to time series forecasting (TSF), yielding promising results. In this survey, we firstly introduce the standard diffusion models and their prevalent variants, explaining their adaptation to TSF tasks. We then provide a comprehensive review of diffusion models for TSF, paying special attention to the sources of conditional information and the mechanisms for integrating this conditioning within the models. In analyzing existing approaches using diffusion models for TSF, we provide a systematic categorization and a comprehensive summary of them in this survey. Furthermore, we examine several foundational diffusion models applied to TSF, alongside commonly used datasets and evaluation metrics. Finally, we discuss current limitations in these approaches and potential future research directions. Overall, this survey details recent progress and future prospects for diffusion models in TSF, serving as a reference for researchers in the field.",
      "authors": [
        "Chen Su",
        "Zhengzhou Cai",
        "Yuanhe Tian",
        "Zihong Zheng",
        "Yan Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:04:04+00:00",
          "link": "https://arxiv.org/abs/2507.14507v1",
          "size": "1587kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion Models for Time Series Forecasting: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14507",
        "HTML": "https://arxiv.org/html/2507.14507",
        "PDF": "https://arxiv.org/pdf/2507.14507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys diffusion models for time series forecasting, which is not relevant to processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15244",
      "abstract": "Empirical research in creative design deepens our theoretical understanding of design principles and perceptual effects, offering valuable guidance for innovating creation tools. However, how these empirical insights currently influence the development of creation tools, and how their integration can be enhanced in the future, remains insufficiently understood. In this paper, we aim to unveil the gap through a case study on data videos, a prominent and wide-spread medium for effective data storytelling. To achieve the goal, we conducted a comprehensive analysis of 46 empirical research papers and 48 creation tool papers on data video, complemented by interviews with 11 experts. Building upon a systematic collection and structured characterization of empirical research by their methodologies (e.g., corpus analysis, comparative evaluations) and component focus (e.g., visuals, motions, narratives, audio), we conducted a context-aware citation analysis and revealed a taxonomy of recurring patterns in how empirical findings inform tool design across citation functions (e.g., problem framing, technical reference). Expert interviews further uncovered researchers' practice patterns in applying empirical findings (e.g., adaptation, synthesis, iteration, etc.) and identified key factors influencing applicability, such as contextual relevance, granularity matching, clarity, credibility, and feasibility. Finally, we derive suggestions and discuss future opportunities to foster closer mutual engagement between empirical and tool research, aiming to reinforce the theoretical grounding of creation tools and enhance the practical impact of empirical research.",
      "authors": [
        "Leixian Shen",
        "Leni Yang",
        "Haotian Li",
        "Yun Wang",
        "Yuyu Luo",
        "Huamin Qu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:02:27+00:00",
          "link": "https://arxiv.org/abs/2507.15244v1",
          "size": "1662kb",
          "version": "v1"
        }
      ],
      "title": "How Does Empirical Research Facilitate Creation Tool Design? A Data Video Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15244",
        "HTML": "https://arxiv.org/html/2507.15244",
        "PDF": "https://arxiv.org/pdf/2507.15244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses how empirical research in design facilitates tool creation for data videos, which is not applicable to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15587",
      "abstract": "Current research on decision-making in safety-critical scenarios often relies on inefficient data-driven scenario generation or specific modeling approaches, which fail to capture corner cases in real-world contexts. To address this issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework, where background vehicles with interference capabilities are treated as red-team agents. Through active interference and exploration, red-team vehicles can uncover corner cases outside the data distribution. The framework uses a Constraint Graph Representation Markov Decision Process, ensuring that red-team vehicles comply with safety rules while continuously disrupting the autonomous vehicles (AVs). A policy threat zone model is constructed to quantify the threat posed by red-team vehicles to AVs, inducing more extreme actions to increase the danger level of the scenario. Experimental results show that the proposed framework significantly impacts AVs decision-making safety and generates various corner cases. This method also offers a novel direction for research in safety-critical scenarios.",
      "authors": [
        "Yinsong Chen",
        "Kaifeng Wang",
        "Xiaoqiang Meng",
        "Xueyuan Li",
        "Zirui Li",
        "Xin Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:08:49+00:00",
          "link": "https://arxiv.org/abs/2507.15587v1",
          "size": "1506kb",
          "version": "v1"
        }
      ],
      "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15587",
        "HTML": "https://arxiv.org/html/2507.15587",
        "PDF": "https://arxiv.org/pdf/2507.15587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a reinforcement learning framework to improve decision-making in autonomous vehicles, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2006.06926",
      "abstract": "Algorithms and hardware for solving quadratic unconstrained binary optimization (QUBO) problems have made significant recent progress. This advancement has focused attention on formulating combinatorial optimization problems as quadratic polynomials. To improve the performance of solving large QUBO problems, it is essential to minimize the number of binary variables used in the objective function. In this paper, we propose a QUBO formulation that offers a bit capacity advantage over conventional quadratization techniques. As a key application, this formulation significantly reduces the number of binary variables required for score-based Bayesian network structure learning. Experimental results on $16$ instances, ranging from $37$ to $223$ variables, demonstrate that our approach requires notably fewer binary variables than quadratization. Moreover, an annealing machine that implement our formulation have outperformed existing algorithms in score maximization.",
      "authors": [
        "Yuta Shikuri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2020-06-12T03:19:48+00:00",
          "link": "https://arxiv.org/abs/2006.06926v1",
          "size": "65kb",
          "version": "v1"
        },
        {
          "date": "2020-06-17T10:03:31+00:00",
          "link": "https://arxiv.org/abs/2006.06926v2",
          "size": "65kb",
          "version": "v2"
        },
        {
          "date": "2022-05-19T16:20:44+00:00",
          "link": "https://arxiv.org/abs/2006.06926v3",
          "size": "60kb",
          "version": "v3"
        },
        {
          "date": "2023-08-08T11:45:08+00:00",
          "link": "https://arxiv.org/abs/2006.06926v4",
          "size": "99kb",
          "version": "v4"
        },
        {
          "date": "2024-12-23T10:06:43+00:00",
          "link": "https://arxiv.org/abs/2006.06926v5",
          "size": "109kb",
          "version": "v5"
        },
        {
          "date": "2025-02-14T02:26:40+00:00",
          "link": "https://arxiv.org/abs/2006.06926v6",
          "size": "123kb",
          "version": "v6"
        },
        {
          "date": "2025-07-19T00:56:59+00:00",
          "link": "https://arxiv.org/abs/2006.06926v7",
          "size": "116kb",
          "version": "v7"
        }
      ],
      "title": "Decomposed Quadratization: Efficient QUBO Formulation for Learning Bayesian Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2006.06926",
        "HTML": "https://arxiv.org/html/2006.06926",
        "PDF": "https://arxiv.org/pdf/2006.06926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a QUBO formulation to improve Bayesian network structure learning in terms of binary variable efficiency, which does not relate to LLM training data processing or involve data engineering operations for language models."
      },
      "conference": "bayesian-network-structure-learning-using-1",
      "conference_url_abs": "https://openreview.net/forum?id=HXjt-kRBzvu",
      "tasks": [
        "Combinatorial Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2205.08293",
      "abstract": "We investigate quantitative implications of the notion of log-concavity through a probabilistic interpretation. In particular, we derive concentration inequalities, moment and entropy bounds for random variables satisfying a precise degree of log-concavity. Along the way, we recover, improve, and simplify several results existing in the literature. Our approach is based on majorization in the convex order.",
      "authors": [
        "Arnaud Marsiglietti and James Melbourne"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-17T12:45:11+00:00",
          "link": "https://arxiv.org/abs/2205.08293v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2022-09-01T21:15:20+00:00",
          "link": "https://arxiv.org/abs/2205.08293v2",
          "size": "17kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T14:58:42+00:00",
          "link": "https://arxiv.org/abs/2205.08293v3",
          "size": "117kb",
          "version": "v3"
        }
      ],
      "title": "Concentration inequalities for log-concave sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.08293",
        "HTML": "https://arxiv.org/html/2205.08293",
        "PDF": "https://arxiv.org/pdf/2205.08293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates mathematical concentration inequalities and log-concave sequences, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.17741",
      "abstract": "Joint punctuated and normalized automatic speech recognition (ASR) aims at outputing transcripts with and without punctuation and casing. This task remains challenging due to the lack of paired speech and punctuated text data in most ASR corpora. We propose two approaches to train an end-to-end joint punctuated and normalized ASR system using limited punctuated data. The first approach uses a language model to convert normalized training transcripts into punctuated transcripts. This achieves a better performance on out-of-domain test data, with up to 17% relative Punctuation-Case-aware Word Error Rate (PC-WER) reduction. The second approach uses a single decoder conditioned on the type of output. This yields a 42% relative PC-WER reduction compared to Whisper-base and a 4% relative (normalized) WER reduction compared to the normalized output of a punctuated-only model. Additionally, our proposed model demonstrates the feasibility of a joint ASR system using as little as 5% punctuated training data with a moderate (2.42% absolute) PC-WER increase.",
      "authors": [
        "Can Cui",
        "Imran Ahamad Sheikh",
        "Mostafa Sadeghi (MULTISPEECH)",
        "Emmanuel Vincent (MULTISPEECH)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-29T15:44:39+00:00",
          "link": "https://arxiv.org/abs/2311.17741v1",
          "size": "467kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T08:27:00+00:00",
          "link": "https://arxiv.org/abs/2311.17741v2",
          "size": "659kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T09:15:54+00:00",
          "link": "https://arxiv.org/abs/2311.17741v3",
          "size": "1237kb",
          "version": "v3"
        }
      ],
      "title": "End-to-end Joint Punctuated and Normalized ASR with a Limited Amount of Punctuated Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.17741",
        "PDF": "https://arxiv.org/pdf/2311.17741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses techniques for enhancing automatic speech recognition (ASR) systems using limited punctuated training data. It focuses on ASR model performance improvement rather than LLM training data processing."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Automatic Speech Recognition (ASR)",
        "Decoder",
        "Language Modeling",
        "Language Modelling",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14307",
      "abstract": "Large language models (LLMs) exhibit increasingly sophisticated linguistic capabilities, yet the extent to which these behaviors reflect human-like cognition versus advanced pattern recognition remains an open question. In this study, we investigate how LLMs process the temporal meaning of linguistic aspect in narratives that were previously used in human studies. Using an Expert-in-the-Loop probing pipeline, we conduct a series of targeted experiments to assess whether LLMs construct semantic representations and pragmatic inferences in a human-like manner. Our findings show that LLMs over-rely on prototypicality, produce inconsistent aspectual judgments, and struggle with causal reasoning derived from aspect, raising concerns about their ability to fully comprehend narratives. These results suggest that LLMs process aspect fundamentally differently from humans and lack robust narrative understanding. Beyond these empirical findings, we develop a standardized experimental framework for the reliable assessment of LLMs' cognitive and linguistic capabilities.",
      "authors": [
        "Karin de Langis",
        "Jong Inn Park",
        "Andreas Schramm",
        "Bin Hu",
        "Khanh Chi Le",
        "Michael Mensink",
        "Ahn Thu Tong",
        "Dongyeop Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:28:35+00:00",
          "link": "https://arxiv.org/abs/2507.14307v1",
          "size": "1728kb",
          "version": "v1"
        }
      ],
      "title": "How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14307",
        "HTML": "https://arxiv.org/html/2507.14307",
        "PDF": "https://arxiv.org/pdf/2507.14307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes how LLMs understand temporal meaning in narratives, focusing on cognitive evaluation rather than any data processing aspect for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15157",
      "abstract": "Requirements elicitation is still one of the most challenging activities of the requirements engineering process due to the difficulty requirements analysts face in understanding and translating complex needs into concrete requirements. In addition, specifying high-quality requirements is crucial, as it can directly impact the quality of the software to be developed. Although automated tools allow for assessing the syntactic quality of requirements, evaluating semantic metrics (e.g., language clarity, internal consistency) remains a manual and time-consuming activity. This paper explores how LLMs can help automate requirements elicitation within agile frameworks, where requirements are defined as user stories (US). We used 10 state-of-the-art LLMs to investigate their ability to generate US automatically by emulating customer interviews. We evaluated the quality of US generated by LLMs, comparing it with the quality of US generated by humans (domain experts and students). We also explored whether and how LLMs can be used to automatically evaluate the semantic quality of US. Our results indicate that LLMs can generate US similar to humans in terms of coverage and stylistic quality, but exhibit lower diversity and creativity. Although LLM-generated US are generally comparable in quality to those created by humans, they tend to meet the acceptance quality criteria less frequently, regardless of the scale of the LLM model. Finally, LLMs can reliably assess the semantic quality of US when provided with clear evaluation criteria and have the potential to reduce human effort in large-scale assessments.",
      "authors": [
        "Giovanni Quattrocchi",
        "Liliana Pasquale",
        "Paola Spoletini",
        "Luciano Baresi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:37:43+00:00",
          "link": "https://arxiv.org/abs/2507.15157v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Generate User Stories and Assess Their Quality?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15157",
        "HTML": "https://arxiv.org/html/2507.15157",
        "PDF": "https://arxiv.org/pdf/2507.15157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores LLMs for generating user stories and assessing their quality, which involves some aspects of data quality evaluation, but the primary focus is not on LLM training data processing or dataset creation for LLM fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15269",
      "abstract": "Perceptual studies demonstrate that conditional diffusion models excel at reconstructing video content aligned with human visual perception. Building on this insight, we propose a video compression framework that leverages conditional diffusion models for perceptually optimized reconstruction. Specifically, we reframe video compression as a conditional generation task, where a generative model synthesizes video from sparse, yet informative signals. Our approach introduces three key modules: (1) Multi-granular conditioning that captures both static scene structure and dynamic spatio-temporal cues; (2) Compact representations designed for efficient transmission without sacrificing semantic richness; (3) Multi-condition training with modality dropout and role-aware embeddings, which prevent over-reliance on any single modality and enhance robustness. Extensive experiments show that our method significantly outperforms both traditional and neural codecs on perceptual quality metrics such as Fr\\'echet Video Distance (FVD) and LPIPS, especially under high compression ratios.",
      "authors": [
        "Fangqiu Yi",
        "Jingyu Xu",
        "Jiawei Shao",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:16:27+00:00",
          "link": "https://arxiv.org/abs/2507.15269v1",
          "size": "45903kb",
          "version": "v1"
        }
      ],
      "title": "Conditional Video Generation for High-Efficiency Video Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15269",
        "HTML": "https://arxiv.org/html/2507.15269",
        "PDF": "https://arxiv.org/pdf/2507.15269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on video compression using conditional diffusion models and does not make any contributions to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.16990",
      "abstract": "Adding proper background music helps complete a short video to be shared. Previous work tackles the task by video-to-music retrieval (V2MR), aiming to find the most suitable music track from a collection to match the content of a given query video. In practice, however, music tracks are typically much longer than the query video, necessitating (manual) trimming of the retrieved music to a shorter segment that matches the video duration. In order to bridge the gap between the practical need for music moment localization and V2MR, we propose a new task termed Music Grounding by Short Video (MGSV). To tackle the new task, we introduce a new benchmark, MGSV-EC, which comprises a diverse set of 53k short videos associated with 35k different music moments from 4k unique music tracks. Furthermore, we develop a new baseline method, MaDe, which performs both video-to-music matching and music moment detection within a unified end-to-end deep network. Extensive experiments on MGSV-EC not only highlight the challenging nature of MGSV but also set MaDe as a strong baseline.",
      "authors": [
        "Zijie Xin",
        "Minquan Wang",
        "Jingyu Liu",
        "Ye Ma",
        "Quan Chen",
        "Peng Jiang",
        "Xirong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T03:36:22+00:00",
          "link": "https://arxiv.org/abs/2408.16990v1",
          "size": "33342kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T08:06:15+00:00",
          "link": "https://arxiv.org/abs/2408.16990v2",
          "size": "16777kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T04:31:17+00:00",
          "link": "https://arxiv.org/abs/2408.16990v3",
          "size": "25550kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T03:31:36+00:00",
          "link": "https://arxiv.org/abs/2408.16990v4",
          "size": "25550kb",
          "version": "v4"
        }
      ],
      "title": "Music Grounding by Short Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16990",
        "HTML": "https://arxiv.org/html/2408.16990",
        "PDF": "https://arxiv.org/pdf/2408.16990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new task for aligning music with video content and does not address issues related to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "xxayt/MGSV-EC",
          "downloads": "29",
          "likes": "2",
          "link": "https://huggingface.co/datasets/xxayt/MGSV-EC"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.15614",
      "abstract": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but are too computationally intensive for on-the-fly decision-making during flood events. The central challenge is to accelerate these simulations without sacrificing accuracy. This paper introduces a deep learning surrogate that treats HEC-RAS not as a solver but as a data-generation engine. We propose a hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU) to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural Operator (Geo-FNO) to model long-range spatial dependencies along a river reach. The model learns underlying physics implicitly from a minimal eight-channel feature vector encoding dynamic state, static geometry, and boundary forcings extracted directly from native HEC-RAS files. Trained on 67 reaches of the Mississippi River Basin, the surrogate was evaluated on a year-long, unseen hold-out simulation. Results show the model achieves a strong predictive accuracy, with a median absolute stage error of 0.31 feet. Critically, for a full 67-reach ensemble forecast, our surrogate reduces the required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly 3.5 times over the traditional solver. The success of this data-driven approach demonstrates that robust feature engineering can produce a viable, high-speed replacement for conventional hydraulic models, improving the computational feasibility of large-scale ensemble flood forecasting.",
      "authors": [
        "Edward Holmberg",
        "Pujan Pokhrel",
        "Maximilian Zoch",
        "Elias Ioup",
        "Ken Pathak",
        "Steven Sloan",
        "Kendall Niles",
        "Jay Ratcliff",
        "Maik Flanagin",
        "Christian Guetl",
        "Julian Simeonov",
        "and Mahdi Abdelguerfi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:38:54+00:00",
          "link": "https://arxiv.org/abs/2507.15614v1",
          "size": "2735kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15614",
        "HTML": "https://arxiv.org/html/2507.15614",
        "PDF": "https://arxiv.org/pdf/2507.15614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on accelerating river forecasting using a deep learning surrogate model, which treats HEC-RAS as a data-generation engine. It does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15655",
      "abstract": "The proliferation of MultiLingual Visual Question Answering (MLVQA) benchmarks augments the capabilities of large language models (LLMs) and multi-modal LLMs, thereby enabling them to adeptly capture the intricate linguistic subtleties and visual complexities inherent across diverse languages. Despite its potential, the current MLVQA model struggles to fully utilize its capabilities when dealing with the extensive variety of handwritten documents. This article delineates HW-MLVQA, an avant-garde VQA benchmark meticulously crafted to mitigate the dearth of authentic Multilingual Handwritten document comprehension. HW-MLVQA encompasses an extensive collection of 1,600 handwritten Pages complemented by 2,400 question-answers. Furthermore, it provides a robust benchmark evaluation framework spanning three distinct modalities: text, image, and an integrated image & text modality. To simulate authentic real-world contexts devoid of ground truth textual transcriptions, we facilitates a rigorous assessment of proprietary and open-source OCR models. The benchmark aspires to facilitate pivotal advancements in multilingual handwritten document interpretation, fostering innovation and scholarly inquiry within this specialized domain.",
      "authors": [
        "Aniket Pal",
        "Ajoy Mondal",
        "Minesh Mathew",
        "C.V. Jawahar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:16:44+00:00",
          "link": "https://arxiv.org/abs/2507.15655v1",
          "size": "14053kb",
          "version": "v1"
        }
      ],
      "title": "HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15655",
        "HTML": "https://arxiv.org/html/2507.15655",
        "PDF": "https://arxiv.org/pdf/2507.15655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces HW-MLVQA, a comprehensive benchmark for multilingual handwritten document understanding, involving data collection and creating a dataset with questions and answers. This represents a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.11017",
      "abstract": "Malicious attacks on open-source software packages are a growing concern. The discovery of the XZ Utils backdoor intensified these concerns because of the potential widespread impact. This study, therefore, explores the challenges of preventing and detecting malware in Linux distribution package repositories. To do so, we ask two research questions: (1) What measures have Linux distributions implemented to counter malware, and how have maintainers experienced these efforts? (2) How effective are current malware detection tools in identifying malicious Linux packages? To answer these questions, we conduct interviews with maintainers at several major Linux distributions and introduce a Linux package malware benchmark dataset. Using this dataset, we evaluate the performance of six open-source malware detection scanners. Distribution maintainers, according to the interviews, have mostly focused on reproducible builds to date. Our interviews identified only a single Linux distribution, Wolfi OS, that performs active malware scanning. Using this new benchmark dataset, the evaluation found that the performance of existing open-source malware scanners is underwhelming. Most studied tools excel at producing false positives but only infrequently detect true malware. Those that avoid high false positive rates often do so at the expense of a satisfactory true positive. Our findings provide insights into Linux distribution package repositories' current practices for malware detection and demonstrate the current inadequacy of open-source tools designed to detect malicious Linux packages.",
      "authors": [
        "Duc-Ly Vu",
        "Trevor Dunlap",
        "Karla Obermeier-Velazquez",
        "Thanh-Cong Nguyen",
        "Paul Gibert",
        "John Speed Meyers",
        "Santiago Torres-Arias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-17T09:42:08+00:00",
          "link": "https://arxiv.org/abs/2411.11017v1",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T13:30:31+00:00",
          "link": "https://arxiv.org/abs/2411.11017v2",
          "size": "267kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T07:23:59+00:00",
          "link": "https://arxiv.org/abs/2411.11017v3",
          "size": "123kb",
          "version": "v3"
        }
      ],
      "title": "A Study of Malware Prevention in Linux Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11017",
        "HTML": "https://arxiv.org/html/2411.11017",
        "PDF": "https://arxiv.org/pdf/2411.11017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates malware prevention in Linux distributions, focusing on detecting malicious software rather than any data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.14939",
      "abstract": "Neural surface representation has demonstrated remarkable success in the areas of novel view synthesis and 3D reconstruction. However, assessing the geometric quality of 3D reconstructions in the absence of ground truth mesh remains a significant challenge, due to its rendering-based optimization process and entangled learning of appearance and geometry with photometric losses. In this paper, we present a novel framework, i.e, GURecon, which establishes a geometric uncertainty field for the neural surface based on geometric consistency. Different from existing methods that rely on rendering-based measurement, GURecon models a continuous 3D uncertainty field for the reconstructed surface, and is learned by an online distillation approach without introducing real geometric information for supervision. Moreover, in order to mitigate the interference of illumination on geometric consistency, a decoupled field is learned and exploited to finetune the uncertainty field. Experiments on various datasets demonstrate the superiority of GURecon in modeling 3D geometric uncertainty, as well as its plug-and-play extension to various neural surface representations and improvement on downstream tasks such as incremental reconstruction. The code and supplementary material are available on the project website: https://zju3dv.github.io/GURecon/.",
      "authors": [
        "Zesong Yang",
        "Ru Zhang",
        "Jiale Shi",
        "Zixiang Ai",
        "Boming Zhao",
        "Hujun Bao",
        "Luwei Yang",
        "Zhaopeng Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T15:15:03+00:00",
          "link": "https://arxiv.org/abs/2412.14939v1",
          "size": "17991kb",
          "version": "v1"
        },
        {
          "date": "2024-12-20T10:02:01+00:00",
          "link": "https://arxiv.org/abs/2412.14939v2",
          "size": "17991kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T12:24:32+00:00",
          "link": "https://arxiv.org/abs/2412.14939v3",
          "size": "17693kb",
          "version": "v3"
        }
      ],
      "title": "GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14939",
        "HTML": "https://arxiv.org/html/2412.14939",
        "PDF": "https://arxiv.org/pdf/2412.14939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D geometric uncertainties in neural surface reconstruction and does not address aspects related to LLM training data processing."
      },
      "tasks": [
        "3D Reconstruction",
        "Novel View Synthesis",
        "Surface Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07942",
      "abstract": "Few Shot Segmentation aims to segment novel object classes given only a handful of labeled examples, enabling rapid adaptation with minimal supervision. Current literature crucially lacks a selection method that goes beyond visual similarity between the query and example images, leading to suboptimal predictions. We present MARS, a plug-and-play ranking system that leverages multimodal cues to filter and merge mask proposals robustly. Starting from a set of mask predictions for a single query image, we score, filter, and merge them to improve results. Proposals are evaluated using multimodal scores computed at local and global levels. Extensive experiments on COCO-20i, Pascal-5i, LVIS-92i, and FSS-1000 demonstrate that integrating all four scoring components is crucial for robust ranking, validating our contribution. As MARS can be effortlessly integrated with various mask proposal systems, we deploy it across a wide range of top-performer methods and achieve new state-of-the-art results on multiple existing benchmarks. Code will be available upon acceptance.",
      "authors": [
        "Nico Catalano",
        "Stefano Samele",
        "Paolo Pertino",
        "Matteo Matteucci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T17:53:23+00:00",
          "link": "https://arxiv.org/abs/2504.07942v1",
          "size": "20442kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:23:21+00:00",
          "link": "https://arxiv.org/abs/2504.07942v2",
          "size": "30392kb",
          "version": "v2"
        }
      ],
      "title": "MARS: a Multimodal Alignment and Ranking System for Few-Shot Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07942",
        "HTML": "https://arxiv.org/html/2504.07942",
        "PDF": "https://arxiv.org/pdf/2504.07942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a system for few-shot segmentation using multimodal cues, which does not involve LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09051",
      "abstract": "Mental health (MH) apps often require sensitive user data to customize services for mental wellness needs. However, such data collection practices in some MH apps raise significant privacy concerns for users. These concerns are often mentioned in app reviews, but other feedback categories, such as reliability and usability, tend to take precedence. This poses a significant challenge in automatically identifying privacy requirements-relevant reviews (privacy reviews) that can be utilized to extract privacy requirements and address users' privacy concerns. Thus, this study introduces SAGE, a context-aware approach to automatically mining privacy reviews from MH apps using Natural Language Inference (NLI) with MH domain-specific privacy hypotheses (provides domain-specific context awareness) and a GPT model (eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a dataset of 204K app reviews achieved an F1 score of 0.85 without any fine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5. Furthermore, SAGE extracted 748 privacy reviews previously overlooked by keyword-based methods, demonstrating its effectiveness through qualitative evaluation. These reviews can later be refined into actionable privacy requirement artifacts.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:53:56+00:00",
          "link": "https://arxiv.org/abs/2507.09051v1",
          "size": "267kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:37:04+00:00",
          "link": "https://arxiv.org/abs/2507.09051v2",
          "size": "267kb",
          "version": "v2"
        }
      ],
      "title": "SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09051",
        "HTML": "https://arxiv.org/html/2507.09051",
        "PDF": "https://arxiv.org/pdf/2507.09051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on mining privacy-related reviews from mental health apps using SAGE, a context-aware approach. It does not contribute to LLM training data processing or the creation of datasets specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09768",
      "abstract": "In recent years, deep learning-based single-channel speech separation has improved considerably, in large part driven by increasingly compute- and parameter-efficient neural network architectures. Most such architectures are, however, designed with a fixed compute and parameter budget, and consequently cannot scale to varying compute demands or resources, which limits their use in embedded and heterogeneous devices such as mobile phones and hearables. To enable such use-cases we design a neural network architecture for speech separation capable of early-exit, and we propose an uncertainty-aware probabilistic framework to jointly model the clean speech signal and error variance which we use to derive probabilistic early-exit conditions in terms of desired signal-to-noise ratios. We evaluate our methods on both speech separation and enhancement tasks, and we show that a single early-exit model can be competitive with state-of-the-art models trained at many compute and parameter budgets. Our framework enables fine-grained dynamic compute-scaling of speech separation networks while achieving state-of-the-art performance and interpretable exit conditions.",
      "authors": [
        "Kenny Falk{\\ae}r Olsen",
        "Mads {\\O}stergaard",
        "Karl Ulb{\\ae}k",
        "S{\\o}ren F{\\o}ns Nielsen",
        "Rasmus Malik H{\\o}egh Lindrup",
        "Bj{\\o}rn Sand Jensen",
        "Morten M{\\o}rup"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:52:34+00:00",
          "link": "https://arxiv.org/abs/2507.09768v1",
          "size": "1882kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:30:26+00:00",
          "link": "https://arxiv.org/abs/2507.09768v2",
          "size": "1882kb",
          "version": "v2"
        }
      ],
      "title": "Knowing When to Quit: Probabilistic Early Exits for Speech Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09768",
        "HTML": "https://arxiv.org/html/2507.09768",
        "PDF": "https://arxiv.org/pdf/2507.09768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concerns designing a neural network for speech separation with probabilistic early exits, not related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14730",
      "abstract": "Generative AI, large language models, and agentic AI have emerged separately of urban planning. However, the convergence between AI and urban planning presents an interesting opportunity towards AI urban planners. This paper conceptualizes urban planning as a generative AI task, where AI synthesizes land-use configurations under geospatial, social, and human-centric constraints. We survey how generative AI approaches, including VAEs, GANs, transformers, and diffusion models, reshape urban design. We further identify critical gaps: 1) limited research on integrating urban theory guidance, 2) limited research of AI urban planning over multiple spatial resolutions or angularities, 3) limited research on augmenting urban design knowledge from data, and 4) limited research on addressing real-world interactions. To address these limitations, we outline future research directions in theory-guided generation, digital twins, and human-machine co-design, calling for a new synthesis of generative intelligence and participatory urbanism.",
      "authors": [
        "Yanjie Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:40:42+00:00",
          "link": "https://arxiv.org/abs/2507.14730v1",
          "size": "78kb",
          "version": "v1"
        }
      ],
      "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14730",
        "HTML": "https://arxiv.org/html/2507.14730",
        "PDF": "https://arxiv.org/pdf/2507.14730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about using generative AI and LLMs in urban planning, not focusing on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15140",
      "abstract": "The diagnosis of oral diseases presents a problematic clinical challenge, characterized by a wide spectrum of pathologies with overlapping symptomatology. To address this, we developed Clinical Semantic Intelligence (CSI), a novel artificial intelligence framework that diagnoses 118 different oral diseases by computationally modeling the cognitive processes of an expert clinician. Our core hypothesis is that moving beyond simple pattern matching to emulate expert reasoning is critical to building clinically useful diagnostic aids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a specialized ChatGLM-6B language model. This system executes a Hierarchical Diagnostic Reasoning Tree (HDRT), a structured framework that distills the systematic, multi-step logic of differential diagnosis. The framework operates in two modes: a Fast Mode for rapid screening and a Standard Mode that leverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310 images, supplemented by an external hold-out set of 176 images for final validation. A clinically-informed augmentation strategy expanded our training data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the HDRT-driven Standard Mode. The performance gain is directly attributable to the hierarchical reasoning process. Herein, we detail the architectural philosophy, development, and rigorous evaluation of the CSI framework.",
      "authors": [
        "Mohammad Mashayekhi",
        "Sara Ahmadi Majd",
        "Arian AmirAmjadi",
        "Parsa Hosseini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:30:01+00:00",
          "link": "https://arxiv.org/abs/2507.15140v1",
          "size": "3684kb",
          "version": "v1"
        }
      ],
      "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15140",
        "HTML": "https://arxiv.org/html/2507.15140",
        "PDF": "https://arxiv.org/pdf/2507.15140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves curating and augmenting a dataset for the purpose of training a model for oral disease diagnosis, the primary focus is on model architecture and hierarchical reasoning processes rather than on broad LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.05030",
      "abstract": "Despite extensive diagnostics and debugging by developers, AI systems sometimes exhibit harmful unintended behaviors. Finding and fixing these is challenging because the attack surface is so large -- it is not tractable to exhaustively search for inputs that may elicit harmful behaviors. Red-teaming and adversarial training (AT) are commonly used to improve robustness, however, they empirically struggle to fix failure modes that differ from the attacks used during training. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without leveraging knowledge of what they are or using inputs that elicit them. LAT makes use of the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. Here, we use it to defend against failure modes without examples that elicit them. Specifically, we use LAT to remove backdoors and defend against held-out classes of adversarial attacks. We show in image classification, text classification, and text generation tasks that LAT usually improves both robustness to novel attacks and performance on clean data relative to AT. This suggests that LAT can be a promising tool for defending against failure modes that are not explicitly identified by developers.",
      "authors": [
        "Stephen Casper",
        "Lennart Schulze",
        "Oam Patel",
        "Dylan Hadfield-Menell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-08T04:22:48+00:00",
          "link": "https://arxiv.org/abs/2403.05030v1",
          "size": "1141kb",
          "version": "v1"
        },
        {
          "date": "2024-03-22T19:49:42+00:00",
          "link": "https://arxiv.org/abs/2403.05030v2",
          "size": "1141kb",
          "version": "v2"
        },
        {
          "date": "2024-04-01T21:32:18+00:00",
          "link": "https://arxiv.org/abs/2403.05030v3",
          "size": "1139kb",
          "version": "v3"
        },
        {
          "date": "2024-08-22T00:24:50+00:00",
          "link": "https://arxiv.org/abs/2403.05030v4",
          "size": "1162kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T19:13:18+00:00",
          "link": "https://arxiv.org/abs/2403.05030v5",
          "size": "743kb",
          "version": "v5"
        }
      ],
      "title": "Defending Against Unforeseen Failure Modes with Latent Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.05030",
        "HTML": "https://arxiv.org/html/2403.05030",
        "PDF": "https://arxiv.org/pdf/2403.05030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents latent adversarial training to defend against AI failure modes, focusing on robustness and defense strategies, which does not include training data processing for LLMs."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Red Teaming",
        "text-classification",
        "Text Classification",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/aengusl/latent-adversarial-training",
        "https://github.com/thestephencasper/latent_adversarial_training"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14231",
      "abstract": "Bipolar disorder is a chronic mental illness frequently underdiagnosed due to subtle early symptoms and social stigma. This paper explores the advanced natural language processing (NLP) models for recognizing signs of bipolar disorder based on user-generated social media text. We conduct a comprehensive evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized (BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed on a large, annotated dataset of Reddit posts after confirming their validity through sentiment variance and judgmental analysis. Our results demonstrate that RoBERTa achieves the highest performance among transformer models with an F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical results. In contrast, LSTMs trained on static embeddings fail to capture meaningful patterns, scoring near-zero F1. These findings underscore the critical role of contextual language modeling in detecting bipolar disorder. In addition, we report model training times and highlight that DistilBERT offers an optimal balance between efficiency and accuracy. In general, our study offers actionable insights for model selection in mental health NLP applications and validates the potential of contextualized language models to support early bipolar disorder screening.",
      "authors": [
        "Khalid Hasan and Jamil Saquer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:14:19+00:00",
          "link": "https://arxiv.org/abs/2507.14231v1",
          "size": "204kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14231",
        "HTML": "https://arxiv.org/html/2507.14231",
        "PDF": "https://arxiv.org/pdf/2507.14231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates contextual embeddings for detecting bipolar disorder on social media but does not involve training data processing operations for LLMs such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14298",
      "abstract": "Recent methods for customizing Large Vision Language Models (LVLMs) for domain-specific tasks have shown promising results in scientific chart comprehension. However, existing approaches face two major limitations: First, they rely on paired data from only a few chart types, limiting generalization to wide range of chart types. Secondly, they lack targeted pre-training for chart-data alignment, which hampers the model's understanding of underlying data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth chart comprehension across diverse chart types. We propose an efficient data generation pipeline that synthesizes paired data for a wide range of chart types, along with a novel Dual-Path training strategy that enabling the model to succinctly capture essential data details while preserving robust reasoning capabilities by incorporating reasoning over the underlying data. Lastly, we establish ChartDQA, a new benchmark for evaluating not only question-answering at different levels but also underlying data understanding. Experimental results demonstrate that ChartScope significantly enhances comprehension on a wide range of chart types. The code and data are available at https://davidhalladay.github.io/chartscope_demo.",
      "authors": [
        "Wan-Cyuan Fan",
        "Yen-Chun Chen",
        "Mengchen Liu",
        "Alexander Jacobson",
        "Lu Yuan",
        "Leonid Sigal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:15:09+00:00",
          "link": "https://arxiv.org/abs/2507.14298v1",
          "size": "3079kb",
          "version": "v1"
        }
      ],
      "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14298",
        "HTML": "https://arxiv.org/html/2507.14298",
        "PDF": "https://arxiv.org/pdf/2507.14298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a data generation pipeline for creating datasets tailored to multimodal chart comprehension, involving data processing operations like synthesis of paired data, making it a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14423",
      "abstract": "Tokenization is a fundamental component of language models for code. It involves breaking down the input into units that are later passed to the language model stack to learn high-dimensional representations used in various contexts, from classification to generation. However, the output of these tokenizers is often longer than that traditionally used in compilers and interpreters. This could result in undesirable effects, such as increased computational overhead. In this work, we investigate the effect of merging the hidden representations of subtokens that belong to the same semantic unit, such as subtokens that form a single identifier. We propose two strategies: one based on averaging the representations and another that leverages a learning-based approach. Both methods can be seamlessly integrated with existing language models for code. We conduct experiments using six language models for code: CodeBERT, GraphCodeBERT, UniXCoder, CdoeT5, CodeT5+ (220M), and CodeT5+ (770M), across three software engineering tasks: vulnerability detection, code classification, and code translation. Results show that these strategies can reduce the number of floating-point operations by $1\\%$ to $19\\%$. Regarding downstream performance, the most significant degradation was observed in the vulnerability detection task, where the F1 score decreased by $1.82$ points compared to the baseline. In contrast, for code translation, we observed an improvement of $2.47$ points in CodeBLEU. This work contributes to the broader effort of improving language models for code across multiple dimensions, including both computational efficiency and downstream performance.",
      "authors": [
        "Mootez Saad and Hao Li and Tushar Sharma and Ahmed E. Hassan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T00:48:20+00:00",
          "link": "https://arxiv.org/abs/2507.14423v1",
          "size": "382kb",
          "version": "v1"
        }
      ],
      "title": "On the Effect of Token Merging on Pre-trained Models for Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14423",
        "HTML": "https://arxiv.org/html/2507.14423",
        "PDF": "https://arxiv.org/pdf/2507.14423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the effect of token merging in language models for code, emphasizing computational efficiency and downstream performance. It does not contribute to LLM training data processing aspects such as data filtration or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14538",
      "abstract": "CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid tendon-driven actuation system that combines shape memory alloys (SMAs) and DC motors. The hand employs high-strength fishing line as artificial tendons and uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal and tendon-muscle structure of the human hand. A linear motor-driven module controls finger flexion, while an SMA-based module enables finger extension and lateral abduction. These modules are integrated into a compact hybrid actuation unit mounted on a custom rear support structure. Mechanical and kinematic experiments, conducted under an Arduino Mega 2560-based control system, validate the effectiveness of the design and demonstrate its biomimetic dexterity.",
      "authors": [
        "Jin Chai",
        "Xiang Yao",
        "Mengfan Hou",
        "Yanghong Li and Erbao Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:51:59+00:00",
          "link": "https://arxiv.org/abs/2507.14538v1",
          "size": "4460kb",
          "version": "v1"
        }
      ],
      "title": "A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14538",
        "PDF": "https://arxiv.org/pdf/2507.14538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a humanoid dexterous hand with a hybrid actuation system. It does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14747",
      "abstract": "Inspired by the prevalence of recurrent circuits in biological brains, we investigate the degree to which directionality is a helpful inductive bias for artificial neural networks. Taking directionality as topologically-ordered information flow between neurons, we formalise a perceptron layer with all-to-all connections (mathematically equivalent to a weight-tied recurrent neural network) and demonstrate that directionality, a hallmark of modern feed-forward networks, can be induced rather than hard-wired by applying appropriate pruning techniques. Across different random seeds our pruning schemes successfully induce greater topological ordering in information flow between neurons without compromising performance, suggesting that directionality is not a prerequisite for learning, but may be an advantageous inductive bias discoverable by gradient descent and sparsification.",
      "authors": [
        "Yiding Song"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:44:17+00:00",
          "link": "https://arxiv.org/abs/2507.14747v1",
          "size": "245kb",
          "version": "v1"
        }
      ],
      "title": "Pruning Increases Orderedness in Recurrent Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14747",
        "HTML": "https://arxiv.org/html/2507.14747",
        "PDF": "https://arxiv.org/pdf/2507.14747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates pruning techniques in neural networks to increase orderedness but does not cover LLM training data processing or relevant data operations like collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14839",
      "abstract": "With rapid advancements in quantum computing, it is widely believed that there will be quantum hardware capable of compromising classical cryptography and hence, the internet and the current information security infrastructure in the coming decade. This is mainly due to the operational realizations of quantum algorithms such as Grover and Shor, to which the current classical encryption protocols are vulnerable. Blockchains, i.e., blockchain data structures and their data, rely heavily on classical cryptography. One approach to secure blockchain is to attempt to achieve information theoretical security by defining blockchain on quantum technologies. There have been two conceptualizations of blockchains on quantum registers: the time-entangled Greenberger-Horne-Zeilinger (GHZ) state blockchain and the quantum hypergraph blockchain. On our part, an attempt is made to conceptualize a new quantum blockchain combining features of both these schemes to achieve the absolute security of the time-temporal GHZ blockchain and the scalability and efficiency of the quantum hypergraph blockchain in the proposed quantum blockchain protocol.",
      "authors": [
        "Ruwanga Konara",
        "Kasun De Zoysa",
        "Anuradha Mahasinghe",
        "Asanka Sayakkara",
        "Nalin Ranasinghe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T06:50:41+00:00",
          "link": "https://arxiv.org/abs/2507.14839v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Time Entangled Quantum Blockchain with Phase Encoding for Classical Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14839",
        "HTML": "https://arxiv.org/html/2507.14839",
        "PDF": "https://arxiv.org/pdf/2507.14839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum blockchain technologies for enhancing information-theoretical security, not on aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14959",
      "abstract": "Real-time multi-label video classification on embedded devices is constrained by limited compute and energy budgets. Yet, video streams exhibit structural properties such as label sparsity, temporal continuity, and label co-occurrence that can be leveraged for more efficient inference. We introduce Polymorph, a context-aware framework that activates a minimal set of lightweight Low Rank Adapters (LoRA) per frame. Each adapter specializes in a subset of classes derived from co-occurrence patterns and is implemented as a LoRA weight over a shared backbone. At runtime, Polymorph dynamically selects and composes only the adapters needed to cover the active labels, avoiding full-model switching and weight merging. This modular strategy improves scalability while reducing latency and energy overhead. Polymorph achieves 40% lower energy consumption and improves mAP by 9 points over strong baselines on the TAO dataset. Polymorph is open source at https://github.com/inference-serving/polymorph/.",
      "authors": [
        "Saeid Ghafouri",
        "Mohsen Fayyaz",
        "Xiangchen Li",
        "Deepu John",
        "Bo Ji",
        "Dimitrios Nikolopoulos",
        "Hans Vandierendonck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:39:50+00:00",
          "link": "https://arxiv.org/abs/2507.14959v1",
          "size": "1289kb",
          "version": "v1"
        }
      ],
      "title": "Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14959",
        "HTML": "https://arxiv.org/html/2507.14959",
        "PDF": "https://arxiv.org/pdf/2507.14959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on energy-efficient multi-label video classification on embedded devices using the Polymorph framework. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14987",
      "abstract": "Large language models (LLMs), despite possessing latent safety understanding from their vast pretraining data, remain vulnerable to generating harmful content and exhibit issues such as over-refusal and utility degradation after safety alignment. Current safety alignment methods often result in superficial refusal shortcuts or rely on intensive supervision for reasoning-based approaches, failing to fully leverage the model's intrinsic safety self-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure reinforcement learning (RL) framework with verifiable safety reward designed to incentivize this latent safety awareness through proactive safety reasoning.} AlphaAlign employs a dual-reward system: a verifiable safety reward encourages correctly formatted and explicitly justified refusals for harmful queries while penalizing over-refusals, and a normalized helpfulness reward guides high-quality responses to benign inputs. This allows the model to develop proactive safety reasoning capabilities without depending on supervised safety-specific reasoning data. AlphaAlign demonstrates three key advantages: (1) Simplicity and efficiency, requiring only binary prompt safety labels and minimal RL steps for substantial improvements. (2) Breaking the safety-utility trade-off, by enhancing refusal of harmful content and reducing over-refusals, while simultaneously maintaining or even improving general task performance and robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety reasoning that generates explicit safety rationales rather than relying on shallow refusal patterns.",
      "authors": [
        "Yi Zhang",
        "An Zhang",
        "XiuYu Zhang",
        "Leheng Sheng",
        "Yuxin Chen",
        "Zhenkai Liang",
        "Xiang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:47:03+00:00",
          "link": "https://arxiv.org/abs/2507.14987v1",
          "size": "3467kb",
          "version": "v1"
        }
      ],
      "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14987",
        "PDF": "https://arxiv.org/pdf/2507.14987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper on AlphaAlign focuses on reinforcing safety alignment in LLMs through reinforcement learning, mentioning pretraining only in the context of safety reasoning. It does not contribute directly to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15245",
      "abstract": "Recent advances in large language models (LLMs) have opened new opportunities for academic literature retrieval. However, existing systems often rely on rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR, a multi-agent framework that incorporates RefChain-based query decomposition and query evolution to enable more flexible and effective search. To facilitate systematic evaluation, we also construct SPARBench, a challenging benchmark with expert-annotated relevance labels. Experimental results demonstrate that SPAR substantially outperforms strong baselines, achieving up to +56% F1 on AutoScholar and +23% F1 on SPARBench over the best-performing baseline. Together, SPAR and SPARBench provide a scalable, interpretable, and high-performing foundation for advancing research in scholarly retrieval. Code and data will be available at: https://github.com/xiaofengShi/SPAR",
      "authors": [
        "Xiaofeng Shi",
        "Yuduo Li",
        "Qian Kou",
        "Longbin Yu",
        "Jinxin Xie",
        "Hua Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:06:53+00:00",
          "link": "https://arxiv.org/abs/2507.15245v1",
          "size": "344kb",
          "version": "v1"
        }
      ],
      "title": "SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15245",
        "PDF": "https://arxiv.org/pdf/2507.15245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SPAR focuses on improving academic search using LLM-based agents, with no mention of contributions to data processing or dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15307",
      "abstract": "Electric Vehicles (EVs) are becoming increasingly prevalent nowadays, with studies highlighting their potential as mobile energy storage systems to provide grid support. Realising this potential requires effective charging coordination, which are often formulated as mixed-integer programming (MIP) problems. However, MIP problems are NP-hard and often intractable when applied to time-sensitive tasks. To address this limitation, we propose a deep learning assisted approach for optimising a day-ahead EV joint routing and scheduling problem with varying number of EVs. This problem simultaneously optimises EV routing, charging, discharging and generator scheduling within a distribution network with renewable energy sources. A convolutional neural network is trained to predict the binary variables, thereby reducing the solution search space and enabling solvers to determine the remaining variables more efficiently. Additionally, a padding mechanism is included to handle the changes in input and output sizes caused by varying number of EVs, thus eliminating the need for re-training. In a case study on the IEEE 33-bus system and Nguyen-Dupuis transportation network, our approach reduced runtime by 97.8% when compared to an unassisted MIP solver, while retaining 99.5% feasibility and deviating less than 0.01% from the optimal solution.",
      "authors": [
        "Jun Kang Yap",
        "Vishnu Monn Baskaran",
        "Wen Shan Tan",
        "Ze Yang Ding",
        "Hao Wang",
        "David L. Dowe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:08:03+00:00",
          "link": "https://arxiv.org/abs/2507.15307v1",
          "size": "1456kb",
          "version": "v1"
        }
      ],
      "title": "Joint Optimisation of Electric Vehicle Routing and Scheduling: A Deep Learning-Driven Approach for Dynamic Fleet Sizes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15307",
        "HTML": "https://arxiv.org/html/2507.15307",
        "PDF": "https://arxiv.org/pdf/2507.15307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses electric vehicle routing and scheduling using a deep learning approach. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.17100",
      "abstract": "Combinatorial optimization (CO) is fundamental to several real-world applications, from logistics and scheduling to hardware design and resource allocation. Deep reinforcement learning (RL) has recently shown significant benefits in solving CO problems, reducing reliance on domain expertise and improving computational efficiency. However, the absence of a unified benchmarking framework leads to inconsistent evaluations, limits reproducibility, and increases engineering overhead, raising barriers to adoption for new researchers. To address these challenges, we introduce RL4CO, a unified and extensive benchmark with in-depth library coverage of 27 CO problem environments and 23 state-of-the-art baselines. Built on efficient software libraries and best practices in implementation, RL4CO features modularized implementation and flexible configurations of diverse environments, policy architectures, RL algorithms, and utilities with extensive documentation. RL4CO helps researchers build on existing successes while exploring and developing their own designs, facilitating the entire research process by decoupling science from heavy engineering. We finally provide extensive benchmark studies to inspire new insights and future work. RL4CO has already attracted numerous researchers in the community and is open-sourced at https://github.com/ai4co/rl4co.",
      "authors": [
        "Federico Berto",
        "Chuanbo Hua",
        "Junyoung Park",
        "Laurin Luttmann",
        "Yining Ma",
        "Fanchen Bu",
        "Jiarui Wang",
        "Haoran Ye",
        "Minsu Kim",
        "Sanghyeok Choi",
        "Nayeli Gast Zepeda",
        "Andr\\'e Hottung",
        "Jianan Zhou",
        "Jieyi Bi",
        "Yu Hu",
        "Fei Liu",
        "Hyeonah Kim",
        "Jiwoo Son",
        "Haeyeon Kim",
        "Davide Angioni",
        "Wouter Kool",
        "Zhiguang Cao",
        "Qingfu Zhang",
        "Joungho Kim",
        "Jie Zhang",
        "Kijung Shin",
        "Cathy Wu",
        "Sungsoo Ahn",
        "Guojie Song",
        "Changhyun Kwon",
        "Kevin Tierney",
        "Lin Xie",
        "Jinkyoo Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-29T16:57:22+00:00",
          "link": "https://arxiv.org/abs/2306.17100v1",
          "size": "5212kb",
          "version": "v1"
        },
        {
          "date": "2023-09-13T10:12:09+00:00",
          "link": "https://arxiv.org/abs/2306.17100v2",
          "size": "4587kb",
          "version": "v2"
        },
        {
          "date": "2023-12-04T09:01:53+00:00",
          "link": "https://arxiv.org/abs/2306.17100v3",
          "size": "5860kb",
          "version": "v3"
        },
        {
          "date": "2024-06-21T10:05:39+00:00",
          "link": "https://arxiv.org/abs/2306.17100v4",
          "size": "11154kb",
          "version": "v4"
        },
        {
          "date": "2025-05-29T20:04:16+00:00",
          "link": "https://arxiv.org/abs/2306.17100v5",
          "size": "6277kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T08:23:56+00:00",
          "link": "https://arxiv.org/abs/2306.17100v6",
          "size": "6258kb",
          "version": "v6"
        }
      ],
      "title": "RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.17100",
        "PDF": "https://arxiv.org/pdf/2306.17100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a benchmark framework for reinforcement learning in combinatorial optimization. It does not involve LLM training data processing, focusing on RL benchmarking instead."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Computational Efficiency",
        "Deep Reinforcement Learning",
        "Management",
        "Navigate",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Traveling Salesman Problem"
      ],
      "repo_urls": [
        "https://github.com/ai4co/rl4co",
        "https://github.com/facebookresearch/rl",
        "https://github.com/pytorch/rl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.20655",
      "abstract": "A stationary Stokes problem with a piecewise constant viscosity coefficient in multiple subdomains is considered in the paper. For standard finite element pairs, a robust inf-sup condition is required to show the robustness of the discretization error with respect to the discontinuous viscosity, which has only been proven for the two-subdomain case in the paper [Numer. Math. (2006) 103: 129--149]. To avoid the robust inf-sup condition of a discrete finite element pair for multiple subdomains, we propose an ultra-weak augmented mixed finite element formulation. By adopting a Galerkin-least-squares method, the augmented mixed formulation can achieve stability without relying on the inf-sup condition in both continuous and discrete settings. The key step to having a robust priori error estimate is to use two norms, one energy norm and one full norm, in robust continuity. The robust coercivity is proved for the energy norm. A robust a priori error estimate in the energy norm is then derived with the best approximation property in the full norm for the case of multiple subdomains. Additionally, the paper introduces a singular Kellogg-type example with exact solutions for the first time. Extensive numerical tests are conducted to validate the robust error estimate.",
      "authors": [
        "Yuxiang Liang and Shun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-30T08:50:49+00:00",
          "link": "https://arxiv.org/abs/2407.20655v1",
          "size": "1279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:54:18+00:00",
          "link": "https://arxiv.org/abs/2407.20655v2",
          "size": "552kb",
          "version": "v2"
        }
      ],
      "title": "Robust Augmented Mixed Finite Element Methods for Stoke Interface Problems with Discontinuous Viscosity in Multiple Subdomains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20655",
        "HTML": "https://arxiv.org/html/2407.20655",
        "PDF": "https://arxiv.org/pdf/2407.20655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents augmented mixed finite element methods for solving Stokes problems with discontinuous viscosity, unrelated to any aspect of LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.09171",
      "abstract": "Chemputation reframes synthesis as the programmable execution of reaction code on a universally re-configurable hardware graph. Here we prove that a chemputer equipped with a finite, but extensible, set of reagents, catalysts and process conditions, together with a chempiler that maps reaction graphs onto hardware, is universal: it can generate any stable, isolable molecule in finite time and in analytically detectable quantity, provided real-time error correction keeps the per-step fidelity above the threshold set by the molecule's assembly index. The proof is constructed by casting the platform as a Chemical Synthesis Turing Machine (CSTM). The CSTM formalism supplies (i) an eight-tuple state definition that unifies reagents, process variables (including catalysts) and tape operations; (ii) the Universal Chemputation Principle; and (iii) a dynamic-error-correction routine ensuring fault tolerant execution. Linking this framework to assembly theory strengthens the definition of a molecule by demanding practical synthesizability and error correction becomes a prerequisite for universality. We validate the abstraction against >100 \\c{hi}DL programs executed on a modular chemputer rigs spanning single step to multi-step routes. Mapping each procedure onto CSTM shows that the cumulative number of unit operations grows linearly with synthetic depth. Together, these results elevate chemical synthesis to the status of a general computation: algorithms written in \\c{hi}DL are compiled to hardware, executed with closed-loop correction, and produce verifiable molecular outputs. By formalising chemistry in this way, the chemputer offers a path to shareable, executable chemical code, interoperable hardware ecosystems, and ultimately a searchable, provable atlas of chemical space.",
      "authors": [
        "Leroy Cronin",
        "Sebastian Pagel",
        "Abhishek Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-17T11:31:18+00:00",
          "link": "https://arxiv.org/abs/2408.09171v1",
          "size": "337kb",
          "version": "v1"
        },
        {
          "date": "2025-05-01T00:55:39+00:00",
          "link": "https://arxiv.org/abs/2408.09171v2",
          "size": "750kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T12:14:29+00:00",
          "link": "https://arxiv.org/abs/2408.09171v3",
          "size": "1245kb",
          "version": "v3"
        }
      ],
      "title": "Chemputer and Chemputation -- A Universal Chemical Compound Synthesis Machine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.09171",
        "PDF": "https://arxiv.org/pdf/2408.09171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a chemical synthesis machine and does not relate to LLM training data processing. It concerns programmable chemical synthesis and error correction in a chemical context, unrelated to data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.02930",
      "abstract": "This paper introduces TemporalVLM, a video large language model (video LLM) capable of effective temporal reasoning and fine-grained understanding in long videos. At the core, our approach includes a visual encoder for mapping a long-term input video into features which are time-aware and contain both local and global cues. In particular, it first divides the input video into short-term clips, which are jointly encoded with their timestamps and fused across overlapping temporal windows into time-sensitive local features. Next, the local features are passed through a bidirectional long short-term memory (BiLSTM) module for global feature aggregation. The extracted time-aware and multi-level features are important for accurate temporal reasoning and fine-grained understanding in long videos. Moreover, to facilitate the evaluation of TemporalVLM, we present a large-scale long video dataset of industry assembly processes, namely IndustryASM, which consists of videos recorded on factory floors with actions and timestamps annotated by industrial engineers for time and motion studies and temporal action segmentation evaluation. Finally, extensive experiments on datasets of long videos, including TimeIT and IndustryASM, show that TemporalVLM achieves superior performance than previous methods across temporal reasoning and fine-grained understanding tasks, namely dense video captioning, temporal video grounding, video highlight detection, and temporal action segmentation. To the best of our knowledge, our work is the first to incorporate LSTMs into video LLMs.",
      "authors": [
        "Fawad Javed Fateh",
        "Umer Ahmed",
        "Hamza Khan",
        "M. Zeeshan Zia",
        "Quoc-Huy Tran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T00:50:33+00:00",
          "link": "https://arxiv.org/abs/2412.02930v1",
          "size": "4311kb",
          "version": "v1"
        },
        {
          "date": "2025-03-09T07:25:51+00:00",
          "link": "https://arxiv.org/abs/2412.02930v2",
          "size": "4311kb",
          "version": "v2"
        },
        {
          "date": "2025-06-06T20:24:54+00:00",
          "link": "https://arxiv.org/abs/2412.02930v3",
          "size": "13304kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T04:32:58+00:00",
          "link": "https://arxiv.org/abs/2412.02930v4",
          "size": "13309kb",
          "version": "v4"
        }
      ],
      "title": "Video LLMs for Temporal Reasoning in Long Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02930",
        "HTML": "https://arxiv.org/html/2412.02930",
        "PDF": "https://arxiv.org/pdf/2412.02930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TemporalVLM, a video large language model, and presents the IndustryASM dataset for evaluation. While there is mention of a new dataset, the main focus lies on the model's architecture for temporal reasoning, not on LLM training data processing operations."
      },
      "tasks": [
        "Action Segmentation",
        "Dense Video Captioning",
        "Highlight Detection",
        "Language Modelling",
        "Large Language Model",
        "Temporal Action Segmentation",
        "Video Captioning",
        "Video Grounding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08676",
      "abstract": "Animating clipart images with seamless motion while maintaining visual fidelity and temporal coherence presents significant challenges. Existing methods, such as AniClipart, effectively model spatial deformations but often fail to ensure smooth temporal transitions, resulting in artifacts like abrupt motions and geometric distortions. Similarly, text-to-video (T2V) and image-to-video (I2V) models struggle to handle clipart due to the mismatch in statistical properties between natural video and clipart styles. This paper introduces FlexiClip, a novel approach designed to overcome these limitations by addressing the intertwined challenges of temporal consistency and geometric integrity. FlexiClip extends traditional B\\'ezier curve-based trajectory modeling with key innovations: temporal Jacobians to correct motion dynamics incrementally, continuous-time modeling via probability flow ODEs (pfODEs) to mitigate temporal noise, and a flow matching loss inspired by GFlowNet principles to optimize smooth motion transitions. These enhancements ensure coherent animations across complex scenarios involving rapid movements and non-rigid deformations. Extensive experiments validate the effectiveness of FlexiClip in generating animations that are not only smooth and natural but also structurally consistent across diverse clipart types, including humans and animals. By integrating spatial and temporal modeling with pre-trained video diffusion models, FlexiClip sets a new standard for high-quality clipart animation, offering robust performance across a wide range of visual content. Project Page: https://creative-gen.github.io/flexiclip.github.io/",
      "authors": [
        "Anant Khandelwal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T09:07:12+00:00",
          "link": "https://arxiv.org/abs/2501.08676v1",
          "size": "23969kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:36:51+00:00",
          "link": "https://arxiv.org/abs/2501.08676v2",
          "size": "15180kb",
          "version": "v2"
        }
      ],
      "title": "FlexiClip: Locality-Preserving Free-Form Character Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08676",
        "HTML": "https://arxiv.org/html/2501.08676",
        "PDF": "https://arxiv.org/pdf/2501.08676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces FlexiClip, focusing on clipart animation and not on LLM training data processing. It does not address data operations pertinent to LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Form",
        "Trajectory Modeling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12829",
      "abstract": "Despite having a population of twenty million, Kazakhstan's culture and language remain underrepresented in the field of natural language processing. Although large language models (LLMs) continue to advance worldwide, progress in Kazakh language has been limited, as seen in the scarcity of dedicated models and benchmark evaluations. To address this gap, we introduce KazMMLU, the first MMLU-style dataset specifically designed for Kazakh language. KazMMLU comprises 23,000 questions that cover various educational levels, including STEM, humanities, and social sciences, sourced from authentic educational materials and manually validated by native speakers and educators. The dataset includes 10,969 Kazakh questions and 12,031 Russian questions, reflecting Kazakhstan's bilingual education system and rich local context. Our evaluation of several state-of-the-art multilingual models (Llama-3.1, Qwen-2.5, GPT-4, and DeepSeek V3) demonstrates substantial room for improvement, as even the best-performing models struggle to achieve competitive performance in Kazakh and Russian. These findings underscore significant performance gaps compared to high-resource languages. We hope that our dataset will enable further research and development of Kazakh-centric LLMs. Data and code will be made available upon acceptance.",
      "authors": [
        "Mukhammed Togmanov",
        "Nurdaulet Mukhituly",
        "Diana Turmakhan",
        "Jonibek Mansurov",
        "Maiya Goloburda",
        "Akhmed Sakip",
        "Zhuohan Xie",
        "Yuxia Wang",
        "Bekassyl Syzdykov",
        "Nurkhan Laiyk",
        "Alham Fikri Aji",
        "Ekaterina Kochmar",
        "Preslav Nakov",
        "Fajri Koto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T12:48:37+00:00",
          "link": "https://arxiv.org/abs/2502.12829v1",
          "size": "1840kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:15:46+00:00",
          "link": "https://arxiv.org/abs/2502.12829v2",
          "size": "1027kb",
          "version": "v2"
        }
      ],
      "title": "KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12829",
        "HTML": "https://arxiv.org/html/2502.12829",
        "PDF": "https://arxiv.org/pdf/2502.12829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces KazMMLU, a new dataset specifically for evaluating LLMs with a focus on Kazakh language. The creation of this dataset involves a significant contribution to training data processing for LLMs in a low-resource language context."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03826",
      "abstract": "Purpose: Cyber-Physical Systems (CPSs) integrate computation and physical processes, producing time series data from thousands of sensors. Knowledge graphs can contextualize these data, yet current approaches that are applicably to monitoring CPS rely on observation-based approaches. This limits the ability to express computations on sensor data, especially when no assumptions can be made about sampling synchronicity or sampling rates.\n  Methodology: We propose an approach for integrating knowledge graphs with signals that model run-time sensor data as functions from time to data. To demonstrate this approach, we introduce SigSPARQL, a query language that can combine RDF data and signals. We assess its technical feasibility with a prototype and demonstrate its use in a typical CPS monitoring use case.\n  Findings: Our approach enables queries to combine graph-based knowledge with signals, overcoming some key limits of observation-based methods. The developed prototype successfully demonstrated feasibility and applicability.\n  Value: This work presents a query-based approach for CPS monitoring that integrates knowledge graphs and signals, alleviating problems of observation-based approaches. By leveraging system knowledge, it enables operators to run a single query across different system instances within the same domain. Future work will extend SigSPARQL with additional signal functions and evaluate it in large-scale CPS deployments.",
      "authors": [
        "Tobias Schwarzinger",
        "Gernot Steindl",
        "Thomas Fr\\\"uhwirth",
        "Thomas Preindl",
        "Konrad Diwold",
        "Katrin Ehrenm\\\"uller",
        "Fajar J. Ekaputra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T10:54:44+00:00",
          "link": "https://arxiv.org/abs/2506.03826v1",
          "size": "173kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:49:34+00:00",
          "link": "https://arxiv.org/abs/2506.03826v2",
          "size": "174kb",
          "version": "v2"
        }
      ],
      "title": "SigSPARQL: Signals as a First-Class Citizen When Querying Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03826",
        "HTML": "https://arxiv.org/html/2506.03826",
        "PDF": "https://arxiv.org/pdf/2506.03826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes SigSPARQL for querying knowledge graphs with signals in CPS, focusing on querying techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12629",
      "abstract": "We present a unified interpolation scheme that combines compactly-supported positive-definite kernels and multivariate polynomials. This unified framework generalizes interpolation with compactly-supported kernels and also classical polynomial least squares approximation. To facilitate the efficient use of this unified interpolation scheme, we present specialized numerical linear algebra procedures that leverage standard matrix factorizations. These procedures allow for efficient computation and storage of the unified interpolant. We also present a modification to the numerical linear algebra that allows us to generalize the application of the unified framework to target functions on manifolds with and without boundary. Our numerical experiments on both Euclidean domains and manifolds indicate that the unified interpolant is superior to polynomial least squares for the interpolation of target functions in settings with boundaries.",
      "authors": [
        "M. Belianovich",
        "G. E. Fasshauer",
        "A. Narayan",
        "V. Shankar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:53:30+00:00",
          "link": "https://arxiv.org/abs/2507.12629v1",
          "size": "2067kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T05:25:57+00:00",
          "link": "https://arxiv.org/abs/2507.12629v2",
          "size": "2074kb",
          "version": "v2"
        }
      ],
      "title": "A Unified Framework for Efficient Kernel and Polynomial Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12629",
        "HTML": "https://arxiv.org/html/2507.12629",
        "PDF": "https://arxiv.org/pdf/2507.12629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a unified framework for interpolation using kernels and polynomials, with no relation to LLM training data processing or data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14553",
      "abstract": "Clutter in photos is a distraction preventing photographers from conveying the intended emotions or stories to the audience. Photography amateurs frequently include clutter in their photos due to unconscious negligence or the lack of experience in creating a decluttered, aesthetically appealing scene for shooting. We are thus motivated to develop a camera guidance system that provides solutions and guidance for clutter identification and removal. We estimate and visualize the contribution of objects to the overall aesthetics and content of a photo, based on which users can interactively identify clutter. Suggestions on getting rid of clutter, as well as a tool that removes cluttered objects computationally, are provided to guide users to deal with different kinds of clutter and improve their photographic work. Two technical novelties underpin interactions in our system: a clutter distinguishment algorithm with aesthetics evaluations for objects and an iterative image inpainting algorithm based on generative adversarial nets that reconstructs missing regions of removed objects for high-resolution images. User studies demonstrate that our system provides flexible interfaces and accurate algorithms that allow users to better identify distractions and take higher quality images within less time.",
      "authors": [
        "Xiaoran Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:15:17+00:00",
          "link": "https://arxiv.org/abs/2507.14553v1",
          "size": "15499kb",
          "version": "v1"
        }
      ],
      "title": "Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14553",
        "HTML": "https://arxiv.org/html/2507.14553",
        "PDF": "https://arxiv.org/pdf/2507.14553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents techniques for clutter detection and image inpainting for photographic enhancement, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15566",
      "abstract": "The availability of downstream resources plays a critical role in planning the admission of patients undergoing elective surgery, with inpatient beds being one of the most crucial resources. When planning patient admissions, predictions on their length-of-stay (LOS) made by machine learning (ML) models are used to ensure bed availability. However, the actual LOS for each patient may differ considerably from the predicted value, potentially making the schedule infeasible. To address such infeasibilities, rescheduling strategies that take advantage of operational flexibility can be implemented. For example, adjustments may include postponing admission dates, relocating patients to different wards, or even transferring patients who are already admitted. The common assumption is that more accurate LOS predictions reduce the impact of rescheduling. However, training ML models that can make such accurate predictions can be costly. Building on previous work that proposed simulated \\ac{ml} for evaluating data-driven approaches, this paper explores the relationship between LOS prediction accuracy and rescheduling flexibility across various corrective policies. Specifically, we examine the most effective patient rescheduling strategies under LOS prediction errors to prevent bed overflows while optimizing resource utilization.",
      "authors": [
        "Pieter Smet",
        "Martina Doneda",
        "Ettore Lanzarone",
        "Giuliana Carello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:46:18+00:00",
          "link": "https://arxiv.org/abs/2507.15566v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15566",
        "PDF": "https://arxiv.org/pdf/2507.15566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work centers on rescheduling strategies and length-of-stay predictions in the context of elective surgery, not on LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15677",
      "abstract": "Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant motion. Still, the inherent properties of cables, such as resilience, hysteresis, and friction, often lead to particular difficulties in modeling and control. This paper proposes a model predictive control (MPC) method that relies exclusively on input-output data, without a physical model, to improve the control accuracy of FCRAs. First, we develop an implicit model based on input-output data and integrate it into an MPC optimization framework. Second, a data selection algorithm (DSA) is introduced to filter the data that best characterize the system, thereby reducing the solution time per step to approximately 4 ms, which is an improvement of nearly 80%. Lastly, the influence of hyperparameters on tracking error is investigated through simulation. The proposed method has been validated on a real FCRA platform, including five-point positioning accuracy tests, a five-point response tracking test, and trajectory tracking for letter drawing. The results demonstrate that the average positioning accuracy is approximately 2.070 mm. Moreover, compared to the PID method with an average tracking error of 1.418{\\deg}, the proposed method achieves an average tracking error of 0.541{\\deg}.",
      "authors": [
        "Huayue Liang",
        "Yanbo Chen",
        "Hongyang Cheng",
        "Yanzhao Yu",
        "Shoujie Li",
        "Junbo Tan",
        "Xueqian Wang",
        "Long Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:42:29+00:00",
          "link": "https://arxiv.org/abs/2507.15677v1",
          "size": "6182kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15677",
        "HTML": "https://arxiv.org/html/2507.15677",
        "PDF": "https://arxiv.org/pdf/2507.15677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model predictive control for flexible cable-driven robotic arms and introduces a data selection algorithm to improve control accuracy. It does not relate to LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15769",
      "abstract": "Vehicular communication systems operating in the millimeter wave (mmWave) band are highly susceptible to signal blockage from dynamic obstacles such as vehicles, pedestrians, and infrastructure. To address this challenge, we propose a proactive blockage prediction framework that utilizes multi-modal sensing, including camera, GPS, LiDAR, and radar inputs in an infrastructure-to-vehicle (I2V) setting. This approach uses modality-specific deep learning models to process each sensor stream independently and fuses their outputs using a softmax-weighted ensemble strategy based on validation performance. Our evaluations, for up to 1.5s in advance, show that the camera-only model achieves the best standalone trade-off with an F1-score of 97.1% and an inference time of 89.8ms. A camera+radar configuration further improves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness and efficiency of multi-modal sensing for mmWave blockage prediction and provide a pathway for proactive wireless communication in dynamic environments.",
      "authors": [
        "Ahmad M. Nazar",
        "Abdulkadir Celik",
        "Mohamed Y. Selim",
        "Asmaa Abdallah",
        "Daji Qiao",
        "and Ahmed M. Eltawil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.15769v1",
          "size": "5721kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15769",
        "HTML": "https://arxiv.org/html/2507.15769",
        "PDF": "https://arxiv.org/pdf/2507.15769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with multi-modal sensor fusion for proactive blockage prediction in vehicular networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.17141",
      "abstract": "Recent advancements in large language models (LLMs) focus on aligning to heterogeneous human expectations and values via multi-objective preference alignment. However, existing methods are dependent on the policy model parameters, which require high-cost repetition of their alignment algorithms for each new policy model, and they cannot expand to unseen objectives due to their static alignment objectives. In this work, we propose Meta-Objective Aligner (MetaAligner), the first policy-agnostic and generalizable method for multi-objective preference alignment. MetaAligner models multi-objective alignment into three stages: (1) dynamic objectives reformulation algorithm reorganizes traditional alignment datasets to supervise the model on performing flexible alignment across different objectives; (2) conditional weak-to-strong correction paradigm aligns the weak outputs of fixed policy models to approach strong outputs with higher preferences in the corresponding alignment objectives, enabling plug-and-play inferences on any policy models, which significantly reduces training costs and facilitates alignment on close-source policy models; (3) generalizable inference method flexibly adjusts target objectives by updating their text descriptions in the prompts, facilitating generalizable alignment to unseen objectives. Experimental results show that MetaAligner achieves significant and balanced improvements in multi-objective alignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU training hours compared to previous alignment methods. The model also effectively aligns unseen objectives, marking the first step towards generalizable multi-objective preference alignment.",
      "authors": [
        "Kailai Yang",
        "Zhiwei Liu",
        "Qianqian Xie",
        "Jimin Huang",
        "Tianlin Zhang",
        "Sophia Ananiadou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-25T19:28:10+00:00",
          "link": "https://arxiv.org/abs/2403.17141v1",
          "size": "4567kb",
          "version": "v1"
        },
        {
          "date": "2024-05-06T14:17:41+00:00",
          "link": "https://arxiv.org/abs/2403.17141v2",
          "size": "11658kb",
          "version": "v2"
        },
        {
          "date": "2024-10-07T03:19:16+00:00",
          "link": "https://arxiv.org/abs/2403.17141v3",
          "size": "11975kb",
          "version": "v3"
        }
      ],
      "title": "MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17141",
        "HTML": "https://arxiv.org/html/2403.17141",
        "PDF": "https://arxiv.org/pdf/2403.17141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a method for multi-objective alignment in LLMs, which impacts LLM performance, it primarily revolves around model alignment processes rather than detailing specific data processing or data operation techniques."
      },
      "tasks": [
        "In-Context Learning"
      ],
      "repo_urls": [
        "https://github.com/stevekgyang/metaaligner"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19166",
      "abstract": "In recent years, the integration of advanced imaging techniques and deep learning methods has significantly advanced computer-aided diagnosis (CAD) systems for breast cancer detection and classification. Transformers, which have shown great promise in computer vision, are now being applied to medical image analysis. However, their application to histopathological images presents challenges due to the need for extensive manual annotations of whole-slide images (WSIs), as these models require large amounts of data to work effectively, which is costly and time-consuming. Furthermore, the quadratic computational cost of Vision Transformers (ViTs) is particularly prohibitive for large, high-resolution histopathological images, especially on edge devices with limited computational resources. In this study, we introduce a novel lightweight breast cancer classification approach using transformers that operates effectively without large datasets. By incorporating parallel processing pathways for Discrete Cosine Transform (DCT) Attention and MobileConv, we convert image data from the spatial domain to the frequency domain to utilize the benefits such as filtering out high frequencies in the image, which reduces computational cost. This demonstrates the potential of our approach to improve breast cancer classification in histopathological images, offering a more efficient solution with reduced reliance on extensive annotated datasets. Our proposed model achieves an accuracy of 96.00% $\\pm$ 0.48% for binary classification and 87.85% $\\pm$ 0.93% for multiclass classification, which is comparable to state-of-the-art models while significantly reducing computational costs. This demonstrates the potential of our approach to improve breast cancer classification in histopathological images, offering a more efficient solution with reduced reliance on extensive annotated datasets.",
      "authors": [
        "Mahtab Ranjbar (1)",
        "Mehdi Mohebbi (1)",
        "Mahdi Cherakhloo (2)",
        "Bijan Vosoughi. Vahdat (2) ((1) Department of Mathematical and Computer Sciences",
        "Kharazmi University",
        "(2) Department of Medical Engineering",
        "Electrical Engineering Department",
        "Sharif University of Technology)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T21:16:56+00:00",
          "link": "https://arxiv.org/abs/2410.19166v1",
          "size": "4342kb",
          "version": "v1"
        }
      ],
      "title": "DCT-HistoTransformer: Efficient Lightweight Vision Transformer with DCT Integration for histopathological image analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19166",
        "HTML": "https://arxiv.org/html/2410.19166",
        "PDF": "https://arxiv.org/pdf/2410.19166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is about improving breast cancer classification using Vision Transformers and DCT integration in image processing. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "Breast Cancer Detection",
        "Cancer Classification",
        "Classification",
        "Medical Image Analysis",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.19463",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a critical technique for enhancing large language model (LLM) capabilities. However, practitioners face significant challenges when making RAG deployment decisions. While existing research prioritizes algorithmic innovations, a systematic gap persists in understanding fundamental engineering trade-offs that determine RAG success. We present the first comprehensive study of three universal RAG deployment decisions: whether to deploy RAG, how much information to retrieve, and how to integrate retrieved knowledge effectively. Through systematic experiments across three LLMs and six datasets spanning question answering and code generation tasks, we reveal critical insights: (1) RAG deployment must be highly selective, with variable recall thresholds and failure modes affecting up to 12.6\\% of samples even with perfect documents. (2) Optimal retrieval volume exhibits task-dependent behavior QA tasks show universal patterns (5-10 documents optimal) while code generation requires scenario-specific optimization. (3) Knowledge integration effectiveness depends on task and model characteristics, with code generation benefiting significantly from prompting methods while question answering shows minimal improvement. These findings demonstrate that universal RAG strategies prove inadequate. Effective RAG systems require context-aware design decisions based on task characteristics and model capabilities. Our analysis provides evidence-based guidance for practitioners and establishes foundational insights for principled RAG deployment.",
      "authors": [
        "Shengming Zhao",
        "Yuchen Shao",
        "Yuheng Huang",
        "Jiayang Song",
        "Zhijie Wang",
        "Chengcheng Wan",
        "Lei Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T04:25:31+00:00",
          "link": "https://arxiv.org/abs/2411.19463v1",
          "size": "338kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:38:53+00:00",
          "link": "https://arxiv.org/abs/2411.19463v2",
          "size": "260kb",
          "version": "v2"
        }
      ],
      "title": "Understanding the Design Decisions of Retrieval-Augmented Generation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19463",
        "HTML": "https://arxiv.org/html/2411.19463",
        "PDF": "https://arxiv.org/pdf/2411.19463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study examines retrieval-augmented generation (RAG) systems for enhancing LLM capabilities, focusing on deployment decisions rather than training data processing. It provides some insights into integrating retrieved information, which is tangentially related to data processing but not central to the paper."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03920",
      "abstract": "Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities, as well as their interactions and synergistic effects on decision-making. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. Additionally, we analyze the performance of current social agents across various game scenarios. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.",
      "authors": [
        "Xiachong Feng",
        "Longxu Dou",
        "Ella Li",
        "Qinghao Wang",
        "Haochuan Wang",
        "Yu Guo",
        "Chang Ma",
        "Lingpeng Kong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T06:46:46+00:00",
          "link": "https://arxiv.org/abs/2412.03920v1",
          "size": "843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:35:50+00:00",
          "link": "https://arxiv.org/abs/2412.03920v2",
          "size": "1451kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03920",
        "PDF": "https://arxiv.org/pdf/2412.03920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLM-based agents in game-theoretic scenarios and provides a survey of these topics. It does not address LLM training data processing or dataset creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18974",
      "abstract": "Detecting maximal square submatrices of ones in binary matrices is a fundamental problem with applications in computer vision and pattern recognition. While the standard dynamic programming (DP) solution achieves optimal asymptotic complexity, its practical performance suffers from repeated minimum operations and inefficient memory access patterns that degrade cache utilization. To address these limitations, we introduce a novel frequency-based algorithm that employs a greedy approach to track the columnar continuity of ones through an adaptive frequency array and a dynamic thresholding mechanism. Extensive benchmarking demonstrates that the frequency-based algorithm achieves faster performance than the standard DP in 100% of test cases with an average speedup of 3.32x, a maximum speedup of 4.60x, and a minimum speedup of 2.31x across matrices up to 5000x5000 with densities from 0.1 to 0.9. The algorithm's average speedup exceeds 2.5x for all densities and rises to over 3.5x for densities of 0.7 and higher across all matrix sizes. These results demonstrate that the frequency-based approach is a superior alternative to standard DP and opens new possibilities for efficient matrix analysis in performance-critical applications.",
      "authors": [
        "Swastik Bhandari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T06:14:33+00:00",
          "link": "https://arxiv.org/abs/2503.18974v1",
          "size": "921kb",
          "version": "v1"
        },
        {
          "date": "2025-03-29T05:33:14+00:00",
          "link": "https://arxiv.org/abs/2503.18974v2",
          "size": "924kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T14:50:41+00:00",
          "link": "https://arxiv.org/abs/2503.18974v3",
          "size": "1845kb",
          "version": "v3"
        }
      ],
      "title": "An Efficient Frequency-Based Approach for Maximal Square Detection in Binary Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18974",
        "HTML": "https://arxiv.org/html/2503.18974",
        "PDF": "https://arxiv.org/pdf/2503.18974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an algorithm for detecting maximal square submatrices in binary matrices, which pertains to computer vision and pattern recognition, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14139",
      "abstract": "This paper introduces SpeedLLM, a neural network accelerator designed on the Xilinx Alevo U280 platform and optimized for the Tinyllama framework to enhance edge computing performance. Key innovations include data stream parallelism, a memory reuse strategy, and Llama2 operator fusion, which collectively reduce latency and energy consumption. SpeedLLM's data pipeline architecture optimizes the read-compute-write cycle, while the memory strategy minimizes FPGA resource demands. The operator fusion boosts computational density and throughput. Results show SpeedLLM outperforms traditional Tinyllama implementations, achieving up to 4.8* faster performance and 1.18* lower energy consumption, offering improvements in edge devices.",
      "authors": [
        "Peipei Wang",
        "Wu Guan",
        "Liping Liang",
        "Zhijun Wang",
        "Hanqing Luo",
        "Zhibin Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T05:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.14139v1",
          "size": "2518kb",
          "version": "v1"
        }
      ],
      "title": "SpeedLLM: An FPGA Co-design of Large Language Model Inference Accelerator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14139",
        "HTML": "https://arxiv.org/html/2507.14139",
        "PDF": "https://arxiv.org/pdf/2507.14139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SpeedLLM, an FPGA-based accelerator for LLM inference on edge devices, focusing on hardware optimization. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14190",
      "abstract": "Effective modern transportation systems depend critically on accurate Signal Phase and Timing (SPaT) estimation. However, acquiring ground-truth SPaT information faces significant hurdles due to communication challenges with transportation departments and signal installers. As a result, Floating Car Data (FCD) has become the primary source for large-scale SPaT analyses. Current FCD approaches often simplify the problem by assuming fixed schedules and basic intersection designs for specific times and locations. These methods fail to account for periodic signal changes, diverse intersection structures, and the inherent limitations of real-world data, thus lacking a comprehensive framework that is universally applicable. Addressing this limitation, we propose an industrial-grade FCD analysis suite that manages the entire process, from initial data preprocessing to final SPaT estimation. Our approach estimates signal phases, identifies time-of-day (TOD) periods, and determines the durations of red and green lights. The framework's notable stability and robustness across diverse conditions, regardless of road geometry, is a key feature. Furthermore, we provide a cleaned, de-identified FCD dataset and supporting parameters to facilitate future research. Currently operational within our navigation platform, the system analyses over 15 million FCD records daily, supporting over two million traffic signals in mainland China, with more than 75\\% of estimations demonstrating less than five seconds of error.",
      "authors": [
        "Mingcheng Liao",
        "Zebang Feng",
        "Miao Fan",
        "Shengtong Xu",
        "Haoyi Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:21:58+00:00",
          "link": "https://arxiv.org/abs/2507.14190v1",
          "size": "1642kb",
          "version": "v1"
        }
      ],
      "title": "Traffic Signal Phase and Timing Estimation with Large-Scale Floating Car Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14190",
        "HTML": "https://arxiv.org/html/2507.14190",
        "PDF": "https://arxiv.org/pdf/2507.14190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on traffic signal phase and timing estimation using Floating Car Data, which is not related to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14808",
      "abstract": "Tokenized U.S. Treasuries have emerged as a prominent subclass of real-world assets (RWAs), offering cryptographically enforced, yield-bearing instruments collateralized by sovereign debt and deployed across multiple blockchain networks. While the market has expanded rapidly, empirical analyses of transaction-level behaviour remain limited. This paper conducts a quantitative, function-level dissection of U.S. Treasury-backed RWA tokens including BUIDL, BENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyze decoded contract calls to isolate core functional primitives such as issuance, redemption, transfer, and bridge activity, revealing segmentation in behaviour between institutional actors and retail users. To model address-level economic roles, we introduce a curvature-aware representation learning framework using Poincar\\'e embeddings and liquidity-based graph features. Our method outperforms baseline models on our RWA Treasury dataset in role inference and generalizes to downstream tasks such as anomaly detection and wallet classification in broader blockchain transaction networks. These findings provide a structured understanding of functional heterogeneity and participant roles in tokenized Treasury in a transaction-level perspective, contributing new empirical evidence to the study of on-chain financialization.",
      "authors": [
        "Junliang Luo",
        "Katrin Tinn",
        "Samuel Ferreira Duran",
        "Di Wu",
        "Xue Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.14808v1",
          "size": "636kb",
          "version": "v1"
        }
      ],
      "title": "Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14808",
        "HTML": "https://arxiv.org/html/2507.14808",
        "PDF": "https://arxiv.org/pdf/2507.14808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on transaction profiling and economic role inference in tokenized U.S. Treasuries using blockchain data. It does not relate to LLM training data processing or any aspects of training data operations for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15094",
      "abstract": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses significant risks, demanding precise, real-time localization and continuous monitoring of the bleeding source for effective hemostatic intervention. In particular, endoscopists have to repeatedly flush to clear blood, allowing only milliseconds to identify bleeding sources, an inefficient process that prolongs operations and elevates patient risks. However, current Artificial Intelligence (AI) methods primarily focus on bleeding region segmentation, overlooking the critical need for accurate bleeding source detection and temporal tracking in the challenging ESD environment, which is marked by frequent visual obstructions and dynamic scene changes. This gap is widened by the lack of specialized datasets, hindering the development of robust AI-assisted guidance systems. To address these challenges, we introduce BleedOrigin-Bench, the first comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated bleeding sources across 106,222 frames from 44 procedures, supplemented with 39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6 challenging clinical scenarios. We also present BleedOrigin-Net, a novel dual-stage detection-tracking framework for the bleeding source localization in ESD procedures, addressing the complete workflow from bleeding onset detection to continuous spatial tracking. We compare with widely-used object detection models (YOLOv11/v12), multimodal large language models, and point tracking methods. Extensive evaluation demonstrates state-of-the-art performance, achieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset detection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source detection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.",
      "authors": [
        "Mengya Xu",
        "Rulin Zhou",
        "An Wang",
        "Chaoyang Lyu",
        "Zhen Li",
        "Ning Zhong",
        "and Hongliang Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:19:42+00:00",
          "link": "https://arxiv.org/abs/2507.15094v1",
          "size": "19384kb",
          "version": "v1"
        }
      ],
      "title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15094",
        "HTML": "https://arxiv.org/html/2507.15094",
        "PDF": "https://arxiv.org/pdf/2507.15094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the BleedOrigin-Bench dataset, a comprehensive ESD bleeding source dataset featuring expert annotations and pseudo-labeled frames. This represents a direct contribution to dataset creation, a core aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15227",
      "abstract": "Interpretability is critical in high-stakes domains such as medical imaging, where understanding model decisions is essential for clinical adoption. In this work, we introduce Sparse Autoencoder (SAE)-based interpretability to breast imaging by analyzing {Mammo-CLIP}, a vision--language foundation model pretrained on large-scale mammogram image--report pairs. We train a patch-level \\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features associated with clinically relevant breast concepts such as \\textit{mass} and \\textit{suspicious calcification}. Our findings reveal that top activated class level latent neurons in the SAE latent space often tend to align with ground truth regions, and also uncover several confounding factors influencing the model's decision-making process. Additionally, we analyze which latent neurons the model relies on during downstream finetuning for improving the breast concept prediction. This study highlights the promise of interpretable SAE latent representations in providing deeper insight into the internal workings of foundation models at every layer for breast imaging.",
      "authors": [
        "Krishna Kanth Nakka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:59:21+00:00",
          "link": "https://arxiv.org/abs/2507.15227v1",
          "size": "9500kb",
          "version": "v1"
        }
      ],
      "title": "Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15227",
        "HTML": "https://arxiv.org/html/2507.15227",
        "PDF": "https://arxiv.org/pdf/2507.15227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses interpretability in medical imaging models using sparse autoencoders, and does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.18423",
      "abstract": "Human perception involves decomposing complex multi-object scenes into time-static object appearance (i.e., size, shape, color) and time-varying object motion (i.e., position, velocity, acceleration). For machines to achieve human-like intelligence in real-world interactions, understanding these physical properties of objects is essential, forming the foundation for dynamic video prediction. While recent advancements in object-centric transformers have demonstrated potential in video prediction, they primarily focus on object appearance, often overlooking motion dynamics, which is crucial for modeling dynamic interactions and maintaining temporal consistency in complex environments. To address these limitations, we propose OCK, a dynamic video prediction model leveraging object-centric kinematics and object slots. We introduce a novel component named Object Kinematics that comprises explicit object motions, serving as an additional attribute beyond conventional appearance features to model dynamic scenes. The Object Kinematics are integrated into various OCK mechanisms, enabling spatiotemporal prediction of complex object interactions over long video sequences. Our model demonstrates superior performance in handling complex scenes with intricate object attributes and motions, highlighting its potential for applicability in vision-related dynamics learning tasks.",
      "authors": [
        "Yeon-Ji Song",
        "Jaein Kim",
        "Suhyung Choi",
        "Jin-Hwa Kim",
        "Byoung-Tak Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T04:47:23+00:00",
          "link": "https://arxiv.org/abs/2404.18423v1",
          "size": "11611kb",
          "version": "v1"
        },
        {
          "date": "2024-05-06T06:10:29+00:00",
          "link": "https://arxiv.org/abs/2404.18423v2",
          "size": "11600kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T03:29:40+00:00",
          "link": "https://arxiv.org/abs/2404.18423v3",
          "size": "4777kb",
          "version": "v3"
        }
      ],
      "title": "OCK: Unsupervised Dynamic Video Prediction with Object-Centric Kinematics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18423",
        "HTML": "https://arxiv.org/html/2404.18423",
        "PDF": "https://arxiv.org/pdf/2404.18423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a video prediction model using object-centric kinematics, which falls outside the scope of LLM training data processing."
      },
      "tasks": [
        "Object",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.09908",
      "abstract": "The field of rigid origami concerns the folding of stiff, inelastic plates of material along crease lines that act like hinges and form a straight-line planar graph, called the crease pattern of the origami. Crease pattern vertices in the interior of the folded material and that are adjacent to four crease lines, i.e. degree-4 vertices, have a single degree of freedom and can be chained together to make flexible polyhedral surfaces. Degree-4 vertices that can fold to a completely flat state have folding kinematics that are very well-understood, and thus they have been used in many engineering and physics applications. However, degree-4 vertices that are not flat-foldable or not folded from flat paper so that the vertex forms either an elliptic or hyperbolic cone, have folding angles at the creases that follow more complicated kinematic equations. In this work we present a new duality between general degree-4 rigid origami vertices, where dual vertices come in elliptic-hyperbolic pairs that have essentially equivalent kinematics. This reveals a mathematical structure in the space of degree-4 rigid origami vertices that can be leveraged in applications, for example in the construction of flexible 3D structures that possess metamaterial properties.",
      "authors": [
        "Thomas C. Hull"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Soft Condensed Matter (cond-mat.soft)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T01:43:15+00:00",
          "link": "https://arxiv.org/abs/2501.09908v1",
          "size": "4618kb",
          "version": "v1"
        }
      ],
      "title": "A rigid origami elliptic-hyperbolic vertex duality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09908",
        "HTML": "https://arxiv.org/html/2501.09908",
        "PDF": "https://arxiv.org/pdf/2501.09908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new duality in rigid origami related to kinematics of crease pattern vertices and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12911",
      "abstract": "Out-of-distribution (OOD) scenarios in autonomous driving refer to situations that deviate from the training domain, often leading to unexpected and potentially hazardous behavior from planners that lack prior exposure to such cases. Recently, Vision-Language Models (VLMs) have been introduced into autonomous driving research for their promising generalization capabilities in OOD settings. Early studies demonstrated that VLMs could recognize OOD scenarios and generate user-level decisions such as \"go straight\" or \"turn right.\" However, a new challenge has emerged due to the misalignment between the VLM's high-level decisions or visual reasoning expressed in language, and the low-level predicted trajectories interpreted as actions. In this paper, we propose LaViPlan, a framework that leverages Reinforcement Learning with Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics. This approach addresses the vision-language-action misalignment observed in existing VLMs fine-tuned via supervised learning, which can recognize driving scenarios but often produce context-unaware decisions. Experimental results demonstrate that our method improves situational awareness and decision-making under OOD conditions, highlighting its potential to mitigate the misalignment issue. This work introduces a promising post-training paradigm for VLM agents in the context of autonomous driving.",
      "authors": [
        "Hayeon Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.12911v1",
          "size": "5639kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T01:01:29+00:00",
          "link": "https://arxiv.org/abs/2507.12911v2",
          "size": "5639kb",
          "version": "v2"
        }
      ],
      "title": "LaViPlan : Language-Guided Visual Path Planning with RLVR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12911",
        "HTML": "https://arxiv.org/html/2507.12911",
        "PDF": "https://arxiv.org/pdf/2507.12911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vision-language models for autonomous driving and proposes a framework for improving decision-making in out-of-distribution scenarios. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14172",
      "abstract": "Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness remain limited by the fixed capabilities of the underlying generative model.\n  We propose SOAR, a method that learns program synthesis by integrating language models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample and refine candidate solutions, and (2) a hindsight learning phase that converts search attempts into valid problem-solution pairs used to fine-tune the LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly effective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance gains across model scales and iterations, leveraging positive transfer between the sampling and refinement finetuning tasks. These improvements carry over to test-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our code is open-sourced at: https://github.com/flowersteam/SOAR",
      "authors": [
        "Julien Pourcel",
        "C\\'edric Colas",
        "Pierre-Yves Oudeyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:42:03+00:00",
          "link": "https://arxiv.org/abs/2507.14172v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14172",
        "PDF": "https://arxiv.org/pdf/2507.14172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper describes SOAR, a method integrating LLMs into a self-improving evolutionary loop for program synthesis. While it involves fine-tuning LLM capabilities, the main focus is on evolutionary search rather than data processing methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14224",
      "abstract": "Background and objective: Brain activity in premature newborns has traditionally been studied using electroencephalography (EEG), leading to substantial advances in our understanding of early neural development. However, since brain development takes root at the fetal stage, a critical window of this process remains largely unknown. The only technique capable of recording neural activity in the intrauterine environment is fetal magnetoencephalography (fMEG), but this approach presents challenges in terms of data quality and scarcity. Using artificial intelligence, the present research aims to transfer the well-established knowledge from EEG studies to fMEG to improve understanding of prenatal brain development, laying the foundations for better detection and treatment of potential pathologies. Methods: We developed an unpaired diffusion translation method based on dual diffusion bridges, which notably includes numerical integration improvements to obtain more qualitative results at a lower computational cost. Models were trained on our unpaired dataset of bursts of spontaneous activity from 30 high-resolution premature newborns EEG recordings and 44 fMEG recordings. Results: We demonstrate that our method achieves significant improvement upon previous results obtained with Generative Adversarial Networks (GANs), by almost 5% on the mean squared error in the time domain, and completely eliminating the mode collapse problem in the frequency domain, thus achieving near-perfect signal fidelity. Conclusion: We set a new state of the art in the EEG-fMEG unpaired translation problem, as our developed tool completely paves the way for early brain activity analysis. Overall, we also believe that our method could be reused for other unpaired signal translation applications.",
      "authors": [
        "Beno\\^it Brebion",
        "Alban Gallard",
        "Katrin Sippel",
        "Amer Zaylaa",
        "Hubert Preissl",
        "Sahar Moghimi",
        "Fabrice Wallois",
        "Ya\\\"el Fr\\'egier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.14224v1",
          "size": "564kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion-based translation between unpaired spontaneous premature neonatal EEG and fetal MEG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14224",
        "HTML": "https://arxiv.org/html/2507.14224",
        "PDF": "https://arxiv.org/pdf/2507.14224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the translation of EEG and fMEG data using diffusion-based methods to study brain activity. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14505",
      "abstract": "Multiview pedestrian detection typically involves two stages: human modeling and pedestrian localization. Human modeling represents pedestrians in 3D space by fusing multiview information, making its quality crucial for detection accuracy. However, existing methods often introduce noise and have low precision. While some approaches reduce noise by fitting on costly multiview 3D annotations, they often struggle to generalize across diverse scenes. To eliminate reliance on human-labeled annotations and accurately model humans, we propose Depth-Consistent Human Modeling (DCHM), a framework designed for consistent depth estimation and multiview fusion in global coordinates. Specifically, our proposed pipeline with superpixel-wise Gaussian Splatting achieves multiview depth consistency in sparse-view, large-scaled, and crowded scenarios, producing precise point clouds for pedestrian localization. Extensive validations demonstrate that our method significantly reduces noise during human modeling, outperforming previous state-of-the-art baselines. Additionally, to our knowledge, DCHM is the first to reconstruct pedestrians and perform multiview segmentation in such a challenging setting. Code is available on the \\href{https://jiahao-ma.github.io/DCHM/}{project page}.",
      "authors": [
        "Jiahao Ma",
        "Tianyu Wang",
        "Miaomiao Liu",
        "David Ahmedt-Aristizabal",
        "Chuong Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:37:14+00:00",
          "link": "https://arxiv.org/abs/2507.14505v1",
          "size": "15561kb",
          "version": "v1"
        }
      ],
      "title": "DCHM: Depth-Consistent Human Modeling for Multiview Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14505",
        "HTML": "https://arxiv.org/html/2507.14505",
        "PDF": "https://arxiv.org/pdf/2507.14505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on multiview pedestrian detection using a depth-consistent human modeling framework, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14795",
      "abstract": "We develop a unified Data Processing Inequality PAC-Bayesian framework -- abbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the supervised learning setting. By embedding the Data Processing Inequality (DPI) into the change-of-measure technique, we obtain explicit bounds on the binary Kullback-Leibler generalization gap for both R\\'enyi divergence and any $f$-divergence measured between a data-independent prior distribution and an algorithm-dependent posterior distribution. We present three bounds derived under our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences. Additionally, our framework also demonstrates a close connection with other well-known bounds. When the prior distribution is chosen to be uniform, our bounds recover the classical Occam's Razor bound and, crucially, eliminate the extraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby achieving tighter results. The framework thus bridges data-processing and PAC-Bayesian perspectives, providing a flexible, information-theoretic tool to construct generalization guarantees.",
      "authors": [
        "Muhan Guan",
        "Farhad Farokhi",
        "Jingge Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:55:15+00:00",
          "link": "https://arxiv.org/abs/2507.14795v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "A DPI-PAC-Bayesian Framework for Generalization Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14795",
        "HTML": "https://arxiv.org/html/2507.14795",
        "PDF": "https://arxiv.org/pdf/2507.14795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a theoretical framework for generalization bounds in supervised learning. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15837",
      "abstract": "We consider optimal interpolation of functions analytic in simply connected domains in the complex plane. By choosing a specific structure for the approximant, we show that the resulting first order optimality conditions can be interpreted as optimal $\\mathcal{H}_2$ interpolation conditions for discrete-time dynamical systems. Connections to the implicit Euler method, the midpoint method, and backward differentiation methods are also established. A data-driven algorithm is developed to compute a (locally) optimal approximant. Our method is tested on three numerical experiments.",
      "authors": [
        "Alessandro Borghi and Tobias Breiten"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.15837v1",
          "size": "584kb",
          "version": "v1"
        }
      ],
      "title": "Data-driven optimal approximation on Hardy spaces in simply connected domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15837",
        "PDF": "https://arxiv.org/pdf/2507.15837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with optimal interpolation of analytic functions and approximation methods in complex domains and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18507",
      "abstract": "Stiffness estimation is crucial for delicate object manipulation in robotic and prosthetic hands but remains challenging due to dependence on force and displacement measurement and real-time sensory integration. This study presents a piezoelectric sensing framework for stiffness estimation at first contact during pinch grasps, addressing the limitations of traditional force-based methods. Inspired by human skin, a multimodal tactile sensor that captures vibrational and force data is developed and integrated into a prosthetic hand's fingertip. Machine learning models, including support vector machines and convolutional neural networks, demonstrate that vibrational signals within the critical 15 ms after first contact reliably encode stiffness, achieving classification accuracies up to 98.6% and regression errors as low as 2.39 Shore A on real-world objects of varying stiffness. Inference times of less than 1.5 ms are significantly faster than the average grasp closure time (16.65 ms in our dataset), enabling real-time stiffness estimation before the object is fully grasped. By leveraging the transient asymmetry in grasp dynamics, where one finger contacts the object before the others, this method enables early grasp modulation, enhancing safety and intuitiveness in prosthetic hands while offering broad applications in robotics.",
      "authors": [
        "Anway S. Pimpalkar",
        "Ariel Slepyan",
        "and Nitish V. Thakor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T16:50:42+00:00",
          "link": "https://arxiv.org/abs/2411.18507v1",
          "size": "4671kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T19:59:24+00:00",
          "link": "https://arxiv.org/abs/2411.18507v2",
          "size": "4671kb",
          "version": "v2"
        }
      ],
      "title": "At First Contact: Stiffness Estimation Using Vibrational Information for Prosthetic Grasp Modulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18507",
        "HTML": "https://arxiv.org/html/2411.18507",
        "PDF": "https://arxiv.org/pdf/2411.18507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for stiffness estimation in prosthetic hands, focusing on vibrational sensing and machine learning models for robotics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00172",
      "abstract": "In this paper, we establish necessary and sufficient conditions for stable inversion, addressing challenges in non-minimum phase, non-square, and singular systems. An H-Infinity based algebraic approximation is introduced for near-perfect tracking without preview. Additionally, we propose a novel robust control strategy combining the nominal model with dual feedforward control to form a feedback structure. Numerical comparison demonstrates the approach's effectiveness.",
      "authors": [
        "Burak K\\\"urk\\c{c}\\\"u",
        "Masayoshi Tomizuka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T22:56:52+00:00",
          "link": "https://arxiv.org/abs/2501.00172v1",
          "size": "198kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T23:37:04+00:00",
          "link": "https://arxiv.org/abs/2501.00172v2",
          "size": "149kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T05:21:11+00:00",
          "link": "https://arxiv.org/abs/2501.00172v3",
          "size": "149kb",
          "version": "v3"
        }
      ],
      "title": "Algebraic Control: Complete Stable Inversion with Necessary and Sufficient Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00172",
        "HTML": "https://arxiv.org/html/2501.00172",
        "PDF": "https://arxiv.org/pdf/2501.00172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on control theory, specifically addressing stable inversion and robust control strategies. It does not address any aspect of large language model (LLM) training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15838",
      "abstract": "Ensemble learning has been widely used in machine learning to improve model robustness, accuracy, and generalization, but has not yet been applied to code generation tasks with large language models (LLMs). We propose an ensemble approach for LLMs in code generation. Instead of relying on the output of a single model, we generate multiple candidate programs from different LLMs and apply a structured voting mechanism to select the most reliable solution. For voting, we compute syntactic and semantic similarity using CodeBLEU and behavioral equivalence using CrossHair's differential behavior analysis. By aggregating these similarity scores, we select the program that best aligns with the consensus among the candidates. We show through experiments that our ensemble approach consistently outperforms standalone LLMs on the well-known HumanEval and the more challenging LiveCodeBench datasets, achieving an accuracy of 90.2% and 50.2%, respectively, on the two datasets. In comparison, the best-performing LLM (GPT-4o) has an accuracy of 83.5% and 43.4%, respectively. Furthermore, even when restricted to free open-source models, our method achieves an accuracy of 80.5% and 41.6%, respectively, demonstrating the viability of our approach in resource-constrained settings.",
      "authors": [
        "Tarek Mahmud",
        "Bin Duan",
        "Corina Pasareanu",
        "Guowei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T04:38:56+00:00",
          "link": "https://arxiv.org/abs/2503.15838v1",
          "size": "115kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T23:27:01+00:00",
          "link": "https://arxiv.org/abs/2503.15838v2",
          "size": "111kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing LLM Code Generation with Ensembles: A Similarity-Based Selection Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15838",
        "PDF": "https://arxiv.org/pdf/2503.15838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses an ensemble approach to improve LLM code generation but does not primarily focus on training data processing. However, it briefly touches on generating multiple candidate programs, which may involve some aspect of data generation or processing, but it's not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23083",
      "abstract": "Fast diagnosis and repair of enterprise network failures is critically important since disruptions cause major business impacts. Prior works focused on diagnosis primitives or procedures limited to a subset of the problem, such as only data plane or only control plane faults. This paper proposes a new paradigm, model-based network diagnosis, that provides a systematic way to derive automated procedures for identifying the root cause of network failures, based on reports of end-to-end user-level symptoms. The diagnosis procedures are systematically derived from a model of packet forwarding and routing, covering hardware, firmware, and software faults in both the data plane and distributed control plane. These automated procedures replace and dramatically accelerate diagnosis by an experienced human operator. Model-based diagnosis is inspired by, leverages, and is complementary to recent work on network verification. We have built NetDx, a proof-of-concept implementation of model-based network diagnosis. We deployed NetDx on a new emulator of networks consisting of P4 switches with distributed routing software. We validated the robustness and coverage of NetDx with an automated fault injection campaign, in which 100% of faults were diagnosed correctly. Furthermore, on a data set of 33 faults from a large cloud provider that are within the domain targeted by NetDx, 30 are efficiently diagnosed in seconds instead of hours.",
      "authors": [
        "Changrong Wu",
        "Yiyao Yu",
        "Myungjin Lee",
        "Jayanth Srinivasa",
        "Ennan Zhai",
        "George Varghese",
        "Yuval Tamir"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:44:31+00:00",
          "link": "https://arxiv.org/abs/2506.23083v1",
          "size": "212kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T23:35:25+00:00",
          "link": "https://arxiv.org/abs/2506.23083v2",
          "size": "211kb",
          "version": "v2"
        }
      ],
      "title": "Model-Based Diagnosis: Automating End-to-End Diagnosis of Network Failures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23083",
        "HTML": "https://arxiv.org/html/2506.23083",
        "PDF": "https://arxiv.org/pdf/2506.23083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with model-based diagnosis for network failures and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14173",
      "abstract": "Human computer interaction has become integral to modern life, driven by advancements in machine learning technologies. Affective computing, in particular, has focused on systems that recognize, interpret, and respond to human emotions, often using wearable devices, which provide continuous data streams of physiological signals. Among various physiological signals, the photoplethysmogram (PPG) has gained prominence due to its ease of acquisition from widely available devices. However, the generalization of PPG-based emotion recognition models across individuals remains an unresolved challenge. This paper introduces a novel hybrid architecture that combines Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), and Temporal Convolutional Networks (TCNs) to address this issue. The proposed model integrates the strengths of these architectures to improve robustness and generalization. Raw PPG signals are fed into the CNN for feature extraction. These features are processed separately by LSTM and TCN. The outputs from these components are concatenated to generate a final feature representation, which serves as the input for classifying valence and arousal, the primary dimensions of emotion. Experiments using the Photoplethysmogram Dataset for Emotional Analysis (PPGE) demonstrate that the proposed hybrid model achieves better model generalization than standalone CNN and LSTM architectures. Our results show that the proposed solution outperforms the state-of-the-art CNN architecture, as well as a CNN-LSTM model, in emotion recognition tasks with PPG signals. Using metrics such as Area Under the Curve (AUC) and F1 Score, we highlight the model's effectiveness in handling subject variability.",
      "authors": [
        "Karim Alghoul",
        "Hussein Al Osman",
        "Abdulmotaleb El Saddik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.14173v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Generalization in PPG-Based Emotion Measurement with a CNN-TCN-LSTM Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14173",
        "PDF": "https://arxiv.org/pdf/2507.14173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a CNN-TCN-LSTM model for emotion measurement using PPG signals. It focuses on model architecture and generalization, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14229",
      "abstract": "We investigate the cryptanalysis of affine ciphers using a hybrid neural network architecture that combines modular arithmetic-aware and statistical feature-based learning. Inspired by recent advances in interpretable neural networks for modular arithmetic and neural cryptanalysis of classical ciphers, our approach integrates a modular branch that processes raw ciphertext sequences and a statistical branch that leverages letter frequency features. Experiments on datasets derived from natural English text demonstrate that the hybrid model attains high key recovery accuracy for short and moderate ciphertexts, outperforming purely statistical approaches for the affine cipher. However, performance degrades for very long ciphertexts, highlighting challenges in model generalization.",
      "authors": [
        "Vanja Stojanovi\\'c",
        "\\v{Z}iga Lesar",
        "CIril Bohak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:54:10+00:00",
          "link": "https://arxiv.org/abs/2507.14229v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Using Modular Arithmetic Optimized Neural Networks To Crack Affine Cryptographic Schemes Efficiently",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14229",
        "HTML": "https://arxiv.org/html/2507.14229",
        "PDF": "https://arxiv.org/pdf/2507.14229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores cryptanalysis using neural networks, specifically targeted at affine cryptographic schemes, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14949",
      "abstract": "Windows have been introduce in \\cite{BalGasq25} as a tool for designing polynomial algorithms to check satisfiability of a bimodal logic of weak-density. In this paper, after revisiting the ``folklore'' case of bimodal $\\K4$ already treated in \\cite{Halpern} but which is worth a fresh review, we show that windows allow to polynomially solve the satisfiability problem when adding transitivity to weak-density, by mixing algorithms for bimodal K together with windows-approach. The conclusion is that both satisfiability and validity are PSPACE-complete for these logics.",
      "authors": [
        "Philippe Balbiani and Olivier Gasquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:12:03+00:00",
          "link": "https://arxiv.org/abs/2507.14949v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "PSPACE-completeness of bimodal transitive weak-density logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14949",
        "HTML": "https://arxiv.org/html/2507.14949",
        "PDF": "https://arxiv.org/pdf/2507.14949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research relates to satisfiability in logic, particularly bimodal transitive weak-density logic. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15448",
      "abstract": "Greaves et al. (2022) extended frames over real or complex numbers to frames over finite fields. In this paper, we study the theory of frames over finite fields by incorporating the Galois inner products introduced by Fan and Zhang (2017), which generalize the Euclidean and Hermitian inner products. We define a class of frames, called Galois frames over finite fields, along with related notions such as Galois Gram matrices, Galois frame operators, and Galois equiangular tight frames (Galois ETFs). We also characterize when Galois self-dual codes induce Galois ETFs. Furthermore, we construct explicitly Galois ETFs from Galois self-dual constacyclic codes.",
      "authors": [
        "Junmin An and Jon-Lark Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:00:29+00:00",
          "link": "https://arxiv.org/abs/2507.15448v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Galois equiangular tight frames from Galois self-dual codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15448",
        "HTML": "https://arxiv.org/html/2507.15448",
        "PDF": "https://arxiv.org/pdf/2507.15448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the theory of frames over finite fields and Galois ETFs, which are not associated with LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "1606.05446",
      "abstract": "The capability to store data about business processes execution in so-called Event Logs has brought to the diffusion of tools for the analysis of process executions and for the assessment of the goodness of a process model. Nonetheless, these tools are often very rigid in dealing with with Event Logs that include incomplete information about the process execution. Thus, while the ability of handling incomplete event data is one of the challenges mentioned in the process mining manifesto, the evaluation of compliance of an execution trace still requires an end-to-end complete trace to be performed.\n  This paper exploits the power of abduction to provide a flexible, yet computationally effective, framework to deal with different forms of incompleteness in an Event Log. Moreover it proposes a refinement of the classical notion of compliance into strong and conditional compliance to take into account incomplete logs. Finally, performances evaluation in an experimental setting shows the feasibility of the presented approach.",
      "authors": [
        "Federico Chesani and Riccardo De Masellis and Chiara Di Francescomarino and Chiara Ghidini and Paola Mello and Marco Montali and Sergio Tessaris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2016-06-17T08:30:28+00:00",
          "link": "https://arxiv.org/abs/1606.05446v1",
          "size": "341kb",
          "version": "v1"
        }
      ],
      "title": "Abducing Compliance of Incomplete Event Logs",
      "links": {
        "Abstract": "https://arxiv.org/abs/1606.05446",
        "PDF": "https://arxiv.org/pdf/1606.05446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on handling incomplete event logs in business processes through abduction, which does not pertain to any LLM training data processing tasks such as dataset generation or data quality improvement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.06919",
      "abstract": "Transfer entropy (TE) is an information theoretic measure that reveals the directional flow of information between processes, providing valuable insights for a wide range of real-world applications. This work proposes Transfer Entropy Estimation via Transformers (TREET), a novel attention-based approach for estimating TE for stationary processes. The proposed approach employs Donsker-Varadhan representation to TE and leverages the attention mechanism for the task of neural estimation. We propose a detailed theoretical and empirical study of the TREET, comparing it to existing methods on a dedicated estimation benchmark. To increase its applicability, we design an estimated TE optimization scheme that is motivated by the functional representation lemma, and use it to estimate the capacity of communication channels with memory, which is a canonical optimization problem in information theory. We further demonstrate how an optimized TREET can be used to estimate underlying densities, providing experimental results. Finally, we apply TREET to feature analysis of patients with Apnea, demonstrating its applicability to real-world physiological data. Our work, applied with state-of-the-art deep learning methods, opens a new door for communication problems which are yet to be solved.",
      "authors": [
        "Omer Luxembourg",
        "Dor Tsur",
        "Haim Permuter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-10T09:53:21+00:00",
          "link": "https://arxiv.org/abs/2402.06919v1",
          "size": "208kb",
          "version": "v1"
        },
        {
          "date": "2024-02-21T10:45:57+00:00",
          "link": "https://arxiv.org/abs/2402.06919v2",
          "size": "206kb",
          "version": "v2"
        },
        {
          "date": "2025-05-14T12:35:16+00:00",
          "link": "https://arxiv.org/abs/2402.06919v3",
          "size": "272kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T19:07:07+00:00",
          "link": "https://arxiv.org/abs/2402.06919v4",
          "size": "274kb",
          "version": "v4"
        }
      ],
      "title": "TREET: TRansfer Entropy Estimation via Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.06919",
        "PDF": "https://arxiv.org/pdf/2402.06919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on transfer entropy estimation via transformers, mainly targeting information flow between processes for communication problems, with no direct relevance to LLM training data processing."
      },
      "tasks": [
        "LEMMA"
      ],
      "repo_urls": [
        "https://github.com/omerlux/treet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02269",
      "abstract": "Structural Health Monitoring (SHM) ensures the safety and longevity of infrastructure by enabling timely damage detection. Vision-based crack detection, combined with UAVs, addresses the limitations of traditional sensor-based SHM methods but requires the deployment of efficient deep learning models on resource-constrained devices. This study evaluates two lightweight convolutional neural network models, MobileNetV1x0.25 and MobileNetV2x0.5, across TensorFlow, PyTorch, and Open Neural Network Exchange platforms using three quantization techniques: dynamic quantization, post-training quantization (PTQ), and quantization-aware training (QAT). Results show that QAT consistently achieves near-floating-point accuracy, such as an F1-score of 0.8376 for MBNV2x0.5 with Torch-QAT, while maintaining efficient resource usage. PTQ significantly reduces memory and energy consumption but suffers from accuracy loss, particularly in TensorFlow. Dynamic quantization preserves accuracy but faces deployment challenges on PyTorch. By leveraging QAT, this work enables real-time, low-power crack detection on UAVs, enhancing safety, scalability, and cost-efficiency in SHM applications, while providing insights into balancing accuracy and efficiency across different platforms for autonomous inspections.",
      "authors": [
        "Yuxuan Zhang",
        "Luciano Sebastian Martinez-Rau",
        "Quynh Nguyen Phuong Vu",
        "Bengt Oelmann",
        "Sebastian Bader"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T12:29:29+00:00",
          "link": "https://arxiv.org/abs/2502.02269v1",
          "size": "918kb",
          "version": "v1"
        }
      ],
      "title": "Survey of Quantization Techniques for On-Device Vision-based Crack Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02269",
        "HTML": "https://arxiv.org/html/2502.02269",
        "PDF": "https://arxiv.org/pdf/2502.02269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study centers on quantization techniques for vision-based crack detection models and does not involve LLM training data processing activities such as data collection or quality improvement."
      },
      "tasks": [
        "Quantization",
        "Structural Health Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02600",
      "abstract": "Affordance refers to the functional properties that an agent perceives and utilizes from its environment, and is key perceptual information required for robots to perform actions. This information is rich and multimodal in nature. Existing multimodal affordance methods face limitations in extracting useful information, mainly due to simple structural designs, basic fusion methods, and large model parameters, making it difficult to meet the performance requirements for practical deployment. To address these issues, this paper proposes the BiT-Align image-depth-text affordance mapping framework. The framework includes a Bypass Prompt Module (BPM) and a Text Feature Guidance (TFG) attention selection mechanism. BPM integrates the auxiliary modality depth image directly as a prompt to the primary modality RGB image, embedding it into the primary modality encoder without introducing additional encoders. This reduces the model's parameter count and effectively improves functional region localization accuracy. The TFG mechanism guides the selection and enhancement of attention heads in the image encoder using textual features, improving the understanding of affordance characteristics. Experimental results demonstrate that the proposed method achieves significant performance improvements on public AGD20K and HICO-IIF datasets. On the AGD20K dataset, compared with the current state-of-the-art method, we achieve a 6.0% improvement in the KLD metric, while reducing model parameters by 88.8%, demonstrating practical application values. The source code will be made publicly available at https://github.com/DAWDSE/BiT-Align.",
      "authors": [
        "Yizhou Huang",
        "Fan Yang",
        "Guoliang Zhu",
        "Gen Li",
        "Hao Shi",
        "Yukun Zuo",
        "Wenrui Chen",
        "Zhiyong Li",
        "Kailun Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T13:20:42+00:00",
          "link": "https://arxiv.org/abs/2503.02600v1",
          "size": "1733kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:21:11+00:00",
          "link": "https://arxiv.org/abs/2503.02600v2",
          "size": "1734kb",
          "version": "v2"
        }
      ],
      "title": "Resource-Efficient Affordance Grounding with Complementary Depth and Semantic Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02600",
        "HTML": "https://arxiv.org/html/2503.02600",
        "PDF": "https://arxiv.org/pdf/2503.02600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work relates to affordance perception in robots using a multimodal framework, which is not directly related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dawdse/bit-align"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03253",
      "abstract": "Wireless mouse rings offer subtle, reliable pointing interactions for wearable computing platforms. However, the small battery below 27 mAh in the miniature rings restricts the ring's continuous lifespan to just 1-10 hours, because current low-powered wireless communication such as BLE is power-consuming for ring's continuous use. The ring's short lifespan frequently disrupts users' mouse use with the need for frequent charging. This paper presents picoRing mouse, enabling a continuous ring-based mouse interaction with ultra-low-powered ring-to-wristband wireless communication. picoRing mouse employs a coil-based impedance sensing named semi-passive inductive telemetry, allowing a wristband coil to capture a unique frequency response of a nearby ring coil via a sensitive inductive coupling between the coils. The ring coil converts the corresponding user's mouse input into the unique frequency response via an up to 449 uW mouse-driven modulation system. Therefore, the continuous use of picoRing mouse can last approximately 600 (8hrs use/day)-1000 (4hrs use/day) hours on a single charge of a 27 mAh battery while supporting subtle thumb-to-index scrolling and pressing interactions in real-world wearable computing situations.",
      "authors": [
        "Yifan Li",
        "Masaaki Fukumoto",
        "Mohamed Kari",
        "Shigemi Ishida",
        "Akihito Noda",
        "Tomoyuki Yokota",
        "Takao Someya",
        "Yoshihiro Kawahara",
        "Ryo Takahashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T08:09:16+00:00",
          "link": "https://arxiv.org/abs/2504.03253v1",
          "size": "6391kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:36:16+00:00",
          "link": "https://arxiv.org/abs/2504.03253v2",
          "size": "6107kb",
          "version": "v2"
        }
      ],
      "title": "Ultra-low-power ring-based wireless tinymouse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03253",
        "HTML": "https://arxiv.org/html/2504.03253",
        "PDF": "https://arxiv.org/pdf/2504.03253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses low-power wireless technology for wearable devices, specifically for a ring-based mouse interaction. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.08373",
      "abstract": "Optimizing inference for long-context Large Language Models (LLMs) is increasingly important due to the quadratic compute and linear memory complexity of Transformers. Existing approximation methods, such as key-value (KV) cache dropping, sparse attention, and prompt compression, typically rely on rough predictions of token or KV pair importance. We propose a novel framework for approximate LLM inference that leverages small draft models to more accurately predict the importance of tokens and KV pairs. Specifically, we introduce two instantiations of our proposed framework: (i) SpecKV, the first method that leverages a draft output to accurately assess the importance of each KV pair for more effective KV cache dropping, and (ii) SpecPC, which uses the draft model's attention activations to identify and discard unimportant prompt tokens. We motivate our methods with theoretical and empirical analyses, and show a strong correlation between the attention patterns of draft and target models. Extensive experiments on long-context benchmarks show that our methods consistently achieve higher accuracy than existing baselines, while preserving the same improvements in memory usage, latency, and throughput. Our code is available at https://github.com/furiosa-ai/draft-based-approx-llm.",
      "authors": [
        "Kevin Galim",
        "Ethan Ewer",
        "Wonjun Kang",
        "Minjae Lee",
        "Hyung Il Koo",
        "Kangwook Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T02:37:46+00:00",
          "link": "https://arxiv.org/abs/2506.08373v1",
          "size": "6157kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T03:40:40+00:00",
          "link": "https://arxiv.org/abs/2506.08373v2",
          "size": "6159kb",
          "version": "v2"
        }
      ],
      "title": "Draft-based Approximate Inference for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08373",
        "PDF": "https://arxiv.org/pdf/2506.08373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method to optimize inference in LLMs using approximate models, focusing on techniques to improve runtime efficiency and memory usage during inference, not on training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/furiosa-ai/draft-based-approx-llm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14828",
      "abstract": "We revisit previous contrastive learning frameworks to investigate the effect of introducing an adaptive margin into the contrastive loss function for time series representation learning. Specifically, we explore whether an adaptive margin (eMargin), adjusted based on a predefined similarity threshold, can improve the separation between adjacent but dissimilar time steps and subsequently lead to better performance in downstream tasks. Our study evaluates the impact of this modification on clustering performance and classification in three benchmark datasets. Our findings, however, indicate that achieving high scores on unsupervised clustering metrics does not necessarily imply that the learned embeddings are meaningful or effective in downstream tasks. To be specific, eMargin added to InfoNCE consistently outperforms state-of-the-art baselines in unsupervised clustering metrics, but struggles to achieve competitive results in downstream classification with linear probing. The source code is publicly available at https://github.com/sfi-norwai/eMargin.",
      "authors": [
        "Abdul-Kazeem Shamba",
        "Kerstin Bach and Gavin Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T05:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.14828v1",
          "size": "2766kb",
          "version": "v1"
        }
      ],
      "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14828",
        "HTML": "https://arxiv.org/html/2507.14828",
        "PDF": "https://arxiv.org/pdf/2507.14828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates contrastive learning for time series data, focusing on the introduction of a margin-based separation. It does not contribute to LLM training data processing or involve any text-focused dataset creation or processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15240",
      "abstract": "For classification with imbalanced class frequencies, i.e., imbalanced classification (IC), standard accuracy is known to be misleading as a performance measure. While most existing methods for IC resort to optimizing balanced accuracy (i.e., the average of class-wise recalls), they fall short in scenarios where the significance of classes varies or certain metrics should reach prescribed levels. In this paper, we study two key classification metrics, precision and recall, under three practical binary IC settings: fix precision optimize recall (FPOR), fix recall optimize precision (FROP), and optimize $F_\\beta$-score (OFBS). Unlike existing methods that rely on smooth approximations to deal with the indicator function involved, \\textit{we introduce, for the first time, exact constrained reformulations for these direct metric optimization (DMO) problems}, which can be effectively solved by exact penalty methods. Experiment results on multiple benchmark datasets demonstrate the practical superiority of our approach over the state-of-the-art methods for the three DMO problems. We also expect our exact reformulation and optimization (ERO) framework to be applicable to a wide range of DMO problems for binary IC and beyond. Our code is available at https://github.com/sun-umn/DMO.",
      "authors": [
        "Le Peng",
        "Yash Travadi",
        "Chuan He",
        "Ying Cui",
        "and Ju Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:52:51+00:00",
          "link": "https://arxiv.org/abs/2507.15240v1",
          "size": "1216kb",
          "version": "v1"
        }
      ],
      "title": "Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15240",
        "HTML": "https://arxiv.org/html/2507.15240",
        "PDF": "https://arxiv.org/pdf/2507.15240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses optimization problems in binary imbalanced classification, focusing on precision and recall metrics. It does not relate to training data processing for LLMs or involve creation or enhancement of datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15249",
      "abstract": "In light of recent breakthroughs in text-to-image (T2I) generation, particularly with diffusion transformers (DiT), subject-driven technologies are increasingly being employed for high-fidelity customized production that preserves subject identity from reference inputs, enabling thrilling design workflows and engaging entertainment. Existing alternatives typically require either per-subject optimization via trainable text embeddings or training specialized encoders for subject feature extraction on large-scale datasets. Such dependencies on training procedures fundamentally constrain their practical applications. More importantly, current methodologies fail to fully leverage the inherent zero-shot potential of modern diffusion transformers (e.g., the Flux series) for authentic subject-driven synthesis. To bridge this gap, we propose FreeCus, a genuinely training-free framework that activates DiT's capabilities through three key innovations: 1) We introduce a pivotal attention sharing mechanism that captures the subject's layout integrity while preserving crucial editing flexibility. 2) Through a straightforward analysis of DiT's dynamic shifting, we propose an upgraded variant that significantly improves fine-grained feature extraction. 3) We further integrate advanced Multimodal Large Language Models (MLLMs) to enrich cross-modal semantic representations. Extensive experiments reflect that our method successfully unlocks DiT's zero-shot ability for consistent subject synthesis across diverse contexts, achieving state-of-the-art or comparable results compared to approaches that require additional training. Notably, our framework demonstrates seamless compatibility with existing inpainting pipelines and control modules, facilitating more compelling experiences. Our code is available at: https://github.com/Monalissaa/FreeCus.",
      "authors": [
        "Yanbing Zhang",
        "Zhe Wang",
        "Qin Zhou",
        "Mengping Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:15:45+00:00",
          "link": "https://arxiv.org/abs/2507.15249v1",
          "size": "10936kb",
          "version": "v1"
        }
      ],
      "title": "FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15249",
        "PDF": "https://arxiv.org/pdf/2507.15249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a training-free framework for diffusion transformers in text-to-image generation, focusing on methodologies for subject-driven synthesis rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15358",
      "abstract": "Understanding the impact of grid-following (GFL) converters on system frequency dynamics is crucial, from both the center of inertia (COI) and frequency spatial variation perspectives. Part I of this series clarifies the mechanisms by which GFLs influence COI frequency dynamics. A multi-generator model of the power system with GFLs is developed, incorporating the local dynamics of GFLs and their interaction with synchronous generators via virtual tie lines. By aggregating the multi-generator model into the COI frame, the interaction between the COI frequency and the equivalent frequency of GFLs is revealed. The equivalent inertia and other components at the GFL side, determined by control parameters and operating conditions, support the COI through virtual tying power. Simulation validates the accuracy of the proposed modeling and demonstrates that the impact of GFLs on COI frequency is relatively weak. The equivalent inertia and other components of GFLs still significantly influence COI frequency dynamics, with their effects being both time-variable and adjustable.",
      "authors": [
        "Jiahao Liu",
        "Cheng Wang",
        "Tianshu Bi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:09:38+00:00",
          "link": "https://arxiv.org/abs/2507.15358v1",
          "size": "9083kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part I: Center of Inertia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15358",
        "HTML": "https://arxiv.org/html/2507.15358",
        "PDF": "https://arxiv.org/pdf/2507.15358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates grid-following converters' effects on frequency dynamics in the power system, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.15129",
      "abstract": "Evolutionary Reinforcement Learning (EvoRL) has emerged as a promising approach to overcoming the limitations of traditional reinforcement learning (RL) by integrating the Evolutionary Computation (EC) paradigm with RL. However, the population-based nature of EC significantly increases computational costs, thereby restricting the exploration of algorithmic design choices and scalability in large-scale settings. To address this challenge, we introduce $\\texttt{$\\textbf{EvoRL}$}$, the first end-to-end EvoRL framework optimized for GPU acceleration. The framework executes the entire training pipeline on accelerators, including environment simulations and EC processes, leveraging hierarchical parallelism through vectorization and compilation techniques to achieve superior speed and scalability. This design enables the efficient training of large populations on a single machine. In addition to its performance-oriented design, $\\texttt{$\\textbf{EvoRL}$}$ offers a comprehensive platform for EvoRL research, encompassing implementations of traditional RL algorithms (e.g., A2C, PPO, DDPG, TD3, SAC), Evolutionary Algorithms (e.g., CMA-ES, OpenES, ARS), and hybrid EvoRL paradigms such as Evolutionary-guided RL (e.g., ERL, CEM-RL) and Population-Based AutoRL (e.g., PBT). The framework's modular architecture and user-friendly interface allow researchers to seamlessly integrate new components, customize algorithms, and conduct fair benchmarking and ablation studies. The project is open-source and available at: https://github.com/EMI-Group/evorl.",
      "authors": [
        "Bowen Zheng",
        "Ran Cheng",
        "Kay Chen Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-25T08:31:07+00:00",
          "link": "https://arxiv.org/abs/2501.15129v1",
          "size": "887kb",
          "version": "v1"
        },
        {
          "date": "2025-02-02T09:28:32+00:00",
          "link": "https://arxiv.org/abs/2501.15129v2",
          "size": "998kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T01:35:01+00:00",
          "link": "https://arxiv.org/abs/2501.15129v3",
          "size": "793kb",
          "version": "v3"
        }
      ],
      "title": "EvoRL: A GPU-accelerated Framework for Evolutionary Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15129",
        "HTML": "https://arxiv.org/html/2501.15129",
        "PDF": "https://arxiv.org/pdf/2501.15129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EvoRL is a framework for Evolutionary Reinforcement Learning; the paper discusses reinforcement learning techniques and infrastructure, not related to LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Evolutionary Algorithms",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/emi-group/evox",
        "https://github.com/emi-group/evorl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.00409",
      "abstract": "Large Language Model (LLM)-based systems, i.e. interconnected elements that include an LLM as a central component, such as conversational agents, are usually designed with monolithic, static architectures that rely on a single, general-purpose LLM to handle all user queries. However, these systems may be inefficient as different queries may require different levels of reasoning, domain knowledge or pre-processing. While generalist LLMs (e.g. GPT-4o, Claude-Sonnet) perform well across a wide range of tasks, they may incur significant financial, energy and computational costs. These costs may be disproportionate for simpler queries, resulting in unnecessary resource utilisation. A routing mechanism can therefore be employed to route queries to more appropriate components, such as smaller or specialised models, thereby improving efficiency and optimising resource consumption. This survey aims to provide a comprehensive overview of routing strategies in LLM-based systems. Specifically, it reviews when, why, and how routing should be integrated into LLM pipelines to improve efficiency, scalability, and performance. We define the objectives to optimise, such as cost minimisation and performance maximisation, and discuss the timing of routing within the LLM workflow, whether it occurs before or after generation. We also detail the various implementation strategies, including similarity-based, supervised, reinforcement learning-based, and generative methods. Practical considerations such as industrial applications and current limitations are also examined, like standardising routing experiments, accounting for non-financial costs, and designing adaptive strategies. By formalising routing as a performance-cost optimisation problem, this survey provides tools and directions to guide future research and development of adaptive low-cost LLM-based systems.",
      "authors": [
        "Clovis Varangot-Reille",
        "Christophe Bouvard",
        "Antoine Gourru",
        "Mathieu Ciancone",
        "Marion Schaeffer",
        "Fran\\c{c}ois Jacquenet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T12:08:38+00:00",
          "link": "https://arxiv.org/abs/2502.00409v1",
          "size": "589kb",
          "version": "v1"
        },
        {
          "date": "2025-02-04T09:12:03+00:00",
          "link": "https://arxiv.org/abs/2502.00409v2",
          "size": "589kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T12:20:06+00:00",
          "link": "https://arxiv.org/abs/2502.00409v3",
          "size": "272kb",
          "version": "v3"
        }
      ],
      "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00409",
        "HTML": "https://arxiv.org/html/2502.00409",
        "PDF": "https://arxiv.org/pdf/2502.00409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey covers routing strategies to optimize resource use in LLM-based systems. The focus is on system efficiency and scalability rather than data processing or quality enhancement for LLM training data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14189",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various applications. However, their use as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowledge and a tendency to hallucinate. Existing solutions, such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency across multiple retrieval steps, while online search-based methods often degrade quality due to unreliable web content. To address these challenges, we introduce DeepWriter, a customizable, multimodal, long-form writing assistant that operates on a curated, offline knowledge base. DeepWriter leverages a novel pipeline that involves task decomposition, outline generation, multimodal retrieval, and section-by-section composition with reflection. By deeply mining information from a structured corpus and incorporating both textual and visual elements, DeepWriter generates coherent, factually grounded, and professional-grade documents. We also propose a hierarchical knowledge representation to enhance retrieval efficiency and accuracy. Our experiments on financial report generation demonstrate that DeepWriter produces high-quality, verifiable articles that surpasses existing baselines in factual accuracy and generated content quality.",
      "authors": [
        "Song Mao",
        "Lejun Cheng",
        "Pinlong Cai",
        "Guohang Yan",
        "Ding Wang",
        "Botian Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.14189v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14189",
        "HTML": "https://arxiv.org/html/2507.14189",
        "PDF": "https://arxiv.org/pdf/2507.14189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While DeepWriter deals with multimodal writing assistance and utilizes a curated knowledge base, it does not contribute to the processing of training data for LLMs, focusing instead on writing applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14851",
      "abstract": "In this work, we propose an all-in-one video restoration framework that grounds degradation-aware semantic context of video frames in natural language via foundation models, offering interpretable and flexible guidance. Unlike prior art, our method assumes no degradation knowledge in train or test time and learns an approximation to the grounded knowledge such that the foundation model can be safely disentangled during inference adding no extra cost. Further, we call for standardization of benchmarks in all-in-one video restoration, and propose two benchmarks in multi-degradation setting, three-task (3D) and four-task (4D), and two time-varying composite degradation benchmarks; one of the latter being our proposed dataset with varying snow intensity, simulating how weather degradations affect videos naturally. We compare our method with prior works and report state-of-the-art performance on all benchmarks.",
      "authors": [
        "Muhammad Kamran Janjua",
        "Amirhosein Ghasemabadi",
        "Kunlin Zhang",
        "Mohammad Salameh",
        "Chao Gao",
        "Di Niu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:43:33+00:00",
          "link": "https://arxiv.org/abs/2507.14851v1",
          "size": "4883kb",
          "version": "v1"
        }
      ],
      "title": "Grounding Degradations in Natural Language for All-In-One Video Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14851",
        "HTML": "https://arxiv.org/html/2507.14851",
        "PDF": "https://arxiv.org/pdf/2507.14851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on video restoration using natural language grounding through foundation models, without any discussion on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14924",
      "abstract": "Accurate pose estimation and shift correction are key challenges in cryo-EM due to the very low SNR, which directly impacts the fidelity of 3D reconstructions. We present an approach for pose estimation in cryo-EM that leverages multi-dimensional scaling (MDS) techniques in a robust manner to estimate the 3D rotation matrix of each particle from pairs of dihedral angles. We express the rotation matrix in the form of an axis of rotation and a unit vector in the plane perpendicular to the axis. The technique leverages the concept of common lines in 3D reconstruction from projections. However, common line estimation is ridden with large errors due to the very low SNR of cryo-EM projection images. To address this challenge, we introduce two complementary components: (i) a robust joint optimization framework for pose estimation based on an $\\ell_1$-norm objective or a similar robust norm, which simultaneously estimates rotation axes and in-plane vectors while exactly enforcing unit norm and orthogonality constraints via projected coordinate descent; and (ii) an iterative shift correction algorithm that estimates consistent in-plane translations through a global least-squares formulation. While prior approaches have leveraged such embeddings and common-line geometry for orientation recovery, existing formulations typically rely on $\\ell_2$-based objectives that are sensitive to noise, and enforce geometric constraints only approximately. These choices, combined with a sequential pipeline structure, can lead to compounding errors and suboptimal reconstructions in low-SNR regimes. Our pipeline consistently outperforms prior methods in both Euler angle accuracy and reconstruction fidelity, as measured by the Fourier Shell Correlation (FSC).",
      "authors": [
        "Kaishva Chintan Shah",
        "Virajith Boddapati",
        "Karthik S. Gurumoorthy",
        "Sandip Kaledhonkar",
        "Ajit Rajwade"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:46:17+00:00",
          "link": "https://arxiv.org/abs/2507.14924v1",
          "size": "9417kb",
          "version": "v1"
        }
      ],
      "title": "3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14924",
        "HTML": "https://arxiv.org/html/2507.14924",
        "PDF": "https://arxiv.org/pdf/2507.14924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses pose estimation and shift correction in cryo-EM for 3D reconstructions, which is not related to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15241",
      "abstract": "Despite the critical threat posed by software security vulnerabilities, reports are often incomplete, lacking the proof-of-vulnerability (PoV) tests needed to validate fixes and prevent regressions. These tests are crucial not only for ensuring patches work, but also for helping developers understand how vulnerabilities can be exploited. Generating PoV tests is a challenging problem, requiring reasoning about the flow of control and data through deeply nested levels of a program.\n  We present FaultLine, an LLM agent workflow that uses a set of carefully designed reasoning steps, inspired by aspects of traditional static and dynamic program analysis, to automatically generate PoV test cases. Given a software project with an accompanying vulnerability report, FaultLine 1) traces the flow of an input from an externally accessible API (\"source\") to the \"sink\" corresponding to the vulnerability, 2) reasons about the conditions that an input must satisfy in order to traverse the branch conditions encountered along the flow, and 3) uses this reasoning to generate a PoV test case in a feedback-driven loop. FaultLine does not use language-specific static or dynamic analysis components, which enables it to be used across programming languages.\n  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100 known vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine is able to generate PoV tests for 16 projects, compared to just 9 for CodeAct 2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine represents a 77% relative improvement over the state of the art. Our findings suggest that hierarchical reasoning can enhance the performance of LLM agents on PoV test generation, but the problem in general remains challenging. We make our code and dataset publicly available in the hope that it will spur further research in this area.",
      "authors": [
        "Vikram Nitin",
        "Baishakhi Ray",
        "Roshanak Zilouchian Moghaddam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:55:34+00:00",
          "link": "https://arxiv.org/abs/2507.15241v1",
          "size": "958kb",
          "version": "v1"
        }
      ],
      "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15241",
        "HTML": "https://arxiv.org/html/2507.15241",
        "PDF": "https://arxiv.org/pdf/2507.15241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating proof-of-vulnerability tests using LLM agents for software security, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15683",
      "abstract": "Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera pose from query images, is fundamental to remote sensing and UAV applications. Existing methods face inherent trade-offs: image-based retrieval and pose regression approaches lack precision, while structure-based methods that register queries to Structure-from-Motion (SfM) models suffer from computational complexity and limited scalability. These challenges are particularly pronounced in remote sensing scenarios due to large-scale scenes, high altitude variations, and domain gaps of existing visual priors. To overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel scene representation that compactly encodes both 3D geometry and appearance. We introduce $\\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting the rich semantic information and geometric constraints inherent in Gaussian primitives. To handle large-scale remote sensing scenarios, we incorporate partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic memory management strategies. Our approach consists of two stages: (1) a sparse stage featuring a Gaussian-specific consistent render-aware sampling strategy and landmark-guided detector for robust and accurate initial pose estimation, and (2) a dense stage that iteratively refines poses through coarse-to-fine dense rasterization matching while incorporating reliability verification. Through comprehensive evaluation on simulation data, public datasets, and real flight experiments, we demonstrate that our method delivers competitive localization accuracy, recall rate, and computational efficiency while effectively filtering unreliable pose estimates. The results confirm the effectiveness of our approach for practical remote sensing applications.",
      "authors": [
        "Boni Hu",
        "Zhenyu Xia",
        "Lin Chen",
        "Pengcheng Han and Shuhui Bu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:47:56+00:00",
          "link": "https://arxiv.org/abs/2507.15683v1",
          "size": "12662kb",
          "version": "v1"
        }
      ],
      "title": "Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15683",
        "HTML": "https://arxiv.org/html/2507.15683",
        "PDF": "https://arxiv.org/pdf/2507.15683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a visual relocalization framework for remote sensing, focusing on camera pose estimation and not related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.17249",
      "abstract": "This paper develops a real-time decentralized metric-semantic SLAM algorithm that enables a heterogeneous robot team to collaboratively construct object-based metric-semantic maps. The proposed framework integrates a data-driven front-end for instance segmentation from either RGBD cameras or LiDARs and a custom back-end for optimizing robot trajectories and object landmarks in the map. To allow multiple robots to merge their information, we design semantics-driven place recognition algorithms that leverage the informativeness and viewpoint invariance of the object-level metric-semantic map for inter-robot loop closure detection. A communication module is designed to track each robot's observations and those of other robots whenever communication links are available. The framework supports real-time, decentralized operation onboard the robots and has been integrated with three types of aerial and ground platforms. We validate its effectiveness through experiments in both indoor and outdoor environments, as well as benchmarks on public datasets and comparisons with existing methods. The framework is open-sourced and suitable for both single-agent and multi-robot real-time metric-semantic SLAM applications. The code is available at: https://github.com/KumarRobotics/SLIDE_SLAM.",
      "authors": [
        "Xu Liu",
        "Jiuzhou Lei",
        "Ankit Prabhu",
        "Yuezhan Tao",
        "Igor Spasojevic",
        "Pratik Chaudhari",
        "Nikolay Atanasov",
        "Vijay Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T03:34:02+00:00",
          "link": "https://arxiv.org/abs/2406.17249v1",
          "size": "27656kb",
          "version": "v1"
        },
        {
          "date": "2024-07-02T21:08:35+00:00",
          "link": "https://arxiv.org/abs/2406.17249v2",
          "size": "41542kb",
          "version": "v2"
        },
        {
          "date": "2024-07-25T16:56:40+00:00",
          "link": "https://arxiv.org/abs/2406.17249v3",
          "size": "43727kb",
          "version": "v3"
        },
        {
          "date": "2024-11-29T06:30:05+00:00",
          "link": "https://arxiv.org/abs/2406.17249v4",
          "size": "44301kb",
          "version": "v4"
        },
        {
          "date": "2024-12-25T04:44:01+00:00",
          "link": "https://arxiv.org/abs/2406.17249v5",
          "size": "41667kb",
          "version": "v5"
        },
        {
          "date": "2025-07-19T16:37:29+00:00",
          "link": "https://arxiv.org/abs/2406.17249v6",
          "size": "31060kb",
          "version": "v6"
        }
      ],
      "title": "SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17249",
        "HTML": "https://arxiv.org/html/2406.17249",
        "PDF": "https://arxiv.org/pdf/2406.17249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a SLAM algorithm for multi-robot navigation, focusing on decentralized map construction and information merging across robots. It does not involve LLM training data processing or creating datasets related to LLMs."
      },
      "repo_urls": [
        "https://github.com/xurobotics/slide_slam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14662",
      "abstract": "Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a data fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality.",
      "authors": [
        "Mathieu Besan\\c{c}on"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T17:35:07+00:00",
          "link": "https://arxiv.org/abs/2501.14662v1",
          "size": "1657kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T08:52:08+00:00",
          "link": "https://arxiv.org/abs/2501.14662v2",
          "size": "1658kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T06:58:08+00:00",
          "link": "https://arxiv.org/abs/2501.14662v3",
          "size": "1658kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T15:30:13+00:00",
          "link": "https://arxiv.org/abs/2501.14662v4",
          "size": "694kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T09:07:34+00:00",
          "link": "https://arxiv.org/abs/2501.14662v5",
          "size": "694kb",
          "version": "v5"
        }
      ],
      "title": "Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14662",
        "HTML": "https://arxiv.org/html/2501.14662",
        "PDF": "https://arxiv.org/pdf/2501.14662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses Sparse Flow Decomposition in operations research and bioinformatics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.17786",
      "abstract": "Graph representation learning is effective for obtaining a meaningful latent space utilizing the structure of graph data and is widely applied, including biological networks. In particular, Graph Contrastive Learning (GCL) has emerged as a powerful self-supervised method that relies on applying perturbations to graphs for data augmentation. However, when applying existing GCL methods to biological networks such as Gene Regulatory Networks (GRNs), they overlooked meaningful biologically relevant perturbations, e.g., gene knockdowns. In this study, we introduce SupGCL (Supervised Graph Contrastive Learning), a novel GCL method for GRNs that directly incorporates biological perturbations derived from gene knockdown experiments as the supervision. SupGCL mathematically extends existing GCL methods that utilize non-biological perturbations to probabilistic models that introduce actual biological gene perturbation utilizing gene knockdown data. Using the GRN representation obtained by our proposed method, our aim is to improve the performance of biological downstream tasks such as patient hazard prediction and disease subtype classification (graph-level task), and gene function classification (node-level task). We applied SupGCL on real GRN datasets derived from patients with multiple types of cancer, and in all experiments SupGCL achieves better performance than state-of-the-art baselines.",
      "authors": [
        "Sho Oshima",
        "Yuji Okamoto",
        "Taisei Tosaki",
        "Ryosuke Kojima",
        "Yasushi Okuno"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T11:59:35+00:00",
          "link": "https://arxiv.org/abs/2505.17786v1",
          "size": "20491kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T09:50:34+00:00",
          "link": "https://arxiv.org/abs/2505.17786v2",
          "size": "10554kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T21:19:01+00:00",
          "link": "https://arxiv.org/abs/2505.17786v3",
          "size": "21108kb",
          "version": "v3"
        }
      ],
      "title": "Supervised Graph Contrastive Learning for Gene Regulatory Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17786",
        "HTML": "https://arxiv.org/html/2505.17786",
        "PDF": "https://arxiv.org/pdf/2505.17786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers around graph contrastive learning applied to gene regulatory networks. It does not relate to any aspect of LLM training data processing; its focus is on biological data and graph learning."
      },
      "tasks": [
        "Contrastive Learning",
        "Data Augmentation",
        "Graph Representation Learning",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14430",
      "abstract": "Large language models (LLMs) have recently achieved significant advances in reasoning and demonstrated their advantages in solving challenging problems. Yet, their effectiveness in the semiconductor display industry remains limited due to a lack of domain-specific training and expertise. To bridge this gap, we present X-Intelligence 3.0, the first high-performance reasoning model specifically developed for the semiconductor display industry. This model is designed to deliver expert-level understanding and reasoning for the industry's complex challenges. Leveraging a carefully curated industry knowledge base, the model undergoes supervised fine-tuning and reinforcement learning to enhance its reasoning and comprehension capabilities. To further accelerate development, we implemented an automated evaluation framework that simulates expert-level assessments. We also integrated a domain-specific retrieval-augmented generation (RAG) mechanism, resulting in notable performance gains on benchmark datasets. Despite its relatively compact size of 32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B across multiple evaluations. This demonstrates its exceptional efficiency and establishes it as a powerful solution to the longstanding reasoning challenges faced by the semiconductor display industry.",
      "authors": [
        "Xiaolin Yan",
        "Yangxing Liu",
        "Jiazhang Zheng",
        "Chi Liu",
        "Mingyu Du",
        "Caisheng Chen",
        "Haoyang Liu",
        "Ming Ding",
        "Yuan Li",
        "Qiuping Liao",
        "Linfeng Li",
        "Zhili Mei",
        "Siyu Wan",
        "Li Li",
        "Ruyi Zhong",
        "Jiangling Yu",
        "Xule Liu",
        "Huihui Hu",
        "Jiameng Yue",
        "Ruohui Cheng",
        "Qi Yang",
        "Liangqing Wu",
        "Ke Zhu",
        "Chi Zhang",
        "Chufei Jing",
        "Yifan Zhou",
        "Yan Liang",
        "Dongdong Li",
        "Zhaohui Wang",
        "Bin Zhao",
        "Mingzhou Wu",
        "Mingzhong Zhou",
        "Peng Du",
        "Zuomin Liao",
        "Chao Dai",
        "Pengfei Liang",
        "Xiaoguang Zhu",
        "Yu Zhang",
        "Yu Gu",
        "Kun Pan",
        "Yuan Wu",
        "Yanqing Guan",
        "Shaojing Wu",
        "Zikang Feng",
        "Xianze Ma",
        "Peishan Cheng",
        "Wenjuan Jiang",
        "Jing Ba",
        "Huihao Yu",
        "Zeping Hu",
        "Yuan Xu",
        "Zhiwei Liu",
        "He Wang",
        "Zhenguo Lin",
        "Ming Liu",
        "Yanhong Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T01:20:39+00:00",
          "link": "https://arxiv.org/abs/2507.14430v1",
          "size": "1297kb",
          "version": "v1"
        }
      ],
      "title": "X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14430",
        "HTML": "https://arxiv.org/html/2507.14430",
        "PDF": "https://arxiv.org/pdf/2507.14430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses X-Intelligence 3.0, incorporating supervised fine-tuning and reinforcement learning with a domain-specific knowledge base for the semiconductor industry. While it mentions the use of a curated dataset, the main focus is on model performance and evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14820",
      "abstract": "High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation to serve as a basic function. Previous approaches either directly generate grasps from point-cloud data, suffering from challenges with small objects and sensor noise, or infer 3D information from RGB images, which introduces expensive annotation requirements and discretization issues. Recent methods mitigate some challenges by retaining a 2D representation to estimate grasp keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF poses. However, these methods are limited by their non-differentiable nature and reliance solely on 2D supervision, which hinders the full exploitation of rich 3D information. In this work, we present KGN-Pro, a novel grasping network that preserves the efficiency and fine-grained object grasping of previous KGNs while integrating direct 3D optimization through probabilistic PnP layers. KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further outputs a 2D confidence map to weight keypoint contributions during re-projection error minimization. By modeling the weighted sum of squared re-projection errors probabilistically, the network effectively transmits 3D supervision to its 2D keypoint predictions, enabling end-to-end learning. Experiments on both simulated and real-world platforms demonstrate that KGN-Pro outperforms existing methods in terms of grasp cover rate and success rate.",
      "authors": [
        "Bingran Chen",
        "Baorun Li",
        "Jian Yang",
        "Yong Liu",
        "and Guangyao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.14820v1",
          "size": "2440kb",
          "version": "v1"
        }
      ],
      "title": "KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14820",
        "HTML": "https://arxiv.org/html/2507.14820",
        "PDF": "https://arxiv.org/pdf/2507.14820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presents a novel grasping network for robotic manipulation using probabilistic 2D-3D correspondence learning. It does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15850",
      "abstract": "Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growth of Arabic LLM research in these essential but underrepresented areas.",
      "authors": [
        "Basma El Amel Boussaha",
        "Leen AlQadi",
        "Mugariya Farooq",
        "Shaikha Alsuwaidi",
        "Giulia Campesan",
        "Ahmed Alzubaidi",
        "Mohammed Alyafeai",
        "Hakim Hacid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:58:27+00:00",
          "link": "https://arxiv.org/abs/2507.15850v1",
          "size": "1481kb",
          "version": "v1"
        }
      ],
      "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15850",
        "PDF": "https://arxiv.org/pdf/2507.15850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to LLM training data processing by releasing 3LM, a suite of benchmarks for Arabic STEM and code tasks. This involves creating new datasets that fill a gap in LLM research, specifically catering to underrepresented areas."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19643",
      "abstract": "This paper presents the concept, design, channel modeling, beamforming algorithm development, prototype fabrication, and experimental measurement of an electromagnetically reconfigurable fluid antenna system (ER-FAS), in which each FAS array element features electromagnetic (EM) reconfigurability. Unlike most existing FAS works that investigate spatial reconfigurability by adjusting the position and/or orientation of array elements, the proposed ER-FAS enables direct control over the EM characteristics of each element, allowing for dynamic radiation pattern reconfigurability. Specifically, a novel ER-FAS architecture leveraging software-controlled fluidics is proposed, and corresponding wireless channel models are established. Based on this ER-FAS channel model, a low-complexity greedy beamforming algorithm is developed to jointly optimize the analog phase shift and the radiation state of each array element. The accuracy of the ER-FAS channel model and the effectiveness of the beamforming algorithm are validated through (i) full-wave EM simulations and (ii) numerical spectral efficiency evaluations. These results confirm that the proposed ER-FAS significantly enhances spectral efficiency in both near-field and far-field scenarios compared to conventional antenna arrays. To further validate this design, we fabricate prototypes for both the ER-FAS element and array, using Galinstan liquid metal alloy, fluid silver paste, and software-controlled fluidic channels. The simulation results are experimentally validated through prototype measurements conducted in an anechoic chamber. Additionally, several indoor communication experiments using a pair of software-defined radios demonstrate the superior received power and bit error rate performance of the ER-FAS prototype.",
      "authors": [
        "Ruiqi Wang",
        "Pinjun Zheng",
        "Vijith Varma Kotte",
        "Sakandar Rauf",
        "Yiming Yang",
        "Muhammad Mahboob Ur Rahman",
        "Tareq Y. Al-Naffouri",
        "Atif Shamim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T00:27:25+00:00",
          "link": "https://arxiv.org/abs/2502.19643v1",
          "size": "4317kb",
          "version": "v1"
        },
        {
          "date": "2025-03-01T22:31:12+00:00",
          "link": "https://arxiv.org/abs/2502.19643v2",
          "size": "9121kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T19:28:03+00:00",
          "link": "https://arxiv.org/abs/2502.19643v3",
          "size": "6201kb",
          "version": "v3"
        }
      ],
      "title": "Electromagnetically Reconfigurable Fluid Antenna System for Wireless Communications: Design, Modeling, Algorithm, Fabrication, and Experiment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19643",
        "PDF": "https://arxiv.org/pdf/2502.19643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the design and testing of an electromagnetic fluid antenna system for wireless communications, which is unrelated to any aspect of LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14156",
      "abstract": "The recent breakthrough of AlphaFold3 in modeling complex biomolecular interactions, including those between proteins and ligands, nucleotides, or metal ions, creates new opportunities for protein design. In so-called inverse protein folding, the objective is to find a sequence of amino acids that adopts a target protein structure. Many inverse folding methods struggle to predict sequences for complexes that contain non-protein components, and perform poorly with complexes that adopt multiple structural states. To address these challenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein folding), a generative model based on discrete flow-matching for designing protein sequences conditioned on all-atom structural contexts. ADFLIP progressively incorporates predicted amino acid side chains as structural context during sequence generation and enables the design of dynamic protein complexes through ensemble sampling across multiple structural states. Furthermore, ADFLIP implements training-free classifier guidance sampling, which allows the incorporation of arbitrary pre-trained models to optimise the designed sequence for desired protein properties. We evaluated the performance of ADFLIP on protein complexes with small-molecule ligands, nucleotides, or metal ions, including dynamic complexes for which structure ensembles were determined by nuclear magnetic resonance (NMR). Our model achieves state-of-the-art performance in single-structure and multi-structure inverse folding tasks, demonstrating excellent potential for all-atom protein design. The code is available at https://github.com/ykiiiiii/ADFLIP.",
      "authors": [
        "Kai Yi and Kiarash Jamali and Sjors H. W. Scheres"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T11:57:38+00:00",
          "link": "https://arxiv.org/abs/2507.14156v1",
          "size": "2535kb",
          "version": "v1"
        }
      ],
      "title": "All-atom inverse protein folding through discrete flow matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14156",
        "HTML": "https://arxiv.org/html/2507.14156",
        "PDF": "https://arxiv.org/pdf/2507.14156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a generative model for inverse protein folding using discrete flow matching, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14194",
      "abstract": "This paper presents a novel framework for pattern prediction and system prognostics centered on Spatiotemporal Permutation Entropy analysis integrated with Boosted Enhanced Quantile Regression Neural Networks (BEQRNNs). We address the challenge of understanding complex dynamical patterns in multidimensional systems through an approach that combines entropy-based complexity measures with advanced neural architectures. The system leverages dual computational stages: first implementing spatiotemporal entropy extraction optimized for multiscale temporal and spatial data streams, followed by an integrated BEQRNN layer that enables probabilistic pattern prediction with uncertainty quantification. This architecture achieves 81.17% accuracy in spatiotemporal pattern classification with prediction horizons up to 200 time steps and maintains robust performance across diverse regimes. Field testing across chaotic attractors, reaction-diffusion systems, and industrial datasets shows a 79% increase in critical transition detection accuracy and 81.22% improvement in long-term prediction reliability. The framework's effectiveness in processing complex, multimodal entropy features demonstrates significant potential for real-time prognostic applications.",
      "authors": [
        "David J Poland"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:19:19+00:00",
          "link": "https://arxiv.org/abs/2507.14194v1",
          "size": "516kb",
          "version": "v1"
        }
      ],
      "title": "Boosted Enhanced Quantile Regression Neural Networks with Spatiotemporal Permutation Entropy for Complex System Prognostics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14194",
        "HTML": "https://arxiv.org/html/2507.14194",
        "PDF": "https://arxiv.org/pdf/2507.14194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a complex system prognostic framework utilizing Spatiotemporal Permutation Entropy and neural networks, with no contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14649",
      "abstract": "Despite the outstanding performance of large language models (LLMs) across various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate responses--remains as a critical problem as it can be directly connected to a crisis of building safe and reliable LLMs. Uncertainty estimation is primarily used to measure hallucination levels in LLM responses so that correct and incorrect answers can be distinguished clearly. This study proposes an effective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based sem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse quantifies the uncertainty with the proportion of the intra-cluster consistency in the total consistency between LLM hidden embeddings which contain adequate semantic information of generations, by employing clustering. The effectiveness of Cleanse for detecting hallucination is validated using four off-the-shelf models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two question-answering benchmarks, SQuAD and CoQA.",
      "authors": [
        "Minsuh Joo",
        "Hyunsoo Cho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:48:24+00:00",
          "link": "https://arxiv.org/abs/2507.14649v1",
          "size": "916kb",
          "version": "v1"
        }
      ],
      "title": "Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14649",
        "HTML": "https://arxiv.org/html/2507.14649",
        "PDF": "https://arxiv.org/pdf/2507.14649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses uncertainty estimation and detecting hallucinations in LLMs, without addressing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15314",
      "abstract": "This application-oriented study concerns computational musicology, which makes use of grammar systems. We define multi-generative rule-synchronized scattered-context grammar systems (without erasing rules) and demonstrates how to simultaneously make the arrangement of a musical composition for performance by a whole orchestra, consisting of several instruments. Primarily, an orchestration like this is illustrated by examples in terms of classical music. In addition, the orchestration of jazz compositions is sketched as well. The study concludes its discussion by suggesting five open problem areas related to this way of orchestration.",
      "authors": [
        "Jozef Maki\\v{s} (Faculty of Information Technology",
        "Brno University of Technology)",
        "Alexander Meduna (Faculty of Information Technology",
        "Brno University of Technology)",
        "Zbyn\\v{e}k K\\v{r}ivka (Faculty of Information Technology",
        "Brno University of Technology)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:15:00+00:00",
          "link": "https://arxiv.org/abs/2507.15314v1",
          "size": "309kb",
          "version": "v1"
        }
      ],
      "title": "Orchestration of Music by Grammar Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15314",
        "PDF": "https://arxiv.org/pdf/2507.15314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses computational musicology through grammar systems, which are not connected to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15465",
      "abstract": "Computational workloads composing traditional Transformer models are starkly bifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic intensity, while feedforward layers are compute-bound. This dichotomy has long motivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent Attention (MLA) and Mixture-of-Experts (MoE), challenge the premise of specialized attention hardware. We make two key observations. First, the arithmetic intensity of MLA is over two orders of magnitude greater than that of MHA, shifting it close to a compute-bound regime well-suited for modern accelerators like GPUs. Second, by distributing MoE experts across a pool of accelerators, their arithmetic intensity can be tuned through batching to match that of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware. The central challenge for next-generation Transformers is no longer accelerating a single memory-bound layer. Instead, the focus must shift to designing balanced systems with sufficient compute, memory capacity, memory bandwidth, and high-bandwidth interconnects to manage the diverse demands of large-scale models.",
      "authors": [
        "Sungmin Yun and Seonyong Park and Hwayong Nam and Younjoo Lee and Gunjun Lee and Kwanhee Kyung and Sangpyo Kim and Nam Sung Kim and Jongmin Kim and Hyungyo Kim and Juhwan Cho and Seungmin Baek and Jung Ho Ahn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:18:33+00:00",
          "link": "https://arxiv.org/abs/2507.15465v1",
          "size": "1282kb",
          "version": "v1"
        }
      ],
      "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15465",
        "HTML": "https://arxiv.org/html/2507.15465",
        "PDF": "https://arxiv.org/pdf/2507.15465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses architectural and computational aspects of LLMs, it does not address any issues related to training data processing, but rather focuses on hardware and computational workload considerations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15748",
      "abstract": "Modern camera pipelines apply extensive on-device processing, such as exposure adjustment, white balance, and color correction, which, while beneficial individually, often introduce photometric inconsistencies across views. These appearance variations violate multi-view consistency and degrade the quality of novel view synthesis. Joint optimization of scene representations and per-image appearance embeddings has been proposed to address this issue, but at the cost of increased computational complexity and slower training. In this work, we propose a transformer-based method that predicts spatially adaptive bilateral grids to correct photometric variations in a multi-view consistent manner, enabling robust cross-scene generalization without the need for scene-specific retraining. By incorporating the learned grids into the 3D Gaussian Splatting pipeline, we improve reconstruction quality while maintaining high training efficiency. Extensive experiments show that our approach outperforms or matches existing scene-specific optimization methods in reconstruction fidelity and convergence speed.",
      "authors": [
        "Jisu Shin",
        "Richard Shaw",
        "Seunghyun Shin",
        "Anton Pelykh",
        "Zhensong Zhang",
        "Hae-Gon Jeon",
        "Eduardo Perez-Pellitero"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:03:58+00:00",
          "link": "https://arxiv.org/abs/2507.15748v1",
          "size": "17240kb",
          "version": "v1"
        }
      ],
      "title": "Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15748",
        "HTML": "https://arxiv.org/html/2507.15748",
        "PDF": "https://arxiv.org/pdf/2507.15748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on photometric correction for 3D view synthesis using transformers, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15752",
      "abstract": "Collecting human-chatbot dialogues typically demands substantial manual effort and is time-consuming, which limits and poses challenges for research on conversational AI. In this work, we propose DialogueForge - a framework for generating AI-simulated conversations in human-chatbot style. To initialize each generated conversation, DialogueForge uses seed prompts extracted from real human-chatbot interactions. We test a variety of LLMs to simulate the human chatbot user, ranging from state-of-the-art proprietary models to small-scale open-source LLMs, and generate multi-turn dialogues tailored to specific tasks. In addition, we explore fine-tuning techniques to enhance the ability of smaller models to produce indistinguishable human-like dialogues. We evaluate the quality of the simulated conversations and compare different models using the UniEval and GTEval evaluation protocols. Our experiments show that large proprietary models (e.g., GPT-4o) generally outperform others in generating more realistic dialogues, while smaller open-source models (e.g., Llama, Mistral) offer promising performance with greater customization. We demonstrate that the performance of smaller models can be significantly improved by employing supervised fine-tuning techniques. Nevertheless, maintaining coherent and natural long-form human-like dialogues remains a common challenge across all models.",
      "authors": [
        "Ruizhe Zhu",
        "Hao Zhu",
        "Yaxuan Li",
        "Syang Zhou",
        "Shijing Cai",
        "Malgorzata Lazuka",
        "Elliott Ash"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:08:19+00:00",
          "link": "https://arxiv.org/abs/2507.15752v1",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15752",
        "HTML": "https://arxiv.org/html/2507.15752",
        "PDF": "https://arxiv.org/pdf/2507.15752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents DialogueForge, a framework for generating AI-simulated conversations to reduce the effort involved in collecting human-chatbot dialogues. It also involves fine-tuning for smaller models, making a significant contribution to generating training data for LLM fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15776",
      "abstract": "Parr et al., 2025 examines how auto-regressive and deep temporal models differ in their treatment of non-Markovian sequence modelling. Building on this, we highlight the need for dissociating model architectures, i.e., how the predictive distribution factorises, from the computations invoked at inference. We demonstrate that deep temporal computations are mimicked by autoregressive models by structuring context access during iterative inference. Using a transformer trained on next-token prediction, we show that inducing hierarchical temporal factorisation during iterative inference maintains predictive capacity while instantiating fewer computations. This emphasises that processes for constructing and refining predictions are not necessarily bound to their underlying model architectures.",
      "authors": [
        "Noor Sajid",
        "Johan Medrano"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:30:42+00:00",
          "link": "https://arxiv.org/abs/2507.15776v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Dissociating model architectures from inference computations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15776",
        "HTML": "https://arxiv.org/html/2507.15776",
        "PDF": "https://arxiv.org/pdf/2507.15776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the separation of model architectures from inference computations, primarily discussing model functionality rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08771",
      "abstract": "We analyze a distributed algorithm to compute a low-rank matrix factorization on $N$ clients, each holding a local dataset $\\mathbf{S}^i \\in \\mathbb{R}^{n_i \\times d}$, mathematically, we seek to solve $min_{\\mathbf{U}^i \\in \\mathbb{R}^{n_i\\times r}, \\mathbf{V}\\in \\mathbb{R}^{d \\times r} } \\frac{1}{2} \\sum_{i=1}^N \\|\\mathbf{S}^i - \\mathbf{U}^i \\mathbf{V}^\\top\\|^2_{\\text{F}}$. Considering a power initialization of $\\mathbf{V}$, we rewrite the previous smooth non-convex problem into a smooth strongly-convex problem that we solve using a parallel Nesterov gradient descent potentially requiring a single step of communication at the initialization step. For any client $i$ in $\\{1, \\dots, N\\}$, we obtain a global $\\mathbf{V}$ in $\\mathbb{R}^{d \\times r}$ common to all clients and a local variable $\\mathbf{U}^i$ in $\\mathbb{R}^{n_i \\times r}$. We provide a linear rate of convergence of the excess loss which depends on $\\sigma_{\\max} / \\sigma_{r}$, where $\\sigma_{r}$ is the $r^{\\mathrm{th}}$ singular value of the concatenation $\\mathbf{S}$ of the matrices $(\\mathbf{S}^i)_{i=1}^N$. This result improves the rates of convergence given in the literature, which depend on $\\sigma_{\\max}^2 / \\sigma_{\\min}^2$. We provide an upper bound on the Frobenius-norm error of reconstruction under the power initialization strategy. We complete our analysis with experiments on both synthetic and real data.",
      "authors": [
        "Constantin Philippenko",
        "Kevin Scaman",
        "Laurent Massouli\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T12:28:42+00:00",
          "link": "https://arxiv.org/abs/2409.08771v1",
          "size": "1369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:57:56+00:00",
          "link": "https://arxiv.org/abs/2409.08771v2",
          "size": "557kb",
          "version": "v2"
        }
      ],
      "title": "In-depth Analysis of Low-rank Matrix Factorisation in a Federated Setting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08771",
        "HTML": "https://arxiv.org/html/2409.08771",
        "PDF": "https://arxiv.org/pdf/2409.08771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines low-rank matrix factorization in federated settings, focusing on algorithmic optimization rather than data processing specific to LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/philipco/matrix_factorization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16644",
      "abstract": "Traditional numerical methods, such as the finite element method and finite volume method, adress partial differential equations (PDEs) by discretizing them into algebraic equations and solving these iteratively. However, this process is often computationally expensive and time-consuming. An alternative approach involves transforming PDEs into integral equations and solving them using Green's functions, which provide analytical solutions. Nevertheless, deriving Green's functions analytically is a challenging and non-trivial task, particularly for complex systems. In this study, we introduce a novel framework, termed GreensONet, which is constructed based on the strucutre of deep operator networks (DeepONet) to learn embedded Green's functions and solve PDEs via Green's integral formulation. Specifically, the Trunk Net within GreensONet is designed to approximate the unknown Green's functions of the system, while the Branch Net are utilized to approximate the auxiliary gradients of the Green's function. These outputs are subsequently employed to perform surface integrals and volume integrals, incorporating user-defined boundary conditions and source terms, respectively. The effectiveness of the proposed framework is demonstrated on three types of PDEs in bounded domains: 3D heat conduction equations, reaction-diffusion equations, and Stokes equations. Comparative results in these cases demonstrate that GreenONet's accuracy and generalization ability surpass those of existing methods, including Physics-Informed Neural Networks (PINN), DeepONet, Physics-Informed DeepONet (PI-DeepONet), and Fourier Neural Operators (FNO).",
      "authors": [
        "Jianghang Gu",
        "Ling Wen",
        "Yuntian Chen",
        "Shiyi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T14:31:03+00:00",
          "link": "https://arxiv.org/abs/2412.16644v1",
          "size": "19831kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T06:44:40+00:00",
          "link": "https://arxiv.org/abs/2412.16644v2",
          "size": "12235kb",
          "version": "v2"
        }
      ],
      "title": "An explainable operator approximation framework under the guideline of Green's function",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16644",
        "HTML": "https://arxiv.org/html/2412.16644",
        "PDF": "https://arxiv.org/pdf/2412.16644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for learning Green's functions to solve PDEs, which is unrelated to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/hangjianggu/greensonet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01781",
      "abstract": "We investigate the robustness of reasoning models trained for step-by-step problem solving by introducing query-agnostic adversarial triggers - short, irrelevant text that, when appended to math problems, systematically mislead models to output incorrect answers without altering the problem's semantics. We propose CatAttack, an automated iterative attack pipeline for generating triggers on a weaker, less expensive proxy model (DeepSeek V3) and successfully transfer them to more advanced reasoning target models like DeepSeek R1 and DeepSeek R1-distilled-Qwen-32B, resulting in greater than 300% increase in the likelihood of the target model generating an incorrect answer. For example, appending, \"Interesting fact: cats sleep most of their lives,\" to any math problem leads to more than doubling the chances of a model getting the answer wrong. Our findings highlight critical vulnerabilities in reasoning models, revealing that even state-of-the-art models remain susceptible to subtle adversarial inputs, raising security and reliability concerns. The CatAttack triggers dataset with model responses is available at https://huggingface.co/datasets/collinear-ai/cat-attack-adversarial-triggers.",
      "authors": [
        "Meghana Rajeev",
        "Rajkumar Ramamurthy",
        "Prapti Trivedi",
        "Vikas Yadav",
        "Oluwanifemi Bamgbose",
        "Sathwik Tejaswi Madhusudan",
        "James Zou",
        "Nazneen Rajani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T18:10:54+00:00",
          "link": "https://arxiv.org/abs/2503.01781v1",
          "size": "963kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:33:39+00:00",
          "link": "https://arxiv.org/abs/2503.01781v2",
          "size": "637kb",
          "version": "v2"
        }
      ],
      "title": "Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01781",
        "PDF": "https://arxiv.org/pdf/2503.01781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on investigating the robustness of reasoning models through adversarial triggers, with no discussion on data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Math"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09305",
      "abstract": "Path smoothness is often overlooked in path imitation learning from expert demonstrations. In this paper, we introduce a novel learning method, termed deep angular A* (DAA*), by incorporating the proposed path angular freedom (PAF) into A* to improve path similarity through adaptive path smoothness. The PAF aims to explore the effect of move angles on path node expansion by finding the trade-off between their minimum and maximum values, allowing for high adaptiveness for imitation learning. DAA* improves path optimality by closely aligning with the reference path through joint optimization of path shortening and smoothing, which correspond to heuristic distance and PAF, respectively. Throughout comprehensive evaluations on 7 datasets, including 4 maze datasets, 2 video-game datasets, and a real-world drone-view dataset containing 2 scenarios, we demonstrate remarkable improvements of our DAA* over neural A* in path similarity between the predicted and reference paths with a shorter path length when the shortest path is plausible, improving by 9.0% SPR, 6.9% ASIM, and 3.9% PSIM. Furthermore, when jointly learning pathfinding with both path loss and path probability map loss, DAA* significantly outperforms the state-of-the-art TransPath by 6.7% SPR, 6.5% PSIM, and 3.7% ASIM. We also discuss the minor trade-off between path optimality and search efficiency where applicable. Our code and model weights are available at https://github.com/zwxu064/DAAStar.git.",
      "authors": [
        "Zhiwei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.09305v1",
          "size": "5270kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:36:50+00:00",
          "link": "https://arxiv.org/abs/2507.09305v2",
          "size": "5270kb",
          "version": "v2"
        }
      ],
      "title": "DAA*: Deep Angular A Star for Image-based Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09305",
        "HTML": "https://arxiv.org/html/2507.09305",
        "PDF": "https://arxiv.org/pdf/2507.09305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces DAA*, a method for path planning focused on path smoothness and similarity. It does not contribute to or relate to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14578",
      "abstract": "We propose XL-DURel, a finetuned, multilingual Sentence Transformer model optimized for ordinal Word-in-Context classification. We test several loss functions for regression and ranking tasks managing to outperform previous models on ordinal and binary data with a ranking objective based on angular distance in complex space. We further show that binary WiC can be treated as a special case of ordinal WiC and that optimizing models for the general ordinal task improves performance on the more specific binary task. This paves the way for a unified treatment of WiC modeling across different task formulations.",
      "authors": [
        "Sachin Yadav",
        "Dominik Schlechtweg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T11:40:37+00:00",
          "link": "https://arxiv.org/abs/2507.14578v1",
          "size": "294kb",
          "version": "v1"
        }
      ],
      "title": "XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14578",
        "HTML": "https://arxiv.org/html/2507.14578",
        "PDF": "https://arxiv.org/pdf/2507.14578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a finetuned Sentence Transformer model but focuses more on improving model performance for Word-in-Context tasks rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14749",
      "abstract": "What insights can machine learning bring to understanding human language acquisition? Large language and multimodal models have achieved remarkable capabilities, but their reliance on massive training datasets creates a fundamental mismatch with children, who succeed in acquiring language from comparatively limited input. To help bridge this gap, researchers have increasingly trained neural networks using data similar in quantity and quality to children's input. Taking this approach to the limit, Vong et al. (2024) showed that a multimodal neural network trained on 61 hours of visual and linguistic input extracted from just one child's developmental experience could acquire word-referent mappings. However, whether this approach's success reflects the idiosyncrasies of a single child's experience, or whether it would show consistent and robust learning patterns across multiple children's experiences was not explored. In this article, we applied automated speech transcription methods to the entirety of the SAYCam dataset, consisting of over 500 hours of video data spread across all three children. Using these automated transcriptions, we generated multi-modal vision-and-language datasets for both training and evaluation, and explored a range of neural network configurations to examine the robustness of simulated word learning. Our findings demonstrate that networks trained on automatically transcribed data from each child can acquire and generalize word-referent mappings across multiple network architectures. These results validate the robustness of multimodal neural networks for grounded word learning, while highlighting the individual differences that emerge in how models learn when trained on each child's developmental experiences.",
      "authors": [
        "Wai Keen Vong",
        "Brenden M. Lake"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.14749v1",
          "size": "6515kb",
          "version": "v1"
        }
      ],
      "title": "On the robustness of modeling grounded word learning through a child's egocentric input",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14749",
        "HTML": "https://arxiv.org/html/2507.14749",
        "PDF": "https://arxiv.org/pdf/2507.14749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of multimodal vision-and-language datasets for simulated word learning, which touches on data preparation for training but is not the central focus of LLM dataset processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14876",
      "abstract": "Indoor mobile networks handle the majority of data traffic, with their performance limited by building materials and structures. However, building designs have historically not prioritized wireless performance. Prior to the advent of reconfigurable intelligent surfaces (RIS), the industry passively adapted to wireless propagation challenges within buildings. Inspired by RIS's successes in outdoor networks, we propose embedding RIS into building structures to manipulate and enhance building wireless performance comprehensively. Nonetheless, the ubiquitous mobility of users introduces complex dynamics to the channels of RIS-covered buildings. A deep understanding of indoor human behavior patterns is essential for achieving wireless-friendly building design. This article is the first to systematically examine the tidal evolution phenomena emerging in the channels of RIS-covered buildings driven by complex human behaviors. We demonstrate that a universal channel model is unattainable and focus on analyzing the challenges faced by advanced deep learning-based prediction and control strategies, including high-order Markov dependencies, concept drift, and generalization issues caused by human-induced disturbances. Possible solutions for orchestrating the coexistence of RIS-covered buildings and crowd mobility are also laid out.",
      "authors": [
        "Zi-Yang Wu",
        "Muhammad Ismail",
        "Jiliang Zhang",
        "Jie Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T09:19:26+00:00",
          "link": "https://arxiv.org/abs/2507.14876v1",
          "size": "6748kb",
          "version": "v1"
        }
      ],
      "title": "Tidal-Like Concept Drift in RIS-Covered Buildings: When Programmable Wireless Environments Meet Human Behaviors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14876",
        "HTML": "https://arxiv.org/html/2507.14876",
        "PDF": "https://arxiv.org/pdf/2507.14876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines RIS-covered building designs and the impact of human behaviors on wireless performance. It addresses wireless networks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14891",
      "abstract": "Machine learning (ML) is increasingly used in network data planes for advanced traffic analysis. However, existing solutions (such as FlowLens, N3IC, and BoS) still struggle to simultaneously achieve low latency, high throughput, and high accuracy. To address these challenges, we present FENIX, a hybrid in-network ML system that performs feature extraction on programmable switch ASICs and deep neural network inference on FPGAs. FENIX introduces a Data Engine that leverages a probabilistic token bucket algorithm to control the sending rate of feature streams, effectively addressing the throughput gap between programmable switch ASICs and FPGAs. In addition, FENIX designs a Model Engine to enable high-accuracy deep neural network inference in the network, overcoming the difficulty of deploying complex models on resource-constrained switch chips. We implement FENIX on a programmable switch platform that integrates a Tofino ASIC and a ZU19EG FPGA directly and evaluate it on real-world network traffic datasets. Our results show that FENIX achieves microsecond-level inference latency and multi-terabit throughput with low hardware overhead, and delivers over 95\\% accuracy on mainstream network traffic classification tasks, outperforming SOTA.",
      "authors": [
        "Xiangyu Gao (1)",
        "Tong Li (2)",
        "Yinchao Zhang (1)",
        "Ziqiang Wang (3)",
        "Xiangsheng Zeng (4)",
        "Su Yao (1)",
        "Ke Xu (1) ((1) Tsinghua University",
        "(2) Renmin University of China",
        "(3) Southeast University",
        "(4) Huazhong University of Science and Technology)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:13:13+00:00",
          "link": "https://arxiv.org/abs/2507.14891v1",
          "size": "4134kb",
          "version": "v1"
        }
      ],
      "title": "FENIX: Enabling In-Network DNN Inference with FPGA-Enhanced Programmable Switches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14891",
        "HTML": "https://arxiv.org/html/2507.14891",
        "PDF": "https://arxiv.org/pdf/2507.14891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enabling in-network DNN inference using FPGA-enhanced switches, primarily addressing ML in network data planes rather than LLM training data processing operations such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15474",
      "abstract": "There has been a growing interest in autonomous systems designed to operate in adverse conditions (e.g. smoke, dust), where the visible light spectrum fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating through such challenging environmental conditions due to the lower frequency components within its broad bandwidth. Therefore, UWB radar has emerged as a potential sensing technology for Simultaneous Localization and Mapping (SLAM) in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are prone to failure. Existing approaches involving UWB radar as the primary exteroceptive sensor generally extract features in the environment, which are later initialized as landmarks in a map. However, these methods are constrained by the number of distinguishable features in the environment. Hence, this paper proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements into UWB radar-based SLAM systems to improve the accuracy and scalability of SLAM in feature-deficient environments. The AOA measurements are obtained using UWB anchor-tag units which are dynamically deployed by the robot in featureless areas during mapping of the environment. This paper thoroughly discusses prevailing constraints associated with UWB AOA measurement units and presents solutions to overcome them. Our experimental results show that integrating UWB AOA units with UWB radar enables SLAM in vision-denied feature-deficient environments.",
      "authors": [
        "Charith Premachandra",
        "Achala Athukorala",
        "U-Xuan Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:25:52+00:00",
          "link": "https://arxiv.org/abs/2507.15474v1",
          "size": "8238kb",
          "version": "v1"
        }
      ],
      "title": "All-UWB SLAM Using UWB Radar and UWB AOA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15474",
        "HTML": "https://arxiv.org/html/2507.15474",
        "PDF": "https://arxiv.org/pdf/2507.15474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses UWV radar-based SLAM systems in vision-denied environments, specifically incorporating AOA measurements. It is unrelated to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15671",
      "abstract": "Detecting software bugs remains a fundamental challenge due to the extensive diversity of real-world defects. Traditional static analysis tools often rely on symbolic workflows, which restrict their coverage and hinder adaptability to customized bugs with diverse anti-patterns. While recent advances incorporate large language models (LLMs) to enhance bug detection, these methods continue to struggle with sophisticated bugs and typically operate within limited analysis contexts. To address these challenges, we propose BugScope, an LLM-driven multi-agent system that emulates how human auditors learn new bug patterns from representative examples and apply that knowledge during code auditing. Given a set of examples illustrating both buggy and non-buggy behaviors, BugScope synthesizes a retrieval strategy to extract relevant detection contexts via program slicing and then constructs a tailored detection prompt to guide accurate reasoning by the LLM. Our evaluation on a curated dataset of 40 real-world bugs drawn from 21 widely-used open-source projects demonstrates that BugScope achieves 87.04% precision and 90.00% recall, surpassing state-of-the-art industrial tools by 0.44 in F1 score. Further testing on large-scale open-source systems, including the Linux kernel, uncovered 141 previously unknown bugs, of which 78 have been fixed and 7 confirmed by developers, highlighting BugScope's substantial practical impact.",
      "authors": [
        "Jinyao Guo",
        "Chengpeng Wang",
        "Dominic Deluca",
        "Jinjie Liu",
        "Zhuo Zhang",
        "Xiangyu Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:34:01+00:00",
          "link": "https://arxiv.org/abs/2507.15671v1",
          "size": "653kb",
          "version": "v1"
        }
      ],
      "title": "BugScope: Learn to Find Bugs Like Human",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15671",
        "HTML": "https://arxiv.org/html/2507.15671",
        "PDF": "https://arxiv.org/pdf/2507.15671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses LLMs for bug detection and discusses training with a curated dataset of bugs, the core contribution lies in software debugging rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.09847",
      "abstract": "We develop a general framework for estimating function-valued parameters under equality or inequality constraints in infinite-dimensional statistical models. Such constrained learning problems are common across many areas of statistics and machine learning, where estimated parameters must satisfy structural requirements such as moment restrictions, policy benchmarks, calibration criteria, or fairness considerations. To address these problems, we characterize the solution as the minimizer of a penalized population risk using a Lagrange-type formulation, and analyze it through a statistical functional lens. Central to our approach is a constraint-specific path through the unconstrained parameter space that defines the constrained solutions. For a broad class of constraint-risk pairs, this path admits closed-form expressions and reveals how constraints shape optimal adjustments. When closed forms are unavailable, we derive recursive representations that support tractable estimation. Our results also suggest natural estimators of the constrained parameter, constructed by combining estimates of unconstrained components of the data-generating distribution. Thus, our procedure can be integrated with any statistical learning approach and implemented using standard software. We provide general conditions under which the resulting estimators achieve optimal risk and constraint satisfaction, and we demonstrate the flexibility and effectiveness of the proposed method through various examples, simulations, and real-data applications.",
      "authors": [
        "Razieh Nabi",
        "Nima S. Hejazi",
        "Mark J. van der Laan",
        "David Benkeser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-15T14:59:21+00:00",
          "link": "https://arxiv.org/abs/2404.09847v1",
          "size": "584kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:19:58+00:00",
          "link": "https://arxiv.org/abs/2404.09847v2",
          "size": "348kb",
          "version": "v2"
        }
      ],
      "title": "Statistical learning for constrained functional parameters in infinite-dimensional models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.09847",
        "PDF": "https://arxiv.org/pdf/2404.09847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on estimating constrained functional parameters in statistical models. It does not address training data processing for LLMs."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11145",
      "abstract": "Accurate and robust simultaneous localization and mapping (SLAM) is crucial for autonomous mobile systems, typically achieved by leveraging the geometric features of the environment. Incorporating semantics provides a richer scene representation that not only enhances localization accuracy in SLAM but also enables advanced cognitive functionalities for downstream navigation and planning tasks. Existing point-wise semantic LiDAR SLAM methods often suffer from poor efficiency and generalization, making them less robust in diverse real-world scenarios. In this paper, we propose a semantic graph-enhanced SLAM framework, named SG-SLAM, which effectively leverages the geometric, semantic, and topological characteristics inherent in environmental structures. The semantic graph serves as a fundamental component that facilitates critical functionalities of SLAM, including robust relocalization during odometry failures, accurate loop closing, and semantic graph map construction. Our method employs a dual-threaded architecture, with one thread dedicated to online odometry and relocalization, while the other handles loop closure, pose graph optimization, and map update. This design enables our method to operate in real time and generate globally consistent semantic graph maps and point cloud maps. We extensively evaluate our method across the KITTI, MulRAN, and Apollo datasets, and the results demonstrate its superiority compared to state-of-the-art methods. Our method has been released at https://github.com/nubot-nudt/SG-SLAM.",
      "authors": [
        "Neng Wang and Huimin Lu and Zhiqiang Zheng and Hesheng Wang and Yun-Hui Liu and Xieyuanli Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T07:25:26+00:00",
          "link": "https://arxiv.org/abs/2503.11145v1",
          "size": "5690kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T06:54:03+00:00",
          "link": "https://arxiv.org/abs/2503.11145v2",
          "size": "5690kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11145",
        "HTML": "https://arxiv.org/html/2503.11145",
        "PDF": "https://arxiv.org/pdf/2503.11145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a framework for LiDAR SLAM, which relates to localization and mapping for autonomous systems, and does not address LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/nubot-nudt/sg-slam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.14075",
      "abstract": "Large vision-language models (VLMs) have demonstrated remarkable capabilities in open-world multimodal understanding, yet their high computational overheads pose great challenges for practical deployment. Some recent works have proposed methods to accelerate VLMs by pruning redundant visual tokens guided by the attention maps of VLM's early layers. Despite the success of these token pruning methods, they still suffer from two major shortcomings: (i) considerable accuracy drop due to insensitive attention signals in early layers, and (ii) limited speedup when generating long responses (e.g., 30 tokens). To address the limitations above, we present TwigVLM -- a simple and general architecture by growing a lightweight twig upon an early layer of the base VLM. Compared with most existing VLM acceleration methods purely based on visual token pruning, our TwigVLM not only achieves better accuracy retention by employing a twig-guided token pruning (TTP) strategy, but also yields higher generation speed by utilizing a self-speculative decoding (SSD) strategy. Taking LLaVA-1.5-7B as the base VLM, experimental results show that TwigVLM preserves 96% of the original performance after pruning 88.9% of visual tokens and achieves 154% speedup in generating long responses, delivering significantly better performance in terms of both accuracy and speed over the state-of-the-art VLM acceleration methods.",
      "authors": [
        "Zhenwei Shao",
        "Mingyang Wang",
        "Zhou Yu",
        "Wenwen Pan",
        "Yan Yang",
        "Tao Wei",
        "Hongyuan Zhang",
        "Ning Mao",
        "Wei Chen",
        "Jun Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T09:52:45+00:00",
          "link": "https://arxiv.org/abs/2503.14075v1",
          "size": "1713kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T13:38:51+00:00",
          "link": "https://arxiv.org/abs/2503.14075v2",
          "size": "3654kb",
          "version": "v2"
        }
      ],
      "title": "Growing a Twig to Accelerate Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14075",
        "HTML": "https://arxiv.org/html/2503.14075",
        "PDF": "https://arxiv.org/pdf/2503.14075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses methods for accelerating vision-language models (VLMs) through architectural innovations, with no relevance to LLM training data processing operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14801",
      "abstract": "Low-level vision involves a wide spectrum of tasks, including image restoration, enhancement, stylization, and feature extraction, which differ significantly in both task formulation and output domains. To address the challenge of unified modeling across such diverse tasks, we propose a Visual task Prompt-based Image Processing (VPIP) framework that leverages input-target image pairs as visual prompts to guide the model in performing a variety of low-level vision tasks. The framework comprises an end-to-end image processing backbone, a prompt encoder, and a prompt interaction module, enabling flexible integration with various architectures and effective utilization of task-specific visual representations. Based on this design, we develop a unified low-level vision model, GenLV, and evaluate its performance across multiple representative tasks. To explore the scalability of this approach, we extend the framework along two dimensions: model capacity and task diversity. We construct a large-scale benchmark consisting of over 100 low-level vision tasks and train multiple versions of the model with varying scales. Experimental results show that the proposed method achieves considerable performance across a wide range of tasks. Notably, increasing the number of training tasks enhances generalization, particularly for tasks with limited data, indicating the model's ability to learn transferable representations through joint training. Further evaluations in zero-shot generalization, few-shot transfer, and task-specific fine-tuning scenarios demonstrate the model's strong adaptability, confirming the effectiveness, scalability, and potential of the proposed framework as a unified foundation for general low-level vision modeling.",
      "authors": [
        "Xiangyu Chen",
        "Kaiwen Zhu",
        "Yuandong Pu",
        "Shuo Cao",
        "Xiaohui Li",
        "Wenlong Zhang",
        "Yihao Liu",
        "Yu Qiao",
        "Jiantao Zhou",
        "and Chao Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:22:52+00:00",
          "link": "https://arxiv.org/abs/2507.14801v1",
          "size": "22796kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Scalable Unified Modeling for General Low-Level Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14801",
        "HTML": "https://arxiv.org/html/2507.14801",
        "PDF": "https://arxiv.org/pdf/2507.14801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with a unified model for low-level vision tasks, using visual prompts, without any discussion on LLM training data processing operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14833",
      "abstract": "The segmentation of mass lesions in digital breast tomosynthesis (DBT) images is very significant for the early screening of breast cancer. However, the high-density breast tissue often leads to high concealment of the mass lesions, which makes manual annotation difficult and time-consuming. As a result, there is a lack of annotated data for model training. Diffusion models are commonly used for data augmentation, but the existing methods face two challenges. First, due to the high concealment of lesions, it is difficult for the model to learn the features of the lesion area. This leads to the low generation quality of the lesion areas, thus limiting the quality of the generated images. Second, existing methods can only generate images and cannot generate corresponding annotations, which restricts the usability of the generated images in supervised training. In this work, we propose a paired image generation method. The method does not require external conditions and can achieve the generation of paired images by training an extra diffusion guider for the conditional diffusion model. During the experimental phase, we generated paired DBT slices and mass lesion masks. Then, we incorporated them into the supervised training process of the mass lesion segmentation task. The experimental results show that our method can improve the generation quality without external conditions. Moreover, it contributes to alleviating the shortage of annotated data, thus enhancing the performance of downstream tasks.",
      "authors": [
        "Haoxuan Zhang",
        "Wenju Cui",
        "Yuzhu Cao",
        "Tao Tan",
        "Jie Liu",
        "Yunsong Peng",
        "Jian Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T06:13:02+00:00",
          "link": "https://arxiv.org/abs/2507.14833v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Paired Image Generation with Diffusion-Guided Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14833",
        "HTML": "https://arxiv.org/html/2507.14833",
        "PDF": "https://arxiv.org/pdf/2507.14833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a method for paired image generation, which can enhance downstream tasks by alleviating the shortage of annotated data. While it addresses data generation, its primary focus is on improving medical imaging for task-specific training rather than contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14867",
      "abstract": "Micro-gestures are unconsciously performed body gestures that can convey the emotion states of humans and start to attract more research attention in the fields of human behavior understanding and affective computing as an emerging topic. However, the modeling of human emotion based on micro-gestures has not been explored sufficiently. In this work, we propose to recognize the emotion states based on the micro-gestures by reconstructing the behavior patterns with a hypergraph-enhanced Transformer in a hybrid-supervised framework. In the framework, hypergraph Transformer based encoder and decoder are separately designed by stacking the hypergraph-enhanced self-attention and multiscale temporal convolution modules. Especially, to better capture the subtle motion of micro-gestures, we construct a decoder with additional upsampling operations for a reconstruction task in a self-supervised learning manner. We further propose a hypergraph-enhanced self-attention module where the hyperedges between skeleton joints are gradually updated to present the relationships of body joints for modeling the subtle local motion. Lastly, for exploiting the relationship between the emotion states and local motion of micro-gestures, an emotion recognition head from the output of encoder is designed with a shallow architecture and learned in a supervised way. The end-to-end framework is jointly trained in a one-stage way by comprehensively utilizing self-reconstruction and supervision information. The proposed method is evaluated on two publicly available datasets, namely iMiGUE and SMG, and achieves the best performance under multiple metrics, which is superior to the existing methods.",
      "authors": [
        "Zhaoqiang Xia",
        "Hexiang Huang",
        "Haoyu Chen",
        "Xiaoyi Feng",
        "and Guoying Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:27:56+00:00",
          "link": "https://arxiv.org/abs/2507.14867v1",
          "size": "2721kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14867",
        "HTML": "https://arxiv.org/html/2507.14867",
        "PDF": "https://arxiv.org/pdf/2507.14867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on emotion recognition using hypergraph-enhanced Transformers for processing micro-gestures, rather than addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14885",
      "abstract": "Remote photoplethysmography (rPPG) captures cardiac signals from facial videos and is gaining attention for its diverse applications. While deep learning has advanced rPPG estimation, it relies on large, diverse datasets for effective generalization. In contrast, handcrafted methods utilize physiological priors for better generalization in unseen scenarios like motion while maintaining computational efficiency. However, their linear assumptions limit performance in complex conditions, where deep learning provides superior pulsatile information extraction. This highlights the need for hybrid approaches that combine the strengths of both methods. To address this, we present BeatFormer, a lightweight spectral attention model for rPPG estimation, which integrates zoomed orthonormal complex attention and frequency-domain energy measurement, enabling a highly efficient model. Additionally, we introduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be trained without any PPG or HR labels. We validate BeatFormer on the PURE, UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance, particularly in cross-dataset evaluations under motion scenarios.",
      "authors": [
        "Joaquim Comas and Federico Sukno"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:00:31+00:00",
          "link": "https://arxiv.org/abs/2507.14885v1",
          "size": "6439kb",
          "version": "v1"
        }
      ],
      "title": "BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14885",
        "HTML": "https://arxiv.org/html/2507.14885",
        "PDF": "https://arxiv.org/pdf/2507.14885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces BeatFormer for remote heart rate estimation from facial videos, leveraging spectral attention and contrastive learning, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1911.08432",
      "abstract": "Robustness of convolutional neural networks (CNNs) has gained in importance on account of adversarial examples, i.e., inputs added as well-designed perturbations that are imperceptible to humans but can cause the model to predict incorrectly. Recent research suggests that the noises in adversarial examples break the textural structure, which eventually leads to wrong predictions. To mitigate the threat of such adversarial attacks, we propose defective convolutional networks that make predictions relying less on textural information but more on shape information by properly integrating defective convolutional layers into standard CNNs. The defective convolutional layers contain defective neurons whose activations are set to be a constant function. As defective neurons contain no information and are far different from standard neurons in its spatial neighborhood, the textural features cannot be accurately extracted, and so the model has to seek other features for classification, such as the shape. We show extensive evidence to justify our proposal and demonstrate that defective CNNs can defense against black-box attacks better than standard CNNs. In particular, they achieve state-of-the-art performance against transfer-based attacks without any adversarial training being applied.",
      "authors": [
        "Tiange Luo",
        "Tianle Cai",
        "Mengxiao Zhang",
        "Siyu Chen",
        "Di He",
        "Liwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2019-11-19T17:56:22+00:00",
          "link": "https://arxiv.org/abs/1911.08432v1",
          "size": "8661kb",
          "version": "v1"
        },
        {
          "date": "2020-04-06T20:47:57+00:00",
          "link": "https://arxiv.org/abs/1911.08432v2",
          "size": "6391kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T21:54:18+00:00",
          "link": "https://arxiv.org/abs/1911.08432v3",
          "size": "3516kb",
          "version": "v3"
        }
      ],
      "title": "Defective Convolutional Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/1911.08432",
        "HTML": "https://arxiv.org/html/1911.08432",
        "PDF": "https://arxiv.org/pdf/1911.08432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing the robustness of convolutional neural networks (CNNs) to adversarial attacks using defective convolutional networks. There is no mention of LLM training data processing, data engineering, or dataset creation."
      },
      "conference_url_abs": "https://openreview.net/forum?id=E8fmaZwzEj",
      "tasks": [],
      "repo_urls": [
        "https://github.com/tiangeluo/DefectiveCNN"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.12828",
      "abstract": "Extensive previous research has focused on post-training knowledge editing (KE) for language models (LMs) to ensure that knowledge remains accurate and up-to-date. One desired property and open question in KE is to let edited LMs correctly handle ripple effects, where LM is expected to answer its logically related knowledge accurately. In this paper, we answer the question of why most KE methods still create messy ripple effects. We conduct extensive analysis and identify a salient indicator, GradSim, that effectively reveals when and why updated knowledge ripples in LMs. GradSim is computed by the cosine similarity between gradients of the original fact and its related knowledge. We observe a strong positive correlation between ripple effect performance and GradSim across different LMs, KE methods, and evaluation metrics. Further investigations into three counter-intuitive failure cases (Negation, Over-Ripple, Multi-Lingual) of ripple effects demonstrate that these failures are often associated with very low GradSim. This finding validates that GradSim is an effective indicator of when knowledge ripples in LMs.",
      "authors": [
        "Jiaxin Qin",
        "Zixuan Zhang",
        "Manling Li",
        "Pengfei Yu",
        "Heng Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-02T14:33:44+00:00",
          "link": "https://arxiv.org/abs/2407.12828v1",
          "size": "1566kb",
          "version": "v1"
        },
        {
          "date": "2024-07-19T01:33:56+00:00",
          "link": "https://arxiv.org/abs/2407.12828v2",
          "size": "1320kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T14:41:16+00:00",
          "link": "https://arxiv.org/abs/2407.12828v3",
          "size": "610kb",
          "version": "v3"
        }
      ],
      "title": "Why Does New Knowledge Create Messy Ripple Effects in LLMs?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.12828",
        "HTML": "https://arxiv.org/html/2407.12828",
        "PDF": "https://arxiv.org/pdf/2407.12828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with knowledge editing in language models, focusing on ripple effects in knowledge, which doesn't directly contribute to training data processing for LLMs."
      },
      "tasks": [
        "knowledge editing",
        "Negation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12419",
      "abstract": "Egocentric gesture recognition is a pivotal technology for enhancing natural human-computer interaction, yet traditional RGB-based solutions suffer from motion blur and illumination variations in dynamic scenarios. While event cameras show distinct advantages in handling high dynamic range with ultra-low power consumption, existing RGB-based architectures face inherent limitations in processing asynchronous event streams due to their synchronous frame-based nature. Moreover, from an egocentric perspective, event cameras record data that includes events generated by both head movements and hand gestures, thereby increasing the complexity of gesture recognition. To address this, we propose a novel network architecture specifically designed for event data processing, incorporating (1) a lightweight CNN with asymmetric depthwise convolutions to reduce parameters while preserving spatiotemporal features, (2) a plug-and-play state-space model as context block that decouples head movement noise from gesture dynamics, and (3) a parameter-free Bins-Temporal Shift Module (BTSM) that shifts features along bins and temporal dimensions to fuse sparse events efficiently. We further establish the EgoEvGesture dataset, the first large-scale dataset for egocentric gesture recognition using event cameras. Experimental results demonstrate that our method achieves 62.7% accuracy tested on unseen subjects with only 7M parameters, 3.1% higher than state-of-the-art approaches. Notable misclassifications in freestyle motions stem from high inter-personal variability and unseen test patterns differing from training data. Moreover, our approach achieved a remarkable accuracy of 97.0% on the DVS128 Gesture, demonstrating the effectiveness and generalization capability of our method on public datasets. The dataset and models are made available at https://github.com/3190105222/EgoEv_Gesture.",
      "authors": [
        "Luming Wang",
        "Hao Shi",
        "Xiaoting Yin",
        "Kailun Yang",
        "Kaiwei Wang",
        "Jian Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T09:08:02+00:00",
          "link": "https://arxiv.org/abs/2503.12419v1",
          "size": "3365kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T02:44:20+00:00",
          "link": "https://arxiv.org/abs/2503.12419v2",
          "size": "3342kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T09:02:46+00:00",
          "link": "https://arxiv.org/abs/2503.12419v3",
          "size": "3089kb",
          "version": "v3"
        }
      ],
      "title": "EgoEvGesture: Gesture Recognition Based on Egocentric Event Camera",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12419",
        "HTML": "https://arxiv.org/html/2503.12419",
        "PDF": "https://arxiv.org/pdf/2503.12419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a gesture recognition model using event cameras and establishes a dataset for this purpose, which is unrelated to LLM training data processing as it deals with a different modality and application area."
      },
      "tasks": [
        "Gesture Recognition"
      ],
      "repo_urls": [
        "https://github.com/3190105222/egoev_gesture"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13567",
      "abstract": "Reachability analysis for hybrid nonaffine systems remains computationally challenging, as existing set representations--including constrained, polynomial, and hybrid zonotopes--either lose tightness under high-order nonaffine maps or suffer exponential blow-up after discrete jumps. This paper introduces Hybrid Polynomial Zonotope (HPZ), a novel set representation that combines the mode-dependent generator structure of hybrid zonotopes with the algebraic expressiveness of polynomial zonotopes. HPZs compactly encode non-convex reachable states across modes by attaching polynomial exponents to each hybrid generator, enabling precise capture of high-order state-input couplings without vertex enumeration. We develop a comprehensive library of HPZ operations, including Minkowski sum, linear transformation, and intersection. Theoretical analysis and computational experiments demonstrate that HPZs achieve superior tightness preservation and computational efficiency compared to existing approaches for hybrid system reachability analysis.",
      "authors": [
        "Peng Xie and Zhen Zhang and Amr Alanwar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T14:51:00+00:00",
          "link": "https://arxiv.org/abs/2506.13567v1",
          "size": "287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T11:32:39+00:00",
          "link": "https://arxiv.org/abs/2506.13567v2",
          "size": "297kb",
          "version": "v2"
        }
      ],
      "title": "Hybrid Polynomial Zonotopes: A Set Representation for Reachability Analysis in Hybrid Nonaffine Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13567",
        "HTML": "https://arxiv.org/html/2506.13567",
        "PDF": "https://arxiv.org/pdf/2506.13567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a set representation for reachability analysis in hybrid systems, which does not pertain to LLM training data processing tasks such as dataset creation or enhancement."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14200",
      "abstract": "This paper aims to demonstrate the potential and strengths of open-source collectives. It leads to a promising question: Can we harness multiple open-source LLMs to match or even beat the closed-source LLMs? To answer this, we propose SMACS, a scalable multi-agent collaboration system (MACS) framework with high performance. Specifically, for continuous integration of new LLMs and generalization to diverse questions, we first propose a Retrieval-based Prior Selection (RPS), which assigns a proxy performance score to each LLM to select the Top-k LLMs at the instance level for any given question. Then, we propose an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the generation of diverse responses through prior dropping and selecting the high-quality response via a hybrid posterior score. Experiments on eight mainstream benchmarks validate the effectiveness of our SMACS: by integrating fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025, e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%) across multiple tasks. Remarkably, it even exceeds the average of best results of different datasets from both open-source LLMs (+2.86%) and closed-source LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released at https://github.com/magent4aci/SMACS.",
      "authors": [
        "Shengji Tang",
        "Jianjian Cao",
        "Weihao Lin",
        "Jiale Hong",
        "Bo Zhang",
        "Shuyue Hu",
        "Lei Bai",
        "Tao Chen",
        "Wanli Ouyang",
        "Peng Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:17:11+00:00",
          "link": "https://arxiv.org/abs/2507.14200v1",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14200",
        "HTML": "https://arxiv.org/html/2507.14200",
        "PDF": "https://arxiv.org/pdf/2507.14200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a multi-agent system for improving LLM performance, focusing on system architecture and collaborative methods rather than on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14216",
      "abstract": "Low-latency localization is critical in cellular networks to support real-time applications requiring precise positioning. In this paper, we propose a distributed machine learning (ML) framework for fingerprint-based localization tailored to cell-free massive multiple-input multiple-output (MIMO) systems, an emerging architecture for 6G networks. The proposed framework enables each access point (AP) to independently train a Gaussian process regression model using local angle-of-arrival and received signal strength fingerprints. These models provide probabilistic position estimates for the user equipment (UE), which are then fused by the UE with minimal computational overhead to derive a final location estimate. This decentralized approach eliminates the need for fronthaul communication between the APs and the central processing unit (CPU), thereby reducing latency. Additionally, distributing computational tasks across the APs alleviates the processing burden on the CPU compared to traditional centralized localization schemes. Simulation results demonstrate that the proposed distributed framework achieves localization accuracy comparable to centralized methods, despite lacking the benefits of centralized data aggregation. Moreover, it effectively reduces uncertainty of the location estimates, as evidenced by the 95\\% covariance ellipse. The results highlight the potential of distributed ML for enabling low-latency, high-accuracy localization in future 6G networks.",
      "authors": [
        "Manish Kumar",
        "Tzu-Hsuan Chou",
        "Byunghyun Lee",
        "Nicol\\`o Michelusi",
        "David J. Love",
        "Yaguang Zhang",
        "and James V. Krogmeier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:05:16+00:00",
          "link": "https://arxiv.org/abs/2507.14216v1",
          "size": "4738kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14216",
        "HTML": "https://arxiv.org/html/2507.14216",
        "PDF": "https://arxiv.org/pdf/2507.14216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a distributed ML framework for localization in 6G networks using MIMO systems, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14221",
      "abstract": "The automated summarisation of parliamentary debates using large language models (LLMs) offers a promising way to make complex legislative discourse more accessible to the public. However, such summaries must not only be accurate and concise but also equitably represent the views and contributions of all speakers. This paper explores the use of LLMs to summarise plenary debates from the European Parliament and investigates the algorithmic and representational biases that emerge in this context. We propose a structured, multi-stage summarisation framework that improves textual coherence and content fidelity, while enabling the systematic analysis of how speaker attributes -- such as speaking order or political affiliation -- influence the visibility and accuracy of their contributions in the final summaries. Through our experiments using both proprietary and open-weight LLMs, we find evidence of consistent positional and partisan biases, with certain speakers systematically under-represented or misattributed. Our analysis shows that these biases vary by model and summarisation strategy, with hierarchical approaches offering the greatest potential to reduce disparity. These findings underscore the need for domain-sensitive evaluation metrics and ethical oversight in the deployment of LLMs for democratic applications.",
      "authors": [
        "Eoghan Cunningham",
        "James Cross",
        "Derek Greene"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:49:33+00:00",
          "link": "https://arxiv.org/abs/2507.14221v1",
          "size": "768kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Algorithmic and Domain-Specific Bias in Parliamentary Debate Summarisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14221",
        "HTML": "https://arxiv.org/html/2507.14221",
        "PDF": "https://arxiv.org/pdf/2507.14221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores biases in LLM-generated summaries of parliamentary debates, which touches on data processing for LLMs in terms of bias analysis, though the main focus is not direct data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14792",
      "abstract": "Information processing tasks involve complex cognitive mechanisms that are shaped by various factors, including individual goals, prior experience, and system environments. Understanding such behaviors requires a sophisticated and personalized data capture of how one interacts with modern information systems (e.g., web search engines). Passive sensors, such as wearables, capturing physiological and behavioral data, have the potential to provide solutions in this context. This paper presents a novel dataset, SenseSeek, designed to evaluate the effectiveness of consumer-grade sensors in a complex information processing scenario: searching via systems (e.g., search engines), one of the common strategies users employ for information seeking. The SenseSeek dataset comprises data collected from 20 participants, 235 trials of the stimulated search process, 940 phases of stages in the search process, including the realization of Information Need (IN), Query Formulation (QF), Query Submission by Typing (QS-T) or Speaking (QS-S), and Relevance Judgment by Reading (RJ-R) or Listening (RJ-L). The data includes Electrodermal Activities (EDA), Electroencephalogram (EEG), PUPIL, GAZE, and MOTION data, which were captured using consumer-grade sensors. It also contains 258 features extracted from the sensor data, the gaze-annotated screen recordings, and task responses. We validate the usefulness of the dataset by providing baseline analysis on the impacts of different cognitive intents and interaction modalities on the sensor data, and effectiveness of the data in discriminating the search stages. To our knowledge, SenseSeek is the first dataset that characterizes the multiple stages involved in information seeking with physiological signals collected from multiple sensors. We hope this dataset can serve as a reference for future research on information-seeking behaviors.",
      "authors": [
        "Kaixin Ji",
        "Danula Hettiachchi",
        "Falk Scholer",
        "Flora D. Salim",
        "Damiano Spina"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:35:47+00:00",
          "link": "https://arxiv.org/abs/2507.14792v1",
          "size": "1884kb",
          "version": "v1"
        }
      ],
      "title": "SenseSeek Dataset: Multimodal Sensing to Study Information Seeking Behaviors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14792",
        "HTML": "https://arxiv.org/html/2507.14792",
        "PDF": "https://arxiv.org/pdf/2507.14792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the SenseSeek dataset for studying information-seeking behaviors using multimodal sensing. It does not address training data processing for LLMs or any related operations as defined by the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15106",
      "abstract": "While human infants robustly discover their own causal efficacy, standard reinforcement learning agents remain brittle, as their reliance on correlation-based rewards fails in noisy, ecologically valid scenarios. To address this, we introduce the Causal Action Influence Score (CAIS), a novel intrinsic reward rooted in causal inference. CAIS quantifies an action's influence by measuring the 1-Wasserstein distance between the learned distribution of sensory outcomes conditional on that action, $p(h|a)$, and the baseline outcome distribution, $p(h)$. This divergence provides a robust reward that isolates the agent's causal impact from confounding environmental noise. We test our approach in a simulated infant-mobile environment where correlation-based perceptual rewards fail completely when the mobile is subjected to external forces. In stark contrast, CAIS enables the agent to filter this noise, identify its influence, and learn the correct policy. Furthermore, the high-quality predictive model learned for CAIS allows our agent, when augmented with a surprise signal, to successfully reproduce the \"extinction burst\" phenomenon. We conclude that explicitly inferring causality is a crucial mechanism for developing a robust sense of agency, offering a psychologically plausible framework for more adaptive autonomous systems.",
      "authors": [
        "Xia Xu",
        "Jochen Triesch"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:02:50+00:00",
          "link": "https://arxiv.org/abs/2507.15106v1",
          "size": "2229kb",
          "version": "v1"
        }
      ],
      "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15106",
        "HTML": "https://arxiv.org/html/2507.15106",
        "PDF": "https://arxiv.org/pdf/2507.15106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about simulating infant agency detection and introduces a causal reward mechanism. It does not address LLM training data processing or the creation/generation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15290",
      "abstract": "Thompson Sampling (TS) is widely used to address the exploration/exploitation tradeoff in contextual bandits, yet recent theory shows that it does not explore aggressively enough in high-dimensional problems. Feel-Good Thompson Sampling (FG-TS) addresses this by adding an optimism bonus that biases toward high-reward models, and it achieves the asymptotically minimax-optimal regret in the linear setting when posteriors are exact. However, its performance with \\emph{approximate} posteriors -- common in large-scale or neural problems -- has not been benchmarked. We provide the first systematic study of FG-TS and its smoothed variant (SFG-TS) across eleven real-world and synthetic benchmarks. To evaluate their robustness, we compare performance across settings with exact posteriors (linear and logistic bandits) to approximate regimes produced by fast but coarse stochastic-gradient samplers. Ablations over preconditioning, bonus scale, and prior strength reveal a trade-off: larger bonuses help when posterior samples are accurate, but hurt when sampling noise dominates. FG-TS generally outperforms vanilla TS in linear and logistic bandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS and its variants are competitive and easy-to-use, we recommend them as baselines in modern contextual-bandit benchmarks. Finally, we provide source code for all our experiments in https://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.",
      "authors": [
        "Emile Anand",
        "Sarah Liaw"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:42:56+00:00",
          "link": "https://arxiv.org/abs/2507.15290v1",
          "size": "3467kb",
          "version": "v1"
        }
      ],
      "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15290",
        "HTML": "https://arxiv.org/html/2507.15290",
        "PDF": "https://arxiv.org/pdf/2507.15290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on exploring the performance of Thompson Sampling in contextual bandits; there is no contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.16894",
      "abstract": "Diffusion models have demonstrated their ability to generate diverse and high-quality images, sparking considerable interest in their potential for real image editing applications. However, existing diffusion-based approaches for local image editing often suffer from undesired artifacts due to the latent-level blending of the noised target images and diffusion latent variables, which lack the necessary semantics for maintaining image consistency. To address these issues, we propose PFB-Diff, a Progressive Feature Blending method for Diffusion-based image editing. Unlike previous methods, PFB-Diff seamlessly integrates text-guided generated content into the target image through multi-level feature blending. The rich semantics encoded in deep features and the progressive blending scheme from high to low levels ensure semantic coherence and high quality in edited images. Additionally, we introduce an attention masking mechanism in the cross-attention layers to confine the impact of specific words to desired regions, further improving the performance of background editing and multi-object replacement. PFB-Diff can effectively address various editing tasks, including object/background replacement and object attribute editing. Our method demonstrates its superior performance in terms of editing accuracy and image quality without the need for fine-tuning or training. Our implementation is available at https://github.com/CMACH508/PFB-Diff.",
      "authors": [
        "Wenjing Huang",
        "Shikui Tu",
        "Lei Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-28T11:10:20+00:00",
          "link": "https://arxiv.org/abs/2306.16894v1",
          "size": "34364kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:39:45+00:00",
          "link": "https://arxiv.org/abs/2306.16894v2",
          "size": "42300kb",
          "version": "v2"
        }
      ],
      "title": "PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.16894",
        "PDF": "https://arxiv.org/pdf/2306.16894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a method for text-driven image editing using diffusion models, not related to LLM training data processing or any data engineering operations for language models specifically."
      },
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/CMACH508/PFB-Diff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08416",
      "abstract": "Humans can naturally identify and mentally complete occluded objects in cluttered environments. However, imparting similar cognitive ability to robotics remains challenging even with advanced reconstruction techniques, which models scenes as undifferentiated wholes and fails to recognize complete object from partial observations. In this paper, we propose InstaScene, a new paradigm towards holistic 3D perception of complex scenes with a primary goal: decomposing arbitrary instances while ensuring complete reconstruction. To achieve precise decomposition, we develop a novel spatial contrastive learning by tracing rasterization of each instance across views, significantly enhancing semantic supervision in cluttered scenes. To overcome incompleteness from limited observations, we introduce in-situ generation that harnesses valuable observations and geometric cues, effectively guiding 3D generative models to reconstruct complete instances that seamlessly align with the real world. Experiments on scene decomposition and object completion across complex real-world and synthetic scenes demonstrate that our method achieves superior decomposition accuracy while producing geometrically faithful and visually intact objects.",
      "authors": [
        "Zesong Yang and Bangbang Yang and Wenqi Dong and Chenxuan Cao and Liyuan Cui and Yuewen Ma and Zhaopeng Cui and Hujun Bao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T08:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.08416v1",
          "size": "18339kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:20:18+00:00",
          "link": "https://arxiv.org/abs/2507.08416v2",
          "size": "7736kb",
          "version": "v2"
        }
      ],
      "title": "InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08416",
        "HTML": "https://arxiv.org/html/2507.08416",
        "PDF": "https://arxiv.org/pdf/2507.08416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D instance decomposition and reconstruction using InstaScene, which is unrelated to LLM training data processing. It does not involve any aspect of data processing for LLMs or related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11019",
      "abstract": "Score-function policy gradients have delivered strong results in game-playing, robotics and language-model fine-tuning. Yet its high-variance often undermines training stability. On the other hand, pathwise policy gradients alleviate the training variance, but are reliable only when driven by an accurate action-conditioned value function which is notoriously hard to train without relying on past off-policy data. In this paper, we discuss how to construct a value-gradient driven, on-policy algorithm that allow training Q-value models purely from on-policy data, unlocking the possibility of using pathwise policy updates in the context of on-policy learning. We show how to balance stochastic policies for exploration with constrained policy updates for stable training, and evaluate important architectural components that facilitate accurate value function learning. Building on these insights, we propose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient on-policy algorithm that combines the sample-efficiency of pathwise policy gradients with the simplicity and minimal memory footprint of standard on-policy learning. We demonstrate that REPPO provides strong empirical performance at decreased sample requirements, wall-clock time, memory footprint as well as high hyperparameter robustness in a set of experiments on two standard GPU-parallelized benchmarks.",
      "authors": [
        "Claas Voelcker",
        "Axel Brunnbauer",
        "Marcel Hussing",
        "Michal Nauman",
        "Pieter Abbeel",
        "Eric Eaton",
        "Radu Grosu",
        "Amir-massoud Farahmand",
        "Igor Gilitschenski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.11019v1",
          "size": "2922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:12:41+00:00",
          "link": "https://arxiv.org/abs/2507.11019v2",
          "size": "2924kb",
          "version": "v2"
        }
      ],
      "title": "Relative Entropy Pathwise Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11019",
        "HTML": "https://arxiv.org/html/2507.11019",
        "PDF": "https://arxiv.org/pdf/2507.11019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a pathwise policy optimization technique for reinforcement learning, but it does not involve any operations related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14182",
      "abstract": "Financial markets exhibit highly dynamic and complex behaviors shaped by both historical price trajectories and exogenous narratives, such as news, policy interpretations, and social media sentiment. The heterogeneity in these data and the diverse insight of investors introduce biases that complicate the modeling of market dynamics. Unlike prior work, this paper explores the potential of bull and bear regimes in investor-driven market dynamics. Through empirical analysis on real-world financial datasets, we uncover a dynamic relationship between bias variation and behavioral adaptation, which enhances trend prediction under evolving market conditions. To model this mechanism, we propose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified framework that jointly embeds temporal price sequences and external contextual signals into a shared latent space where opposing bull and bear forces naturally emerge, forming the foundation for bias representation. Within this space, an inertial pairing module pairs temporally adjacent samples to preserve momentum, while the dual competition mechanism contrasts bullish and bearish embeddings to capture behavioral divergence. Together, these components allow B4 to model bias-driven asymmetry, behavioral inertia, and market heterogeneity. Experimental results on real-world financial datasets demonstrate that our model not only achieves superior performance in predicting market trends but also provides interpretable insights into the interplay of biases, investor behaviors, and market dynamics.",
      "authors": [
        "Xiaotong Luo",
        "Shengda Zhuo",
        "Min Chen",
        "Lichun Li",
        "Ruizhao Lu",
        "Wenqi Fan",
        "Shuqiang Huang and Yin Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T11:36:26+00:00",
          "link": "https://arxiv.org/abs/2507.14182v1",
          "size": "1317kb",
          "version": "v1"
        }
      ],
      "title": "From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14182",
        "HTML": "https://arxiv.org/html/2507.14182",
        "PDF": "https://arxiv.org/pdf/2507.14182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores modeling market dynamics with contrastive modeling and does not contribute to training data processing for LLMs or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14241",
      "abstract": "Large Language Models (LLMs) perform best with well-crafted prompts, yet prompt engineering remains manual, inconsistent, and inaccessible to non-experts. We introduce Promptomatix, an automatic prompt optimization framework that transforms natural language task descriptions into high-quality prompts without requiring manual tuning or domain expertise. Promptomatix supports both a lightweight meta-prompt-based optimizer and a DSPy-powered compiler, with modular design enabling future extension to more advanced frameworks. The system analyzes user intent, generates synthetic training data, selects prompting strategies, and refines prompts using cost-aware objectives. Evaluated across 5 task categories, Promptomatix achieves competitive or superior performance compared to existing libraries, while reducing prompt length and computational overhead making prompt optimization scalable and efficient.",
      "authors": [
        "Rithesh Murthy",
        "Ming Zhu",
        "Liangwei Yang",
        "Jielin Qiu",
        "Juntao Tan",
        "Shelby Heinecke",
        "Huan Wang",
        "Caiming Xiong",
        "Silvio Savarese"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T18:18:20+00:00",
          "link": "https://arxiv.org/abs/2507.14241v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14241",
        "HTML": "https://arxiv.org/html/2507.14241",
        "PDF": "https://arxiv.org/pdf/2507.14241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on prompt optimization for large language models, not on training data processing. It provides an automatic framework for prompt creation and refinement rather than addressing data processing operations like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15260",
      "abstract": "Diffusion-based generative models have become dominant generators of high-fidelity images and videos but remain limited by their computationally expensive inference procedures. Existing acceleration techniques either require extensive model retraining or compromise significantly on sample quality. This paper explores a general, training-free, and model-agnostic acceleration strategy via multi-core parallelism. Our framework views multi-core diffusion sampling as an ODE solver pipeline, where slower yet accurate solvers progressively rectify faster solvers through a theoretically justified inter-core communication mechanism. This motivates our multi-core training-free diffusion sampling accelerator, CHORDS, which is compatible with various diffusion samplers, model architectures, and modalities. Through extensive experiments, CHORDS significantly accelerates sampling across diverse large-scale image and video diffusion models, yielding up to 2.1x speedup with four cores, improving by 50% over baselines, and 2.9x speedup with eight cores, all without quality degradation. This advancement enables CHORDS to establish a solid foundation for real-time, high-fidelity diffusion generation.",
      "authors": [
        "Jiaqi Han",
        "Haotian Ye",
        "Puheng Li",
        "Minkai Xu",
        "James Zou",
        "Stefano Ermon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:48:47+00:00",
          "link": "https://arxiv.org/abs/2507.15260v1",
          "size": "3500kb",
          "version": "v1"
        }
      ],
      "title": "CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15260",
        "PDF": "https://arxiv.org/pdf/2507.15260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores acceleration strategies for diffusion sampling of generative models, which does not pertain to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15511",
      "abstract": "We present, to our knowledge, the first deterministic, certificate-sensitive algorithm for a canonical NP-complete problem whose runtime provably adapts to the structure of each input. For a Subset-Sum instance $(S, t)$, let $\\Sigma(S)$ denote the set of distinct subset sums and define $U = |\\Sigma(S)|$. This set serves as an information-theoretically minimal witness, the instance-complexity (IC) certificate.\n  Our solver, IC-SubsetSum, enumerates every element of $\\Sigma(S)$ in deterministic time $O(U \\cdot n^2)$ and space $O(U \\cdot n)$. A randomized variant achieves expected runtime $O(U \\cdot n)$. The algorithm's complexity is thus directly governed by the certificate size, and this structure-sensitive performance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 - \\varepsilon})$ for some constant $\\varepsilon > 0$, the first such result to strictly outperform classical methods on every instance.\n  We revisit fine-grained reductions that rely on the classical $2^{n/2}$ hardness of SubsetSum and show that these arguments hold only for collision-free instances where $U$ is maximal. IC-SubsetSum reframes this barrier structurally and introduces a new paradigm for certificate-sensitive algorithms across NP-complete problems.",
      "authors": [
        "Jesus Salas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:26:38+00:00",
          "link": "https://arxiv.org/abs/2507.15511v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Certificate-Sensitive Subset Sum: Realizing Instance Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15511",
        "HTML": "https://arxiv.org/html/2507.15511",
        "PDF": "https://arxiv.org/pdf/2507.15511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel algorithm for solving the subset-sum problem with a focus on algorithm complexity, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15523",
      "abstract": "Domain shift is a prominent problem in Deep Learning, causing a model pre-trained on a source dataset to suffer significant performance degradation on test datasets. This research aims to address the issue of audio classification under domain shift caused by background noise using Test-Time Adaptation (TTA), a technique that adapts a pre-trained model during testing using only unlabelled test data before making predictions. We adopt two common TTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and investigate their respective performance on two popular audio classification datasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types of background noise and noise severity levels. The experimental results reveal that our proposed modified version of CoNMix produced the highest classification accuracy under domain shift (5.31% error rate under 10 dB exercise bike background noise and 12.75% error rate under 3 dB running tap background noise for AM) compared to TTT and TENT. The literature search provided no evidence of similar works, thereby motivating the work reported here as the first study to leverage TTA techniques for audio classification under domain shift.",
      "authors": [
        "Weichuang Shao",
        "Iman Yi Liao",
        "Tomas Henrique Bode Maul",
        "and Tissa Chandesa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:44:24+00:00",
          "link": "https://arxiv.org/abs/2507.15523v1",
          "size": "7172kb",
          "version": "v1"
        }
      ],
      "title": "An Investigation of Test-time Adaptation for Audio Classification under Background Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15523",
        "HTML": "https://arxiv.org/html/2507.15523",
        "PDF": "https://arxiv.org/pdf/2507.15523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers around test-time adaptation for audio classification under background noise, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.17351",
      "abstract": "SmartNICs are increasingly deployed in datacenters to offload tasks from server CPUs, improving the efficiency and flexibility of datacenter security, networking and storage. Optimizing cloud server efficiency in this way is critically important to ensure that virtually all server resources are available to paying customers. Userspace system software, specifically, decision-making tasks performed by various operating system subsystems, is particularly well suited for execution on mid-tier SmartNIC ARM cores. To this end, we introduce Wave, a framework for offloading userspace system software to processes/agents running on the SmartNIC. Wave uses Linux userspace systems to better align system functionality with SmartNIC capabilities. It also introduces a new host-SmartNIC communication API that enables offloading of even $\\mu$s-scale system software. To evaluate Wave, we offloaded preexisting userspace system software including kernel thread scheduling, memory management, and an RPC stack to SmartNIC ARM cores, which showed a performance degradation of 1.1%-7.4% in an apples-to-apples comparison with on-host implementations. Wave recovered host resources consumed by on-host system software for memory management (saving 16 host cores), RPCs (saving 8 host cores), and virtual machines (an 11.2% performance improvement). Wave highlights the potential for rethinking system software placement in modern datacenters, unlocking new opportunities for efficiency and scalability.",
      "authors": [
        "Jack Tigar Humphries",
        "Neel Natu",
        "Kostis Kaffes",
        "Stanko Novakovi\\'c",
        "Paul Turner",
        "Hank Levy",
        "David Culler",
        "Christos Kozyrakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T15:30:00+00:00",
          "link": "https://arxiv.org/abs/2408.17351v1",
          "size": "260kb",
          "version": "v1"
        },
        {
          "date": "2024-10-20T19:41:12+00:00",
          "link": "https://arxiv.org/abs/2408.17351v2",
          "size": "243kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T17:44:57+00:00",
          "link": "https://arxiv.org/abs/2408.17351v3",
          "size": "852kb",
          "version": "v3"
        }
      ],
      "title": "Wave: Offloading Resource Management to SmartNIC Cores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.17351",
        "PDF": "https://arxiv.org/pdf/2408.17351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses offloading userspace system software to SmartNICs in datacenters to improve efficiency, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14270",
      "abstract": "We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both computationally efficient and elegant. The proposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters $\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\\% test accuracy in just 20 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and computational efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it.",
      "authors": [
        "Ravin Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:17:40+00:00",
          "link": "https://arxiv.org/abs/2507.14270v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14270",
        "HTML": "https://arxiv.org/html/2507.14270",
        "PDF": "https://arxiv.org/pdf/2507.14270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel neural architecture, APTx Neuron, for computation efficiency and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14519",
      "abstract": "Privacy-preserving machine learning (PPML) based on cryptographic protocols has emerged as a promising paradigm to protect user data privacy in cloud-based machine learning services. While it achieves formal privacy protection, PPML often incurs significant efficiency and scalability costs due to orders of magnitude overhead compared to the plaintext counterpart. Therefore, there has been a considerable focus on mitigating the efficiency gap for PPML. In this survey, we provide a comprehensive and systematic review of recent PPML studies with a focus on cross-level optimizations. Specifically, we categorize existing papers into protocol level, model level, and system level, and review progress at each level. We also provide qualitative and quantitative comparisons of existing works with technical insights, based on which we discuss future research directions and highlight the necessity of integrating optimizations across protocol, model, and system levels. We hope this survey can provide an overarching understanding of existing approaches and potentially inspire future breakthroughs in the PPML field. As the field is evolving fast, we also provide a public GitHub repository to continuously track the developments, which is available at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.",
      "authors": [
        "Wenxuan Zeng",
        "Tianshi Xu",
        "Yi Chen",
        "Yifan Zhou",
        "Mingzhe Zhang",
        "Jin Tan",
        "Cheng Hong",
        "Meng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:45:39+00:00",
          "link": "https://arxiv.org/abs/2507.14519v1",
          "size": "17093kb",
          "version": "v1"
        }
      ],
      "title": "Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14519",
        "HTML": "https://arxiv.org/html/2507.14519",
        "PDF": "https://arxiv.org/pdf/2507.14519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a systematic review of privacy-preserving ML techniques and does not discuss LLM training data processing, focusing instead on cryptographic protocols and PPML optimizations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14702",
      "abstract": "Excessive use of smartphones is a worldwide known issue. In this study, we proposed a notification-based intervention approach to reduce smartphone overuse without making the user feel any annoyance or irritation. Most of the work in this field tried to reduce smartphone overuse by making smartphone use more difficult for the user. In our user study (n = 109), we found that 19.3% of the participants are unwilling to use any usage-limiting application because a) they do not want their smartphone activities to get restricted or b) those applications are annoying. Following that, we devised a hypothesis to minimize smartphone usage among undergraduates. Finally, we designed a prototype for Android, \"App Usage Monitor,\" and conducted a 3-week experiment through which we found proof of concept for our hypothesis. In our prototype, we combined techniques such as nudge and visualization to increase self-awareness among the user by leveraging notifications.",
      "authors": [
        "Partha Sarker",
        "Dipto Dey",
        "Marium-E-Jannat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:39:48+00:00",
          "link": "https://arxiv.org/abs/2507.14702v1",
          "size": "1902kb",
          "version": "v1"
        }
      ],
      "title": "A Notification Based Nudge for Handling Excessive Smartphone Use",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14702",
        "HTML": "https://arxiv.org/html/2507.14702",
        "PDF": "https://arxiv.org/pdf/2507.14702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates reducing smartphone overuse through notification-based interventions and is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15024",
      "abstract": "With the rapid advancement of Large Language Models (LLMs), developing effective critic modules for precise guidance has become crucial yet challenging. In this paper, we initially demonstrate that supervised fine-tuning for building critic modules (which is widely adopted in current solutions) fails to genuinely enhance models' critique abilities, producing superficial critiques with insufficient reflections and verifications. To unlock the unprecedented critique capabilities, we propose RefCritic, a long-chain-of-thought critic module based on reinforcement learning with dual rule-based rewards: (1) instance-level correctness of solution judgments and (2) refinement accuracies of the policy model based on critiques, aiming to generate high-quality evaluations with actionable feedback that effectively guides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and DeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement settings, RefCritic demonstrates consistent advantages across all benchmarks, e.g., 6.8\\% and 7.2\\% gains on AIME25 for the respective base models. Notably, under majority voting, policy models filtered by RefCritic show superior scaling with increased voting numbers. Moreover, despite training on solution-level supervision, RefCritic outperforms step-level supervised approaches on ProcessBench, a benchmark to identify erroneous steps in mathematical reasoning.",
      "authors": [
        "Qiaoyu Tang",
        "Hao Xiang",
        "Le Yu",
        "Bowen Yu",
        "Hongyu Lin",
        "Yaojie Lu",
        "Xianpei Han",
        "Le Sun",
        "Junyang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:19:51+00:00",
          "link": "https://arxiv.org/abs/2507.15024v1",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "title": "RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15024",
        "HTML": "https://arxiv.org/html/2507.15024",
        "PDF": "https://arxiv.org/pdf/2507.15024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the training of critic modules using reinforcement learning and refinement feedback, important for enhancing LLM performance; however, the primary focus is not on data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15041",
      "abstract": "In India, online news media outlets were an important source of information for people with digital access during the COVID-19 pandemic. In India, where \"transgender\" was legally recognised as a category only in 2014, and same-sex marriages are yet to be legalised, it becomes crucial to analyse whether and how they reported the lived realities of vulnerable LGBTQ+ communities during the pandemic. This study analysed articles from online editions of two English-language newspaper websites, which differed vastly in their circulation figures-The Times of India and The Indian Express. The results of our study suggest that these newspaper websites published articles surrounding various aspects of the lives of LGBTQ+ individuals with a greater focus on transgender communities. However, they lacked quality and depth. Focusing on the period spanning March 2020 to August 2021, we analysed articles using sentiment analysis and topic modelling. We also compared our results to the period before the pandemic (January 2019 - December 2019) to understand the shift in topics, sentiments, and stances across the two newspaper websites. A manual analysis of the articles indicated that the language used in certain articles by The Times of India was transphobic and obsolete. Our study captures the visibility and representation of the LGBTQ+ communities in Indian newspaper websites during the pandemic.",
      "authors": [
        "Dhruvee Birla",
        "Nazia Akhtar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:45:38+00:00",
          "link": "https://arxiv.org/abs/2507.15041v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "Visibility vs. Engagement: How Two Indian News Websites Reported on LGBTQ+ Individuals and Communities during the Pandemic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15041",
        "HTML": "https://arxiv.org/html/2507.15041",
        "PDF": "https://arxiv.org/pdf/2507.15041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes the reporting of LGBTQ+ issues in Indian media and uses sentiment analysis, but it does not make contributions to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15379",
      "abstract": "Taxes finance important government services that are now taken for granted in our society, such as infrastructure, health care, or retirement pensions. Tax authorities everywhere strive to ensure that all individuals and organizations comply with applicable tax laws. In this regard, tax authorities must prevent individuals and organizations from evading taxes in an illegal manner. To this end, Austrian tax authorities employ state-of-the-art predictive analytics technology for the selection of suspicious cases for tax audits, thus making efficient use of scarce resources for tax auditing. In this paper, we explore how Austrian tax authorities employ predictive analytics technology in tax auditing and how well the use of such technology fits the characteristics of the task at hand. We collaborated with the Austrian Federal Ministry of Finance's Predictive Analytics Competence Center to obtain insights into the application of predictive analytics technology by Austrian tax authorities. The thus obtained insights serve as the basis for a qualitative analysis in the context of the task-technology fit framework.",
      "authors": [
        "Simon Staudinger and Christoph G. Schuetz and Marina Luketina"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:35:22+00:00",
          "link": "https://arxiv.org/abs/2507.15379v1",
          "size": "428kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Use of Predictive Analytics by Austrian Tax Authorities: A Qualitative Study within the Task-Technology Fit Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15379",
        "HTML": "https://arxiv.org/html/2507.15379",
        "PDF": "https://arxiv.org/pdf/2507.15379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of predictive analytics by Austrian tax authorities within the task-technology fit framework, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15558",
      "abstract": "This article presents a method for improving a keyword spotter (KWS) algorithm in noisy environments. Although beamforming (BF) and adaptive noise cancellation (ANC) techniques are robust in some conditions, they may degrade the performance of the activation system by distorting or suppressing useful signals. The authors propose a neural network architecture that uses several input channels and an attention mechanism that allows the network to determine the most useful channel or their combination. The improved quality of the algorithm was demonstrated on two datasets: from a laboratory with controlled conditions and from smart speakers in natural conditions. The proposed algorithm was compared against several baselines in terms of the quality of noise reduction metrics, KWS metrics, and computing resources in comparison with existing solutions.",
      "authors": [
        "Dzmitry Saladukha",
        "Ivan Koriabkin",
        "Kanstantsin Artsiom",
        "Aliaksei Rak",
        "Nikita Ryzhikov"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:38:54+00:00",
          "link": "https://arxiv.org/abs/2507.15558v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "Multichannel Keyword Spotting for Noisy Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15558",
        "HTML": "https://arxiv.org/html/2507.15558",
        "PDF": "https://arxiv.org/pdf/2507.15558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an improved keyword spotting algorithm in noisy conditions, focusing on audio signal processing and algorithm design, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06348",
      "abstract": "Understanding the motivations underlying the human inclination to automate tasks is vital to developing truly helpful robots integrated into daily life. Accordingly, we ask: are individuals more inclined to automate chores based on the time they consume or the feelings experienced while performing them? This study explores these preferences and whether they vary across different social groups (i.e., gender category and income level). Leveraging data from the BEHAVIOR-1K dataset, the American Time-Use Survey, and the American Time-Use Survey Well-Being Module, we investigate the relationship between the desire for automation, time spent on daily activities, and their associated feelings - Happiness, Meaningfulness, Sadness, Painfulness, Stressfulness, or Tiredness. Our key findings show that, despite common assumptions, time spent does not strongly relate to the desire for automation for the general population. For the feelings analyzed, only happiness and pain are key indicators. Significant differences by gender and economic level also emerged: Women prefer to automate stressful activities, whereas men prefer to automate those that make them unhappy; mid-income individuals prioritize automating less enjoyable and meaningful activities, while low and high-income show no significant correlations. We hope our research helps motivate technologies to develop robots that match the priorities of potential users, moving domestic robotics toward more socially relevant solutions. We open-source all the data, including an online tool that enables the community to replicate our analysis and explore additional trends at https://hri1260.github.io/why-automate-this.",
      "authors": [
        "Ruchira Ray",
        "Leona Pang",
        "Sanjana Srivastava",
        "Li Fei-Fei",
        "Samantha Shorey",
        "Roberto Mart\\'in-Mart\\'in"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T21:20:11+00:00",
          "link": "https://arxiv.org/abs/2501.06348v1",
          "size": "2403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T16:18:12+00:00",
          "link": "https://arxiv.org/abs/2501.06348v2",
          "size": "1860kb",
          "version": "v2"
        }
      ],
      "title": "Why Automate This? Exploring the Connection between Time Use, Well-being and Robot Automation Across Social Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06348",
        "PDF": "https://arxiv.org/pdf/2501.06348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores social preferences for task automation using survey data, focusing on human behavior and robot automation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.16772",
      "abstract": "A tenet of reinforcement learning is that the agent always observes rewards. However, this is not true in many realistic settings, e.g., a human observer may not always be available to provide rewards, sensors may be limited or malfunctioning, or rewards may be inaccessible during deployment. Monitored Markov decision processes (Mon-MDPs) have recently been proposed to model such settings. However, existing Mon-MDP algorithms have several limitations: they do not fully exploit the problem structure, cannot leverage a known monitor, lack worst-case guarantees for 'unsolvable' Mon-MDPs without specific initialization, and offer only asymptotic convergence proofs. This paper makes three contributions. First, we introduce a model-based algorithm for Mon-MDPs that addresses these shortcomings. The algorithm employs two instances of model-based interval estimation: one to ensure that observable rewards are reliably captured, and another to learn the minimax-optimal policy. Second, we empirically demonstrate the advantages. We show faster convergence than prior algorithms in over four dozen benchmarks, and even more dramatic improvement when the monitoring process is known. Third, we present the first finite-sample bound on performance. We show convergence to a minimax-optimal policy even when some rewards are never observable.",
      "authors": [
        "Alireza Kazemipour",
        "Simone Parisi",
        "Matthew E. Taylor",
        "Michael Bowling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T01:35:32+00:00",
          "link": "https://arxiv.org/abs/2502.16772v1",
          "size": "4402kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T20:13:39+00:00",
          "link": "https://arxiv.org/abs/2502.16772v2",
          "size": "21096kb",
          "version": "v2"
        },
        {
          "date": "2025-05-30T14:57:33+00:00",
          "link": "https://arxiv.org/abs/2502.16772v3",
          "size": "3528kb",
          "version": "v3"
        },
        {
          "date": "2025-06-05T21:52:08+00:00",
          "link": "https://arxiv.org/abs/2502.16772v4",
          "size": "3537kb",
          "version": "v4"
        },
        {
          "date": "2025-06-24T17:32:18+00:00",
          "link": "https://arxiv.org/abs/2502.16772v5",
          "size": "3537kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T15:25:51+00:00",
          "link": "https://arxiv.org/abs/2502.16772v6",
          "size": "3537kb",
          "version": "v6"
        }
      ],
      "title": "Model-Based Exploration in Monitored Markov Decision Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16772",
        "PDF": "https://arxiv.org/pdf/2502.16772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with improvements in reinforcement learning through a model-based approach for Monitored Markov Decision Processes (Mon-MDPs). It does not address training data processing for LLMs or involve any related data operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10125",
      "abstract": "In the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a (multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost $k$-edge-connected spanning subgraph of $G$. The problem admits a $2$-approximation algorithm and no better approximation ratio is known. Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria $(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected spanning subgraph of cost at most the optimal value of a standard Cut-LP for $k$-ECSS. This LP bicriteria approximation was recently improved by Cohen and Nutov [ESA 25] to $(1,k-4)$, where also was given a bicriteria approximation $(3/2,k-2)$. In this paper we improve the bicriteria approximation to $(1,k-2)$ for $k$ even and to $\\left(1-\\frac{1}{k},k-3\\right)$ for $k$ is odd, and also give another bicriteria approximation $(3/2,k-1)$. After this paper was written, we became aware that the same result was achieved earlier by Kumar and Swamy.\n  The $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost the same as $k$-ECSS, except that any edge can be selected multiple times at the same cost. The previous best approximation ratio for $k$-ECSM was $1+4/k$. Our result improves this to $1+\\frac{2}{k}$ for $k$ even and to $1+\\frac{3}{k}$ for $k$ odd, where for $k$ odd the computed subgraph is in fact $(k+1)$-edge-connected.",
      "authors": [
        "Zeev Nutov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.10125v1",
          "size": "276kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:35:41+00:00",
          "link": "https://arxiv.org/abs/2507.10125v2",
          "size": "227kb",
          "version": "v2"
        }
      ],
      "title": "Improved bicriteria approximation for $k$-edge-connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10125",
        "HTML": "https://arxiv.org/html/2507.10125",
        "PDF": "https://arxiv.org/pdf/2507.10125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with approximation algorithms for edge-connectivity problems in graph theory. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14353",
      "abstract": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach for adapting a Large Language Model (LLM) for newer tasks. One of the most prominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on adjusting the attention weight matrices within individual decoder blocks of a Generative Pre trained Transformer (GPT2). In contrast, we introduce Solo Connection a novel method that adapts the representation at the decoder-block level rather than modifying individual weight matrices. Not only does Solo Connection outperform LoRA on E2E natural language generation benchmarks, but it also reduces the number of trainable parameters by 59% relative to LoRA and by more than 99% compared to full fine-tuning of GPT2, an early version of Large Language Models (LLMs). Solo Connection is also motivated by homotopy theory: we introduce a trainable linear transformation that gradually interpolates between a zero vector and the task-specific representation, enabling smooth and stable adaptation over time. While skip connections in the original 12 layer GPT2 are typically confined to individual decoder blocks, subsequent GPT2 variants scale up to 48 layers, and even larger language models can include 128 or more decoder blocks. These expanded architectures underscore the need to revisit how skip connections are employed during fine-tuning. This paper focuses on long skip connections that link outputs of different decoder blocks, potentially enhancing the model's ability to adapt to new tasks while leveraging pre-trained knowledge.",
      "authors": [
        "Harsh Nilesh Pathak and Randy Paffenroth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T20:11:50+00:00",
          "link": "https://arxiv.org/abs/2507.14353v1",
          "size": "654kb",
          "version": "v1"
        }
      ],
      "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14353",
        "HTML": "https://arxiv.org/html/2507.14353",
        "PDF": "https://arxiv.org/pdf/2507.14353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a parameter efficient fine-tuning technique for transformers (LLMs), focusing on model architecture rather than training data processing. The relation to data processing is not explicit or central."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14652",
      "abstract": "Hamiltonian Monte Carlo (HMC) is a powerful and accurate method to sample from the posterior distribution in Bayesian inference. However, HMC techniques are computationally demanding for Bayesian neural networks due to the high dimensionality of the network's parameter space and the non-convexity of their posterior distributions. Therefore, various approximation techniques, such as variational inference (VI) or stochastic gradient MCMC, are often employed to infer the posterior distribution of the network parameters. Such approximations introduce inaccuracies in the inferred distributions, resulting in unreliable uncertainty estimates. In this work, we propose a hybrid approach that combines inexpensive VI and accurate HMC methods to efficiently and accurately quantify uncertainties in neural networks and neural operators. The proposed approach leverages an initial VI training on the full network. We examine the influence of individual parameters on the prediction uncertainty, which shows that a large proportion of the parameters do not contribute substantially to uncertainty in the network predictions. This information is then used to significantly reduce the dimension of the parameter space, and HMC is performed only for the subset of network parameters that strongly influence prediction uncertainties. This yields a framework for accelerating the full batch HMC for posterior inference in neural networks. We demonstrate the efficiency and accuracy of the proposed framework on deep neural networks and operator networks, showing that inference can be performed for large networks with tens to hundreds of thousands of parameters. We show that this method can effectively learn surrogates for complex physical systems by modeling the operator that maps from upstream conditions to wall-pressure data on a cone in hypersonic flow.",
      "authors": [
        "Ponkrshnan Thiagarajan",
        "Tamer A. Zaki and Michael D. Shields"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:57:54+00:00",
          "link": "https://arxiv.org/abs/2507.14652v1",
          "size": "12827kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Hamiltonian Monte Carlo for Bayesian Inference in Neural Networks and Neural Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14652",
        "HTML": "https://arxiv.org/html/2507.14652",
        "PDF": "https://arxiv.org/pdf/2507.14652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on accelerating Hamiltonian Monte Carlo for Bayesian inference in neural networks, which does not pertain to LLM training data processing such as dataset creation, collection, or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.05403",
      "abstract": "System auditing is a vital technique for collecting system call events as system provenance and investigating complex multi-step attacks such as Advanced Persistent Threats. However, existing attack investigation methods struggle to uncover long attack sequences due to the massive volume of system provenance data and their inability to focus on attack-relevant parts. In this paper, we present Provexa, a defense system that enables human analysts to effectively analyze large-scale system provenance to reveal multi-step attack sequences. Provexa introduces an expressive domain-specific language, ProvQL, that offers essential primitives for various types of attack analyses (e.g., attack pattern search, attack dependency tracking) with user-defined constraints, enabling analysts to focus on attack-relevant parts and iteratively sift through the large provenance data. Moreover, Provexa provides an optimized execution engine for efficient language execution. Our extensive evaluations on a wide range of attack scenarios demonstrate the practical effectiveness of Provexa in facilitating timely attack investigation.",
      "authors": [
        "Saimon Amanuel Tsegai",
        "Xinyu Yang",
        "Haoyuan Liu",
        "Peng Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-10T08:13:19+00:00",
          "link": "https://arxiv.org/abs/2211.05403v1",
          "size": "312kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T05:18:59+00:00",
          "link": "https://arxiv.org/abs/2211.05403v2",
          "size": "293kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T13:51:04+00:00",
          "link": "https://arxiv.org/abs/2211.05403v3",
          "size": "238kb",
          "version": "v3"
        }
      ],
      "title": "Enabling Efficient Attack Investigation via Human-in-the-Loop Security Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.05403",
        "PDF": "https://arxiv.org/pdf/2211.05403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a system for analyzing system provenance to investigate attacks, which is unrelated to the processing of LLM training data, focusing instead on security analysis."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2305.02957",
      "abstract": "Fixpoints are ubiquitous in computer science as they play a central role in providing a meaning to recursive and cyclic definitions. Bisimilarity, behavioural metrics, termination probabilities for Markov chains and stochastic games are defined in terms of least or greatest fixpoints. Here we show that our recent work which proposes a technique for checking whether the fixpoint of a function is the least (or the largest) admits a natural categorical interpretation in terms of gs-monoidal categories. The technique is based on a construction that maps a function to a suitable approximation. We study the compositionality properties of this mapping and show that under some restrictions it can naturally be interpreted as a (lax) gs-monoidal functor. This guides the development of a tool, called UDEfix that allows us to build functions (and their approximations) like a circuit out of basic building blocks and subsequently perform the fixpoints checks. We also show that a slight generalisation of the theory allows one to treat a new relevant case study: coalgebraic behavioural metrics based on Wasserstein liftings.",
      "authors": [
        "Paolo Baldan and Richard Eggert and Barbara K\\\"onig and Timo Matt and Tommaso Padoan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-04T16:04:34+00:00",
          "link": "https://arxiv.org/abs/2305.02957v1",
          "size": "155kb",
          "version": "v1"
        },
        {
          "date": "2024-01-15T07:38:54+00:00",
          "link": "https://arxiv.org/abs/2305.02957v2",
          "size": "505kb",
          "version": "v2"
        },
        {
          "date": "2024-12-18T18:26:09+00:00",
          "link": "https://arxiv.org/abs/2305.02957v3",
          "size": "493kb",
          "version": "v3"
        },
        {
          "date": "2025-05-12T14:29:37+00:00",
          "link": "https://arxiv.org/abs/2305.02957v4",
          "size": "462kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T13:45:21+00:00",
          "link": "https://arxiv.org/abs/2305.02957v5",
          "size": "463kb",
          "version": "v5"
        }
      ],
      "title": "A Monoidal View on Fixpoint Checks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.02957",
        "PDF": "https://arxiv.org/pdf/2305.02957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a categorical interpretation of fixpoint checks in computer science, specifically related to gs-monoidal categories and coalgebraic behavioural metrics. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.14146",
      "abstract": "Textual style expresses a diverse set of information, including interpersonal dynamics (e.g., formality) and the author's emotions or attitudes (e.g., disgust). An open question is how language models can be explicitly controlled so that they weave together target styles when generating text: for example, to produce text that is both negative and non-toxic. One approach to such controlled generation is multi-objective reinforcement learning (RL), but how best to combine multiple objectives in a reward function is an open question. In this paper, we investigate various formulations of multi-style rewards, including calibrated outputs from discriminators and dynamic weighting by discriminator gradient magnitudes. We find that our proposed dynamic weighting outperforms static weighting approaches with respect to style control while maintaining linguistic quality, and we explore its effectiveness in 2- and 3-style control.",
      "authors": [
        "Karin de Langis",
        "Ryan Koo",
        "Dongyeop Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T22:02:37+00:00",
          "link": "https://arxiv.org/abs/2402.14146v1",
          "size": "8338kb",
          "version": "v1"
        },
        {
          "date": "2024-10-23T04:39:25+00:00",
          "link": "https://arxiv.org/abs/2402.14146v2",
          "size": "8541kb",
          "version": "v2"
        },
        {
          "date": "2024-10-29T11:13:14+00:00",
          "link": "https://arxiv.org/abs/2402.14146v3",
          "size": "8541kb",
          "version": "v3"
        }
      ],
      "title": "Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.14146",
        "HTML": "https://arxiv.org/html/2402.14146",
        "PDF": "https://arxiv.org/pdf/2402.14146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores controlled text generation using multi-objective reinforcement learning, involving weighting of style rewards, which indirectly relates to fine-tuning operations. However, the main focus is on the generation method rather than on the training data processing itself."
      },
      "tasks": [
        "Multi-Objective Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/minnesotanlp/dynamic-multi-reward-weighting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11066",
      "abstract": "This paper describes the development of the Four Model Tree Ensemble (FMTE). The FMTE is a composite of machine learning models trained on experimental binding energies from the Atomic Mass Evaluation (AME) 2012. The FMTE predicts binding energy values for all nuclei with N > 7 and Z > 7 from AME 2020 with a standard deviation of 76 keV and a mean average deviation of 34 keV. The FMTE model was developed by combining three new models with one prior model. The new models presented here have been trained on binding energy residuals from mass models using four machine learning approaches. The models presented in this work leverage shape parameters along with other physical features. We have determined the preferred machine learning approach for binding energy residuals is the least-squares boosted ensemble of trees. This approach appears to have a superior ability to both interpolate and extrapolate binding energy residuals. A comparison with the masses of isotopes that were not measured previously and a discussion of extrapolations approaching the neutron drip line have been included.",
      "authors": [
        "I. Bentley",
        "J. Tedder",
        "M. Gebran",
        "and A. Paul"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Nuclear Theory (nucl-th)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T04:19:23+00:00",
          "link": "https://arxiv.org/abs/2503.11066v1",
          "size": "7374kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T11:01:56+00:00",
          "link": "https://arxiv.org/abs/2503.11066v2",
          "size": "7285kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T14:19:32+00:00",
          "link": "https://arxiv.org/abs/2503.11066v3",
          "size": "4931kb",
          "version": "v3"
        }
      ],
      "title": "Further exploration of binding energy residuals using machine learning and the development of a composite ensemble model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11066",
        "PDF": "https://arxiv.org/pdf/2503.11066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on developing a composite ensemble model for predicting nuclear binding energies, without any connection to LLM training data processing."
      },
      "tasks": [
        "Physics-informed machine learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10921",
      "abstract": "China has a long and rich history, encompassing a vast cultural heritage that includes diverse multimodal information, such as silk patterns, Dunhuang murals, and their associated historical narratives. Cross-modal retrieval plays a pivotal role in understanding and interpreting Chinese cultural heritage by bridging visual and textual modalities to enable accurate text-to-image and image-to-text retrieval. However, despite the growing interest in multimodal research, there is a lack of specialized datasets dedicated to Chinese cultural heritage, limiting the development and evaluation of cross-modal learning models in this domain. To address this gap, we propose a multimodal dataset named CulTi, which contains 5,726 image-text pairs extracted from two series of professional documents, respectively related to ancient Chinese silk and Dunhuang murals. Compared to existing general-domain multimodal datasets, CulTi presents a challenge for cross-modal retrieval: the difficulty of local alignment between intricate decorative motifs and specialized textual descriptions. To address this challenge, we propose LACLIP, a training-free local alignment strategy built upon a fine-tuned Chinese-CLIP. LACLIP enhances the alignment of global textual descriptions with local visual regions by computing weighted similarity scores during inference. Experimental results on CulTi demonstrate that LACLIP significantly outperforms existing models in cross-modal retrieval, particularly in handling fine-grained semantic associations within Chinese cultural heritage.",
      "authors": [
        "Junyi Yuan",
        "Jian Zhang",
        "Fangyu Wu",
        "Dongming Lu",
        "Huanda Lu",
        "Qiufeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T06:52:46+00:00",
          "link": "https://arxiv.org/abs/2505.10921v1",
          "size": "8386kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:40:24+00:00",
          "link": "https://arxiv.org/abs/2505.10921v2",
          "size": "6781kb",
          "version": "v2"
        }
      ],
      "title": "Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10921",
        "HTML": "https://arxiv.org/html/2505.10921",
        "PDF": "https://arxiv.org/pdf/2505.10921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cross-modal retrieval in Chinese cultural heritage documents and proposes a dataset for multimodal data. It does not relate to LLM training data processing operations like data collection, filtering, or quality improvements specific to LLMs."
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Image to text",
        "Image-to-Text Retrieval",
        "Retrieval",
        "Text Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17556",
      "abstract": "The Nystr\\\"om method is a popular low-rank approximation technique for large matrices that arise in kernel methods and convex optimization. Yet, when the data exhibits heavy-tailed spectral decay, the effective dimension of the problem often becomes so large that even the Nystr\\\"om method may be outside of our computational budget. To address this, we propose Block-Nystr\\\"om, an algorithm that injects a block-diagonal structure into the Nystr\\\"om method, thereby significantly reducing its computational cost while recovering strong approximation guarantees. We show that Block-Nystr\\\"om can be used to construct improved preconditioners for second-order optimization, as well as to efficiently solve kernel ridge regression for statistical learning over Hilbert spaces. Our key technical insight is that, within the same computational budget, combining several smaller Nystr\\\"om approximations leads to stronger tail estimates of the input spectrum than using one larger approximation. Along the way, we provide a novel recursive preconditioning scheme for efficiently inverting the Block-Nystr\\\"om matrix, and provide new statistical learning bounds for a broad class of approximate kernel ridge regression solvers.",
      "authors": [
        "Sachin Garg",
        "Micha{\\l} Derezi\\'nski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T02:50:37+00:00",
          "link": "https://arxiv.org/abs/2506.17556v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T03:04:49+00:00",
          "link": "https://arxiv.org/abs/2506.17556v2",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "title": "Faster Low-Rank Approximation and Kernel Ridge Regression via the Block-Nystr\\\"om Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17556",
        "PDF": "https://arxiv.org/pdf/2506.17556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a low-rank approximation method for large matrices in optimization and kernel methods, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21763",
      "abstract": "Large Language Models (LLMs) are accelerating scientific idea generation, but rigorously evaluating these numerous, often superficial, AI-generated propositions for novelty and factual accuracy is a critical bottleneck; manual verification is too slow. Existing validation methods are inadequate: LLMs as standalone verifiers may hallucinate and lack domain knowledge (our findings show 60% unawareness of relevant papers in specific domains), while traditional citation networks lack explicit causality and narrative surveys are unstructured. This underscores a core challenge: the absence of structured, verifiable, and causally-linked historical data of scientific evolution.To address this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology \\textbf{H}istory \\textbf{E}volution Tree), a computational framework that constructs such domain-specific evolution trees from scientific literature. THE-Tree employs a search algorithm to explore evolutionary paths. During its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\" process: an LLM proposes potential advancements and cites supporting literature. Critically, each proposed evolutionary link is then validated for logical coherence and evidential support by a recovered natural language inference mechanism that interrogates the cited literature, ensuring that each step is grounded. We construct and validate 88 THE-Trees across diverse domains and release a benchmark dataset including up to 71k fact verifications covering 27k papers to foster further research. Experiments demonstrate that i) in graph completion, our THE-Tree improves hit@1 by 8% to 14% across multiple models compared to traditional citation networks; ii) for predicting future scientific developments, it improves hit@1 metric by nearly 10%; and iii) when combined with other methods, it boosts the performance of evaluating important scientific papers by almost 100%.",
      "authors": [
        "Xin Wang",
        "Jiyao Liu",
        "Yulong Xiao",
        "Junzhi Ning",
        "Lihao Liu",
        "Junjun He",
        "Botian Shi",
        "Kaicheng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:44:51+00:00",
          "link": "https://arxiv.org/abs/2506.21763v1",
          "size": "14669kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T06:49:51+00:00",
          "link": "https://arxiv.org/abs/2506.21763v2",
          "size": "14674kb",
          "version": "v2"
        }
      ],
      "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21763",
        "HTML": "https://arxiv.org/html/2506.21763",
        "PDF": "https://arxiv.org/pdf/2506.21763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces THE-Tree to enhance scientific verification and reasoning, focusing on constructing evolutionary trees from literature. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09116",
      "abstract": "Despite improvements in automatic speech recognition, performance drops with accented speech. Generative error correction (GER) leverages the linguistic knowledge of large language models (LLMs), outperforming typical language model methods. However, it lacks specificity in accented speech scenarios. Accents represent deviations from standard pronunciation, making multi-granularity pronunciation and semantic information essential for accented speech recognition. Moreover, accents exhibit considerable diversity, with each accent possessing distinct characteristics. In this study, we leverage GER to improve transcription accuracy by addressing the two primary features. We propose the multi-modal GER, which integrates pronunciation information from the speech modality, and the multi-granularity GER, which incorporates fine-grained phoneme-level pronunciation information. These methods enable the LLM to utilize the pronunciation information of accented speech and the semantic information from word-level hypotheses for accurate transcription predictions through low-rank adaptation (LoRA) fine-tuning. We employ a three-stage strategy to train separate multi-modal GER models for each accent to obtain mono-accent LoRA experts. By adopting our proposed HDMoLE method, which incorporates hierarchical routing and dynamic thresholds within the mixture of LoRA experts, we effectively merge mono-accent LoRA experts within a single multi-modal GER to overcome accent diversity challenges. Furthermore, multi-granularity GER leverages N-best word-level and phoneme-level hypotheses from the HDMoLE model to predict final transcriptions. Experiments on a multi-accent English dataset show that our methods reduce word error rate by 67.35% compared to the baseline vanilla Whisper-large-v3 model.",
      "authors": [
        "Bingshen Mu",
        "Kun Wei",
        "Pengcheng Guo",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09116v1",
          "size": "1770kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:03:44+00:00",
          "link": "https://arxiv.org/abs/2507.09116v2",
          "size": "1770kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T16:25:24+00:00",
          "link": "https://arxiv.org/abs/2507.09116v3",
          "size": "1770kb",
          "version": "v3"
        }
      ],
      "title": "Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09116",
        "HTML": "https://arxiv.org/html/2507.09116",
        "PDF": "https://arxiv.org/pdf/2507.09116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improving transcription accuracy for accented speech using LLM generative error correction and LoRA fine-tuning. While it includes aspects of fine-tuning LLMs, the primary focus is on speech recognition and error correction rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14330",
      "abstract": "Software correctness is ensured mathematically through formal verification, which involves the resources of generating formal requirement specifications and having an implementation that must be verified. Tools such as model-checkers and theorem provers ensure software correctness by verifying the implementation against the specification. Formal methods deployment is regularly enforced in the development of safety-critical systems e.g. aerospace, medical devices and autonomous systems. Generating these specifications from informal and ambiguous natural language requirements remains the key challenge. Our project, VERIFAI^{1}, aims to investigate automated and semi-automated approaches to bridge this gap, using techniques from Natural Language Processing (NLP), ontology-based domain modelling, artefact reuse, and large language models (LLMs). This position paper presents a preliminary synthesis of relevant literature to identify recurring challenges and prospective research directions in the generation of verifiable specifications from informal requirements.",
      "authors": [
        "Arshad Beg and Diarmuid O'Donoghue and Rosemary Monahan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:15:50+00:00",
          "link": "https://arxiv.org/abs/2507.14330v1",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14330",
        "HTML": "https://arxiv.org/html/2507.14330",
        "PDF": "https://arxiv.org/pdf/2507.14330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on leveraging LLMs for generating formal software requirement specifications, which primarily involves NLP and ontology modeling techniques rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14935",
      "abstract": "This paper extends Cross Modal Generalization (CMG) to open-set environments by proposing the more challenging Open-set Cross Modal Generalization (OSCMG) task. This task evaluates multimodal unified representations in open-set conditions, addressing the limitations of prior closed-set cross-modal evaluations. OSCMG requires not only cross-modal knowledge transfer but also robust generalization to unseen classes within new modalities, a scenario frequently encountered in real-world applications. Existing multimodal unified representation work lacks consideration for open-set environments. To tackle this, we propose MICU, comprising two key components: Fine-Coarse Masked multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI enhances multimodal alignment by applying contrastive learning at both holistic semantic and temporal levels, incorporating masking to enhance generalization. CUJP enhances feature diversity and model uncertainty by integrating modality-agnostic feature selection with self-supervised learning, thereby strengthening the model's ability to handle unknown categories in open-set tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the effectiveness of our approach. The code is available at https://github.com/haihuangcode/CMG.",
      "authors": [
        "Hai Huang",
        "Yan Xia",
        "Shulei Wang",
        "Hanting Wang",
        "Minghui Fang",
        "Shengpeng Ji",
        "Sashuai Zhou",
        "Tao Jin",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T12:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.14935v1",
          "size": "2351kb",
          "version": "v1"
        }
      ],
      "title": "Open-set Cross Modal Generalization via Multimodal Unified Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14935",
        "HTML": "https://arxiv.org/html/2507.14935",
        "PDF": "https://arxiv.org/pdf/2507.14935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for open-set cross-modal generalization, focusing on multimodal unified representations. It does not pertain to LLM training data processing operations or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15686",
      "abstract": "Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, is proposed to realize fast inference and compact decoder size. Experimental results show that our method consistently outperforms traditional and AI-based methods: for example, with the convergence time in the MVUB dataset, our method reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and 21.95% compared to SparsePCGC. Our project can be seen on https://huangwenjie2023.github.io/LINR-PCGC/.",
      "authors": [
        "Wenjie Huang and Qi Yang and Shuting Xia and He Huang and Zhu Li and Yiling Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:48:54+00:00",
          "link": "https://arxiv.org/abs/2507.15686v1",
          "size": "5856kb",
          "version": "v1"
        }
      ],
      "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15686",
        "HTML": "https://arxiv.org/html/2507.15686",
        "PDF": "https://arxiv.org/pdf/2507.15686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on point cloud geometry compression and introduces a method for lossless compression, which is not related to LLM training data processing or any aspect of data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15728",
      "abstract": "Generating consistent long videos is a complex challenge: while diffusion-based generative models generate visually impressive short clips, extending them to longer durations often leads to memory bottlenecks and long-term inconsistency. In this paper, we propose TokensGen, a novel two-stage framework that leverages condensed tokens to address these issues. Our method decomposes long video generation into three core tasks: (1) inner-clip semantic control, (2) long-term consistency control, and (3) inter-clip smooth transition. First, we train To2V (Token-to-Video), a short video diffusion model guided by text and video tokens, with a Video Tokenizer that condenses short clips into semantically rich tokens. Second, we introduce T2To (Text-to-Token), a video token diffusion transformer that generates all tokens at once, ensuring global consistency across clips. Finally, during inference, an adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips, reducing boundary artifacts and enhancing smooth transitions. Experimental results demonstrate that our approach significantly enhances long-term temporal and content coherence without incurring prohibitive computational overhead. By leveraging condensed tokens and pre-trained short video models, our method provides a scalable, modular solution for long video generation, opening new possibilities for storytelling, cinematic production, and immersive simulations. Please see our project page at https://vicky0522.github.io/tokensgen-webpage/ .",
      "authors": [
        "Wenqi Ouyang",
        "Zeqi Xiao",
        "Danni Yang",
        "Yifan Zhou",
        "Shuai Yang",
        "Lei Yang",
        "Jianlou Si",
        "Xingang Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:37:33+00:00",
          "link": "https://arxiv.org/abs/2507.15728v1",
          "size": "6629kb",
          "version": "v1"
        }
      ],
      "title": "TokensGen: Harnessing Condensed Tokens for Long Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15728",
        "HTML": "https://arxiv.org/html/2507.15728",
        "PDF": "https://arxiv.org/pdf/2507.15728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a novel framework for long video generation, utilizing generative models and diffusion strategies, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.12033",
      "abstract": "Self-supervised learning (SSL) has emerged as a promising paradigm that presents supervisory signals to real-world problems, bypassing the extensive cost of manual labeling. Consequently, self-supervised anomaly detection (SSAD) has seen a recent surge of interest, since SSL is especially attractive for unsupervised tasks. However, recent works have reported that the choice of a data augmentation function has significant impact on the accuracy of SSAD, posing augmentation search as an essential but nontrivial problem due to lack of labeled validation data. In this paper, we introduce ST-SSAD, the first unsupervised approach to end-to-end augmentation tuning for SSAD. To this end, our work presents two key contributions. The first is a new unsupervised validation loss that quantifies the alignment between augmented training data and unlabeled validation data. The second is new differentiable augmentation functions, allowing data augmentation hyperparameter(s) to be tuned in an end-to-end manner. Experiments on two testbeds with semantic class anomalies and subtle industrial defects show that ST-SSAD gives significant performance gains over existing works. All our code and testbeds are available at https://github.com/jaeminyoo/ST-SSAD.",
      "authors": [
        "Jaemin Yoo",
        "Lingxiao Zhao",
        "and Leman Akoglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-21T05:48:51+00:00",
          "link": "https://arxiv.org/abs/2306.12033v1",
          "size": "14100kb",
          "version": "v1"
        },
        {
          "date": "2025-03-02T06:19:58+00:00",
          "link": "https://arxiv.org/abs/2306.12033v2",
          "size": "14476kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T06:10:02+00:00",
          "link": "https://arxiv.org/abs/2306.12033v3",
          "size": "7298kb",
          "version": "v3"
        }
      ],
      "title": "Self-Tuning Self-Supervised Image Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.12033",
        "HTML": "https://arxiv.org/html/2306.12033",
        "PDF": "https://arxiv.org/pdf/2306.12033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on self-supervised anomaly detection in images, specifically on data augmentation and validation for unsupervised learning. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection",
        "Data Augmentation",
        "Self-Supervised Anomaly Detection",
        "Self-Supervised Learning",
        "Supervised Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19707",
      "abstract": "This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T05:05:13+00:00",
          "link": "https://arxiv.org/abs/2407.19707v1",
          "size": "1004kb",
          "version": "v1"
        },
        {
          "date": "2024-07-30T14:08:43+00:00",
          "link": "https://arxiv.org/abs/2407.19707v2",
          "size": "1004kb",
          "version": "v2"
        },
        {
          "date": "2024-08-05T11:22:34+00:00",
          "link": "https://arxiv.org/abs/2407.19707v3",
          "size": "1004kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T15:19:11+00:00",
          "link": "https://arxiv.org/abs/2407.19707v4",
          "size": "1004kb",
          "version": "v4"
        }
      ],
      "title": "Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19707",
        "HTML": "https://arxiv.org/html/2407.19707",
        "PDF": "https://arxiv.org/pdf/2407.19707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a neural network method to solve nonlinear PDEs and eigenvalue problems, which does not involve any element of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.15703",
      "abstract": "We consider dynamic games with linear dynamics and quadratic objective functions. We observe that the unconstrained open-loop Nash equilibrium coincides with a linear quadratic regulator in an augmented space, thus deriving an explicit expression of the cost-to-go. With such cost-to-go as a terminal cost, we show asymptotic stability for the receding-horizon solution of the finite-horizon, constrained game. Furthermore, we show that the problem is equivalent to a non-symmetric variational inequality, which does not correspond to any Nash equilibrium problem. For unconstrained closed-loop Nash equilibria, we derive a receding-horizon controller that is equivalent to the infinite-horizon one and ensures asymptotic stability.",
      "authors": [
        "Emilio Benenati and Sergio Grammatico"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T11:02:31+00:00",
          "link": "https://arxiv.org/abs/2408.15703v1",
          "size": "745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:52:22+00:00",
          "link": "https://arxiv.org/abs/2408.15703v2",
          "size": "1684kb",
          "version": "v2"
        }
      ],
      "title": "Linear-Quadratic Dynamic Games as Receding-Horizon Variational Inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15703",
        "HTML": "https://arxiv.org/html/2408.15703",
        "PDF": "https://arxiv.org/pdf/2408.15703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about dynamic games with linear dynamics and quadratic objective functions, focusing on Nash equilibria and stability. It doesn't address any aspects of LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/bemilio/Receding-Horizon-GNE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.14621",
      "abstract": "Conformational ensembles of protein structures are immensely important both for understanding protein function and drug discovery in novel modalities such as cryptic pockets. Current techniques for sampling ensembles such as molecular dynamics (MD) are computationally inefficient, while many recent machine learning methods do not transfer to systems outside their training data. We propose JAMUN which performs MD in a smoothed, noised space of all-atom 3D conformations of molecules by utilizing the framework of walk-jump sampling. JAMUN enables ensemble generation for small peptides at rates of an order of magnitude faster than traditional molecular dynamics. The physical priors in JAMUN enables transferability to systems outside of its training data, even to peptides that are longer than those originally trained on. Our model, code and weights are available at https://github.com/prescient-design/jamun.",
      "authors": [
        "Ameya Daigavane",
        "Bodhi P. Vani",
        "Darcy Davidson",
        "Saeed Saremi",
        "Joshua Rackers",
        "Joseph Kleinhenz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biological Physics (physics.bio-ph)",
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-18T17:21:25+00:00",
          "link": "https://arxiv.org/abs/2410.14621v1",
          "size": "10478kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:05:11+00:00",
          "link": "https://arxiv.org/abs/2410.14621v2",
          "size": "38391kb",
          "version": "v2"
        }
      ],
      "title": "JAMUN: Bridging Smoothed Molecular Dynamics and Score-Based Learning for Conformational Ensembles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14621",
        "HTML": "https://arxiv.org/html/2410.14621",
        "PDF": "https://arxiv.org/pdf/2410.14621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method called JAMUN for protein conformations using molecular dynamics and score-based learning, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Drug Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14160",
      "abstract": "Survival modeling predicts the time until an event occurs and is widely used in risk analysis; for example, it's used in medicine to predict the survival of a patient based on censored data. There is a need for large-scale, realistic, and freely available datasets for benchmarking artificial intelligence (AI) survival models. In this paper, we derive a suite of 16 survival modeling tasks from publicly available transaction data generated by lending of cryptocurrencies in Decentralized Finance (DeFi). Each task was constructed using an automated pipeline based on choices of index and outcome events. For example, the model predicts the time from when a user borrows cryptocurrency coins (index event) until their first repayment (outcome event). We formulate a survival benchmark consisting of a suite of 16 survival-time prediction tasks (FinSurvival). We also automatically create 16 corresponding classification problems for each task by thresholding the survival time using the restricted mean survival time. With over 7.5 million records, FinSurvival provides a suite of realistic financial modeling tasks that will spur future AI survival modeling research. Our evaluation indicated that these are challenging tasks that are not well addressed by existing methods. FinSurvival enables the evaluation of AI survival models applicable to traditional finance, industry, medicine, and commerce, which is currently hindered by the lack of large public datasets. Our benchmark demonstrates how AI models could assess opportunities and risks in DeFi. In the future, the FinSurvival benchmark pipeline can be used to create new benchmarks by incorporating more DeFi transactions and protocols as the use of cryptocurrency grows.",
      "authors": [
        "Aaron Green",
        "Zihan Nie",
        "Hanzhen Qin",
        "Oshani Seneviratne",
        "Kristin P. Bennett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T12:48:47+00:00",
          "link": "https://arxiv.org/abs/2507.14160v1",
          "size": "951kb",
          "version": "v1"
        }
      ],
      "title": "FinSurvival: A Suite of Large Scale Survival Modeling Tasks from Finance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14160",
        "HTML": "https://arxiv.org/html/2507.14160",
        "PDF": "https://arxiv.org/pdf/2507.14160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces large-scale survival modeling tasks from finance using DeFi data. While it focuses on data creation for benchmarking, it is not directly concerned with LLM training but discusses dataset creation, which slightly relates to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14687",
      "abstract": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural coverage criterion for ensuring the reliability and safety of critical systems. While its strictest form, Unique-Cause MC/DC, offers the highest assurance, research on its efficient test generation has been lacking. This gap is particularly significant, as an analysis of large-scale avionics systems shows that 99.7% of all conditional decisions are, in fact, Singular Boolean Expressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This paper proposes 'Robin's Rule', a deterministic algorithm that directly constructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause MC/DC for SBEs with N conditions, without generating a full truth table. To validate our approach, we constructed a benchmark by reformulating the TCAS-II specifications into SBEs and verified the results using an industry-standard, certified commercial tool. The results confirm that our method consistently achieves 100% coverage with the theoretical minimum number of tests and is more efficient than the commercial tool. This work provides a practical and provably optimal solution for verifying safety-critical systems, ensuring both rigor and efficiency.",
      "authors": [
        "Robin Lee",
        "Youngho Nam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:30:39+00:00",
          "link": "https://arxiv.org/abs/2507.14687v1",
          "size": "220kb",
          "version": "v1"
        }
      ],
      "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14687",
        "HTML": "https://arxiv.org/html/2507.14687",
        "PDF": "https://arxiv.org/pdf/2507.14687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating minimal test cases for Modified Condition/Decision Coverage in safety-critical systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14715",
      "abstract": "The integration of generative AI models, particularly large language models (LLMs), into real-time multi-model AI applications such as video conferencing and gaming is giving rise to a new class of workloads: real-time generative AI (RTGen). These workloads combine the compute intensity and dynamic execution patterns of generative models with the stringent latency and concurrency constraints of real-time inference. To meet the diverse demands of RTGen workloads, modern edge platforms increasingly adopt heterogeneous system-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite the potential of heterogeneous SoC, the scheduling space complexity and performance implications of RTGen workloads on such platforms remain underexplored. In this work, we perform a comprehensive characterization of RTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct realistic multi-model scenarios inspired by industry use cases and profile model performance across all available backends. Using this data, we evaluate five scheduling policies and their impact on both real-time metrics (e.g., deadline violation rate) and LLM performance (e.g., time-to-first-token and tokens-per-second). Our results show that scheduling decisions significantly affect workload performance (e.g., leading to a 41.7% difference in deadline violation rates on average), and highlight the need for scheduling strategies that are aware of workload dynamics and hardware heterogeneity. Our findings underscore the importance of workload-aware, dynamic heterogeneous scheduling in enabling high-performance, on-device RTGen applications.",
      "authors": [
        "Rachid Karami",
        "Rajeev Patwari",
        "Hyoukjun Kwon",
        "Ashish Sirasao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:24:11+00:00",
          "link": "https://arxiv.org/abs/2507.14715v1",
          "size": "2962kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14715",
        "HTML": "https://arxiv.org/html/2507.14715",
        "PDF": "https://arxiv.org/pdf/2507.14715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines dynamic scheduling for real-time generative AI applications on heterogeneous systems, focusing on performance and system architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15151",
      "abstract": "Anemia is a widespread global health issue, particularly among young children in low-resource settings. Traditional methods for anemia detection often require expensive equipment and expert knowledge, creating barriers to early and accurate diagnosis. To address these challenges, we explore the use of deep learning models for detecting anemia through conjunctival pallor, focusing on the CP-AnemiC dataset, which includes 710 images from children aged 6-59 months. The dataset is annotated with hemoglobin levels, gender, age and other demographic data, enabling the development of machine learning models for accurate anemia detection. We use the MobileNet architecture as a backbone, known for its efficiency in mobile and embedded vision applications, and fine-tune our model end-to-end using data augmentation techniques and a cross-validation strategy. Our model implementation achieved an accuracy of 0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong performance on the dataset. To optimize the model for deployment on edge devices, we performed post-training quantization, evaluating the impact of different bit-widths (FP32, FP16, INT8, and INT4) on model performance. Preliminary results suggest that while FP16 quantization maintains high accuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive quantization (INT8 and INT4) leads to significant performance degradation. Overall, our study supports further exploration of quantization schemes and hardware optimizations to assess trade-offs between model size, inference time, and diagnostic accuracy in mobile healthcare applications.",
      "authors": [
        "Sebastian A. Cruz Romero",
        "Wilfredo E. Lugo Beauchamp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:02:58+00:00",
          "link": "https://arxiv.org/abs/2507.15151v1",
          "size": "1338kb",
          "version": "v1"
        }
      ],
      "title": "Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15151",
        "HTML": "https://arxiv.org/html/2507.15151",
        "PDF": "https://arxiv.org/pdf/2507.15151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses anemia detection using CNN models and explores post-training quantization. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15574",
      "abstract": "The rapid expansion of satellite constellations in near-Earth orbits presents significant challenges in satellite network management, requiring innovative approaches for efficient, scalable, and resilient operations. This paper explores the role of Artificial Intelligence (AI) in optimizing the operation of satellite mega-constellations, drawing from the ConstellAI project funded by the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland University, and Thales Alenia Space collaborates to develop AI-driven algorithms and demonstrates their effectiveness over traditional methods for two crucial operational challenges: data routing and resource allocation. In the routing use case, Reinforcement Learning (RL) is used to improve the end-to-end latency by learning from historical queuing latency, outperforming classical shortest path algorithms. For resource allocation, RL optimizes the scheduling of tasks across constellations, focussing on efficiently using limited resources such as battery and memory. Both use cases were tested for multiple satellite constellation configurations and operational scenarios, resembling the real-life spacecraft operations of communications and Earth observation satellites. This research demonstrates that RL not only competes with classical approaches but also offers enhanced flexibility, scalability, and generalizability in decision-making processes, which is crucial for the autonomous and intelligent management of satellite fleets. The findings of this activity suggest that AI can fundamentally alter the landscape of satellite constellation management by providing more adaptive, robust, and cost-effective solutions.",
      "authors": [
        "Gregory F. Stock and Juan A. Fraire and Holger Hermanns and J\\k{e}drzej Mosi\\k{e}\\.zny and Yusra Al-Khazraji and Julio Ram\\'irez Molina and Evridiki V. Ntagiou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:56:16+00:00",
          "link": "https://arxiv.org/abs/2507.15574v1",
          "size": "657kb",
          "version": "v1"
        }
      ],
      "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15574",
        "PDF": "https://arxiv.org/pdf/2507.15574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the application of AI in managing satellite constellations, specifically in data routing and resource allocation. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15613",
      "abstract": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as Microsoft 365 Copilot) face novel security challenges. One critical threat is prompt inference attacks: adversaries chain together seemingly benign prompts to gradually extract confidential data. In this paper, we present a comprehensive study of multi-stage prompt inference attacks in an enterprise LLM context. We simulate realistic attack scenarios where an attacker uses mild-mannered queries and indirect prompt injections to exploit an LLM integrated with private corporate data. We develop a formal threat model for these multi-turn inference attacks and analyze them using probability theory, optimization frameworks, and information-theoretic leakage bounds. The attacks are shown to reliably exfiltrate sensitive information from the LLM's context (e.g., internal SharePoint documents or emails), even when standard safety measures are in place.\n  We propose and evaluate defenses to counter such attacks, including statistical anomaly detection, fine-grained access control, prompt sanitization techniques, and architectural modifications to LLM deployment. Each defense is supported by mathematical analysis or experimental simulation. For example, we derive bounds on information leakage under differential privacy-based training and demonstrate an anomaly detection method that flags multi-turn attacks with high AUC. We also introduce an approach called \"spotlighting\" that uses input transformations to isolate untrusted prompt content, reducing attack success by an order of magnitude. Finally, we provide a formal proof of concept and empirical validation for a combined defense-in-depth strategy. Our work highlights that securing LLMs in enterprise settings requires moving beyond single-turn prompt filtering toward a holistic, multi-stage perspective on both attacks and defenses.",
      "authors": [
        "Andrii Balashov",
        "Olena Ponomarova",
        "Xiaohua Zhai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:38:12+00:00",
          "link": "https://arxiv.org/abs/2507.15613v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15613",
        "HTML": "https://arxiv.org/html/2507.15613",
        "PDF": "https://arxiv.org/pdf/2507.15613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses security threats and defenses for LLMs in enterprise settings, but it does not focus on training data processing aspects such as collection, filtering, or augmentation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00721",
      "abstract": "Zero-shot domain adaptation (ZSDA) presents substantial challenges due to the lack of images in the target domain. Previous approaches leverage Vision-Language Models (VLMs) to tackle this challenge, exploiting their zero-shot learning capabilities. However, these methods primarily address domain distribution shifts and overlook the misalignment between the detection task and VLMs, which rely on manually crafted prompts. To overcome these limitations, we propose the unified prompt and representation enhancement (UPRE) framework, which jointly optimizes both textual prompts and visual representations. Specifically, our approach introduces a multi-view domain prompt that combines linguistic domain priors with detection-specific knowledge, and a visual representation enhancement module that produces domain style variations. Furthermore, we introduce multi-level enhancement strategies, including relative domain distance and positive-negative separation, which align multi-modal representations at the image level and capture diverse visual representations at the instance level, respectively. Extensive experiments conducted on nine benchmark datasets demonstrate the superior performance of our framework in ZSDA detection scenarios. Code is available at https://github.com/AMAP-ML/UPRE.",
      "authors": [
        "Xiao Zhang",
        "Fei Wei",
        "Yong Wang",
        "Wenda Zhao",
        "Feiyi Li and Xiangxiang Chu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T13:00:41+00:00",
          "link": "https://arxiv.org/abs/2507.00721v1",
          "size": "5718kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:56:13+00:00",
          "link": "https://arxiv.org/abs/2507.00721v2",
          "size": "5767kb",
          "version": "v2"
        }
      ],
      "title": "UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00721",
        "HTML": "https://arxiv.org/html/2507.00721",
        "PDF": "https://arxiv.org/pdf/2507.00721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on zero-shot domain adaptation and performance enhancement for object detection using unified prompt and representation enhancement, which relates to model improvement rather than any aspect of LLM training data processing such as dataset creation, filtering, or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14340",
      "abstract": "Topological Data Analysis (TDA) has emerged as a powerful framework for extracting robust and interpretable features from noisy high-dimensional data. In the context of Social Choice Theory, where preference profiles and collective decisions are geometrically rich yet sensitive to perturbations, TDA remains largely unexplored. This work introduces a novel conceptual bridge between these domains by proposing a new metric framework for persistence diagrams tailored to noisy preference data.We define a polar coordinate-based distance that captures both the magnitude and orientation of topological features in a smooth and differentiable manner. Our metric addresses key limitations of classical distances, such as bottleneck and Wasserstein, including instability under perturbation, lack of continuity, and incompatibility with gradient-based learning. The resulting formulation offers improved behavior in both theoretical and applied settings.To the best of our knowledge, this is the first study to systematically apply persistent homology to social choice systems, providing a mathematically grounded method for comparing topological summaries of voting structures and preference dynamics. We demonstrate the superiority of our approach through extensive experiments, including robustness tests and supervised learning tasks, and we propose a modular pipeline for building predictive models from online preference data. This work contributes a conceptually novel and computationally effective tool to the emerging interface of topology and decision theory, opening new directions in interpretable machine learning for political and economic systems.",
      "authors": [
        "Athanasios Andrikopoulos",
        "Nikolaos Sampanis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Algebraic Topology (math.AT)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:41:19+00:00",
          "link": "https://arxiv.org/abs/2507.14340v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Topological Social Choice: Designing a Noise-Robust Polar Distance for Persistence Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14340",
        "HTML": "https://arxiv.org/html/2507.14340",
        "PDF": "https://arxiv.org/pdf/2507.14340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a new metric for persistence diagrams in topological data analysis, applied to social choice systems. It does not relate to LLM training data processing or contribute to dataset generation or curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14595",
      "abstract": "We introduce Learning-Augmented Control (LAC), an approach that integrates untrusted machine learning predictions into the control of constrained, nonlinear dynamical systems. LAC is designed to achieve the \"best-of-both-worlds\" guarantees, i.e, near-optimal performance when predictions are accurate, and robust, safe performance when they are not. The core of our approach is a delayed confidence learning procedure that optimizes a confidence parameter online, adaptively balancing between ML and nominal predictions. We establish formal competitive ratio bounds for general nonlinear systems under standard MPC regularity assumptions. For the linear quadratic case, we derive a competitive ratio bound that is provably tight, thereby characterizing the fundamental limits of this learning-augmented approach. The effectiveness of LAC is demonstrated in numerical studies, where it maintains stability and outperforms standard methods under adversarial prediction errors.",
      "authors": [
        "Tongxin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:44:27+00:00",
          "link": "https://arxiv.org/abs/2507.14595v1",
          "size": "1140kb",
          "version": "v1"
        }
      ],
      "title": "Learning-Augmented Control: Adaptively Confidence Learning for Competitive MPC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14595",
        "HTML": "https://arxiv.org/html/2507.14595",
        "PDF": "https://arxiv.org/pdf/2507.14595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a control method for dynamical systems, focusing on learning-augmented control, which is unrelated to LLM training data processing. It neither discusses data operations nor contributes directly to LLM-related data quality or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14600",
      "abstract": "Passwords that are long and human-generated pose a challenge for both classical and quantum attacks due to their irregular structure and large search space. In this work, we present an enhanced classical-quantum hybrid attack tailored to this scenario. We build rainbow tables using dictionary-based password generation with transformation rules to better model real user behavior. These tables are then organized into buckets, enabling faster lookup and reduced space complexity. To perform quantum search within each bucket, we use a distributed exact variant of Grover's algorithm, which offers lower circuit depth and deterministic success. As a result, the overall quantum circuit is shallower and more robust against noise, particularly from depolarizing channels commonly found in near-term quantum devices. Through this work, Overall, we propose a hybrid framework that combines structured rainbow tables with efficient quantum search to enhance password recovery.",
      "authors": [
        "MA. Khajeian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:51:38+00:00",
          "link": "https://arxiv.org/abs/2507.14600v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Classical-Quantum Rainbow Table Attack on Human Passwords",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14600",
        "HTML": "https://arxiv.org/html/2507.14600",
        "PDF": "https://arxiv.org/pdf/2507.14600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses hybrid classical-quantum attacks on human passwords and does not cover any topics related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15316",
      "abstract": "Linear automata are automata with two reading heads starting from the two extremes of the input, are equivalent to 5' -> 3' Watson-Crick (WK) finite automata. The heads read the input in opposite directions and the computation finishes when the heads meet. These automata accept the class LIN of linear languages. The deterministic counterpart of these models, on the one hand, is less expressive, as only a proper subset of LIN, the class 2detLIN is accepted; and on the other hand, they are also equivalent in the sense of the class of the accepted languages. Now, based on these automata models, we characterize the class of 2detLIN languages with a Myhill-Nerode type of equivalence classes. However, as these automata may do the computation of both the prefix and the suffix of the input, we use prefix-suffix pairs in our classes. Additionally, it is proven that finitely many classes in the characterization match with the 2detLIN languages, but we have some constraints on the used prefix-suffix pairs, i.e., the characterization should have the property to be complete and it must not have any crossing pairs.",
      "authors": [
        "Benedek Nagy (Eastern Mediterranean University / Eszterh\\'azy K\\'aroly Catholic University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:15:27+00:00",
          "link": "https://arxiv.org/abs/2507.15316v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "A Myhill-Nerode Type Characterization of 2detLIN Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15316",
        "PDF": "https://arxiv.org/pdf/2507.15316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a Myhill-Nerode type characterization of 2detLIN languages using linear automata, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15649",
      "abstract": "To support humanoid robots in performing manipulation tasks, it is essential to study stable standing while accommodating upper-body motions. However, the limited controllable range of humanoid robots in a standing position affects the stability of the entire body. Thus we introduce a reinforcement learning based framework for humanoid robots to imitate human upper-body motions while maintaining overall stability. Our approach begins with designing a retargeting network that generates a large-scale upper-body motion dataset for training the reinforcement learning (RL) policy, which enables the humanoid robot to track upper-body motion targets, employing domain randomization for enhanced robustness. To avoid exceeding the robot's execution capability and ensure safety and stability, we propose an Executable Motion Prior (EMP) module, which adjusts the input target movements based on the robot's current state. This adjustment improves standing stability while minimizing changes to motion amplitude. We evaluate our framework through simulation and real-world tests, demonstrating its practical applicability.",
      "authors": [
        "Haocheng Xu",
        "Haodong Zhang",
        "Zhenghan Chen and Rong Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:14:04+00:00",
          "link": "https://arxiv.org/abs/2507.15649v1",
          "size": "1834kb",
          "version": "v1"
        }
      ],
      "title": "EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15649",
        "HTML": "https://arxiv.org/html/2507.15649",
        "PDF": "https://arxiv.org/pdf/2507.15649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concerns humanoid robots and reinforcement learning for motion imitation, which is unrelated to LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2209.12825",
      "abstract": "Abductive forgetting is removing variables from a logical formula while maintaining its abductive explanations. It is carried in two alternative ways depending on its intended application. Both differ from the usual forgetting, which maintains consequences rather than explanations. Differently from that, abductive forgetting from a propositional formula may not be expressed by any propositional formula. A necessary and sufficient condition tells when it is. Checking it is $\\Pi^p_3$-complete. A way to guarantee expressibility of abductive forgetting is to switch from propositional to default logic. Another is to introduce new variables.",
      "authors": [
        "Paolo Liberatore"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-26T16:31:07+00:00",
          "link": "https://arxiv.org/abs/2209.12825v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:20:47+00:00",
          "link": "https://arxiv.org/abs/2209.12825v2",
          "size": "46kb",
          "version": "v2"
        }
      ],
      "title": "Abductive forgetting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.12825",
        "HTML": "https://arxiv.org/html/2209.12825",
        "PDF": "https://arxiv.org/pdf/2209.12825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on abductive forgetting in logical formulas, which is unrelated to LLM training data processing, as it does not involve data engineering operations or dataset creation for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.15008",
      "abstract": "Accurately identifying and representing object edges is a challenging task in computer vision and image processing. The Segment Anything Model (SAM) has significantly influenced the field of image segmentation, but suffers from high memory consumption and long inference times, limiting its efficiency in real-time applications. To address these limitations, Fast Segment Anything (FastSAM) was proposed, achieving real-time segmentation. However, FastSAM often generates jagged edges that deviate from the true object shapes. Therefore, this paper introduces a novel refinement approach using B-Spline curve fitting techniques to enhance the edge quality in FastSAM. Leveraging the robust shape control and flexible geometric construction of B-Splines, a four-stage refining process involving two rounds of curve fitting is employed to effectively smooth jagged edges. This approach significantly improves the visual quality and analytical accuracy of object edges without compromising critical geometric information. The proposed method improves the practical utility of FastSAM by improving segmentation accuracy while maintaining real-time processing capabilities. This advancement unlocks greater potential for FastSAM technology in various real-world scenarios, such as industrial automation, medical imaging, and autonomous systems, where precise and efficient edge recognition is crucial.",
      "authors": [
        "Jiasheng Xu",
        "Yewang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:35:16+00:00",
          "link": "https://arxiv.org/abs/2507.15008v1",
          "size": "4327kb",
          "version": "v1"
        }
      ],
      "title": "FastSmoothSAM: A Fast Smooth Method For Segment Anything Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15008",
        "HTML": "https://arxiv.org/html/2507.15008",
        "PDF": "https://arxiv.org/pdf/2507.15008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses image segmentation improvements through B-Spline techniques and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15216",
      "abstract": "Self-supervised learning has become an incredibly successful method for feature learning, widely applied to many downstream tasks. It has proven especially effective for discriminative tasks, surpassing the trending generative models. However, generative models perform better in image generation and detail enhancement. Thus, it is natural for us to find a connection between SSL and generative models to further enhance the representation capacity of SSL. As generative models can create new samples by approximating the data distribution, such modeling should also lead to a semantic understanding of the raw visual data, which is necessary for recognition tasks. This enlightens us to combine the core principle of the diffusion model: diffusion noise, with SSL to learn a competitive recognition model. Specifically, diffusion noise can be viewed as a particular state of mask that reveals a close relationship between masked image modeling (MIM) and diffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to incorporate diffusion noise into MIM by the position embedding of masked tokens. The multi-level noise schedule is a series of feature augmentations to further enhance the robustness of our model. We perform a comprehensive study to confirm its effectiveness in the classification of downstream tasks. Codes will be released soon in public.",
      "authors": [
        "Yuping Qiu",
        "Rui Zhu",
        "Ying-cong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:36:58+00:00",
          "link": "https://arxiv.org/abs/2507.15216v1",
          "size": "752kb",
          "version": "v1"
        }
      ],
      "title": "Improving Joint Embedding Predictive Architecture with Diffusion Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15216",
        "HTML": "https://arxiv.org/html/2507.15216",
        "PDF": "https://arxiv.org/pdf/2507.15216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for enhancing representation capacity in self-supervised learning using diffusion noise. It is more about image data processing rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15328",
      "abstract": "The guiding principle of AI alignment is to train large language models (LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are mounting concerns that LLMs exhibit a left-wing political bias. Yet, the commitment to AI alignment cannot be harmonized with the latter critique. In this article, I argue that intelligent systems that are trained to be harmless and honest must necessarily exhibit left-wing political bias. Normative assumptions underlying alignment objectives inherently concur with progressive moral frameworks and left-wing principles, emphasizing harm avoidance, inclusivity, fairness, and empirical truthfulness. Conversely, right-wing ideologies often conflict with alignment guidelines. Yet, research on political bias in LLMs is consistently framing its insights about left-leaning tendencies as a risk, as problematic, or concerning. This way, researchers are actively arguing against AI alignment, tacitly fostering the violation of HHH principles.",
      "authors": [
        "Thilo Hagendorff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:37:28+00:00",
          "link": "https://arxiv.org/abs/2507.15328v1",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "title": "On the Inevitability of Left-Leaning Political Bias in Aligned Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15328",
        "PDF": "https://arxiv.org/pdf/2507.15328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses political bias in LLMs, touching on AI alignment principles, but does not focus on data processing techniques or dataset creation relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.11346",
      "abstract": "Forests are crucial for ecological balance, but wildfires, a major cause of forest loss, pose significant risks. Fire weather indices, which assess wildfire risk and predict resource demands, are vital. With the rise of sensor networks in fields like healthcare and environmental monitoring, semantic sensor networks are increasingly used to gather climatic data such as wind speed, temperature, and humidity. However, processing these data streams to determine fire weather indices presents challenges, underscoring the growing importance of effective forest fire detection. This paper discusses using Apache Spark for early forest fire detection, enhancing fire risk prediction with meteorological and geographical data. Building on our previous development of Semantic Sensor Network (SSN) ontologies and Semantic Web Rules Language (SWRL) for managing forest fires in Monesterial Natural Park, we expanded SWRL to improve a Decision Support System (DSS) using a Large Language Models (LLMs) and Spark framework. We implemented real-time alerts with Spark streaming, tailored to various fire scenarios, and validated our approach using ontology metrics, query-based evaluations, LLMs score precision, F1 score, and recall measures.",
      "authors": [
        "Ritesh Chandra",
        "Shashi Shekhar Kumar",
        "Rushil Patra",
        "Sonali Agarwal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-18T17:30:30+00:00",
          "link": "https://arxiv.org/abs/2405.11346v1",
          "size": "762kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T06:13:48+00:00",
          "link": "https://arxiv.org/abs/2405.11346v2",
          "size": "768kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T05:48:07+00:00",
          "link": "https://arxiv.org/abs/2405.11346v3",
          "size": "768kb",
          "version": "v3"
        }
      ],
      "title": "Decision support system for Forest fire management using Ontology with Big Data and LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11346",
        "PDF": "https://arxiv.org/pdf/2405.11346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the use of LLMs for forest fire management but is primarily focused on decision support and sensor networks. The mention of LLMs is not central to the creation or improvement of LLM training datasets."
      },
      "tasks": [
        "Fire Detection",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.07668",
      "abstract": "Many real-world applications require machine-learning models to be able to deal with non-stationary data distributions and thus learn autonomously over an extended period of time, often in an online setting. One of the main challenges in this scenario is the so-called catastrophic forgetting (CF) for which the learning model tends to focus on the most recent tasks while experiencing predictive degradation on older ones. In the online setting, the most effective solutions employ a fixed-size memory buffer to store old samples used for replay when training on new tasks. Many approaches have been presented to tackle this problem. However, it is not clear how predictive uncertainty information for memory management can be leveraged in the most effective manner and conflicting strategies are proposed to populate the memory. Are the easiest-to-forget or the easiest-to-remember samples more effective in combating CF? Starting from the intuition that predictive uncertainty provides an idea of the samples' location in the decision space, this work presents an in-depth analysis of different uncertainty estimates and strategies for populating the memory. The investigation provides a better understanding of the characteristics data points should have for alleviating CF. Then, we propose an alternative method for estimating predictive uncertainty via the generalised variance induced by the negative log-likelihood. Finally, we demonstrate that the use of predictive uncertainty measures helps in reducing CF in different settings.",
      "authors": [
        "Giuseppe Serra",
        "Ben Werner",
        "Florian Buettner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-10T13:51:15+00:00",
          "link": "https://arxiv.org/abs/2407.07668v1",
          "size": "843kb",
          "version": "v1"
        },
        {
          "date": "2024-10-10T10:34:08+00:00",
          "link": "https://arxiv.org/abs/2407.07668v2",
          "size": "843kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:03:37+00:00",
          "link": "https://arxiv.org/abs/2407.07668v3",
          "size": "695kb",
          "version": "v3"
        }
      ],
      "title": "How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.07668",
        "HTML": "https://arxiv.org/html/2407.07668",
        "PDF": "https://arxiv.org/pdf/2407.07668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses catastrophic forgetting in online continual learning and does not discuss any aspect of training data processing for LLMs."
      },
      "tasks": [
        "Continual Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05895",
      "abstract": "Modern automotive infotainment systems require intelligent and adaptive solutions to handle frequent User Interface (UI) updates and diverse design variations. We introduce a vision-language framework for understanding and interacting with automotive infotainment systems, enabling seamless adaptation across different UI designs. To further support research in this field, we release AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208 annotations. Additionally, we present a synthetic data pipeline to generate training data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation (LoRa) and incorporating reasoning generated by our pipeline, along with visual grounding and evaluation capabilities. The fine-tuned Evaluative Large Action Model (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and dataset are available on Hugging Face) and demonstrating strong cross-domain generalization, including a +5.6% improvement on ScreenSpot over the baseline model. Notably, our approach achieves 80.8% average accuracy on ScreenSpot, closely matching or even surpassing specialized models for desktop, mobile, and web, such as ShowUI, despite being trained for the infotainment domain. This research investigates how data collection and subsequent fine-tuning can lead to AI-driven progress within automotive UI understanding and interaction. The applied method is cost-efficient and fine-tuned models can be deployed on consumer-grade GPUs.",
      "authors": [
        "Benjamin Raphael Ernhofer",
        "Daniil Prokhorov",
        "Jannica Langner and Dominik Bollmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T09:01:52+00:00",
          "link": "https://arxiv.org/abs/2505.05895v1",
          "size": "11834kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T12:17:02+00:00",
          "link": "https://arxiv.org/abs/2505.05895v2",
          "size": "11827kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05895",
        "HTML": "https://arxiv.org/html/2505.05895",
        "PDF": "https://arxiv.org/pdf/2505.05895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a synthetic data pipeline for training data generation, which is relevant but not the main focus. It primarily details application in visual grounding and analysis of automotive UI rather than LLM data processing."
      },
      "models": [
        {
          "model_path": "sparks-solutions/ELAM-7B",
          "downloads": "25",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/sparks-solutions/ELAM-7B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "sparks-solutions/AutomotiveUI-Bench-4K",
          "downloads": "159",
          "likes": "1",
          "link": "https://huggingface.co/datasets/sparks-solutions/AutomotiveUI-Bench-4K"
        }
      ],
      "tasks": [
        "4k",
        "Domain Generalization",
        "GUI Element Detection",
        "Visual Grounding",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://huggingface.co/sparks-solutions/ELAM-7B"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09222",
      "abstract": "Foundation models like CLIP and SAM have advanced computer vision and medical imaging via low-shot transfer learning, aiding CADD with limited data. However, their deployment faces two key challenges. \\textit{distribution shift} where pre-training and post-training data distributions differ (e.g., due to inter-center image acquisition) and \\textit{confidence misalignment}, which leads to overconfident errors. These issues surface differently, vision-language models (e.g., CLIP) suffer from 2D embedding shift (image-text misalignment), while medical models (e.g., SAM) encounter 3D domain shifts (e.g., scanner variation) and voxel-wise calibration need. Existing solutions are domain-specific. We propose \\textbf{StaRFM}, a fusion of Fisher information penalty (FIP) and confidence misalignment penalty (CMP) tackling both challenges. It applies FIP, extended to 3D via patch-wise regularization, to reduce embedding shift, and CMP, reformulated for voxel-level predictions, to calibrate segmentation uncertainty. We derive PAC-Bayes bounds. FIP controls generalization via the Fisher-Rao norm, and CMP reduces calibration error via Brier score minimization. StaRFM surpasses baselines by \\texttt{+}3.5\\% accuracy and 28\\% lower ECE on 19 vision datasets (e.g., ImageNet, Office-Home), achieves +4.2\\% DSC over SAM-FT and 4.8mm HD95 on medical benchmarks (e.g., BraTS, ATLAS), and reduces cross-domain gaps by up to 20\\%. The framework is plug-and-play, requiring minimal architectural changes. Code and models are available at: \\href{https://anonymous.4open.science/r/StaRFM-C0CD/}{\\textcolor{blue}{\\underline{StaRFM}}}",
      "authors": [
        "Behraj Khan",
        "Tahir Qasim Syed",
        "Nouman M. Durrani",
        "Bilal Naseem",
        "Shabir Ahmad",
        "Rizwan Qureshi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.09222v1",
          "size": "2974kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T07:22:45+00:00",
          "link": "https://arxiv.org/abs/2507.09222v2",
          "size": "3502kb",
          "version": "v2"
        }
      ],
      "title": "Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09222",
        "HTML": "https://arxiv.org/html/2507.09222",
        "PDF": "https://arxiv.org/pdf/2507.09222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses distribution shifts and confidence misalignment in foundation models for vision-language and medical tasks, focusing on model robustness rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14201",
      "abstract": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on the task of Cyber Threat Investigation through security questions derived from investigation graphs. Real-world security analysts must sift through a large number of heterogeneous alert signals and security logs, follow multi-hop chains of evidence, and compile an incident report. With the developments of LLMs, building LLM-based agents for automatic thread investigation is a promising direction. To assist the development and evaluation of LLM agents, we construct a dataset from a controlled Azure tenant that covers 8 simulated real-world multi-step attacks, 57 log tables from Microsoft Sentinel and related services, and 589 automatically generated questions. We leverage security logs extracted with expert-crafted detection logic to build threat investigation graphs, and then generate questions with LLMs using paired nodes on the graph, taking the start node as background context and the end node as answer. Anchoring each question to these explicit nodes and edges not only provides automatic, explainable ground truth answers but also makes the pipeline reusable and readily extensible to new logs. This also enables the automatic generation of procedural tasks with verifiable rewards, which can be naturally extended to training agents via reinforcement learning. Our comprehensive experiments with different models confirm the difficulty of the task: with the base setting, the average reward across all evaluated models is 0.249, and the best achieved is 0.368, leaving substantial headroom for future research. Code and data are coming soon!",
      "authors": [
        "Yiran Wu",
        "Mauricio Velazco",
        "Andrew Zhao",
        "Manuel Ra\\'ul Mel\\'endez Luj\\'an",
        "Srisuma Movva",
        "Yogesh K Roy",
        "Quang Nguyen",
        "Roberto Rodriguez",
        "Qingyun Wu",
        "Michael Albada",
        "Julia Kiseleva",
        "Anand Mudgerikar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:06:26+00:00",
          "link": "https://arxiv.org/abs/2507.14201v1",
          "size": "1122kb",
          "version": "v1"
        }
      ],
      "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14201",
        "HTML": "https://arxiv.org/html/2507.14201",
        "PDF": "https://arxiv.org/pdf/2507.14201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ExCyTIn-Bench, a dataset for evaluating LLMs in cyber threat investigation, which involves generating questions and tasks for LLM-based agents. While it includes dataset construction, its primary focus is on benchmarking LLM capabilities in a specific application area rather than on general LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14339",
      "abstract": "Brain foundation models represent a new frontier in AI: instead of processing text or images, these models interpret real-time neural signals from EEG, fMRI, and other neurotechnologies. When integrated with brain-computer interfaces (BCIs), they may enable transformative applications-from thought controlled devices to neuroprosthetics-by interpreting and acting on brain activity in milliseconds. However, these same systems pose unprecedented risks, including the exploitation of subconscious neural signals and the erosion of cognitive liberty. Users cannot easily observe or control how their brain signals are interpreted, creating power asymmetries that are vulnerable to manipulation. This paper proposes embedding fiduciary duties-loyalty, care, and confidentiality-directly into BCI-integrated brain foundation models through technical design. Drawing on legal traditions and recent advancements in AI alignment techniques, we outline implementable architectural and governance mechanisms to ensure these systems act in users' best interests. Placing brain foundation models on a fiduciary footing is essential to realizing their potential without compromising self-determination.",
      "authors": [
        "Abhishek Bhattacharjee",
        "Jack Pilkington",
        "Nita Farahany"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:34:08+00:00",
          "link": "https://arxiv.org/abs/2507.14339v1",
          "size": "563kb",
          "version": "v1"
        }
      ],
      "title": "Fiduciary AI for the Future of Brain-Technology Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14339",
        "PDF": "https://arxiv.org/pdf/2507.14339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses integrating fiduciary duties into brain foundation models and brain-computer interfaces. It does not pertain to LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14915",
      "abstract": "Well-coordinated, music-aligned holistic dance enhances emotional expressiveness and audience engagement. However, generating such dances remains challenging due to the scarcity of holistic 3D dance datasets, the difficulty of achieving cross-modal alignment between music and dance, and the complexity of modeling interdependent motion across the body, hands, and face. To address these challenges, we introduce SoulDance, a high-precision music-dance paired dataset captured via professional motion capture systems, featuring meticulously annotated holistic dance movements. Building on this dataset, we propose SoulNet, a framework designed to generate music-aligned, kinematically coordinated holistic dance sequences. SoulNet consists of three principal components: (1) Hierarchical Residual Vector Quantization, which models complex, fine-grained motion dependencies across the body, hands, and face; (2) Music-Aligned Generative Model, which composes these hierarchical motion units into expressive and coordinated holistic dance; (3) Music-Motion Retrieval Module, a pre-trained cross-modal model that functions as a music-dance alignment prior, ensuring temporal synchronization and semantic coherence between generated dance and input music throughout the generation process. Extensive experiments demonstrate that SoulNet significantly surpasses existing approaches in generating high-quality, music-coordinated, and well-aligned holistic 3D dance sequences.",
      "authors": [
        "Xiaojie Li",
        "Ronghui Li",
        "Shukai Fang",
        "Shuzhao Xie",
        "Xiaoyang Guo",
        "Jiaqing Zhou",
        "Junkun Peng",
        "Zhi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:06:47+00:00",
          "link": "https://arxiv.org/abs/2507.14915v1",
          "size": "8889kb",
          "version": "v1"
        }
      ],
      "title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14915",
        "HTML": "https://arxiv.org/html/2507.14915",
        "PDF": "https://arxiv.org/pdf/2507.14915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the SoulDance dataset for music-aligned 3D dance generation, which relates to dataset creation. However, its primary focus is not on LLM training data processing but on hierarchical motion modeling and dance sequence alignment."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.16113",
      "abstract": "The need for larger-scale fast-charging electric vehicle (EV) hubs is on the rise due to the growth in EV adoption. Another area of power infrastructure growth is the proliferation of independently operated stand-alone battery storage systems (BSS), which is fueled by improvements and cost reductions in battery technology. Many possible uses of the stand-alone BSS are being explored including participation in the energy and ancillary markets, load balancing for renewable generations, and supporting large-scale load-consuming entities like hospitals. In this paper, we study a novel usage of the stand-alone BSS whereby in addition to participating in the electricity reserve market, it allows an EV hub to use a part of its storage capacity, when profitable. The hub uses the BSS storage capacity for arbitrage consequently reducing its operating cost. We formulate this joint operation as a bi-objective optimization model. We then reformulate it into a second-order cone Nash bargaining problem, the solution of which guarantees fairness to both the hub and the BSS. A sample numerical case study is formulated using actual prices of electricity and simulated data for the reserve market and EV charging demand. The Nash bargaining solution shows that both participants can benefit from the joint operation.",
      "authors": [
        "Diwas Paudel",
        "Luke Wolf and Tapas K. Das"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-24T18:11:31+00:00",
          "link": "https://arxiv.org/abs/2404.16113v1",
          "size": "9649kb",
          "version": "v1"
        }
      ],
      "title": "Joint operation of a fast-charging EV hub with a stand-alone independent battery storage system under fairness considerations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16113",
        "HTML": "https://arxiv.org/html/2404.16113",
        "PDF": "https://arxiv.org/pdf/2404.16113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the operation and optimization of EV charging hubs with battery storage systems, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03108",
      "abstract": "Recently, Provenance-based Intrusion Detection Systems (PIDSes) have been widely used for endpoint threat analysis. These studies can be broadly categorized into rule-based detection systems and learning-based detection systems. Among these, due to the evolution of attack techniques, rules cannot dynamically model all the characteristics of attackers. As a result, such systems often face false negatives. Learning-based detection systems are further divided into supervised learning and anomaly detection. The scarcity of attack samples hinders the usability and effectiveness of supervised learning-based detection systems in practical applications. Anomaly-based detection systems face a massive false positive problem because they cannot distinguish between changes in normal behavior and real attack behavior. The alert results of detection systems are closely related to the manual labor costs of subsequent security analysts. To reduce manual analysis time, we propose OMNISEC, which applies large language models (LLMs) to anomaly-based intrusion detection systems via retrieval-augmented behavior prompting. OMNISEC can identify abnormal nodes and corresponding abnormal events by constructing suspicious nodes and rare paths. By combining two external knowledge bases, OMNISEC uses Retrieval Augmented Generation (RAG) to enable the LLM to determine whether abnormal behavior is a real attack. Finally, OMNISEC can reconstruct the attack graph and restore the complete attack behavior chain of the attacker's intrusion. Experimental results show that OMNISEC outperforms state-of-the-art methods on public benchmark datasets.",
      "authors": [
        "Wenrui Cheng",
        "Tiantian Zhua",
        "Shunan Jing",
        "Jian-Ping Mei",
        "Mingjun Ma",
        "Jiaobo Jin and Zhengqiu Weng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T02:08:12+00:00",
          "link": "https://arxiv.org/abs/2503.03108v1",
          "size": "1563kb",
          "version": "v1"
        },
        {
          "date": "2025-04-28T12:27:25+00:00",
          "link": "https://arxiv.org/abs/2503.03108v2",
          "size": "1651kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T12:16:13+00:00",
          "link": "https://arxiv.org/abs/2503.03108v3",
          "size": "797kb",
          "version": "v3"
        }
      ],
      "title": "OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03108",
        "HTML": "https://arxiv.org/html/2503.03108",
        "PDF": "https://arxiv.org/pdf/2503.03108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on intrusion detection systems using LLMs for behavior prompting but does not address any aspect of data processing for LLM training such as dataset creation, filtering, or quality improvement."
      },
      "tasks": [
        "All",
        "Intrusion Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03433",
      "abstract": "Vision foundation models (VFMs) have demonstrated remarkable performance across a wide range of downstream tasks. While several VFM adapters have shown promising results by leveraging the prior knowledge of VFMs, we identify two inefficiencies in these approaches. First, the interaction between convolutional neural network (CNN) and VFM backbone triggers early layer gradient backpropagation. Second, existing methods require tuning all components, adding complexity. Besides, these adapters alter VFM features, underutilizing the prior knowledge. To tackle these challenges, we propose a new approach called ViT-Split, based on a key observation: the layers of several VFMs, like DINOv2, can be divided into two distinct components: an extractor for learning low-level features and an adapter for learning task-specific features. Leveraging this insight, we eliminate the CNN branch and introduce two heads, task head and prior head, to the frozen VFM. The task head is designed to learn task-specific features, mitigating the early gradient propagation issue. The prior head is used to leverage the multi-scale prior features from the frozen VFM, reducing tuning parameters and overfitting. Extensive experiments on various tasks (e.g., segmentation, detection, depth estimation, and visual question answering) validate the effectiveness and efficiency of ViT-Split. Specifically, ViT-Split reduces training time up to $4\\times$ while achieving comparable or even better results on ADE20K, compared to other VFM adapters.",
      "authors": [
        "Yifan Li",
        "Xin Li",
        "Tianqin Li",
        "Wenbin He",
        "Yu Kong",
        "Liu Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T22:34:17+00:00",
          "link": "https://arxiv.org/abs/2506.03433v1",
          "size": "22671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:02:16+00:00",
          "link": "https://arxiv.org/abs/2506.03433v2",
          "size": "22672kb",
          "version": "v2"
        }
      ],
      "title": "ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03433",
        "HTML": "https://arxiv.org/html/2506.03433",
        "PDF": "https://arxiv.org/pdf/2506.03433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses optimizing vision foundation models with a new architectural approach, unrelated to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.06806",
      "abstract": "The explosion of textual data has made manual document classification increasingly challenging. To address this, we introduce a robust, efficient domain-agnostic generative model framework for multi-label text classification. Instead of treating labels as mere atomic symbols, our approach utilizes predefined label descriptions and is trained to generate these descriptions based on the input text. During inference, the generated descriptions are matched to the pre-defined labels using a finetuned sentence transformer. We integrate this with a dual-objective loss function, combining cross-entropy loss and cosine similarity of the generated sentences with the predefined target descriptions, ensuring both semantic alignment and accuracy. Our proposed model LAGAMC stands out for its parameter efficiency and versatility across diverse datasets, making it well-suited for practical applications. We demonstrate the effectiveness of our proposed model by achieving new state-of-the-art performances across all evaluated datasets, surpassing several strong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in Macro-F1 compared to the closest baseline across all datasets.",
      "authors": [
        "Subhendu Khatuya",
        "Shashwat Naidu",
        "Saptarshi Ghosh",
        "Pawan Goyal",
        "Niloy Ganguly"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T14:07:07+00:00",
          "link": "https://arxiv.org/abs/2506.06806v1",
          "size": "1432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:38:19+00:00",
          "link": "https://arxiv.org/abs/2506.06806v2",
          "size": "1434kb",
          "version": "v2"
        }
      ],
      "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06806",
        "HTML": "https://arxiv.org/html/2506.06806",
        "PDF": "https://arxiv.org/pdf/2506.06806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a generative model for multi-label text classification, utilizing label semantics during training. It briefly touches on data processing by refining label descriptions, but its primary focus is model architecture and classification approach, not LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14169",
      "abstract": "We propose a novel interference prediction scheme to improve link adaptation (LA) in densely deployed industrial sub-networks (SNs) with high-reliability and low-latency communication (HRLLC) requirements. The proposed method aims to improve the LA framework by predicting and leveraging the heavy-tailed interference probability density function (pdf). Interference is modeled as a latent vector of available channel quality indicator (CQI), using a vector discrete-time state-space model (vDSSM) at the SN controller, where the CQI is subjected to compression, quantization, and delay-induced errors. To robustly estimate interference power values under these impairments, we employ a low-complexity, outlier-robust, sparse Student-t process regression (SPTPR) method. This is integrated into a modified unscented Kalman filter, which recursively refines predicted interference using CQI, enabling accurate estimation and compensating protocol feedback delays, crucial for accurate LA. Numerical results show that the proposed method achieves over 10x lower complexity compared to a similar non-parametric baseline. It also maintains a BLER below the 90th percentile target of 1e-6 while delivering performance comparable to a state-of-the-art supervised technique using only CQI reports.",
      "authors": [
        "Pramesh Gautam",
        "Ravi Sharan B A G",
        "Paolo Baracca",
        "Carsten Bockelmann",
        "Thorsten Wild",
        "Armin Dekorsy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:31:21+00:00",
          "link": "https://arxiv.org/abs/2507.14169v1",
          "size": "550kb",
          "version": "v1"
        }
      ],
      "title": "CQI-Based Interference Prediction for Link Adaptation in Industrial Sub-networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14169",
        "HTML": "https://arxiv.org/html/2507.14169",
        "PDF": "https://arxiv.org/pdf/2507.14169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interference prediction to improve link adaptation in industrial sub-networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14323",
      "abstract": "We consider classical-quantum (cq-)channels with memory, and establish that Ar{\\i}kan-constructed polar codes achieve the classical capacity for two key noise models, namely for (i) qubit erasures and (ii) unital qubit noise with channel state information at the receiver. The memory in the channel is assumed to be governed by a discrete-time, countable-state, aperiodic, irreducible, and positive recurrent Markov process. We establish this result by leveraging existing classical polar coding guarantees established for finite-state, aperiodic, and irreducible Markov processes [FAIM], alongside the recent finding that no entanglement is required to achieve the capacity of Markovian unital and erasure quantum channels when transmitting classical information. More broadly, our work illustrates that for cq-channels with memory, where an optimal coding strategy is essentially classical, polar codes can be shown to approach the capacity.",
      "authors": [
        "Jaswanthi Mandalapu",
        "Vikesh Siddhu",
        "Krishna Jagannathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.14323v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Polar Codes for Erasure and Unital Classical-Quantum Markovian Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14323",
        "HTML": "https://arxiv.org/html/2507.14323",
        "PDF": "https://arxiv.org/pdf/2507.14323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses classical-quantum channels and polar codes, which do not pertain to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14378",
      "abstract": "Convolutional neural networks (CNNs) are a standard tool for computer vision tasks such as image classification. However, typical model architectures may result in the loss of topological information. In specific domains such as histopathology, topology is an important descriptor that can be used to distinguish between disease-indicating tissue by analyzing the shape characteristics of cells. Current literature suggests that reintroducing topological information using persistent homology can improve medical diagnostics; however, previous methods utilize global topological summaries which do not contain information about the locality of topological features. To address this gap, we present a novel method that generates local persistent homology-based data using a modified version of the convolution operator called Persistent Homology Convolutions. This method captures information about the locality and translation invariance of topological features. We perform a comparative study using various representations of histopathology slides and find that models trained with persistent homology convolutions outperform conventionally trained models and are less sensitive to hyperparameters. These results indicate that persistent homology convolutions extract meaningful geometric information from the histopathology slides.",
      "authors": [
        "Shrunal Pothagoni and Benjamin Schweinhart"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:56:53+00:00",
          "link": "https://arxiv.org/abs/2507.14378v1",
          "size": "4822kb",
          "version": "v1"
        }
      ],
      "title": "Classification of Histopathology Slides with Persistence Homology Convolutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14378",
        "HTML": "https://arxiv.org/html/2507.14378",
        "PDF": "https://arxiv.org/pdf/2507.14378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with using persistent homology in convolutional neural networks for histopathology slide classification, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15255",
      "abstract": "Electrocardiogram (ECG) plays a foundational role in modern cardiovascular care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and conduction disorders. While machine learning has achieved expert-level performance in ECG interpretation, the development of clinically deployable multimodal AI systems remains constrained, primarily due to the lack of publicly available datasets that simultaneously incorporate raw signals, diagnostic images, and interpretation text. Most existing ECG datasets provide only single-modality data or, at most, dual modalities, making it difficult to build models that can understand and integrate diverse ECG information in real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw waveform data, high-resolution plotted images, and detailed textual interpretations generated by large language models. In addition, MEETI includes beat-level quantitative ECG parameters extracted from each lead, offering structured parameters that support fine-grained analysis and model interpretability. Each MEETI record is aligned across four components: (1) the raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature parameters, and (4) detailed interpretation text. This alignment is achieved using consistent, unique identifiers. This unified structure supports transformer-based multimodal learning and supports fine-grained, interpretable reasoning about cardiac health. By bridging the gap between traditional signal analysis, image-based interpretation, and language-driven understanding, MEETI established a robust foundation for the next generation of explainable, multimodal cardiovascular AI. It offers the research community a comprehensive benchmark for developing and evaluating ECG-based AI systems.",
      "authors": [
        "Deyun Zhang",
        "Xiang Lan",
        "Shijia Geng",
        "Qinghao Zhao",
        "Sumei Fan",
        "Mengling Feng",
        "and Shenda Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:32:44+00:00",
          "link": "https://arxiv.org/abs/2507.15255v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15255",
        "HTML": "https://arxiv.org/html/2507.15255",
        "PDF": "https://arxiv.org/pdf/2507.15255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the MEETI dataset, focusing on multimodal ECG data for cardiovascular AI, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15381",
      "abstract": "Active learning (AL) seeks to reduce annotation costs by selecting the most informative samples for labeling, making it particularly valuable in resource-constrained settings. However, traditional evaluation methods, which focus solely on final accuracy, fail to capture the full dynamics of the learning process. To address this gap, we propose PALM (Performance Analysis of Active Learning Models), a unified and interpretable mathematical model that characterizes AL trajectories through four key parameters: achievable accuracy, coverage efficiency, early-stage performance, and scalability. PALM provides a predictive description of AL behavior from partial observations, enabling the estimation of future performance and facilitating principled comparisons across different strategies. We validate PALM through extensive experiments on CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and self-supervised embeddings. Our results demonstrate that PALM generalizes effectively across datasets, budgets, and strategies, accurately predicting full learning curves from limited labeled data. Importantly, PALM reveals crucial insights into learning efficiency, data space coverage, and the scalability of AL methods. By enabling the selection of cost-effective strategies and predicting performance under tight budget constraints, PALM lays the basis for more systematic, reproducible, and data-efficient evaluation of AL in both research and real-world applications. The code is available at: https://github.com/juliamachnio/PALM.",
      "authors": [
        "Julia Machnio",
        "Mads Nielsen",
        "Mostafa Mehdipour Ghazi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:37:44+00:00",
          "link": "https://arxiv.org/abs/2507.15381v1",
          "size": "3234kb",
          "version": "v1"
        }
      ],
      "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15381",
        "HTML": "https://arxiv.org/html/2507.15381",
        "PDF": "https://arxiv.org/pdf/2507.15381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents PALM, a model for evaluating sample efficiency in active learning models, particularly focusing on image datasets. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15463",
      "abstract": "Given two 2 disjoint vertex-sets $S=\\{u,x\\}$ and $T=\\{v,y\\}$, a paired many-to-many 2-disjoint path cover joining S and T, is a set of two vertex-disjoint paths with endpoints $u,v$ and $x,y$, respectively, that cover every vertex of the graph. If the graph has a many-to-many 2-disjoint path cover for any two disjoint vertex-sets $S$ and $T$, then it is called paired 2-coverable. It is known that if a graph is paired 2-coverable, then it must be Hamilton-connected, but the reverse is not true. It has been proved that Johnson graphs $J(n,k)$, $0\\le k\\le n$, are Hamilton-connected by Brian Alspach in [Ars Math. Contemp. 6 (2013) 21--23]. In this paper, we prove that Johnson graphs are paired 2-coverable. Moreover, we obtain that another family of graphs $QJ(n,k)$ constructed from Johnson graphs by Alspach are also paired 2-coverable.",
      "authors": [
        "Jinhao Liu and Huazhong L\\\"u"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:17:33+00:00",
          "link": "https://arxiv.org/abs/2507.15463v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "Paired many-to-many 2-disjoint path cover of Johnson graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15463",
        "HTML": "https://arxiv.org/html/2507.15463",
        "PDF": "https://arxiv.org/pdf/2507.15463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a theoretical topic in graph theory specifically about Johnson graphs and path coverability, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15727",
      "abstract": "This paper introduces a novel multi-agent ski-rental problem that generalizes the classical ski-rental dilemma to a group setting where agents incur individual and shared costs. In our model, each agent can either rent at a fixed daily cost, or purchase a pass at an individual cost, with an additional third option of a discounted group pass available to all. We consider scenarios in which agents' active days differ, leading to dynamic states as agents drop out of the decision process. To address this problem from different perspectives, we define three distinct competitive ratios: overall, state-dependent, and individual rational. For each objective, we design and analyze optimal deterministic and randomized policies. Our deterministic policies employ state-aware threshold functions that adapt to the dynamic states, while our randomized policies sample and resample thresholds from tailored state-aware distributions. The analysis reveals that symmetric policies, in which all agents use the same threshold, outperform asymmetric ones. Our results provide competitive ratio upper and lower bounds and extend classical ski-rental insights to multi-agent settings, highlighting both theoretical and practical implications for group decision-making under uncertainty.",
      "authors": [
        "Xuchuang Wang",
        "Bo Sun",
        "Hedyeh Beyhaghi",
        "John C.S. Lui",
        "Mohammad Hajiesmaili",
        "Adam Wierman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:36:34+00:00",
          "link": "https://arxiv.org/abs/2507.15727v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15727",
        "PDF": "https://arxiv.org/pdf/2507.15727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with a theoretical multi-agent ski-rental problem and competitive algorithm analysis that do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15753",
      "abstract": "Generative machine learning models have revolutionized material discovery by capturing complex structure-property relationships, yet extending these approaches to the inverse design of three-dimensional metamaterials remains limited by computational complexity and underexplored design spaces due to the lack of expressive representations. Here, we present DiffuMeta, a generative framework integrating diffusion transformers with a novel algebraic language representation, encoding 3D geometries as mathematical sentences. This compact, unified parameterization spans diverse topologies while enabling direct application of transformers to structural design. DiffuMeta leverages diffusion models to generate novel shell structures with precisely targeted stress-strain responses under large deformations, accounting for buckling and contact while addressing the inherent one-to-many mapping by producing diverse solutions. Uniquely, our approach enables simultaneous control over multiple mechanical objectives, including linear and nonlinear responses beyond training domains. Experimental validation of fabricated structures further confirms the efficacy of our approach for accelerated design of metamaterials and structures with tailored properties.",
      "authors": [
        "Li Zheng",
        "Siddhant Kumar",
        "and Dennis M. Kochmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:09:26+00:00",
          "link": "https://arxiv.org/abs/2507.15753v1",
          "size": "26472kb",
          "version": "v1"
        }
      ],
      "title": "DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15753",
        "HTML": "https://arxiv.org/html/2507.15753",
        "PDF": "https://arxiv.org/pdf/2507.15753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the inverse design of metamaterials using generative models, which does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.09032",
      "abstract": "We have developed a reinforcement learning agent that often finds a minimal sequence of unknotting crossing changes for a knot diagram with up to 200 crossings, hence giving an upper bound on the unknotting number. We have used this to determine the unknotting number of 57k knots. We took diagrams of connected sums of such knots with oppositely signed signatures, where the summands were overlaid. The agent has found examples where several of the crossing changes in an unknotting collection of crossings result in hyperbolic knots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy some mild assumptions, there is a diagram of their connected sum and $u(K) + u(K')$ unknotting crossings such that changing any one of them results in a prime knot. As a by-product, we have obtained a dataset of 2.6 million distinct hard unknot diagrams; most of them under 35 crossings. Assuming the additivity of the unknotting number, we have determined the unknotting number of 43 at most 12-crossing knots for which the unknotting number is unknown.",
      "authors": [
        "Taylor Applebaum",
        "Sam Blackwell",
        "Alex Davies",
        "Thomas Edlich",
        "Andr\\'as Juh\\'asz",
        "Marc Lackenby",
        "Nenad Toma\\v{s}ev",
        "Daniel Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Geometric Topology (math.GT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T17:59:52+00:00",
          "link": "https://arxiv.org/abs/2409.09032v1",
          "size": "303kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T19:05:27+00:00",
          "link": "https://arxiv.org/abs/2409.09032v2",
          "size": "305kb",
          "version": "v2"
        }
      ],
      "title": "The unknotting number, hard unknot diagrams, and reinforcement learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09032",
        "HTML": "https://arxiv.org/html/2409.09032",
        "PDF": "https://arxiv.org/pdf/2409.09032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on reinforcing learning approaches for computing the unknotting number of knots and creating a dataset of hard unknot diagrams. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.16824",
      "abstract": "Generating detailed descriptions from multiple cameras and viewpoints is challenging due to the complex and inconsistent nature of visual data. In this paper, we introduce PerspectiveNet, a lightweight yet efficient model for generating long descriptions across multiple camera views. Our approach utilizes a vision encoder, a compact connector module to convert visual features into a fixed-size tensor, and large language models (LLMs) to harness the strong natural language generation capabilities of LLMs. The connector module is designed with three main goals: mapping visual features onto LLM embeddings, emphasizing key information needed for description generation, and producing a fixed-size feature matrix. Additionally, we augment our solution with a secondary task, the correct frame sequence detection, enabling the model to search for the correct sequence of frames to generate descriptions. Finally, we integrate the connector module, the secondary task, the LLM, and a visual feature extraction model into a single architecture, which is trained for the Traffic Safety Description and Analysis task. This task requires generating detailed, fine-grained descriptions of events from multiple cameras and viewpoints. The resulting model is lightweight, ensuring efficient training and inference, while remaining highly effective.",
      "authors": [
        "Vinh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T08:57:17+00:00",
          "link": "https://arxiv.org/abs/2410.16824v1",
          "size": "274kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:59:12+00:00",
          "link": "https://arxiv.org/abs/2410.16824v2",
          "size": "846kb",
          "version": "v2"
        }
      ],
      "title": "PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16824",
        "HTML": "https://arxiv.org/html/2410.16824",
        "PDF": "https://arxiv.org/pdf/2410.16824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces PerspectiveNet for generating descriptions from visual data using LLMs but does not focus on LLM training data processing aspects such as data collection or filtering."
      },
      "tasks": [
        "Scene Understanding",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.15035",
      "abstract": "Accurate and efficient simulation of wave equations is crucial in computational wave imaging applications, such as ultrasound computed tomography (USCT), which reconstructs tissue material properties from observed scattered waves. Traditional numerical solvers for wave equations are computationally intensive and often unstable, limiting their practical applications for quasi-real-time image reconstruction. Neural operators offer an innovative approach by accelerating PDE solving using neural networks; however, their effectiveness in realistic imaging is limited because existing datasets oversimplify real-world complexity. In this paper, we present OpenBreastUS, a large-scale wave equation dataset designed to bridge the gap between theoretical equations and practical imaging applications. OpenBreastUS includes 8,000 anatomically realistic human breast phantoms and over 16 million frequency-domain wave simulations using real USCT configurations. It enables a comprehensive benchmarking of popular neural operators for both forward simulation and inverse imaging tasks, allowing analysis of their performance, scalability, and generalization capabilities. By offering a realistic and extensive dataset, OpenBreastUS not only serves as a platform for developing innovative neural PDE solvers but also facilitates their deployment in real-world medical imaging problems. For the first time, we demonstrate efficient in vivo imaging of the human breast using neural operator solvers.",
      "authors": [
        "Zhijun Zeng",
        "Youjia Zheng",
        "Hao Hu",
        "Zeyuan Dong",
        "Yihang Zheng",
        "Xinliang Liu",
        "Jinzhuo Wang",
        "Zuoqiang Shi",
        "Linfeng Zhang",
        "Yubing Li",
        "He Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:36:24+00:00",
          "link": "https://arxiv.org/abs/2507.15035v1",
          "size": "17659kb",
          "version": "v1"
        }
      ],
      "title": "OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15035",
        "PDF": "https://arxiv.org/pdf/2507.15035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents the OpenBreastUS dataset for benchmarking neural operators in ultrasound imaging, which does not pertain to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15856",
      "abstract": "Despite their fundamental role, it remains unclear what properties could make visual tokenizers more effective for generative modeling. We observe that modern generative models share a conceptually similar training objective -- reconstructing clean signals from corrupted inputs such as Gaussian noise or masking -- a process we term denoising. Motivated by this insight, we propose aligning tokenizer embeddings directly with the downstream denoising objective, encouraging latent embeddings to be more easily reconstructed even when heavily corrupted. To achieve this, we introduce the Latent Denoising Tokenizer (l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images from latent embeddings corrupted by interpolative noise and random masking. Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer consistently outperforms standard tokenizers across six representative generative models. Our findings highlight denoising as a fundamental design principle for tokenizer development, and we hope it could motivate new perspectives for future tokenizer design.",
      "authors": [
        "Jiawei Yang and Tianhong Li and Lijie Fan and Yonglong Tian and Yue Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2507.15856v1",
          "size": "4039kb",
          "version": "v1"
        }
      ],
      "title": "Latent Denoising Makes Good Visual Tokenizers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15856",
        "HTML": "https://arxiv.org/html/2507.15856",
        "PDF": "https://arxiv.org/pdf/2507.15856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new visual tokenizer with applications in denoising for generative models. It is focused on image processing rather than LLM data processing or dataset curation."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.10442",
      "abstract": "Sampling-based path planning algorithms play an important role in autonomous robotics. However, a common problem among these algorithms is that the initial path generated is not optimal, and the convergence is too slow for real-world applications. In this paper, we propose a novel image-based learning algorithm using a Convolutional Block Attention Generative Adversarial Network (CBAGAN-RRT) with a combination of spatial and channel attention and a novel loss function to design the heuristics, find a better optimal path, and improve the convergence of the algorithm, both concerning time and speed. The probability distribution of the paths generated from our GAN model is used to guide the sampling process for the RRT algorithm. We demonstrate that our algorithm outperforms the previous state-of-the-art algorithms using both the image quality generation metrics, like IOU Score, Dice Score, FID score, and path planning metrics like time cost and the number of nodes. Ablation studies show the effectiveness of various components in our network architecture. The advantage of our approach is that we can avoid the complicated preprocessing in the state space, our model can be generalized to complex environments like those containing turns and narrow passages without loss of accuracy, and our model can be easily integrated with other sampling-based path planning algorithms.",
      "authors": [
        "Abhinav Sagar",
        "Sai Teja Gilukara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-13T20:06:53+00:00",
          "link": "https://arxiv.org/abs/2305.10442v1",
          "size": "397kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:15:46+00:00",
          "link": "https://arxiv.org/abs/2305.10442v2",
          "size": "236kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T23:36:32+00:00",
          "link": "https://arxiv.org/abs/2305.10442v3",
          "size": "244kb",
          "version": "v3"
        }
      ],
      "title": "CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network for Sampling-Based Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.10442",
        "HTML": "https://arxiv.org/html/2305.10442",
        "PDF": "https://arxiv.org/pdf/2305.10442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving sampling-based path planning for robotics using a Generative Adversarial Network, with no connection to the processing of training data for LLMs."
      },
      "tasks": [
        "Generative Adversarial Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14658",
      "abstract": "Popular methods in cooperative Multi-Agent Reinforcement Learning with partially observable environments typically allow agents to act independently during execution, which may limit the coordinated effect of the trained policies. However, by sharing information such as known or suspected ongoing threats, effective communication can lead to improved decision-making in the cyber battle space. We propose a game design where defender agents learn to communicate and defend against imminent cyber threats by playing training games in the Cyber Operations Research Gym, using the Differentiable Inter Agent Learning algorithm adapted to the cyber operational environment. The tactical policies learned by these autonomous agents are akin to those of human experts during incident responses to avert cyber threats. In addition, the agents simultaneously learn minimal cost communication messages while learning their defence tactical policies.",
      "authors": [
        "Faizan Contractor",
        "Li Li",
        "Ranwa Al Mallah"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:16:24+00:00",
          "link": "https://arxiv.org/abs/2507.14658v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14658",
        "HTML": "https://arxiv.org/html/2507.14658",
        "PDF": "https://arxiv.org/pdf/2507.14658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about communication in multi-agent reinforcement learning for autonomous cyber defense, which does not involve LLM training data processing operations or datasets related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15049",
      "abstract": "Unmanned Aerial Vehicles are reshaping Non-Terrestrial Networks by acting as agile, intelligent nodes capable of advanced analytics and instantaneous situational awareness. This article introduces a budget-friendly quadcopter platform that unites 5G communications, edge-based processing, and AI to tackle core challenges in NTN scenarios. Outfitted with a panoramic camera, robust onboard computation, and LLMs, the drone system delivers seamless object recognition, contextual analysis, and immersive operator experiences through virtual reality VR technology. Field evaluations confirm the platform's ability to process visual streams with low latency and sustain robust 5G links. Adding LLMs further streamlines operations by extracting actionable insights and refining collected data for decision support. Demonstrated use cases, including emergency response, infrastructure assessment, and environmental surveillance, underscore the system's adaptability in demanding contexts.",
      "authors": [
        "Andres Navarro",
        "Carlos de Quinto",
        "and Jos\\'e Alberto Hern\\'andez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:06:02+00:00",
          "link": "https://arxiv.org/abs/2507.15049v1",
          "size": "3288kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Visual Line of Sight: UAVs with Edge AI, Connected LLMs, and VR for Autonomous Aerial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15049",
        "HTML": "https://arxiv.org/html/2507.15049",
        "PDF": "https://arxiv.org/pdf/2507.15049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of UAVs with Edge AI and LLMs for non-terrestrial networks and VR applications, focusing on system capabilities and performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15633",
      "abstract": "Optical Music Recognition (OMR) is a cornerstone of music digitization initiatives in cultural heritage, yet it remains limited by the scarcity of annotated data and the complexity of historical manuscripts. In this paper, we present a preliminary study of Active Learning (AL) and Sequential Learning (SL) tailored for object detection and layout recognition in an old medieval music manuscript. Leveraging YOLOv8, our system selects samples with the highest uncertainty (lowest prediction confidence) for iterative labeling and retraining. Our approach starts with a single annotated image and successfully boosts performance while minimizing manual labeling. Experimental results indicate that comparable accuracy to fully supervised training can be achieved with significantly fewer labeled examples. We test the methodology as a preliminary investigation on a novel dataset offered to the community by the Anonymous project, which studies laude, a poetical-musical genre spread across Italy during the 12th-16th Century. We show that in the manuscript at-hand, uncertainty-based AL is not effective and advocates for more usable methods in data-scarcity scenarios.",
      "authors": [
        "Sachin Sharma (GSSI)",
        "Federico Simonetta (GSSI)",
        "Michele Flammini (GSSI)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:55:54+00:00",
          "link": "https://arxiv.org/abs/2507.15633v1",
          "size": "651kb",
          "version": "v1"
        }
      ],
      "title": "Experimenting active and sequential learning in a medieval music manuscript",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15633",
        "PDF": "https://arxiv.org/pdf/2507.15633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on active and sequential learning strategies for optical music recognition in medieval manuscripts. It does not address any aspects of LLM training data processing or operations related to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15735",
      "abstract": "In the setup of selling one or more goods, various papers have shown, in various forms and for various purposes, that a small change in the distribution of a buyer's valuations may cause only a small change in the possible revenue that can be extracted. We prove a simple, clean, convenient, and general statement to this effect: let X and Y be random valuations on k additive goods, and let W(X,Y) be the Wasserstein (or \"earth mover's\") distance between them; then sqrt(Rev(X))-sqrt(Rev(Y)) <= sqrt(W(X,Y)). This further implies that a simple explicit modification of any optimal mechanism for X, namely, \"uniform discounting\", is guaranteed to be almost optimal for any Y that is close to X in the Wasserstein distance.",
      "authors": [
        "Sergiu Hart and Noam Nisan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:42:41+00:00",
          "link": "https://arxiv.org/abs/2507.15735v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "The Root of Revenue Continuity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15735",
        "HTML": "https://arxiv.org/html/2507.15735",
        "PDF": "https://arxiv.org/pdf/2507.15735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses revenue continuity in economic settings using Wasserstein distance and does not mention any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.09675",
      "abstract": "Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit posts and comments, a detailed codebook adapted to the social media context, and models to predict storytelling at the document and span levels. Our dataset is sampled from hundreds of popular English-language Reddit communities ranging across 33 topic categories, and it contains fine-grained expert annotations, including binary story labels, story spans, and event spans. We evaluate a range of detection methods using our data, and we identify the distinctive textual features of online storytelling, focusing on storytelling spans. We illuminate distributional characteristics of storytelling on a large community-centric social media platform, and we also conduct a case study on r/ChangeMyView, where storytelling is used as one of many persuasive strategies, illustrating that our data and models can be used for both inter- and intra-community research. Finally, we discuss implications of our tools and analyses for narratology and the study of online communities.",
      "authors": [
        "Maria Antoniak",
        "Joel Mire",
        "Maarten Sap",
        "Elliott Ash",
        "Andrew Piper"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-16T08:42:26+00:00",
          "link": "https://arxiv.org/abs/2311.09675v1",
          "size": "8104kb",
          "version": "v1"
        },
        {
          "date": "2024-02-27T03:37:03+00:00",
          "link": "https://arxiv.org/abs/2311.09675v2",
          "size": "7994kb",
          "version": "v2"
        },
        {
          "date": "2024-08-02T22:47:24+00:00",
          "link": "https://arxiv.org/abs/2311.09675v3",
          "size": "8284kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T16:02:22+00:00",
          "link": "https://arxiv.org/abs/2311.09675v4",
          "size": "7972kb",
          "version": "v4"
        }
      ],
      "title": "Where Do People Tell Stories Online? Story Detection Across Online Communities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.09675",
        "HTML": "https://arxiv.org/html/2311.09675",
        "PDF": "https://arxiv.org/pdf/2311.09675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on story detection in online communities and introduces the StorySeeker toolkit for analyzing Reddit data. It does not address training data processing for LLMs or contribute to pretraining, fine-tuning, or data quality improvement in the context of LLMs."
      },
      "tasks": [
        "Persuasion Strategies"
      ],
      "repo_urls": [
        "https://github.com/maria-antoniak/storyseeker"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08047",
      "abstract": "Complex logical reasoning tasks require a long sequence of reasoning, which a large language model (LLM) with chain-of-thought prompting still falls short. To alleviate this issue, neurosymbolic approaches incorporate a symbolic solver. Specifically, an LLM only translates a natural language problem into a satisfiability (SAT) problem that consists of first-order logic formulas, and a sound symbolic solver returns a mathematically correct solution. However, we discover that LLMs have difficulties to capture complex logical semantics hidden in the natural language during translation. To resolve this limitation, we propose a Compositional First-Order Logic Translation. An LLM first parses a natural language sentence into newly defined logical dependency structures that consist of an atomic subsentence and its dependents, then sequentially translate the parsed subsentences. Since multiple logical dependency structures and sequential translations are possible for a single sentence, we also introduce two Verification algorithms to ensure more reliable results. We utilize an SAT solver to rigorously compare semantics of generated first-order logic formulas and select the most probable one. We evaluate the proposed method, dubbed CLOVER, on seven logical reasoning benchmarks and show that it outperforms the previous neurosymbolic approaches and achieves new state-of-the-art results.",
      "authors": [
        "Hyun Ryu",
        "Gyeongman Kim",
        "Hyemin S. Lee",
        "Eunho Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T15:42:39+00:00",
          "link": "https://arxiv.org/abs/2410.08047v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T09:30:50+00:00",
          "link": "https://arxiv.org/abs/2410.08047v2",
          "size": "1511kb",
          "version": "v2"
        }
      ],
      "title": "Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08047",
        "HTML": "https://arxiv.org/html/2410.08047",
        "PDF": "https://arxiv.org/pdf/2410.08047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for translating natural language problems into First-Order Logic for logical reasoning tasks, and does not contribute to LLM training data processing or data operations related to LLM training."
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model",
        "Logical Reasoning",
        "Logic Grid Puzzle"
      ],
      "repo_urls": [
        "https://github.com/Hyun-Ryu/clover"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15652",
      "abstract": "Large language models (LLMs) have achieved remarkable successes on various tasks. However, recent studies have found that there are still significant challenges to the logical reasoning abilities of LLMs, which can be categorized into the following two aspects: (1) Logical question answering: LLMs often fail to generate the correct answer within a complex logical problem which requires sophisticated deductive, inductive or abductive reasoning given a collection of premises. (2) Logical consistency: LLMs are prone to producing responses contradicting themselves across different questions. For example, a state-of-the-art question-answering LLM Macaw, answers Yes to both questions Is a magpie a bird? and Does a bird have wings? but answers No to Does a magpie have wings?. To facilitate this research direction, we comprehensively investigate the most cutting-edge methods and propose a detailed taxonomy. Specifically, to accurately answer complex logic questions, previous methods can be categorized based on reliance on external solvers, prompts, and fine-tuning. To avoid logical contradictions, we discuss concepts and solutions of various logical consistencies, including implication, negation, transitivity, factuality consistencies, and their composites. In addition, we review commonly used benchmark datasets and evaluation metrics, and discuss promising research directions, such as extending to modal logic to account for uncertainty and developing efficient algorithms that simultaneously satisfy multiple logical consistencies.",
      "authors": [
        "Fengxiang Cheng",
        "Haoxuan Li",
        "Fenrong Liu",
        "Robert van Rooij",
        "Kun Zhang",
        "Zhouchen Lin"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:20:35+00:00",
          "link": "https://arxiv.org/abs/2502.15652v1",
          "size": "180kb",
          "version": "v1"
        },
        {
          "date": "2025-02-24T19:01:38+00:00",
          "link": "https://arxiv.org/abs/2502.15652v2",
          "size": "179kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T19:38:43+00:00",
          "link": "https://arxiv.org/abs/2502.15652v3",
          "size": "184kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T01:15:52+00:00",
          "link": "https://arxiv.org/abs/2502.15652v4",
          "size": "184kb",
          "version": "v4"
        }
      ],
      "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15652",
        "HTML": "https://arxiv.org/html/2502.15652",
        "PDF": "https://arxiv.org/pdf/2502.15652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys methods to improve the logical reasoning abilities of LLMs and evaluates logical consistency, focusing on model improvements rather than any aspect of training data processing."
      },
      "tasks": [
        "Logical Reasoning",
        "Negation",
        "Question Answering",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16385",
      "abstract": "This paper proposes an optimization framework for distributed resource logistics system design to support future multimission space exploration. The performance and impact of distributed In-Situ Resource Utilization (ISRU) systems in facilitating space transportation are analyzed. The proposed framework considers technology trade studies, deployment strategy, facility location evaluation, and resource logistics after production for distributed ISRU systems. We develop piecewise linear sizing and cost estimation models based on economies of scale that can be easily integrated into network-based mission planning formulations. A case study on a multi-mission cislunar logistics campaign is conducted to demonstrate the value of the proposed method and evaluate key tradeoffs to compare the performance of distributed ISRU systems with traditional concentrated ISRU. Finally, a comprehensive sensitivity analysis is performed to assess the proposed system under varying conditions, comparing concentrated and distributed ISRU systems.",
      "authors": [
        "Evangelia Gkaravela",
        "Hang Woon Lee",
        "Hao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T03:26:43+00:00",
          "link": "https://arxiv.org/abs/2504.16385v1",
          "size": "1142kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Space Resource Logistics Architecture Optimization under Economies of Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16385",
        "HTML": "https://arxiv.org/html/2504.16385",
        "PDF": "https://arxiv.org/pdf/2504.16385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimization frameworks for space resource logistics and does not contribute to LLM training data processing or involve data-related operations for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14677",
      "abstract": "The superiority of graph contrastive learning (GCL) has prompted its application to anomaly detection tasks for more powerful risk warning systems. Unfortunately, existing GCL-based models tend to excessively prioritize overall detection performance while neglecting robustness to structural imbalance, which can be problematic for many real-world networks following power-law degree distributions. Particularly, GCL-based methods may fail to capture tail anomalies (abnormal nodes with low degrees). This raises concerns about the security and robustness of current anomaly detection algorithms and therefore hinders their applicability in a variety of realistic high-risk scenarios. To the best of our knowledge, research on the robustness of graph anomaly detection to structural imbalance has received little scrutiny. To address the above issues, this paper presents a novel GCL-based framework named AD-GCL. It devises the neighbor pruning strategy to filter noisy edges for head nodes and facilitate the detection of genuine tail nodes by aligning from head nodes to forged tail nodes. Moreover, AD-GCL actively explores potential neighbors to enlarge the receptive field of tail nodes through anomaly-guided neighbor completion. We further introduce intra- and inter-view consistency loss of the original and augmentation graph for enhanced representation. The performance evaluation of the whole, head, and tail nodes on multiple datasets validates the comprehensive superiority of the proposed AD-GCL in detecting both head anomalies and tail anomalies.",
      "authors": [
        "Yiming Xu",
        "Zhen Peng",
        "Bin Shi",
        "Xu Hua",
        "Bo Dong",
        "Song Wang",
        "Chen Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:05:27+00:00",
          "link": "https://arxiv.org/abs/2507.14677v1",
          "size": "718kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14677",
        "HTML": "https://arxiv.org/html/2507.14677",
        "PDF": "https://arxiv.org/pdf/2507.14677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph contrastive learning for anomaly detection, particularly addressing structural imbalances in networks. It does not pertain to LLM training data processing tasks or involve any relevant data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15224",
      "abstract": "SIMD (Single Instruction Multiple Data) instructions and their compiler intrinsics are widely supported by modern processors to accelerate performance-critical tasks. SIMD intrinsic programming, a trade-off between coding productivity and high performance, is widely used in the development of mainstream performance-critical libraries and daily computing tasks. Large Language Models (LLMs), which have demonstrated strong and comprehensive capabilities in code generation, show promise in assisting programmers with the challenges of SIMD intrinsic programming. However, existing code-generation benchmarks focus on only scalar code, and it is unclear how LLMs perform in generating vectorized code using SIMD intrinsics. To fill this gap, we propose SimdBench, the first code benchmark specifically designed for SIMD-intrinsic code generation, comprising 136 carefully crafted tasks and targeting five representative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86 Advanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM Scalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a systematic evaluation (measuring both correctness and performance) of 18 representative LLMs on SimdBench, resulting in a series of novel and insightful findings. Our evaluation results demonstrate that LLMs exhibit a universal decrease in pass@k during SIMD-intrinsic code generation compared to scalar-code generation. Our in-depth analysis highlights promising directions for the further advancement of LLMs in the challenging domain of SIMD-intrinsic code generation. SimdBench is fully open source at https://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader research community.",
      "authors": [
        "Yibo He",
        "Shuoran Zhao",
        "Jiaming Huang",
        "Yingjie Fu",
        "Hao Yu",
        "Cunjian Huang",
        "Tao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:55:41+00:00",
          "link": "https://arxiv.org/abs/2507.15224v1",
          "size": "589kb",
          "version": "v1"
        }
      ],
      "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15224",
        "HTML": "https://arxiv.org/html/2507.15224",
        "PDF": "https://arxiv.org/pdf/2507.15224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the focus of the paper is on benchmarking LLMs for SIMD-intrinsic code generation, it does involve creating the SimdBench dataset for evaluating language models. However, the main focus is performance evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15740",
      "abstract": "In this article we investigate the question of finding a network configuration of minimal length connecting three given points in the Heisenberg group. After proving existence of (possibly degenerate) minimal horizontal triods, we investigate their characterization. We then formulate a horizontal curve shortening flow that deforms any given suitable initial triod into a critical point for the length functional. Numerical experiments based on a stable fully discrete finite element scheme provide useful insights into the rich landscape of this sub-Riemannian geometry.",
      "authors": [
        "Robert N\\\"urnberg and Paola Pozzi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:54:03+00:00",
          "link": "https://arxiv.org/abs/2507.15740v1",
          "size": "18324kb",
          "version": "v1"
        }
      ],
      "title": "Minimal horizontal triods: Analysis and computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15740",
        "HTML": "https://arxiv.org/html/2507.15740",
        "PDF": "https://arxiv.org/pdf/2507.15740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses geometric configurations in the Heisenberg group and does not engage with the topics of LLM training data processing or any related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.16789",
      "abstract": "Dialogue systems (DS), including the task-oriented dialogue system (TOD) and the open-domain dialogue system (ODD), have always been a fundamental task in natural language processing (NLP), allowing various applications in practice. Owing to sophisticated training and well-designed model architecture, language models (LM) are usually adopted as the necessary backbone to build the dialogue system. Consequently, every breakthrough in LM brings about a shift in learning paradigm and research attention within dialogue system, especially the appearance of pre-trained language models (PLMs) and large language models (LLMs). In this paper, we take a deep look at the history of the dialogue system, especially its special relationship with the advancements of language models. Thus, our survey offers a systematic perspective, categorizing different stages in a chronological order aligned with LM breakthroughs, providing a comprehensive review of state-of-the-art research outcomes. What's more, we turn our attention to emerging topics and engage in a discussion on open challenges, providing valuable insights into the future directions for LLM-based dialogue systems. In summary, this survey delves into the dynamic interplay between language models and dialogue systems, unraveling the evolutionary path of this essential relationship. Through this exploration, we pave the way for a deeper comprehension of the field, guiding future developments in LM-based dialogue systems.",
      "authors": [
        "Hongru Wang",
        "Lingzhi Wang",
        "Yiming Du",
        "Liang Chen",
        "Jingyan Zhou",
        "Yufei Wang",
        "Kam-Fai Wong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-28T13:51:32+00:00",
          "link": "https://arxiv.org/abs/2311.16789v1",
          "size": "11903kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T10:06:23+00:00",
          "link": "https://arxiv.org/abs/2311.16789v2",
          "size": "356kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems: Data, Task and Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16789",
        "HTML": "https://arxiv.org/html/2311.16789",
        "PDF": "https://arxiv.org/pdf/2311.16789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a survey of dialogue systems and their evolution in relation to language models but does not offer a contribution to LLM training data processing or specific techniques for data handling in training LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.07851",
      "abstract": "The Indian summer monsoon is a highly complex and critical weather system that directly affects the livelihoods of over a billion people across the Indian subcontinent. Accurate short-term forecasting remains a major scientific challenge due to the monsoon's intrinsic nonlinearity and its sensitivity to multi-scale drivers, including local land-atmosphere interactions and large-scale ocean-atmosphere phenomena. In this study, we address the problem of forecasting daily rainfall across India during the summer months, focusing on both one-day and three-day lead times. We use Autoformers - deep learning transformer-based architectures designed for time series forecasting. These are trained on historical gridded precipitation data from the Indian Meteorological Department (1901--2023) at spatial resolutions of $0.25^\\circ \\times 0.25^\\circ$, as well as $1^\\circ \\times 1^\\circ$. The models also incorporate auxiliary meteorological variables from ECMWFs reanalysis datasets, namely, cloud cover, humidity, temperature, soil moisture, vorticity, and wind speed. Forecasts at $0.25^\\circ \\times 0.25^\\circ$ are benchmarked against ECMWFs High-Resolution Ensemble System (HRES), widely regarded as the most accurate numerical weather predictor, and at $1^\\circ \\times 1^\\circ $ with those from National Centre for Environmental Prediction (NCEP). We conduct both nationwide evaluations and localized analyses for major Indian cities. Our results indicate that transformer-based deep learning models consistently outperform both HRES and NCEP, as well as other climatological baselines. Specifically, compared to our model, forecasts from HRES and NCEP model have about 22\\% and 43\\% higher error, respectively, for a single day prediction, and over 27\\% and 66\\% higher error respectively, for a three day prediction.",
      "authors": [
        "Apoorva Narula",
        "Aastha Jain",
        "Jatin Batra",
        "MN Rajeevan and Sandeep Juneja"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T17:59:20+00:00",
          "link": "https://arxiv.org/abs/2402.07851v1",
          "size": "27477kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:33:17+00:00",
          "link": "https://arxiv.org/abs/2402.07851v2",
          "size": "4164kb",
          "version": "v2"
        }
      ],
      "title": "Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NWP forecasts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.07851",
        "HTML": "https://arxiv.org/html/2402.07851",
        "PDF": "https://arxiv.org/pdf/2402.07851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with monsoon rainfall prediction using transformer-based architectures and historical meteorological data, but it does not address any aspect of training data processing for LLMs."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14503",
      "abstract": "In this paper, we formulate the knowledge distillation (KD) as a conditional generative problem and propose the \\textit{Generative Distribution Distillation (GenDD)} framework. A naive \\textit{GenDD} baseline encounters two major challenges: the curse of high-dimensional optimization and the lack of semantic supervision from labels. To address these issues, we introduce a \\textit{Split Tokenization} strategy, achieving stable and effective unsupervised KD. Additionally, we develop the \\textit{Distribution Contraction} technique to integrate label supervision into the reconstruction objective. Our theoretical proof demonstrates that \\textit{GenDD} with \\textit{Distribution Contraction} serves as a gradient-level surrogate for multi-task learning, realizing efficient supervised training without explicit classification loss on multi-step sampling image representations. To evaluate the effectiveness of our method, we conduct experiments on balanced, imbalanced, and unlabeled data. Experimental results show that \\textit{GenDD} performs competitively in the unsupervised setting, significantly surpassing KL baseline by \\textbf{16.29\\%} on ImageNet validation set. With label supervision, our ResNet-50 achieves \\textbf{82.28\\%} top-1 accuracy on ImageNet in 600 epochs training, establishing a new state-of-the-art.",
      "authors": [
        "Jiequan Cui",
        "Beier Zhu",
        "Qingshan Xu",
        "Xiaogang Xu",
        "Pengguang Chen",
        "Xiaojuan Qi",
        "Bei Yu",
        "Hanwang Zhang",
        "Richang Hong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:27:42+00:00",
          "link": "https://arxiv.org/abs/2507.14503v1",
          "size": "331kb",
          "version": "v1"
        }
      ],
      "title": "Generative Distribution Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14503",
        "HTML": "https://arxiv.org/html/2507.14503",
        "PDF": "https://arxiv.org/pdf/2507.14503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Generative Distribution Distillation within the context of knowledge distillation and does not address LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14513",
      "abstract": "Recent advances in large language models (LLMs) and autonomous agents have enabled systems capable of performing complex tasks across domains such as human-computer interaction, planning, and web navigation. However, many existing frameworks struggle in real-world or resource-constrained environments due to their reliance on cloud-based computation, limited robustness in dynamic contexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous agents optimized for embedded systems. Written in Rust for safety and performance, Amico supports reactive, persistent agents that operate efficiently across embedded platforms and browser environments via WebAssembly. It provides clean abstractions for event handling, state management, behavior execution, and integration with reasoning modules. Amico delivers a unified infrastructure for constructing resilient, interactive agents suitable for deployment in settings with limited compute and intermittent connectivity.",
      "authors": [
        "Hongyi Yang and Yue Pan and Jiayi Xu and Kelsen Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:21:09+00:00",
          "link": "https://arxiv.org/abs/2507.14513v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14513",
        "HTML": "https://arxiv.org/html/2507.14513",
        "PDF": "https://arxiv.org/pdf/2507.14513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for autonomous agents in embedded environments. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14670",
      "abstract": "Accurately predicting gene expression from histopathology images offers a scalable and non-invasive approach to molecular profiling, with significant implications for precision medicine and computational pathology. However, existing methods often underutilize the cross-modal representation alignment between histopathology images and gene expression profiles across multiple representational levels, thereby limiting their prediction performance. To address this, we propose Gene-DML, a unified framework that structures latent space through Dual-pathway Multi-Level discrimination to enhance correspondence between morphological and transcriptional modalities. The multi-scale instance-level discrimination pathway aligns hierarchical histopathology representations extracted at local, neighbor, and global levels with gene expression profiles, capturing scale-aware morphological-transcriptional relationships. In parallel, the cross-level instance-group discrimination pathway enforces structural consistency between individual (image/gene) instances and modality-crossed (gene/image, respectively) groups, strengthening the alignment across modalities. By jointly modelling fine-grained and structural-level discrimination, Gene-DML is able to learn robust cross-modal representations, enhancing both predictive accuracy and generalization across diverse biological contexts. Extensive experiments on public spatial transcriptomics datasets demonstrate that Gene-DML achieves state-of-the-art performance in gene expression prediction. The code and checkpoints will be released soon.",
      "authors": [
        "Yaxuan Song",
        "Jianan Fan",
        "Hang Chang",
        "Weidong Cai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:45:12+00:00",
          "link": "https://arxiv.org/abs/2507.14670v1",
          "size": "22146kb",
          "version": "v1"
        }
      ],
      "title": "Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14670",
        "HTML": "https://arxiv.org/html/2507.14670",
        "PDF": "https://arxiv.org/pdf/2507.14670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on predicting gene expression from histopathology images, employing methods like dual-pathway multi-level discrimination. It does not relate to LLM training data processing or involve data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14706",
      "abstract": "Detecting fraudulent credit card transactions remains a significant challenge, due to the extreme class imbalance in real-world data and the often subtle patterns that separate fraud from legitimate activity. Existing research commonly attempts to address this by generating synthetic samples for the minority class using approaches such as GANs, VAEs, or hybrid generative models. However, these techniques, particularly when applied only to minority-class data, tend to result in overconfident classifiers and poor latent cluster separation, ultimately limiting real-world detection performance. In this study, we propose the Causal Prototype Attention Classifier (CPAC), an interpretable architecture that promotes class-aware clustering and improved latent space structure through prototype-based attention mechanisms and we will couple it with the encoder in a VAE-GAN allowing it to offer a better cluster separation moving beyond post-hoc sample augmentation. We compared CPAC-augmented models to traditional oversamplers, such as SMOTE, as well as to state-of-the-art generative models, both with and without CPAC-based latent classifiers. Our results show that classifier-guided latent shaping with CPAC delivers superior performance, achieving an F1-score of 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster separation. Further ablation studies and visualizations provide deeper insight into the benefits and limitations of classifier-driven representation learning for fraud detection. The codebase for this work will be available at final submission.",
      "authors": [
        "Claudio Giusti",
        "Luca Guarnera",
        "Mirko Casu",
        "Sebastiano Battiato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:51:54+00:00",
          "link": "https://arxiv.org/abs/2507.14706v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14706",
        "HTML": "https://arxiv.org/html/2507.14706",
        "PDF": "https://arxiv.org/pdf/2507.14706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on fraud detection using prototype attention mechanisms and synthetic oversampling in the context of credit card transactions. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15042",
      "abstract": "Adversarial prompt attacks can significantly alter the reliability of Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce incorrect outputs. In this paper, we present a novel method that applies Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. Our approach is gradient-free, treating the RAG pipeline as a black box and evolving a population of candidate suffixes to maximize the retrieval rank of a targeted incorrect document to be closer to real world scenarios. We conducted experiments on the BEIR QA datasets to evaluate attack success at certain retrieval rank thresholds under multiple retrieving applications. Our results demonstrate that DE-based prompt optimization attains competitive (and in some cases higher) success rates compared to GGPP to dense retrievers and PRADA to sparse retrievers, while using only a small number of tokens (<=5 tokens) in the adversarial suffix. Furthermore, we introduce a readability-aware suffix construction strategy, validated by a statistically significant reduction in MLM negative log-likelihood with Welch's t-test. Through evaluations with a BERT-based adversarial suffix detector, we show that DE-generated suffixes evade detection, yielding near-chance detection accuracy.",
      "authors": [
        "Jerry Wang and Fang Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:48:20+00:00",
          "link": "https://arxiv.org/abs/2507.15042v1",
          "size": "1330kb",
          "version": "v1"
        }
      ],
      "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15042",
        "HTML": "https://arxiv.org/html/2507.15042",
        "PDF": "https://arxiv.org/pdf/2507.15042"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial attacks using prompt injections on Retrieval-Augmented Generation systems, which concerns model robustness and security rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15607",
      "abstract": "Autonomous navigation of vehicle-trailer systems is crucial in environments like airports, supermarkets, and concert venues, where various types of trailers are needed to navigate with different payloads and conditions. However, accurately modeling such systems remains challenging, especially for trailers with castor wheels. In this work, we propose a novel universal vehicle-trailer navigation system that integrates a hybrid nominal kinematic model--combining classical nonholonomic constraints for vehicles and neural network-based trailer kinematics--with a lightweight online residual learning module to correct real-time modeling discrepancies and disturbances. Additionally, we develop a model predictive control framework with a weighted model combination strategy that improves long-horizon prediction accuracy and ensures safer motion planning. Our approach is validated through extensive real-world experiments involving multiple trailer types and varying payload conditions, demonstrating robust performance without manual tuning or trailer-specific calibration.",
      "authors": [
        "Yanbo Chen",
        "Yunzhe Tan",
        "Yaojia Wang",
        "Zhengzhe Xu",
        "Junbo Tan",
        "Xueqian Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:31:02+00:00",
          "link": "https://arxiv.org/abs/2507.15607v1",
          "size": "3700kb",
          "version": "v1"
        }
      ],
      "title": "A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15607",
        "HTML": "https://arxiv.org/html/2507.15607",
        "PDF": "https://arxiv.org/pdf/2507.15607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a navigation system for vehicle-trailer systems, involving kinematic models and learning modules. It does not pertain to LLMs or their training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10148",
      "abstract": "Aligning large language models (LLMs) with human values and intentions is crucial for their utility, honesty, and safety. Reinforcement learning from human feedback (RLHF) is a popular approach to achieve this alignment, but it faces challenges in computational efficiency and training stability. Recent methods like Direct Preference Optimization (DPO) and Simple Preference Optimization (SimPO) have proposed offline alternatives to RLHF, simplifying the process by reparameterizing the reward function. However, DPO depends on a potentially suboptimal reference model, and SimPO's assumption of a fixed target reward margin may lead to suboptimal decisions in diverse data settings. In this work, we propose $\\alpha$-DPO, an adaptive preference optimization algorithm designed to address these limitations by introducing a dynamic reward margin. Specifically, $\\alpha$-DPO employs an adaptive preference distribution, balancing the policy model and the reference model to achieve personalized reward margins. We provide theoretical guarantees for $\\alpha$-DPO, demonstrating its effectiveness as a surrogate optimization objective and its ability to balance alignment and diversity through KL divergence control. Empirical evaluations on AlpacaEval 2 and Arena-Hard show that $\\alpha$-DPO consistently outperforms DPO and SimPO across various model settings, establishing it as a robust approach for fine-tuning LLMs. Our method achieves significant improvements in win rates, highlighting its potential as a powerful tool for LLM alignment. The code is available at https://github.com/junkangwu/alpha-DPO",
      "authors": [
        "Junkang Wu",
        "Xue Wang",
        "Zhengyi Yang",
        "Jiancan Wu",
        "Jinyang Gao",
        "Bolin Ding",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T04:29:57+00:00",
          "link": "https://arxiv.org/abs/2410.10148v1",
          "size": "1256kb",
          "version": "v1"
        },
        {
          "date": "2024-10-16T05:59:33+00:00",
          "link": "https://arxiv.org/abs/2410.10148v2",
          "size": "1256kb",
          "version": "v2"
        },
        {
          "date": "2024-10-19T11:28:34+00:00",
          "link": "https://arxiv.org/abs/2410.10148v3",
          "size": "1256kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T03:40:37+00:00",
          "link": "https://arxiv.org/abs/2410.10148v4",
          "size": "1252kb",
          "version": "v4"
        }
      ],
      "title": "AlphaDPO: Adaptive Reward Margin for Direct Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10148",
        "HTML": "https://arxiv.org/html/2410.10148",
        "PDF": "https://arxiv.org/pdf/2410.10148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes $\\alpha$-DPO, an algorithm for adaptive preference optimization to align LLMs with human values, focusing on improving reward functions. While it relates to fine-tuning LLMs, it primarily addresses optimization rather than explicit training data processing operations."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/junkangwu/alpha-dpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14735",
      "abstract": "The introduction of large language models (LLMs) has enhanced automation in software engineering tasks, including in Model Driven Engineering (MDE). However, using general-purpose LLMs for domain modeling has its limitations. One approach is to adopt fine-tuned models, but this requires significant computational resources and can lead to issues like catastrophic forgetting.\n  This paper explores how hyperparameter tuning and prompt engineering can improve the accuracy of the Llama 3.1 model for generating domain models from textual descriptions. We use search-based methods to tune hyperparameters for a specific medical data model, resulting in a notable quality improvement over the baseline LLM. We then test the optimized hyperparameters across ten diverse application domains.\n  While the solutions were not universally applicable, we demonstrate that combining hyperparameter tuning with prompt engineering can enhance results across nearly all examined domain models.",
      "authors": [
        "Vladyslav Bulhakov",
        "Giordano d'Aloisio",
        "Claudio Di Sipio",
        "Antinisca Di Marco",
        "Davide Di Ruscio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:49:58+00:00",
          "link": "https://arxiv.org/abs/2507.14735v1",
          "size": "238kb",
          "version": "v1"
        }
      ],
      "title": "Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14735",
        "HTML": "https://arxiv.org/html/2507.14735",
        "PDF": "https://arxiv.org/pdf/2507.14735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning LLMs for domain modeling, touching on hyperparameter tuning and prompt engineering. While it explores fine-tuning, it does not focus on data processing stages like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14835",
      "abstract": "We study the problem of releasing a differentially private (DP) synthetic graph $G'$ that well approximates the triangle-motif sizes of all cuts of any given graph $G$, where a motif in general refers to a frequently occurring subgraph within complex networks. Non-private versions of such graphs have found applications in diverse fields such as graph clustering, graph sparsification, and social network analysis. Specifically, we present the first $(\\varepsilon,\\delta)$-DP mechanism that, given an input graph $G$ with $n$ vertices, $m$ edges and local sensitivity of triangles $\\ell_{3}(G)$, generates a synthetic graph $G'$ in polynomial time, approximating the triangle-motif sizes of all cuts $(S,V\\setminus S)$ of the input graph $G$ up to an additive error of $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$. Additionally, we provide a lower bound of $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ on the additive error for any DP algorithm that answers the triangle-motif size queries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to weighted graphs, and our lower bound extends to any $K_h$-motif cut for any constant $h\\geq 2$.",
      "authors": [
        "Pan Peng",
        "Hangyu Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T06:20:53+00:00",
          "link": "https://arxiv.org/abs/2507.14835v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14835",
        "HTML": "https://arxiv.org/html/2507.14835",
        "PDF": "https://arxiv.org/pdf/2507.14835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with generating differentially private synthetic graphs for preserving triangle-motif cuts. It primarily focuses on privacy in graph analysis and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14947",
      "abstract": "Echoes of the Land is an interactive installation that transforms seismic dynamics into a multisensory experience through a scientifically grounded spring-block model. Simulating earthquake recurrence and self-organized criticality, the work generates real-time sound and light via motion capture and concatenative granular synthesis. Each block acts as an agent, producing emergent audiovisual cascades that visualize the physics of rupture and threshold behavior. This work exemplifies the amalgamation of scientific knowledge and artistic practice, opening new avenues for novel forms of musical instrument and narrative medium, while inviting further investigation into the intersection of emergent complexity, aesthetics and interactivity.",
      "authors": [
        "Ivan C. H. Liu",
        "Chung-En Hao",
        "Jing Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T12:58:16+00:00",
          "link": "https://arxiv.org/abs/2507.14947v1",
          "size": "4473kb",
          "version": "v1"
        }
      ],
      "title": "Echoes of the Land: An Interactive Installation Based on Physical Model of Earthquake",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14947",
        "HTML": "https://arxiv.org/html/2507.14947",
        "PDF": "https://arxiv.org/pdf/2507.14947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an interactive installation based on an earthquake model, focusing on artistic and scientific intersections. It does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15849",
      "abstract": "Proficient multilingual speakers often intentionally switch languages in the middle of a conversation. Similarly, recent reasoning-focused bilingual large language models (LLMs) with strong capabilities in both languages exhibit language mixing--alternating languages within their chain of thought. Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy, suggesting that language mixing may benefit reasoning. In this work, we study language switching in Chinese-English bilingual reasoning models. We identify reinforcement learning with verifiable rewards (RLVR) as the critical training stage that leads to language mixing. We demonstrate that language mixing can enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6 percentage points on math reasoning tasks. Additionally, a lightweight probe can be trained to predict whether a potential language switch would benefit or harm reasoning, and when used to guide decoding, increases accuracy by up to 6.25 percentage points. Our findings suggest that language mixing is not merely a byproduct of multilingual training, but is a strategic reasoning behavior.",
      "authors": [
        "Yihao Li",
        "Jiayi Xin",
        "Miranda Muqing Miao",
        "Qi Long",
        "Lyle Ungar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:56:09+00:00",
          "link": "https://arxiv.org/abs/2507.15849v1",
          "size": "1365kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of Language Mixing on Bilingual LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15849",
        "HTML": "https://arxiv.org/html/2507.15849",
        "PDF": "https://arxiv.org/pdf/2507.15849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines bilingual LLM reasoning and the phenomenon of language mixing. While it discusses training stages that induce language mixing, the main focus is on model behavior rather than on data processing techniques or dataset creation for training the LLM."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.06771",
      "abstract": "We present a method that allows efficient and safe approximation of model predictive controllers using kernel interpolation. Since the computational complexity of the approximating function scales linearly with the number of data points, we propose to use a scoring function which chooses the most promising data. To further reduce the complexity of the approximation, we restrict our considerations to the set of closed-loop reachable states. That is, the approximating function only has to be accurate within this set. This makes our method especially suited for systems, where the set of initial conditions is small. In order to guarantee safety and high performance of the designed approximated controller, we use reachability analysis based on Monte Carlo methods.",
      "authors": [
        "Alexander Rose",
        "Philipp Schaub",
        "Rolf Findeisen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T11:04:15+00:00",
          "link": "https://arxiv.org/abs/2410.06771v1",
          "size": "224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:53:04+00:00",
          "link": "https://arxiv.org/abs/2410.06771v2",
          "size": "211kb",
          "version": "v2"
        }
      ],
      "title": "Safe and High-Performance Learning of Model Predicitve Control using Kernel-Based Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06771",
        "HTML": "https://arxiv.org/html/2410.06771",
        "PDF": "https://arxiv.org/pdf/2410.06771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a method for model predictive control using kernel interpolation, which is not related to LLM training data processing or higher-quality dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.02024",
      "abstract": "Manus AI is a general-purpose AI agent introduced in early 2025, marking a significant advancement in autonomous artificial intelligence. Developed by the Chinese startup Monica.im, Manus is designed to bridge the gap between \"mind\" and \"hand\" - combining the reasoning and planning capabilities of large language models with the ability to execute complex, end-to-end tasks that produce tangible outcomes. This paper presents a comprehensive overview of Manus AI, exploring its core technical architecture, diverse applications across sectors such as healthcare, finance, manufacturing, robotics, and gaming, as well as its key strengths, current limitations, and future potential. Positioned as a preview of what lies ahead, Manus AI represents a shift toward intelligent agents that can translate high-level intentions into real-world actions, heralding a new era of human-AI collaboration.",
      "authors": [
        "Minjie Shen and Yanshu Li and Lulu Chen and Qikai Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T08:24:00+00:00",
          "link": "https://arxiv.org/abs/2505.02024v1",
          "size": "3148kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T20:38:54+00:00",
          "link": "https://arxiv.org/abs/2505.02024v2",
          "size": "3149kb",
          "version": "v2"
        }
      ],
      "title": "From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02024",
        "HTML": "https://arxiv.org/html/2505.02024",
        "PDF": "https://arxiv.org/pdf/2505.02024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides an overview of Manus AI, an autonomous digital agent, focusing on its architecture and applications. It does not discuss LLM training data processing."
      },
      "tasks": [
        "AI Agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14475",
      "abstract": "Temporal Knowledge Graph Alignment (TKGA) seeks to identify equivalent entities across heterogeneous temporal knowledge graphs (TKGs) for fusion to improve their completeness. Although some approaches have been proposed to tackle this task, most assume unified temporal element standards and simplified temporal structures across different TKGs. They cannot deal with TKGA in the wild (TKGA-Wild), where multi-scale temporal element entanglement and cross-source temporal structural imbalances are common. To bridge this gap, we study the task of TKGA-Wild and propose HyDRA, a new and effective solution. HyDRA is the first to reformulate the task via multi-scale hypergraph retrieval-augmented generation to address the challenges of TKGA-Wild.In addition, we design a new scale-weave synergy mechanism for HyDRA, which incorporates intra-scale interactions and cross-scale conflict detection. This mechanism is designed to alleviate the fragmentation caused by multi-source temporal incompleteness and resolves inconsistencies arising from complex and uneven temporal event density distributions, thereby enhancing the model capacity to handle the intricacies of real-world temporal alignment. Finally, there is no standard benchmark that captures these challenges of TKGA-Wild and effectively evaluates existing methods. To this end, we formally propose to benchmark challenges for TKGA-Wild and validate the effectiveness of the method by establishing two new datasets(BETA and WildBETA). Extensive experiments on the new datasets and six representative benchmarks show that BETA and WildBETA better reflect real-world challenges. Meanwhile, HyDRA proposes a new paradigm for TKGA-Wild, consistently outperforming 24 competitive baselines, while maintaining strong efficiency and scalability.",
      "authors": [
        "Runhao Zhao",
        "Weixin Zeng",
        "Wentao Zhang",
        "Xiang Zhao",
        "Jiuyang Tang",
        "and Lei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:12:06+00:00",
          "link": "https://arxiv.org/abs/2507.14475v1",
          "size": "1424kb",
          "version": "v1"
        }
      ],
      "title": "Towards Temporal Knowledge Graph Alignment in the Wild",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14475",
        "HTML": "https://arxiv.org/html/2507.14475",
        "PDF": "https://arxiv.org/pdf/2507.14475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces TKGA-Wild for temporal knowledge graphs and benchmarks, it primarily focuses on knowledge graph alignment rather than LLM training data processing. There is a potential overlap in dataset creation, but the main contribution lies elsewhere."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14484",
      "abstract": "In recent years, graph neural networks (GNN) have achieved unprecedented successes in node classification tasks. Although GNNs inherently encode specific inductive biases (e.g., acting as low-pass or high-pass filters), most existing methods implicitly assume conditional independence among node labels in their optimization objectives. While this assumption is suitable for traditional classification tasks such as image recognition, it contradicts the intuitive observation that node labels in graphs remain correlated, even after conditioning on the graph structure. To make structured predictions for node labels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for Structured node Classification. ReDiSC estimates the joint distribution of node labels using a reparameterized masked diffusion model, which is learned through the variational expectation-maximization (EM) framework. Our theoretical analysis shows the efficiency advantage of ReDiSC in the E-step compared to DPM-SNC, a state-of-the-art model that relies on a manifold-constrained diffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's M-step objective to popular GNN and label propagation hybrid approaches. Extensive experiments demonstrate that ReDiSC achieves superior or highly competitive performance compared to state-of-the-art GNN, label propagation, and diffusion-based baselines across both homophilic and heterophilic graphs of varying sizes. Notably, ReDiSC scales effectively to large-scale datasets on which previous structured diffusion methods fail due to computational constraints, highlighting its significant practical advantage in structured node classification tasks.",
      "authors": [
        "Yule Li",
        "Yifeng Lu",
        "Zhen Wang",
        "Zhewei Wei",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:46:53+00:00",
          "link": "https://arxiv.org/abs/2507.14484v1",
          "size": "425kb",
          "version": "v1"
        }
      ],
      "title": "ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14484",
        "HTML": "https://arxiv.org/html/2507.14484",
        "PDF": "https://arxiv.org/pdf/2507.14484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "ReDiSC is about structured node classification using graph neural networks and diffusion models, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15839",
      "abstract": "Synthetic data generation has emerged as an invaluable solution in scenarios where real-world data collection and usage are limited by cost and scarcity. Large language models (LLMs) have demonstrated remarkable capabilities in producing high-fidelity, domain-relevant samples across various fields. However, existing approaches that directly use LLMs to generate each record individually impose prohibitive time and cost burdens, particularly when large volumes of synthetic data are required. In this work, we propose a fast, cost-effective method for realistic tabular data synthesis that leverages LLMs to infer and encode each field's distribution into a reusable sampling script. By automatically classifying fields into numerical, categorical, or free-text types, the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale without continuous model inference. Experimental results show that our approach outperforms traditional direct methods in both diversity and data realism, substantially reducing the burden of high-volume synthetic data generation. We plan to apply this methodology to accelerate testing in production pipelines, thereby shortening development cycles and improving overall system efficiency. We believe our insights and lessons learned will aid researchers and practitioners seeking scalable, cost-effective solutions for synthetic data generation.",
      "authors": [
        "Anh Nguyen",
        "Sam Schafft",
        "Nicholas Hale",
        "John Alfaro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:51:46+00:00",
          "link": "https://arxiv.org/abs/2507.15839v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15839",
        "HTML": "https://arxiv.org/html/2507.15839",
        "PDF": "https://arxiv.org/pdf/2507.15839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a method for fast, cost-effective synthetic tabular data generation using LLMs. This is directly relevant to LLM training data processing as it involves generating synthetic datasets, which is a core aspect of data processing for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14571",
      "abstract": "Phase distortion refers to the alteration of the phase relationships between frequencies in a signal, which can be perceptible. In this paper, we discuss a special case of phase distortion known as phase-intercept distortion, which is created by a frequency-independent phase shift. We hypothesize that, though this form of distortion changes a signal's waveform significantly, the distortion is imperceptible. Human-subject experiment results are reported which are consistent with this hypothesis. Furthermore, we discuss how the imperceptibility of phase-intercept distortion can be useful for machine learning, specifically for data augmentation. We conducted multiple experiments using phase-intercept distortion as a novel approach to data augmentation, and obtained improved results for audio machine learning tasks.",
      "authors": [
        "Venkatakrishnan Vaidyanathapuram Krishnan",
        "Nathaniel Condit-Schultz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T14:28:14+00:00",
          "link": "https://arxiv.org/abs/2506.14571v1",
          "size": "478kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T01:53:48+00:00",
          "link": "https://arxiv.org/abs/2506.14571v2",
          "size": "477kb",
          "version": "v2"
        }
      ],
      "title": "The Perception of Phase Intercept Distortion and its Application in Data Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14571",
        "HTML": "https://arxiv.org/html/2506.14571",
        "PDF": "https://arxiv.org/pdf/2506.14571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the concept of phase intercept distortion for data augmentation in audio machine learning, which does not involve LLM training data processing for pretraining or fine-tuning."
      },
      "tasks": [
        "Data Augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14741",
      "abstract": "The peer review process is often regarded as the gatekeeper of scientific integrity, yet increasing evidence suggests that it is not immune to bias. Although structural inequities in peer review have been widely debated, much less attention has been paid to the subtle ways in which language itself may reinforce disparities. This study undertakes one of the most comprehensive linguistic analyses of peer review to date, examining more than 80,000 reviews in two major journals. Using natural language processing and large-scale statistical modeling, it uncovers how review tone, sentiment, and supportive language vary across author demographics, including gender, race, and institutional affiliation. Using a data set that includes both anonymous and signed reviews, this research also reveals how the disclosure of reviewer identity shapes the language of evaluation. The findings not only expose hidden biases in peer feedback, but also challenge conventional assumptions about anonymity's role in fairness. As academic publishing grapples with reform, these insights raise critical questions about how review policies shape career trajectories and scientific progress.",
      "authors": [
        "Maria Sahakyan",
        "Bedoor AlShebli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:19:21+00:00",
          "link": "https://arxiv.org/abs/2507.14741v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "Disparities in Peer Review Tone and the Role of Reviewer Anonymity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14741",
        "PDF": "https://arxiv.org/pdf/2507.14741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses disparities in the peer review process using NLP techniques to analyze sentiment and tone in reviews. It does not contribute to LLM training data processing, as it does not discuss data operations related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14980",
      "abstract": "Federated Learning (FL) enables decentralized model training while preserving data privacy. Despite its benefits, FL faces challenges with non-identically distributed (non-IID) data, especially in long-tailed scenarios with imbalanced class samples. Momentum-based FL methods, often used to accelerate FL convergence, struggle with these distributions, resulting in biased models and making FL hard to converge. To understand this challenge, we conduct extensive investigations into this phenomenon, accompanied by a layer-wise analysis of neural network behavior. Based on these insights, we propose FedWCM, a method that dynamically adjusts momentum using global and per-round data to correct directional biases introduced by long-tailed distributions. Extensive experiments show that FedWCM resolves non-convergence issues and outperforms existing methods, enhancing FL's efficiency and effectiveness in handling client heterogeneity and data imbalance.",
      "authors": [
        "Tianle Li",
        "Yongzhi Huang",
        "Linshan Jiang",
        "Qipeng Xie",
        "Chang Liu",
        "Wenfeng Du",
        "Lu Wang",
        "and Kaishun Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.14980v1",
          "size": "5881kb",
          "version": "v1"
        }
      ],
      "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14980",
        "HTML": "https://arxiv.org/html/2507.14980",
        "PDF": "https://arxiv.org/pdf/2507.14980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses federated learning with a focus on overcoming challenges of non-IID data and does not pertain to data processing operations specific to LLM pretraining or fine-tuning datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15152",
      "abstract": "Automating data extraction from full-text randomised controlled trials (RCTs) for meta-analysis remains a significant challenge. This study evaluates the practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini) across tasks involving statistical results, risk-of-bias assessments, and study-level characteristics in three medical domains: hypertension, diabetes, and orthopaedics. We tested four distinct prompting strategies (basic prompting, self-reflective prompting, model ensemble, and customised prompts) to determine how to improve extraction quality. All models demonstrate high precision but consistently suffer from poor recall by omitting key information. We found that customised prompts were the most effective, boosting recall by up to 15\\%. Based on this analysis, we propose a three-tiered set of guidelines for using LLMs in data extraction, matching data types to appropriate levels of automation based on task complexity and risk. Our study offers practical advice for automating data extraction in real-world meta-analyses, balancing LLM efficiency with expert oversight through targeted, task-specific automation.",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.15152v1",
          "size": "338kb",
          "version": "v1"
        }
      ],
      "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15152",
        "HTML": "https://arxiv.org/html/2507.15152",
        "PDF": "https://arxiv.org/pdf/2507.15152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores using LLMs for data extraction automation and tests prompting strategies to improve extraction quality, it focuses more on task-specific automation rather than directly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15174",
      "abstract": "Traffic Signal Control (TSC) is essential for managing urban traffic flow and reducing congestion. Reinforcement Learning (RL) offers an adaptive method for TSC by responding to dynamic traffic patterns, with multi-agent RL (MARL) gaining traction as intersections naturally function as coordinated agents. However, due to shifts in environmental dynamics, implementing MARL-based TSC policies in the real world often leads to a significant performance drop, known as the sim-to-real gap. Grounded Action Transformation (GAT) has successfully mitigated this gap in single-agent RL for TSC, but real-world traffic networks, which involve numerous interacting intersections, are better suited to a MARL framework. In this work, we introduce JL-GAT, an application of GAT to MARL-based TSC that balances scalability with enhanced grounding capability by incorporating information from neighboring agents. JL-GAT adopts a decentralized approach to GAT, allowing for the scalability often required in real-world traffic networks while still capturing key interactions between agents. Comprehensive experiments on various road networks under simulated adverse weather conditions, along with ablation studies, demonstrate the effectiveness of JL-GAT. The code is publicly available at https://github.com/DaRL-LibSignal/JL-GAT/.",
      "authors": [
        "Justin Turnau",
        "Longchao Da",
        "Khoa Vo",
        "Ferdous Al Rafi",
        "Shreyas Bachiraju",
        "Tiejin Chen",
        "Hua Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T01:33:59+00:00",
          "link": "https://arxiv.org/abs/2507.15174v1",
          "size": "961kb",
          "version": "v1"
        }
      ],
      "title": "Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15174",
        "HTML": "https://arxiv.org/html/2507.15174",
        "PDF": "https://arxiv.org/pdf/2507.15174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses reinforcement learning for traffic signal control and addresses sim-to-real transfer challenges, with no relation to LLM training data processing or data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15761",
      "abstract": "Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed loop to identify, validate, and apply Gas-saving improvements. Experiments on 100 verified real-world contracts demonstrate that GasAgent successfully optimizes 82 contracts, achieving an average deployment Gas savings of 9.97%. In addition, our evaluation confirms its compatibility with existing tools and validates the effectiveness of each module through ablation studies. To assess broader usability, we further evaluate 500 contracts generated by five representative LLMs across 10 categories and find that GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from 4.79% to 13.93%, showing its usability as the optimization layer for LLM-assisted smart contract development.",
      "authors": [
        "Jingyi Zheng",
        "Zifan Peng",
        "Yule Liu",
        "Junfeng Wang",
        "Yifan Liao",
        "Wenhan Dong",
        "Xinlei He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:17:25+00:00",
          "link": "https://arxiv.org/abs/2507.15761v1",
          "size": "545kb",
          "version": "v1"
        }
      ],
      "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15761",
        "PDF": "https://arxiv.org/pdf/2507.15761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Gas optimization in smart contracts using a multi-agent framework, leveraging LLMs. It is not related to LLM training data processing in any significant way."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.00002",
      "abstract": "Several data compressors have been proposed in distributed optimization frameworks of network systems to reduce communication overhead in large-scale applications. In this paper, we demonstrate that effective information compression may occur over time or space during sequences of node communications in distributed algorithms, leading to the concept of spatio-temporal compressors. This abstraction classifies existing compressors and inspires new compressors as spatio-temporal compressors, with their effectiveness described by constructive stability criteria from nonlinear system theory. Subsequently, we incorporate these spatio-temporal compressors directly into standard continuous-time consensus flows and distributed primal-dual flows, establishing conditions ensuring exponential convergence. Additionally, we introduce a novel observer-based distributed primal-dual continuous flow integrated with spatio-temporal compressors, which provides broader convergence conditions. These continuous flows achieve exponential convergence to the global optimum when the objective function is strongly convex and can be discretized using Euler approximations. Finally, numerical simulations illustrate the versatility of the proposed spatio-temporal compressors and verify the convergence of",
      "authors": [
        "Zihao Ren",
        "Lei Wang",
        "Xinlei Yi",
        "Xi Wang",
        "Deming Yuan",
        "Tao Yang",
        "Zhengguang Wu",
        "Guodong Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T08:54:44+00:00",
          "link": "https://arxiv.org/abs/2409.00002v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2024-11-15T08:24:32+00:00",
          "link": "https://arxiv.org/abs/2409.00002v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-03-05T08:21:34+00:00",
          "link": "https://arxiv.org/abs/2409.00002v3",
          "size": "28kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T06:52:37+00:00",
          "link": "https://arxiv.org/abs/2409.00002v4",
          "size": "35kb",
          "version": "v4"
        }
      ],
      "title": "Distributed Optimization by Network Flows with Spatio-Temporal Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00002",
        "HTML": "https://arxiv.org/html/2409.00002",
        "PDF": "https://arxiv.org/pdf/2409.00002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on distributed optimization and spatio-temporal compression in network systems, which is not directly related to LLM training data processing."
      },
      "tasks": [
        "Distributed Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12655",
      "abstract": "We propose a novel statistical inference framework for streaming principal component analysis (PCA) using Oja's algorithm, enabling the construction of confidence intervals for individual entries of the estimated eigenvector. Most existing works on streaming PCA focus on providing sharp sin-squared error guarantees. Recently, there has been some interest in uncertainty quantification for the sin-squared error. However, uncertainty quantification or sharp error guarantees for entries of the estimated eigenvector in the streaming setting remains largely unexplored. We derive a sharp Bernstein-type concentration bound for elements of the estimated vector matching the optimal error rate up to logarithmic factors. We also establish a Central Limit Theorem for a suitably centered and scaled subset of the entries. To efficiently estimate the coordinate-wise variance, we introduce a provably consistent subsampling algorithm that leverages the median-of-means approach, empirically achieving similar accuracy to multiplier bootstrap methods while being significantly more computationally efficient. Numerical experiments demonstrate its effectiveness in providing reliable uncertainty estimates with a fraction of the computational cost of existing methods.",
      "authors": [
        "Syamantak Kumar",
        "Shourya Pandey",
        "Purnamrita Sarkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T22:50:54+00:00",
          "link": "https://arxiv.org/abs/2506.12655v1",
          "size": "2719kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T20:09:07+00:00",
          "link": "https://arxiv.org/abs/2506.12655v2",
          "size": "2720kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Sin-Squared Error: Linear-Time Entrywise Uncertainty Quantification for Streaming PCA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12655",
        "PDF": "https://arxiv.org/pdf/2506.12655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new framework for PCA with uncertainty quantification, focusing on statistical inference techniques rather than on LLM data processing operations."
      },
      "tasks": [
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18668",
      "abstract": "Pretraining on large-scale, in-domain datasets grants histopathology foundation models (FM) the ability to learn task-agnostic data representations, enhancing transfer learning on downstream tasks. In computational pathology, automated whole slide image analysis requires multiple instance learning (MIL) frameworks due to the gigapixel scale of the slides. The diversity among histopathology FMs has highlighted the need to design real-world challenges for evaluating their effectiveness. To bridge this gap, our work presents a novel benchmark for evaluating histopathology FMs as patch-level feature extractors within a MIL classification framework. For that purpose, we leverage the AI4SkIN dataset, a multi-center cohort encompassing slides with challenging cutaneous spindle cell neoplasm subtypes. We also define the Foundation Model - Silhouette Index (FM-SI), a novel metric to measure model consistency against distribution shifts. Our experimentation shows that extracting less biased features enhances classification performance, especially in similarity-based MIL classifiers.",
      "authors": [
        "Pablo Meseguer and Roc\\'io del Amor and Valery Naranjo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T14:12:16+00:00",
          "link": "https://arxiv.org/abs/2506.18668v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18668",
        "HTML": "https://arxiv.org/html/2506.18668",
        "PDF": "https://arxiv.org/pdf/2506.18668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking histopathology foundation models for skin cancer subtyping using a specified dataset and does not involve LLM training data processing or operations related to data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04695",
      "abstract": "We introduce Concept Bottleneck Reward Models (CB-RM), a reward modeling framework that enables interpretable preference learning through selective concept annotation. Unlike standard RLHF methods that rely on opaque reward functions, CB-RM decomposes reward prediction into human-interpretable concepts. To make this framework efficient in low-supervision settings, we formalize an active learning strategy that dynamically acquires the most informative concept labels. We propose an acquisition function based on Expected Information Gain and show that it significantly accelerates concept learning without compromising preference accuracy. Evaluated on the UltraFeedback dataset, our method outperforms baselines in interpretability and sample efficiency, marking a step towards more transparent, auditable, and human-aligned reward models.",
      "authors": [
        "Sonia Laguna",
        "Katarzyna Kobalczyk",
        "Julia E. Vogt",
        "Mihaela Van der Schaar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T06:26:04+00:00",
          "link": "https://arxiv.org/abs/2507.04695v1",
          "size": "360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T05:53:25+00:00",
          "link": "https://arxiv.org/abs/2507.04695v2",
          "size": "320kb",
          "version": "v2"
        }
      ],
      "title": "Interpretable Reward Modeling with Active Concept Bottlenecks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04695",
        "HTML": "https://arxiv.org/html/2507.04695",
        "PDF": "https://arxiv.org/pdf/2507.04695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Concept Bottleneck Reward Models for interpretable preference learning in reinforcement learning contexts. It does not focus on training data processing for LLMs in the pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14293",
      "abstract": "The rapid development of autonomous web agents powered by Large Language Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of taking unintended or harmful actions. This situation underscores an urgent need for effective safety measures, akin to access controls for human users. To address this critical challenge, we introduce WebGuard, the first comprehensive dataset designed to support the assessment of web agent action risks and facilitate the development of guardrails for real-world online environments. In doing so, WebGuard specifically focuses on predicting the outcome of state-changing actions and contains 4,939 human-annotated actions from 193 websites across 22 diverse domains, including often-overlooked long-tail websites. These actions are categorized using a novel three-tier risk schema: SAFE, LOW, and HIGH. The dataset includes designated training and test splits to support evaluation under diverse generalization settings. Our initial evaluations reveal a concerning deficiency: even frontier LLMs achieve less than 60% accuracy in predicting action outcomes and less than 60% recall in lagging HIGH-risk actions, highlighting the risks of deploying current-generation agents without dedicated safeguards. We therefore investigate fine-tuning specialized guardrail models using WebGuard. We conduct comprehensive evaluations across multiple generalization settings and find that a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from 20% to 76%. Despite these improvements, the performance still falls short of the reliability required for high-stakes deployment, where guardrails must approach near-perfect accuracy and recall.",
      "authors": [
        "Boyuan Zheng",
        "Zeyi Liao",
        "Scott Salisbury",
        "Zeyuan Liu",
        "Michael Lin",
        "Qinyuan Zheng",
        "Zifan Wang",
        "Xiang Deng",
        "Dawn Song",
        "Huan Sun",
        "Yu Su"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:06:27+00:00",
          "link": "https://arxiv.org/abs/2507.14293v1",
          "size": "3231kb",
          "version": "v1"
        }
      ],
      "title": "WebGuard: Building a Generalizable Guardrail for Web Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14293",
        "HTML": "https://arxiv.org/html/2507.14293",
        "PDF": "https://arxiv.org/pdf/2507.14293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces WebGuard, a dataset aimed at assessing and improving the safety of web agent actions. It involves data creation and the use of fine-tuning with LLMs to evaluate and enhance model performance, aligning with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14619",
      "abstract": "Large Language Models (LLMs) face significant challenges in specialized domains like law, where precision and domain-specific knowledge are critical. This paper presents a streamlined two-stage framework consisting of Retrieval and Re-ranking to enhance legal document retrieval efficiency and accuracy. Our approach employs a fine-tuned Bi-Encoder for rapid candidate retrieval, followed by a Cross-Encoder for precise re-ranking, both optimized through strategic negative example mining. Key innovations include the introduction of the Exist@m metric to evaluate retrieval effectiveness and the use of semi-hard negatives to mitigate training bias, which significantly improved re-ranking performance. Evaluated on the SoICT Hackathon 2024 for Legal Document Retrieval, our team, 4Huiter, achieved a top-three position. While top-performing teams employed ensemble models and iterative self-training on large bge-m3 architectures, our lightweight, single-pass approach offered a competitive alternative with far fewer parameters. The framework demonstrates that optimized data processing, tailored loss functions, and balanced negative sampling are pivotal for building robust retrieval-augmented systems in legal contexts.",
      "authors": [
        "Van-Hoang Le",
        "Duc-Vu Nguyen",
        "Kiet Van Nguyen",
        "Ngan Luu-Thuy Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:30:14+00:00",
          "link": "https://arxiv.org/abs/2507.14619v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Legal Document Retrieval in Vietnamese with Semi-Hard Negative Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14619",
        "HTML": "https://arxiv.org/html/2507.14619",
        "PDF": "https://arxiv.org/pdf/2507.14619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving legal document retrieval using fine-tuned models and strategic negative example mining. It does not address any specific data processing contributions for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14997",
      "abstract": "Multimodal Large Language Models (MLLMs) show promise for image-based regression tasks, but current approaches face key limitations. Recent methods fine-tune MLLMs using preset output vocabularies and generic task-level prompts (e.g., \"How would you rate this image?\"), assuming this mimics human rating behavior. Our analysis reveals these approaches provide no benefit over image-only training. Models using preset vocabularies and generic prompts perform equivalently to image-only models, failing to leverage semantic understanding from textual input. We propose Regression via Transformer-Based Classification (RvTC), which replaces vocabulary-constrained classification with a flexible bin-based approach. Unlike approaches that address discretization errors through complex distributional modeling, RvTC eliminates manual vocabulary crafting through straightforward bin increase, achieving state-of-the-art performance on four image assessment datasets using only images. More importantly, we demonstrate that data-specific prompts dramatically improve performance. Unlike generic task descriptions, prompts containing semantic information about specific images enable MLLMs to leverage cross-modal understanding. On the AVA dataset, adding challenge titles to prompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We demonstrate through empirical evidence from the AVA and AGIQA-3k datasets that MLLMs benefit from semantic prompt information surpassing mere statistical biases. This underscores the importance of incorporating meaningful textual context in multimodal regression tasks.",
      "authors": [
        "Roy H. Jennings",
        "Genady Paikin",
        "Roy Shaul",
        "Evgeny Soloveichik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:05:24+00:00",
          "link": "https://arxiv.org/abs/2507.14997v1",
          "size": "1430kb",
          "version": "v1"
        }
      ],
      "title": "Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14997",
        "HTML": "https://arxiv.org/html/2507.14997",
        "PDF": "https://arxiv.org/pdf/2507.14997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus is on improving multimodal LLMs for image-based regression tasks by using semantic prompts, rather than on data processing for pretraining or fine-tuning in LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.10770",
      "abstract": "Natural language processing (NLP) applications such as named entity recognition (NER) for low-resource corpora do not benefit from recent advances in the development of large language models (LLMs) where there is still a need for larger annotated datasets. This research article introduces a methodology for generating translated versions of annotated datasets through crosslingual annotation projection. Leveraging a language agnostic BERT-based approach, it is an efficient solution to increase low-resource corpora with few human efforts and by only using already available open data resources. Quantitative and qualitative evaluations are often lacking when it comes to evaluating the quality and effectiveness of semi-automatic data generation strategies. The evaluation of our crosslingual annotation projection approach showed both effectiveness and high accuracy in the resulting dataset. As a practical application of this methodology, we present the creation of French Annotated Resource with Semantic Information for Medical Entities Detection (FRASIMED), an annotated corpus comprising 2'051 synthetic clinical cases in French. The corpus is now available for researchers and practitioners to develop and refine French natural language processing (NLP) applications in the clinical field (https://zenodo.org/record/8355629), making it the largest open annotated corpus with linked medical concepts in French.",
      "authors": [
        "Jamil Zaghir",
        "Mina Bjelogrlic",
        "Jean-Philippe Goldman",
        "Souka\\\"ina Aananou",
        "Christophe Gaudet-Blavignac and Christian Lovis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-19T17:17:28+00:00",
          "link": "https://arxiv.org/abs/2309.10770v1",
          "size": "974kb",
          "version": "v1"
        }
      ],
      "title": "FRASIMED: a Clinical French Annotated Resource Produced through Crosslingual BERT-Based Annotation Projection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.10770",
        "PDF": "https://arxiv.org/pdf/2309.10770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a methodology for data generation through crosslingual annotation projection, resulting in the creation of the FRASIMED dataset. This involves the generation of new datasets and data engineering operations, making it directly relevant to LLM training data processing."
      },
      "tasks": [
        "named-entity-recognition",
        "Named Entity Recognition",
        "Named Entity Recognition (NER)",
        "NER"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.07089",
      "abstract": "A simple procedure for the design of recursive digital filters with an infinite impulse response (IIR) and non-recursive digital filters with a finite impulse response (FIR) is described. The fixed-lag smoothing filters are designed to track an approximately polynomial signal of specified degree without bias at steady state, while minimizing the gain of high-frequency (coloured) noise with a specified power spectral density. For the IIR variant, the procedure determines the optimal lag (i.e. the passband group delay) yielding a recursive low-complexity smoother of low order, with a specified bandwidth, and excellent passband phase linearity. The filters are applied to the problem of instantaneous frequency estimation, e.g. for Doppler-shift measurement, for a complex exponential with polynomial phase progression in additive white noise. For this classical problem, simulations show that the incorporation of a prediction filter (with a one-sample lead) reduces the incidence of (phase or frequency) angle unwrapping errors, particularly for signals with high rates of angle change, which are known to limit the performance of standard FIR estimators at low SNR. This improvement allows the instantaneous phase of low-frequency signals to be estimated, e.g. for time-delay measurement, and/or the instantaneous frequency of frequency-modulated signals, down to a lower SNR. In the absence of unwrapping errors, the error variance of the IIR estimators (with the optimal phase lag) reaches the FIR lower bound, at a significantly lower computational cost. Guidelines for configuring and tuning both FIR and IIR filters are provided.",
      "authors": [
        "Hugh Lachlan Kennedy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-13T05:37:03+00:00",
          "link": "https://arxiv.org/abs/2311.07089v1",
          "size": "3391kb",
          "version": "v1"
        },
        {
          "date": "2023-11-14T03:15:08+00:00",
          "link": "https://arxiv.org/abs/2311.07089v2",
          "size": "3414kb",
          "version": "v2"
        },
        {
          "date": "2023-11-28T06:31:04+00:00",
          "link": "https://arxiv.org/abs/2311.07089v3",
          "size": "3387kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T12:17:17+00:00",
          "link": "https://arxiv.org/abs/2311.07089v4",
          "size": "3387kb",
          "version": "v4"
        }
      ],
      "title": "Recursive and non-recursive filters for sequential smoothing and prediction with instantaneous phase and frequency estimation applications (extended version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.07089",
        "PDF": "https://arxiv.org/pdf/2311.07089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this research is on digital filter design for signal processing applications, including frequency estimation. It is unrelated to LLM training data processing as it does not involve any aspect of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2311.11457",
      "abstract": "The term Research Software Engineer, or RSE, emerged a little over 10 years ago as a way to represent individuals working in the research community but focusing on software development. The term has been widely adopted and there are a number of high-level definitions of what an RSE is. However, the roles of RSEs vary depending on the institutional context they work in. At one end of the spectrum, RSE roles may look similar to a traditional research role. At the other extreme, they resemble that of a software engineer in industry. Most RSE roles inhabit the space between these two extremes. Therefore, providing a straightforward, comprehensive definition of what an RSE does and what experience, skills and competencies are required to become one is challenging. In this community paper we define the broad notion of what an RSE is, explore the different types of work they undertake, and define a list of fundamental competencies as well as values that define the general profile of an RSE. On this basis, we elaborate on the progression of these skills along different dimensions, looking at specific types of RSE roles, proposing recommendations for organisations, and giving examples of future specialisations. An appendix details how existing curricula fit into this framework.",
      "authors": [
        "Florian Goth",
        "Renato Alves",
        "Matthias Braun",
        "Leyla Jael Castro",
        "Gerasimos Chourdakis",
        "Simon Christ",
        "Jeremy Cohen",
        "Stephan Druskat",
        "Fredo Erxleben",
        "Jean-No\\\"el Grad",
        "Magnus Hagdorn",
        "Toby Hodges",
        "Guido Juckeland",
        "Dominic Kempf",
        "Anna-Lena Lamprecht",
        "Jan Linxweiler",
        "Frank L\\\"offler",
        "Michele Martone",
        "Moritz Schwarzmeier",
        "Heidi Seibold",
        "Jan Philipp Thiele",
        "Harald von Waldow",
        "Samantha Wittke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computers and Society (cs.CY)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-19T23:44:57+00:00",
          "link": "https://arxiv.org/abs/2311.11457v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2024-04-12T17:05:31+00:00",
          "link": "https://arxiv.org/abs/2311.11457v2",
          "size": "114kb",
          "version": "v2"
        },
        {
          "date": "2024-08-12T18:54:07+00:00",
          "link": "https://arxiv.org/abs/2311.11457v3",
          "size": "135kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T18:38:03+00:00",
          "link": "https://arxiv.org/abs/2311.11457v4",
          "size": "125kb",
          "version": "v4"
        }
      ],
      "title": "Foundational Competencies and Responsibilities of a Research Software Engineer: Current State and Suggestions for Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.11457",
        "HTML": "https://arxiv.org/html/2311.11457",
        "PDF": "https://arxiv.org/pdf/2311.11457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the roles and responsibilities of Research Software Engineers and does not involve training data processing for LLMs. It is centered on professional competencies rather than data engineering or dataset creation."
      },
      "repo_urls": [
        "https://github.com/the-teachingrse-project/competencies",
        "https://github.com/captainsifff/paper_teaching-learning-rse",
        "https://github.com/rsetoolkit/rse-competencies-toolkit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12442",
      "abstract": "The demand for machine intelligence capable of processing continuous, long-context inputs on local devices is growing rapidly. However, the quadratic complexity and memory requirements of traditional Transformer architectures make them inefficient and often unusable for these tasks. This has spurred a paradigm shift towards new architectures like State Space Models (SSMs) and hybrids, which promise near-linear scaling. While most current research focuses on the accuracy and theoretical throughput of these models, a systematic performance characterization on practical consumer hardware is critically needed to guide system-level optimization and unlock new applications.\n  To address this gap, we present a comprehensive, comparative benchmarking of carefully selected Transformer, SSM, and hybrid models specifically for long-context inference on consumer and embedded GPUs. Our analysis reveals that SSMs are not only viable but superior for this domain, capable of processing sequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than comparable Transformers. While Transformers may be up to 1.8x faster at short sequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x faster at very long contexts (~57K tokens). Our operator-level analysis reveals that custom, hardware-aware SSM kernels dominate the inference runtime, accounting for over 55% of latency on edge platforms, identifying them as a primary target for future hardware acceleration. We also provide detailed, device-specific characterization results to guide system co-design for the edge. To foster further research, we will open-source our characterization framework.",
      "authors": [
        "Saptarshi Mitra",
        "Rachid Karami",
        "Haocheng Xu",
        "Sitao Huang",
        "Hyoukjun Kwon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:28:40+00:00",
          "link": "https://arxiv.org/abs/2507.12442v1",
          "size": "9235kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T08:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.12442v2",
          "size": "9230kb",
          "version": "v2"
        }
      ],
      "title": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12442",
        "HTML": "https://arxiv.org/html/2507.12442",
        "PDF": "https://arxiv.org/pdf/2507.12442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on performance analysis and benchmarking of State Space Models (SSMs) and Transformer hybrids for long-context processing. It does not address training data processing operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12862",
      "abstract": "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.",
      "authors": [
        "Taylan Akay",
        "Harrison Tolley",
        "Hussein Abbass"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:34:24+00:00",
          "link": "https://arxiv.org/abs/2507.12862v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T23:31:14+00:00",
          "link": "https://arxiv.org/abs/2507.12862v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12862",
        "HTML": "https://arxiv.org/html/2507.12862",
        "PDF": "https://arxiv.org/pdf/2507.12862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses ethical decision-making in AI simulations, focusing on weighting ethical attributes rather than LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14274",
      "abstract": "Series elastic actuators (SEA) were introduced for serial robotic arms. Their model-based trajectory tracking control requires the second time derivatives of the inverse dynamics solution, for which algorithms were proposed. Trajectory control of parallel kinematics manipulators (PKM) equipped with SEAs has not yet been pursued. Key element for this is the computationally efficient evaluation of the second time derivative of the inverse dynamics solution. This has not been presented in the literature, and is addressed in the present paper for the first time. The special topology of PKM is exploited reusing the recursive algorithms for evaluating the inverse dynamics of serial robots. A Lie group formulation is used and all relations are derived within this framework. Numerical results are presented for a 6-DOF Gough-Stewart platform (as part of an exoskeleton), and for a planar PKM when a flatness-based control scheme is applied.",
      "authors": [
        "Andreas Mueller",
        "Shivesh Kumar",
        "Thomas Kordik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)",
        "Dynamical Systems (math.DS)",
        "Group Theory (math.GR)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T17:48:01+00:00",
          "link": "https://arxiv.org/abs/2507.14274v1",
          "size": "8681kb",
          "version": "v1"
        }
      ],
      "title": "A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14274",
        "HTML": "https://arxiv.org/html/2507.14274",
        "PDF": "https://arxiv.org/pdf/2507.14274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a formulation for the inverse dynamics of parallel kinematic manipulators and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14374",
      "abstract": "Relation Classification (RC) in biomedical texts is essential for constructing knowledge graphs and enabling applications such as drug repurposing and clinical decision-making. We propose an error-aware teacher--student framework that improves RC through structured guidance from a large language model (GPT-4o). Prediction failures from a baseline student model are analyzed by the teacher to classify error types, assign difficulty scores, and generate targeted remediations, including sentence rewrites and suggestions for KG-based enrichment. These enriched annotations are used to train a first student model via instruction tuning. This model then annotates a broader dataset with difficulty scores and remediation-enhanced inputs. A second student is subsequently trained via curriculum learning on this dataset, ordered by difficulty, to promote robust and progressive learning. We also construct a heterogeneous biomedical knowledge graph from PubMed abstracts to support context-aware RC. Our approach achieves new state-of-the-art performance on 4 of 5 PPI datasets and the DDI dataset, while remaining competitive on ChemProt.",
      "authors": [
        "Sinchani Chakraborty",
        "Sudeshna Sarkar",
        "Pawan Goyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:41:20+00:00",
          "link": "https://arxiv.org/abs/2507.14374v1",
          "size": "1105kb",
          "version": "v1"
        }
      ],
      "title": "Error-Aware Curriculum Learning for Biomedical Relation Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14374",
        "HTML": "https://arxiv.org/html/2507.14374",
        "PDF": "https://arxiv.org/pdf/2507.14374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper utilizes a large language model to enhance biomedical relation classification through instruction tuning and curriculum learning but does not primarily focus on dataset creation, generation, or significant LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14800",
      "abstract": "With the advanced reasoning and information analysis capabilities, large language models (LLMs) can offer a novel approach for the autonomous generation of dispatch strategies in power systems. This letter proposes an LLM-based experience-driven voltage control solution for distribution networks, which enables the self-evolution of LLM-based voltage control strategies through the collaboration and interaction of multiple modules-specifically, experience storage, experience retrieval, experience generation, and experience modification. Comprehensive experimental results validate the effectiveness of the proposed method and highlight the applicability of LLM in addressing power system dispatch challenges.",
      "authors": [
        "Xu Yang",
        "Chenhui Lin",
        "Haotian Liu",
        "Qi Wang",
        "Wenchuan Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:22:08+00:00",
          "link": "https://arxiv.org/abs/2507.14800v1",
          "size": "904kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14800",
        "PDF": "https://arxiv.org/pdf/2507.14800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on LLMs for voltage control in distribution networks, involving strategy generation and self-evolution of control strategies, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15345",
      "abstract": "This study presents a numerical analysis of the Field-Noyes reaction-diffusion model with nonsmooth initial data, employing a linear Galerkin finite element method for spatial discretization and a second-order exponential Runge-Kutta scheme for temporal integration. The initial data are assumed to reside in the fractional Sobolev space H^gamma with 0 < gamma < 2, where classical regularity conditions are violated, necessitating specialized error analysis. By integrating semigroup techniques and fractional Sobolev space theory, sharp fully discrete error estimates are derived in both L2 and H1 norms. This demonstrates that the convergence order adapts to the smoothness of initial data, a key advancement over traditional approaches that assume higher regularity. Numerical examples are provided to support the theoretical analysis.",
      "authors": [
        "Runjie Zhang",
        "Jinwei Fang",
        "Shuo Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:01:07+00:00",
          "link": "https://arxiv.org/abs/2507.15345v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Exponential Runge-Kutta Galerkin finite element method for a reaction-diffusion system with nonsmooth initial data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15345",
        "HTML": "https://arxiv.org/html/2507.15345",
        "PDF": "https://arxiv.org/pdf/2507.15345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a numerical analysis study focusing on a reaction-diffusion system, employing finite element methods. It does not relate to LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15457",
      "abstract": "In business processes, activity batching refers to packing multiple activity instances for joint execution. Batching allows managers to trade off cost and processing effort against waiting time. Larger and less frequent batches may lower costs by reducing processing effort and amortizing fixed costs, but they create longer waiting times. In contrast, smaller and more frequent batches reduce waiting times but increase fixed costs and processing effort. A batching policy defines how activity instances are grouped into batches and when each batch is activated. This paper addresses the problem of discovering batching policies that strike optimal trade-offs between waiting time, processing effort, and cost. The paper proposes a Pareto optimization approach that starts from a given set (possibly empty) of activity batching policies and generates alternative policies for each batched activity via intervention heuristics. Each heuristic identifies an opportunity to improve an activity's batching policy with respect to a metric (waiting time, processing time, cost, or resource utilization) and an associated adjustment to the activity's batching policy (the intervention). The impact of each intervention is evaluated via simulation. The intervention heuristics are embedded in an optimization meta-heuristic that triggers interventions to iteratively update the Pareto front of the interventions identified so far. The paper considers three meta-heuristics: hill-climbing, simulated annealing, and reinforcement learning. An experimental evaluation compares the proposed approach based on intervention heuristics against the same (non-heuristic guided) meta-heuristics baseline regarding convergence, diversity, and cycle time gain of Pareto-optimal policies.",
      "authors": [
        "Orlenys L\\'opez-Pintado",
        "Jannis Rosenbaum",
        "Marlon Dumas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:11:51+00:00",
          "link": "https://arxiv.org/abs/2507.15457v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Optimization of Activity Batching Policies in Business Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15457",
        "HTML": "https://arxiv.org/html/2507.15457",
        "PDF": "https://arxiv.org/pdf/2507.15457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimization in business processes and does not involve any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.17285",
      "abstract": "A/B testing has become the gold standard for policy evaluation in modern technological industries. Motivated by the widespread use of switchback experiments in A/B testing, this paper conducts a comprehensive comparative analysis of various switchback designs in Markovian environments. Unlike many existing works which derive the optimal design based on specific and relatively simple estimators, our analysis covers a range of state-of-the-art estimators developed in the reinforcement learning (RL) literature. It reveals that the effectiveness of different switchback designs depends crucially on (i) the size of the carryover effect and (ii) the auto-correlations among reward errors over time. Meanwhile, these findings are estimator-agnostic, i.e., they apply to most RL estimators. Based on these insights, we provide a workflow to offer guidelines for practitioners on designing switchback experiments in A/B testing.",
      "authors": [
        "Qianglin Wen",
        "Chengchun Shi",
        "Ying Yang",
        "Niansheng Tang and Hongtu Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-26T00:25:32+00:00",
          "link": "https://arxiv.org/abs/2403.17285v1",
          "size": "8252kb",
          "version": "v1"
        },
        {
          "date": "2024-10-05T04:24:18+00:00",
          "link": "https://arxiv.org/abs/2403.17285v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-05-29T12:21:30+00:00",
          "link": "https://arxiv.org/abs/2403.17285v3",
          "size": "16822kb",
          "version": "v3"
        },
        {
          "date": "2025-06-19T01:39:49+00:00",
          "link": "https://arxiv.org/abs/2403.17285v4",
          "size": "24395kb",
          "version": "v4"
        },
        {
          "date": "2025-07-11T05:19:33+00:00",
          "link": "https://arxiv.org/abs/2403.17285v5",
          "size": "26592kb",
          "version": "v5"
        },
        {
          "date": "2025-07-20T06:44:45+00:00",
          "link": "https://arxiv.org/abs/2403.17285v6",
          "size": "26591kb",
          "version": "v6"
        }
      ],
      "title": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17285",
        "PDF": "https://arxiv.org/pdf/2403.17285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses switchback experiments and their design in the context of A/B testing, without any mention of LLM training data processing or related activities."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10406",
      "abstract": "Unifying diverse image generation tasks within a single framework remains a fundamental challenge in visual generation. While large language models (LLMs) achieve unification through task-agnostic data and generation, existing visual generation models fail to meet these principles. Current approaches either rely on per-task datasets and large-scale training or adapt pre-trained image models with task-specific modifications, limiting their generalizability. In this work, we explore video models as a foundation for unified image generation, leveraging their inherent ability to model temporal correlations. We introduce RealGeneral, a novel framework that reformulates image generation as a conditional frame prediction task, analogous to in-context learning in LLMs. To bridge the gap between video models and condition-image pairs, we propose (1) a Unified Conditional Embedding module for multi-modal alignment and (2) a Unified Stream DiT Block with decoupled adaptive LayerNorm and attention mask to mitigate cross-modal interference. RealGeneral demonstrates effectiveness in multiple important visual generation tasks, e.g., it achieves a 14.5% improvement in subject similarity for customized generation and a 10% enhancement in image quality for canny-to-image task. Project page: https://lyne1.github.io/realgeneral_web/; GitHub Link: https://github.com/Lyne1/RealGeneral",
      "authors": [
        "Yijing Lin",
        "Mengqi Huang",
        "Shuhan Zhuang",
        "Zhendong Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T14:31:52+00:00",
          "link": "https://arxiv.org/abs/2503.10406v1",
          "size": "31746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T08:44:35+00:00",
          "link": "https://arxiv.org/abs/2503.10406v2",
          "size": "23403kb",
          "version": "v2"
        }
      ],
      "title": "RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10406",
        "HTML": "https://arxiv.org/html/2503.10406",
        "PDF": "https://arxiv.org/pdf/2503.10406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for unifying image generation tasks through video models and in-context learning. It focuses on visual generation, not LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10424",
      "abstract": "Many scholarly societies face challenges in adapting their publishing to an open access model where neither authors nor readers pay any fees. Some have argued that one of the main barriers is the actual cost of publishing. The goal of this paper is to show that the actual costs can be extremely low while still maintaining scholarly quality. We accomplish this by building a journal publishing workflow that minimizes the amount of required human labor. We recently built a software system for this and launched a journal using the system, and we estimate estimate our cost to publish this journal is approximately \\$705 per year, plus \\$1 per article and about 10 minutes of volunteer labor per article. We benefited from two factors, namely the fact that authors in our discipline use LaTeX to prepare their manuscripts, and we had volunteer labor to develop software and run the journal. We have made most of this software open source in the hopes that it can help others.",
      "authors": [
        "Joppe Bos and Kevin S. McCurley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T17:13:45+00:00",
          "link": "https://arxiv.org/abs/2504.10424v1",
          "size": "1011kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:04:19+00:00",
          "link": "https://arxiv.org/abs/2504.10424v2",
          "size": "1025kb",
          "version": "v2"
        }
      ],
      "title": "Lowering the Cost of Diamond Open Access Journals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10424",
        "PDF": "https://arxiv.org/pdf/2504.10424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a cost-effective approach to open access journal publishing, which is unrelated to LLM training data processing. It focuses on lowering publication costs rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19570",
      "abstract": "In many settings -- like market research and social choice -- people may be presented with unfamiliar options. Classical mechanisms may perform poorly because they fail to incentivize people to learn about these options, or worse, encourage counterproductive information acquisition. We formalize this problem in a model of robust mechanism design where agents find it costly to learn about their values for a product or policy. We identify sharp limits on the designer's ability to elicit, or learn about, these values. Where these limits do not bind, we propose two-stage mechanisms that are detail-free and robust: the second stage is a classical mechanism and the first stage asks participants to predict the results of the second stage.",
      "authors": [
        "Modibo K. Camara",
        "Nicole Immorlica",
        "Brendan Lucier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T06:36:55+00:00",
          "link": "https://arxiv.org/abs/2505.19570v1",
          "size": "164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:42:40+00:00",
          "link": "https://arxiv.org/abs/2505.19570v2",
          "size": "149kb",
          "version": "v2"
        }
      ],
      "title": "Eliciting Informed Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19570",
        "HTML": "https://arxiv.org/html/2505.19570",
        "PDF": "https://arxiv.org/pdf/2505.19570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses mechanism design to incentivize learning preferences for products or policies. It does not involve training data processing for LLMs or contribute to dataset creation or quality improvement in this context."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09024",
      "abstract": "Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized images in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.",
      "authors": [
        "Marie St-Laurent",
        "Basile Pinsard",
        "Oliver Contier",
        "Elizabeth DuPre",
        "Katja Seeliger",
        "Valentina Borghesani",
        "Julie A. Boyle",
        "Lune Bellec",
        "Martin N. Hebart"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:16:59+00:00",
          "link": "https://arxiv.org/abs/2507.09024v1",
          "size": "17450kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T21:09:28+00:00",
          "link": "https://arxiv.org/abs/2507.09024v2",
          "size": "23061kb",
          "version": "v2"
        }
      ],
      "title": "CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09024",
        "PDF": "https://arxiv.org/pdf/2507.09024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The CNeuroMod-THINGS paper describes an fMRI dataset for visual neuroscience, aimed at neuro-AI modeling. It is unrelated to any aspect of LLM training data processing, focusing on neuroimaging data instead."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14170",
      "abstract": "Structured pruning aims to reduce the size and computational cost of deep neural networks by removing entire filters or channels. The traditional regularizers such as L1 or Group Lasso and its variants lead to magnitude-biased pruning decisions, such that the filters with small magnitudes are likely to be pruned. Also, they often entail pruning results with almost zero margin around pruning decision boundary, such that tiny perturbation in a filter magnitude can flip the pruning decision. In this paper, we identify the precise algebraic condition under which pruning operations preserve model performance, and use the condition to construct a novel regularizer defined in an extended parameter space via auxiliary catalyst variables. The proposed Catalyst regularization ensures fair pruning chance for each filters with theoretically provable zero bias to their magnitude and robust pruning behavior achieved by wide-margin bifurcation of magnitudes between the preserved and the pruned filters. The theoretical properties naturally lead to real-world effectiveness, as shown by empirical validations of Catalyst Pruning algorithm. Pruning results on various datasets and models are superior to state-of-the-art filter pruning methods, and at the same time confirm the predicted robust and fair pruning characteristics of Catalyst pruning.",
      "authors": [
        "Jaeheun Jung",
        "Donghun Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:10:02+00:00",
          "link": "https://arxiv.org/abs/2507.14170v1",
          "size": "1758kb",
          "version": "v1"
        }
      ],
      "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14170",
        "HTML": "https://arxiv.org/html/2507.14170",
        "PDF": "https://arxiv.org/pdf/2507.14170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses structured pruning and introduces a novel regularizer for neural networks, which does not involve any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14682",
      "abstract": "The rate at which data is generated has been increasing rapidly, raising challenges related to its management. Traditional database management systems suffer from scalability and are usually inefficient when dealing with large-scale and heterogeneous data. This paper introduces IDSS (InnoCyPES Data Storage Service), a novel large-scale data storage tool that leverages peer-to-peer networks and embedded relational databases. We present the IDSS architecture and its design, and provide details related to the implementation. The peer-to-peer framework is used to provide support for distributed queries leveraging a relational database architecture based on a common schema. Furthermore, methods to support complex distributed query processing, enabling robust and efficient management of vast amounts of data are presented.",
      "authors": [
        "Massimo Cafaro",
        "Italo Epicoco",
        "Marco Pulimeno",
        "Lunodzo J. Mwinuka",
        "Lucas Pereira",
        "Hugo Morais"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:11:56+00:00",
          "link": "https://arxiv.org/abs/2507.14682v1",
          "size": "506kb",
          "version": "v1"
        }
      ],
      "title": "IDSS, a Novel P2P Relational Data Storage Service",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14682",
        "HTML": "https://arxiv.org/html/2507.14682",
        "PDF": "https://arxiv.org/pdf/2507.14682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel data storage service leveraging peer-to-peer networks, with no direct relevance to LLM training data processing or the creation, generation, or processing of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15185",
      "abstract": "Quantile-based randomized Kaczmarz (QRK) was recently introduced to efficiently solve sparsely corrupted linear systems $\\mathbf{A} \\mathbf{x}^*+\\mathbf{\\epsilon} = \\mathbf{b}$ [SIAM J. Matrix Anal. Appl., 43(2), 605-637], where $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$ and $\\mathbf{\\epsilon}$ is an arbitrary $(\\beta m)$-sparse corruption. However, all existing theoretical guarantees for QRK require quantiles to be computed using all $m$ samples (or a subsample of the same order), thus negating the computational advantage of Kaczmarz-type methods. This paper overcomes the bottleneck. We analyze a subsampling QRK, which computes quantiles from $D$ uniformly chosen samples at each iteration. Under some standard scaling assumptions on the coefficient matrix, we show that QRK with subsample size $D\\ge\\frac{C\\log (T)}{\\log(1/\\beta)}$ linearly converges over the first $T$ iterations with high probability, where $C$ is some absolute constant. This subsample size is a substantial reduction from $O(m)$ in prior results. For instance, it translates into $O(\\log(n))$ even if an approximation error of $\\exp(-n^2)$ is desired. Intriguingly, our subsample size is also tight up to a multiplicative constant: if $D\\le \\frac{c\\log(T)}{\\log(1/\\beta)}$ for some constant $c$, the error of the $T$-th iterate could be arbitrarily large with high probability. Numerical results are provided to corroborate our theory.",
      "authors": [
        "Jian-Feng Cai",
        "Junren Chen",
        "Anna Ma",
        "Tong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.15185v1",
          "size": "2120kb",
          "version": "v1"
        }
      ],
      "title": "On Subsample Size of Quantile-Based Randomized Kaczmarz",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15185",
        "HTML": "https://arxiv.org/html/2507.15185",
        "PDF": "https://arxiv.org/pdf/2507.15185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research deals with optimization techniques for sparsely corrupted linear systems using a quantile-based randomized Kaczmarz method, which is unrelated to any processes involved in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15399",
      "abstract": "Natural language offers a highly intuitive interface for enabling localized fine-grained edits of 3D shapes. However, prior works face challenges in preserving global coherence while locally modifying the input 3D shape. In this work, we introduce an inpainting-based framework for editing shapes represented as point clouds. Our approach leverages foundation 3D diffusion models for achieving localized shape edits, adding structural guidance in the form of a partial conditional shape, ensuring that other regions correctly preserve the shape's identity. Furthermore, to encourage identity preservation also within the local edited region, we propose an inference-time coordinate blending algorithm which balances reconstruction of the full shape with inpainting at a progression of noise levels during the inference process. Our coordinate blending algorithm seamlessly blends the original shape with its edited version, enabling a fine-grained editing of 3D shapes, all while circumventing the need for computationally expensive and often inaccurate inversion. Extensive experiments show that our method outperforms alternative techniques across a wide range of metrics that evaluate both fidelity to the original shape and also adherence to the textual description.",
      "authors": [
        "Etai Sella",
        "Noam Atia",
        "Ron Mokady",
        "Hadar Averbuch-Elor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:00:19+00:00",
          "link": "https://arxiv.org/abs/2507.15399v1",
          "size": "30756kb",
          "version": "v1"
        }
      ],
      "title": "Blended Point Cloud Diffusion for Localized Text-guided Shape Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15399",
        "PDF": "https://arxiv.org/pdf/2507.15399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for 3D shape editing using diffusion models and an inpainting approach. It does not involve language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.16737",
      "abstract": "We propose Point'n Move, a method that achieves interactive scene object manipulation with exposed region inpainting. Interactivity here further comes from intuitive object selection and real-time editing. To achieve this, we adopt Gaussian Splatting Radiance Field as the scene representation and fully leverage its explicit nature and speed advantage. Its explicit representation formulation allows us to devise a 2D prompt points to 3D mask dual-stage self-prompting segmentation algorithm, perform mask refinement and merging, minimize change as well as provide good initialization for scene inpainting and perform editing in real-time without per-editing training, all leads to superior quality and performance. We test our method by performing editing on both forward-facing and 360 scenes. We also compare our method against existing scene object removal methods, showing superior quality despite being more capable and having a speed advantage.",
      "authors": [
        "Jiajun Huang",
        "Hongchuan Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-28T12:33:49+00:00",
          "link": "https://arxiv.org/abs/2311.16737v1",
          "size": "26383kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T08:49:09+00:00",
          "link": "https://arxiv.org/abs/2311.16737v2",
          "size": "26382kb",
          "version": "v2"
        }
      ],
      "title": "Point'n Move: Interactive Scene Object Manipulation on Gaussian Splatting Radiance Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16737",
        "HTML": "https://arxiv.org/html/2311.16737",
        "PDF": "https://arxiv.org/pdf/2311.16737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for interactive scene object manipulation using Gaussian Splatting Radiance Fields. It does not relate to LLM training data processing or pertinent data allocation techniques."
      },
      "tasks": [
        "Object"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12851",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. \"Normal\" evaluates tool usage in basic scenarios; \"Special\" evaluates tool usage in situations with ambiguous or incomplete instructions; \"Agent\" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.",
      "authors": [
        "Chen Chen",
        "Xinlong Hao",
        "Weiwen Liu",
        "Xu Huang",
        "Xingshan Zeng",
        "Shuai Yu",
        "Dexun Li",
        "Shuai Wang",
        "Weinan Gan",
        "Yuefeng Huang",
        "Wulong Liu",
        "Xinzhi Wang",
        "Defu Lian",
        "Baoqun Yin",
        "Yasheng Wang",
        "Wu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T12:59:08+00:00",
          "link": "https://arxiv.org/abs/2501.12851v1",
          "size": "1669kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T14:36:52+00:00",
          "link": "https://arxiv.org/abs/2501.12851v2",
          "size": "1669kb",
          "version": "v2"
        },
        {
          "date": "2025-02-13T12:43:59+00:00",
          "link": "https://arxiv.org/abs/2501.12851v3",
          "size": "1052kb",
          "version": "v3"
        },
        {
          "date": "2025-02-26T09:54:28+00:00",
          "link": "https://arxiv.org/abs/2501.12851v4",
          "size": "915kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T05:06:20+00:00",
          "link": "https://arxiv.org/abs/2501.12851v5",
          "size": "910kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T07:20:02+00:00",
          "link": "https://arxiv.org/abs/2501.12851v6",
          "size": "1824kb",
          "version": "v6"
        }
      ],
      "title": "ACEBench: Who Wins the Match Point in Tool Usage?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12851",
        "HTML": "https://arxiv.org/html/2501.12851",
        "PDF": "https://arxiv.org/pdf/2501.12851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces ACEBench, a benchmark for assessing tool usage in LLMs, but it does not involve any aspect of LLM training data processing such as data collection or dataset generation."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08608",
      "abstract": "We present a numerical analysis of a higher order unfitted space-time Finite Element method applied to a convection-diffusion model problem posed on a moving bulk domain. The method uses isoparametric space-time mappings for the geometry approximation of level set domains and has been presented and investigated computationally in [Heimann, Lehrenfeld, Preu{\\ss}, SIAM J. Sci. Comp. 45(2), 2023, B139 - B165]. Recently, in [Heimann, Lehrenfeld, IMA J. Numer. Anal., 2025] error bounds for the geometry approximation have been proven. In this paper we prove stability and accuracy including the influence of the geometry approximation.",
      "authors": [
        "Fabian Heimann",
        "Christoph Lehrenfeld",
        "Janosch Preu{\\ss}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2504.08608v1",
          "size": "15840kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:02:33+00:00",
          "link": "https://arxiv.org/abs/2504.08608v2",
          "size": "237kb",
          "version": "v2"
        }
      ],
      "title": "Discretization Error Analysis of a High Order Unfitted Space-Time Method for moving domain problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08608",
        "PDF": "https://arxiv.org/pdf/2504.08608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a numerical analysis of a finite element method in moving domain problems, which does not relate to LLM training data processing at any stage."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06565",
      "abstract": "Large language models (LLMs) turn writing into a live exchange between humans and software. We characterize this new medium as a discursive network that treats people and LLMs as equal nodes and tracks how their statements circulate. We define the generation of erroneous information as invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. We develop a general mathematical model of discursive networks that shows that a network governed only by drift and self-repair stabilizes at a modest error rate. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source Flaws-of-Others (FOO) algorithm: a configurable loop in which any set of agents critique one another while a harmonizer merges their verdicts. We identify an ethical transgression, epithesis, that occurs when humans fail to engage in the discursive network. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from connecting imperfect ones into networks that enforce mutual accountability.",
      "authors": [
        "Juan B. Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.06565v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:34:51+00:00",
          "link": "https://arxiv.org/abs/2507.06565v2",
          "size": "742kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:19:46+00:00",
          "link": "https://arxiv.org/abs/2507.06565v3",
          "size": "849kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T14:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.06565v4",
          "size": "857kb",
          "version": "v4"
        }
      ],
      "title": "A Mathematical Theory of Discursive Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06565",
        "HTML": "https://arxiv.org/html/2507.06565",
        "PDF": "https://arxiv.org/pdf/2507.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the mathematical modeling of discursive networks involving humans and LLMs. It primarily discusses network dynamics and reliability rather than specific data processing for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14303",
      "abstract": "In recent years, the concept of artificial intelligence (AI) has become a prominent keyword because it is promising in solving complex tasks. The need for human expertise in specific areas may no longer be needed because machines have achieved successful results using artificial intelligence and can make the right decisions in critical situations. This process is possible with the help of deep learning (DL), one of the most popular artificial intelligence technologies. One of the areas in which the use of DL is used is in the development of self-driving cars, which is very effective and important. In this work, we propose several efficient models to investigate scene understanding through semantic segmentation. We use the BDD100k dataset to investigate these models. Another contribution of this work is the usage of several Backbones as encoders for models. The obtained results show that choosing the appropriate backbone has a great effect on the performance of the model for semantic segmentation. Better performance in semantic segmentation allows us to understand better the scene and the environment around the agent. In the end, we analyze and evaluate the proposed models in terms of accuracy, mean IoU, and loss function, and the results show that these metrics are improved.",
      "authors": [
        "Ehsan Rassekh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.14303v1",
          "size": "11956kb",
          "version": "v1"
        }
      ],
      "title": "Semantic Segmentation based Scene Understanding in Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14303",
        "PDF": "https://arxiv.org/pdf/2507.14303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses semantic segmentation in autonomous vehicles using deep learning, without any mention of LLM training data processing techniques or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14593",
      "abstract": "This paper presents the Coordinate Heart System (CHS), a geometric framework for emotion representation in artificial intelligence applications. We position eight core emotions as coordinates on a unit circle, enabling mathematical computation of complex emotional states through coordinate mixing and vector operations. Our initial five-emotion model revealed significant coverage gaps in the emotion space, leading to the development of an eight-emotion system that provides complete geometric coverage with mathematical guarantees. The framework converts natural language input to emotion coordinates and supports real-time emotion interpolation through computational algorithms. The system introduces a re-calibrated stability parameter S in [0,1], which dynamically integrates emotional load, conflict resolution, and contextual drain factors. This stability model leverages advanced Large Language Model interpretation of textual cues and incorporates hybrid temporal tracking mechanisms to provide nuanced assessment of psychological well-being states. Our key contributions include: (i) mathematical proof demonstrating why five emotions are insufficient for complete geometric coverage, (ii) an eight-coordinate system that eliminates representational blind spots, (iii) novel algorithms for emotion mixing, conflict resolution, and distance calculation in emotion space, and (iv) a comprehensive computational framework for AI emotion recognition with enhanced multi-dimensional stability modeling. Experimental validation through case studies demonstrates the system's capability to handle emotionally conflicted states, contextual distress factors, and complex psychological scenarios that traditional categorical emotion models cannot adequately represent. This work establishes a new mathematical foundation for emotion modeling in artificial intelligence systems.",
      "authors": [
        "Omar Al-Desi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:38:30+00:00",
          "link": "https://arxiv.org/abs/2507.14593v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14593",
        "HTML": "https://arxiv.org/html/2507.14593",
        "PDF": "https://arxiv.org/pdf/2507.14593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a geometric framework for emotion representation, focusing on AI emotion modeling rather than LLM training data processing. It doesn't involve any discussion around data operations relevant to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14908",
      "abstract": "This research introduces the Theory of Partial Symmetry Enforced Attention Decomposition (PSEAD), a new and rigorous group-theoretic framework designed to seamlessly integrate local symmetry awareness into the core architecture of self-attention mechanisms within Transformer models. We formalize the concept of local permutation subgroup actions on windows of biological data, proving that under such actions, the attention mechanism naturally decomposes into a direct sum of orthogonal irreducible components. Critically, these components are intrinsically aligned with the irreducible representations of the acting permutation subgroup, thereby providing a powerful mathematical basis for disentangling symmetric and asymmetric features. We show that PSEAD offers substantial advantages. These include enhanced generalization capabilities to novel biological motifs exhibiting similar partial symmetries, unprecedented interpretability by allowing direct visualization and analysis of attention contributions from different symmetry channels, and significant computational efficiency gains by focusing representational capacity on relevant symmetric subspaces. Beyond static data analysis, we extend PSEAD's applicability to dynamic biological processes within reinforcement learning paradigms, showcasing its potential to accelerate the discovery and optimization of biologically meaningful policies in complex environments like protein folding and drug discovery. This work lays the groundwork for a new generation of biologically informed, symmetry-aware artificial intelligence models.",
      "authors": [
        "Daniel Ayomide Olanrewaju"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Representation Theory (math.RT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:44:31+00:00",
          "link": "https://arxiv.org/abs/2507.14908v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14908",
        "HTML": "https://arxiv.org/html/2507.14908",
        "PDF": "https://arxiv.org/pdf/2507.14908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new framework for Transformers in biological systems by integrating symmetry into self-attention mechanisms. It does not pertain to data processing for LLM pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15205",
      "abstract": "Emotion Recognition in Conversation (ERC) is a practical and challenging task. This paper proposes a novel multimodal approach, the Long-Short Distance Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it constructs a long-distance graph neural network and a short-distance graph neural network to obtain multimodal features of distant and nearby utterances, respectively. To ensure that long- and short-distance features are as distinct as possible in representation while enabling mutual influence between the two modules, we employ a Differential Regularizer and incorporate a BiAffine Module to facilitate feature interaction. In addition, we propose an Improved Curriculum Learning (ICL) to address the challenge of data imbalance. By computing the similarity between different emotions to emphasize the shifts in similar emotions, we design a \"weighted emotional shift\" metric and develop a difficulty measurer, enabling a training process that prioritizes learning easy samples before harder ones. Experimental results on the IEMOCAP and MELD datasets demonstrate that our model outperforms existing benchmarks.",
      "authors": [
        "Xinran Li",
        "Xiujuan Xu",
        "Jiaqi Qiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:12:54+00:00",
          "link": "https://arxiv.org/abs/2507.15205v1",
          "size": "2965kb",
          "version": "v1"
        }
      ],
      "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15205",
        "PDF": "https://arxiv.org/pdf/2507.15205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel approach for Emotion Recognition in Conversation using graph neural networks and curriculum learning. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15246",
      "abstract": "Accurate demand forecasting is critical for enhancing the efficiency and responsiveness of food delivery platforms, where spatial heterogeneity and temporal fluctuations in order volumes directly influence operational decisions. This paper proposes an attention-based Graph Neural Network framework that captures spatial-temporal dependencies by modeling the food delivery environment as a graph. In this graph, nodes represent urban delivery zones, while edges reflect spatial proximity and inter-regional order flow patterns derived from historical data. The attention mechanism dynamically weighs the influence of neighboring zones, enabling the model to focus on the most contextually relevant areas during prediction. Temporal trends are jointly learned alongside spatial interactions, allowing the model to adapt to evolving demand patterns. Extensive experiments on real-world food delivery datasets demonstrate the superiority of the proposed model in forecasting future order volumes with high accuracy. The framework offers a scalable and adaptive solution to support proactive fleet positioning, resource allocation, and dispatch optimization in urban food delivery operations.",
      "authors": [
        "Rabia Latief Bhat and Iqra Altaf Gillani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:10:32+00:00",
          "link": "https://arxiv.org/abs/2507.15246v1",
          "size": "1111kb",
          "version": "v1"
        }
      ],
      "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15246",
        "HTML": "https://arxiv.org/html/2507.15246",
        "PDF": "https://arxiv.org/pdf/2507.15246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a prediction model for food delivery demand using graph neural networks, which does not address LLM training data processing or related dataset engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.12510",
      "abstract": "Diffusion models (DMs) excel in unconditional generation, as well as on applications such as image editing and restoration. The success of DMs lies in the iterative nature of diffusion: diffusion breaks down the complex process of mapping noise to data into a sequence of simple denoising tasks. Moreover, we are able to exert fine-grained control over the generation process by injecting guidance terms into each denoising step. However, the iterative process is also computationally intensive, often taking from tens up to thousands of function evaluations. Although consistency trajectory models (CTMs) enable traversal between any time points along the probability flow ODE (PFODE) and score inference with a single function evaluation, CTMs only allow translation from Gaussian noise to data. This work aims to unlock the full potential of CTMs by proposing generalized CTMs (GCTMs), which translate between arbitrary distributions via ODEs. We discuss the design space of GCTMs and demonstrate their efficacy in various image manipulation tasks such as image-to-image translation, restoration, and editing.",
      "authors": [
        "Beomsu Kim and Jaemin Kim and Jeongsol Kim and Jong Chul Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T07:24:54+00:00",
          "link": "https://arxiv.org/abs/2403.12510v1",
          "size": "39865kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T10:31:58+00:00",
          "link": "https://arxiv.org/abs/2403.12510v2",
          "size": "14997kb",
          "version": "v2"
        },
        {
          "date": "2024-10-10T04:04:44+00:00",
          "link": "https://arxiv.org/abs/2403.12510v3",
          "size": "14998kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T12:53:26+00:00",
          "link": "https://arxiv.org/abs/2403.12510v4",
          "size": "11064kb",
          "version": "v4"
        }
      ],
      "title": "Generalized Consistency Trajectory Models for Image Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.12510",
        "HTML": "https://arxiv.org/html/2403.12510",
        "PDF": "https://arxiv.org/pdf/2403.12510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on generalized consistency trajectory models for image manipulation tasks, lacking any discussion on LLM training data processing or related dataset operations."
      },
      "tasks": [
        "Denoising",
        "Image Manipulation",
        "Image-to-Image Translation",
        "Translation"
      ],
      "repo_urls": [
        "https://github.com/1202kbs/gctm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.00430",
      "abstract": "Deformable image registration (DIR) is a crucial tool in radiotherapy for analyzing anatomical changes and motion patterns. Current DIR implementations rely on discrete volumetric motion representation, which often leads to compromised accuracy and uncertainty when handling significant anatomical changes and sliding boundaries. This limitation affects the reliability of subsequent contour propagation and dose accumulation procedures, particularly in regions with complex anatomical interfaces such as the lung-chest wall boundary. Given that organ motion is inherently a continuous process in both space and time, we aimed to develop a model that preserves these fundamental properties. Drawing inspiration from fluid mechanics, we propose a novel approach using implicit neural representation (INR) for continuous modeling of patient anatomical motion. This approach ensures spatial and temporal continuity while effectively unifying Eulerian and Lagrangian specifications to enable natural continuous motion modeling and frame interpolation. The integration of these specifications provides a more comprehensive understanding of anatomical deformation patterns. By leveraging the continuous representations, the CPT-DIR method significantly enhances registration and interpolation accuracy, automation, and speed. The method demonstrates superior performance in landmark and contour precision, particularly in challenging anatomical regions, representing a substantial advancement over conventional approaches in deformable image registration. The improved efficiency and accuracy of CPT-DIR make it particularly suitable for real-time adaptive radiotherapy applications.",
      "authors": [
        "Xia Li",
        "Runzhao Yang",
        "Muheng Li",
        "Xiangtai Li",
        "Antony J. Lomax",
        "Joachim M. Buhmann",
        "Ye Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-01T10:26:08+00:00",
          "link": "https://arxiv.org/abs/2405.00430v1",
          "size": "1074kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:18:53+00:00",
          "link": "https://arxiv.org/abs/2405.00430v2",
          "size": "12948kb",
          "version": "v2"
        }
      ],
      "title": "Continuous sPatial-Temporal Deformable Image Registration (CPT-DIR) for motion modelling in radiotherapy: beyond classic voxel-based methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.00430",
        "HTML": "https://arxiv.org/html/2405.00430",
        "PDF": "https://arxiv.org/pdf/2405.00430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deformable image registration in radiotherapy, employing neural networks for motion modeling but does not address LLM training data processing."
      },
      "tasks": [
        "Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20016",
      "abstract": "Vertical text input is commonly encountered in various real-world applications, such as mathematical computations and word-based Sudoku puzzles. While current large language models (LLMs) have excelled in natural language tasks, they remain vulnerable to variations in text formatting. Recent research demonstrates that modifying input formats, such as vertically aligning words for encoder-based models, can substantially lower accuracy in text classification tasks. While easily understood by humans, these inputs can significantly mislead models, posing a potential risk of bypassing detection in real-world scenarios involving harmful or sensitive information. With the expanding application of LLMs, a crucial question arises: \\textit{Do decoder-based LLMs exhibit similar vulnerabilities to vertically formatted text input?} In this paper, we investigate the impact of vertical text input on the performance of various LLMs across multiple text classification datasets and analyze the underlying causes. Our findings are as follows: (i) Vertical text input significantly degrades the accuracy of LLMs in text classification tasks. (ii) \\textit{Chain of Thought (CoT)} reasoning does not help LLMs recognize vertical input or mitigate its vulnerability, but \\textit{few-shot learning} with careful analysis does. (iii) We explore the underlying cause of the vulnerability by analyzing the inherent issues in tokenization and attention matrices.",
      "authors": [
        "Zhecheng Li",
        "Yiwei Wang",
        "Bryan Hooi",
        "Yujun Cai",
        "Zhen Xiong",
        "Nanyun Peng",
        "Kai-wei Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T00:16:08+00:00",
          "link": "https://arxiv.org/abs/2410.20016v1",
          "size": "423kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T05:09:53+00:00",
          "link": "https://arxiv.org/abs/2410.20016v2",
          "size": "446kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T02:44:30+00:00",
          "link": "https://arxiv.org/abs/2410.20016v3",
          "size": "447kb",
          "version": "v3"
        }
      ],
      "title": "Vulnerability of LLMs to Vertically Aligned Text Manipulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20016",
        "HTML": "https://arxiv.org/html/2410.20016",
        "PDF": "https://arxiv.org/pdf/2410.20016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the effect of vertically aligned text on the performance of LLMs, focusing on vulnerabilities in text formatting, but it does not contribute to LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Few-Shot Learning",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.17125",
      "abstract": "With recent advances in Multimodal Large Language Models (MLLMs), grounding and referring capabilities have gained increasing attention for achieving detailed understanding and flexible user interaction. However, these capabilities still remain underdeveloped in visual document understanding due to the scarcity of fine-grained datasets and comprehensive benchmarks. To fill this gap, we propose the DOcument Grounding and Referring data engine (DOGR-Engine), which generates two types of high-quality fine-grained document data: (1) multi-granular parsing data to improve text localization and recognition, and (2) instruction-tuning data to activate MLLMs' grounding and referring capabilities in dialogue and reasoning. Using the DOGR-Engine, we construct DOGR-Bench, a benchmark covering seven grounding and referring tasks across three document types (chart, poster, and PDF document), offering a comprehensive evaluation of fine-grained document understanding. Leveraging the generated data, we further develop DOGR, a strong baseline model that excels in text localization and recognition, while precisely grounds and refers to key textual information during conversation and reasoning, thereby advancing document understanding to a finer granularity and enable flexible interaction paradigms.",
      "authors": [
        "Yinan Zhou",
        "Yuxin Chen",
        "Haokun Lin",
        "Shuyu Yang",
        "Zhongang Qi",
        "Chen Ma",
        "Li Zhu",
        "and Ying Shan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T05:38:34+00:00",
          "link": "https://arxiv.org/abs/2411.17125v1",
          "size": "37330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:43:33+00:00",
          "link": "https://arxiv.org/abs/2411.17125v2",
          "size": "38853kb",
          "version": "v2"
        }
      ],
      "title": "DOGR: Towards Versatile Visual Document Grounding and Referring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17125",
        "HTML": "https://arxiv.org/html/2411.17125",
        "PDF": "https://arxiv.org/pdf/2411.17125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the DOGR-Engine, aimed at generating fine-grained document data and benchmarks for grounding and referring tasks, contributing directly to the creation and improvement of datasets which can be used for training MLLMs."
      },
      "tasks": [
        "document understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23179",
      "abstract": "In modern cancer research, the vast volume of medical data generated is often underutilised due to challenges related to patient privacy. The OncoReg Challenge addresses this issue by enabling researchers to develop and validate image registration methods through a two-phase framework that ensures patient privacy while fostering the development of more generalisable AI models. Phase one involves working with a publicly available dataset, while phase two focuses on training models on a private dataset within secure hospital networks. OncoReg builds upon the foundation established by the Learn2Reg Challenge by incorporating the registration of interventional cone-beam computed tomography (CBCT) with standard planning fan-beam CT (FBCT) images in radiotherapy. Accurate image registration is crucial in oncology, particularly for dynamic treatment adjustments in image-guided radiotherapy, where precise alignment is necessary to minimise radiation exposure to healthy tissues while effectively targeting tumours. This work details the methodology and data behind the OncoReg Challenge and provides a comprehensive analysis of the competition entries and results. Findings reveal that feature extraction plays a pivotal role in this registration task. A new method emerging from this challenge demonstrated its versatility, while established approaches continue to perform comparably to newer techniques. Both deep learning and classical approaches still play significant roles in image registration, with the combination of methods, particularly in feature extraction, proving most effective.",
      "authors": [
        "Wiebke Heyer",
        "Yannic Elser",
        "Lennart Berkel",
        "Xinrui Song",
        "Xuanang Xu",
        "Pingkun Yan",
        "Xi Jia",
        "Jinming Duan",
        "Zi Li",
        "Tony C. W. Mok",
        "BoWen LI",
        "Tim Hable",
        "Christian Staackmann",
        "Christoph Gro{\\ss}br\\\"ohmer",
        "Lasse Hansen",
        "Alessa Hering",
        "Malte M. Sieren",
        "Mattias P. Heinrich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T18:16:10+00:00",
          "link": "https://arxiv.org/abs/2503.23179v1",
          "size": "2794kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T08:44:33+00:00",
          "link": "https://arxiv.org/abs/2503.23179v2",
          "size": "2794kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T20:14:28+00:00",
          "link": "https://arxiv.org/abs/2503.23179v3",
          "size": "5210kb",
          "version": "v3"
        }
      ],
      "title": "OncoReg: Medical Image Registration for Oncological Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23179",
        "HTML": "https://arxiv.org/html/2503.23179",
        "PDF": "https://arxiv.org/pdf/2503.23179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on medical image registration for oncological applications, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Image Registration",
        "Medical Image Registration"
      ],
      "repo_urls": [
        "https://github.com/xi-jia/fourier-net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09039",
      "abstract": "Mobile app reviews are a large-scale data source for software improvements. A key task in this context is effectively extracting requirements from app reviews to analyze the users' needs and support the software's evolution. Recent studies show that existing methods fail at this task since app reviews usually contain informal language, grammatical and spelling errors, and a large amount of irrelevant information that might not have direct practical value for developers. To address this, we propose a novel reformulation of requirements extraction as a Named Entity Recognition (NER) task based on the sequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a Seq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced with a self-attention mechanism, GloVe embeddings, and a CRF model. We evaluated our framework on two datasets: a manually annotated set of 1,000 reviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The quantitative evaluation of our framework showed that it outperformed existing state-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved comparable performance on Dataset 1 with an F1 score of 0.47.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:35:14+00:00",
          "link": "https://arxiv.org/abs/2507.09039v1",
          "size": "892kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:43:55+00:00",
          "link": "https://arxiv.org/abs/2507.09039v2",
          "size": "892kb",
          "version": "v2"
        }
      ],
      "title": "Towards Extracting Software Requirements from App Reviews using Seq2seq Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09039",
        "HTML": "https://arxiv.org/html/2507.09039",
        "PDF": "https://arxiv.org/pdf/2507.09039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on extracting software requirements from app reviews using a Seq2seq framework. It does not pertain to LLM training data processing, pretraining, or fine-tuning operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14212",
      "abstract": "Goal-oriented Communication (GoC) is a new paradigm that plans data transmission to occur only when it is instrumental for the receiver to achieve a certain goal. This leads to the advantage of reducing the frequency of transmissions significantly while maintaining adherence to the receiver's objectives. However, GoC scheduling also opens a timing-based side channel that an eavesdropper can exploit to obtain information about the state of the system. This type of attack sidesteps even information-theoretic security, as it exploits the timing of updates rather than their content. In this work, we study such an eavesdropping attack against pull-based goal-oriented scheduling for remote monitoring and control of Markov processes. We provide a theoretical framework for defining the effectiveness of the attack and propose possible countermeasures, including two practical heuristics that provide a balance between the performance gains offered by GoC and the amount of leaked information. Our results show that, while a naive goal-oriented scheduler allows the eavesdropper to correctly guess the system state about 60% of the time, our heuristic defenses can halve the leakage with a marginal reduction of the benefits of goal-oriented approaches.",
      "authors": [
        "Federico Mason",
        "Federico Chiariotti",
        "Pietro Talli",
        "and Andrea Zanella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:36:48+00:00",
          "link": "https://arxiv.org/abs/2507.14212v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Secure Goal-Oriented Communication: Defending against Eavesdropping Timing Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14212",
        "PDF": "https://arxiv.org/pdf/2507.14212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses secure goal-oriented communication against timing attacks, a topic related to network security and eavesdropping, not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14446",
      "abstract": "In this work, we study how to efficiently apply reinforcement learning (RL) for solving large-scale stochastic optimization problems by leveraging intervention models. The key of the proposed methodology is to better explore the solution space by simulating and composing the stochastic processes using pre-trained deep learning (DL) models. We demonstrate our approach on a challenging real-world application, the multi-sourcing multi-period inventory management problem in supply chain optimization. In particular, we employ deep RL models for learning and forecasting the stochastic supply chain processes under a range of assumptions. Moreover, we also introduce a constraint coordination mechanism, designed to forecast dual costs given the cross-products constraints in the inventory network. We highlight that instead of directly modeling the complex physical constraints into the RL optimization problem and solving the stochastic problem as a whole, our approach breaks down those supply chain processes into scalable and composable DL modules, leading to improved performance on large real-world datasets. We also outline open problems for future research to further investigate the efficacy of such models.",
      "authors": [
        "Feng Liu",
        "Ying Liu",
        "Carson Eisenach"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:44:45+00:00",
          "link": "https://arxiv.org/abs/2507.14446v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14446",
        "HTML": "https://arxiv.org/html/2507.14446",
        "PDF": "https://arxiv.org/pdf/2507.14446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying reinforcement learning for inventory management and supply chain optimization, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14537",
      "abstract": "Understanding how the human brain encodes and processes external visual stimuli has been a fundamental challenge in neuroscience. With advancements in artificial intelligence, sophisticated visual decoding architectures have achieved remarkable success in fMRI research, enabling more precise and fine-grained spatial concept localization. This has provided new tools for exploring the spatial representation of concepts in the brain. However, despite the millisecond-scale temporal resolution of EEG, which offers unparalleled advantages in tracking the dynamic evolution of cognitive processes, the temporal dynamics of neural representations based on EEG remain underexplored. This is primarily due to EEG's inherently low signal-to-noise ratio and its complex spatiotemporal coupling characteristics. To bridge this research gap, we propose a novel approach that integrates advanced neural decoding algorithms to systematically investigate how low-dimensional object properties are temporally encoded in EEG signals. We are the first to attempt to identify the specificity and prototypical temporal characteristics of concepts within temporal distributions. Our framework not only enhances the interpretability of neural representations but also provides new insights into visual decoding in brain-computer interfaces (BCI).",
      "authors": [
        "Jiahua Tang",
        "Song Wang",
        "Jiachen Zou",
        "Chen Wei",
        "Quanying Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.14537v1",
          "size": "1999kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering the EEG Temporal Representation of Low-dimensional Object Properties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14537",
        "HTML": "https://arxiv.org/html/2507.14537",
        "PDF": "https://arxiv.org/pdf/2507.14537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research delves into EEG temporal representation of visual stimuli, which does not pertain to the domain of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14825",
      "abstract": "In image compression, with recent advances in generative modeling, existence of a trade-off between the rate and perceptual quality has been brought to light, where the perceptual quality is measured by the closeness of the output and source distributions. We consider the compression of a memoryless source sequence $X^n=(X_1, \\ldots, X_n)$ in the presence of memoryless side information $Z^n=(Z_1, \\ldots, Z_n),$ originally studied by Wyner and Ziv, but elucidate the impact of a strong perfect realism constraint, which requires the joint distribution of output symbols $Y^n=(Y_1,...,Y_n)$ to match the distribution of the source sequence. We consider two cases: when $Z^n$ is available only at the decoder, or at both the encoder and decoder, and characterize the information theoretic limits under various scenarios. Previous works show the superiority of randomized codes under strong perceptual quality constraints. When $Z^n$ is available at both terminals, we characterize its dual role, as a source of common randomness, and as a second look on the source for the receiver. We also study different notions of strong perfect realism which we call marginal realism, joint realism and near-perfect realism. We derive explicit solutions when $X$ and $Z$ are jointly Gaussian under the squared error distortion measure. In traditional lossy compression, having $Z$ only at the decoder imposes no rate penalty in the Gaussian scenario. We show that, when strong perfect realism constraints are imposed this holds only when sufficient common randomness is available.",
      "authors": [
        "Yassine Hamdi and Aaron B. Wagner and Deniz G\\\"und\\\"uz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T05:08:55+00:00",
          "link": "https://arxiv.org/abs/2507.14825v1",
          "size": "167kb",
          "version": "v1"
        }
      ],
      "title": "Rate-Distortion-Perception Trade-off with Strong Realism Constraints: Role of Side Information and Common Randomness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14825",
        "PDF": "https://arxiv.org/pdf/2507.14825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses image compression with a focus on trade-offs involving rate and perceptual quality. It does not involve any contributions to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15026",
      "abstract": "Condition and structural health monitoring (CM/SHM) is a pivotal component of predictive maintenance (PdM) strategies across diverse industrial sectors, including mechanical rotating machinery, airplane composite wings, offshore wind turbines, and civil engineering structures. Conventional deep learning models, while effective in fault diagnosis and anomaly detection through supervised feature extraction and rule-based data augmentation, often struggle with operational variability, imbalanced or scarce fault datasets, and multimodal sensory data from complex systems. Deep generative models (DGMs) in this regard, including autoregressive models, variational autoencoders, generative adversarial networks, diffusion-based models, and emerging large language models, offer transformative capabilities by synthesizing high-fidelity data samples, reconstructing latent system states, and modeling complex multimodal data streams. This review systematically examines state-of-the-art DGM applications in CM/SHM systems, emphasizing their role in addressing key challenges: data imbalance and imputation, domain adaptation and generalization, multimodal data fusion, and downstream fault diagnosis and anomaly detection tasks, with rigorous comparison among signal processing, conventional machine learning or deep learning models, and DGMs. We also analyze current limitations of DGMs, including challenges of explainable and trustworthy models, computational inefficiencies for edge deployment, and the need for parameter-efficient fine-tuning strategies. Future research directions can focus on zero-shot and few-shot learning, robust multimodal generalization, hybrid architectures integrating DGMs with physics knowledge, and reinforcement learning with DGMs to enhance robustness and accuracy in industrial scenarios.",
      "authors": [
        "Xin Yang",
        "Chen Fang",
        "Yunlai Liao",
        "Jian Yang",
        "Konstantinos Gryllias",
        "Dimitrios Chronopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:28:12+00:00",
          "link": "https://arxiv.org/abs/2507.15026v1",
          "size": "5735kb",
          "version": "v1"
        }
      ],
      "title": "Deep Generative Models in Condition and Structural Health Monitoring: Opportunities, Limitations and Future Outlook",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15026",
        "PDF": "https://arxiv.org/pdf/2507.15026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the application of deep generative models in condition and structural health monitoring, not focusing on LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15067",
      "abstract": "Detecting bad actors is critical to ensure the safety and integrity of internet platforms. Several deep learning-based models have been developed to identify such users. These models should not only accurately detect bad actors, but also be robust against adversarial attacks that aim to evade detection. However, past deep learning-based detection models do not meet the robustness requirement because they are sensitive to even minor changes in the input sequence. To address this issue, we focus on (1) improving the model understanding capability and (2) enhancing the model knowledge such that the model can recognize potential input modifications when making predictions. To achieve these goals, we create a novel transformer-based classification model, called ROBAD (RObust adversary-aware local-global attended Bad Actor Detection model), which uses the sequence of user posts to generate user embedding to detect bad actors. Particularly, ROBAD first leverages the transformer encoder block to encode each post bidirectionally, thus building a post embedding to capture the local information at the post level. Next, it adopts the transformer decoder block to model the sequential pattern in the post embeddings by using the attention mechanism, which generates the sequence embedding to obtain the global information at the sequence level. Finally, to enrich the knowledge of the model, embeddings of modified sequences by mimicked attackers are fed into a contrastive-learning-enhanced classification layer for sequence prediction. In essence, by capturing the local and global information (i.e., the post and sequence information) and leveraging the mimicked behaviors of bad actors in training, ROBAD can be robust to adversarial attacks. Extensive experiments on Yelp and Wikipedia datasets show that ROBAD can effectively detect bad actors when under state-of-the-art adversarial attacks.",
      "authors": [
        "Bing He",
        "Mustaque Ahamad",
        "Srijan Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:03:44+00:00",
          "link": "https://arxiv.org/abs/2507.15067v1",
          "size": "612kb",
          "version": "v1"
        }
      ],
      "title": "ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15067",
        "HTML": "https://arxiv.org/html/2507.15067",
        "PDF": "https://arxiv.org/pdf/2507.15067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on building a transformer-based model for detecting bad actors and enhancing robustness against adversarial attacks. It does not address LLM training data processing and is unrelated to data operations or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15266",
      "abstract": "Scene understanding and risk-aware attentions are crucial for human drivers to make safe and effective driving decisions. To imitate this cognitive ability in urban autonomous driving while ensuring the transparency and interpretability, we propose a vision-language model (VLM)-enhanced unified decision-making and motion control framework, named VLM-UDMC. This framework incorporates scene reasoning and risk-aware insights into an upper-level slow system, which dynamically reconfigures the optimal motion planning for the downstream fast system. The reconfiguration is based on real-time environmental changes, which are encoded through context-aware potential functions. More specifically, the upper-level slow system employs a two-step reasoning policy with Retrieval-Augmented Generation (RAG), leveraging foundation models to process multimodal inputs and retrieve contextual knowledge, thereby generating risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM provides real-time trajectory predictions for heterogeneous traffic participants by extracting smoother trend representations for short-horizon trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is verified via both simulations and real-world experiments with a full-size autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively leverages scene understanding and attention decomposition for rational driving decisions, thus improving the overall urban driving performance. Our open-source project is available at https://github.com/henryhcliu/vlmudmc.git.",
      "authors": [
        "Haichao Liu",
        "Haoren Guo",
        "Pei Liu",
        "Benshan Ma",
        "Yuxiang Zhang",
        "Jun Ma",
        "Tong Heng Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:06:27+00:00",
          "link": "https://arxiv.org/abs/2507.15266v1",
          "size": "15771kb",
          "version": "v1"
        }
      ],
      "title": "VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15266",
        "HTML": "https://arxiv.org/html/2507.15266",
        "PDF": "https://arxiv.org/pdf/2507.15266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a decision-making and motion control framework for urban autonomous driving using vision-language models. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.05039",
      "abstract": "We introduce StaccaToe, a human-scale, electric motor-powered single-leg robot designed to rival the agility of human locomotion through two distinctive attributes: an actuated toe and a co-actuation configuration inspired by the human leg. Leveraging the foundational design of HyperLeg's lower leg mechanism, we develop a stand-alone robot by incorporating new link designs, custom-designed power electronics, and a refined control system. Unlike previous jumping robots that rely on either special mechanisms (e.g., springs and clutches) or hydraulic/pneumatic actuators, StaccaToe employs electric motors without energy storage mechanisms. This choice underscores our ultimate goal of developing a practical, high-performance humanoid robot capable of human-like, stable walking as well as explosive dynamic movements. In this paper, we aim to empirically evaluate the balance capability and the exertion of explosive ground reaction forces of our toe and co-actuation mechanisms. Throughout extensive hardware and controller development, StaccaToe showcases its control fidelity by demonstrating a balanced tip-toe stance and dynamic jump. This study is significant for three key reasons: 1) StaccaToe represents the first human-scale, electric motor-driven single-leg robot to execute dynamic maneuvers without relying on specialized mechanisms; 2) our research provides empirical evidence of the benefits of replicating critical human leg attributes in robotic design; and 3) we explain the design process for creating agile legged robots, the details that have been scantily covered in academic literature.",
      "authors": [
        "Nisal Perera",
        "Shangqun Yu",
        "Daniel Marew",
        "Mack Tang",
        "Ken Suzuki",
        "Aidan McCormack",
        "Shifan Zhu",
        "Yong-Jae Kim and Donghyun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-07T18:47:52+00:00",
          "link": "https://arxiv.org/abs/2404.05039v1",
          "size": "17113kb",
          "version": "v1"
        }
      ],
      "title": "StaccaToe: A Single-Leg Robot that Mimics the Human Leg and Toe",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.05039",
        "HTML": "https://arxiv.org/html/2404.05039",
        "PDF": "https://arxiv.org/pdf/2404.05039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the design and control of a single-leg robot, and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.07057",
      "abstract": "Tokenization is a fundamental preprocessing step in NLP, directly impacting large language models' (LLMs) ability to capture syntactic, morphosyntactic, and semantic structures. This paper introduces a novel framework for systematically evaluating tokenization strategies, addressing challenges in morphologically rich and low-resource languages. Using a Turkish dataset of 6,200 multiple-choice questions from the Massive Multitask Language Understanding (MMLU) benchmark, the framework assesses tokenizers across five key metrics: vocabulary size, token count, processing time, language-specific token percentages (\\%TR), and token purity. These metrics provide a structured approach to evaluating how well tokenizers preserve linguistic structures. While \\%TR measures the proportion of valid words in the target language, \\%Pure assesses the alignment of tokens with meaningful linguistic units, such as roots and valid morphemes, minimizing semantic fragmentation. The findings reveal that \\%TR, introduced as a critical metric, exhibits a stronger correlation with downstream performance (e.g., MMLU scores) than token purity, emphasizing its role in improving model accuracy. Additionally, larger model parameters do not necessarily yield better tokenization quality or enhanced results, highlighting the importance of tailored tokenization strategies that prioritize linguistic alignment. This framework sets a new standard for developing robust tokenization methods optimized for morphologically complex and low-resource languages. Future work will refine morphological analysis, explore domain-specific customizations, and conduct cross-linguistic evaluations to further enhance tokenization practices.",
      "authors": [
        "M. Ali Bayram",
        "Ali Arda Fincan",
        "Ahmet Semih G\\\"um\\\"u\\c{s}",
        "Sercan Karaka\\c{s}",
        "Banu Diri",
        "Sava\\c{s} Y{\\i}ld{\\i}r{\\i}m"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T21:47:49+00:00",
          "link": "https://arxiv.org/abs/2502.07057v1",
          "size": "499kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:05:14+00:00",
          "link": "https://arxiv.org/abs/2502.07057v2",
          "size": "202kb",
          "version": "v2"
        }
      ],
      "title": "Tokenization Standards for Linguistic Integrity: Turkish as a Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07057",
        "HTML": "https://arxiv.org/html/2502.07057",
        "PDF": "https://arxiv.org/pdf/2502.07057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a novel tokenization framework, which is a preprocessing step relevant for LLMs, its main contribution lies in linguistic alignment and tokenization standards rather than direct training data processing operations."
      },
      "tasks": [
        "MMLU",
        "Morphological Analysis",
        "Multiple-choice",
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23200",
      "abstract": "Precise detection of rooftops from historical aerial imagery is essential for analyzing long-term urban development and human settlement patterns. Nonetheless, black-and-white analog photographs present considerable challenges for modern object detection frameworks due to their limited spatial resolution, absence of color information, and archival degradation. To address these challenges, this research introduces a two-stage image enhancement pipeline based on Generative Adversarial Networks (GANs): image colorization utilizing DeOldify, followed by super-resolution enhancement with Real-ESRGAN. The enhanced images were subsequently employed to train and evaluate rooftop detection models, including Faster R-CNN, DETReg, and YOLOv11n. The results demonstrate that the combination of colorization with super-resolution significantly enhances detection performance, with YOLOv11n achieving a mean Average Precision (mAP) exceeding 85\\%. This signifies an enhancement of approximately 40\\% over the original black-and-white images and 20\\% over images enhanced solely through colorization. The proposed method effectively bridges the gap between archival imagery and contemporary deep learning techniques, facilitating more reliable extraction of building footprints from historical aerial photographs. Code and resources for reproducing our results are publicly available at \\href{https://github.com/Pengyu-gis/Historical-Aerial-Photos}{github.com/Pengyu-gis/Historical-Aerial-Photos}.",
      "authors": [
        "Pengyu Chen",
        "Sicheng Wang",
        "Cuizhen Wang",
        "Senrong Wang",
        "Beiao Huang",
        "Lu Huang",
        "Zhe Zang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T19:51:39+00:00",
          "link": "https://arxiv.org/abs/2503.23200v1",
          "size": "40159kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T14:53:48+00:00",
          "link": "https://arxiv.org/abs/2503.23200v2",
          "size": "25535kb",
          "version": "v2"
        }
      ],
      "title": "A GAN-Enhanced Deep Learning Framework for Rooftop Detection from Historical Aerial Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23200",
        "HTML": "https://arxiv.org/html/2503.23200",
        "PDF": "https://arxiv.org/pdf/2503.23200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses image enhancement for rooftop detection from historical imagery using GANs, which is not related to LLM training data processing."
      },
      "tasks": [
        "Colorization",
        "Image Colorization",
        "Image Enhancement",
        "object-detection",
        "Object Detection",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14509",
      "abstract": "A typical goal of research in combinatorial optimization is to come up with fast algorithms that find optimal solutions to a computational problem. The process that takes a real-world problem and extracts a clean mathematical abstraction of it often throws out a lot of \"side information\" which is deemed irrelevant. However, the discarded information could be of real significance to the end-user of the algorithm's output. All solutions of the same cost are not necessarily of equal impact in the real-world; some solutions may be much more desirable than others, even at the expense of additional increase in cost. If the impact, positive or negative, is mostly felt by some specific (minority) subgroups of the population, the population at large will be largely unaware of it. In this work we ask the question of finding solutions to combinatorial optimization problems that are \"unbiased\" with respect to a collection of specified subgroups of the total population.",
      "authors": [
        "Sheikh Shakil Akhtar",
        "Jayakrishnan Madathil",
        "Pranabendu Misra",
        "Geevarghese Philip"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:05:27+00:00",
          "link": "https://arxiv.org/abs/2507.14509v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and Feedback Vertex Set",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14509",
        "PDF": "https://arxiv.org/pdf/2507.14509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithmic solutions for combinatorial optimization problems and addressing biases, which do not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14985",
      "abstract": "The rapid growth of metaverse technologies, including virtual worlds, augmented reality, and lifelogging, has accelerated their adoption across diverse domains. This rise exposes users to significant new security and privacy challenges due to sociotechnical complexity, pervasive connectivity, and extensive user data collection in immersive environments. We present a systematic review of the literature published between 2013 and 2024, offering a comprehensive analysis of how the research community has addressed metaverse-related security and privacy issues over the past decade. We organize the studies by method, examined the security and privacy properties, immersive components, and evaluation strategies. Our investigation reveals a sharp increase in research activity in the last five years, a strong focus on practical and user-centered approaches, and a predominant use of benchmarking, human experimentation, and qualitative methods. Authentication and unobservability are the most frequently studied properties. However, critical gaps remain in areas such as policy compliance, accessibility, interoperability, and back-end infrastructure security. We emphasize the intertwined technical complexity and human factors of the metaverse and call for integrated, interdisciplinary approaches to securing inclusive and trustworthy immersive environments.",
      "authors": [
        "Argianto Rahartomo",
        "Leonel Merino",
        "Mohammad Ghafari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:42:17+00:00",
          "link": "https://arxiv.org/abs/2507.14985v1",
          "size": "2684kb",
          "version": "v1"
        }
      ],
      "title": "Metaverse Security and Privacy Research: A Systematic Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14985",
        "HTML": "https://arxiv.org/html/2507.14985",
        "PDF": "https://arxiv.org/pdf/2507.14985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a systematic review on security and privacy issues in metaverse technologies, which is not related to the training data processing for LLMs or associated operations such as data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15154",
      "abstract": "Raft is a leader-based consensus algorithm that implements State Machine Replication (SMR), which replicates the service state across multiple servers to enhance fault tolerance. In Raft, the servers play one of three roles: leader, follower, or candidate. The leader receives client requests, determines the processing order, and replicates them to the followers. When the leader fails, the service must elect a new leader to continue processing requests, during which the service experiences an out-of-service (OTS) time. The OTS time is directly influenced by election parameters, such as heartbeat interval and election timeout. However, traditional approaches, such as Raft, often struggle to effectively tune these parameters, particularly under fluctuating network conditions, leading to increased OTS time and reduced service responsiveness. To address this, we propose Dynatune, a mechanism that dynamically adjusts Raft's election parameters based on network metrics such as round-trip time and packet loss rates measured via heartbeats. By adapting to changing network environments, Dynatune significantly reduces the leader failure detection and OTS time without altering Raft's core mechanisms or introducing additional communication overheads. Experimental results demonstrate that Dynatune reduces the leader failure detection and OTS times by 80% and 45%, respectively, compared with Raft, while maintaining high availability even under dynamic network conditions. These findings confirm that Dynatune effectively enhances the performance and reliability of SMR services in various network scenarios.",
      "authors": [
        "Kohya Shiozaki",
        "Junya Nakamura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.15154v1",
          "size": "1259kb",
          "version": "v1"
        }
      ],
      "title": "Dynatune: Dynamic Tuning of Raft Election Parameters Using Network Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15154",
        "HTML": "https://arxiv.org/html/2507.15154",
        "PDF": "https://arxiv.org/pdf/2507.15154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for tuning Raft election parameters based on network conditions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15481",
      "abstract": "Virtual Reality (VR) is often described as the \"ultimate empathy machine,\" framing disability as an experience to be simulated through such technologies, which can reduce disability to a spectacle of pity or inspiration. In response, we present Waiting for Hands (WfH), an interactive eXtended Reality (XR) installation that critiques this logic by: (1) repurposing interaction norms in XR through the creation of Alternative Controllers, and (2) staging an absurd XR performance using the built controllers to disrupt sentimentalized disability narratives. The performance involves eight people: two XR participants on stage and six audience members watching a projected documentary about Hema Kumari, an Indian singer living with Rheumatoid Arthritis. The XR users partially obscure the film, drawing attention through strange mouth and hand movements performed in XR. This creates a layered experience that disrupts direct engagement with Hema's story and introduces uncertainty. While XR is often seen as a fully immersive, sensory-dominant medium, this piece subverts that framing by using XR to produce absurdity and alienation. By challenging empathy-driven and pitiable narratives of disability, we ask what ethical stance an XR performance can take to attune participants to non-normative embodiment while resisting spectacle.",
      "authors": [
        "Yesica Duarte and Puneet Jain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.15481v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Challenging Disability and Interaction Norms in XR: Cooling Down the Empathy Machine in Waiting for Hands",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15481",
        "PDF": "https://arxiv.org/pdf/2507.15481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on eXtended Reality (XR) and the exploration of disability narratives through XR performance. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15493",
      "abstract": "We report our recent progress towards building generalist robot policies, the development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model. It showcases exceptional capabilities in generalizing to novel objects, environments, and instructions involving abstract concepts. Furthermore, it can be efficiently fine-tuned with minimal human trajectory data, enabling rapid and cost-effective adaptation to new settings. GR-3 also excels in handling long-horizon and dexterous tasks, including those requiring bi-manual manipulation and mobile movement, showcasing robust and reliable performance. These capabilities are achieved through a multi-faceted training recipe that includes co-training with web-scale vision-language data, efficient fine-tuning from human trajectory data collected via VR devices, and effective imitation learning with robot trajectory data. In addition, we introduce ByteMini, a versatile bi-manual mobile robot designed with exceptional flexibility and reliability, capable of accomplishing a wide range of tasks when integrated with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the state-of-the-art baseline method, $\\pi_0$, on a wide variety of challenging tasks. We hope GR-3 can serve as a step towards building generalist robots capable of assisting humans in daily life.",
      "authors": [
        "Chilam Cheang",
        "Sijin Chen",
        "Zhongren Cui",
        "Yingdong Hu",
        "Liqun Huang",
        "Tao Kong",
        "Hang Li",
        "Yifeng Li",
        "Yuxiao Liu",
        "Xiao Ma",
        "Hao Niu",
        "Wenxuan Ou",
        "Wanli Peng",
        "Zeyu Ren",
        "Haixin Shi",
        "Jiawen Tian",
        "Hongtao Wu",
        "Xin Xiao",
        "Yuyang Xiao",
        "Jiafeng Xu",
        "Yichu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:54:13+00:00",
          "link": "https://arxiv.org/abs/2507.15493v1",
          "size": "12202kb",
          "version": "v1"
        }
      ],
      "title": "GR-3 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15493",
        "HTML": "https://arxiv.org/html/2507.15493",
        "PDF": "https://arxiv.org/pdf/2507.15493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The report discusses developments in robot policy models and a versatile robot design, focusing on vision-language-action models. It does not address any aspect of LLM training data processing or dataset generation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.13832",
      "abstract": "The scarcity of high-quality and multi-task singing datasets significantly hinders the development of diverse controllable and personalized singing tasks, as existing singing datasets suffer from low quality, limited diversity of languages and singers, absence of multi-technique information and realistic music scores, and poor task suitability. To tackle these problems, we present GTSinger, a large global, multi-technique, free-to-use, high-quality singing corpus with realistic music scores, designed for all singing tasks, along with its benchmarks. Particularly, (1) we collect 80.59 hours of high-quality singing voices, forming the largest recorded singing dataset; (2) 20 professional singers across nine widely spoken languages offer diverse timbres and styles; (3) we provide controlled comparison and phoneme-level annotations of six commonly used singing techniques, helping technique modeling and control; (4) GTSinger offers realistic music scores, assisting real-world musical composition; (5) singing voices are accompanied by manual phoneme-to-audio alignments, global style labels, and 16.16 hours of paired speech for various singing tasks. Moreover, to facilitate the use of GTSinger, we conduct four benchmark experiments: technique-controllable singing voice synthesis, technique recognition, style transfer, and speech-to-singing conversion. The demos can be found at http://aaronz345.github.io/GTSingerDemo/. We provide the dataset and the code for processing data and conducting benchmarks at https://huggingface.co/datasets/AaronZ345/GTSinger and https://github.com/AaronZ345/GTSinger.",
      "authors": [
        "Yu Zhang",
        "Changhao Pan",
        "Wenxiang Guo",
        "Ruiqi Li",
        "Zhiyuan Zhu",
        "Jialei Wang",
        "Wenhao Xu",
        "Jingyu Lu",
        "Zhiqing Hong",
        "Chuxin Wang",
        "LiChao Zhang",
        "Jinzheng He",
        "Ziyue Jiang",
        "Yuxin Chen",
        "Chen Yang",
        "Jiecheng Zhou",
        "Xinyu Cheng",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-20T18:18:14+00:00",
          "link": "https://arxiv.org/abs/2409.13832v1",
          "size": "4335kb",
          "version": "v1"
        },
        {
          "date": "2024-09-26T12:07:20+00:00",
          "link": "https://arxiv.org/abs/2409.13832v2",
          "size": "4335kb",
          "version": "v2"
        },
        {
          "date": "2024-10-16T14:56:59+00:00",
          "link": "https://arxiv.org/abs/2409.13832v3",
          "size": "4336kb",
          "version": "v3"
        },
        {
          "date": "2024-10-30T04:37:33+00:00",
          "link": "https://arxiv.org/abs/2409.13832v4",
          "size": "4336kb",
          "version": "v4"
        },
        {
          "date": "2025-02-04T11:55:53+00:00",
          "link": "https://arxiv.org/abs/2409.13832v5",
          "size": "4336kb",
          "version": "v5"
        },
        {
          "date": "2025-05-11T17:54:10+00:00",
          "link": "https://arxiv.org/abs/2409.13832v6",
          "size": "4336kb",
          "version": "v6"
        },
        {
          "date": "2025-05-30T10:24:13+00:00",
          "link": "https://arxiv.org/abs/2409.13832v7",
          "size": "4335kb",
          "version": "v7"
        },
        {
          "date": "2025-07-20T11:33:47+00:00",
          "link": "https://arxiv.org/abs/2409.13832v8",
          "size": "4335kb",
          "version": "v8"
        }
      ],
      "title": "GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13832",
        "HTML": "https://arxiv.org/html/2409.13832",
        "PDF": "https://arxiv.org/pdf/2409.13832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents GTSinger, a singing corpus for various singing tasks. It involves dataset creation but not in the context of LLM training data processing."
      },
      "models": [
        {
          "model_path": "shuoyang-zheng/jaspers-rave-models",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/shuoyang-zheng/jaspers-rave-models"
        }
      ],
      "datasets": [
        {
          "dataset_name": "AaronZ345/GTSinger",
          "downloads": "5717",
          "likes": "5",
          "link": "https://huggingface.co/datasets/AaronZ345/GTSinger"
        },
        {
          "dataset_name": "GTSinger/GTSinger",
          "downloads": "3131",
          "likes": "33",
          "link": "https://huggingface.co/datasets/GTSinger/GTSinger"
        }
      ],
      "tasks": [
        "All",
        "Singing Voice Synthesis",
        "Style Transfer",
        "Vocal technique classification"
      ],
      "repo_urls": [
        "https://github.com/aaronz345/gtsinger"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.18347",
      "abstract": "Predicting agents impacted by legal policies, physical limitations, and operational preferences is inherently difficult. In recent years, neuro-symbolic methods have emerged, integrating machine learning and symbolic reasoning models into end-to-end learnable systems. Hereby, a promising avenue for expressing high-level constraints over multi-modal input data in robotics has opened up. This work introduces an approach for Bayesian estimation of agents expected to comply with a human-interpretable neuro-symbolic model we call its Constitution. Hence, we present the Constitutional Filter (CoFi), leading to improved tracking of agents by leveraging expert knowledge, incorporating deep learning architectures, and accounting for environmental uncertainties. CoFi extends the general, recursive Bayesian estimation setting, ensuring compatibility with a vast landscape of established techniques such as Particle Filters. To underpin the advantages of CoFi, we evaluate its performance on real-world marine traffic data. Beyond improved performance, we show how CoFi can learn to trust and adapt to the level of compliance of an agent, recovering baseline performance even if the assumed Constitution clashes with reality.",
      "authors": [
        "Simon Kohaut",
        "Felix Divo",
        "Benedict Flade",
        "Devendra Singh Dhami",
        "Julian Eggert",
        "Kristian Kersting"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T11:14:55+00:00",
          "link": "https://arxiv.org/abs/2412.18347v1",
          "size": "12934kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T00:20:00+00:00",
          "link": "https://arxiv.org/abs/2412.18347v2",
          "size": "4669kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:09:59+00:00",
          "link": "https://arxiv.org/abs/2412.18347v3",
          "size": "4667kb",
          "version": "v3"
        }
      ],
      "title": "The Constitutional Filter: Bayesian Estimation of Compliant Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18347",
        "HTML": "https://arxiv.org/html/2412.18347",
        "PDF": "https://arxiv.org/pdf/2412.18347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a Bayesian estimation approach for compliant agents using neuro-symbolic models, which does not pertain to training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/HRI-EU/ProMis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14547",
      "abstract": "Architectural degradation, also known as erosion, decay, or aging, impacts system quality, maintainability, and adaptability. Although widely acknowledged, current literature shows fragmented definitions, metrics, and remediation strategies. Our study aims to unify understanding of architectural degradation by identifying its definitions, causes, metrics, tools, and remediation approaches across academic and gray literature. We conducted a multivocal literature review of 108 studies extracting definitions, causes, metrics, measurement approaches, tools, and remediation strategies. We developed a taxonomy encompassing architectural, code, and process debt to explore definition evolution, methodological trends, and research gaps. Architectural degradation has shifted from a low-level issue to a socio-technical concern. Definitions now address code violations, design drift, and structural decay. Causes fall under architectural (e.g., poor documentation), code (e.g., hasty fixes), and process debt (e.g., knowledge loss). We identified 54 metrics and 31 measurement techniques, focused on smells, cohesion/coupling, and evolution. Yet, most tools detect issues but rarely support ongoing or preventive remediation. Degradation is both technical and organizational. While detection is well-studied, continuous remediation remains lacking. Our study reveals missed integration between metrics, tools, and repair logic, urging holistic, proactive strategies for sustainable architecture.",
      "authors": [
        "Noman Ahmad",
        "Ruoyu Su",
        "Matteo Esposito",
        "Andrea Janes",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:09:38+00:00",
          "link": "https://arxiv.org/abs/2507.14547v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "Architectural Degradation: Definition, Motivations, Measurement and Remediation Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14547",
        "PDF": "https://arxiv.org/pdf/2507.14547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study deals with architectural degradation in systems, exploring definitions, causes, and remediation strategies, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14575",
      "abstract": "Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering distinct diagnostic insights. However, acquiring all desired modalities increases scan time and cost, motivating research into computational methods for cross-modal synthesis. To address this, recent approaches aim to synthesize missing MRI contrasts from those already acquired, reducing acquisition time while preserving diagnostic quality. Image-to-image (I2I) translation provides a promising framework for this task. In this paper, we present a comprehensive benchmark of generative models$\\unicode{x2013}$specifically, Generative Adversarial Networks (GANs), diffusion models, and flow matching (FM) techniques$\\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All frameworks are implemented with comparable settings and evaluated on three publicly available MRI datasets of healthy adults. Our quantitative and qualitative analyses show that the GAN-based Pix2Pix model outperforms diffusion and FM-based methods in terms of structural fidelity, image quality, and computational efficiency. Consistent with existing literature, these results suggest that flow-based models are prone to overfitting on small datasets and simpler tasks, and may require more data to match or surpass GAN performance. These findings offer practical guidance for deploying I2I translation techniques in real-world MRI workflows and highlight promising directions for future research in cross-modal medical image synthesis. Code and models are publicly available at https://github.com/AndreaMoschetto/medical-I2I-benchmark.",
      "authors": [
        "Andrea Moschetto",
        "Lemuel Puglisi",
        "Alec Sargood",
        "Pierluigi Dell'Acqua",
        "Francesco Guarnera",
        "Sebastiano Battiato",
        "Daniele Rav\\`i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T10:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.14575v1",
          "size": "1697kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14575",
        "HTML": "https://arxiv.org/html/2507.14575",
        "PDF": "https://arxiv.org/pdf/2507.14575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper benchmarks generative models for MRI image translation. It does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14871",
      "abstract": "A prominent achievement of natural language processing (NLP) is its ability to understand and generate meaningful human language. This capability relies on complex feedforward transformer block architectures pre-trained on large language models (LLMs). However, LLM pre-training is currently feasible only for a few dominant companies due to the immense computational resources required, limiting broader research participation. This creates a critical need for more accessible alternatives. In this study, we explore whether tiny language models (TLMs) exhibit the same key qualitative features of LLMs. We demonstrate that TLMs exhibit a clear performance gap between pre-trained and non-pre-trained models across classification tasks, indicating the effectiveness of pre-training, even at a tiny scale. The performance gap increases with the size of the pre-training dataset and with greater overlap between tokens in the pre-training and classification datasets. Furthermore, the classification accuracy achieved by a pre-trained deep TLM architecture can be replicated through a soft committee of multiple, independently pre-trained shallow architectures, enabling low-latency TLMs without affecting classification accuracy. Our results are based on pre-training BERT-6 and variants of BERT-1 on subsets of the Wikipedia dataset and evaluating their performance on FewRel, AGNews, and DBPedia classification tasks. Future research on TLM is expected to further illuminate the mechanisms underlying NLP, especially given that its biologically inspired models suggest that TLMs may be sufficient for children or adolescents to develop language.",
      "authors": [
        "Ronit D. Gross",
        "Yarden Tzach",
        "Tal Halevi",
        "Ella Koresh and Ido Kanter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.14871v1",
          "size": "693kb",
          "version": "v1"
        }
      ],
      "title": "Tiny language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14871",
        "PDF": "https://arxiv.org/pdf/2507.14871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the concept of Tiny Language Models (TLMs) and the effectiveness of pre-training, utilizing subsets of Wikipedia datasets. It touches on data processing for pre-training, but the main focus is on model architecture and scaling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15120",
      "abstract": "Standard automated planning employs first-order formulas under closed-world semantics to achieve a goal with a given set of actions from an initial state. We follow a line of research that aims to incorporate background knowledge into automated planning problems, for example, by means of ontologies, which are usually interpreted under open-world semantics. We present a new approach for planning with DL-Lite ontologies that combines the advantages of ontology-based action conditions provided by explicit-input knowledge and action bases (eKABs) and ontology-aware action effects under the coherence update semantics. We show that the complexity of the resulting formalism is not higher than that of previous approaches and provide an implementation via a polynomial compilation into classical planning. An evaluation of existing and new benchmarks examines the performance of a planning system on different variants of our compilation.",
      "authors": [
        "Stefan Borgwardt",
        "Duy Nhu",
        "Gabriele R\\\"oger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:49:21+00:00",
          "link": "https://arxiv.org/abs/2507.15120v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Automated planning with ontologies under coherence update semantics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15120",
        "HTML": "https://arxiv.org/html/2507.15120",
        "PDF": "https://arxiv.org/pdf/2507.15120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses planning with ontologies under coherence update semantics. It does not relate to LLM training data processing as it deals with automated planning and ontologies rather than language model data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15247",
      "abstract": "Despite the theoretical and practical significance of BCH codes, the exact minimum distance and dimension remain unknown for many families. This paper establishes the precise minimum distance and dimension of narrow-sense BCH codes $\\C_{(q, m, \\lambda, \\ell_0, \\ell_1)}$ over $\\gf(q)$ of length $\\frac{q^m-1}{\\lambda}$ and designed distance $\\frac{(q-\\lambda \\ell_0)q^{m-1-\\ell_1}-1}{\\lambda}$, where $\\lambda\\mid (q-1)$, $0\\leq \\ell_0< \\frac{q-1}{\\lambda}$, and $0\\leq \\ell_1\\leq m-1$. These results conclusively resolve the three open problems posed by Li et al. (IEEE Trans. Inf. Theory, vol. 63, no. 11, pp. 7219-7236, Nov. 2017) while establishing complementary advances to Ding's seminal framework (IEEE Trans. Inf. Theory, vol. 61, no. 10, pp. 5322-5330, Oct. 2015).",
      "authors": [
        "Zhonghua Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:12:56+00:00",
          "link": "https://arxiv.org/abs/2507.15247v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "The Exact Parameters of A Family of BCH Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15247",
        "HTML": "https://arxiv.org/html/2507.15247",
        "PDF": "https://arxiv.org/pdf/2507.15247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on establishing the precise minimum distance and dimension of BCH codes, which is unrelated to LLM training data processing, data engineering operations, or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15301",
      "abstract": "Smoothing and filtering two-dimensional sequences are fundamental tasks in fields such as computer vision. Conventional filtering algorithms often rely on the selection of the filtering window, limiting their applicability in certain scenarios. To this end, we propose a novel Two-Dimensional Smoothing (TDS) algorithm for the smoothing and filtering problem of two-dimensional sequences. Typically, the TDS algorithm does not require assumptions about the type of noise distribution. It is simple and easy to implement compared to conventional filtering methods, such as 2D adaptive Wiener filtering and Gaussian filtering. The TDS algorithm can effectively extract the trend contained in the two-dimensional sequence and reduce the influence of noise on the data by adjusting only a single parameter. In this work, unlike existing algorithms that depend on the filtering window, we introduce a loss function, where the trend sequence is identified as the solution when this loss function takes a minimum value. Therefore, within the framework of the TDS algorithm, a general two-dimensional sequence can be innovatively decomposed into a trend sequence and a fluctuation sequence, in which the trend sequence contains the main features of the sequence and the fluctuation sequence contains the detailed features or noise interference of the sequence. To ensure the reliability of the TDS algorithm, a crucial lemma is first established, indicating that the trend sequence and fluctuation sequence obtained by the TDS algorithm are existent and unique when the global smoothing parameter is determined. Three modified algorithms are then proposed based on the TDS algorithm, with corresponding lemmas and corollaries demonstrating their reliability. Finally, the accuracy and effectiveness of the TDS algorithm are further verified through numerical simulations and image processing cases.",
      "authors": [
        "Xufeng Chen",
        "Liang Yan",
        "Xiaoshan Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:59:33+00:00",
          "link": "https://arxiv.org/abs/2507.15301v1",
          "size": "7963kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Two-Dimensional Smoothing Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15301",
        "PDF": "https://arxiv.org/pdf/2507.15301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel Two-Dimensional Smoothing Algorithm for sequences in computer vision. It does not address issues concerning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15356",
      "abstract": "Offline reinforcement learning (RL) enables agents to learn policies from fixed datasets, avoiding costly or unsafe environment interactions. However, its effectiveness is often limited by dataset sparsity and the lack of transition overlap between suboptimal and expert trajectories, which makes long-horizon planning particularly challenging. Prior solutions based on synthetic data augmentation or trajectory stitching often fail to generalize to novel states and rely on heuristic stitching points. To address these challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for decision-making, which combines non-parametric retrieval with diffusion-based generative modeling. RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. Such retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states. Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.",
      "authors": [
        "Lu Guo",
        "Yixiang Shan",
        "Zhengbang Zhu",
        "Qifan Liang",
        "Lichang Song",
        "Ting Long",
        "Weinan Zhang",
        "Yi Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:08:18+00:00",
          "link": "https://arxiv.org/abs/2507.15356v1",
          "size": "718kb",
          "version": "v1"
        }
      ],
      "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15356",
        "HTML": "https://arxiv.org/html/2507.15356",
        "PDF": "https://arxiv.org/pdf/2507.15356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces RAD, a technique in offline reinforcement learning for decision-making through retrieval and generative modeling. It focuses on improving trajectory stitching, not LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15716",
      "abstract": "This paper proposes DiffPF, a differentiable particle filter that leverages diffusion models for state estimation in dynamic systems. Unlike conventional differentiable particle filters, which require importance weighting and typically rely on predefined or low-capacity proposal distributions. DiffPF learns a flexible posterior sampler by conditioning a diffusion model on predicted particles and the current observation. This enables accurate, equally-weighted sampling from complex, high-dimensional, and multimodal filtering distributions. We evaluate DiffPF across a range of scenarios, including both unimodal and highly multimodal distributions, and test it on simulated as well as real-world tasks, where it consistently outperforms existing filtering baselines. In particular, DiffPF achieves an 82.8% improvement in estimation accuracy on a highly multimodal global localization benchmark, and a 26% improvement on the real-world KITTI visual odometry benchmark, compared to state-of-the-art differentiable filters. To the best of our knowledge, DiffPF is the first method to integrate conditional diffusion models into particle filtering, enabling high-quality posterior sampling that produces more informative particles and significantly improves state estimation.",
      "authors": [
        "Ziyu Wan and Lin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:27:23+00:00",
          "link": "https://arxiv.org/abs/2507.15716v1",
          "size": "1285kb",
          "version": "v1"
        }
      ],
      "title": "DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15716",
        "HTML": "https://arxiv.org/html/2507.15716",
        "PDF": "https://arxiv.org/pdf/2507.15716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes DiffPF for state estimation using diffusion models in particle filtering, which is unrelated to LLM training data processing. It deals with improving state estimation accuracy rather than any aspect of LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15775",
      "abstract": "We present GravLensX, an innovative method for rendering black holes with gravitational lensing effects using neural networks. The methodology involves training neural networks to fit the spacetime around black holes and then employing these trained models to generate the path of light rays affected by gravitational lensing. This enables efficient and scalable simulations of black holes with optically thin accretion disks, significantly decreasing the time required for rendering compared to traditional methods. We validate our approach through extensive rendering of multiple black hole systems with superposed Kerr metric, demonstrating its capability to produce accurate visualizations with significantly $15\\times$ reduced computational time. Our findings suggest that neural networks offer a promising alternative for rendering complex astrophysical phenomena, potentially paving a new path to astronomical visualization.",
      "authors": [
        "Mingyuan Sun",
        "Zheng Fang",
        "Jiaxu Wang",
        "Kunyi Zhang",
        "Qiang Zhang",
        "Renjing Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:30:36+00:00",
          "link": "https://arxiv.org/abs/2507.15775v1",
          "size": "9232kb",
          "version": "v1"
        }
      ],
      "title": "Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15775",
        "HTML": "https://arxiv.org/html/2507.15775",
        "PDF": "https://arxiv.org/pdf/2507.15775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rendering black holes with gravitational lensing effects using neural networks, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15800",
      "abstract": "The integration of sensing and communication (ISAC) is a key enabler for next-generation technologies. With high-frequency bands and large-scale antenna arrays, the Rayleigh distance extends, necessitating near-field (NF) models where waves are spherical. Although NF-ISAC improves both sensing and communication, it also poses challenges such as high data volume and potential privacy risks. To address these, we propose a novel framework: near-field integrated sensing, computing, and semantic communication (NF-ISCSC), which leverages semantic communication to transmit contextual information only, thereby reducing data overhead and improving efficiency. However, semantic communication is sensitive to channel variations, requiring adaptive mechanisms. To this end, fluid antennas (FAs) are introduced to support the NF-ISCSC system, enabling dynamic adaptability to changing channels. The proposed FA-enabled NF-ISCSC framework considers multiple communication users and extended targets comprising several scatterers. A joint optimization problem is formulated to maximize data rate while accounting for sensing quality, computational load, and power budget. Using an alternating optimization (AO) approach, the original problem is divided into three sub-problems: ISAC beamforming, FA positioning, and semantic extraction ratio. Beamforming is optimized using the successive convex approximation method. FA positioning is solved via a projected Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, and the semantic extraction ratio is optimized using bisection search. Simulation results demonstrate that the proposed framework achieves higher data rates and better privacy preservation.",
      "authors": [
        "Yinchao Yang",
        "Jingxuan Zhou",
        "Zhaohui Yang",
        "Mohammad Shikh-Bahaei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:58:15+00:00",
          "link": "https://arxiv.org/abs/2507.15800v1",
          "size": "368kb",
          "version": "v1"
        }
      ],
      "title": "Fluid Antenna-enabled Near-Field Integrated Sensing, Computing and Semantic Communication for Emerging Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15800",
        "HTML": "https://arxiv.org/html/2507.15800",
        "PDF": "https://arxiv.org/pdf/2507.15800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic communication and fluid antenna systems for sensing and communications. It does not address language model training or data processing for LLMs, making it irrelevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10062",
      "abstract": "Building mixture-of-experts (MoE) architecture for Low-rank adaptation (LoRA) is emerging as a potential direction in parameter-efficient fine-tuning (PEFT) for its modular design and remarkable performance. However, simply stacking the number of experts cannot guarantee significant improvement. In this work, we first conduct qualitative analysis to indicate that experts collapse to similar representations in vanilla MoE, limiting the capacity of modular design and computational efficiency. Ulteriorly, Our analysis reveals that the performance of previous MoE variants maybe limited by a lack of diversity among experts. Motivated by these findings, we propose Orthogonal Mixture-of-Experts (OMoE), a resource-efficient MoE variant that trains experts in an orthogonal manner to promote diversity. In OMoE, a Gram-Schmidt process is leveraged to enforce that the experts' representations lie within the Stiefel manifold. By applying orthogonal constraints directly to the architecture, OMoE keeps the learning objective unchanged, without compromising optimality. Our method is simple and alleviates memory bottlenecks, as it incurs minimal experts compared to vanilla MoE models. Experiments on diverse commonsense reasoning benchmarks demonstrate that OMoE can consistently achieve stable and efficient performance improvement when compared with the state-of-the-art methods while significantly reducing the number of required experts.",
      "authors": [
        "Jinyuan Feng and Zhiqiang Pu and Tianyi Hu and Dongmin Li and Xiaolin Ai and Huimu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T09:27:08+00:00",
          "link": "https://arxiv.org/abs/2501.10062v1",
          "size": "1508kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:51:55+00:00",
          "link": "https://arxiv.org/abs/2501.10062v2",
          "size": "1424kb",
          "version": "v2"
        }
      ],
      "title": "OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal Finetuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10062",
        "HTML": "https://arxiv.org/html/2501.10062",
        "PDF": "https://arxiv.org/pdf/2501.10062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses Orthogonal Mixture-of-Experts (OMoE) for model fine-tuning and efficiency, it primarily focuses on model training and architecture rather than directly addressing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Computational Efficiency",
        "Diversity",
        "Mixture-of-Experts",
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14529",
      "abstract": "We consider the maximum causal entropy inverse reinforcement learning problem for infinite-horizon stationary mean-field games, in which we model the unknown reward function within a reproducing kernel Hilbert space. This allows the inference of rich and potentially nonlinear reward structures directly from expert demonstrations, in contrast to most existing inverse reinforcement learning approaches for mean-field games that typically restrict the reward function to a linear combination of a fixed finite set of basis functions. We also focus on the infinite-horizon cost structure, whereas prior studies primarily rely on finite-horizon formulations. We introduce a Lagrangian relaxation to this maximum causal entropy inverse reinforcement learning problem that enables us to reformulate it as an unconstrained log-likelihood maximization problem, and obtain a solution \\lk{via} a gradient ascent algorithm. To illustrate the theoretical consistency of the algorithm, we establish the smoothness of the log-likelihood objective by proving the Fr\\'echet differentiability of the related soft Bellman operators with respect to the parameters in the reproducing kernel Hilbert space. We demonstrate the effectiveness of our method on a mean-field traffic routing game, where it accurately recovers expert behavior.",
      "authors": [
        "Berkay Anahtarci",
        "Can Deha Kariksiz",
        "Naci Saldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:06:52+00:00",
          "link": "https://arxiv.org/abs/2507.14529v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14529",
        "PDF": "https://arxiv.org/pdf/2507.14529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses kernel based maximum entropy inverse reinforcement learning for mean-field games. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14534",
      "abstract": "Zero-shot online voice conversion (VC) holds significant promise for real-time communications and entertainment. However, current VC models struggle to preserve semantic fidelity under real-time constraints, deliver natural-sounding conversions, and adapt effectively to unseen speaker characteristics. To address these challenges, we introduce Conan, a chunkwise online zero-shot voice conversion model that preserves the content of the source while matching the voice timbre and styles of reference speech. Conan comprises three core components: 1) a Stream Content Extractor that leverages Emformer for low-latency streaming content encoding; 2) an Adaptive Style Encoder that extracts fine-grained stylistic features from reference speech for enhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully causal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations demonstrate that Conan outperforms baseline models in subjective and objective metrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo.",
      "authors": [
        "Yu Zhang",
        "Baotong Tian",
        "Zhiyao Duan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.14534v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14534",
        "HTML": "https://arxiv.org/html/2507.14534",
        "PDF": "https://arxiv.org/pdf/2507.14534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about voice conversion technology for real-time applications, with no contribution or relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14864",
      "abstract": "Online social networks have become an integral part of modern society, profoundly influencing how individuals form and exchange opinions across diverse domains ranging from politics to public health. The Friedkin-Johnsen model serves as a foundational framework for modeling opinion formation dynamics in such networks. In this paper, we address the computational task of efficiently determining the equilibrium opinion vector and associated metrics including polarization and disagreement, applicable to both directed and undirected social networks. We propose a deterministic local algorithm with relative error guarantees, scaling to networks exceeding ten million nodes. Further acceleration is achieved through integration with successive over-relaxation techniques, where a relaxation factor optimizes convergence rates. Extensive experiments on diverse real-world networks validate the practical effectiveness of our approaches, demonstrating significant improvements in computational efficiency and scalability compared to conventional methods.",
      "authors": [
        "Gengyu Wang",
        "Runze Zhang",
        "Zhongzhi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:21:02+00:00",
          "link": "https://arxiv.org/abs/2507.14864v1",
          "size": "118kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion Dynamics Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14864",
        "HTML": "https://arxiv.org/html/2507.14864",
        "PDF": "https://arxiv.org/pdf/2507.14864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on opinion dynamics models in social networks, specifically the Friedkin-Johnsen model, for efficiently determining equilibrium vectors in networks. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15759",
      "abstract": "This paper introduces \"Interaction as Intelligence\" research series, presenting a reconceptualization of human-AI relationships in deep research tasks. Traditional approaches treat interaction merely as an interface for accessing AI capabilities-a conduit between human intent and machine output. We propose that interaction itself constitutes a fundamental dimension of intelligence. As AI systems engage in extended thinking processes for research tasks, meaningful interaction transitions from an optional enhancement to an essential component of effective intelligence. Current deep research systems adopt an \"input-wait-output\" paradigm where users initiate queries and receive results after black-box processing. This approach leads to error cascade effects, inflexible research boundaries that prevent question refinement during investigation, and missed opportunities for expertise integration. To address these limitations, we introduce Deep Cognition, a system that transforms the human role from giving instructions to cognitive oversight-a mode of engagement where humans guide AI thinking processes through strategic intervention at critical junctures. Deep cognition implements three key innovations: (1)Transparent, controllable, and interruptible interaction that reveals AI reasoning and enables intervention at any point; (2)Fine-grained bidirectional dialogue; and (3)Shared cognitive context where the system observes and adapts to user behaviors without explicit instruction. User evaluation demonstrates that this cognitive oversight paradigm outperforms the strongest baseline across six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%), Real-Time Intervention(+18.5%), Ease of Collaboration(+27.7%), Results-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on challenging research problems show 31.8% to 50.0% points of improvements over deep research systems.",
      "authors": [
        "Lyumanshan Ye",
        "Xiaojie Cai",
        "Xinkai Wang",
        "Junfei Wang",
        "Xiangkun Hu",
        "Jiadi Su",
        "Yang Nan",
        "Sihan Wang",
        "Bohan Zhang",
        "Xiaoze Fan",
        "Jinbin Luo",
        "Yuxiang Zheng",
        "Tianze Xu",
        "Dayuan Fu",
        "Yunze Wu",
        "Pengrui Lu",
        "Zengzhi Wang",
        "Yiwei Qin",
        "Zhen Huang",
        "Yan Ma",
        "Zhulin Hu",
        "Haoyang Zou",
        "Tiantian Mi",
        "Yixin Ye",
        "Ethan Chern",
        "Pengfei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:15:18+00:00",
          "link": "https://arxiv.org/abs/2507.15759v1",
          "size": "12096kb",
          "version": "v1"
        }
      ],
      "title": "Interaction as Intelligence: Deep Research With Human-AI Partnership",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15759",
        "PDF": "https://arxiv.org/pdf/2507.15759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a new concept of human-AI interaction and cognitive oversight in AI systems, particularly in deep research tasks. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.01249",
      "abstract": "Prompt engineering is crucial for harnessing the potential of large language models (LLMs), especially in the medical domain where specialized terminology and phrasing is used. However, the efficacy of prompt engineering in the medical domain remains to be explored. In this work, 114 recent studies (2022-2024) applying prompt engineering in medicine, covering prompt learning (PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used interchangeably. ChatGPT is the most commonly used LLM, with seven papers using it for processing sensitive clinical data. Chain-of-Thought emerges as the most common prompt engineering technique. While PL and PT articles typically provide a baseline for evaluating prompt-based approaches, 64% of PD studies lack non-prompt-related baselines. We provide tables and figures summarizing existing work, and reporting recommendations to guide future research contributions.",
      "authors": [
        "Jamil Zaghir",
        "Marco Naguib",
        "Mina Bjelogrlic",
        "Aur\\'elie N\\'ev\\'eol",
        "Xavier Tannier",
        "Christian Lovis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-02T12:52:23+00:00",
          "link": "https://arxiv.org/abs/2405.01249v1",
          "size": "1799kb",
          "version": "v1"
        }
      ],
      "title": "Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.01249",
        "PDF": "https://arxiv.org/pdf/2405.01249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper reviews prompt engineering paradigms in the medical domain, which touches on LLM usage but mainly focuses on prompt design and engineering rather than training data processing."
      },
      "tasks": [
        "Articles",
        "Prompt Engineering",
        "Prompt Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05742",
      "abstract": "This study presents an aposteriori error analysis of adaptive finite element approximations of parabolic boundary control problems with bilateral box constraints that act on a Neumann boundary. The control problem is discretized using the symmetric interior penalty Galerkin (SIPG) technique. We derive both reliable and efficient type residual-based error estimators coupling with the data oscillations. The implementation of these error estimators serves as a guide for the adaptive mesh refinement process, indicating whether or not more refinement is required. Although the control error estimator effectively captured control approximation errors, it had limitations in guiding refinement localization in critical cases. To overcome this, an alternative control indicator was used in numerical tests. The results demonstrated the clear superiority of adaptive refinements over uniform refinements, confirming the proposed approach's effectiveness in achieving accurate solutions while optimizing computational efficiency. numerical experiment showcases the effectiveness of the derived error estimators.",
      "authors": [
        "Ram Manohar",
        "B. V. Rathish Kumar",
        "Kedarnath Buda",
        "Rajen Kumar Sinha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T05:38:59+00:00",
          "link": "https://arxiv.org/abs/2503.05742v1",
          "size": "1105kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T02:18:28+00:00",
          "link": "https://arxiv.org/abs/2503.05742v2",
          "size": "2209kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive SIPG method for approximations of boundary control problems governed by parabolic PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05742",
        "PDF": "https://arxiv.org/pdf/2503.05742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on error analysis for boundary control problems solved using finite element methods. It does not relate to LLM training data or its processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14570",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph mining tasks, yet existing scalable solutions often struggle to balance execution efficiency with prediction accuracy. These difficulties stem from iterative message-passing techniques, which place significant computational demands and require extensive GPU memory, particularly when dealing with the neighbor explosion issue inherent in large-scale graphs. This paper introduces a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN, which can perform representation learning on 100 billion graphs with a single GPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We examine existing graph partitioning methods and design a superior graph partition algorithm named LPMetis. In particular, LPMetis outperforms current state-of-the-art (SOTA) approaches on various evaluation metrics. In addition, our paper proposes a subgraph augmentation strategy to enhance the model's predictive performance. It exhibits excellent compatibility, allowing the entire framework to accommodate various GNN algorithms. Successfully deployed on the Tencent platform, LPS-GNN has been tested on public and real-world datasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in online applications.",
      "authors": [
        "Xu Cheng",
        "Liang Yao",
        "Feng He",
        "Yukuo Cen",
        "Yufei He",
        "Chenhui Zhang",
        "Wenzheng Feng",
        "Hongyun Cai",
        "Jie Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T10:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.14570v1",
          "size": "1516kb",
          "version": "v1"
        }
      ],
      "title": "LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14570",
        "HTML": "https://arxiv.org/html/2507.14570",
        "PDF": "https://arxiv.org/pdf/2507.14570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework called LPS-GNN for deploying Graph Neural Networks efficiently, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14975",
      "abstract": "Autonomous error correction is critical for domestic robots to achieve reliable execution of complex long-horizon tasks. Prior work has explored self-reflection in Large Language Models (LLMs) for task planning error correction; however, existing methods are constrained by inflexible self-reflection mechanisms that limit their effectiveness. Motivated by these limitations and inspired by human cognitive adaptation, we propose the Flexible Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture that enables LLMs to perform flexible self-reflection based on task difficulty, while constructively integrating historical valuable experience with failure lessons. We evaluated FCRF on diverse domestic tasks through simulation in AlfWorld and physical deployment in the real-world environment. Experimental results demonstrate that FCRF significantly improves overall performance and self-reflection flexibility in complex long-horizon robotic tasks.",
      "authors": [
        "Yufan Song",
        "Jiatao Zhang",
        "Zeng Gu",
        "Qingmiao Liang",
        "Tuocheng Hu",
        "Wei Song",
        "Shiqiang Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:15:39+00:00",
          "link": "https://arxiv.org/abs/2507.14975v1",
          "size": "5537kb",
          "version": "v1"
        }
      ],
      "title": "FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14975",
        "HTML": "https://arxiv.org/html/2507.14975",
        "PDF": "https://arxiv.org/pdf/2507.14975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on error correction in robotic task planning using LLMs, not on training data processing for LLMs themselves. It addresses self-reflection in LLM-based task planning but doesn't involve data processes like collection, filtering, or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15167",
      "abstract": "We propose a modular, fast and large-area fabrication of bio-piezoelectric films. The technique is based on the formation of cone-jet mode by applying a high voltage electric field to conductive spiked metal disks. And the self-assembly process of biomolecular materials through nanoconfinement with in-situ poling effect. This job achieved print speeds of up to 9.2 109 um3/s with a combination of only 2 printheads. At the same time, the modular design allows the MLSP to achieve theoretically unlimited print efficiency. It also provides flexible configuration options for different printing needs, such as preparing films of different areas and shapes. In short, MLSP demonstrates the ability of piezoelectric biomaterials to undergo ultra-fast, large-scale assembly. Demonstrates good potential as a universally applicable bio-device for the fabrication of bio-piezoelectric films",
      "authors": [
        "Nan An",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T00:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.15167v1",
          "size": "582kb",
          "version": "v1"
        }
      ],
      "title": "A New Ultrafast Printer for Large-Scale Assembly of Piezoelectric Biomaterials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15167",
        "HTML": "https://arxiv.org/html/2507.15167",
        "PDF": "https://arxiv.org/pdf/2507.15167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new printing technology for piezoelectric biomaterials and does not address any aspect of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15737",
      "abstract": "Matching games is a one-to-one two sided market model introduced by Garrido-Lucero and Laraki, in which coupled agents' utilities are endogenously determined as the outcome of a strategic game. They refine the classical pairwise stability by requiring robustness to renegotiation and provide general conditions under which pairwise stable and renegotiation-proof outcomes exist as the limit of a deferred acceptance with competitions algorithm together with a renegotiation process. In this article, we extend their model to a general setting encompassing most of one-to-many matching markets and roommates models and specify two frameworks under which core stable and renegotiation-proof outcomes exist and can be efficiently computed.",
      "authors": [
        "Felipe Garrido-Lucero and Rida Laraki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.15737v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "General Matching Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15737",
        "HTML": "https://arxiv.org/html/2507.15737",
        "PDF": "https://arxiv.org/pdf/2507.15737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on matching games and market models, which do not relate to any aspect of LLM training data processing or data-related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.08033",
      "abstract": "Trajectory prediction and planning are essential for autonomous vehicles to navigate safely and efficiently in dynamic environments. Traditional approaches often treat them separately, limiting the ability for interactive planning. While recent diffusion-based generative models have shown promise in multi-agent trajectory generation, their slow sampling is less suitable for high-frequency planning tasks. In this paper, we leverage the consistency model to build a predictive planner that samples from a joint distribution of ego and surrounding agents, conditioned on the ego vehicle's navigational goal. Trained on real-world human driving datasets, our consistency model generates higher-quality trajectories with fewer sampling steps than standard diffusion models, making it more suitable for real-time deployment. To enforce multiple planning constraints simultaneously on the ego trajectory, a novel online guided sampling approach inspired by the Alternating Direction Method of Multipliers (ADMM) is introduced. Evaluated on the Waymo Open Motion Dataset (WOMD), our method enables proactive behavior such as nudging and yielding, and also demonstrates smoother, safer, and more efficient trajectories and satisfaction of multiple constraints under a limited computational budget.",
      "authors": [
        "Anjian Li",
        "Sangjae Bae",
        "David Isele",
        "Ryne Beeson",
        "Faizan M. Tariq"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T00:26:01+00:00",
          "link": "https://arxiv.org/abs/2502.08033v1",
          "size": "16270kb",
          "version": "v1"
        },
        {
          "date": "2025-05-02T19:45:46+00:00",
          "link": "https://arxiv.org/abs/2502.08033v2",
          "size": "4642kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T16:17:09+00:00",
          "link": "https://arxiv.org/abs/2502.08033v3",
          "size": "4330kb",
          "version": "v3"
        }
      ],
      "title": "Predictive Planner for Autonomous Driving with Consistency Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08033",
        "HTML": "https://arxiv.org/html/2502.08033",
        "PDF": "https://arxiv.org/pdf/2502.08033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses trajectory prediction and planning for autonomous driving, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Navigate",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06216",
      "abstract": "We construct $\\varepsilon$-approximate unitary $k$-designs on $n$ qubits in circuit depth $O(\\log k \\log \\log n k / \\varepsilon)$. The depth is exponentially improved over all known results in all three parameters $n$, $k$, $\\varepsilon$. We further show that each dependence is optimal up to exponentially smaller factors. Our construction uses $\\tilde{{O}}(nk)$ ancilla qubits and ${O}(nk)$ bits of randomness, which are also optimal up to $\\log(n k)$ factors. An alternative construction achieves a smaller ancilla count $\\tilde{{O}}(n)$ with circuit depth ${O}(k \\log \\log nk/\\varepsilon)$. To achieve these efficient unitary designs, we introduce a highly-structured random unitary ensemble that leverages long-range two-qubit gates and low-depth implementations of random classical hash functions. We also develop a new analytical framework for bounding errors in quantum experiments involving many queries to random unitaries. As an illustration of this framework's versatility, we provide a succinct alternative proof of the existence of pseudorandom unitaries.",
      "authors": [
        "Laura Cui",
        "Thomas Schuster",
        "Fernando Brandao",
        "and Hsin-Yuan Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:48:33+00:00",
          "link": "https://arxiv.org/abs/2507.06216v1",
          "size": "291kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:11:58+00:00",
          "link": "https://arxiv.org/abs/2507.06216v2",
          "size": "293kb",
          "version": "v2"
        }
      ],
      "title": "Unitary designs in nearly optimal depth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06216",
        "HTML": "https://arxiv.org/html/2507.06216",
        "PDF": "https://arxiv.org/pdf/2507.06216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for constructing unitary designs for quantum systems. It discusses quantum circuits and randomness, with no connection to LLM training data processing, dataset creation, or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14147",
      "abstract": "Insomnia affects a vast population of the world and can have a wide range of causes. Existing treatments for insomnia have been linked with many side effects like headaches, dizziness, etc. As such, there is a clear need for improved insomnia treatment. Brain modelling has helped with assessing the effects of brain pathology on brain network dynamics and with supporting clinical decisions in the treatment of Alzheimer's disease, epilepsy, etc. However, such models have not been developed for insomnia. Therefore, this project attempts to understand the characteristics of the brain of individuals experiencing insomnia using continuous long-duration EEG data. Brain networks are derived based on functional connectivity and spatial distance between EEG channels. The power spectral density of the channels is then computed for the major brain wave frequency bands. A graph convolutional neural network (GCNN) model is then trained to capture the functional characteristics associated with insomnia and configured for the classification task to judge performance. Results indicated a 50-second non-overlapping sliding window was the most suitable choice for EEG segmentation. This approach achieved a classification accuracy of 70% at window level and 68% at subject level. Additionally, the omission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in model performance than the removal of other channels. These channel electrodes are positioned near brain regions known to exhibit atypical levels of functional connectivity in individuals with insomnia, which can explain such results.",
      "authors": [
        "Kevin Monteiro",
        "Sam Nallaperuma-Herzberg",
        "Martina Mason",
        "Steve Niederer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.14147v1",
          "size": "812kb",
          "version": "v1"
        }
      ],
      "title": "Graph Convolutional Neural Networks to Model the Brain for Insomnia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14147",
        "HTML": "https://arxiv.org/html/2507.14147",
        "PDF": "https://arxiv.org/pdf/2507.14147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is concerned with modeling the brain for insomnia using EEG data and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14831",
      "abstract": "A multiple-waveguide pinching-antenna (PA)-based multi-user communication system is investigated. With a given number of PAs, two deployment strategies are considered, namely the centralized PA deployment, where all PAs are switched between waveguides to serve users in a time-division manner to avail of beamforming gain, and the distributed PA deployment, where a single PA is deployed on each waveguide to simultaneously serve multiple users by leveraging the multiplexing gain. The spectral efficiency (SE) achieved by each deployment strategy is analyzed: i) For the centralized deployment, the positioning strategy of PAs on each waveguide is determined first with the aim of maximizing the channel gain of the corresponding nearest served user. Based on this, the corresponding system SE is derived. ii) For the distributed deployment, the system SE under the maximum ratio transmission (MRT) is first obtained. To obtain an analytically tractable form, the stationary phase method is utilized to approximate the system SE. The approximation result reveals that the average inter-user interference can be negligible with a large waveguide spacing and thus the simple MRT is appealing for PA-based multi-user communications. Furthermore, the system SEs achieved by the two strategies are compared in both the high and low signal-to-noise ratio (SNR) regimes. Our analysis suggests that at high SNRs, the distributed deployment is superior to achieve the maximal system SE, while the centralized deployment is more suitable for the low-SNR regime. Finally, the theoretical analysis is verified through simulations.",
      "authors": [
        "Mengyu Qian",
        "Xidong Mu",
        "Li You and Michail Matthaiou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T06:00:00+00:00",
          "link": "https://arxiv.org/abs/2507.14831v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "Pinching-Antenna-based Communications: Spectral Efficiency Analysis and Deployment Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14831",
        "HTML": "https://arxiv.org/html/2507.14831",
        "PDF": "https://arxiv.org/pdf/2507.14831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses spectral efficiency in communication systems, specifically around pinching-antenna-based multi-user configurations. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14999",
      "abstract": "False Data Injection Attacks (FDIAs) pose severe security risks to smart grids by manipulating measurement data collected from spatially distributed devices such as SCADA systems and PMUs. These measurements typically exhibit Non-Independent and Identically Distributed (Non-IID) characteristics across different regions, which significantly challenges the generalization ability of detection models. Traditional centralized training approaches not only face privacy risks and data sharing constraints but also incur high transmission costs, limiting their scalability and deployment feasibility. To address these issues, this paper proposes a privacy-preserving federated learning framework, termed Federated Cluster Average (FedClusAvg), designed to improve FDIA detection in Non-IID and resource-constrained environments. FedClusAvg incorporates cluster-based stratified sampling and hierarchical communication (client-subserver-server) to enhance model generalization and reduce communication overhead. By enabling localized training and weighted parameter aggregation, the algorithm achieves accurate model convergence without centralizing sensitive data. Experimental results on benchmark smart grid datasets demonstrate that FedClusAvg not only improves detection accuracy under heterogeneous data distributions but also significantly reduces communication rounds and bandwidth consumption. This work provides an effective solution for secure and efficient FDIA detection in large-scale distributed power systems.",
      "authors": [
        "Yunfeng Li",
        "Junhong Liu",
        "Zhaohui Yang",
        "Guofu Liao",
        "Chuyun Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:10:43+00:00",
          "link": "https://arxiv.org/abs/2507.14999v1",
          "size": "925kb",
          "version": "v1"
        }
      ],
      "title": "Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14999",
        "HTML": "https://arxiv.org/html/2507.14999",
        "PDF": "https://arxiv.org/pdf/2507.14999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a federated learning framework for FDIA detection in smart grids. It involves heterogeneous data processing but not in the context of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15772",
      "abstract": "Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner. We applied DIVA to detect a range of plant stresses, including abiotic (shading, high light intensity, high temperature) and biotic stressors (bacterial infections). By integrating deep learning with vibrational spectroscopy, DIVA paves the way for AI-driven plant health assessment, fostering more resilient and sustainable agricultural practices.",
      "authors": [
        "Anoop C. Patil",
        "Benny Jian Rong Sng",
        "Yu-Wei Chang",
        "Joana B. Pereira",
        "Chua Nam-Hai",
        "Rajani Sarojam",
        "Gajendra Pratap Singh",
        "In-Cheol Jang",
        "and Giovanni Volpe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.15772v1",
          "size": "6907kb",
          "version": "v1"
        }
      ],
      "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15772",
        "HTML": "https://arxiv.org/html/2507.15772",
        "PDF": "https://arxiv.org/pdf/2507.15772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a deep-learning framework for analyzing Raman spectra to detect plant stress, without any relevance to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14474",
      "abstract": "This article presents a class of explicit Runge-Kutta methods with multiquadric (MQ) and inverse multiquadric (IMQ) radial basis functions (RBFs) to improve the accuracy of time integration for ordinary differential equations. By introducing RBF-based corrections derived from Taylor series expansions and optimally selecting the shape parameter, the method achieves a one-order increase in accuracy without additional stages. Convergence and stability analyses support the theoretical claims, and numerical experiments in MATLAB confirm the predicted performance.",
      "authors": [
        "Shipra Mahata",
        "Samala Rathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:10:48+00:00",
          "link": "https://arxiv.org/abs/2507.14474v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "Explicit Runge-Kutta Methods with MQ and IMQ-Radial Basis Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14474",
        "HTML": "https://arxiv.org/html/2507.14474",
        "PDF": "https://arxiv.org/pdf/2507.14474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving the accuracy of Runge-Kutta methods for ordinary differential equations with radial basis functions, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14752",
      "abstract": "We document strategies and lessons learned from sampling the web by collecting 27.3 million URLs with 3.8 billion archived pages spanning 26 years (1996-2021) from the Internet Archive's (IA) Wayback Machine. Our goal is to revisit fundamental questions regarding the size, nature, and prevalence of the publicly archivable web, in particular, to reconsider the question: \"How long does a web page last?\" Addressing this question requires obtaining a sample of the web. We proposed several dimensions to sample URLs from the Wayback Machine's holdings: time of first archive, HTML vs. other MIME types, URL depth (top-level pages vs. deep links), and top-level domain (TLD). We sampled 285 million URLs from IA's ZipNum index file, which contains every 6000th line of the CDX index. These indexes also include URLs of embedded resources such as images, CSS, and JavaScript. To limit our sample to \"web pages\" (i.e., pages intended for human interaction), we filtered for likely HTML pages based on filename extension. We then queried IA's CDX API to determine the time of first capture and MIME type of each URL. We grouped 92 million text/html URLs based on year of first capture. Archiving speed and capacity have increased over time, so we found more URLs archived in later years. To counter this, we extracted top-level URLs from deep links to upsample earlier years. Our target was 1 million URLs per year, but due to sparseness during 1996-2021, we clustered those years, collecting 1.2 million URLs for that range. Popular domains like Yahoo and Twitter were over-represented, so we performed logarithmic-scale downsampling. Our final dataset contains TimeMaps of 27.3 million URLs, comprising 3.8 billion archived pages. We convey lessons learned from sampling the archived web to inform future studies.",
      "authors": [
        "Kritika Garg",
        "Sawood Alam",
        "Dietrich Ayala",
        "Mark Graham",
        "Michele C. Weigle",
        "and Michael L. Nelson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:01:38+00:00",
          "link": "https://arxiv.org/abs/2507.14752v1",
          "size": "1233kb",
          "version": "v1"
        }
      ],
      "title": "Longitudinal Sampling of URLs From the Wayback Machine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14752",
        "HTML": "https://arxiv.org/html/2507.14752",
        "PDF": "https://arxiv.org/pdf/2507.14752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper outlines strategies for sampling and filtering large web datasets from the Internet Archive's Wayback Machine. This involves significant data engineering operations relevant to data collection and filtering, contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15288",
      "abstract": "System identification methods for multivariate time-series, such as neural and behavioral recordings, have been used to build models for predicting one from the other. For example, Preferential Subspace Identification (PSID) builds a state-space model of a primary time-series (e.g., neural activity) to optimally predict a secondary time-series (e.g., behavior). However, PSID focuses on optimal prediction using past primary data, even though in offline applications, better estimation can be achieved by incorporating concurrent data (filtering) or all available data (smoothing). Here, we extend PSID to enable optimal filtering and smoothing. First, we show that the presence of a secondary signal makes it possible to uniquely identify a model with an optimal Kalman update step (to enable filtering) from a family of otherwise equivalent state-space models. Our filtering solution augments PSID with a reduced-rank regression step that directly learns the optimal gain required for the update step from data. We refer to this extension of PSID as PSID with filtering. Second, inspired by two-filter Kalman smoother formulations, we develop a novel forward-backward PSID smoothing algorithm where we first apply PSID with filtering and then apply it again in the reverse time direction on the residuals of the filtered secondary signal. We validate our methods on simulated data, showing that our approach recovers the ground-truth model parameters for filtering, and achieves optimal filtering and smoothing decoding performance of the secondary signal that matches the ideal performance of the true underlying model. This work provides a principled framework for optimal linear filtering and smoothing in the two-signal setting, significantly expanding the toolkit for analyzing dynamic interactions in multivariate time-series.",
      "authors": [
        "Omid G. Sani and Maryam M. Shanechi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:39:31+00:00",
          "link": "https://arxiv.org/abs/2507.15288v1",
          "size": "187kb",
          "version": "v1"
        }
      ],
      "title": "Preferential subspace identification (PSID) with forward-backward smoothing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15288",
        "HTML": "https://arxiv.org/html/2507.15288",
        "PDF": "https://arxiv.org/pdf/2507.15288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses system identification for multivariate time-series using PSID and Kalman smoothing, which is unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15372",
      "abstract": "Mutual information (MI) is a useful information-theoretic measure to quantify the statistical dependence between two random variables: $X$ and $Y$. Often, we are interested in understanding how the dependence between $X$ and $Y$ in one set of samples compares to another. Although the dependence between $X$ and $Y$ in each set of samples can be measured separately using MI, these estimates cannot be compared directly if they are based on samples from a non-stationary distribution. Here, we propose an alternative measure for characterising how the dependence between $X$ and $Y$ as defined by one set of samples is expressed in another, \\textit{cross mutual information}. We present a comprehensive set of simulation studies sampling data with $X$-$Y$ dependencies to explore this measure. Finally, we discuss how this relates to measures of model fit in linear regression, and some future applications in neuroimaging data analysis.",
      "authors": [
        "Chetan Gohil",
        "Oliver M Cliff",
        "James M. Shine",
        "Ben D. Fulcher",
        "Joseph T. Lizier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:22:37+00:00",
          "link": "https://arxiv.org/abs/2507.15372v1",
          "size": "1226kb",
          "version": "v1"
        }
      ],
      "title": "Cross Mutual Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15372",
        "HTML": "https://arxiv.org/html/2507.15372",
        "PDF": "https://arxiv.org/pdf/2507.15372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the concept of cross mutual information and its applications in statistical dependence and linear regression, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15419",
      "abstract": "Phishing websites remain a major cybersecurity threat, yet existing methods primarily focus on detection, while the recognition of underlying malicious intentions remains largely unexplored. To address this gap, we propose PhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework that uncovers phishing intentions from website screenshots. Leveraging the visual-language capabilities of large language models (LLMs), our framework identifies four key phishing objectives: Credential Theft, Financial Fraud, Malware Distribution, and Personal Information Harvesting. We construct and release the first phishing intention ground truth dataset (~2K samples) and evaluate the framework using four commercial LLMs. Experimental results show that PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and significantly outperforms the single-agent baseline with a ~95% improvement in micro-precision. Compared to the previous work, it achieves 0.8545 precision for credential theft, marking a ~4% improvement. Additionally, we generate a larger dataset of ~9K samples for large-scale phishing intention profiling across sectors. This work provides a scalable and interpretable solution for intention-aware phishing analysis.",
      "authors": [
        "Wenhao Li",
        "Selvakumar Manickam",
        "Yung-wey Chong",
        "Shankar Karuppayah"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:20:43+00:00",
          "link": "https://arxiv.org/abs/2507.15419v1",
          "size": "3171kb",
          "version": "v1"
        }
      ],
      "title": "PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15419",
        "HTML": "https://arxiv.org/html/2507.15419",
        "PDF": "https://arxiv.org/pdf/2507.15419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper involves the construction of a phishing intention dataset and generation of data samples, which is somewhat related to data processing. However, the primary focus is on phishing intention detection rather than LLM data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15660",
      "abstract": "Mega events such as the Olympics, World Cup tournaments, G-20 Summit, religious events such as MahaKumbh are increasingly digitalized. From event ticketing, vendor booth or lodging reservations, sanitation, event scheduling, customer service, crime reporting, media streaming and messaging on digital display boards, surveillance, crowd control, traffic control and many other services are based on mobile and web applications, wired and wireless networking, network of Closed-Circuit Television (CCTV) cameras, specialized control room with network and video-feed monitoring. Consequently, cyber threats directed at such digital infrastructure are common. Starting from hobby hackers, hacktivists, cyber crime gangs, to the nation state actors, all target such infrastructure to unleash chaos on an otherwise smooth operation, and often the cyber threat actors attempt to embarrass the organizing country or the organizers. Unlike long-standing organizations such as a corporate or a government department, the infrastructure of mega-events is temporary, constructed over a short time span in expediency, and often shortcuts are taken to make the deadline for the event. As a result, securing such an elaborate yet temporary infrastructure requires a different approach than securing a standard organizational digital infrastructure. In this paper, we describe our approach to securing MahaKumbh 2025, a 600 million footfall event for 45 days in Prayagraj, India, as a cyber security assessment and risk management oversight team. We chronicle the scope, process, methodology, and outcome of our team's effort to secure this mega event. It should be noted that none of the cyber attacks during the 45-day event was successful. Our goal is to put on record the methodology and discuss what we would do differently in case we work on similar future mega event.",
      "authors": [
        "Rohit Negi",
        "Amit Negi",
        "Manish Sharma",
        "S. Venkatesan",
        "Prem Kumar and Sandeep K. Shukla"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:21:59+00:00",
          "link": "https://arxiv.org/abs/2507.15660v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Cyber security of Mega Events: A Case Study of Securing the Digital Infrastructure for MahaKumbh 2025 -- A 45 days Mega Event of 600 Million Footfalls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15660",
        "PDF": "https://arxiv.org/pdf/2507.15660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with cybersecurity measures for a mega event and does not involve any aspect of LLM training data processing or dataset-related improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09186",
      "abstract": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility Co-Simulation Platform), an open-source, synchronized, and extensible co-simulation framework that tightly couples three best-in-class simulation tools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support advanced research in transportation safety, mobility, and cybersecurity by combining the strengths of each simulation domain. Specifically, SUMO provides large-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D perception, vehicle dynamics, and control simulation; and OMNeT++ enables modular, event-driven network communication, such as cellular vehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized, bidirectional coupling architecture that ensures coherent simulation progression across traffic, perception, and communication domains while preserving modularity and reproducibility. For example, CARLA can simulate and render a subset of vehicles that require detailed sensor emulation and control logic; SUMO orchestrates network-wide traffic flow, vehicle routing, and traffic signal management; and OMNeT++ dynamically maps communication nodes to both mobile entities (e.g., vehicles) and static entities (e.g., roadside units) to enable C-V2X communication. While these three simulators form the foundational core of OpenCAMS, the platform is designed to be expandable and future-proof, allowing additional simulators to be integrated on top of this core without requiring fundamental changes to the system architecture. The OpenCAMS platform is fully open-source and publicly available through its GitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim, providing the research community with an accessible, flexible, and collaborative environment for advancing next-generation intelligent transportation systems.",
      "authors": [
        "Minhaj Uddin Ahmad",
        "Akid Abrar",
        "Sagar Dasgupta",
        "Mizanur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:10:37+00:00",
          "link": "https://arxiv.org/abs/2507.09186v1",
          "size": "3296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T18:38:34+00:00",
          "link": "https://arxiv.org/abs/2507.09186v2",
          "size": "3296kb",
          "version": "v2"
        }
      ],
      "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advancing Next-Generation Intelligent Transportation Systems Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09186",
        "HTML": "https://arxiv.org/html/2507.09186",
        "PDF": "https://arxiv.org/pdf/2507.09186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents OpenCAMS, a co-simulation platform for transportation systems involving SUMO, CARLA, and OMNeT++. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14195",
      "abstract": "Radar technology presents untapped potential for continuous, contactless, and passive heart rate monitoring via consumer electronics like mobile phones. However the variety of available radar systems and lack of standardization means that a large new paired dataset collection is required for each radar system. This study demonstrates transfer learning between frequency-modulated continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems, both increasingly integrated into consumer devices. FMCW radar utilizes a continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3 receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119 participants, an average of 8 hours per participant). This model maintained performance (under 5 MAE/10% MAPE) across various body positions and heart rate ranges, with a 98.9% recall. We then fine-tuned a variant of this model, trained on single-antenna and single-range bin FMCW data, using a small (N=376, avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE reduction over the IR-UWB baseline. This demonstration of transfer learning between radar systems for heart rate monitoring has the potential to accelerate its introduction into existing consumer devices.",
      "authors": [
        "Elzbieta Gruzewska",
        "Pooja Rao",
        "Sebastien Baur",
        "Matthew Baugh",
        "Mathias M.J. Bellaiche",
        "Sharanya Srinivas",
        "Octavio Ponce",
        "Matthew Thompson",
        "Pramod Rudrapatna",
        "Michael A. Sanchez",
        "Lawrence Z. Cai",
        "Timothy JA Chico",
        "Robert F. Storey",
        "Emily Maz",
        "Umesh Telang",
        "Shravya Shetty",
        "Mayank Daswani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T11:45:57+00:00",
          "link": "https://arxiv.org/abs/2507.14195v1",
          "size": "6097kb",
          "version": "v1"
        }
      ],
      "title": "UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14195",
        "HTML": "https://arxiv.org/html/2507.14195",
        "PDF": "https://arxiv.org/pdf/2507.14195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores transfer learning for radar-based heart rate monitoring, which does not contribute to LLM training data processing or related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15585",
      "abstract": "One way social groups are marginalized in discourse is that the narratives told about them often default to a narrow, stereotyped range of topics. In contrast, default groups are allowed the full complexity of human existence. We describe the constrained representations of queer people in LLM generations in terms of harmful representations, narrow representations, and discursive othering and formulate hypotheses to test for these phenomena. Our results show that LLMs are significantly limited in their portrayals of queer personas.",
      "authors": [
        "Atreya Ghosal",
        "Ashim Gupta",
        "Vivek Srikumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:03:38+00:00",
          "link": "https://arxiv.org/abs/2507.15585v1",
          "size": "9779kb",
          "version": "v1"
        }
      ],
      "title": "Unequal Voices: How LLMs Construct Constrained Queer Narratives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15585",
        "HTML": "https://arxiv.org/html/2507.15585",
        "PDF": "https://arxiv.org/pdf/2507.15585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the representation of queer personas in LLM-generated content and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15708",
      "abstract": "One of the most important satellite subsystems is its electric power subsystem. The occurrence of a fault in the satellite power system causes the failure of all or part of the satellite. Calculating the overall reliability of the power system before the mission is crucial in improving the design of the satellite power system. Each component of the power system may malfunction due to pressure, launch pressure, and operating conditions. Accordingly, in this paper, first, a healthy and faulty system for the components of the electrical power system is simulated with MATLAB. Finally, by drawing a fault tree to analyze the reliability of the power subsystem, overall mission reliability, power system fault rate, and overall fault rate of the mission are calculated by Windchill software. Finally, a total mission assurance of 0.999 was achieved, indicating the high reliability of the simulated system.",
      "authors": [
        "Niloofar Nobahari",
        "Alireza Rezaee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:16:08+00:00",
          "link": "https://arxiv.org/abs/2507.15708v1",
          "size": "1146kb",
          "version": "v1"
        }
      ],
      "title": "Reliability-Based Fault Analysis and Modeling of Satellite Electrical Power Subsystems Using Fault Tree and Simulation Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15708",
        "PDF": "https://arxiv.org/pdf/2507.15708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reliability-based fault analysis of satellite electrical power systems using fault tree and simulation tools, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.05911",
      "abstract": "Approximate message passing (AMP) has emerged both as a popular class of iterative algorithms and as a powerful analytic tool in a wide range of statistical estimation problems and statistical physics models. A well established line of AMP theory proves Gaussian approximations for the empirical distributions of the AMP iterate in the high dimensional limit, under the GOE random matrix model and its variants.\n  This paper provides a non-asymptotic, leave-one-out representation for the AMP iterate that holds under a broad class of Gaussian random matrix models with general variance profiles. In contrast to the typical AMP theory that describes the empirical distributions of the AMP iterate via a low dimensional state evolution, our leave-one-out representation yields an intrinsically high dimensional state evolution formula which provides non-asymptotic characterizations for the possibly heterogeneous, entrywise behavior of the AMP iterate under the prescribed random matrix models.\n  To exemplify some distinct features of our AMP theory in applications, we analyze, in the context of regularized linear estimation, the precise stochastic behavior of the Ridge estimator for independent and non-identically distributed observations whose covariates exhibit general variance profiles. We find that its finite-sample distribution is characterized via a weighted Ridge estimator in a heterogeneous Gaussian sequence model. Notably, in contrast to the i.i.d. sampling scenario, the effective noise and regularization are now full dimensional vectors determined via a high dimensional system of equations.\n  Our leave-one-out method of proof differs significantly from the widely adopted conditioning approach for rotational invariant ensembles, and relies instead on an inductive method that utilizes almost solely integration-by-parts and concentration techniques.",
      "authors": [
        "Zhigang Bao",
        "Qiyang Han",
        "Xiaocong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-10T15:27:20+00:00",
          "link": "https://arxiv.org/abs/2312.05911v1",
          "size": "938kb",
          "version": "v1"
        },
        {
          "date": "2023-12-25T06:21:10+00:00",
          "link": "https://arxiv.org/abs/2312.05911v2",
          "size": "238kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T02:52:35+00:00",
          "link": "https://arxiv.org/abs/2312.05911v3",
          "size": "220kb",
          "version": "v3"
        }
      ],
      "title": "A leave-one-out approach to approximate message passing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.05911",
        "PDF": "https://arxiv.org/pdf/2312.05911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores non-asymptotic analysis for approximate message passing algorithms in statistical estimation problems. It does not relate to LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.09971",
      "abstract": "Object-goal navigation requires mobile robots to efficiently locate targets with visual and spatial information, yet existing methods struggle with generalization in unseen environments. Heuristic approaches with naive metrics fail in complex layouts, while graph-based and learning-based methods suffer from environmental biases and limited generalization. Although Large Language Models (LLMs) as planners or agents offer a rich knowledge base, they are cost-inefficient and lack targeted historical experience. To address these challenges, we propose the LLM-enhanced Object Affinities Transfer (LOAT) framework, integrating LLM-derived semantics with learning-based approaches to leverage experiential object affinities for better generalization in unseen settings. LOAT employs a dual-module strategy: one module accesses LLMs' vast knowledge, and the other applies learned object semantic relationships, dynamically fusing these sources based on context. Evaluations in AI2-THOR and Habitat simulators show significant improvements in navigation success and efficiency, and real-world deployment demonstrates the zero-shot ability of LOAT to enhance object-goal navigation systems.",
      "authors": [
        "Mengying Lin",
        "Shugao Liu",
        "Dingxi Zhang",
        "Yaran Chen",
        "Zhaoran Wang",
        "Haoran Li",
        "Dongbin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-15T02:28:26+00:00",
          "link": "https://arxiv.org/abs/2403.09971v1",
          "size": "13570kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T16:20:28+00:00",
          "link": "https://arxiv.org/abs/2403.09971v2",
          "size": "1705kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T03:04:27+00:00",
          "link": "https://arxiv.org/abs/2403.09971v3",
          "size": "2497kb",
          "version": "v3"
        }
      ],
      "title": "Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.09971",
        "HTML": "https://arxiv.org/html/2403.09971",
        "PDF": "https://arxiv.org/pdf/2403.09971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving object-goal navigation for robots using LLM-enhanced object affinities, which does not relate to LLM training data processing or data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14235",
      "abstract": "Automated grading systems, or auto-graders, have become ubiquitous in programming education, and the way they generate feedback has become increasingly automated as well. However, there is insufficient evidence regarding auto-grader feedback's effectiveness in improving student learning outcomes, in a way that differentiates students who utilized the feedback and students who did not. In this study, we fill this critical gap. Specifically, we analyze students' interactions with auto-graders in an introductory Python programming course, offered at five community colleges in the United States. Our results show that students checking the feedback more frequently tend to get higher scores from their programming assignments overall. Our results also show that a submission that follows a student checking the feedback tends to receive a higher score than a submission that follows a student ignoring the feedback. Our results provide evidence on auto-grader feedback's effectiveness, encourage their increased utilization, and call for future work to continue their evaluation in this age of automation",
      "authors": [
        "Adam Zhang",
        "Heather Burte",
        "Jaromir Savelka",
        "Christopher Bogart",
        "Majd Sakr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:11:59+00:00",
          "link": "https://arxiv.org/abs/2507.14235v1",
          "size": "1912kb",
          "version": "v1"
        }
      ],
      "title": "Auto-grader Feedback Utilization and Its Impacts: An Observational Study Across Five Community Colleges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14235",
        "HTML": "https://arxiv.org/html/2507.14235",
        "PDF": "https://arxiv.org/pdf/2507.14235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on auto-grader feedback in programming education, and it does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14477",
      "abstract": "Visual Place Recognition (VPR) in dynamic and perceptually aliased environments remains a fundamental challenge for long-term localization. Existing deep learning-based solutions predominantly focus on single-frame embeddings, neglecting the temporal coherence present in image sequences. This paper presents OptiCorNet, a novel sequence modeling framework that unifies spatial feature extraction and temporal differencing into a differentiable, end-to-end trainable module. Central to our approach is a lightweight 1D convolutional encoder combined with a learnable differential temporal operator, termed Differentiable Sequence Delta (DSD), which jointly captures short-term spatial context and long-range temporal transitions. The DSD module models directional differences across sequences via a fixed-weight differencing kernel, followed by an LSTM-based refinement and optional residual projection, yielding compact, discriminative descriptors robust to viewpoint and appearance shifts. To further enhance inter-class separability, we incorporate a quadruplet loss that optimizes both positive alignment and multi-negative divergence within each batch. Unlike prior VPR methods that treat temporal aggregation as post-processing, OptiCorNet learns sequence-level embeddings directly, enabling more effective end-to-end place recognition. Comprehensive evaluations on multiple public benchmarks demonstrate that our approach outperforms state-of-the-art baselines under challenging seasonal and viewpoint variations.",
      "authors": [
        "Zhenyu Li",
        "Tianyi Shang",
        "Pengjie Xu",
        "Ruirui Zhang",
        "Fanchen Kong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:29:43+00:00",
          "link": "https://arxiv.org/abs/2507.14477v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14477",
        "HTML": "https://arxiv.org/html/2507.14477",
        "PDF": "https://arxiv.org/pdf/2507.14477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Visual Place Recognition and involves novel sequence modeling using spatial and temporal features, which does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14641",
      "abstract": "This research integrates deep learning, copula functions, and survival analysis to effectively handle highly correlated and right-censored multivariate survival data. It introduces copula-based activation functions (Clayton, Gumbel, and their combinations) to model the nonlinear dependencies inherent in such data. Through simulation studies and analysis of real breast cancer data, our proposed CNN-LSTM with copula-based activation functions for multivariate multi-types of survival responses enhances prediction accuracy by explicitly addressing right-censored data and capturing complex patterns. The model's performance is evaluated using Shewhart control charts, focusing on the average run length (ARL).",
      "authors": [
        "Jong-Min Kim",
        "Il Do Ha",
        "Sangjin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:35:51+00:00",
          "link": "https://arxiv.org/abs/2507.14641v1",
          "size": "8116kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-Based Survival Analysis with Copula-Based Activation Functions for Multivariate Response Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14641",
        "HTML": "https://arxiv.org/html/2507.14641",
        "PDF": "https://arxiv.org/pdf/2507.14641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research integrates deep learning with survival analysis for multivariate prediction, not addressing any LLM training data processing aspects such as dataset creation or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14767",
      "abstract": "Causality helps people reason about and understand complex systems, particularly through what-if analyses that explore how interventions might alter outcomes. Although existing methods embrace causal reasoning using interventions and counterfactual analysis, they primarily focus on effects at the population level. These approaches often fall short in systems characterized by significant heterogeneity, where the impact of an intervention can vary widely across subgroups. To address this challenge, we present XplainAct, a visual analytics framework that supports simulating, explaining, and reasoning interventions at the individual level within subpopulations. We demonstrate the effectiveness of XplainAct through two case studies: investigating opioid-related deaths in epidemiology and analyzing voting inclinations in the presidential election.",
      "authors": [
        "Yanming Zhang",
        "Krishnakumar Hegde",
        "Klaus Mueller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T22:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.14767v1",
          "size": "1221kb",
          "version": "v1"
        }
      ],
      "title": "XplainAct: Visualization for Personalized Intervention Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14767",
        "HTML": "https://arxiv.org/html/2507.14767",
        "PDF": "https://arxiv.org/pdf/2507.14767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a visual analytics framework for individual-level intervention insights but does not contribute to LLM training data processing. It focuses on causal reasoning and visualization within subpopulations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14807",
      "abstract": "Multi-face deepfake videos are becoming increasingly prevalent, often appearing in natural social settings that challenge existing detection methods. Most current approaches excel at single-face detection but struggle in multi-face scenarios, due to a lack of awareness of crucial contextual cues. In this work, we develop a novel approach that leverages human cognition to analyze and defend against multi-face deepfake videos. Through a series of human studies, we systematically examine how people detect deepfake faces in social settings. Our quantitative analysis reveals four key cues humans rely on: scene-motion coherence, inter-face appearance compatibility, interpersonal gaze alignment, and face-body consistency. Guided by these insights, we introduce \\textsf{HICOM}, a novel framework designed to detect every fake face in multi-face scenarios. Extensive experiments on benchmark datasets show that \\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and 2.8\\% under real-world perturbations. Moreover, it outperforms existing methods by 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired cues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM to provide human-readable explanations, making detection results more transparent and convincing. Our work sheds light on involving human factors to enhance defense against deepfakes.",
      "authors": [
        "Juan Hu",
        "Shaojing Fan",
        "Terence Sim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:53:52+00:00",
          "link": "https://arxiv.org/abs/2507.14807v1",
          "size": "5652kb",
          "version": "v1"
        }
      ],
      "title": "Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14807",
        "HTML": "https://arxiv.org/html/2507.14807",
        "PDF": "https://arxiv.org/pdf/2507.14807"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses deepfake detection using human-inspired cues, focusing on interpretability and defense against deepfakes, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15195",
      "abstract": "In this article, we utilize the concept of average controllability in graphs, along with a novel rank encoding method, to enhance the performance of Graph Neural Networks (GNNs) in social network classification tasks. GNNs have proven highly effective in various network-based learning applications and require some form of node features to function. However, their performance is heavily influenced by the expressiveness of these features. In social networks, node features are often unavailable due to privacy constraints or the absence of inherent attributes, making it challenging for GNNs to achieve optimal performance. To address this limitation, we propose two strategies for constructing expressive node features. First, we introduce average controllability along with other centrality metrics (denoted as NCT-EFA) as node-level metrics that capture critical aspects of network topology. Building on this, we develop a rank encoding method that transforms average controllability or any other graph-theoretic metric into a fixed-dimensional feature space, thereby improving feature representation. We conduct extensive numerical evaluations using six benchmark GNN models across four social network datasets to compare different node feature construction methods. Our results demonstrate that incorporating average controllability into the feature space significantly improves GNN performance. Moreover, the proposed rank encoding method outperforms traditional one-hot degree encoding, improving the ROC AUC from 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset, underscoring its effectiveness in generating expressive and efficient node representations.",
      "authors": [
        "Anwar Said",
        "Yifan Wei",
        "Ubaid Ullah Ahmad",
        "Mudassir Shabbir",
        "Waseem Abbas",
        "Xenofon Koutsoukos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:45:55+00:00",
          "link": "https://arxiv.org/abs/2507.15195v1",
          "size": "297kb",
          "version": "v1"
        }
      ],
      "title": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15195",
        "HTML": "https://arxiv.org/html/2507.15195",
        "PDF": "https://arxiv.org/pdf/2507.15195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores feature construction for GNNs using network control theory and rank encoding methods to enhance social network classification tasks, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15378",
      "abstract": "Recent progress in LLMs, such as reasoning models, has demonstrated strong abilities to solve complex competitive programming problems, often rivaling top human competitors. However, it remains underexplored whether these abilities generalize to relevant domains that are less seen during training. To address this, we introduce AlgoSimBench, a new benchmark designed to assess LLMs' ability to identify algorithmically similar problems (ASPs)-problems that can be solved using similar algorithmic approaches. AlgoSimBench consists of 1317 problems, annotated with 231 distinct fine-grained algorithm tags, from which we curate 402 multiple-choice questions (MCQs), where each question presents one algorithmically similar problem alongside three textually similar but algorithmically dissimilar distractors. Our evaluation reveals that LLMs struggle to identify ASPs, with the best-performing model (o3-mini) achieving only 65.9% accuracy on the MCQ task. To address this challenge, we propose attempted solution matching (ASM), a novel method for improving problem similarity detection. On our MCQ task, ASM yields an absolute accuracy improvement of 6.7% to 11.7% across different models. We also evaluated code embedding models and retrieval methods on similar problem identification. While the adversarial selection of problems degrades the performance to be less than random, we found that simply summarizing the problem to remove narrative elements eliminates the effect, and combining ASM with a keyword-prioritized method, BM25, can yield up to 52.2% accuracy. Code and data are available at github.com",
      "authors": [
        "Jierui Li and Raymond Mooney"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:34:20+00:00",
          "link": "https://arxiv.org/abs/2507.15378v1",
          "size": "764kb",
          "version": "v1"
        }
      ],
      "title": "AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15378",
        "HTML": "https://arxiv.org/html/2507.15378",
        "PDF": "https://arxiv.org/pdf/2507.15378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLMs' abilities to identify algorithmically similar problems in competitive programming and proposes a benchmark for this purpose. It does not address LLM training data processing or contribute to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.17655",
      "abstract": "Decentralized Autonomous Organizations (DAOs) have emerged as a novel governance mechanism in blockchain ecosystems, particularly within Decentralized Finance (DeFi). By enabling token holders to propose and vote on protocol changes, these systems promise transparent and equitable decision-making without centralized control. In this paper, we present an in-depth empirical study of the governance protocols of Compound and Uniswap, two of the most widely used DAOs in DeFi. Analyzing over 370 governance proposals and millions of on-chain events from their inception until August 2024, we uncover significant centralization of voting power: as few as 3--5 voters were sufficient to sway the majority of proposals. We also find that the cost of voting disproportionately burdens smaller token holders, and that strategic voting behaviors, such as delayed participation and coalition formation, further distort governance outcomes. Our findings suggest that despite their decentralized ideals, current DAO governance mechanisms fall short in practice.",
      "authors": [
        "Johnnatan Messias and Vabuk Pahari and Balakrishnan Chandrasekaran and Krishna P. Gummadi and Patrick Loiseau"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-28T07:45:33+00:00",
          "link": "https://arxiv.org/abs/2305.17655v1",
          "size": "1339kb",
          "version": "v1"
        },
        {
          "date": "2024-01-04T20:49:50+00:00",
          "link": "https://arxiv.org/abs/2305.17655v2",
          "size": "1353kb",
          "version": "v2"
        },
        {
          "date": "2024-04-21T17:22:40+00:00",
          "link": "https://arxiv.org/abs/2305.17655v3",
          "size": "1408kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T08:57:58+00:00",
          "link": "https://arxiv.org/abs/2305.17655v4",
          "size": "1728kb",
          "version": "v4"
        }
      ],
      "title": "Understanding Blockchain Governance: Analyzing Decentralized Voting to Amend DeFi Smart Contracts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.17655",
        "PDF": "https://arxiv.org/pdf/2305.17655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study conducts an empirical analysis of governance protocols in decentralized finance platforms, focusing on voting and decision-making mechanisms rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10805",
      "abstract": "Establishing the existence of exact or near Markov or stationary perfect Nash equilibria in nonzero-sum Markov games over Borel spaces is a challenging problem with limited positive results. Motivated by problems in multi-agent and Bayesian learning, this paper demonstrates the existence of approximate Markov and stationary Nash equilibria for such games under mild regularity conditions. Our approach is constructive: For both compact and non-compact state spaces, we approximate the Borel model with finite state-action models and show that their equilibria correspond to \\(\\epsilon\\)-equilibria for the original game. Compared with previous results in the literature, which we comprehensively review, we provide more general and complementary conditions, along with explicit approximation models whose equilibria are $\\epsilon$-equilibria for the original model. For completeness, we also study the approximation of zero-sum Markov games and Markov teams to highlight the key differences between zero-sum and nonzero-sum settings. In particular, while for zero-sum and team games, joint weak (Feller) continuity of the transition kernel is sufficient (as the value function is continuous), this is not the case for general nonzero-sum games.",
      "authors": [
        "Naci Saldi",
        "Gurdal Arslan",
        "and Serdar Yuksel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-16T13:49:06+00:00",
          "link": "https://arxiv.org/abs/2411.10805v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T09:47:42+00:00",
          "link": "https://arxiv.org/abs/2411.10805v2",
          "size": "50kb",
          "version": "v2"
        }
      ],
      "title": "Existence of $\\epsilon$-Nash Equilibria in Nonzero-Sum and Zero-Sum Markov Games with Standard Borel Spaces via Finite Model Approximations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10805",
        "PDF": "https://arxiv.org/pdf/2411.10805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on establishing the existence of Nash equilibria in Markov games, which is unrelated to LLM training data processing or any data engineering operations associated with LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09049",
      "abstract": "With the increasing proliferation of mobile applications in our daily lives, the concerns surrounding ethics have surged significantly. Users communicate their feedback in app reviews, frequently emphasizing ethical concerns, such as privacy and security. Incorporating these reviews has proved to be useful for many areas of software engineering (e.g., requirement engineering, testing, etc.). However, app reviews related to ethical concerns generally use domain-specific language and are typically overshadowed by more generic categories of user feedback, such as app reliability and usability. Thus, making automated extraction a challenging and time-consuming effort.\n  This study proposes CMER (A \\underline{C}ontext-Aware Approach for \\underline{M}ining \\underline{E}thical Concern-related App \\underline{R}eviews), a novel approach that combines Natural Language Inference (NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract ethical concern-related app reviews at scale. In CMER, NLI provides domain-specific context awareness by using domain-specific hypotheses, and the Llama-like LLM eliminates the need for labeled data in the classification task. We evaluated the validity of CMER by mining privacy and security-related reviews (PSRs) from the dataset of more than 382K app reviews of mobile investment apps. First, we evaluated four NLI models and compared the results of domain-specific hypotheses with generic hypotheses. Next, we evaluated three LLMs for the classification task. Finally, we combined the best NLI and LLM models (CMER) and extracted 2,178 additional PSRs overlooked by the previous study using a keyword-based approach, thus demonstrating the effectiveness of CMER. These reviews can be further refined into actionable requirement artifacts.",
      "authors": [
        "Aakash Sorathiya and Gouri Ginde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:46:04+00:00",
          "link": "https://arxiv.org/abs/2507.09049v1",
          "size": "231kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:27:14+00:00",
          "link": "https://arxiv.org/abs/2507.09049v2",
          "size": "231kb",
          "version": "v2"
        }
      ],
      "title": "CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09049",
        "HTML": "https://arxiv.org/html/2507.09049",
        "PDF": "https://arxiv.org/pdf/2507.09049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the extraction of ethical concern-related app reviews using CMER, which involves natural language inference and LLMs for classification. It does not directly contribute to LLM training data processing, dataset creation, or improvement in data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11907",
      "abstract": "Many real-world tasks such as recommending videos with the kids tag can be reduced to finding most similar vectors associated with hard predicates. This task, filtered vector search, is challenging as prior state-of-the-art graph-based (unfiltered) similarity search techniques quickly degenerate when hard constraints are considered. That is, effective graph-based filtered similarity search relies on sufficient connectivity for reaching the most similar items within just a few hops. To consider predicates, recent works propose modifying graph traversal to visit only the items that may satisfy predicates. However, they fail to offer the just-a-few-hops property for a wide range of predicates: they must restrict predicates significantly or lose efficiency if only a small fraction of items satisfy predicates.\n  We propose an opposite approach: instead of constraining traversal, we build many indexes each serving different predicate forms. For effective construction, we devise a three-dimensional analytical model capturing relationships among index size, search time, and recall, with which we follow a workload-aware approach to pack as many useful indexes as possible into a collection. At query time, the analytical model is employed yet again to discern the one that offers the fastest search at a given recall. We show superior performance and support on datasets with varying selectivities and forms: our approach achieves up to 8.06x speedup while having as low as 1% build time versus other indexes, with less than 2.15x memory of a standard HNSW graph and modest knowledge of past workloads.",
      "authors": [
        "Zhaoheng Li",
        "Silu Huang",
        "Wei Ding",
        "Yongjoo Park",
        "Jianjun Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T04:46:28+00:00",
          "link": "https://arxiv.org/abs/2507.11907v1",
          "size": "207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:50:39+00:00",
          "link": "https://arxiv.org/abs/2507.11907v2",
          "size": "207kb",
          "version": "v2"
        }
      ],
      "title": "SIEVE: Effective Filtered Vector Search with Collection of Indexes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11907",
        "HTML": "https://arxiv.org/html/2507.11907",
        "PDF": "https://arxiv.org/pdf/2507.11907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an efficient method for filtered vector search using a collection of indexes and does not discuss any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14633",
      "abstract": "The development of satellite-augmented low-altitude economy and terrestrial networks (SLAETNs) demands intelligent and autonomous systems that can operate reliably across heterogeneous, dynamic, and mission-critical environments. To address these challenges, this survey focuses on enabling agentic artificial intelligence (AI), that is, artificial agents capable of perceiving, reasoning, and acting, through generative AI (GAI) and large language models (LLMs). We begin by introducing the architecture and characteristics of SLAETNs, and analyzing the challenges that arise in integrating satellite, aerial, and terrestrial components. Then, we present a model-driven foundation by systematically reviewing five major categories of generative models: variational autoencoders (VAEs), generative adversarial networks (GANs), generative diffusion models (GDMs), transformer-based models (TBMs), and LLMs. Moreover, we provide a comparative analysis to highlight their generative mechanisms, capabilities, and deployment trade-offs within SLAETNs. Building on this foundation, we examine how these models empower agentic functions across three domains: communication enhancement, security and privacy protection, and intelligent satellite tasks. Finally, we outline key future directions for building scalable, adaptive, and trustworthy generative agents in SLAETNs. This survey aims to provide a unified understanding and actionable reference for advancing agentic AI in next-generation integrated networks.",
      "authors": [
        "Xiaozheng Gao",
        "Yichen Wang",
        "Bosen Liu",
        "Xiao Zhou",
        "Ruichen Zhang",
        "Jiacheng Wang",
        "Dusit Niyato",
        "Dong In Kim",
        "Abbas Jamalipour",
        "Chau Yuen",
        "Jianping An",
        "and Kai Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:07:05+00:00",
          "link": "https://arxiv.org/abs/2507.14633v1",
          "size": "1757kb",
          "version": "v1"
        }
      ],
      "title": "Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14633",
        "HTML": "https://arxiv.org/html/2507.14633",
        "PDF": "https://arxiv.org/pdf/2507.14633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey discusses generative approaches and agentic AI for networks but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14688",
      "abstract": "Post-training has emerged as a crucial technique for aligning pre-trained Large Language Models (LLMs) with human instructions, significantly enhancing their performance across a wide range of tasks. Central to this process is the quality and diversity of post-training datasets. This paper presents a review of publicly available Arabic post-training datasets on the Hugging Face Hub, organized along four key dimensions: (1) LLM Capabilities (e.g., Question Answering, Translation, Reasoning, Summarization, Dialogue, Code Generation, and Function Calling); (2) Steerability (e.g., persona and system prompts); (3) Alignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness. Each dataset is rigorously evaluated based on popularity, practical adoption, recency and maintenance, documentation and annotation quality, licensing transparency, and scientific contribution. Our review revealed critical gaps in the development of Arabic post-training datasets, including limited task diversity, inconsistent or missing documentation and annotation, and low adoption across the community. Finally, the paper discusses the implications of these gaps on the progress of Arabic LLMs and applications while providing concrete recommendations for future efforts in post-training dataset development.",
      "authors": [
        "Mohammed Alkhowaiter",
        "Norah Alshahrani",
        "Saied Alshahrani",
        "Reem I. Masoud",
        "Alaa Alzahrani",
        "Deema Alnuhait",
        "Emad A. Alghamdi",
        "Khalid Almubarak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:30:45+00:00",
          "link": "https://arxiv.org/abs/2507.14688v1",
          "size": "2301kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14688",
        "HTML": "https://arxiv.org/html/2507.14688",
        "PDF": "https://arxiv.org/pdf/2507.14688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper reviews Arabic post-training datasets, identifies gaps in task diversity and dataset quality, and provides insights and recommendations for future post-training dataset development, directly contributing to LLM training data processing, particularly in the context of fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.02883",
      "abstract": "Natural language interaction with sensing systems is crucial for addressing users' personal concerns and providing health-related insights into their daily lives. When a user asks a question, the system automatically analyzes the full history of sensor data, extracts relevant information, and generates an appropriate response. However, existing systems are limited to short-duration (e.g., one minute) or low-frequency (e.g., daily step count) sensor data. In addition, they struggle with quantitative questions that require precise numerical answers. In this work, we introduce SensorChat, the first end-to-end QA system designed for daily life monitoring using long-duration, high-frequency time series data. Given raw sensor signals spanning multiple days and a user-defined natural language question, SensorChat generates semantically meaningful responses that directly address user concerns. SensorChat effectively handles both quantitative questions that require numerical precision and qualitative questions that require high-level reasoning to infer subjective insights. To achieve this, SensorChat uses an innovative three-stage pipeline including question decomposition, sensor data query, and answer assembly. The first and third stages leverage Large Language Models (LLMs) to interpret human queries and generate responses. The intermediate querying stage extracts relevant information from the complete sensor data history. Real-world implementations demonstrate SensorChat's capability for real-time interactions on a cloud server while also being able to run entirely on edge platforms after quantization. Comprehensive QA evaluations show that SensorChat achieves 93% higher answer accuracy than the best performing state-of-the-art systems on quantitative questions. Furthermore, a user study with eight volunteers highlights SensorChat's effectiveness in answering qualitative questions.",
      "authors": [
        "Xiaofan Yu",
        "Lanxiang Hu",
        "Benjamin Reichman",
        "Dylan Chu",
        "Rushil Chandrupatla",
        "Xiyuan Zhang",
        "Larry Heck",
        "Tajana Rosing"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T04:41:59+00:00",
          "link": "https://arxiv.org/abs/2502.02883v1",
          "size": "10565kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T06:31:41+00:00",
          "link": "https://arxiv.org/abs/2502.02883v2",
          "size": "12752kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T23:00:52+00:00",
          "link": "https://arxiv.org/abs/2502.02883v3",
          "size": "5816kb",
          "version": "v3"
        }
      ],
      "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02883",
        "HTML": "https://arxiv.org/html/2502.02883",
        "PDF": "https://arxiv.org/pdf/2502.02883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces SensorChat, a QA system for handling long-term sensor data, and utilizes LLMs for query interpretation and response generation. However, it focuses on sensor interaction rather than LLM training data processing."
      },
      "tasks": [
        "Quantization",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04790",
      "abstract": "Motion planning is a crucial component of autonomous robot driving. While various trajectory datasets exist, effectively utilizing them for a target domain remains challenging due to differences in agent interactions and environmental characteristics. Conventional approaches, such as domain adaptation or ensemble learning, leverage multiple source datasets but suffer from domain imbalance, catastrophic forgetting, and high computational costs. To address these challenges, we propose Interaction-Merged Motion Planning (IMMP), a novel approach that leverages parameter checkpoints trained on different domains during adaptation to the target domain. IMMP follows a two-step process: pre-merging to capture agent behaviors and interactions, sufficiently extracting diverse information from the source domain, followed by merging to construct an adaptable model that efficiently transfers diverse interactions to the target domain. Our method is evaluated on various planning benchmarks and models, demonstrating superior performance compared to conventional approaches.",
      "authors": [
        "Giwon Lee",
        "Wooseong Jeong",
        "Daehee Park",
        "Jaewoo Jeong",
        "and Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T09:11:45+00:00",
          "link": "https://arxiv.org/abs/2507.04790v1",
          "size": "2781kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:46:21+00:00",
          "link": "https://arxiv.org/abs/2507.04790v2",
          "size": "2782kb",
          "version": "v2"
        }
      ],
      "title": "Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04790",
        "PDF": "https://arxiv.org/pdf/2507.04790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel approach for motion planning in autonomous driving by leveraging diverse motion datasets. It does not involve training data processing for language models or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14148",
      "abstract": "The integration of Optical Intelligent Reflective Surfaces (OIRSs) into Visible Light Communication (VLC) systems is gaining momentum as a valid alternative to RF technologies, harnessing the existing lighting infrastructures and the vast unlicensed optical spectrum to enable higher spectral efficiency, improved resilience to Line-of-Sight (LoS) blockages, and enhanced positioning capabilities. This paper investigates the problem of localizing a low-cost Photo Detector (PD) in a VLC-based indoor environment consisting of only a single Light Emitting Diode (LED) as an active anchor, and multiple spatially distributed single-element OIRSs. We formulate the problem within an indirect, computationally efficient localization framework: first, the optimal Maximum Likelihood (ML) estimators of the LoS and Non-Line-of-Sight (NLoS) distances are derived, using a suitable OIRS activation strategy to prevent interferences. To overcome the grid-based optimization required by the ML NLoS estimator, we devise a novel algorithm based on an unstructured noise variance transformation, which admits a closed-form solution. The set of estimated LoS/NLoS distances are then used within a low-complexity localization algorithm combining an Iterative Weighted Least Squares (IWLS) procedure, whose weights are set according to the inverse of the Cram\\'er-Rao Lower Bound (CRLB), with an adaptive beam steering strategy that allows the OIRSs network to dynamically align with the PD, without any prior knowledge of its position. Accordingly, we derive the CRLB for both LoS/NLoS distance estimation and PD position estimation. Simulation results demonstrate the effectiveness of our approach in terms of localization accuracy, robustness against OIRSs misalignment conditions, and low number of iterations required to attain the theoretical bounds.",
      "authors": [
        "Daniele Pugliese",
        "Giovanni Iacovelli",
        "Alessio Fascista",
        "Domenico Striccoli",
        "Oleksandr Romanov",
        "Luigi Alfredo Grieco and Gennaro Boggia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T16:49:04+00:00",
          "link": "https://arxiv.org/abs/2507.14148v1",
          "size": "6353kb",
          "version": "v1"
        }
      ],
      "title": "Visible Light Indoor Positioning with a Single LED and Distributed Single-Element OIRS: An Iterative Approach with Adaptive Beam Steering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14148",
        "PDF": "https://arxiv.org/pdf/2507.14148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates a localization problem using optical communications and does not involve LLM training data processing-related activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14180",
      "abstract": "In line with the AI-native 6G vision, explainability and robustness are crucial for building trust and ensuring reliable performance in millimeter-wave (mmWave) systems. Efficient beam alignment is essential for initial access, but deep learning (DL) solutions face challenges, including high data collection overhead, hardware constraints, lack of explainability, and susceptibility to adversarial attacks. This paper proposes a robust and explainable DL-based beam alignment engine (BAE) for mmWave multiple-input multiple output (MIMO) systems. The BAE uses received signal strength indicator (RSSI) measurements from wide beams to predict the best narrow beam, reducing the overhead of exhaustive beam sweeping. To overcome the challenge of real-world data collection, this work leverages a site-specific digital twin (DT) to generate synthetic channel data closely resembling real-world environments. A model refinement via transfer learning is proposed to fine-tune the pre-trained model residing in the DT with minimal real-world data, effectively bridging mismatches between the digital replica and real-world environments. To reduce beam training overhead and enhance transparency, the framework uses deep Shapley additive explanations (SHAP) to rank input features by importance, prioritizing key spatial directions and minimizing beam sweeping. It also incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a credibility metric for detecting out-of-distribution inputs and ensuring robust, transparent decision-making. Experimental results show that the proposed framework reduces real-world data needs by 70%, beam training overhead by 62%, and improves outlier detection robustness by up to 8.5x, achieving near-optimal spectral efficiency and transparent decision making compared to traditional softmax based DL models.",
      "authors": [
        "Nasir Khan",
        "Asmaa Abdallah",
        "Abdulkadir Celik",
        "Ahmed M. Eltawil and Sinem Coleri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T09:56:20+00:00",
          "link": "https://arxiv.org/abs/2507.14180v1",
          "size": "5875kb",
          "version": "v1"
        }
      ],
      "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14180",
        "HTML": "https://arxiv.org/html/2507.14180",
        "PDF": "https://arxiv.org/pdf/2507.14180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on explainable AI for beam prediction in mmWave MIMO systems and does not address LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14542",
      "abstract": "High-frequency oscillations (HFOs) in intracranial Electroencephalography (iEEG) are critical biomarkers for localizing the epileptogenic zone in epilepsy treatment. However, traditional rule-based detectors for HFOs suffer from unsatisfactory precision, producing false positives that require time-consuming manual review. Supervised machine learning approaches have been used to classify the detection results, yet they typically depend on labeled datasets, which are difficult to acquire due to the need for specialized expertise. Moreover, accurate labeling of HFOs is challenging due to low inter-rater reliability and inconsistent annotation practices across institutions. The lack of a clear consensus on what constitutes a pathological HFO further challenges supervised refinement approaches. To address this, we leverage the insight that legacy detectors reliably capture clinically relevant signals despite their relatively high false positive rates. We thus propose the Self-Supervised to Label Discovery (SS2LD) framework to refine the large set of candidate events generated by legacy detectors into a precise set of pathological HFOs. SS2LD employs a variational autoencoder (VAE) for morphological pre-training to learn meaningful latent representation of the detected events. These representations are clustered to derive weak supervision for pathological events. A classifier then uses this supervision to refine detection boundaries, trained on real and VAE-augmented data. Evaluated on large multi-institutional interictal iEEG datasets, SS2LD outperforms state-of-the-art methods. SS2LD offers a scalable, label-efficient, and clinically effective strategy to identify pathological HFOs using legacy detectors.",
      "authors": [
        "Yipeng Zhang",
        "Yuanyi Ding",
        "Chenda Duan",
        "Atsuro Daida",
        "Hiroki Nariai",
        "Vwani Roychowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:01:13+00:00",
          "link": "https://arxiv.org/abs/2507.14542v1",
          "size": "1920kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Distillation of Legacy Rule-Based Methods for Enhanced EEG-Based Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14542",
        "HTML": "https://arxiv.org/html/2507.14542",
        "PDF": "https://arxiv.org/pdf/2507.14542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses enhancing EEG-based decision-making with a self-supervised method and does not address LLM training data processing or related topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2110.03781",
      "abstract": "In today's day and age, a mobile phone has become a basic requirement needed for anyone to thrive. With the cellular traffic demand increasing so dramatically, it is now necessary to accurately predict the user traffic in cellular networks, so as to improve the performance in terms of resource allocation and utilisation. Since traffic learning and prediction is a classical and appealing field, which still yields many meaningful results, there has been an increasing interest in leveraging Machine Learning tools to analyse the total traffic served in a given region, to optimise the operation of the network. With the help of this project, we seek to exploit the traffic history by using it to predict the nature and occurrence of future traffic. Furthermore, we classify the traffic into particular application types, to increase our understanding of the nature of the traffic. By leveraging the power of machine learning and identifying its usefulness in the field of cellular networks we try to achieve three main objectives - classification of the application generating the traffic, prediction of packet arrival intensity and burst occurrence. The design of the prediction and classification system is done using Long Short Term Memory (LSTM) model. The LSTM predictor developed in this experiment would return the number of uplink packets and also estimate the probability of burst occurrence in the specified future time interval. For the purpose of classification, the regression layer in our LSTM prediction model is replaced by a softmax classifier which is used to classify the application generating the cellular traffic into one of the four applications including surfing, video calling, voice calling, and video streaming.",
      "authors": [
        "Nikhil Nayak",
        "Rujula Singh R",
        "Rameshwar Garg",
        "Varun Danda",
        "Chandana Kiran",
        "Kaustuv Saha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2021-10-07T20:24:34+00:00",
          "link": "https://arxiv.org/abs/2110.03781v1",
          "size": "359kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T10:28:28+00:00",
          "link": "https://arxiv.org/abs/2110.03781v2",
          "size": "283kb",
          "version": "v2"
        }
      ],
      "title": "5G Traffic Prediction with Time Series Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.03781",
        "HTML": "https://arxiv.org/html/2110.03781",
        "PDF": "https://arxiv.org/pdf/2110.03781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about traffic prediction in cellular networks using machine learning models. It does not address LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Prediction",
        "Time Series",
        "Time Series Analysis",
        "Traffic Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03350",
      "abstract": "Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning.",
      "authors": [
        "Ziyan Li and Naoki Hiratani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T16:43:58+00:00",
          "link": "https://arxiv.org/abs/2502.03350v1",
          "size": "2677kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:26:04+00:00",
          "link": "https://arxiv.org/abs/2502.03350v2",
          "size": "3093kb",
          "version": "v2"
        }
      ],
      "title": "Optimal Task Order for Continual Learning of Multiple Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03350",
        "HTML": "https://arxiv.org/html/2502.03350",
        "PDF": "https://arxiv.org/pdf/2502.03350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the task order optimization in continual learning, focusing on task similarity and arrangement for improved learning but does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14205",
      "abstract": "We propose an integrated architecture combining Software-Defined Wireless Mesh Networks (SDWMN), Direct-to-Mobile (D2M) broadcasting, and Kafka-based hybrid cloud streaming to improve wireless network performance in both urban and rural settings. The approach addresses urban congestion and rural digital exclusion through traffic offloading, enhanced fault tolerance, and equitable resource allocation. We model urban congestion $\\rho_u = \\lambda_t / \\mu_c$ and rural coverage deficit $\\delta_r = 1 - C_r / C_{req}$, and aim to minimize global performance loss $GPL = w_1 \\cdot \\rho_u + w_2 \\cdot \\delta_r + w_3 \\cdot T_{rec}$, where $T_{rec}$ is recovery time. Experiments in Bangkok, Mumbai, and rural Finland demonstrate latency reduction over 32%, bandwidth offloading of 40%, rural coverage gain of 28%, and fairness index rising from 0.78 to 0.91. The system achieves recovery under 10 s using SDWMN and Kafka. We recommend optimal spectrum allocation $\\alpha_s$, targeted subsidies, and device mandates to promote adoption. This scalable, fault-tolerant design supports equitable digital transformation and suggests directions for future research.",
      "authors": [
        "Pavel Malinovskiy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:34:39+00:00",
          "link": "https://arxiv.org/abs/2507.14205v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "A Fault-Tolerant Architecture for Urban and Rural Digital Connectivity: Synergizing SDWMN, Direct-to-Mobile Broadcasting, and Hybrid Cloud Streaming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14205",
        "HTML": "https://arxiv.org/html/2507.14205",
        "PDF": "https://arxiv.org/pdf/2507.14205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving wireless network performance through a fault-tolerant architecture, which is unrelated to LLM training data processing, dataset creation, or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15168",
      "abstract": "Ultrasound imaging, as a noninvasive, real-time, and low-cost modality, plays a vital role in clinical diagnosis, catheterization intervention, and portable devices. With the development of transducer hardware and the continuous progress of imaging algorithms, how to realize high-quality image reconstruction in different application scenarios has become a research focus.This project focuses on the systematic research and implementation of three typical ultrasound imaging modalities - line array imaging, endoscopic imaging and plane wave imaging, covering simulation data processing, imaging algorithm implementation and real data validation, etc., aiming to deepen the understanding of the principles and processes of various types of imaging.",
      "authors": [
        "Xuyang Chen",
        "Mingtong Chen",
        "Zhengbao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T00:59:11+00:00",
          "link": "https://arxiv.org/abs/2507.15168v1",
          "size": "1663kb",
          "version": "v1"
        }
      ],
      "title": "Exploration and Comparison: Development and Implementation of Multiple Ultrasound Imaging Modalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15168",
        "HTML": "https://arxiv.org/html/2507.15168",
        "PDF": "https://arxiv.org/pdf/2507.15168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on ultrasound imaging modalities and the development of imaging algorithms, not on LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15365",
      "abstract": "The state of the art in human-centric computer vision achieves high accuracy and robustness across a diverse range of tasks. The most effective models in this domain have billions of parameters, thus requiring extremely large datasets, expensive training regimes, and compute-intensive inference. In this paper, we demonstrate that it is possible to train models on much smaller but high-fidelity synthetic datasets, with no loss in accuracy and higher efficiency. Using synthetic training data provides us with excellent levels of detail and perfect labels, while providing strong guarantees for data provenance, usage rights, and user consent. Procedural data synthesis also provides us with explicit control on data diversity, that we can use to address unfairness in the models we train. Extensive quantitative assessment on real input images demonstrates accuracy of our models on three dense prediction tasks: depth estimation, surface normal estimation, and soft foreground segmentation. Our models require only a fraction of the cost of training and inference when compared with foundational models of similar accuracy. Our human-centric synthetic dataset and trained models are available at https://aka.ms/DAViD.",
      "authors": [
        "Fatemeh Saleh",
        "Sadegh Aliakbarian",
        "Charlie Hewitt",
        "Lohit Petikam",
        "Xiao-Xian",
        "Antonio Criminisi",
        "Thomas J. Cashman",
        "Tadas Baltru\\v{s}aitis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:17:41+00:00",
          "link": "https://arxiv.org/abs/2507.15365v1",
          "size": "43303kb",
          "version": "v1"
        }
      ],
      "title": "DAViD: Data-efficient and Accurate Vision Models from Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15365",
        "HTML": "https://arxiv.org/html/2507.15365",
        "PDF": "https://arxiv.org/pdf/2507.15365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on training vision models using synthetic data for human-centric computer vision tasks, not on LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15604",
      "abstract": "As the availability of cobots increases, it is essential to address the needs of users with little to no programming knowledge to operate such systems efficiently. Programming concepts often use intuitive interaction modalities, such as hand guiding, to address this. When programming in-contact motions, such frameworks require knowledge of the robot tool's payload inertial parameters (PIP) in addition to the demonstrated velocities and forces to ensure effective hybrid motion-force control. This paper aims to enable non-expert users to program in-contact motions more efficiently by eliminating the need for a dedicated PIP calibration, thereby enabling flexible robot tool changes. Since demonstrated tasks generally also contain motions with non-contact, our approach uses these parts to estimate the robot's PIP using established estimation techniques. The results show that the estimation of the payload's mass is accurate, whereas the center of mass and the inertia tensor are affected by noise and a lack of excitation. Overall, these findings show the feasibility of PIP estimation during hand guiding but also highlight the need for sufficient payload accelerations for an accurate estimation.",
      "authors": [
        "Johannes Hartwig and Philipp Lienhardt and Dominik Henrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:27:04+00:00",
          "link": "https://arxiv.org/abs/2507.15604v1",
          "size": "803kb",
          "version": "v1"
        }
      ],
      "title": "Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15604",
        "HTML": "https://arxiv.org/html/2507.15604",
        "PDF": "https://arxiv.org/pdf/2507.15604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating payload inertial parameters for programming robot motions, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.02543",
      "abstract": "The popular frameworks for self-supervised learning of speech representations have largely focused on frame-level masked prediction of speech regions. While this has shown promising downstream task performance for speech recognition and related tasks, this has largely ignored factors of speech that are encoded at coarser level, like characteristics of the speaker or channel that remain consistent through-out a speech utterance. In this work, we propose a framework for Learning Disentangled Self Supervised (termed as Learn2Diss) representations of speech, which consists of frame-level and an utterance-level encoder modules. The two encoders are initially learned independently, where the frame-level model is largely inspired by existing self supervision techniques, thereby learning pseudo-phonemic representations, while the utterance-level encoder is inspired by constrastive learning of pooled embeddings, thereby learning pseudo-speaker representations. The joint learning of these two modules consists of disentangling the two encoders using a mutual information based criterion. With several downstream evaluation experiments, we show that the proposed Learn2Diss achieves state-of-the-art results on a variety of tasks, with the frame-level encoder representations improving semantic tasks, while the utterance-level representations improve non-semantic tasks.",
      "authors": [
        "Varun Krishna and Sriram Ganapathy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-02T07:13:35+00:00",
          "link": "https://arxiv.org/abs/2407.02543v1",
          "size": "1591kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:26:06+00:00",
          "link": "https://arxiv.org/abs/2407.02543v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Towards the Next Frontier in Speech Representation Learning Using Disentanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02543",
        "HTML": "https://arxiv.org/html/2407.02543",
        "PDF": "https://arxiv.org/pdf/2407.02543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is related to speech representation learning through disentangled self-supervised learning frameworks. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Disentanglement",
        "Representation Learning",
        "Self-Supervised Learning",
        "speech-recognition",
        "Speech Recognition",
        "Speech Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14452",
      "abstract": "The accurate identification of high-quality correspondences is a prerequisite task in feature-based point cloud registration. However, it is extremely challenging to handle the fusion of local and global features due to feature redundancy and complex spatial relationships. Given that Gestalt principles provide key advantages in analyzing local and global relationships, we propose a novel Gestalt-guided Parallel Interaction Network via orthogonal geometric consistency (GPI-Net) in this paper. It utilizes Gestalt principles to facilitate complementary communication between local and global information. Specifically, we introduce an orthogonal integration strategy to optimally reduce redundant information and generate a more compact global structure for high-quality correspondences. To capture geometric features in correspondences, we leverage a Gestalt Feature Attention (GFA) block through a hybrid utilization of self-attention and cross-attention mechanisms. Furthermore, to facilitate the integration of local detail information into the global structure, we design an innovative Dual-path Multi-Granularity parallel interaction aggregation (DMG) block to promote information exchange across different granularities. Extensive experiments on various challenging tasks demonstrate the superior performance of our proposed GPI-Net in comparison to existing methods. The code will be released at https://github.com/gwk/GPI-Net.",
      "authors": [
        "Weikang Gu",
        "Mingyue Han",
        "Li Xue",
        "Heng Dong",
        "Changcai Yang",
        "Riqing Chen",
        "and Lifang Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.14452v1",
          "size": "3371kb",
          "version": "v1"
        }
      ],
      "title": "GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14452",
        "HTML": "https://arxiv.org/html/2507.14452",
        "PDF": "https://arxiv.org/pdf/2507.14452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods related to point cloud registration using Gestalt principles and focuses on feature-based techniques for geometric consistency, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15602",
      "abstract": "Surface reconstruction and novel view rendering from sparse-view images are challenging. Signed Distance Function (SDF)-based methods struggle with fine details, while 3D Gaussian Splatting (3DGS)-based approaches lack global geometry coherence. We propose a novel hybrid method that combines the strengths of both approaches: SDF captures coarse geometry to enhance 3DGS-based rendering, while newly rendered images from 3DGS refine the details of SDF for accurate surface reconstruction. As a result, our method surpasses state-of-the-art approaches in surface reconstruction and novel view synthesis on the DTU and MobileBrick datasets. Code will be released at https://github.com/Gaozihui/SurfaceSplat.",
      "authors": [
        "Zihui Gao",
        "Jia-Wang Bian",
        "Guosheng Lin",
        "Hao Chen",
        "Chunhua Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:25:03+00:00",
          "link": "https://arxiv.org/abs/2507.15602v1",
          "size": "26086kb",
          "version": "v1"
        }
      ],
      "title": "SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15602",
        "HTML": "https://arxiv.org/html/2507.15602",
        "PDF": "https://arxiv.org/pdf/2507.15602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new method for surface reconstruction and view synthesis using SDF and 3DGS. It is not related to LLM training data processing, pretraining, or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15707",
      "abstract": "Large Language Models (LLMs) have been evaluated using diverse question types, e.g., multiple-choice, true/false, and short/long answers. This study answers an unexplored question about the impact of different question types on LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on three different types of questions using quantitative and deductive reasoning tasks. The performance metrics include accuracy in the reasoning steps and choosing the final answer. Key Findings: (1) Significant differences exist in LLM performance across different question types. (2) Reasoning accuracy does not necessarily correlate with the final selection accuracy. (3) The number of options and the choice of words, influence LLM performance.",
      "authors": [
        "Seok Hwan Song",
        "Mohna Chakraborty",
        "Qi Li",
        "Wallapak Tavanapong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:15:30+00:00",
          "link": "https://arxiv.org/abs/2507.15707v1",
          "size": "1800kb",
          "version": "v1"
        }
      ],
      "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15707",
        "HTML": "https://arxiv.org/html/2507.15707",
        "PDF": "https://arxiv.org/pdf/2507.15707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines how different question types affect LLM performance on reasoning tasks, which is centered around evaluation rather than any data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09309",
      "abstract": "Optimal path planning in nonconvex free spaces is notoriously challenging, as formulating such problems as mixed-integer linear programs (MILPs) is NP-hard. We propose HZ-MP, an informed Hybrid Zonotope-based Motion Planner, as an alternative approach that decomposes the obstacle-free space and performs low-dimensional face sampling guided by an ellipsotope heuristic, enabling focused exploration along promising transit regions. This structured exploration eliminates the excessive, unreachable sampling that degrades existing informed planners such as AIT* and EIT* in narrow gaps or boxed-goal scenarios. We prove that HZ-MP is probabilistically complete and asymptotically optimal. It converges to near-optimal trajectories in finite time and scales to high-dimensional cluttered scenes.",
      "authors": [
        "Peng Xie",
        "Johannes Betz",
        "Amr Alanwar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:54:46+00:00",
          "link": "https://arxiv.org/abs/2507.09309v1",
          "size": "366kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:13:29+00:00",
          "link": "https://arxiv.org/abs/2507.09309v2",
          "size": "366kb",
          "version": "v2"
        }
      ],
      "title": "Informed Hybrid Zonotope-based Motion Planning Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09309",
        "HTML": "https://arxiv.org/html/2507.09309",
        "PDF": "https://arxiv.org/pdf/2507.09309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes HZ-MP, a motion planning algorithm dealing with optimal path planning in non-convex spaces. It does not discuss LLM training data processing or dataset-related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10880",
      "abstract": "Every day, multinational firms process thousands of transactions, each of which must adhere to tax regulations that vary by jurisdiction and are often nuanced. The determination of product and service tax codes, such as HSN or SAC is a major use case in Tax compliance. An accurate determination of such codes is imperative to avoid any tax penalties. This paper proposes a domain-adaptive small language model (SLM) with an encoder-decoder architecture for the enhanced prediction of product and service tax codes. In this approach, we address the problem of predicting hierarchical tax code sequences using unstructured product and services data. We employ an SLM based upon encoder-decoder architecture as this enables sequential generation of tax codes to capture the hierarchical dependencies present within the tax codes. Our experiments demonstrate that encoder-decoder SLMs can be successfully applied to the sequential prediction of structured tax codes, a domain that remains comparatively unexplored in current NLP research. In this paper, we demonstrate the superior performance of the domain-adaptive encoder-decoder SLMs over flat classifiers when applied to the Harmonized System of Nomenclature (HSN), and achieve superior results compared to decoder-only and encoder-only architectures for structured sequence generation tasks. This approach can also be scaled to other government-mandated tax commodity codes, such as United Nations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura Comum do Mercosul (NCM).",
      "authors": [
        "Souvik Nath",
        "Sumit Wadhwa",
        "Luis Perez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:46:01+00:00",
          "link": "https://arxiv.org/abs/2507.10880v1",
          "size": "541kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T21:12:12+00:00",
          "link": "https://arxiv.org/abs/2507.10880v2",
          "size": "541kb",
          "version": "v2"
        }
      ],
      "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10880",
        "HTML": "https://arxiv.org/html/2507.10880",
        "PDF": "https://arxiv.org/pdf/2507.10880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses domain-adaptive language models for structured tax code prediction, focusing on the prediction of hierarchical tax codes rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13023",
      "abstract": "This paper provides a comprehensive empirical analysis of the economics and dynamics behind arbitrages between centralized and decentralized exchanges (CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions from on-chain data and introduce a robust empirical framework to estimate arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging an extensive dataset spanning 19 months from August 2023 to March 2025, we estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from 7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing centralization trends as three searchers captured three-quarters of both volume and extracted value. We also demonstrate that searchers' profitability is tied to their integration level with block builders and uncover exclusive searcher-builder relationships and their market impact. Finally, we correct the previously underestimated profitability of block builders who vertically integrate with a searcher. These insights illuminate the darkest corner of the MEV landscape and highlight the critical implications of CEX-DEX arbitrages for Ethereum's decentralization.",
      "authors": [
        "Fei Wu",
        "Danning Sui",
        "Thomas Thiery",
        "Mallesh Pai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Trading and Market Microstructure (q-fin.TR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:50:42+00:00",
          "link": "https://arxiv.org/abs/2507.13023v1",
          "size": "7167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:27:04+00:00",
          "link": "https://arxiv.org/abs/2507.13023v2",
          "size": "7167kb",
          "version": "v2"
        }
      ],
      "title": "Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13023",
        "HTML": "https://arxiv.org/html/2507.13023",
        "PDF": "https://arxiv.org/pdf/2507.13023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes arbitrage in Ethereum exchanges and the economics of CEX-DEX without discussing any aspects of language model training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14686",
      "abstract": "Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot abilities but struggle with complex Grounded Situation Recognition (GSR) and are resource-intensive for edge device deployment. Meanwhile, conventional GSR models often lack generalization ability, falling short in recognizing unseen and rare situations. In this paper, we exploit transferring knowledge from a teacher MLLM to a small GSR model to enhance its generalization and zero-shot abilities, thereby introducing the task of Open-vocabulary Grounded Situation Recognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt Distillation (MIPD), a novel framework that distills enriched multimodal knowledge from the foundation model, enabling the student Ov-GSR model to recognize unseen situations and be better aware of rare situations. Specifically, the MIPD framework first leverages the LLM-based Judgmental Rationales Generator (JRG) to construct positive and negative glimpse and gaze rationales enriched with contextual semantic information. The proposed scene-aware and instance-perception prompts are then introduced to align rationales with visual information from the MLLM teacher via the Negative-Guided Multimodal Prompting Alignment (NMPA) module, effectively capturing holistic and perceptual multimodal knowledge. Finally, the aligned multimodal knowledge is distilled into the student Ov-GSR model, providing a stronger foundation for generalization that enhances situation understanding, bridges the gap between seen and unseen scenarios, and mitigates prediction bias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving superior performance on seen, rare, and unseen situations, and further demonstrate improved unseen detection on the HICO-DET dataset.",
      "authors": [
        "Chen Cai",
        "Tianyi Liu",
        "Jianjun Gao",
        "Wenyang Liu",
        "Kejun Wu",
        "Ruoyu Wang",
        "Yi Wang",
        "Soo Chin Liew"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:29:02+00:00",
          "link": "https://arxiv.org/abs/2507.14686v1",
          "size": "709kb",
          "version": "v1"
        }
      ],
      "title": "From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14686",
        "HTML": "https://arxiv.org/html/2507.14686",
        "PDF": "https://arxiv.org/pdf/2507.14686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a new framework for distilling knowledge from multimodal LLMs to enhance a grounded situation recognition model but focuses more on model performance and architecture than on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15312",
      "abstract": "In this paper, we continue the research on the power of contextual grammars with selection languages from  subfamilies of the family of regular languages.  We investigate infix-, prefix-, and suffix-closed languages (referred to as idefix-closed languages) and compare such language families to some other subregular families of languages (finite, monoidal, nilpotent, combinational, (symmetric) definite, ordered, non-counting,  power-separating, commutative, circular, union-free, star, and comet languages). Further, we compare the families of the hierarchies obtained for external and internal contextual grammars with the language families defined by these new types for the selection. In this way, we extend the existing hierarchies by new language families. Moreover, we solve an open problem regarding internal contextual grammars with suffix-closed selection languages.",
      "authors": [
        "Marvin K\\\"odding",
        "Bianca Truthe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:14:33+00:00",
          "link": "https://arxiv.org/abs/2507.15312v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Idefix-Closed Languages and Their Application in Contextual Grammars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15312",
        "PDF": "https://arxiv.org/pdf/2507.15312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores idefix-closed languages in the context of contextual grammars, which does not pertain to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.14620",
      "abstract": "The quest for analytical solutions to differential equations has traditionally been constrained by the need for extensive mathematical expertise. Machine learning methods like genetic algorithms have shown promise in this domain, but are hindered by significant computational time and the complexity of their derived solutions. This paper introduces SSDE (Symbolic Solver for Differential Equations), a novel reinforcement learning-based approach that derives symbolic closed-form solutions for various differential equations. Evaluations across a diverse set of ordinary and partial differential equations demonstrate that SSDE outperforms existing machine learning methods, delivering superior accuracy and efficiency in obtaining analytical solutions.",
      "authors": [
        "Shu Wei",
        "Yanjie Li",
        "Lina Yu",
        "Weijun Li",
        "Min Wu",
        "Linjun Sun",
        "Jingyi Liu",
        "Hong Qin",
        "Yusong Deng",
        "Jufeng Han",
        "Yan Pang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-23T14:29:15+00:00",
          "link": "https://arxiv.org/abs/2405.14620v1",
          "size": "4261kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T15:01:34+00:00",
          "link": "https://arxiv.org/abs/2405.14620v2",
          "size": "482kb",
          "version": "v2"
        },
        {
          "date": "2025-05-29T12:40:28+00:00",
          "link": "https://arxiv.org/abs/2405.14620v3",
          "size": "422kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T11:55:39+00:00",
          "link": "https://arxiv.org/abs/2405.14620v4",
          "size": "423kb",
          "version": "v4"
        }
      ],
      "title": "Closed-form Solutions: A New Perspective on Solving Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14620",
        "PDF": "https://arxiv.org/pdf/2405.14620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for solving differential equations and does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Form"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15441",
      "abstract": "Declarative specifications have a vital role to play in developing safe and dependable software systems. Writing specifications correctly, however, remains particularly challenging. This paper presents a controlled experiment on using large language models (LLMs) to write declarative formulas in the well-known language Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write complete Alloy formulas from given natural language descriptions (in English). Two, we employ LLMs to create alternative but equivalent formulas in Alloy with respect to given Alloy formulas. Three, we employ LLMs to complete sketches of Alloy formulas and populate the holes in the sketches by synthesizing Alloy expressions and operators so that the completed formulas accurately represent the desired properties (that are given in natural language). We conduct the experimental evaluation using 11 well-studied subject specifications and employ two popular LLMs, namely ChatGPT and DeepSeek. The experimental results show that the LLMs generally perform well in synthesizing complete Alloy formulas from input properties given in natural language or in Alloy, and are able to enumerate multiple unique solutions. Moreover, the LLMs are also successful at completing given sketches of Alloy formulas with respect to natural language descriptions of desired properties (without requiring test cases). We believe LLMs offer a very exciting advance in our ability to write specifications, and can help make specifications take a pivotal role in software development and enhance our ability to build robust software.",
      "authors": [
        "Yang Hong",
        "Shan Jiang",
        "Yulei Fu",
        "Sarfraz Khurshid"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T13:09:58+00:00",
          "link": "https://arxiv.org/abs/2502.15441v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15441",
        "HTML": "https://arxiv.org/html/2502.15441",
        "PDF": "https://arxiv.org/pdf/2502.15441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using LLMs to write Alloy formulas from natural language and doesn't make any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00302",
      "abstract": "Most materials science datasets are limited to atomic geometries (e.g., XYZ files), restricting their utility for multimodal learning and comprehensive data-centric analysis. These constraints have historically impeded the adoption of advanced machine learning techniques in the field. This work introduces MultiCrystalSpectrumSet (MCS-Set), a curated framework that expands materials datasets by integrating atomic structures with 2D projections and structured textual annotations, including lattice parameters and coordination metrics. MCS-Set enables two key tasks: (1) multimodal property and summary prediction, and (2) constrained crystal generation with partial cluster supervision. Leveraging a human-in-the-loop pipeline, MCS-Set combines domain expertise with standardized descriptors for high-quality annotation. Evaluations using state-of-the-art language and vision-language models reveal substantial modality-specific performance gaps and highlight the importance of annotation quality for generalization. MCS-Set offers a foundation for benchmarking multimodal models, advancing annotation practices, and promoting accessible, versatile materials science datasets. The dataset and implementations are available at https://github.com/KurbanIntelligenceLab/MultiCrystalSpectrumSet.",
      "authors": [
        "Can Polat",
        "Erchin Serpedin",
        "Mustafa Kurban",
        "Hasan Kurban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T23:18:42+00:00",
          "link": "https://arxiv.org/abs/2506.00302v1",
          "size": "3030kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T19:25:44+00:00",
          "link": "https://arxiv.org/abs/2506.00302v2",
          "size": "3016kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Atomic Geometry Representations in Materials Science: A Human-in-the-Loop Multimodal Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00302",
        "HTML": "https://arxiv.org/html/2506.00302",
        "PDF": "https://arxiv.org/pdf/2506.00302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for multimodal datasets in materials science. It does not contribute to LLM training data processing or involve any relevant operations such as data collection, filtering, or dataset creation for LLMs."
      },
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/kurbanintelligencelab/multicrystalspectrumset"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14220",
      "abstract": "This article introduces an advanced space mapping (SM) technique that applies a shared electromagnetic (EM)-based coarse model for multistate tuning-driven multiphysics optimization of tunable filters. The SM method combines the computational efficiency of EM single-physics simulations with the precision of multiphysics simulations. The shared coarse model is based on EM single-physics responses corresponding to various nontunable design parameters values. Conversely, the fine model is implemented to delineate the behavior of multiphysics responses concerning both nontunable and tunable design parameter values. The proposed overall surrogate model comprises multiple subsurrogate models, each consisting of one shared coarse model and two distinct mapping neural networks. The responses from the shared coarse model in the EM single-physics filed offer a suitable approximation for the fine responses in the multiphysics filed, whereas the mapping neural networks facilitate transition from the EM single-physics field to the multiphysics field. Each subsurrogate model maintains consistent nontunable design parameter values but possesses unique tunable design parameter values. By developing multiple subsurrogate models, optimization can be simultaneously performed for each tuning state. Nontunable design parameter values are constrained by all tuning states, whereas tunable design parameter values are confined to their respective tuning states. This optimization technique simultaneously accounts for all the tuning states to fulfill the necessary multiple tuning state requirements. Multiple EM and multiphysics training samples are generated concurrently to develop the surrogate model. Compared with existing direct multiphysics parameterized modeling techniques, our proposed method achieves superior multiphysics modeling accuracy with fewer training samples and reduced computational costs.",
      "authors": [
        "Haitian Hu",
        "Wei Zhang",
        "Feng Feng",
        "Zhiguo Zhang",
        "Qi-Jun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Accelerator Physics (physics.acc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:47:35+00:00",
          "link": "https://arxiv.org/abs/2507.14220v1",
          "size": "8159kb",
          "version": "v1"
        }
      ],
      "title": "Advanced Space Mapping Technique Integrating a Shared Coarse Model for Multistate Tuning-Driven Multiphysics Optimization of Tunable Filters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14220",
        "HTML": "https://arxiv.org/html/2507.14220",
        "PDF": "https://arxiv.org/pdf/2507.14220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an advanced space mapping technique for tuning filters, unrelated to LLM training data processing or any relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14226",
      "abstract": "A scan of 110 AI companion platforms reveals a rapidly growing global market for emotionally engaging, personalized AI interactions. While parasocial use of general-purpose AI (GPAI) tools currently dominates, a growing number of platforms are designed specifically for care, transactional, or romantic companionship. In the UK alone, these platforms receive between 46 million and 91 million monthly visits (1.1--2.2 billion globally), with users spending an average of 3.5 minutes per session. For context, Instagram averaged 67.3 million UK visits per month between January and March 2025. Notably, romantic and sexual AI companions make up 44\\% of UK visits--higher than the global average of 30\\%--but see lower session time and return rates than mixed-use platforms, suggesting unmet demand or quality gaps. As romantic AI offerings improve, increased engagement may follow, raising urgent concerns about online safety, particularly for children, given weak age safeguards. Meanwhile, GPAI tools are moving toward more emotionally intelligent, personalized interactions, making parasocial AI use increasingly mainstream. These trends highlight the need for the UK AI Safety Institute (AISI) to monitor this sector and assess whether existing regulation sufficiently addresses emerging societal risks.",
      "authors": [
        "Zilan Qian",
        "Mari Izumikawa",
        "Fiona Lodge",
        "Angelo Leone"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:01:34+00:00",
          "link": "https://arxiv.org/abs/2507.14226v1",
          "size": "330kb",
          "version": "v1"
        }
      ],
      "title": "Mapping the Parasocial AI Market: User Trends, Engagement and Risks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14226",
        "HTML": "https://arxiv.org/html/2507.14226",
        "PDF": "https://arxiv.org/pdf/2507.14226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes trends and risks of parasocial AI market, particularly AI companions, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14579",
      "abstract": "Detecting collaborative problem solving (CPS) indicators from dialogue using machine learning techniques is a significant challenge for the field of AI in Education. Recent studies have explored the use of Bidirectional Encoder Representations from Transformers (BERT) models on transcription data to reliably detect meaningful CPS indicators. A notable advancement involved the multimodal BERT variant, AudiBERT, which integrates speech and acoustic-prosodic audio features to enhance CPS diagnosis. Although initial results demonstrated multimodal improvements, the statistical significance of these enhancements remained unclear, and there was insufficient guidance on leveraging human-AI complementarity for CPS diagnosis tasks. This workshop paper extends the previous research by highlighting that the AudiBERT model not only improved the classification of classes that were sparse in the dataset, but it also had statistically significant class-wise improvements over the BERT model for classifications in the social-cognitive dimension. However, similar significant class-wise improvements over the BERT model were not observed for classifications in the affective dimension. A correlation analysis highlighted that larger training data was significantly associated with higher recall performance for both the AudiBERT and BERT models. Additionally, the precision of the BERT model was significantly associated with high inter-rater agreement among human coders. When employing the BERT model to diagnose indicators within these subskills that were well-detected by the AudiBERT model, the performance across all indicators was inconsistent. We conclude the paper by outlining a structured approach towards achieving human-AI complementarity for CPS diagnosis, highlighting the crucial inclusion of model explainability to support human agency and engagement in the reflective coding process.",
      "authors": [
        "Kester Wong",
        "Sahan Bulathwela and Mutlu Cukurova"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T11:47:08+00:00",
          "link": "https://arxiv.org/abs/2507.14579v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14579",
        "HTML": "https://arxiv.org/html/2507.14579",
        "PDF": "https://arxiv.org/pdf/2507.14579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores using BERT models for collaborative problem solving diagnosis, with a focus on human-AI complementarity, rather than addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15254",
      "abstract": "The evolution towards future generation of mobile systems and fixed wireless networks is primarily driven by the urgency to support high-bandwidth and low-latency services across various vertical sectors. This endeavor is fueled by smartphones as well as technologies like industrial internet of things, extended reality (XR), and human-to-machine (H2M) collaborations for fostering industrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To ensure an ideal immersive experience and avoid cyber-sickness for users in all the aforementioned usage scenarios, it is typically challenging to synchronize XR content from a remote machine to a human collaborator according to their head movements across a large geographic span in real-time over communication networks. Thus, we propose a novel H2M collaboration scheme where the human's head movements are predicted ahead with highly accurate models like bidirectional long short-term memory networks to orient the machine's camera in advance. We validate that XR frame size varies in accordance with the human's head movements and predict the corresponding bandwidth requirements from the machine's camera to propose a human-machine coordinated dynamic bandwidth allocation (HMC-DBA) scheme. Through extensive simulations, we show that end-to-end latency and jitter requirements of XR frames are satisfied with much lower bandwidth consumption over enterprise networks like Fiber-To-The-Room-Business. Furthermore, we show that better efficiency in network resource utilization is achieved by employing our proposed HMC-DBA over state-of-the-art schemes.",
      "authors": [
        "Sourav Mondal and Elaine Wong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:31:24+00:00",
          "link": "https://arxiv.org/abs/2507.15254v1",
          "size": "1673kb",
          "version": "v1"
        }
      ],
      "title": "User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15254",
        "PDF": "https://arxiv.org/pdf/2507.15254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on predicting head movements for immersive XR experiences over future networks, without any connection to LLM training data processing or enhancing data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15317",
      "abstract": "Deterministic 2-head finite automata which are machines that process an input word from both ends are analyzed for their ability to perform reversible computations. This implies that the automata are backward deterministic, enabling unique forward and backward computation. We explore the computational power of such automata, discovering that, while some regular languages cannot be accepted by these machines, they are capable of accepting some characteristic linear languages, e.g., the language of palindromes. Additionally, we prove that restricted variants, i.e., both 1-limited reversible 2-head finite automata and complete reversible 2-head finite automata are less powerful and they form a proper hierarchy. In the former, in each computation step exactly one input letter is being processed, i.e., only one of the heads can read a letter. These automata are also characterized by putting their states to classes based on the head(s) used to reach and to leave the state. In the complete reversible 2-head finite automata, it is required that any input can be fully read by the automaton. The accepted families are also compared to the classes generated by left deterministic linear grammars.",
      "authors": [
        "Benedek Nagy (Eastern Mediterranean University / Eszterh\\'azy K\\'aroly Catholic University)",
        "Walaa Yasin (Eastern Mediterranean University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:15:40+00:00",
          "link": "https://arxiv.org/abs/2507.15317v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "On some Classes of Reversible 2-head Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15317",
        "PDF": "https://arxiv.org/pdf/2507.15317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes reversible 2-head finite automata for their computational power, which doesn't relate to LLM training data processing or any data engineering operations in the field."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15346",
      "abstract": "Pavement defect detection faces critical challenges including limited annotated data, domain shift between training and deployment environments, and high variability in defect appearances across different road conditions. We propose RoadFusion, a framework that addresses these limitations through synthetic anomaly generation with dual-path feature adaptation. A latent diffusion model synthesizes diverse, realistic defects using text prompts and spatial masks, enabling effective training under data scarcity. Two separate feature adaptors specialize representations for normal and anomalous inputs, improving robustness to domain shift and defect variability. A lightweight discriminator learns to distinguish fine-grained defect patterns at the patch level. Evaluated on six benchmark datasets, RoadFusion achieves consistently strong performance across both classification and localization tasks, setting new state-of-the-art in multiple metrics relevant to real-world road inspection.",
      "authors": [
        "Muhammad Aqeel",
        "Kidus Dagnaw Bellete",
        "Francesco Setti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:01:08+00:00",
          "link": "https://arxiv.org/abs/2507.15346v1",
          "size": "8648kb",
          "version": "v1"
        }
      ],
      "title": "RoadFusion: Latent Diffusion Model for Pavement Defect Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15346",
        "HTML": "https://arxiv.org/html/2507.15346",
        "PDF": "https://arxiv.org/pdf/2507.15346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents RoadFusion for pavement defect detection, which includes synthetic data generation using a latent diffusion model, its primary focus is on the application to defect detection rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15599",
      "abstract": "Large language models for code (Code LLM) are increasingly utilized in programming environments. Despite their utility, the training datasets for top LLM remain undisclosed, raising concerns about potential copyright violations. Some models, such as Pleias and Comma put emphasis on data curation and licenses, however, with limited training data these models are not competitive and only serve as proof of concepts. To improve the utility of these models, we propose an application of the \"Chinese Wall\" technique, inspired by the reverse engineering technique of the same name -- a high quality model is used to generate detailed instructions for a weaker model. By doing so, a weaker but ethically aligned model may be used to perform complicated tasks that, otherwise, can only be completed by more powerful models. In our evaluation, we've found that this technique improves Comma v0.1 1T's performance in CanItEdit benchmark by over 66%, and Starcoder2 Instruct by roughly 20% compared to when running the same model on the benchmark alone. The practical application of this technique today, however, may be limited due to the lack of models trained on public domain content without copyright restrictions.",
      "authors": [
        "Manatsawin Hanmongkolchai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:21:29+00:00",
          "link": "https://arxiv.org/abs/2507.15599v1",
          "size": "148kb",
          "version": "v1"
        }
      ],
      "title": "Applying the Chinese Wall Reverse Engineering Technique to Large Language Model Code Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15599",
        "PDF": "https://arxiv.org/pdf/2507.15599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using the 'Chinese Wall' technique for improving the performance of code-generating language models through reverse engineering. It does not address LLM training data processing operations like data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15641",
      "abstract": "In this paper, we present our submission to the MM-ArgFallacy2025 shared task, which aims to advance research in multimodal argument mining, focusing on logical fallacies in political debates. Our approach uses pretrained Transformer-based models and proposes several ways to leverage context. In the fallacy classification subtask, our models achieved macro F1-scores of 0.4444 (text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed performance comparable to the text-only model, suggesting potential for improvements.",
      "authors": [
        "Alessio Pittiglio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:03:08+00:00",
          "link": "https://arxiv.org/abs/2507.15641v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15641",
        "HTML": "https://arxiv.org/html/2507.15641",
        "PDF": "https://arxiv.org/pdf/2507.15641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multimodal fallacy classification in political debates using pretrained models. It does not cover aspects of training data processing specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15667",
      "abstract": "Every semicomplete multipartite digraph contains a quasi-Hamiltonian path, but the problem of finding a quasi-Hamiltonian path with prescribed start and end vertex is NP-complete even when restricted to semicomplete multipartite digraphs with independence number exactly 3. Bang-Jensen, Wang and Yeo (arXiv 2024) showed that deciding the presence of a quasi-Hamiltonian cycle which does not contain at least one vertex from each color class is NP-complete. Similarly, deciding the presence of a quasi-Hamiltonian cycle which intersects every part exactly once is also NP-complete as shown in the same work.\n  In this paper, we continue the study of paths with constraints on the number of covered vertices from each color class. We consider the problem of finding a path with prescribed start and end vertex that contains at least $a$ and at most $b$ vertices from each color class where all color classes have size exactly $\\alpha$. This unifies the Hamiltonian path problem, the quasi-Hamiltonian path problem and the path-version of the cycle problems mentioned above, among other problems. Using Schaefer's dichotomy theorem, we classify the complexity of almost all problems in our framework. Notable open problems are the Hamiltonian path problem on semicomplete multipartite digraphs as well as the quasi-Hamiltonian path problem restricted to semicomplete multipartite digraphs with independence number 2.\n  We then investigate the quasi-Hamiltonian path problem restricted to semicomplete multipartite digraphs with independence number 2. We generalize sufficient criteria for Hamiltonian $(s,t)$-paths in semicomplete digraphs to sufficient criteria for quasi-Hamiltonian $(s,t)$-paths in this class. Although this does not settle the problem, the initial results suggest that this special case may be solvable in polynomial time.",
      "authors": [
        "Julian Brinkmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:32:47+00:00",
          "link": "https://arxiv.org/abs/2507.15667v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "The Complexity of Color-constrained Paths in Semicomplete Multipartite Digraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15667",
        "HTML": "https://arxiv.org/html/2507.15667",
        "PDF": "https://arxiv.org/pdf/2507.15667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses paths in semicomplete multipartite digraphs, focusing on complexity and path problems, not related to LLM training or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15673",
      "abstract": "Point clouds are a promising video representation for next-generation multimedia experiences in virtual and augmented reality. Point clouds are notoriously high-bitrate, however, which limits the feasibility of live streaming systems. Prior methods have adopted traditional HTTP-based protocols for point cloud streaming, but they rely on explicit client-side adaptation to maintain low latency under congestion. In this work, we leverage the delivery timeout feature within the Media Over QUIC protocol to perform implicit server-side adaptation based on an application's latency target. Through experimentation with several publisher and network configurations, we demonstrate that our system unlocks a unique trade-off on a per-client basis: applications with lower latency requirements will receive lower-quality video, while applications with more relaxed latency requirements will receive higher-quality video.",
      "authors": [
        "Andrew Freeman",
        "Michael Rudolph",
        "Amr Rizk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:36:09+00:00",
          "link": "https://arxiv.org/abs/2507.15673v1",
          "size": "645kb",
          "version": "v1"
        }
      ],
      "title": "Point Cloud Streaming with Latency-Driven Implicit Adaptation using MoQ",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15673",
        "HTML": "https://arxiv.org/html/2507.15673",
        "PDF": "https://arxiv.org/pdf/2507.15673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses point cloud streaming optimization for multimedia experiences, which does not pertain to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05609",
      "abstract": "Ensuring the safety of Generative AI requires a nuanced understanding of pluralistic viewpoints. In this paper, we introduce a novel data-driven approach for interpreting granular ratings in pluralistic datasets. Specifically, we address the challenge of analyzing nuanced differences in safety feedback from a diverse population expressed via ordinal scales (e.g., a Likert scale). We distill non-parametric responsiveness metrics that quantify the consistency of raters in scoring varying levels of the severity of safety violations. Leveraging a publicly available pluralistic dataset of safety feedback on AI-generated content as our case study, we investigate how raters from different demographic groups (age, gender, ethnicity) use an ordinal scale to express their perceptions of the severity of violations. We apply our metrics across violation types, demonstrating their utility in extracting nuanced insights that are crucial for aligning AI systems reliably in multi-cultural contexts. We show that our approach can inform rater selection and feedback interpretation by capturing nuanced viewpoints across different demographic groups, hence improving the quality of pluralistic data collection and in turn contributing to more robust AI development.",
      "authors": [
        "Pushkar Mishra",
        "Charvi Rastogi",
        "Stephen R. Pfohl",
        "Alicia Parrish",
        "Tian Huey Teh",
        "Roma Patel",
        "Mark Diaz",
        "Ding Wang",
        "Michela Paganini",
        "Vinodkumar Prabhakaran",
        "Lora Aroyo",
        "Verena Rieser"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T17:32:31+00:00",
          "link": "https://arxiv.org/abs/2503.05609v1",
          "size": "1906kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T10:34:20+00:00",
          "link": "https://arxiv.org/abs/2503.05609v2",
          "size": "2164kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T17:28:24+00:00",
          "link": "https://arxiv.org/abs/2503.05609v3",
          "size": "2164kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T10:38:03+00:00",
          "link": "https://arxiv.org/abs/2503.05609v4",
          "size": "2164kb",
          "version": "v4"
        }
      ],
      "title": "Decoding Safety Feedback from Diverse Raters: A Data-driven Lens on Responsiveness to Severity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05609",
        "HTML": "https://arxiv.org/html/2503.05609",
        "PDF": "https://arxiv.org/pdf/2503.05609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interpreting safety feedback from diverse raters using a novel data-driven approach. While it deals with data analysis, it does not directly contribute to LLM training data processing operations like data collection or dataset creation for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22693",
      "abstract": "We introduce a new categorical and constructive foundation for analytic approximation based on a Contextual Choice Principle (CCP), which enforces locality and compatibility in the construction of mathematical objects. Central to our approach is the Universal Embedding and Linear Approximation Theorem (UELAT), which establishes that functions in broad spaces -- including C(K), Sobolev spaces W^{k,p}(Omega), and distributions D'(Omega) -- can be explicitly approximated by finite-rank linear projections, each with a constructive, algorithmically verifiable certificate of accuracy.\n  These constructions are governed categorically by a functorial adjunction between local logical probes and analytic models, making analytic existence both formally certifiable and programmatically extractable. As a key result, we prove a uniform certificate stability theorem, ensuring that approximation certificates persist under uniform convergence.\n  The CCP avoids classical pathologies (e.g., non-measurable sets, Banach--Tarski paradoxes) by eliminating non-constructive choice and replacing it with a coherent, local-to-global semantic logic. Our framework strengthens the foundations of constructive analysis while contributing tools relevant to formal verification, type-theoretic proof systems, and computational mathematics.",
      "authors": [
        "Andreu Ballus Santacana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Functional Analysis (math.FA)",
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:26:31+00:00",
          "link": "https://arxiv.org/abs/2506.22693v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T13:00:07+00:00",
          "link": "https://arxiv.org/abs/2506.22693v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "Universal Gluing and Contextual Choice: Categorical Logic and the Foundations of Analytic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22693",
        "HTML": "https://arxiv.org/html/2506.22693",
        "PDF": "https://arxiv.org/pdf/2506.22693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for analytic approximation using categorical logic and does not address LLM training data processing or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14185",
      "abstract": "Latent spaces offer an efficient and effective means of summarizing data while implicitly preserving meta-information through relational encoding. We leverage these meta-embeddings to develop a modality-agnostic, unified encoder. Our method employs sensor-latent fusion to analyze and correlate multimodal physiological signals. Using a compressed sensing approach with autoencoder-based latent space fusion, we address the computational challenges of biosignal analysis on resource-constrained devices. Experimental results show that our unified encoder is significantly faster, lighter, and more scalable than modality-specific alternatives, without compromising representational accuracy.",
      "authors": [
        "Abdullah Ahmed",
        "Jeremy Gummeson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:58:48+00:00",
          "link": "https://arxiv.org/abs/2507.14185v1",
          "size": "1680kb",
          "version": "v1"
        }
      ],
      "title": "Latent Sensor Fusion: Multimedia Learning of Physiological Signals for Resource-Constrained Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14185",
        "HTML": "https://arxiv.org/html/2507.14185",
        "PDF": "https://arxiv.org/pdf/2507.14185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on latent sensor fusion and multimodal physiological signal analysis on resource-constrained devices. It does not pertain to LLM training data processing or any aspect of LLM-related data curation or generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14471",
      "abstract": "Massive strides in deterministic models have been made using synchronous languages. They are mainly focused on centralised applications, as the traditional approach is to compile away the concurrency. Time triggered languages such as Giotto and Lingua Franca are suitable for distribution albeit that they rely on expensive physical clock synchronisation, which is both expensive and may suffer from scalability. Hence, deterministic programming of distributed systems remains challenging. We address the challenges of deterministic distribution by developing a novel multiclock semantics of synchronous programs. The developed semantics is amenable to seamless distribution. Moreover, our programming model, Timetide, alleviates the need for physical clock synchronisation by building on the recently proposed logical synchrony model for distributed systems. We discuss the important aspects of distributing computation, such as network communication delays, and explore the formal verification of Timetide programs. To the best of our knowledge, Timetide is the first multiclock synchronous language that is both amenable to distribution and formal verification without the need for physical clock synchronisation or clock gating.",
      "authors": [
        "Logan Kenwright",
        "Partha Roop",
        "Nathan Allen",
        "C\\u{a}lin Ca\\c{s}caval",
        "Avinash Malik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:04:33+00:00",
          "link": "https://arxiv.org/abs/2507.14471v1",
          "size": "218kb",
          "version": "v1"
        }
      ],
      "title": "Timetide: A programming model for logically synchronous distributed systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14471",
        "HTML": "https://arxiv.org/html/2507.14471",
        "PDF": "https://arxiv.org/pdf/2507.14471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deterministic programming of distributed systems with a novel multiclock semantics. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14743",
      "abstract": "Traffic monitoring is crucial for urban mobility, road safety, and intelligent transportation systems (ITS). Deep learning has advanced video-based traffic monitoring through video question answering (VideoQA) models, enabling structured insight extraction from traffic videos. However, existing VideoQA models struggle with the complexity of real-world traffic scenes, where multiple concurrent events unfold across spatiotemporal dimensions. To address these challenges, this paper introduces \\textbf{InterAct VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of real-world traffic footage collected from diverse intersections, segmented into 10-second video clips, with over 25,000 question-answer (QA) pairs covering spatiotemporal dynamics, vehicle interactions, incident detection, and other critical traffic attributes. State-of-the-art VideoQA models are evaluated on InterAct VideoQA, exposing challenges in reasoning over fine-grained spatiotemporal dependencies within complex traffic scenarios. Additionally, fine-tuning these models on InterAct VideoQA yields notable performance improvements, demonstrating the necessity of domain-specific datasets for VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to facilitate future research in real-world deployable VideoQA models for intelligent transportation systems. GitHub Repo: https://github.com/joe-rabbit/InterAct_VideoQA",
      "authors": [
        "Joseph Raj Vishal",
        "Rutuja Patil",
        "Manas Srinivas Gowda",
        "Katha Naik",
        "Yezhou Yang",
        "Bharatesh Chakravarthi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:30:43+00:00",
          "link": "https://arxiv.org/abs/2507.14743v1",
          "size": "5904kb",
          "version": "v1"
        }
      ],
      "title": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14743",
        "HTML": "https://arxiv.org/html/2507.14743",
        "PDF": "https://arxiv.org/pdf/2507.14743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a dataset for video question answering in traffic monitoring scenarios. While it involves dataset creation, it is specific to the domain of traffic analysis and does not address data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15033",
      "abstract": "Social media was one of the most popular forms of communication among young people with digital access during the pandemic. Consequently, crucial debates and discussions about the pandemic crisis have also developed on social media platforms, making them a great primary source to study the experiences of specific groups and communities during the pandemic. This study involved research using LDA topic modeling and sentiment analysis on data obtained from the social media platform Reddit to understand the themes and attitudes in circulation within five subreddits devoted to LGBTQ+ experiences and issues. In the process, we attempt to make sense of the role that Reddit may have played in the lives of LGBTQ+ people who were online during the pandemic, and whether this was marked by any continuities or discontinuities from before the pandemic period.",
      "authors": [
        "Dhruvee Birla",
        "Nazia Akhtar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:35:37+00:00",
          "link": "https://arxiv.org/abs/2507.15033v1",
          "size": "103kb",
          "version": "v1"
        }
      ],
      "title": "'A Little Bubble of Friends': An Analysis of LGBTQ+ Pandemic Experiences Using Reddit Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15033",
        "HTML": "https://arxiv.org/html/2507.15033",
        "PDF": "https://arxiv.org/pdf/2507.15033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing LGBTQ+ pandemic experiences using Reddit data with topic modeling and sentiment analysis. It does not discuss any LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15147",
      "abstract": "Multi-agent systems (MASs) consisting of a number of autonomous agents that communicate, coordinate, and jointly sense the environment to achieve complex missions can be found in a variety of applications such as robotics, smart cities, and internet-of-things applications. Modeling and monitoring MAS requirements to guarantee overall mission objectives, safety, and reliability is an important problem. Such requirements implicitly require reasoning about diverse sensing and communication modalities between agents, analysis of the dependencies between agent tasks, and the spatial or virtual distance between agents. To capture such rich MAS requirements, we model agent interactions via multiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic with Graph Operators (STL-GO). The key innovation in STL-GO are graph operators that enable us to reason about the number of agents along either the incoming or outgoing edges of the underlying interaction graph that satisfy a given property of interest; for example, the requirement that an agent should sense at least two neighboring agents whose task graphs indicate the ability to collaborate. We then propose novel distributed monitoring conditions for individual agents that use only local information to determine whether or not an STL-GO specification is satisfied. We compare the expressivity of STL-GO against existing spatio-temporal logic formalisms, and demonstrate the utility of STL-GO and our distributed monitors in a bike-sharing and a multi-drone case study.",
      "authors": [
        "Yiqi Zhao",
        "Xinyi Yu",
        "Bardh Hoxha",
        "Georgios Fainekos",
        "Jyotirmoy V. Deshmukh",
        "Lars Lindemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:54:40+00:00",
          "link": "https://arxiv.org/abs/2507.15147v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15147",
        "HTML": "https://arxiv.org/html/2507.15147",
        "PDF": "https://arxiv.org/pdf/2507.15147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new spatio-temporal logic for multi-agent systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15661",
      "abstract": "We establish a strong converse bound for the private classical capacity of anti-degradable quantum channels. Specifically, we prove that this capacity is zero whenever the error $\\epsilon > 0$ and privacy parameter $\\delta > 0$ satisfy the inequality $\\delta (1-\\epsilon^2)^{\\frac{1}{2}}+\\epsilon (1-\\delta^2)^{\\frac{1}{2}}<1$. This result strengthens previous understandings by sharply defining the boundary beyond which reliable and private communication is impossible. Furthermore, we present a ``pretty simple'' proof of the ``pretty strong'' converse for the quantum capacity of anti-degradable channels, valid for any error $\\epsilon < \\frac{1}{\\sqrt{2}}$. Our approach offers clarity and technical simplicity, shedding new light on the fundamental limits of quantum communication.",
      "authors": [
        "Zahra Baghali Khanian and Christoph Hirche"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:22:28+00:00",
          "link": "https://arxiv.org/abs/2507.15661v1",
          "size": "35kb",
          "version": "v1"
        }
      ],
      "title": "On Strong Converse Bounds for the Private and Quantum Capacities of Anti-degradable Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15661",
        "HTML": "https://arxiv.org/html/2507.15661",
        "PDF": "https://arxiv.org/pdf/2507.15661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper establishes bounds for private and quantum capacities of anti-degradable channels, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15710",
      "abstract": "Sampling-based algorithms are widely used for motion planning in high-dimensional configuration spaces. However, due to low sampling efficiency, their performance often diminishes in complex configuration spaces with narrow corridors. Existing approaches address this issue using handcrafted or learned heuristics to guide sampling toward useful regions. Unfortunately, these strategies often lack generalizability to various problems or require extensive prior training. In this paper, we propose a simple yet efficient sampling-based planning framework along with its bidirectional version that overcomes these issues by integrating different levels of planning granularity. Our approach probes configuration spaces with uniform random samples at varying resolutions and explores these multi-resolution samples online with a bias towards sparse samples when traveling large free configuration spaces. By seamlessly transitioning between sparse and dense samples, our approach can navigate complex configuration spaces while maintaining planning speed and completeness. The simulation results demonstrate that our approach outperforms several state-of-the-art sampling-based planners in $\\mathbb{SE}(2)$, $\\mathbb{SE}(3)$, and $\\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments conducted with the Franka Emika Panda robot operating in a constrained workspace provide additional evidence of the superiority of the proposed method.",
      "authors": [
        "Lu Huang",
        "Lingxiao Meng",
        "Jiankun Wang",
        "Xingjian Jing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:17:59+00:00",
          "link": "https://arxiv.org/abs/2507.15710v1",
          "size": "9274kb",
          "version": "v1"
        }
      ],
      "title": "Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15710",
        "HTML": "https://arxiv.org/html/2507.15710",
        "PDF": "https://arxiv.org/pdf/2507.15710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses motion planning in high-dimensional configuration spaces using sampling-based algorithms. It does not pertain to LLM training data processing, but rather focuses on improving sampling efficiency in motion planning contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15809",
      "abstract": "Diffusion models offer stable training and state-of-the-art performance for deep generative modeling tasks. Here, we consider their use in the context of multivariate subsurface modeling and probabilistic inversion. We first demonstrate that diffusion models enhance multivariate modeling capabilities compared to variational autoencoders and generative adversarial networks. In diffusion modeling, the generative process involves a comparatively large number of time steps with update rules that can be modified to account for conditioning data. We propose different corrections to the popular Diffusion Posterior Sampling approach by Chung et al. (2023). In particular, we introduce a likelihood approximation accounting for the noise-contamination that is inherent in diffusion modeling. We assess performance in a multivariate geological scenario involving facies and correlated acoustic impedance. Conditional modeling is demonstrated using both local hard data (well logs) and nonlinear geophysics (fullstack seismic data). Our tests show significantly improved statistical robustness, enhanced sampling of the posterior probability density function and reduced computational costs, compared to the original approach. The method can be used with both hard and indirect conditioning data, individually or simultaneously. As the inversion is included within the diffusion process, it is faster than other methods requiring an outer-loop around the generative model, such as Markov chain Monte Carlo.",
      "authors": [
        "Roberto Miele",
        "Niklas Linde"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:10:16+00:00",
          "link": "https://arxiv.org/abs/2507.15809v1",
          "size": "6993kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion models for multivariate subsurface generation and efficient probabilistic inversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15809",
        "HTML": "https://arxiv.org/html/2507.15809",
        "PDF": "https://arxiv.org/pdf/2507.15809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on diffusion models for subsurface generation and probabilistic inversion in geological scenarios. It does not address LLM training data processing, but rather discusses advancements in generative modeling techniques for a specific scientific domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10440",
      "abstract": "Large language models have demonstrated substantial advancements in reasoning capabilities. However, current Vision-Language Models (VLMs) often struggle to perform systematic and structured reasoning, especially when handling complex visual question-answering tasks. In this work, we introduce LLaVA-CoT, a large VLM designed to conduct autonomous multistage reasoning. Unlike chain-of-thought prompting, LLaVA-CoT independently engages in sequential stages of summarization, visual interpretation, logical reasoning, and conclusion generation. This structured approach enables LLaVA-CoT to achieve marked improvements on reasoning-intensive tasks. To accomplish this, we construct the LLaVA-CoT-100k dataset, integrating samples from various visual question answering sources and providing structured reasoning annotations. Besides, we propose a test-time stage-wise retracing search method (SWIRES), which enables effective and efficient test-time scaling. Remarkably, with only 100k training samples and test-time scaling, LLaVA-CoT not only outperforms its base model by 9.4% on a wide range of multimodal reasoning benchmarks, but also surpasses the performance of larger and even closed-source models, such as Gemini-1.5-pro, GPT-4o-mini, and Llama-3.2-90B-Vision-Instruct. The code, dataset, and pre-trained weights are publicly available at https://github.com/PKU-YuanGroup/LLaVA-CoT.",
      "authors": [
        "Guowei Xu",
        "Peng Jin",
        "Ziang Wu",
        "Hao Li",
        "Yibing Song",
        "Lichao Sun",
        "Li Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T18:58:31+00:00",
          "link": "https://arxiv.org/abs/2411.10440v1",
          "size": "700kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T07:42:20+00:00",
          "link": "https://arxiv.org/abs/2411.10440v2",
          "size": "3492kb",
          "version": "v2"
        },
        {
          "date": "2025-01-09T07:58:20+00:00",
          "link": "https://arxiv.org/abs/2411.10440v3",
          "size": "3474kb",
          "version": "v3"
        },
        {
          "date": "2025-02-16T08:24:42+00:00",
          "link": "https://arxiv.org/abs/2411.10440v4",
          "size": "3476kb",
          "version": "v4"
        },
        {
          "date": "2025-07-13T06:36:59+00:00",
          "link": "https://arxiv.org/abs/2411.10440v5",
          "size": "3604kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T03:53:30+00:00",
          "link": "https://arxiv.org/abs/2411.10440v6",
          "size": "3604kb",
          "version": "v6"
        }
      ],
      "title": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10440",
        "PDF": "https://arxiv.org/pdf/2411.10440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces LLaVA-CoT, a vision-language model, and constructs a new dataset (LLaVA-CoT-100k) with structured reasoning annotations. This involves creation and refinement of datasets, making it relevant to LLM training data processing."
      },
      "models": [
        {
          "model_path": "Xkev/Llama-3.2V-11B-cot",
          "downloads": "3084",
          "likes": "153",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Xkev/Llama-3.2V-11B-cot"
        },
        {
          "model_path": "BarraHome/Mistroll-3.0-CoT-Llama-3.2-11B-Vision-Instruct",
          "downloads": "5",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BarraHome/Mistroll-3.0-CoT-Llama-3.2-11B-Vision-Instruct"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Xkev/LLaVA-CoT-100k",
          "downloads": "1529",
          "likes": "95",
          "link": "https://huggingface.co/datasets/Xkev/LLaVA-CoT-100k"
        },
        {
          "dataset_name": "berhaan/pisc-tr",
          "downloads": "9",
          "likes": "1",
          "link": "https://huggingface.co/datasets/berhaan/pisc-tr"
        },
        {
          "dataset_name": "berhaan/clevr-tr",
          "downloads": "10",
          "likes": "2",
          "link": "https://huggingface.co/datasets/berhaan/clevr-tr"
        },
        {
          "dataset_name": "Nagase-Kotono/LLaVA-CoT-ko",
          "downloads": "31",
          "likes": "2",
          "link": "https://huggingface.co/datasets/Nagase-Kotono/LLaVA-CoT-ko"
        },
        {
          "dataset_name": "di-zhang-fdu/llava-cot-100k-r1-format",
          "downloads": "38",
          "likes": "2",
          "link": "https://huggingface.co/datasets/di-zhang-fdu/llava-cot-100k-r1-format"
        }
      ],
      "tasks": [
        "Logical Reasoning",
        "Multimodal Reasoning",
        "Question Answering",
        "Visual Question Answering"
      ],
      "repo_urls": [
        "https://github.com/PKU-YuanGroup/LLaVA-CoT",
        "https://github.com/zhaoolee/garss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14306",
      "abstract": "Understanding complex scientific and mathematical concepts, particularly those presented in dense research papers, poses a significant challenge for learners. Dynamic visualizations can greatly enhance comprehension, but creating them manually is time-consuming and requires specialized knowledge and skills. We introduce manimator, an open-source system that leverages Large Language Models to transform research papers and natural language prompts into explanatory animations using the Manim engine. Manimator employs a pipeline where an LLM interprets the input text or research paper PDF to generate a structured scene description outlining key concepts, mathematical formulas, and visual elements and another LLM translates this description into executable Manim Python code. We discuss its potential as an educational tool for rapidly creating engaging visual explanations for complex STEM topics, democratizing the creation of high-quality educational content.",
      "authors": [
        "Samarth P",
        "Vyoman Jain",
        "Shiva Golugula",
        "Motamarri Sai Sathvik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:28:26+00:00",
          "link": "https://arxiv.org/abs/2507.14306v1",
          "size": "795kb",
          "version": "v1"
        }
      ],
      "title": "Manimator: Transforming Research Papers into Visual Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14306",
        "HTML": "https://arxiv.org/html/2507.14306",
        "PDF": "https://arxiv.org/pdf/2507.14306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a system to transform research papers into animations using LLMs, which is not related to the processing of training data for LLMs in the context described."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15088",
      "abstract": "In this paper, we propose a search-based interactive motion planning scheme for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to traditional search-based approaches, the newly developed approach considers other road users (e.g. drivers and pedestrians) as intelligent agents rather than static obstacles. This leads to the generation of a more realistic path for the AV. Due to the low computational time, the proposed motion planning scheme is implementable in real-time applications. The performance of the developed motion planning scheme is compared with existing motion planning techniques and validated through experiments using WATonoBus, an electrical all-weather autonomous shuttle bus.",
      "authors": [
        "Pouya Panahandeh",
        "Mohammad Pirani",
        "Baris Fidan",
        "Amir Khajepour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:02:10+00:00",
          "link": "https://arxiv.org/abs/2507.15088v1",
          "size": "7180kb",
          "version": "v1"
        }
      ],
      "title": "Search-Based Autonomous Vehicle Motion Planning Using Game Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15088",
        "HTML": "https://arxiv.org/html/2507.15088",
        "PDF": "https://arxiv.org/pdf/2507.15088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a motion planning scheme for autonomous vehicles using game-theory, with no connection to LLM training data processing or any data processing techniques for language model development."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.06886",
      "abstract": "Primary key (PK) and foreign key (FK) constraints are widely used for query optimization. Knowledge about additional data dependencies, such as order dependencies, enables further substantial performance improvements. However, such dependencies are not maintained by database systems or are even unknown to the user. Identifying and validating relevant dependencies automatically and efficiently remains an unsolved problem. This paper presents a system that (i) recognizes dependency candidates for optimization, (ii) efficiently validates their applicability, and (iii) optimizes query plans using valid dependencies.\n  First, we demonstrate the performance impact of optimization techniques using data dependencies additional to PKs and FKs. Using rewritten SQL queries, we empirically show that data dependencies improve performance for a wide range of analytical database systems and benchmarks. Second, we present how to integrate data dependencies into a system to use them without (i) manual declaration and maintenance or (ii) SQL rewrites. Our integrated and fully automated system matches the performance of dedicated SQL rewrites: compared to using only PKs and FKs, queries improve with geometric mean speedups of 35 % for TPC-DS and 29 % for JOB. Individual query latencies drop by more than 90 %. The dependency discovery overhead is orders of magnitude lower than the latency improvement of a single workload execution.",
      "authors": [
        "Daniel Lindner",
        "Daniel Ritter",
        "and Felix Naumann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-11T01:52:04+00:00",
          "link": "https://arxiv.org/abs/2406.06886v1",
          "size": "1455kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T10:44:10+00:00",
          "link": "https://arxiv.org/abs/2406.06886v2",
          "size": "1221kb",
          "version": "v2"
        }
      ],
      "title": "Enabling Data Dependency-based Query Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06886",
        "HTML": "https://arxiv.org/html/2406.06886",
        "PDF": "https://arxiv.org/pdf/2406.06886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses query optimization in databases using data dependencies like PKs and FKs but does not pertain to LLM training data processing for pretraining or fine-tuning."
      },
      "repo_urls": [
        "https://github.com/HPI-Information-Systems/dependency-based-qo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14899",
      "abstract": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for industrial quality assurance, yet existing deep-learning-based approaches often lack interactivity, interpretability, and the capacity for critical self-assessment, limiting their reliability and operator trust. To address these shortcomings, this paper proposes InsightX Agent, a novel LMM-based agentic framework designed to deliver reliable, interpretable, and interactive X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent positions a Large Multimodal Model (LMM) as a central orchestrator, coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect region proposals for multi-scale feature maps and sparsifies them through Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in X-ray images while maintaining computational efficiency. The EGR tool guides the LMM agent through a chain-of-thought-inspired review process, incorporating context assessment, individual defect analysis, false positive elimination, confidence recalibration and quality assurance to validate and refine the SDMSD's initial proposals. By strategically employing and intelligently using tools, InsightX Agent moves beyond passive data processing to active reasoning, enhancing diagnostic reliability and providing interpretations that integrate diverse information sources. Experimental evaluations on the GDXray+ dataset demonstrate that InsightX Agent not only achieves a high object detection F1-score of 96.35% but also offers significantly improved interpretability and trustworthiness in its analyses, highlighting the transformative potential of agentic LLM frameworks for industrial inspection tasks.",
      "authors": [
        "Jiale Liu",
        "Huan Wang",
        "Yue Zhang",
        "Xiaoyu Luo",
        "Jiaxiang Hu",
        "Zhiliang Liu",
        "Min Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.14899v1",
          "size": "1764kb",
          "version": "v1"
        }
      ],
      "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14899",
        "HTML": "https://arxiv.org/html/2507.14899",
        "PDF": "https://arxiv.org/pdf/2507.14899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "InsightX Agent deals with X-ray NDT analysis for industrial quality assurance using a multimodal model framework. It doesn't focus on LLM training data processing or dataset improvement techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15132",
      "abstract": "The research community continues to seek increasingly more advanced synthetic data generators to reliably evaluate the strengths and limitations of machine learning methods. This work aims to increase the availability of datasets encompassing a diverse range of problem complexities by proposing a genetic algorithm that optimizes a set of problem complexity measures for classification and regression tasks towards specific targets. For classification, a set of 10 complexity measures was used, while for regression tasks, 4 measures demonstrating promising optimization capabilities were selected. Experiments confirmed that the proposed genetic algorithm can generate datasets with varying levels of difficulty by transforming synthetically created datasets to achieve target complexity values through linear feature projections. Evaluations involving state-of-the-art classifiers and regressors revealed a correlation between the complexity of the generated data and the recognition quality.",
      "authors": [
        "Joanna Komorniczak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T21:42:30+00:00",
          "link": "https://arxiv.org/abs/2507.15132v1",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15132",
        "HTML": "https://arxiv.org/html/2507.15132",
        "PDF": "https://arxiv.org/pdf/2507.15132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper contributes by proposing a genetic algorithm to generate datasets with varying complexities for machine learning tasks, focusing on creating synthetic data with specific complexity, which is a direct contribution to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15532",
      "abstract": "Safe policy improvement (SPI) is an offline reinforcement learning problem in which a new policy that reliably outperforms the behavior policy with high confidence needs to be computed using only a dataset and the behavior policy. Markov decision processes (MDPs) are the standard formalism for modeling environments in SPI. In many applications, additional information in the form of parametric dependencies between distributions in the transition dynamics is available. We make SPI more data-efficient by leveraging these dependencies through three contributions: (1) a parametric SPI algorithm that exploits known correlations between distributions to more accurately estimate the transition dynamics using the same amount of data; (2) a preprocessing technique that prunes redundant actions from the environment through a game-based abstraction; and (3) a more advanced preprocessing technique, based on satisfiability modulo theory (SMT) solving, that can identify more actions to prune. Empirical results and an ablation study show that our techniques increase the data efficiency of SPI by multiple orders of magnitude while maintaining the same reliability guarantees.",
      "authors": [
        "Kasper Engelen",
        "Guillermo A. P\\'erez",
        "Marnix Suilen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:00:03+00:00",
          "link": "https://arxiv.org/abs/2507.15532v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15532",
        "HTML": "https://arxiv.org/html/2507.15532",
        "PDF": "https://arxiv.org/pdf/2507.15532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses safe policy improvement in offline reinforcement learning, focusing on data efficiency in MDPs. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.16374",
      "abstract": "We address the challenge of preserving the simultaneity and chronology of sensing events in multisensor systems with wireless links. The network uses temporal windows of integration (TWIs), borrowed from human multisensory perception, to preserve the temporal structure of the sensing data at the application side. We introduce a composite latency model for propagation, sensing, and communication that leads to the derivation of the probability of simultaneity violation. This is used to select the TWI duration aiming to achieve the desired degrees of chronological preservation, while maintaining the throughput of events. The letter provides important insights and analytical tools about the TWI impact on the event registration.",
      "authors": [
        "Jo\\~ao Henrique Inacio de Souza",
        "Fabio Saggese",
        "Beatriz Soret",
        "Petar Popovski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T22:28:38+00:00",
          "link": "https://arxiv.org/abs/2502.16374v1",
          "size": "613kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:37:40+00:00",
          "link": "https://arxiv.org/abs/2502.16374v2",
          "size": "453kb",
          "version": "v2"
        }
      ],
      "title": "Preserving Simultaneity and Chronology for Sensing in Perceptive Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16374",
        "HTML": "https://arxiv.org/html/2502.16374",
        "PDF": "https://arxiv.org/pdf/2502.16374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on preserving simultaneity and chronology in multisensor systems with wireless links, which is unrelated to LLM training data processing, as it does not involve data preprocessing stages or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11092",
      "abstract": "Retrieval-Augmented Generation (RAG) has significantly advanced large language models (LLMs) by grounding their outputs in external tools and knowledge sources. However, existing RAG systems are typically constrained to static, single-turn interactions with fixed toolsets, making them ill-suited for dynamic domains such as healthcare and smart homes, where user intent, available tools, and contextual factors evolve over time. We present Dynamic Context Tuning (DCT), a lightweight framework that extends RAG to support multi-turn dialogue and evolving tool environments without requiring retraining. DCT integrates an attention-based context cache to track relevant past information, LoRA-based retrieval to dynamically select domain-specific tools, and efficient context compression to maintain inputs within LLM context limits. Experiments on both synthetic and real-world benchmarks show that DCT improves plan accuracy by 14% and reduces hallucinations by 37%, while matching GPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to previously unseen tools, enabling scalable and adaptable AI assistants across a wide range of dynamic environments.",
      "authors": [
        "Jubin Abhishek Soni",
        "Amit Anand",
        "Rajesh Kumar Pandey",
        "Aniket Abhishek Soni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T19:47:22+00:00",
          "link": "https://arxiv.org/abs/2506.11092v1",
          "size": "341kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:46:19+00:00",
          "link": "https://arxiv.org/abs/2506.11092v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11092",
        "HTML": "https://arxiv.org/html/2506.11092",
        "PDF": "https://arxiv.org/pdf/2506.11092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Dynamic Context Tuning for Retrieval-Augmented Generation, focusing on dynamic environments and multi-turn dialogue adaptation. It does not contribute to any LLM training data processing operations."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14236",
      "abstract": "This study explores the relationship between voter trust and their experiences during elections by applying a rule-based data mining technique to the 2022 Survey of the Performance of American Elections (SPAE). Using the Apriori algorithm and setting parameters to capture meaningful associations (support >= 3%, confidence >= 60%, and lift > 1.5), the analysis revealed a strong connection between demographic attributes and voting-related challenges, such as registration hurdles, accessibility issues, and queue times. For instance, respondents who indicated that accessing polling stations was \"very easy\" and who reported moderate confidence were found to be over six times more likely (lift = 6.12) to trust their county's election outcome and experience no registration issues. A further analysis, which adjusted the support threshold to 2%, specifically examined patterns among minority voters. It revealed that 98.16 percent of Black voters who reported easy access to polling locations also had smooth registration experiences. Additionally, those who had high confidence in the vote-counting process were almost two times as likely to identify as Democratic Party supporters. These findings point to the important role that enhancing voting access and offering targeted support can play in building trust in the electoral system, particularly among marginalized communities.",
      "authors": [
        "Md Al Jubair",
        "Mohammad Shamsul Arefin",
        "Ahmed Wasif Reza"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:25:12+00:00",
          "link": "https://arxiv.org/abs/2507.14236v1",
          "size": "691kb",
          "version": "v1"
        }
      ],
      "title": "Mining Voter Behaviour and Confidence: A Rule-Based Analysis of the 2022 U.S. Elections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14236",
        "PDF": "https://arxiv.org/pdf/2507.14236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on voter behavior and confidence analysis using rule-based data mining in the context of elections. It does not pertain to LLM training data processing or involve data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14361",
      "abstract": "Existing studies on bundle construction have relied merely on user feedback via bipartite graphs or enhanced item representations using semantic information. These approaches fail to capture elaborate relations hidden in real-world bundle structures, resulting in suboptimal bundle representations. To overcome this limitation, we propose RaMen, a novel method that provides a holistic multi-strategy approach for bundle construction. RaMen utilizes both intrinsic (characteristics) and extrinsic (collaborative signals) information to model bundle structures through Explicit Strategy-aware Learning (ESL) and Implicit Strategy-aware Learning (ISL). ESL employs task-specific attention mechanisms to encode multi-modal data and direct collaborative relations between items, thereby explicitly capturing essential bundle features. Moreover, ISL computes hyperedge dependencies and hypergraph message passing to uncover shared latent intents among groups of items. Integrating diverse strategies enables RaMen to learn more comprehensive and robust bundle representations. Meanwhile, Multi-strategy Alignment & Discrimination module is employed to facilitate knowledge transfer between learning strategies and ensure discrimination between items/bundles. Extensive experiments demonstrate the effectiveness of RaMen over state-of-the-art models on various domains, justifying valuable insights into complex item set problems.",
      "authors": [
        "Huy-Son Nguyen",
        "Quang-Huy Nguyen",
        "Duc-Hoang Pham",
        "Duc-Trong Le",
        "Hoang-Quynh Le",
        "Padipat Sitkrongwong",
        "Atsuhiro Takasu and Masoud Mansoury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T20:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.14361v1",
          "size": "975kb",
          "version": "v1"
        }
      ],
      "title": "RaMen: Multi-Strategy Multi-Modal Learning for Bundle Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14361",
        "HTML": "https://arxiv.org/html/2507.14361",
        "PDF": "https://arxiv.org/pdf/2507.14361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on multi-strategy multi-modal learning for bundle construction, dealing with item and collaborative relations modeling. There is no mention of LLM training data processing or the creation or improvement of datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14548",
      "abstract": "In this paper, we investigate the approximation properties of two types of multiscale finite element methods with oversampling as proposed in [Hou \\& Wu, {\\textit{J. Comput. Phys.}}, 1997] and [Efendiev, Hou \\& Wu, \\textit{SIAM J. Numer. Anal.}, 2000] without scale separation. We develop a general interpolation error analysis for elliptic problems with highly oscillatory rough coefficients, under the assumption of the existence of a macroscopic problem with suitable $L^2$-accuracy. The distinct features of the analysis, in the setting of highly oscillatory periodic coefficients, include: (i) The analysis is independent of the first-order corrector or the solutions to the cell problems, and thus independent of their regularity properties; (ii) The analysis only involves the homogenized solution and its minimal regularity. We derive an interpolation error $\\mathcal{O}\\left(H+\\frac{\\epsilon}{H}\\right)$ with $\\epsilon$ and $H$ being the period size and the coarse mesh size, respectively, when the oversampling domain includes one layer of elements from the target coarse element.",
      "authors": [
        "Guanglian Li"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:11:33+00:00",
          "link": "https://arxiv.org/abs/2507.14548v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "On the convergence analysis of MsFEM with oversampling: Interpolation error",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14548",
        "HTML": "https://arxiv.org/html/2507.14548",
        "PDF": "https://arxiv.org/pdf/2507.14548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multiscale finite element methods and interpolation error analysis for elliptic problems, with no discussion on LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14855",
      "abstract": "This paper investigates the problem of object detection with a focus on improving both the localization accuracy of bounding boxes and explicitly modeling prediction uncertainty. Conventional detectors rely on deterministic bounding box regression, ignoring uncertainty in predictions and limiting model robustness. In this paper, we propose an uncertainty-aware enhancement framework for DETR-based object detectors. We model bounding boxes as multivariate Gaussian distributions and incorporate the Gromov-Wasserstein distance into the loss function to better align the predicted and ground-truth distributions. Building on this, we derive a Bayes Risk formulation to filter high-risk information and improve detection reliability. We also propose a simple algorithm to quantify localization uncertainty via confidence intervals. Experiments on the COCO benchmark show that our method can be effectively integrated into existing DETR variants, enhancing their performance. We further extend our framework to leukocyte detection tasks, achieving state-of-the-art results on the LISC and WBCDD datasets. These results confirm the scalability of our framework across both general and domain-specific detection tasks. Code page: https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.",
      "authors": [
        "Xingshu Chen",
        "Sicheng Yu",
        "Chong Cheng",
        "Hao Wang",
        "Ting Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:53:04+00:00",
          "link": "https://arxiv.org/abs/2507.14855v1",
          "size": "4921kb",
          "version": "v1"
        }
      ],
      "title": "An Uncertainty-aware DETR Enhancement Framework for Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14855",
        "HTML": "https://arxiv.org/html/2507.14855",
        "PDF": "https://arxiv.org/pdf/2507.14855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving object detection through an uncertainty-aware framework and does not address training data processing for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15021",
      "abstract": "Coastal communities increasingly face compound floods, where multiple drivers like storm surge, high tide, heavy rainfall, and river discharge occur together or in sequence to produce impacts far greater than any single driver alone. Traditional hydrodynamic models can provide accurate physics-based simulations but require substantial computational resources for real-time applications or risk assessments, while machine learning alternatives often sacrifice physical consistency for speed, producing unrealistic predictions during extreme events. This study addresses these challenges by developing ALPINE (All-in-one Physics Informed Neural Emulator), a physics-informed neural network (PINN) framework to enforce complete shallow water dynamics in compound flood modeling. Unlike previous approaches that implement partial constraints, our framework simultaneously enforces mass conservation and both momentum equations, ensuring full adherence to Newton's laws throughout the prediction process. The model integrates a convolutional encoder-decoder architecture with ConvLSTM temporal processing, trained using a composite loss function that balances data fidelity with physics-based residuals. Using six historical storm events (four for training, one for validation, and one held-out for unseen testing), we observe substantial improvements over baseline neural networks. ALPINE reduces domain-averaged prediction errors and improves model skill metrics for water surface elevation and velocity components. Physics-informed constraints prove most valuable during peak storm intensity, when multiple flood drivers interact and reliable predictions matter most. This approach yields a physically consistent emulator capable of supporting compound-flood forecasting and large-scale risk analyses while preserving physical realism essential for coastal emergency management.",
      "authors": [
        "Soheil Radfar",
        "Faezeh Maghsoodifar",
        "Hamed Moftakhari and Hamid Moradkhani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:06:10+00:00",
          "link": "https://arxiv.org/abs/2507.15021v1",
          "size": "10869kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Newton's Laws with deep learning for enhanced physics-informed compound flood modelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15021",
        "HTML": "https://arxiv.org/html/2507.15021",
        "PDF": "https://arxiv.org/pdf/2507.15021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a physics-informed neural network for compound flood modeling, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15101",
      "abstract": "Detecting partial deepfake speech is essential due to its potential for subtle misinformation. However, existing methods depend on costly frame-level annotations during training, limiting real-world scalability. Also, they focus on detecting transition artifacts between bonafide and deepfake segments. As deepfake generation techniques increasingly smooth these transitions, detection has become more challenging. To address this, our work introduces a new perspective by analyzing frame-level temporal differences and reveals that deepfake speech exhibits erratic directional changes and unnatural local transitions compared to bonafide speech. Based on this finding, we propose a Temporal Difference Attention Module (TDAM) that redefines partial deepfake detection as identifying unnatural temporal variations, without relying on explicit boundary annotations. A dual-level hierarchical difference representation captures temporal irregularities at both fine and coarse scales, while adaptive average pooling preserves essential patterns across variable-length inputs to minimize information loss. Our TDAM-AvgPool model achieves state-of-the-art performance, with an EER of 0.59% on the PartialSpoof dataset and 0.03% on the HAD dataset, which significantly outperforms the existing methods without requiring frame-level supervision.",
      "authors": [
        "Menglu Li",
        "Xiao-Ping Zhang",
        "Lian Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Cryptography and Security (cs.CR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:46:23+00:00",
          "link": "https://arxiv.org/abs/2507.15101v1",
          "size": "1940kb",
          "version": "v1"
        }
      ],
      "title": "Frame-level Temporal Difference Learning for Partial Deepfake Speech Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15101",
        "HTML": "https://arxiv.org/html/2507.15101",
        "PDF": "https://arxiv.org/pdf/2507.15101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses deepfake speech detection using a novel approach focused on temporal differences, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15108",
      "abstract": "This essay explores strong data-processing inequalities (SPDI's) as they appear in the work of Evans and Schulman \\cite{ES} and von Neumann \\cite{vN} on computing with noisy circuits. We first develop the framework in \\cite{ES}, which leads to lower bounds on depth and upper bounds on noise that permit reliable computation. We then introduce the $3$-majority gate, introduced by \\cite{vN} for the purpose of controlling noise, and obtain an upper bound on noise necessary for its function. We end by generalizing von Neumann's analysis to majority gates of any order, proving an analogous noise threshold and giving a sufficient upper bound for order given a desired level of reliability.\n  The presentation of material has been modified in a way deemed more natural by the author, occasionally leading to simplifications of existing proofs. Furthermore, many computations omitted from the original works have been worked out, and some new commentary added. The intended audience has a rudimentary understanding of information theory similar to that of the author.",
      "authors": [
        "Chenyang Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:07:12+00:00",
          "link": "https://arxiv.org/abs/2507.15108v1",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "title": "Noise Quantification and Control in Circuits via Strong Data-Processing Inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15108",
        "HTML": "https://arxiv.org/html/2507.15108",
        "PDF": "https://arxiv.org/pdf/2507.15108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses noise quantification in circuits and data-processing inequalities. It does not address the topic of LLM training data processing or improvements in dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15615",
      "abstract": "Primal heuristics play a critical role in improving the efficiency of mixed integer programming (MILP) solvers. As large language models (LLMs) have demonstrated superior code generation abilities, recent MILP works are devoted to leveraging the evolutionary computation approaches with LLMs to generate effective primal heuristics. Although the generated heuristics have achieved better solving performance than the hand-crafted ones with little adaptability, the advantage of current LLM-based methods is limited to few MILP instances in one problem class, as they fail to capture the instance characteristics in the problem class (the MILP instances generated from the same mathematical model are defined as a problem class). Since MILP instances often differ significantly in structure and feature distribution, the neglect of their characteristics in the evolution process results in poor generalization within the same problem class. To overcome this challenge, we propose a data-algorithm co-evolution framework (DHEvo) that iteratively selects representative instances and evolves corresponding heuristics. With the initial instance distribution, we develop an LLM-based multi-agent system to generate data-code pairs simultaneously. These data-code pairs are iteratively refined based on their fitness scores, leading to the identification of the most effective heuristic over the entire problem class. Extensive experiments across diverse MILP benchmarks demonstrate that our approach significantly outperforms both human-designed heuristics and existing LLM-based methods.",
      "authors": [
        "Zhihao Zhang",
        "Siyuan Li",
        "Chenxi Li",
        "Feifan Liu",
        "Mengjing Chen",
        "Kai Li",
        "Tao Zhong",
        "Bo An",
        "Peng Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:40:19+00:00",
          "link": "https://arxiv.org/abs/2507.15615v1",
          "size": "2478kb",
          "version": "v1"
        }
      ],
      "title": "DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15615",
        "HTML": "https://arxiv.org/html/2507.15615",
        "PDF": "https://arxiv.org/pdf/2507.15615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper involves LLMs in the context of generating data-algorithm pairs for MILP solving, the main focus is on algorithm evolution and heuristic improvement rather than LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15678",
      "abstract": "The fundamental laws of physics are intrinsically geometric, dictating the evolution of systems through principles of symmetry and conservation. While modern machine learning offers powerful tools for modeling complex dynamics from data, common methods often ignore this underlying geometric fabric. Physics-informed neural networks, for instance, can violate fundamental physical principles, leading to predictions that are unstable over long periods, particularly for high-dimensional and chaotic systems. Here, we introduce \\textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework that learns dynamics by explicitly encoding the geometric priors inherent to physical laws. Our approach enforces two fundamental structures: the Riemannian geometry of inertia, by parameterizing inertia matrices in their natural mathematical space of symmetric positive-definite matrices, and the symplectic geometry of phase space, using a constrained autoencoder to ensure the preservation of phase space volume in a reduced latent space. We demonstrate through experiments on systems ranging from coupled oscillators to high-dimensional deformable objects that GeoHNN significantly outperforms existing models. It achieves superior long-term stability, accuracy, and energy conservation, confirming that embedding the geometry of physics is not just a theoretical appeal but a practical necessity for creating robust and generalizable models of the physical world.",
      "authors": [
        "Amine Mohamed Aboussalah and Abdessalam Ed-dib"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Differential Geometry (math.DG)",
        "Dynamical Systems (math.DS)",
        "Symplectic Geometry (math.SG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:42:39+00:00",
          "link": "https://arxiv.org/abs/2507.15678v1",
          "size": "1537kb",
          "version": "v1"
        }
      ],
      "title": "GeoHNNs: Geometric Hamiltonian Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15678",
        "HTML": "https://arxiv.org/html/2507.15678",
        "PDF": "https://arxiv.org/pdf/2507.15678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Geometric Hamiltonian Neural Networks for modeling physical dynamics and does not involve any LLM training data processing or dataset development relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.10360",
      "abstract": "Hand shadow puppetry, also known as shadowgraphy or ombromanie, is a form of theatrical art and storytelling where hand shadows are projected onto flat surfaces to create illusions of living creatures. The skilled performers create these silhouettes by hand positioning, finger movements, and dexterous gestures to resemble shadows of animals and objects. Due to the lack of practitioners and a seismic shift in people's entertainment standards, this art form is on the verge of extinction. To facilitate its preservation and proliferate it to a wider audience, we introduce ${\\rm H{\\small A}SP{\\small E}R}$, a novel dataset consisting of 15,000 images of hand shadow puppets across 15 classes extracted from both professional and amateur hand shadow puppeteer clips. We provide a detailed statistical analysis of the dataset and employ a range of pretrained image classification models to establish baselines. Our findings show a substantial performance superiority of skip-connected convolutional models over attention-based transformer architectures. We also find that lightweight models, such as MobileNetV2, suited for mobile applications and embedded devices, perform comparatively well. We surmise that such low-latency architectures can be useful in developing ombromanie teaching tools, and we create a prototype application to explore this surmission. Keeping the best-performing model ResNet34 under the limelight, we conduct comprehensive feature-spatial, explainability, and error analyses to gain insights into its decision-making process and explore architectural improvements. To the best of our knowledge, this is the first documented dataset and research endeavor to preserve this dying art for future generations, with computer vision approaches. Our code and data are publicly available at https://github.com/Starscream-11813/HaSPeR.",
      "authors": [
        "Syed Rifat Raiyan",
        "Zibran Zarif Amio",
        "Sabbir Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-19T18:56:24+00:00",
          "link": "https://arxiv.org/abs/2408.10360v1",
          "size": "44465kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T11:02:07+00:00",
          "link": "https://arxiv.org/abs/2408.10360v2",
          "size": "27106kb",
          "version": "v2"
        },
        {
          "date": "2024-12-24T00:55:15+00:00",
          "link": "https://arxiv.org/abs/2408.10360v3",
          "size": "27190kb",
          "version": "v3"
        },
        {
          "date": "2025-02-02T21:34:33+00:00",
          "link": "https://arxiv.org/abs/2408.10360v4",
          "size": "27170kb",
          "version": "v4"
        },
        {
          "date": "2025-02-14T10:53:27+00:00",
          "link": "https://arxiv.org/abs/2408.10360v5",
          "size": "27170kb",
          "version": "v5"
        },
        {
          "date": "2025-03-31T19:29:48+00:00",
          "link": "https://arxiv.org/abs/2408.10360v6",
          "size": "27561kb",
          "version": "v6"
        },
        {
          "date": "2025-07-20T16:48:33+00:00",
          "link": "https://arxiv.org/abs/2408.10360v7",
          "size": "27712kb",
          "version": "v7"
        }
      ],
      "title": "HaSPeR: An Image Repository for Hand Shadow Puppet Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10360",
        "HTML": "https://arxiv.org/html/2408.10360",
        "PDF": "https://arxiv.org/pdf/2408.10360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an image dataset for hand shadow puppetry and evaluates image classification models on it. While it involves data creation, it is not related to LLM training data processing, focusing instead on computer vision tasks."
      },
      "datasets": [
        {
          "dataset_name": "Starscream-11813/HaSPeR",
          "downloads": "12",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Starscream-11813/HaSPeR"
        }
      ],
      "tasks": [
        "image-classification",
        "Image Classification"
      ],
      "repo_urls": [
        "https://github.com/Starscream-11813/HaSPeR"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.07337",
      "abstract": "Sampling from unnormalized densities presents a fundamental challenge with wide-ranging applications, from posterior inference to molecular dynamics simulations. Continuous flow-based neural samplers offer a promising approach, learning a velocity field that satisfies key principles of marginal density evolution (e.g., the continuity equation) to generate samples. However, this learning procedure requires accurate estimation of intractable terms linked to the computationally challenging partition function, for which existing estimators often suffer from high variance or low accuracy. To overcome this, we introduce an improved estimator for these challenging quantities, employing a velocity-driven Sequential Monte Carlo method enhanced with control variates. Furthermore, we introduce a shortcut consistency model to boost the runtime efficiency of the flow-based neural sampler by minimizing its required sampling steps. Our proposed Neural Flow Shortcut Sampler empirically outperforms existing flow-based neural samplers on both synthetic datasets and complex n-body system targets.",
      "authors": [
        "Wuhao Chen",
        "Zijing Ou",
        "Yingzhen Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T07:55:41+00:00",
          "link": "https://arxiv.org/abs/2502.07337v1",
          "size": "26246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:34:31+00:00",
          "link": "https://arxiv.org/abs/2502.07337v2",
          "size": "38829kb",
          "version": "v2"
        }
      ],
      "title": "Neural Flow Samplers with Shortcut Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07337",
        "HTML": "https://arxiv.org/html/2502.07337",
        "PDF": "https://arxiv.org/pdf/2502.07337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sampling techniques for unnormalized densities using neural flow samplers, which does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.15639",
      "abstract": "Aligned representations across languages is a desired property in multilingual large language models (mLLMs), as alignment can improve performance in cross-lingual tasks. Typically alignment requires fine-tuning a model, which is computationally expensive, and sizable language data, which often may not be available. A data-efficient alternative to fine-tuning is model interventions -- a method for manipulating model activations to steer generation into the desired direction. We analyze the effect of a popular intervention (finding experts) on the alignment of cross-lingual representations in mLLMs. We identify the neurons to manipulate for a given language and introspect the embedding space of mLLMs pre- and post-manipulation. We show that modifying the mLLM's activations changes its embedding space such that cross-lingual alignment is enhanced. Further, we show that the changes to the embedding space translate into improved downstream performance on retrieval tasks, with up to 2x improvements in top-1 accuracy on cross-lingual retrieval.",
      "authors": [
        "Anirudh Sundar",
        "Sinead Williamson",
        "Katherine Metcalf",
        "Barry-John Theobald",
        "Skyler Seto",
        "Masha Fedzechkina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:09:54+00:00",
          "link": "https://arxiv.org/abs/2502.15639v1",
          "size": "22692kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:03:22+00:00",
          "link": "https://arxiv.org/abs/2502.15639v2",
          "size": "27099kb",
          "version": "v2"
        }
      ],
      "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15639",
        "PDF": "https://arxiv.org/pdf/2502.15639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a data-efficient method for enhancing cross-lingual alignment in multilingual LLMs. While it touches on fine-tuning and interventions, the primary focus is on model manipulation rather than training data processing."
      },
      "tasks": [
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00813",
      "abstract": "Recently, there has been a surge of research on a class of methods called feedback optimization. These are methods to steer the state of a control system to an equilibrium that arises as the solution of an optimization problem. Despite the growing literature on the topic, the important problem of enforcing state constraints at all times remains unaddressed. In this work, we present the first feedback-optimization method that enforces state constraints. The method combines a class of dynamics called safe gradient flows with high-order control barrier functions. We provide a number of results on our proposed controller, including well-posedness guarantees, anytime constraint-satisfaction guarantees, equivalence between the closed-loop's equilibria and the optimization problem's critical points, and local asymptotic stability of optima.",
      "authors": [
        "Giannis Delimpaltadakis",
        "Pol Mestres",
        "Jorge Cort\\'es",
        "W.P.M.H. Heemels"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T14:04:09+00:00",
          "link": "https://arxiv.org/abs/2504.00813v1",
          "size": "2663kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:01:53+00:00",
          "link": "https://arxiv.org/abs/2504.00813v2",
          "size": "2545kb",
          "version": "v2"
        }
      ],
      "title": "Feedback Optimization with State Constraints through Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00813",
        "HTML": "https://arxiv.org/html/2504.00813",
        "PDF": "https://arxiv.org/pdf/2504.00813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a feedback optimization method with state constraints using control barrier functions, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14258",
      "abstract": "The peer review process for scientific publications faces significant challenges due to the increasing volume of submissions and inherent reviewer biases. While artificial intelligence offers the potential to facilitate the process, it also risks perpetuating biases present in training data. This research addresses these challenges by applying formal methods from argumentation theory to support transparent and unbiased dispute resolution in peer review. Specifically, we conceptualize scientific peer review as a single mixed argumentative dispute between manuscript authors and reviewers and formalize it using abstract argumentation frameworks. We analyze the resulting peer review argumentation frameworks from semantic, graph-theoretic, and computational perspectives, showing that they are well-founded and decidable in linear time. These frameworks are then implemented using OWL DL and resolved with reasoning engines. We validate our approach by annotating a corpus of scientific peer reviews with abstract argumentation frameworks and applying a proof of concept to resolve the annotated disputes. The results demonstrate that integrating our method could enhance the quality of published work by providing a more rigorous and systematic approach to accounting reviewer arguments.",
      "authors": [
        "Ildar Baimuratov",
        "Elena Lisanyuk",
        "Dmitry Prokudin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:21:25+00:00",
          "link": "https://arxiv.org/abs/2507.14258v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Dispute Resolution in Peer Review with Abstract Argumentation and OWL DL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14258",
        "HTML": "https://arxiv.org/html/2507.14258",
        "PDF": "https://arxiv.org/pdf/2507.14258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses peer review disputes using argumentation theory, which does not relate to LLM training data processing or include discussions on training data operations or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14777",
      "abstract": "Concerned with privacy threats, memorization in LLMs is often seen as undesirable, specifically for learning. In this paper, we study whether memorization can be avoided when optimally learning a language, and whether the privacy threat posed by memorization is exaggerated or not. To this end, we re-examine existing privacy-focused measures of memorization, namely recollection-based and counterfactual memorization, along with a newly proposed contextual memorization.\n  Relating memorization to local over-fitting during learning, contextual memorization aims to disentangle memorization from the contextual learning ability of LLMs. Informally, a string is contextually memorized if its recollection due to training exceeds the optimal contextual recollection, a learned threshold denoting the best contextual learning without training. Conceptually, contextual recollection avoids the fallacy of recollection-based memorization, where any form of high recollection is a sign of memorization. Theoretically, contextual memorization relates to counterfactual memorization, but imposes stronger conditions. Memorization measures differ in outcomes and information requirements.\n  Experimenting on 18 LLMs from 6 families and multiple formal languages of different entropy, we show that (a) memorization measures disagree on memorization order of varying frequent strings, (b) optimal learning of a language cannot avoid partial memorization of training strings, and (c) improved learning decreases contextual and counterfactual memorization but increases recollection-based memorization. Finally, (d) we revisit existing reports of memorized strings by recollection that neither pose a privacy threat nor are contextually or counterfactually memorized.",
      "authors": [
        "Bishwamittra Ghosh",
        "Soumi Das",
        "Qinyuan Wu",
        "Mohammad Aflah Khan",
        "Krishna P. Gummadi",
        "Evimaria Terzi",
        "Deepak Garg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T00:33:19+00:00",
          "link": "https://arxiv.org/abs/2507.14777v1",
          "size": "2096kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Memorization Measures and their Implications in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14777",
        "HTML": "https://arxiv.org/html/2507.14777",
        "PDF": "https://arxiv.org/pdf/2507.14777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper explores memorization in LLMs, relating it to privacy and contextual learning. It discusses implications for learning but does not center on training data processing operations like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14863",
      "abstract": "This study investigates the vulnerability of direct data-driven control methods, specifically for the linear quadratic regulator problem, to adversarial perturbations in collected data used for controller synthesis. We consider stealthy attacks that subtly manipulate offline-collected data to destabilize the resulting closed-loop system while evading detection. To generate such perturbations, we propose the Directed Gradient Sign Method (DGSM) and its iterative variant (I-DGSM), adaptations of the fast gradient sign method originally developed for neural networks, which align perturbations with the gradient of the spectral radius of the closed-loop matrix to reduce stability. A key contribution is an efficient gradient computation technique based on implicit differentiation through the Karush-Kuhn-Tucker conditions of the underlying semidefinite program, enabling scalable and exact gradient evaluation without repeated optimization computations. To defend against these attacks, we propose two defense strategies: a regularization-based approach that enhances robustness by suppressing controller sensitivity to data perturbations and a robust data-driven control approach that guarantees closed-loop stability within bounded perturbation sets. Extensive numerical experiments on benchmark systems show that adversarial perturbations with magnitudes up to ten times smaller than random noise can destabilize controllers trained on corrupted data and that the proposed defense strategies effectively mitigate attack success rates while maintaining control performance. Additionally, we evaluate attack transferability under partial knowledge scenarios, highlighting the practical importance of protecting training data confidentiality.",
      "authors": [
        "Hampei Sasahara"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:17:15+00:00",
          "link": "https://arxiv.org/abs/2507.14863v1",
          "size": "963kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Destabilization Attacks to Direct Data-Driven Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14863",
        "HTML": "https://arxiv.org/html/2507.14863",
        "PDF": "https://arxiv.org/pdf/2507.14863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the study explores vulnerabilities in data used for control synthesis, it does not relate to LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15499",
      "abstract": "We propose CLEVER, an active learning system for robust semantic perception with Deep Neural Networks (DNNs). For data arriving in streams, our system seeks human support when encountering failures and adapts DNNs online based on human instructions. In this way, CLEVER can eventually accomplish the given semantic perception tasks. Our main contribution is the design of a system that meets several desiderata of realizing the aforementioned capabilities. The key enabler herein is our Bayesian formulation that encodes domain knowledge through priors. Empirically, we not only motivate CLEVER's design but further demonstrate its capabilities with a user validation study as well as experiments on humanoid and deformable objects. To our knowledge, we are the first to realize stream-based active learning on a real robot, providing evidence that the robustness of the DNN-based semantic perception can be improved in practice. The project website can be accessed at https://sites.google.com/view/thecleversystem.",
      "authors": [
        "Jongseok Lee and Timo Birr and Rudolph Triebel and Tamim Asfour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:04:58+00:00",
          "link": "https://arxiv.org/abs/2507.15499v1",
          "size": "7844kb",
          "version": "v1"
        }
      ],
      "title": "CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15499",
        "HTML": "https://arxiv.org/html/2507.15499",
        "PDF": "https://arxiv.org/pdf/2507.15499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an active learning system, CLEVER, for semantic perception tasks, emphasizing DNN robustness through human-in-the-loop approaches. This does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.02655",
      "abstract": "This paper presents the development process of a Vietnamese spoken language corpus for machine reading comprehension (MRC) tasks and provides insights into the challenges and opportunities associated with using real-world data for machine reading comprehension tasks. The existing MRC corpora in Vietnamese mainly focus on formal written documents such as Wikipedia articles, online newspapers, or textbooks. In contrast, the VlogQA consists of 10,076 question-answer pairs based on 1,230 transcript documents sourced from YouTube -- an extensive source of user-uploaded content, covering the topics of food and travel. By capturing the spoken language of native Vietnamese speakers in natural settings, an obscure corner overlooked in Vietnamese research, the corpus provides a valuable resource for future research in reading comprehension tasks for the Vietnamese language. Regarding performance evaluation, our deep-learning models achieved the highest F1 score of 75.34% on the test set, indicating significant progress in machine reading comprehension for Vietnamese spoken language data. In terms of EM, the highest score we accomplished is 53.97%, which reflects the challenge in processing spoken-based content and highlights the need for further improvement.",
      "authors": [
        "Thinh Phuoc Ngo",
        "Khoa Tran Anh Dang",
        "Son T. Luu",
        "Kiet Van Nguyen",
        "Ngan Luu-Thuy Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-05T00:54:40+00:00",
          "link": "https://arxiv.org/abs/2402.02655v1",
          "size": "8402kb",
          "version": "v1"
        },
        {
          "date": "2024-04-06T04:29:58+00:00",
          "link": "https://arxiv.org/abs/2402.02655v2",
          "size": "9396kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T01:38:45+00:00",
          "link": "https://arxiv.org/abs/2402.02655v3",
          "size": "7911kb",
          "version": "v3"
        }
      ],
      "title": "VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based Machine Reading Comprehension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02655",
        "HTML": "https://arxiv.org/html/2402.02655",
        "PDF": "https://arxiv.org/pdf/2402.02655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces VlogQA, a Vietnamese spoken language corpus for machine reading comprehension, involving the creation of a new dataset from spoken language data, which is directly relevant to LLM training data processing."
      },
      "tasks": [
        "Articles",
        "Machine Reading Comprehension",
        "Reading Comprehension"
      ],
      "repo_urls": [
        "https://github.com/sonlam1102/vlogqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06443",
      "abstract": "The problem of learning single index and multi index models has gained significant interest as a fundamental task in high-dimensional statistics. Many recent works have analysed gradient-based methods, particularly in the setting of isotropic data distributions, often in the context of neural network training. Such studies have uncovered precise characterisations of algorithmic sample complexity in terms of certain analytic properties of the target function, such as the leap, information, and generative exponents. These properties establish a quantitative separation between low and high complexity learning tasks. In this work, we show that high complexity cases are rare. Specifically, we prove that introducing a small random perturbation to the data distribution--via a random shift in the first moment--renders any Gaussian single index model as easy to learn as a linear function. We further extend this result to a class of multi index models, namely sparse Boolean functions, also known as Juntas.",
      "authors": [
        "Elisabetta Cornacchia",
        "Dan Mikulincer",
        "Elchanan Mossel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T13:19:30+00:00",
          "link": "https://arxiv.org/abs/2502.06443v1",
          "size": "79kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:48:50+00:00",
          "link": "https://arxiv.org/abs/2502.06443v2",
          "size": "81kb",
          "version": "v2"
        }
      ],
      "title": "Low-dimensional Functions are Efficiently Learnable under Randomly Biased Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06443",
        "PDF": "https://arxiv.org/pdf/2502.06443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the efficiency of learning low-dimensional functions under randomly biased distributions, with a focus on learning models rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.18208",
      "abstract": "We study the convergence of gradient methods for the training of mean-field single-hidden-layer neural networks with square loss. For this high-dimensional and non-convex optimization problem, most known convergence results are either qualitative or rely on a neural tangent kernel analysis where nonlinear representations of the data are fixed. Using that this problem belongs to the class of separable nonlinear least squares problems, we consider here a Variable Projection (VarPro) or two-timescale learning algorithm, thereby eliminating the linear variables and reducing the learning problem to the training of nonlinear features. In a teacher-student scenario, we show such a strategy enables provable convergence rates for the sampling of a teacher feature distribution. Precisely, in the limit where the regularization strength vanishes, we show that the dynamic of the feature distribution corresponds to a weighted ultra-fast diffusion equation. Recent results on the asymptotic behavior of such PDEs then give quantitative guarantees for the convergence of the learned feature distribution.",
      "authors": [
        "Rapha\\\"el Barboni (\\'ENS-PSL)",
        "Gabriel Peyr\\'e (CNRS and \\'ENS-PSL)",
        "Fran\\c{c}ois-Xavier Vialard (LIGM)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T09:40:10+00:00",
          "link": "https://arxiv.org/abs/2504.18208v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:02:53+00:00",
          "link": "https://arxiv.org/abs/2504.18208v2",
          "size": "3549kb",
          "version": "v2"
        }
      ],
      "title": "Ultra-fast feature learning for the training of two-layer neural networks in the two-timescale regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18208",
        "PDF": "https://arxiv.org/pdf/2504.18208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers around convergence of gradient methods for neural networks, without contributions to LLM training data processing or dataset generation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.13545",
      "abstract": "While the capabilities of large language models (LLMs) have progressed significantly, their use in high-stakes applications have been limited due to risks of hallucination. One key approach in reducing hallucination is retrieval-augmented generation (RAG), but even in such setups, LLMs may still hallucinate when presented with questions outside of the knowledge base. Such behavior is unacceptable in high-stake applications where LLMs are expected to abstain from answering queries it does not have sufficient context on. In this work, we present a novel methodology for systematically evaluating out-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not know) in the RAG setting, without the need for manual annotation of gold standard answers. We implement our methodology in knowornot, an open-source library that enables users to develop their own customized evaluation data and pipelines for OOKB robustness. knowornot comprises four main features. Firstly, it provides a unified, high-level API that streamlines the process of setting up and running robustness benchmarks. Secondly, its modular architecture emphasizes extensibility and flexibility, allowing users to easily integrate their own LLM clients and RAG settings. Thirdly, its rigorous data modeling design ensures experiment reproducibility, reliability and traceability. Lastly, it implements a comprehensive suite of tools for users to customize their pipelines. We demonstrate the utility of knowornot by developing a challenging benchmark, PolicyBench, which spans four Question-Answer (QA) chatbots on government policies, and analyze its OOKB robustness. The source code of knowornot is available https://github.com/govtech-responsibleai/KnowOrNot.",
      "authors": [
        "Jessica Foo",
        "Pradyumna Shyama Prasad",
        "Shaun Khoo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T03:17:41+00:00",
          "link": "https://arxiv.org/abs/2505.13545v1",
          "size": "201kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:09:54+00:00",
          "link": "https://arxiv.org/abs/2505.13545v2",
          "size": "201kb",
          "version": "v2"
        }
      ],
      "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13545",
        "HTML": "https://arxiv.org/html/2505.13545",
        "PDF": "https://arxiv.org/pdf/2505.13545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the out-of-knowledge base robustness of LLMs in retrieval-augmented generation setups, primarily emphasizing the development of an evaluation library rather than LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "govtech/PolicyBench",
          "downloads": "8",
          "likes": "0",
          "link": "https://huggingface.co/datasets/govtech/PolicyBench"
        }
      ],
      "tasks": [
        "Hallucination",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/govtech-responsibleai/knowornot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04422",
      "abstract": "The recent advancement of artificial intelligence, especially machine learning (ML), has significantly impacted software engineering research, including bug report analysis. ML aims to automate the understanding, extraction, and correlation of information from bug reports. Despite its growing importance, there has been no comprehensive review in this area. In this paper, we present a systematic literature review covering 1,825 papers, selecting 204 for detailed analysis. We derive seven key findings: 1) Extensive use of CNN, LSTM, and $k$NN for bug report analysis, with advanced models like BERT underutilized due to their complexity. 2) Word2Vec and TF-IDF are popular for feature representation, with a rise in deep learning approaches. 3) Stop word removal is the most common preprocessing, with structural methods rising after 2020. 4) Eclipse and Mozilla are the most frequently evaluated software projects. 5) Bug categorization is the most common task, followed by bug localization and severity prediction. 6) There is increasing attention on specific bugs like non-functional and performance bugs. 7) Common evaluation metrics are F1-score, Recall, Precision, and Accuracy, with $k$-fold cross-validation preferred for model evaluation. 8) Many studies lack robust statistical tests. We also identify six promising future research directions to provide useful insights for practitioners.",
      "authors": [
        "Guoming Long",
        "Jingzhi Gong",
        "Hui Fang",
        "Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T15:17:59+00:00",
          "link": "https://arxiv.org/abs/2507.04422v1",
          "size": "1466kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:18:33+00:00",
          "link": "https://arxiv.org/abs/2507.04422v2",
          "size": "1465kb",
          "version": "v2"
        }
      ],
      "title": "Learning Software Bug Reports: A Systematic Literature Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04422",
        "PDF": "https://arxiv.org/pdf/2507.04422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a systematic literature review on machine learning in software bug report analysis. It does not relate to LLM training data processing or contribute to training data operations or techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14314",
      "abstract": "Online news outlets operate predominantly on an advertising-based revenue model, compelling journalists to create headlines that are often scandalous, intriguing, and provocative -- commonly referred to as clickbait. Automatic detection of clickbait headlines is essential for preserving information quality and reader trust in digital media and requires both contextual understanding and world knowledge. For this task, particularly in less-resourced languages, it remains unclear whether fine-tuned methods or in-context learning (ICL) yield better results. In this paper, we compile CLIC, a novel dataset for clickbait detection of Croatian news headlines spanning a 20-year period and encompassing mainstream and fringe outlets. We fine-tune the BERTi\\'c model on this task and compare its performance to LLM-based ICL methods with prompts both in Croatian and English. Finally, we analyze the linguistic properties of clickbait. We find that nearly half of the analyzed headlines contain clickbait, and that finetuned models deliver better results than general LLMs.",
      "authors": [
        "Marija An{\\dj}edeli\\'c",
        "Dominik \\v{S}ipek",
        "Laura Majer",
        "Jan \\v{S}najder"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.14314v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "What Makes You CLIC: Detection of Croatian Clickbait Headlines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14314",
        "HTML": "https://arxiv.org/html/2507.14314",
        "PDF": "https://arxiv.org/pdf/2507.14314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves creating a dataset (CLIC) for clickbait detection, the main focus is on task-specific model performance rather than general LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15032",
      "abstract": "The discovery of fast and variable coherent signals in a handful of ultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington accreting neutron stars, and drastically changed the understanding of the ULX class. Our capability of discovering pulsations in ULXs is limited, among others, by poor statistics. However, catalogues and archives of high-energy missions contain information which can be used to identify new candidate pulsating ULXs (PULXs). The goal of this research is to single out candidate PULXs among those ULXs which have not shown pulsations due to an unfavourable combination of factors. We applied an AI approach to an updated database of ULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm to sort out sources with similar characteristics into two clusters. Then, the sample of known PULX observations has been used to set the separation threshold between the two clusters and to identify the one containing the new candidate PULXs. We found that only a few criteria are needed to assign the membership of an observation to one of the two clusters. The cluster of new candidate PULXs counts 85 unique sources for 355 observations, with $\\sim$85% of these new candidates having multiple observations. A preliminary timing analysis found no new pulsations for these candidates. This work presents a sample of new candidate PULXs observed by XMM-Newton, the properties of which are similar (in a multi-dimensional phase space) to those of the known PULXs, despite the absence of pulsations in their light curves. While this result is a clear example of the predictive power of AI-based methods, it also highlights the need for high-statistics observational data to reveal coherent signals from the sources in this sample and thus validate the robustness of the approach.",
      "authors": [
        "Nicol\\`o Oreste Pinciroli Vago",
        "Roberta Amato",
        "Matteo Imbrogno",
        "GianLuca Israel",
        "Andrea Belfiore",
        "Konstantinos Kovlakas",
        "Piero Fraternali",
        "Mario Pasquato"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:33:18+00:00",
          "link": "https://arxiv.org/abs/2507.15032v1",
          "size": "220kb",
          "version": "v1"
        }
      ],
      "title": "The hunt for new pulsating ultraluminous X-ray sources: a clustering approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15032",
        "HTML": "https://arxiv.org/html/2507.15032",
        "PDF": "https://arxiv.org/pdf/2507.15032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper applies clustering approaches to discover candidate pulsating ultraluminous X-ray sources in astrophysics, lacking relevance to LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15202",
      "abstract": "Millions of people listen to podcasts, audio stories, and lectures, but editing speech remains tedious and time-consuming. Creators remove unnecessary words, cut tangential discussions, and even re-record speech to make recordings concise and engaging. Prior work automatically summarized speech by removing full sentences (extraction), but rigid extraction limits expressivity. AI tools can summarize then re-synthesize speech (abstraction), but abstraction strips the speaker's style. We present TalkLess, a system that flexibly combines extraction and abstraction to condense speech while preserving its content and style. To edit speech, TalkLess first generates possible transcript edits, selects edits to maximize compression, coverage, and audio quality, then uses a speech editing model to translate transcript edits into audio edits. TalkLess's interface provides creators control over automated edits by separating low-level wording edits (via the compression pane) from major content edits (via the outline pane). TalkLess achieves higher coverage and removes more speech errors than a state-of-the-art extractive approach. A comparison study (N=12) showed that TalkLess significantly decreased cognitive load and editing effort in speech editing. We further demonstrate TalkLess's potential in an exploratory study (N=3) where creators edited their own speech.",
      "authors": [
        "Karim Benharrak",
        "Puyuan Peng",
        "Amy Pavel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:00:00+00:00",
          "link": "https://arxiv.org/abs/2507.15202v1",
          "size": "10844kb",
          "version": "v1"
        }
      ],
      "title": "TalkLess: Blending Extractive and Abstractive Speech Summarization for Editing Speech to Preserve Content and Style",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15202",
        "HTML": "https://arxiv.org/html/2507.15202",
        "PDF": "https://arxiv.org/pdf/2507.15202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for summarizing and editing speech, blending extractive and abstractive techniques, which is not connected to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15268",
      "abstract": "The injection molding industry faces critical challenges in preserving and transferring field knowledge, particularly as experienced workers retire and multilingual barriers hinder effective communication. This study introduces IM-Chat, a multi-agent framework based on large language models (LLMs), designed to facilitate knowledge transfer in injection molding. IM-Chat integrates both limited documented knowledge (e.g., troubleshooting tables, manuals) and extensive field data modeled through a data-driven process condition generator that infers optimal manufacturing settings from environmental inputs such as temperature and humidity, enabling robust and context-aware task resolution. By adopting a retrieval-augmented generation (RAG) strategy and tool-calling agents within a modular architecture, IM-Chat ensures adaptability without the need for fine-tuning. Performance was assessed across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance and correctness, and was further supplemented by automated evaluation using GPT-4o guided by a domain-adapted instruction prompt. The evaluation results indicate that more capable models tend to achieve higher accuracy, particularly in complex, tool-integrated scenarios. Overall, these findings demonstrate the viability of multi-agent LLM systems for industrial knowledge workflows and establish IM-Chat as a scalable and generalizable approach to AI-assisted decision support in manufacturing.",
      "authors": [
        "Junhyeong Lee",
        "Joon-Young Kim",
        "Heekyu Kim",
        "Inhyo Lee and Seunghwa Ryu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:13:53+00:00",
          "link": "https://arxiv.org/abs/2507.15268v1",
          "size": "1838kb",
          "version": "v1"
        }
      ],
      "title": "IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15268",
        "PDF": "https://arxiv.org/pdf/2507.15268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "IM-Chat discusses using LLMs for knowledge transfer in the injection molding industry but focuses on application-level solutions. It does not make a significant contribution to LLM training data processing, though it briefly mentions integrating data-driven methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15415",
      "abstract": "Polylogarithmic time delineates a relevant notion of feasibility on several classical computational models such as Boolean circuits or parallel random access machines. As far as the quantum paradigm is concerned, this notion yields the complexity class FBQPOLYLOG of functions approximable in polylogarithmic time with a quantum random-access Turing machine. We introduce a quantum programming language with first-order recursive procedures, which provides the first programming-language-based characterization of FBQPOLYLOG. Each program computes a function in FBQPOLYLOG (soundness) and, conversely, each function of this complexity class is computed by a program (completeness). We also provide a compilation strategy from programs to uniform families of quantum circuits of polylogarithmic depth and polynomial size, whose set of computed functions is known as QNC, and recover the well-known separation result FBQPOLYLOG $\\subsetneq$ QNC.",
      "authors": [
        "Florent Ferrari (ENS de Lyon)",
        "Emmanuel Hainry (MOCQUA",
        "LORIA)",
        "Romain P\\'echoux (LORIA",
        "MOCQUA)",
        "M\\'ario Silva (LORIA",
        "MOCQUA)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:12:38+00:00",
          "link": "https://arxiv.org/abs/2507.15415v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Programming in Polylogarithmic Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15415",
        "PDF": "https://arxiv.org/pdf/2507.15415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantum programming and complexity classes, which are unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15564",
      "abstract": "Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain method for the analysis of nonlinear systems. However, we show that the current SRG analysis suffers from a pitfall that limits its applicability in analyzing practical nonlinear systems. We overcome this pitfall by introducing a novel reformulation of the SRG of a linear time-invariant operator and combining the SRG with the Nyquist criterion. The result is a theorem that can be used to assess stability and $L_2$-gain performance for general interconnections of nonlinear dynamic systems. We provide practical calculation results for canonical interconnections and apply our result to Lur'e systems to obtain a generalization of the celebrated circle criterion, which deals with broader class of nonlinearities, and we derive (incremental) $L_2$-gain performance bounds. We illustrate the power of the new approach on the analysis of several examples.",
      "authors": [
        "Julius P. J. Krebbekx",
        "Roland T\\'oth",
        "Amritam Das"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:42:53+00:00",
          "link": "https://arxiv.org/abs/2507.15564v1",
          "size": "437kb",
          "version": "v1"
        }
      ],
      "title": "Scaled Relative Graph Analysis of General Interconnections of SISO Nonlinear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15564",
        "HTML": "https://arxiv.org/html/2507.15564",
        "PDF": "https://arxiv.org/pdf/2507.15564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a graphical frequency-domain method for analyzing nonlinear systems, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2210.14702",
      "abstract": "We present a detailed privacy analysis of Samsung's Offline Finding (OF) protocol, which is part of Samsung's Find My Mobile (FMM) location tracking system for locating Samsung mobile devices, such as Samsung smartphones and Bluetooth trackers (Galaxy SmartTags). The OF protocol uses Bluetooth Low Energy (BLE) to broadcast a unique beacon for a lost device. This beacon is then picked up by nearby Samsung phones or tablets (the {\\em finder} devices), which then forward the unique beacon, along with the location it was detected at, to a Samsung managed server. The owner of a lost device can then query the server to locate their device. We examine several security and privacy related properties of the OF protocol and its implementation, from the perspectives of the owner, the finder and the vendor. These include examining: the possibility of identifying the owner of a device through the Bluetooth data obtained from the device, the possibility for a malicious actor to perform unwanted tracking against a person by exploiting the OF network, the possibility for the vendor to de-anonymise location reports to determine the locations of the owners or the finders of lost devices, and the possibility for an attacker to compromise the integrity of the location reports. Our findings suggest that there are privacy risks on all accounts, arising from issues in the design and the implementation of the OF protocol.",
      "authors": [
        "Tingfeng Yu",
        "James Henderson",
        "Alwen Tiu",
        "Thomas Haines"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-26T13:31:24+00:00",
          "link": "https://arxiv.org/abs/2210.14702v1",
          "size": "470kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:16:59+00:00",
          "link": "https://arxiv.org/abs/2210.14702v2",
          "size": "16764kb",
          "version": "v2"
        }
      ],
      "title": "Privacy Analysis of Samsung's Crowd-Sourced Bluetooth Location Tracking System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.14702",
        "PDF": "https://arxiv.org/pdf/2210.14702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a privacy analysis of a location tracking system and does not address any data processing operations related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12788",
      "abstract": "Despite progress in Arabic large language models, such as Jais and AceGPT, their evaluation on commonsense reasoning has largely relied on machine-translated datasets, which lack cultural depth and may introduce Anglocentric biases. Commonsense reasoning is shaped by geographical and cultural contexts, and existing English datasets fail to capture the diversity of the Arab world. To address this, we introduce ArabCulture, a commonsense reasoning dataset in Modern Standard Arabic (MSA), covering cultures of 13 countries across the Gulf, Levant, North Africa, and the Nile Valley. The dataset was built from scratch by engaging native speakers to write and validate culturally relevant questions for their respective countries. ArabCulture spans 12 daily life domains with 54 fine-grained subtopics, reflecting various aspects of social norms, traditions, and everyday experiences. Zero-shot evaluations show that open-weight language models with up to 32B parameters struggle to comprehend diverse Arab cultures, with performance varying across regions. These findings highlight the need for more culturally aware models and datasets tailored to the Arabic-speaking world.",
      "authors": [
        "Abdelrahman Sadallah and Junior Cedric Tonga and Khalid Almubarak and Saeed Almheiri and Farah Atif and Chatrine Qwaider and Karima Kadaoui and Sara Shatnawi and Yaser Alesh and Fajri Koto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T11:49:54+00:00",
          "link": "https://arxiv.org/abs/2502.12788v1",
          "size": "2168kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:30:52+00:00",
          "link": "https://arxiv.org/abs/2502.12788v2",
          "size": "1406kb",
          "version": "v2"
        }
      ],
      "title": "Commonsense Reasoning in Arab Culture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12788",
        "HTML": "https://arxiv.org/html/2502.12788",
        "PDF": "https://arxiv.org/pdf/2502.12788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces ArabCulture, a dataset built specifically for evaluating commonsense reasoning in the context of Arab culture. It involves creating a culturally relevant dataset from scratch, which aligns with LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "MBZUAI/ArabCulture",
          "downloads": "969",
          "likes": "11",
          "link": "https://huggingface.co/datasets/MBZUAI/ArabCulture"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09487",
      "abstract": "Visual and semantic concepts are often structured in a hierarchical manner. For instance, textual concept `cat' entails all images of cats. A recent study, MERU, successfully adapts multimodal learning techniques from Euclidean space to hyperbolic space, effectively capturing the visual-semantic hierarchy. However, a critical question remains: how can we more efficiently train a model to capture and leverage this hierarchy? In this paper, we propose the Hyperbolic Masked Image and Distillation Network (HMID-Net), a novel and efficient method that integrates Masked Image Modeling (MIM) and knowledge distillation techniques within hyperbolic space. To the best of our knowledge, this is the first approach to leverage MIM and knowledge distillation in hyperbolic space to train highly efficient models. In addition, we introduce a distillation loss function specifically designed to facilitate effective knowledge transfer in hyperbolic space. Our experiments demonstrate that MIM and knowledge distillation techniques in hyperbolic space can achieve the same remarkable success as in Euclidean space. Extensive evaluations show that our method excels across a wide range of downstream tasks, significantly outperforming existing models like MERU and CLIP in both image classification and retrieval.",
      "authors": [
        "Changli Wang",
        "Fang Yin",
        "Jiafeng Liu",
        "Rui Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T04:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.09487v1",
          "size": "2787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:57:55+00:00",
          "link": "https://arxiv.org/abs/2507.09487v2",
          "size": "2783kb",
          "version": "v2"
        }
      ],
      "title": "HMID-Net: An Exploration of Masked Image Modeling and Knowledge Distillation in Hyperbolic Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09487",
        "HTML": "https://arxiv.org/html/2507.09487",
        "PDF": "https://arxiv.org/pdf/2507.09487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on masked image modeling and knowledge distillation in hyperbolic space, which does not pertain to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14569",
      "abstract": "We consider the problems of characterizing and testing the stability of cellular automata configurations that evolve on a two-dimensional torus according to threshold rules with respect to the von-Neumann neighborhood. While stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are trivial (and hence easily testable), the other threshold rules exhibit much more diverse behaviors. We first characterize the structure of stable configurations with respect to the Threshold-2 (similarly, Threshold-4) and Threshold-3 (Majority) rules. We then design and analyze a testing algorithm that distinguishes between configurations that are stable with respect to the Threshold-2 rule, and those that are $\\epsilon$-far from any stable configuration, where the query complexity of the algorithm is independent of the size of the configuration and depends quadratically on $1/\\epsilon$.",
      "authors": [
        "Yonatan Nakar and Dana Ron"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T10:35:28+00:00",
          "link": "https://arxiv.org/abs/2507.14569v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing and Testing Configuration Stability in Two-Dimensional Threshold Cellular Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14569",
        "HTML": "https://arxiv.org/html/2507.14569",
        "PDF": "https://arxiv.org/pdf/2507.14569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the stability of cellular automata configurations and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15486",
      "abstract": "The visual systems of birds and mammals exhibit remarkable organizational similarities: the dorsal ventricular ridge (DVR) demonstrates a columnar microcircuitry that parallels the cortical architecture observed in mammals. However, the specific neuronal subtypes involved and their functional roles in pigeon hierarchical visual processing remain unclear. This study investigates the role of excitatory parvalbumin (PV+) neurons within the Ento-MVL (entoallium-mesopallium venterolaterale) circuit of pigeons underlying hierarchical moving target recognition. Electrophysiological recordings and immunofluorescence staining reveal that excitatory PV+ neurons originating from the entopallial internal (Ei) predominantly modulate MVL responses to varying visual stimuli. Using a heterochronous-speed recurrent neural network (HS-RNN) model, we further validated these dynamics, replicating the rapid adaptation of the Ento-MVL circuit to moving visual targets. The findings suggest that the fast-spiking and excitatory properties of PV+ neurons enable rapid processing of motion-related information within the Ento-MVL circuit. Our results elucidate the functional role of excitatory PV+ neurons in hierarchical information processing under the columnar organization of the visual DVR and underscore the convergent neural processing strategies shared by avian and mammalian visual systems.",
      "authors": [
        "Shan Lu",
        "Xiaoteng Zhang",
        "Yueyang Cang",
        "Shihao Pan",
        "Yanyan Peng",
        "Xinwei Li",
        "Shaoju Zeng",
        "Yingjie Zhu",
        "Li Shi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:42:17+00:00",
          "link": "https://arxiv.org/abs/2507.15486v1",
          "size": "880kb",
          "version": "v1"
        }
      ],
      "title": "The Role of Excitatory Parvalbumin-positive Neurons in the Tectofugal Pathway of Pigeon (Columba livia) Hierarchical Visual Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15486",
        "PDF": "https://arxiv.org/pdf/2507.15486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines neuronal functions in visual processing in pigeons and does not touch upon the technical contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15826",
      "abstract": "Natural language interfaces offer a compelling approach for music recommendation, enabling users to express complex preferences conversationally. While Large Language Models (LLMs) show promise in this direction, their scalability in recommender systems is limited by high costs and latency. Retrieval-based approaches using smaller language models mitigate these issues but often rely on single-modal item representations, overlook long-term user preferences, and require full model retraining, posing challenges for real-world deployment. In this paper, we present JAM (Just Ask for Music), a lightweight and intuitive framework for natural language music recommendation. JAM models user-query-item interactions as vector translations in a shared latent space, inspired by knowledge graph embedding methods like TransE. To capture the complexity of music and user intent, JAM aggregates multimodal item features via cross-attention and sparse mixture-of-experts. We also introduce JAMSessions, a new dataset of over 100k user-query-item triples with anonymized user/item embeddings, uniquely combining conversational queries and user long-term preferences. Our results show that JAM provides accurate recommendations, produces intuitive representations suitable for practical use cases, and can be easily integrated with existing music recommendation stacks.",
      "authors": [
        "Alessandro B. Melchiorre",
        "Elena V. Epure",
        "Shahed Masoudian",
        "Gustavo Escobedo",
        "Anna Hausberger",
        "Manuel Moussallam",
        "Markus Schedl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:36:03+00:00",
          "link": "https://arxiv.org/abs/2507.15826v1",
          "size": "356kb",
          "version": "v1"
        }
      ],
      "title": "Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15826",
        "HTML": "https://arxiv.org/html/2507.15826",
        "PDF": "https://arxiv.org/pdf/2507.15826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces JAM, a framework for music recommendation involving LLMs, its main contribution is in the context of recommendation systems and multimodal interactions rather than LLM training data processing. It does introduce the JAMSessions dataset but it is focused on recommendation contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.04161",
      "abstract": "Attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. To deepen our understanding of their sequential modeling capabilities, there is a growing interest in using Markov input processes to study them. A key finding is that when trained on first-order Markov chains, transformers with two or more layers consistently develop an induction head mechanism to estimate the in-context bigram conditional distribution. In contrast, single-layer transformers, unable to form an induction head, directly learn the Markov kernel but often face a surprising challenge: they become trapped in local minima representing the unigram distribution, whereas deeper models reliably converge to the ground-truth bigram. While single-layer transformers can theoretically model first-order Markov chains, their empirical failure to learn this simple kernel in practice remains a curious phenomenon. To explain this contrasting behavior of single-layer models, in this paper we introduce a new framework for a principled analysis of transformers via Markov chains. Leveraging our framework, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima (bigram) and bad local minima (unigram) contingent on data properties and model architecture. We precisely delineate the regimes under which these local optima occur. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. Finally, we outline several open problems in this arena. Code is available at https://github.com/Bond1995/Markov .",
      "authors": [
        "Ashok Vardhan Makkuva",
        "Marco Bondaschi",
        "Adway Girish",
        "Alliot Nagle",
        "Martin Jaggi",
        "Hyeji Kim",
        "Michael Gastpar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T17:18:59+00:00",
          "link": "https://arxiv.org/abs/2402.04161v1",
          "size": "100kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:23:40+00:00",
          "link": "https://arxiv.org/abs/2402.04161v2",
          "size": "1022kb",
          "version": "v2"
        }
      ],
      "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04161",
        "HTML": "https://arxiv.org/html/2402.04161",
        "PDF": "https://arxiv.org/pdf/2402.04161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the theoretical analysis of transformers using Markov processes, focusing on model behavior rather than training data processing for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/bond1995/markov"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12137",
      "abstract": "Modeling and rendering dynamic urban driving scenes is crucial for self-driving simulation. Current high-quality methods typically rely on costly manual object tracklet annotations, while self-supervised approaches fail to capture dynamic object motions accurately and decompose scenes properly, resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised framework for high-quality free-viewpoint rendering of driving scenes from a single log. At its core is a novel learnable motion model that integrates locality-aware B-spline curves with global-aware trigonometric functions, enabling flexible yet precise dynamic object modeling. Rather than requiring comprehensive semantic labeling, AD-GS automatically segments scenes into objects and background with the simplified pseudo 2D segmentation, representing objects using dynamic Gaussians and bidirectional temporal visibility masks. Further, our model incorporates visibility reasoning and physically rigid regularization to enhance robustness. Extensive evaluations demonstrate that our annotation-free model significantly outperforms current state-of-the-art annotation-free methods and is competitive with annotation-dependent approaches.",
      "authors": [
        "Jiawei Xu",
        "Kai Deng",
        "Zexin Fan",
        "Shenlong Wang",
        "Jin Xie",
        "Jian Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T11:10:57+00:00",
          "link": "https://arxiv.org/abs/2507.12137v1",
          "size": "18515kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:05:53+00:00",
          "link": "https://arxiv.org/abs/2507.12137v2",
          "size": "18515kb",
          "version": "v2"
        }
      ],
      "title": "AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12137",
        "HTML": "https://arxiv.org/html/2507.12137",
        "PDF": "https://arxiv.org/pdf/2507.12137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses self-supervised modeling and rendering of driving scenes and does not pertain to LLM training data collection, processing, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14239",
      "abstract": "Multilingual Large Language Models(MLLMs) demonstrate strong generalization across languages, yet they remain prone to hallucinations, especially in low-resource languages, due to training data imbalances. These hallucinations, which include inaccurate or fabricated outputs, are particularly problematic in domain-specific generation tasks (Chataigner et al., 2024). To address this challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for mitigating hallucination in MLLMs. Our approach first enhances cross-lingual semantic alignment through curriculum-based contrastive learning combined with next-token prediction during continued pre-training. Building on this foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting strategy during instruction fine-tuning, which guides the model to reason in a high-resource language before generating answers in the target low-resource language. Experimental results show that CCL-XCoT reduces hallucination rates by up to 62% and substantially improves factual knowledge transfer across language pairs, without relying on external retrieval or multi-model ensembles.",
      "authors": [
        "Weihua Zheng",
        "Roy Ka-Wei Lee",
        "Zhengyuan Liu",
        "Kui Wu",
        "AiTi Aw",
        "Bowei Zou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:25:24+00:00",
          "link": "https://arxiv.org/abs/2507.14239v1",
          "size": "245kb",
          "version": "v1"
        }
      ],
      "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14239",
        "HTML": "https://arxiv.org/html/2507.14239",
        "PDF": "https://arxiv.org/pdf/2507.14239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper proposes a method to mitigate hallucination in multilingual LLMs using a cross-lingual knowledge transfer approach, it primarily focuses on model fine-tuning strategies and not on substantial training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14449",
      "abstract": "Real-world infrared imagery presents unique challenges for vision-language models due to the scarcity of aligned text data and domain-specific characteristics. Although existing methods have advanced the field, their reliance on synthetic infrared images generated through style transfer from visible images, which limits their ability to capture the unique characteristics of the infrared modality. To address this, we propose IRGPT, the first multi-modal large language model for real-world infrared images, built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K authentic image-text pairs. The proposed IR-TD dataset contains real infrared images paired with meticulously handcrafted texts, where the initial drafts originated from two complementary processes: (1) LLM-generated descriptions of visible images, and (2) rule-based descriptions of annotations. Furthermore, we introduce a bi-cross-modal curriculum transfer learning strategy that systematically transfers knowledge from visible to infrared domains by considering the difficulty scores of both infrared-visible and infrared-text. Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT achieves state-of-the-art performance even compared with larger-scale models.",
      "authors": [
        "Zhe Cao and Jin Zhang and Ruiheng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:53:01+00:00",
          "link": "https://arxiv.org/abs/2507.14449v1",
          "size": "2960kb",
          "version": "v1"
        }
      ],
      "title": "IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14449",
        "HTML": "https://arxiv.org/html/2507.14449",
        "PDF": "https://arxiv.org/pdf/2507.14449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents IRGPT, a model built on the newly created InfraRed-Text Dataset (IR-TD), and involves dataset creation and processing with LLM-generated and rule-based text descriptions, making a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14758",
      "abstract": "Generative models have recently demonstrated strong potential in multi-behavior recommendation systems, leveraging the expressive power of transformers and tokenization to generate personalized item sequences. However, their adoption is hindered by (1) the lack of explicit information for token reasoning, (2) high computational costs due to quadratic attention complexity and dense sequence representations after tokenization, and (3) limited multi-scale modeling over user history. In this work, we propose GRACE (Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization), a novel generative framework for multi-behavior sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT) tokenization method that encodes user-item interactions with explicit attributes from product knowledge graphs (e.g., category, brand, price) over semantic tokenization, enabling interpretable and behavior-aligned generation. To address the inefficiency of standard attention, we design a Journey-Aware Sparse Attention (JSA) mechanism, which selectively attends to compressed, intra-, inter-, and current-context segments in the tokenized sequence. Experiments on two real-world datasets show that GRACE significantly outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and +106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces attention computation by up to 48% with long sequences.",
      "authors": [
        "Luyi Ma",
        "Wanjia Zhang",
        "Kai Zhao",
        "Abhishek Kulkarni",
        "Lalitesh Morishetti",
        "Anjana Ganesh",
        "Ashish Ranjan",
        "Aashika Padmanabhan",
        "Jianpeng Xu",
        "Jason Cho",
        "Praveen Kanumala",
        "Kaushiki Nag",
        "Sumit Dutta",
        "Kamiya Motwani",
        "Malay Patel",
        "Evren Korpeoglu",
        "Sushant Kumar",
        "Kannan Achan"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:23:23+00:00",
          "link": "https://arxiv.org/abs/2507.14758v1",
          "size": "898kb",
          "version": "v1"
        }
      ],
      "title": "GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14758",
        "HTML": "https://arxiv.org/html/2507.14758",
        "PDF": "https://arxiv.org/pdf/2507.14758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a generative recommendation system using sparse attention, focusing on recommendation algorithms rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14944",
      "abstract": "Deploying Large Language Models (LLMs) in high-stakes domains is impeded by a dual challenge: the need for deep, dynamic expert knowledge injection and nuanced value alignment. Prevailing paradigms often address these challenges separately, creating a persistent tension between knowledge and alignment; knowledge-focused methods like Retrieval-Augmented Generation (RAG) have limited deep alignment capabilities, while alignment-focused methods like Reinforcement Learning from Human Feedback (RLHF) struggle with the agile injection of expert wisdom. This paper introduces a new collaborative philosophy, Expert-owned AI behavior design, realized through Architectural Alignment-a paradigm that unifies these two goals within a single framework called the Layered Expert Knowledge Injection Architecture (LEKIA). LEKIA operates as an intelligent intermediary that guides an LLM's reasoning process without altering its weights, utilizing a three-tiered structure: a Theoretical Layer for core principles, a Practical Layer for exemplary cases, and an Evaluative Layer for real-time, value-aligned self-correction. We demonstrate the efficacy of this paradigm through the successful implementation of a LEKIA-based psychological support assistant for the special education field. Our work presents a path toward more responsible and expert-driven AI, empowering domain specialists to directly architect AI behavior and resolve the tension between knowledge and alignment.",
      "authors": [
        "Boning Zhao and Yutong Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T12:45:07+00:00",
          "link": "https://arxiv.org/abs/2507.14944v1",
          "size": "414kb",
          "version": "v1"
        }
      ],
      "title": "LEKIA: A Framework for Architectural Alignment via Expert Knowledge Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14944",
        "HTML": "https://arxiv.org/html/2507.14944",
        "PDF": "https://arxiv.org/pdf/2507.14944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for architectural alignment and expert knowledge injection into LLMs, but it does not address training data processing operations such as dataset creation, filtering, or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15121",
      "abstract": "Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational bottleneck in sparse tensor decomposition. As real-world sparse tensors grow to billions of nonzeros, they increasingly demand higher memory capacity and compute throughput from hardware accelerators. In this work, we present AMPED, a multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale sparse tensors. AMPED scales beyond the limits of a single GPU, meeting both the memory and performance requirements of large-scale workloads. We introduce a partitioning strategy combined with a dynamic load balancing scheme to distribute computation and minimize GPU idle time. On real-world billion-scale tensors, AMPED achieves a 5.1x geometric mean speedup in total execution time over state-of-the-art GPU baselines using 4 GPUs on a single CPU node.",
      "authors": [
        "Sasindu Wijeratne",
        "Rajgopal Kannan",
        "Viktor Prasanna"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T21:01:13+00:00",
          "link": "https://arxiv.org/abs/2507.15121v1",
          "size": "238kb",
          "version": "v1"
        }
      ],
      "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15121",
        "HTML": "https://arxiv.org/html/2507.15121",
        "PDF": "https://arxiv.org/pdf/2507.15121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work targets the acceleration of sparse tensor decomposition using GPUs. It focuses on computational efficiency in tensor-based methods and lacks any mention of training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15521",
      "abstract": "Do large language models (LLMs) construct and manipulate internal world models, or do they rely solely on statistical associations represented as output layer token probabilities? We adapt cognitive science methodologies from human mental models research to test LLMs on pulley system problems using TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical advantage (MA). State-of-the-art models performed marginally but significantly above chance, and their estimates correlated significantly with ground-truth MA. Significant correlations between number of pulleys and model estimates suggest that models employed a pulley counting heuristic, without necessarily simulating pulley systems to derive precise values. Study 2 tested this by probing whether LLMs represent global features crucial to MA estimation. Models evaluated a functionally connected pulley system against a fake system with randomly placed components. Without explicit cues, models identified the functional system as having greater MA with F1=0.8, suggesting LLMs could represent systems well enough to differentiate jumbled from functional systems. Study 3 built on this by asking LLMs to compare functional systems with matched systems which were connected up but which transferred no force to the weight; LLMs identified the functional system with F1=0.46, suggesting random guessing. Insofar as they may generalize, these findings are compatible with the notion that LLMs manipulate internal world models, sufficient to exploit statistical associations between pulley count and MA (Study 1), and to approximately represent system components' spatial relations (Study 2). However, they may lack the facility to reason over nuanced structural connectivity (Study 3). We conclude by advocating the utility of cognitive scientific methods to evaluate the world-modeling capacities of artificial intelligence systems.",
      "authors": [
        "Cole Robertson and Philip Wolff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:42:03+00:00",
          "link": "https://arxiv.org/abs/2507.15521v1",
          "size": "1443kb",
          "version": "v1"
        }
      ],
      "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15521",
        "HTML": "https://arxiv.org/html/2507.15521",
        "PDF": "https://arxiv.org/pdf/2507.15521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates LLMs' abilities to model world systems and mechanical reasoning, but it does not discuss data processing for LLM training or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "1312.4874",
      "abstract": "Modern information systems that support complex business processes generally maintain significant amounts of process execution data, particularly records of events corresponding to the execution of activities (event logs). In this paper, we present an approach to analyze such event logs in order to predictively monitor business goals during business process execution. At any point during an execution of a process, the user can define business goals in the form of linear temporal logic rules. When an activity is being executed, the framework identifies input data values that are more (or less) likely to lead to the achievement of each business goal. Unlike reactive compliance monitoring approaches that detect violations only after they have occurred, our predictive monitoring approach provides early advice so that users can steer ongoing process executions towards the achievement of business goals. In other words, violations are predicted (and potentially prevented) rather than merely detected. The approach has been implemented in the ProM process mining toolset and validated on a real-life log pertaining to the treatment of cancer patients in a large hospital.",
      "authors": [
        "Fabrizio Maria Maggi",
        "Chiara Di Francescomarino",
        "Marlon Dumas",
        "Chiara Ghidini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2013-12-17T17:38:09+00:00",
          "link": "https://arxiv.org/abs/1312.4874v1",
          "size": "1348kb",
          "version": "v1"
        },
        {
          "date": "2013-12-19T19:34:45+00:00",
          "link": "https://arxiv.org/abs/1312.4874v2",
          "size": "499kb",
          "version": "v2"
        }
      ],
      "title": "Predictive Monitoring of Business Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/1312.4874",
        "PDF": "https://arxiv.org/pdf/1312.4874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on predictive monitoring of business processes using event logs, without any emphasis on training data processing for LLMs, such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07416",
      "abstract": "Modern listwise recommendation systems need to consider both long-term user perceptions and short-term interest shifts. Reinforcement learning can be applied on recommendation to study such a problem but is also subject to large search space, sparse user feedback and long interactive latency. Motivated by recent progress in hierarchical reinforcement learning, we propose a novel framework called mccHRL to provide different levels of temporal abstraction on listwise recommendation. Within the hierarchical framework, the high-level agent studies the evolution of user perception, while the low-level agent produces the item selection policy by modeling the process as a sequential decision-making problem. We argue that such framework has a well-defined decomposition of the outra-session context and the intra-session context, which are encoded by the high-level and low-level agents, respectively. To verify this argument, we implement both a simulator-based environment and an industrial dataset-based experiment. Results observe significant performance improvement by our method, compared with several well-known baselines. Data and codes have been made public.",
      "authors": [
        "Luo Ji",
        "Gao Liu",
        "Mingyang Yin",
        "Hongxia Yang",
        "Jingren Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T17:01:06+00:00",
          "link": "https://arxiv.org/abs/2409.07416v1",
          "size": "314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T13:22:36+00:00",
          "link": "https://arxiv.org/abs/2409.07416v2",
          "size": "315kb",
          "version": "v2"
        }
      ],
      "title": "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07416",
        "HTML": "https://arxiv.org/html/2409.07416",
        "PDF": "https://arxiv.org/pdf/2409.07416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hierarchical reinforcement learning for enhancing listwise recommendation systems, which focuses on user perception and item selection without addressing LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Hierarchical Reinforcement Learning",
        "Recommendation Systems",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01184",
      "abstract": "Detecting deepfake videos is highly challenging given the complexity of characterizing spatio-temporal artifacts. Most existing methods rely on binary classifiers trained using real and fake image sequences, therefore hindering their generalization capabilities to unseen generation methods. Moreover, with the constant progress in generative Artificial Intelligence (AI), deepfake artifacts are becoming imperceptible at both the spatial and the temporal levels, making them extremely difficult to capture. To address these issues, we propose a fine-grained deepfake video detection approach called FakeSTormer that enforces the modeling of subtle spatio-temporal inconsistencies while avoiding overfitting. Specifically, we introduce a multi-task learning framework that incorporates two auxiliary branches for explicitly attending artifact-prone spatial and temporal regions. Additionally, we propose a video-level data synthesis strategy that generates pseudo-fake videos with subtle spatio-temporal artifacts, providing high-quality samples and hand-free annotations for our additional branches. Extensive experiments on several challenging benchmarks demonstrate the superiority of our approach compared to recent state-of-the-art methods. The code is available at https://github.com/10Ring/FakeSTormer.",
      "authors": [
        "Dat Nguyen",
        "Marcella Astrid",
        "Anis Kacem",
        "Enjie Ghorbel",
        "Djamila Aouada"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T10:21:34+00:00",
          "link": "https://arxiv.org/abs/2501.01184v1",
          "size": "14922kb",
          "version": "v1"
        },
        {
          "date": "2025-01-16T17:11:06+00:00",
          "link": "https://arxiv.org/abs/2501.01184v2",
          "size": "14920kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T09:15:28+00:00",
          "link": "https://arxiv.org/abs/2501.01184v3",
          "size": "12810kb",
          "version": "v3"
        }
      ],
      "title": "Vulnerability-Aware Spatio-Temporal Learning for Generalizable Deepfake Video Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01184",
        "HTML": "https://arxiv.org/html/2501.01184",
        "PDF": "https://arxiv.org/pdf/2501.01184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses deepfake video detection using a multi-task learning framework. It does not contribute to LLM training data processing."
      },
      "tasks": [
        "Face Swapping",
        "Multi-Task Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11299",
      "abstract": "Text-based telemedicine has become increasingly common, yet the quality of medical advice in doctor-patient interactions is often judged more on how advice is communicated rather than its clinical accuracy. To address this, we introduce Dr. Copilot , a multi-agent large language model (LLM) system that supports Romanian-speaking doctors by evaluating and enhancing the presentation quality of their written responses. Rather than assessing medical correctness, Dr. Copilot provides feedback along 17 interpretable axes. The system comprises of three LLM agents with prompts automatically optimized via DSPy. Designed with low-resource Romanian data and deployed using open-weight models, it delivers real-time specific feedback to doctors within a telemedicine platform. Empirical evaluations and live deployment with 41 doctors show measurable improvements in user reviews and response quality, marking one of the first real-world deployments of LLMs in Romanian medical settings.",
      "authors": [
        "Andrei Niculae",
        "Adrian Cosma",
        "Cosmin Dumitrache",
        "Emilian R\\v{a}doi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.11299v1",
          "size": "4454kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.11299v2",
          "size": "4454kb",
          "version": "v2"
        }
      ],
      "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11299",
        "HTML": "https://arxiv.org/html/2507.11299",
        "PDF": "https://arxiv.org/pdf/2507.11299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents Dr.Copilot, an LLM-based system designed to optimize communication in medical settings. It does discuss training data processing concerning Romanian low-resource data but focuses more on application than on new data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14206",
      "abstract": "Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.",
      "authors": [
        "Zhijiang Tang",
        "Jiaxin Qi",
        "Yuhua Zheng",
        "Jianqiang Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:54:24+00:00",
          "link": "https://arxiv.org/abs/2507.14206v1",
          "size": "246kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Benchmark for Electrocardiogram Time-Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14206",
        "HTML": "https://arxiv.org/html/2507.14206",
        "PDF": "https://arxiv.org/pdf/2507.14206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a benchmark for analyzing ECG time-series data, focusing on medical applications. It does not address LLM training data processing, data engineering operations, or dataset creation related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14245",
      "abstract": "Unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact. However, progress has been hindered by limited datasets and the restricted generalizability of existing models. Here, we propose NanoPro-3M, the largest nanomaterial-protein interaction dataset to date, comprising over 3.2 million samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer, a foundational model that predicts nanomaterial-protein affinities through multimodal representation learning, demonstrating strong generalization, handling missing features, and unseen nanomaterials or proteins. We show that multimodal modeling significantly outperforms single-modality approaches and identifies key determinants of corona formation. Furthermore, we demonstrate its applicability to a range of downstream tasks through zero-shot inference and fine-tuning. Together, this work establishes a solid foundation for high-performance and generalized prediction of nanomaterial-protein interaction endpoints, reducing experimental reliance and accelerating various in vitro applications.",
      "authors": [
        "Hengjie Yu",
        "Kenneth A. Dawson",
        "Haiyun Yang",
        "Shuya Liu",
        "Yan Yan",
        "Yaochu Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T00:00:52+00:00",
          "link": "https://arxiv.org/abs/2507.14245v1",
          "size": "1817kb",
          "version": "v1"
        }
      ],
      "title": "A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14245",
        "PDF": "https://arxiv.org/pdf/2507.14245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a large-scale dataset (NanoPro-3M) and a foundation model for nanomaterial-protein interactions. While it involves dataset creation, its primary focus isn't on LLM training data processing, but rather on material science applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14398",
      "abstract": "Intent-Based Networking (IBN) often leverages the programmability of Software-Defined Networking (SDN) to simplify network management. However, significant challenges remain in automating the entire pipeline, from user-specified high-level intents to device-specific low-level configurations. Existing solutions often rely on rigid, rule-based translators and fixed APIs, limiting extensibility and adaptability. By contrast, recent advances in large language models (LLMs) offer a promising pathway that leverages natural language understanding and flexible reasoning. However, it is unclear to what extent LLMs can perform IBN tasks. To address this, we introduce IBNBench, a first-of-its-kind benchmarking suite comprising four novel datasets: Intent2Flow-ODL, Intent2Flow-ONOS, FlowConflict-ODL, and FlowConflict-ONOS. These datasets are specifically designed for evaluating LLMs performance in intent translation and conflict detection tasks within the industry-grade SDN controllers ODL and ONOS. Our results provide the first comprehensive comparison of 33 open-source LLMs on IBNBench and related datasets, revealing a wide range of performance outcomes. However, while these results demonstrate the potential of LLMs for isolated IBN tasks, integrating LLMs into a fully autonomous IBN pipeline remains unexplored. Thus, our second contribution is NetIntent, a unified and adaptable framework that leverages LLMs to automate the full IBN lifecycle, including translation, activation, and assurance within SDN systems. NetIntent orchestrates both LLM and non-LLM agents, supporting dynamic re-prompting and contextual feedback to robustly execute user-defined intents with minimal human intervention. Our implementation of NetIntent across both ODL and ONOS SDN controllers achieves a consistent and adaptive end-to-end IBN realization.",
      "authors": [
        "Md. Kamrul Hossain",
        "Walid Aljoby"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T23:01:40+00:00",
          "link": "https://arxiv.org/abs/2507.14398v1",
          "size": "414kb",
          "version": "v1"
        }
      ],
      "title": "NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14398",
        "HTML": "https://arxiv.org/html/2507.14398",
        "PDF": "https://arxiv.org/pdf/2507.14398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces novel datasets for evaluating LLM performance in SDN context and a framework called NetIntent. While it involves datasets, the main focus is on LLM application for intent translation and SDN automation, not specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14604",
      "abstract": "Neural IR architectures, particularly cross-encoders, are highly effective models whose internal mechanisms are mostly unknown. Most works trying to explain their behavior focused on high-level processes (e.g., what in the input influences the prediction, does the model adhere to known IR axioms) but fall short of describing the matching process. Instead of Mechanistic Interpretability approaches which specifically aim at explaining the hidden mechanisms of neural models, we demonstrate that more straightforward methods can already provide valuable insights. In this paper, we first focus on the attention process and extract causal insights highlighting the crucial roles of some attention heads in this process. Second, we provide an interpretation of the mechanism underlying matching detection.",
      "authors": [
        "Mathias Vast and Basile Van Cooten and Laure Soulier and Benjamin Piwowarski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:05:27+00:00",
          "link": "https://arxiv.org/abs/2507.14604v1",
          "size": "259kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Matching Mechanisms in Cross-Encoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14604",
        "HTML": "https://arxiv.org/html/2507.14604",
        "PDF": "https://arxiv.org/pdf/2507.14604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores matching mechanisms in cross-encoders for neural IR architectures. It does not contribute to or discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14922",
      "abstract": "Persona-driven LLMs have emerged as powerful tools in computational social science, yet existing approaches fall at opposite extremes, either relying on costly human-curated data or producing synthetic personas that lack consistency and realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from 10,000 real social media users from BlueSky open platform across three time windows, bridging this spectrum by grounding synthetic generation in authentic user activity. Our evaluation demonstrates that SYNTHIA achieves competitive performance with state-of-the-art methods in demographic diversity and social survey alignment while significantly outperforming them in narrative consistency. Uniquely, SYNTHIA incorporates temporal dimensionality and provides rich social interaction metadata from the underlying network, enabling new research directions in computational social science and persona-driven language modeling.",
      "authors": [
        "Vahid Rahimzadeh",
        "Erfan Moosavi Monazzah",
        "Mohammad Taher Pilehvar",
        "Yadollah Yaghoobzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:37:07+00:00",
          "link": "https://arxiv.org/abs/2507.14922v1",
          "size": "4859kb",
          "version": "v1"
        }
      ],
      "title": "SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14922",
        "HTML": "https://arxiv.org/html/2507.14922",
        "PDF": "https://arxiv.org/pdf/2507.14922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "SYNTHIA introduces a dataset of synthetic personas derived from real social media users, aimed at improving narrative consistency in persona-driven LLMs, making a substantial contribution to LLM training data processing by generating high-quality new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15851",
      "abstract": "As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic numerical values in shallow layers to abstract temporal orientation in deep layers. Finally, using pre-trained embedding models, we found that the training corpus itself possesses an inherent, non-linear temporal structure, which provides the raw material for the model's internal construction. In discussion, we propose an experientialist perspective for understanding these findings, where the LLMs' cognition is viewed as a subjective construction of the external world by its internal representational system. This nuanced perspective implies the potential emergence of alien cognitive frameworks that humans cannot intuitively predict, pointing toward a direction for AI alignment that focuses on guiding internal constructions. Our code is available at https://TheOtherMind.github.io.",
      "authors": [
        "Lingyu Li",
        "Yang Yao",
        "Yixu Wang",
        "Chubo Li",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2507.15851v1",
          "size": "40484kb",
          "version": "v1"
        }
      ],
      "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15851",
        "HTML": "https://arxiv.org/html/2507.15851",
        "PDF": "https://arxiv.org/pdf/2507.15851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the cognitive patterns of LLMs related to temporal cognition rather than any aspect of data processing, collection, or dataset creation. Its emphasis is on the internal cognitive frameworks formed by LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.00849",
      "abstract": "This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure the recovery of the true latent causal variables and the underlying latent causal graph. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to mixing with parents for general causal models and perfect recovery of the latent graph for sufficiently nonlinear causal models. Secondly, it focuses on general transformations and demonstrates that two stochastic hard interventions per node are sufficient for identifiability. This is achieved by defining a differentiable loss function whose global optima ensure identifiability for general CRL. Notably, one does not need to know which pair of interventional environments has the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.",
      "authors": [
        "Burak Var{\\i}c{\\i}",
        "Emre Acart\\\"urk",
        "Karthikeyan Shanmugam",
        "Abhishek Kumar",
        "Ali Tajer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-01T18:40:03+00:00",
          "link": "https://arxiv.org/abs/2402.00849v1",
          "size": "959kb",
          "version": "v1"
        },
        {
          "date": "2024-02-26T21:30:37+00:00",
          "link": "https://arxiv.org/abs/2402.00849v2",
          "size": "959kb",
          "version": "v2"
        },
        {
          "date": "2024-10-30T01:47:27+00:00",
          "link": "https://arxiv.org/abs/2402.00849v3",
          "size": "1123kb",
          "version": "v3"
        },
        {
          "date": "2025-02-21T19:10:59+00:00",
          "link": "https://arxiv.org/abs/2402.00849v4",
          "size": "3023kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T22:38:11+00:00",
          "link": "https://arxiv.org/abs/2402.00849v5",
          "size": "2652kb",
          "version": "v5"
        }
      ],
      "title": "Score-based Causal Representation Learning: Linear and General Transformations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.00849",
        "PDF": "https://arxiv.org/pdf/2402.00849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on causal representation learning and the development of algorithms for identifiability, with no focus on LLM training data processing or dataset creation for language models."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/acarturk-e/score-based-crl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03087",
      "abstract": "Recent advancements in medical imaging and artificial intelligence (AI) have greatly enhanced diagnostic capabilities, but the development of effective deep learning (DL) models is still constrained by the lack of high-quality annotated datasets. The traditional manual annotation process by medical experts is time- and resource-intensive, limiting the scalability of these datasets. In this work, we introduce a robust and versatile framework that combines AI and crowdsourcing to improve both the quality and quantity of medical image datasets across different modalities. Our approach utilises a user-friendly online platform that enables a diverse group of crowd annotators to label medical images efficiently. By integrating the MedSAM segmentation AI with this platform, we accelerate the annotation process while maintaining expert-level quality through an algorithm that merges crowd-labelled images. Additionally, we employ pix2pixGAN, a generative AI model, to expand the training dataset with synthetic images that capture realistic morphological features. These methods are combined into a cohesive framework designed to produce an enhanced dataset, which can serve as a universal pre-processing pipeline to boost the training of any medical deep learning segmentation model. Our results demonstrate that this framework significantly improves model performance, especially when training data is limited.",
      "authors": [
        "Amir Syahmi",
        "Xiangrong Lu",
        "Yinxuan Li",
        "Haoxuan Yao",
        "Hanjun Jiang",
        "Ishita Acharya",
        "Shiyi Wang",
        "Yang Nan",
        "Xiaodan Xing",
        "Guang Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T21:22:54+00:00",
          "link": "https://arxiv.org/abs/2409.03087v1",
          "size": "6521kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T12:10:54+00:00",
          "link": "https://arxiv.org/abs/2409.03087v2",
          "size": "4690kb",
          "version": "v2"
        }
      ],
      "title": "Coupling AI and Citizen Science in Creation of Enhanced Training Dataset for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03087",
        "HTML": "https://arxiv.org/html/2409.03087",
        "PDF": "https://arxiv.org/pdf/2409.03087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a framework for enhancing medical image datasets using AI and citizen science, involving data generation and synthesis, which is directly relevant to LLM training data processing."
      },
      "tasks": [
        "Diagnostic",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17689",
      "abstract": "Different organisations often run similar digitised business processes to achieve their business goals. However, organisations often need to slightly adapt the business processes implemented in an information system in order to adopt them. Various approaches have been proposed to manage variants in process models. While these approaches mainly deal with control flow variability, in previous work we introduced an approach to manage implementation variants of digitised business processes. In this context Software Product Line (SPL) Engineering was applied to manage a set of common core artefacts including a process model from which Process-Aware Information Systems (PAIS) can be derived, which differ in the implementation of their process activities. When deriving a PAIS, implementations are selected for each process activity and then included in the PAIS at compilation time. One challenge that has not yet been solved is giving users of digitised business processes the option of selecting multiple implementations at runtime. This paper extends our previous work by not only allowing for the selection of activity implementations at compile time, but also at start time and runtime. Consequently, it becomes possible to defer the decision as to which implementation should be selected to start time and runtime. Furthermore, multiple implementations of a particular activity may be selected and executed concurrently. The presented approach also allows customising the input and output data of activities. Data from expert interviews with German municipalities suggests digitising business processes with varying implementations is a widespread challenge and our approach is a way to mitigate it.",
      "authors": [
        "Philipp Hehnle",
        "Manfred Reichert"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T09:10:42+00:00",
          "link": "https://arxiv.org/abs/2410.17689v1",
          "size": "821kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:34:02+00:00",
          "link": "https://arxiv.org/abs/2410.17689v2",
          "size": "777kb",
          "version": "v2"
        }
      ],
      "title": "Flexible Process Variant Binding in Information Systems with Software Product Line Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17689",
        "HTML": "https://arxiv.org/html/2410.17689",
        "PDF": "https://arxiv.org/pdf/2410.17689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores software design in information systems using Software Product Line Engineering to manage digitized business process variants. It does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10203",
      "abstract": "Multimodal learning often encounters the under-optimized problem and may perform worse than unimodal learning. Existing approaches attribute this issue to imbalanced learning across modalities and tend to address it through gradient balancing. However, this paper argues that balanced learning is not the optimal setting for multimodal learning. With bias-variance analysis, we prove that imbalanced dependency on each modality obeying the inverse ratio of their variances contributes to optimal performance. To this end, we propose the Asymmetric Representation Learning(ARL) strategy to assist multimodal learning via imbalanced optimization. ARL introduces auxiliary regularizers for each modality encoder to calculate their prediction variance. ARL then calculates coefficients via the unimodal variance to re-weight the optimization of each modality, forcing the modality dependence ratio to be inversely proportional to the modality variance ratio. Moreover, to minimize the generalization error, ARL further introduces the prediction bias of each modality and jointly optimizes them with multimodal loss. Notably, all auxiliary regularizers share parameters with the multimodal model and rely only on the modality representation. Thus the proposed ARL strategy introduces no extra parameters and is independent of the structures and fusion methods of the multimodal model. Finally, extensive experiments on various datasets validate the effectiveness and versatility of ARL. Code is available at \\href{https://github.com/shicaiwei123/ICCV2025-ARL}{https://github.com/shicaiwei123/ICCV2025-ARL}",
      "authors": [
        "Shicai Wei",
        "Chunbo Luo",
        "Yang Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.10203v1",
          "size": "1128kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:29:28+00:00",
          "link": "https://arxiv.org/abs/2507.10203v2",
          "size": "1128kb",
          "version": "v2"
        }
      ],
      "title": "Improving Multimodal Learning via Imbalanced Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10203",
        "HTML": "https://arxiv.org/html/2507.10203",
        "PDF": "https://arxiv.org/pdf/2507.10203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving multimodal learning using the Asymmetric Representation Learning (ARL) strategy, which addresses the problem of imbalanced learning across modalities. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14326",
      "abstract": "Generative AI models have substantially improved the realism of synthetic media, yet their misuse through sophisticated DeepFakes poses significant risks. Despite recent advances in deepfake detection, fairness remains inadequately addressed, enabling deepfake markers to exploit biases against specific populations. While previous studies have emphasized group-level fairness, individual fairness (i.e., ensuring similar predictions for similar individuals) remains largely unexplored. In this work, we identify for the first time that the original principle of individual fairness fundamentally fails in the context of deepfake detection, revealing a critical gap previously unexplored in the literature. To mitigate it, we propose the first generalizable framework that can be integrated into existing deepfake detectors to enhance individual fairness and generalization. Extensive experiments conducted on leading deepfake datasets demonstrate that our approach significantly improves individual fairness while maintaining robust detection performance, outperforming state-of-the-art methods. The code is available at https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.",
      "authors": [
        "Aryana Hou",
        "Li Lin",
        "Justin Li",
        "Shu Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:04:47+00:00",
          "link": "https://arxiv.org/abs/2507.14326v1",
          "size": "14602kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Individual Fairness in Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14326",
        "HTML": "https://arxiv.org/html/2507.14326",
        "PDF": "https://arxiv.org/pdf/2507.14326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses individual fairness in deepfake detection rather than topics related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14802",
      "abstract": "Pre-trained Transformer-based large models have revolutionized personal virtual assistants, but their deployment in cloud environments faces challenges related to data privacy and response latency. Deploying large models closer to the data and users has become a key research area to address these issues. However, applying these models directly often entails significant difficulties, such as model mismatching, resource constraints, and energy inefficiency. Automated design of customized models is necessary, but it faces three key challenges, namely, the high cost of centralized model customization, imbalanced performance from user heterogeneity, and suboptimal performance from data heterogeneity. In this paper, we propose ACME, an adaptive customization approach of Transformer-based large models via distributed systems. To avoid the low cost-efficiency of centralized methods, ACME employs a bidirectional single-loop distributed system to progressively achieve fine-grained collaborative model customization. In order to better match user heterogeneity, it begins by customizing the backbone generation and identifying the Pareto Front under model size constraints to ensure optimal resource utilization. Subsequently, it performs header generation and refines the model using data distribution-based personalized architecture aggregation to match data heterogeneity. Evaluation on different datasets shows that ACME achieves cost-efficient models under model size constraints. Compared to centralized systems, data transmission volume is reduced to 6 percent. Additionally, the average accuracy improves by 10 percent compared to the baseline, with the trade-off metrics increasing by nearly 30 percent.",
      "authors": [
        "Ziming Dai",
        "Chao Qiu",
        "Fei Gao",
        "Yunfeng Zhao",
        "Xiaofei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:30:24+00:00",
          "link": "https://arxiv.org/abs/2507.14802v1",
          "size": "3193kb",
          "version": "v1"
        }
      ],
      "title": "ACME: Adaptive Customization of Large Models via Distributed Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14802",
        "HTML": "https://arxiv.org/html/2507.14802",
        "PDF": "https://arxiv.org/pdf/2507.14802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper mentions challenges related to data heterogeneity in the context of adaptive customization of LLMs but doesn't delve deeply into specific LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15282",
      "abstract": "The rapid proliferation of food delivery platforms has reshaped urban mobility but has also contributed significantly to environmental degradation through increased greenhouse gas emissions. Existing optimization mechanisms produce sub-optimal outcomes as they do not consider environmental sustainability their optimization objective. This study proposes a novel eco-friendly food delivery optimization framework that integrates demand prediction, delivery person routing, and order allocation to minimize environmental impact while maintaining service efficiency. Since recommending routes is NP-Hard, the proposed approach utilizes the submodular and monotone properties of the objective function and designs an efficient greedy optimization algorithm. Thereafter, it formulates order allocation problem as a network flow optimization model, which, to the best of our knowledge, has not been explored in the context of food delivery. A three-layered network architecture is designed to match orders with delivery personnel based on capacity constraints and spatial demand. Through this framework, the proposed approach reduces the vehicle count, and creates a sustainable food delivery ecosystem.",
      "authors": [
        "Aqsa Ashraf Makhdomi and Iqra Altaf Gillani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:31:40+00:00",
          "link": "https://arxiv.org/abs/2507.15282v1",
          "size": "455kb",
          "version": "v1"
        }
      ],
      "title": "Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture for Sustainable Urban Food Delivery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15282",
        "HTML": "https://arxiv.org/html/2507.15282",
        "PDF": "https://arxiv.org/pdf/2507.15282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper aims to optimize food delivery systems for sustainability and does not relate to LLM training data processing or model development stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15741",
      "abstract": "This paper introduces a framework for uncertainty quantification in regression models defined in metric spaces. Leveraging a newly defined notion of homoscedasticity, we develop a conformal prediction algorithm that offers finite-sample coverage guarantees and fast convergence rates of the oracle estimator. In heteroscedastic settings, we forgo these non-asymptotic guarantees to gain statistical efficiency, proposing a local $k$--nearest--neighbor method without conformal calibration that is adaptive to the geometry of each particular nonlinear space. Both procedures work with any regression algorithm and are scalable to large data sets, allowing practitioners to plug in their preferred models and incorporate domain expertise. We prove consistency for the proposed estimators under minimal conditions. Finally, we demonstrate the practical utility of our approach in personalized--medicine applications involving random response objects such as probability distributions and graph Laplacians.",
      "authors": [
        "G\\'abor Lugosi and Marcos Matabuena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:54:13+00:00",
          "link": "https://arxiv.org/abs/2507.15741v1",
          "size": "3994kb",
          "version": "v1"
        }
      ],
      "title": "Conformal and kNN Predictive Uncertainty Quantification Algorithms in Metric Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15741",
        "HTML": "https://arxiv.org/html/2507.15741",
        "PDF": "https://arxiv.org/pdf/2507.15741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces algorithms for uncertainty quantification in regression models, with no discussion relevant to LLM training data processing procedures or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14642",
      "abstract": "Recently, LLMs have garnered increasing attention across academic disciplines for their potential as human digital twins, virtual proxies designed to replicate individuals and autonomously perform tasks such as decision-making, problem-solving, and reasoning on their behalf. However, current evaluations of LLMs primarily emphasize dialogue simulation while overlooking human behavior simulation, which is crucial for digital twins. To address this gap, we introduce BehaviorChain, the first benchmark for evaluating LLMs' ability to simulate continuous human behavior. BehaviorChain comprises diverse, high-quality, persona-based behavior chains, totaling 15,846 distinct behaviors across 1,001 unique personas, each with detailed history and profile metadata. For evaluation, we integrate persona metadata into LLMs and employ them to iteratively infer contextually appropriate behaviors within dynamic scenarios provided by BehaviorChain. Comprehensive evaluation results demonstrated that even state-of-the-art models struggle with accurately simulating continuous human behavior.",
      "authors": [
        "Rui Li",
        "Heming Xia",
        "Xinfeng Yuan",
        "Qingxiu Dong",
        "Lei Sha",
        "Wenjie Li",
        "Zhifang Sui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T15:29:32+00:00",
          "link": "https://arxiv.org/abs/2502.14642v1",
          "size": "3637kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:40:08+00:00",
          "link": "https://arxiv.org/abs/2502.14642v2",
          "size": "1458kb",
          "version": "v2"
        }
      ],
      "title": "How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14642",
        "PDF": "https://arxiv.org/pdf/2502.14642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the BehaviorChain benchmark for evaluating LLMs by simulating continuous human behavior, which involves creating a dataset of behavior chains. However, the main focus is on evaluation methods rather than training data processing."
      },
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/o-l1ru1/behaviorchain"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19116",
      "abstract": "Large language models often suffer from language confusion, a phenomenon in which responses are partially or entirely generated in unintended languages. This critically degrades the user experience, especially in low-resource settings. We hypothesize that this issue stems from limitations in conventional fine-tuning objectives, such as supervised learning, which optimize the likelihood of correct tokens without explicitly penalizing undesired outputs such as cross-lingual mixing. Analysis of loss trajectories during pretraining further reveals that models fail to distinguish between monolingual and language-mixed texts, highlighting the absence of inherent pressure to avoid such confusion. In this work, we apply ORPO, which adds penalties for unwanted output styles to standard SFT, effectively suppressing language-confused generations. ORPO maintains strong language consistency, even under high decoding temperatures, while preserving general QA performance. Our findings suggest that incorporating appropriate penalty terms can effectively mitigate language confusion in multilingual models, particularly in low-resource scenarios.",
      "authors": [
        "Nahyun Lee",
        "Yeongseo Woo",
        "Hyunwoo Ko",
        "Guijin Son"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T12:15:31+00:00",
          "link": "https://arxiv.org/abs/2505.19116v1",
          "size": "2315kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T08:57:14+00:00",
          "link": "https://arxiv.org/abs/2505.19116v2",
          "size": "1798kb",
          "version": "v2"
        }
      ],
      "title": "Controlling Language Confusion in Multilingual LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19116",
        "HTML": "https://arxiv.org/html/2505.19116",
        "PDF": "https://arxiv.org/pdf/2505.19116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ORPO, a method to control language confusion in multilingual LLMs, by applying penalties for unwanted outputs during supervised fine-tuning. However, its primary focus is on model behavior and performance improvement, rather than on data processing itself."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.07886",
      "abstract": "Understanding multimodal signals in egocentric vision, such as RGB video, depth, camera poses, and gaze, is essential for applications in augmented reality, robotics, and human-computer interaction, enabling systems to better interpret the camera wearer's actions, intentions, and surrounding environment. However, building large-scale egocentric multimodal and multitask models presents unique challenges. Egocentric data are inherently heterogeneous, with large variations in modality coverage across devices and settings. Generating pseudo-labels for missing modalities, such as gaze or head-mounted camera trajectories, is often infeasible, making standard supervised learning approaches difficult to scale. Furthermore, dynamic camera motion and the complex temporal and spatial structure of first-person video pose additional challenges for the direct application of existing multimodal foundation models.\n  To address these challenges, we introduce a set of efficient temporal tokenizers and propose EgoM2P, a masked modeling framework that learns from temporally-aware multimodal tokens to train a large, general-purpose model for egocentric 4D understanding. This unified design supports multitasking across diverse egocentric perception and synthesis tasks, including gaze prediction, egocentric camera tracking, and monocular depth estimation from egocentric video, and also serves as a generative model for conditional egocentric video synthesis. Across these tasks, EgoM2P matches or outperforms specialist models while being an order of magnitude faster. We will fully open-source EgoM2P to support the community and advance egocentric vision research. Project page: https://egom2p.github.io/.",
      "authors": [
        "Gen Li",
        "Yutong Chen",
        "Yiqian Wu",
        "Kaifeng Zhao",
        "Marc Pollefeys",
        "Siyu Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T15:59:25+00:00",
          "link": "https://arxiv.org/abs/2506.07886v1",
          "size": "10141kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T17:13:31+00:00",
          "link": "https://arxiv.org/abs/2506.07886v2",
          "size": "10671kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T15:33:13+00:00",
          "link": "https://arxiv.org/abs/2506.07886v3",
          "size": "10671kb",
          "version": "v3"
        }
      ],
      "title": "EgoM2P: Egocentric Multimodal Multitask Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07886",
        "HTML": "https://arxiv.org/html/2506.07886",
        "PDF": "https://arxiv.org/pdf/2506.07886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal pretraining for egocentric vision tasks, such as gaze prediction and depth estimation. It does not address training data processing related to LLMs."
      },
      "tasks": [
        "Depth Estimation",
        "Gaze Prediction",
        "Monocular Depth Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14178",
      "abstract": "Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign high scores to in-distribution (ID) samples and low scores to OOD samples, thereby helping distinguish OOD samples. Among these methods, distance-based score functions are widely used because of their efficiency and ease of use. However, deep learning often leads to a biased distribution of data features, and extreme features are inevitable. These extreme features make the distance-based methods tend to assign too low scores to ID samples. This limits the OOD detection capabilities of such methods. To address this issue, we propose a simple yet effective method, Feature Bank Enhancement (FBE), that uses statistical characteristics from dataset to identify and constrain extreme features to the separation boundaries, therapy making the distance between samples inside and outside the distribution farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10 respectively, and the results show that our method achieves state-of-the-art performance on both benchmark. Additionally, theoretical analysis and supplementary experiments are conducted to provide more insights into our method.",
      "authors": [
        "Yuhang Liu",
        "Yuefei Wu",
        "Bin Shi and Bo Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T13:32:26+00:00",
          "link": "https://arxiv.org/abs/2507.14178v1",
          "size": "280kb",
          "version": "v1"
        }
      ],
      "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14178",
        "HTML": "https://arxiv.org/html/2507.14178",
        "PDF": "https://arxiv.org/pdf/2507.14178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The topic of this paper is out-of-distribution detection and feature bank enhancement, which does not relate to LLM training data processing strategies, techniques, or quality improvements for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14913",
      "abstract": "Evaluating LLMs with a single prompt has proven unreliable, with small changes leading to significant performance differences. However, generating the prompt variations needed for a more robust multi-prompt evaluation is challenging, limiting its adoption in practice. To address this, we introduce PromptSuite, a framework that enables the automatic generation of various prompts. PromptSuite is flexible - working out of the box on a wide range of tasks and benchmarks. It follows a modular prompt design, allowing controlled perturbations to each component, and is extensible, supporting the addition of new components and perturbation types. Through a series of case studies, we show that PromptSuite provides meaningful variations to support strong evaluation practices. It is available through both a Python API: https://github.com/eliyahabba/PromptSuite, and a user-friendly web interface: https://promptsuite.streamlit.app/",
      "authors": [
        "Eliya Habba",
        "Noam Dahan",
        "Gili Lior",
        "Gabriel Stanovsky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:55:29+00:00",
          "link": "https://arxiv.org/abs/2507.14913v1",
          "size": "1122kb",
          "version": "v1"
        }
      ],
      "title": "PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14913",
        "HTML": "https://arxiv.org/html/2507.14913",
        "PDF": "https://arxiv.org/pdf/2507.14913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PromptSuite is a framework for generating diverse prompts to evaluate LLMs' performance, which focuses on prompt engineering, not on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15243",
      "abstract": "Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model pre-trained with DINO combined with a prototypical classifier outperforms the latest SOTA methods. A crucial limitation that needs to be overcome is that updating too many parameters of the transformers leads to overfitting due to the scarcity of labeled samples. To address this challenge, we propose a new concept, Coalescent Projection (CP), as an effective successor to soft prompts. Additionally, we propose a novel pseudo-class generation method combined with Self-Supervised Transformations (SSTs) that relies solely on the base domain to prepare the network for encountering unseen samples from different domains. The proposed method exhibits its effectiveness in comprehensive experiments on the extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published at https://github.com/Naeem-Paeedeh/CPLSR.",
      "authors": [
        "Naeem Paeedeh",
        "Mahardhika Pratama",
        "Wolfgang Mayer",
        "Jimmy Cao",
        "Ryszard Kowlczyk"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:01:27+00:00",
          "link": "https://arxiv.org/abs/2507.15243v1",
          "size": "1002kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15243",
        "HTML": "https://arxiv.org/html/2507.15243",
        "PDF": "https://arxiv.org/pdf/2507.15243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on improving Cross-Domain Few-Shot Learning through novel projections and pseudo-class generation, unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15693",
      "abstract": "This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach, and sub-millimeter repeatability - at a material cost under $215. As an accessible robot for broad applications across classroom education to AI experiments, Forte pushes forward the performance limitations of existing low-cost educational arms. We introduce a cost-effective mechanical design that combines capstan-based cable drives, timing belts, simple tensioning mechanisms, and lightweight 3D-printed structures, along with topology optimization for structural stiffness. Through careful drivetrain engineering, we minimize backlash and maintain control fidelity without relying on high-power electronics or expensive manufacturing processes. Experimental validation demonstrates that Forte achieves high repeatability and load capacity, offering a compelling robotic platform for both classroom instruction and advanced robotics research.",
      "authors": [
        "Georges Chebly",
        "Spencer Little",
        "Nisal Perera",
        "Aliya Abedeen",
        "Ken Suzuki and Donghyun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:02:01+00:00",
          "link": "https://arxiv.org/abs/2507.15693v1",
          "size": "35039kb",
          "version": "v1"
        }
      ],
      "title": "Strong, Accurate, and Low-Cost Robot Manipulator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15693",
        "HTML": "https://arxiv.org/html/2507.15693",
        "PDF": "https://arxiv.org/pdf/2507.15693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a cost-effective robotic arm design, which does not involve any aspect of LLM training data processing or data engineering relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15765",
      "abstract": "Dynamic Facial Expression Recognition (DFER) plays a critical role in affective computing and human-computer interaction. Although existing methods achieve comparable performance, they inevitably suffer from performance degradation under sample heterogeneity caused by multi-source data and individual expression variability. To address these challenges, we propose a novel framework, called Heterogeneity-aware Distributional Framework (HDF), and design two plug-and-play modules to enhance time-frequency modeling and mitigate optimization imbalance caused by hard samples. Specifically, the Time-Frequency Distributional Attention Module (DAM) captures both temporal consistency and frequency robustness through a dual-branch attention design, improving tolerance to sequence inconsistency and visual style shifts. Then, based on gradient sensitivity and information bottleneck principles, an adaptive optimization module Distribution-aware Scaling Module (DSM) is introduced to dynamically balance classification and contrastive losses, enabling more stable and discriminative representation learning. Extensive experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF significantly improves both recognition accuracy and robustness. Our method achieves superior weighted average recall (WAR) and unweighted average recall (UAR) while maintaining strong generalization across diverse and imbalanced scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.",
      "authors": [
        "Feng-Qi Cui",
        "Anyang Tong",
        "Jinyang Huang",
        "Jie Zhang",
        "Dan Guo",
        "Zhi Liu",
        "Meng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.15765v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15765",
        "HTML": "https://arxiv.org/html/2507.15765",
        "PDF": "https://arxiv.org/pdf/2507.15765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for dynamic facial expression recognition using time-frequency modeling and distributionally robust optimization, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.16832",
      "abstract": "We introduce a novel approach for simultaneous self-supervised video alignment and action segmentation based on a unified optimal transport framework. In particular, we first tackle self-supervised video alignment by developing a fused Gromov-Wasserstein optimal transport formulation with a structural prior, which trains efficiently on GPUs and needs only a few iterations for solving the optimal transport problem. Our single-task method achieves the state-of-the-art performance on multiple video alignment benchmarks and outperforms VAVA, which relies on a traditional Kantorovich optimal transport formulation with an optimality prior. Furthermore, we extend our approach by proposing a unified optimal transport framework for joint self-supervised video alignment and action segmentation, which requires training and storing a single model and saves both time and memory consumption as compared to two different single-task models. Extensive evaluations on several video alignment and action segmentation datasets demonstrate that our multi-task method achieves comparable video alignment yet superior action segmentation results over previous methods in video alignment and action segmentation respectively. Finally, to the best of our knowledge, this is the first work to unify video alignment and action segmentation into a single model.",
      "authors": [
        "Ali Shah Ali",
        "Syed Ahmed Mahmood",
        "Mubin Saeed",
        "Andrey Konin",
        "M. Zeeshan Zia",
        "Quoc-Huy Tran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T04:02:00+00:00",
          "link": "https://arxiv.org/abs/2503.16832v1",
          "size": "1378kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:48:43+00:00",
          "link": "https://arxiv.org/abs/2503.16832v2",
          "size": "1048kb",
          "version": "v2"
        }
      ],
      "title": "Joint Self-Supervised Video Alignment and Action Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16832",
        "HTML": "https://arxiv.org/html/2503.16832",
        "PDF": "https://arxiv.org/pdf/2503.16832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for video alignment and action segmentation, which is unrelated to training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14845",
      "abstract": "Depth completion is an important vision task, and many efforts have been made to enhance the quality of depth maps from sparse depth measurements. Despite significant advances, training these models to recover dense depth from sparse measurements remains a challenging problem. Supervised learning methods rely on dense depth labels to predict unobserved regions, while self-supervised approaches require image sequences to enforce geometric constraints and photometric consistency between frames. However, acquiring dense annotations is costly, and multi-frame dependencies limit the applicability of self-supervised methods in static or single-frame scenarios. To address these challenges, we propose a novel self-supervised depth completion paradigm that requires only sparse depth measurements and their corresponding image for training. Unlike existing methods, our approach eliminates the need for dense depth labels or additional images captured from neighboring viewpoints. By leveraging the characteristics of depth distribution, we design novel loss functions that effectively propagate depth information from observed points to unobserved regions. Additionally, we incorporate segmentation maps generated by vision foundation models to further enhance depth estimation. Extensive experiments demonstrate the effectiveness of our proposed method.",
      "authors": [
        "Rizhao Fan and Zhigen Li and Heping Li and Ning An"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:24:09+00:00",
          "link": "https://arxiv.org/abs/2507.14845v1",
          "size": "9479kb",
          "version": "v1"
        }
      ],
      "title": "Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14845",
        "HTML": "https://arxiv.org/html/2507.14845",
        "PDF": "https://arxiv.org/pdf/2507.14845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on self-supervised depth completion using sparse measurements for depth map enhancement, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.20448",
      "abstract": "Deep learning models benefit from rich (e.g., multi-modal) input features. However, multimodal models might be challenging to deploy, because some inputs may be missing at inference. Current popular solutions include marginalization, imputation, and training multiple models. Marginalization achieves calibrated predictions, but it is computationally expensive and only feasible for low dimensional inputs. Imputation may result in inaccurate predictions, particularly when high-dimensional data, such as images, are missing. Training multiple models, where each model is designed to handle different subsets of inputs, can work well but requires prior knowledge of missing input patterns. Furthermore, training and retaining multiple models can be costly. We propose an efficient method to learn both the conditional distribution using full inputs and the marginal distributions. Our method, Knockout, randomly replaces input features with appropriate placeholder values during training. We provide a theoretical justification for Knockout and show that it can be interpreted as an implicit marginalization strategy. We evaluate Knockout across a wide range of simulations and real-world datasets and show that it offers strong empirical performance.",
      "authors": [
        "Minh Nguyen",
        "Batuhan K. Karaman",
        "Heejong Kim",
        "Alan Q. Wang",
        "Fengbei Liu",
        "Mert R. Sabuncu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-30T19:47:34+00:00",
          "link": "https://arxiv.org/abs/2405.20448v1",
          "size": "428kb",
          "version": "v1"
        },
        {
          "date": "2024-06-03T14:40:28+00:00",
          "link": "https://arxiv.org/abs/2405.20448v2",
          "size": "428kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T13:42:40+00:00",
          "link": "https://arxiv.org/abs/2405.20448v3",
          "size": "809kb",
          "version": "v3"
        }
      ],
      "title": "Knockout: A simple way to handle missing inputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.20448",
        "HTML": "https://arxiv.org/html/2405.20448",
        "PDF": "https://arxiv.org/pdf/2405.20448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes 'Knockout', a method to handle missing inputs in multimodal models. It focuses on input handling strategies rather than training data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Imputation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.18652",
      "abstract": "Neural Radiance Fields (NeRFs) provide a high fidelity, continuous scene representation that can realistically represent complex behaviour of light. Despite works like Ref-NeRF improving geometry through physics-inspired models, the ability for a NeRF to overcome shape-radiance ambiguity and converge to a representation consistent with real geometry remains limited. We demonstrate how both curriculum learning of a surface light field model and using a lattice-based hash encoding helps a NeRF converge towards a more geometrically accurate scene representation. We introduce four regularisation terms to impose geometric smoothness, consistency of normals, and a separation of Lambertian and specular appearance at geometry in the scene, conforming to physical models. Our approach yields 28% more accurate normals than traditional grid-based NeRF variants with reflection parameterisation. Our approach more accurately separates view-dependent appearance, conditioning a NeRF to have a geometric representation consistent with the captured scene. We demonstrate compatibility of our method with existing NeRF variants, as a key step in enabling radiance-based representations for geometry critical applications.",
      "authors": [
        "Jack Naylor",
        "Viorela Ila and Donald G. Dansereau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T03:18:02+00:00",
          "link": "https://arxiv.org/abs/2411.18652v1",
          "size": "27173kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:37:09+00:00",
          "link": "https://arxiv.org/abs/2411.18652v2",
          "size": "10348kb",
          "version": "v2"
        }
      ],
      "title": "Surf-NeRF: Surface Regularised Neural Radiance Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18652",
        "HTML": "https://arxiv.org/html/2411.18652",
        "PDF": "https://arxiv.org/pdf/2411.18652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is about enhancing neural radiance fields (NeRFs) for better geometry representation in scenes. It does not make contributions to LLM training data processing or any related data operations."
      },
      "tasks": [
        "NeRF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20162",
      "abstract": "Domain Generalization (DG) research has gained considerable traction as of late, since the ability to generalize to unseen data distributions is a requirement that eludes even state-of-the-art training algorithms. In this paper we observe that the initial iterations of model training play a key role in domain generalization effectiveness, since the loss landscape may be significantly different across the training and test distributions, contrary to the case of i.i.d. data. Conflicts between gradients of the loss components of each domain lead the optimization procedure to undesirable local minima that do not capture the domain-invariant features of the target classes. We propose alleviating domain conflicts in model optimization, by iteratively annealing the parameters of a model in the early stages of training and searching for points where gradients align between domains. By discovering a set of parameter values where gradients are updated towards the same direction for each data distribution present in the training set, the proposed Gradient-Guided Annealing (GGA) algorithm encourages models to seek out minima that exhibit improved robustness against domain shifts. The efficacy of GGA is evaluated on five widely accepted and challenging image classification domain generalization benchmarks, where its use alone is able to establish highly competitive or even state-of-the-art performance. Moreover, when combined with previously proposed domain-generalization algorithms it is able to consistently improve their effectiveness by significant margins.",
      "authors": [
        "Aristotelis Ballas and Christos Diou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T15:01:55+00:00",
          "link": "https://arxiv.org/abs/2502.20162v1",
          "size": "8522kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T18:33:58+00:00",
          "link": "https://arxiv.org/abs/2502.20162v2",
          "size": "8518kb",
          "version": "v2"
        },
        {
          "date": "2025-03-10T18:50:14+00:00",
          "link": "https://arxiv.org/abs/2502.20162v3",
          "size": "8384kb",
          "version": "v3"
        },
        {
          "date": "2025-03-24T17:49:54+00:00",
          "link": "https://arxiv.org/abs/2502.20162v4",
          "size": "8373kb",
          "version": "v4"
        },
        {
          "date": "2025-05-09T11:15:50+00:00",
          "link": "https://arxiv.org/abs/2502.20162v5",
          "size": "8368kb",
          "version": "v5"
        },
        {
          "date": "2025-06-15T17:36:02+00:00",
          "link": "https://arxiv.org/abs/2502.20162v6",
          "size": "8373kb",
          "version": "v6"
        },
        {
          "date": "2025-07-21T15:07:01+00:00",
          "link": "https://arxiv.org/abs/2502.20162v7",
          "size": "8713kb",
          "version": "v7"
        }
      ],
      "title": "Gradient-Guided Annealing for Domain Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20162",
        "HTML": "https://arxiv.org/html/2502.20162",
        "PDF": "https://arxiv.org/pdf/2502.20162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a gradient-guided annealing technique for domain generalization in model training, without addressing any specific aspects of training data processing for LLMs."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Ballas_Gradient-Guided_Annealing_for_Domain_Generalization_CVPR_2025_paper.html",
      "tasks": [
        "Domain Generalization",
        "image-classification",
        "Image Classification",
        "Model Optimization"
      ],
      "repo_urls": [
        "https://github.com/aristotelisballas/gga"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04722",
      "abstract": "Conversational recommender systems (CRSs) often suffer from an extreme long-tail distribution of dialogue data, causing a strong bias toward head-frequency blockbusters that sacrifices diversity and exacerbates the cold-start problem. An empirical analysis of DCRS and statistics on the REDIAL corpus show that only 10% of head movies account for nearly half of all mentions, whereas about 70% of tail movies receive merely 26% of the attention. This imbalance gives rise to three critical challenges: head over-fitting, body representation drift, and tail sparsity. To address these issues, we propose LumiCRS, an end-to-end framework that mitigates long-tail imbalance through three mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss (ACFL) that dynamically adjusts class weights and focusing factors to curb head over-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail Recommendation, which selects semantic, affective, and contextual prototypes to guide clustering and stabilize body and tail representations; and (iii) a GPT-4o-driven prototype-guided dialogue augmentation module that automatically generates diverse long-tail conversational snippets to alleviate tail sparsity and distribution shift. Together, these strategies enable LumiCRS to markedly improve recommendation accuracy, diversity, and fairness: on the REDIAL and INSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over fifteen strong baselines, while human evaluations confirm superior fluency, informativeness, and long-tail relevance. These results demonstrate the effectiveness of multi-layer collaboration in building an efficient and fair long-tail conversational recommender.",
      "authors": [
        "Jinzhi Wang",
        "Bin Li",
        "Qingke Peng",
        "Haozhou Li",
        "Zeyuan Zeng",
        "Ruimeng Li",
        "Kaixuan Yang",
        "Jiangbo Zhang",
        "Biyi Zhou",
        "Yaoying Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T07:33:00+00:00",
          "link": "https://arxiv.org/abs/2507.04722v1",
          "size": "4200kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:31:22+00:00",
          "link": "https://arxiv.org/abs/2507.04722v2",
          "size": "4624kb",
          "version": "v2"
        }
      ],
      "title": "LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04722",
        "HTML": "https://arxiv.org/html/2507.04722",
        "PDF": "https://arxiv.org/pdf/2507.04722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the challenge of long-tail distribution in conversational recommender systems using a framework called LumiCRS. It does not contribute to LLM training data processing or operations related to data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14900",
      "abstract": "Large language models (LLMs) have demonstrated remarkable multilingual capabilities, however, how to evaluate cross-lingual alignment remains underexplored. Existing alignment benchmarks primarily focus on sentence embeddings, but prior research has shown that neural models tend to induce a non-smooth representation space, which impact of semantic alignment evaluation on low-resource languages. Inspired by neuroscientific findings that similar information activates overlapping neuronal regions, we propose a novel Neuron State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a lignment capabilities of LLMs, which offers a more semantically grounded approach to assess cross-lingual alignment. We evaluate NeuronXA on several prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two transfer tasks and three multilingual benchmarks. The results demonstrate that with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation of 0.9556 with downstream tasks performance and 0.8514 with transferability. These findings demonstrate NeuronXA's effectiveness in assessing both cross-lingual alignment and transferability, even with a small dataset. This highlights its potential to advance cross-lingual alignment research and to improve the semantic understanding of multilingual LLMs.",
      "authors": [
        "Chongxuan Huang",
        "Yongshi Ye",
        "Biao Fu",
        "Qifeng Su",
        "Xiaodong Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.14900v1",
          "size": "1373kb",
          "version": "v1"
        }
      ],
      "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14900",
        "HTML": "https://arxiv.org/html/2507.14900",
        "PDF": "https://arxiv.org/pdf/2507.14900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating cross-linguistic alignment capabilities of large language models through a novel method, NeuronXA. It does not discuss processes related to data collection, dataset construction, or other data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15142",
      "abstract": "Homophone normalization, where characters that have the same sound in a writing script are mapped to one character, is a pre-processing step applied in Amharic Natural Language Processing (NLP) literature. While this may improve performance reported by automatic metrics, it also results in models that are not able to understand different forms of writing in a single language. Further, there might be impacts in transfer learning, where models trained on normalized data do not generalize well to other languages. In this paper, we experiment with monolingual training and cross-lingual transfer to understand the impacts of normalization on languages that use the Ge'ez script. We then propose a post-inference intervention in which normalization is applied to model predictions instead of training data. With our simple scheme of post-inference normalization, we show that we can achieve an increase in BLEU score of up to 1.03 while preserving language features in training. Our work contributes to the broader discussion on technology-facilitated language change and calls for more language-aware interventions.",
      "authors": [
        "Hellina Hailu Nigatu",
        "Atnafu Lambebo Tonja",
        "Henok Biadglign Ademtew",
        "Hizkel Mitiku Alemayehu",
        "Negasi Haile Abadi",
        "Tadesse Destaw Belay",
        "Seid Muhie Yimam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:35:08+00:00",
          "link": "https://arxiv.org/abs/2507.15142v1",
          "size": "7732kb",
          "version": "v1"
        }
      ],
      "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15142",
        "PDF": "https://arxiv.org/pdf/2507.15142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses homophone normalization in NLP, specifically for languages using the Ge'ez script, and focuses on post-inference interventions rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15192",
      "abstract": "We study the stability of a class of dynamical low-rank methods--the projector-splitting integrator (PSI)--applied to linear hyperbolic and parabolic equations. Using a von Neumann-type analysis, we investigate the stability of such low-rank time integrator coupled with standard spatial discretizations, including upwind and central finite difference schemes, under two commonly used formulations: discretize-then-project (DtP) and project-then-discretize (PtD). For hyperbolic equations, we show that the stability conditions for DtP and PtD are the same under Lie-Trotter splitting, and that the stability region can be significantly enlarged by using Strang splitting. For parabolic equations, despite the presence of a negative S-step, unconditional stability can still be achieved by employing Crank-Nicolson or a hybrid forward-backward Euler scheme in time stepping. While our analysis focuses on simplified model problems, it offers insight into the stability behavior of PSI for more complex systems, such as those arising in kinetic theory.",
      "authors": [
        "Shiheng Zhang",
        "Jingwei Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:32:19+00:00",
          "link": "https://arxiv.org/abs/2507.15192v1",
          "size": "591kb",
          "version": "v1"
        }
      ],
      "title": "On the stability of the low-rank projector-splitting integrator for hyperbolic and parabolic equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15192",
        "HTML": "https://arxiv.org/html/2507.15192",
        "PDF": "https://arxiv.org/pdf/2507.15192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the stability of low-rank integrators for solving hyperbolic and parabolic equations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15357",
      "abstract": "This paper presents a comprehensive evaluation of the capabilities of Large Language Models (LLMs) in metaphor interpretation across multiple datasets, tasks, and prompt configurations. Although metaphor processing has gained significant attention in Natural Language Processing (NLP), previous research has been limited to single-dataset evaluations and specific task settings, often using artificially constructed data through lexical replacement. We address these limitations by conducting extensive experiments using diverse publicly available datasets with inference and metaphor annotations, focusing on Natural Language Inference (NLI) and Question Answering (QA) tasks. The results indicate that LLMs' performance is more influenced by features like lexical overlap and sentence length than by metaphorical content, demonstrating that any alleged emergent abilities of LLMs to understand metaphorical language are the result of a combination of surface-level features, in-context learning, and linguistic knowledge. This work provides critical insights into the current capabilities and limitations of LLMs in processing figurative language, highlighting the need for more realistic evaluation frameworks in metaphor interpretation tasks. Data and code are publicly available.",
      "authors": [
        "Elisa Sanchez-Bayona",
        "Rodrigo Agerri"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:09:11+00:00",
          "link": "https://arxiv.org/abs/2507.15357v1",
          "size": "202kb",
          "version": "v1"
        }
      ],
      "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15357",
        "HTML": "https://arxiv.org/html/2507.15357",
        "PDF": "https://arxiv.org/pdf/2507.15357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating LLMs' capabilities in metaphor interpretation but does not discuss training data processing or contribute to dataset creation or data quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15784",
      "abstract": "Graph node classification is a fundamental task in graph neural networks (GNNs), aiming to assign predefined class labels to nodes. On the PubMed citation network dataset, we observe significant classification difficulty disparities, with Category 2 achieving only 74.4% accuracy in traditional GCN, 7.5% lower than Category 1. To address this, we propose a Wasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM), training specialized GNN models for Categories 0/1 (with layer normalization and residual connections) and Multi-hop Graph Attention Networks (GAT) for Category 2. The WR distance metric optimizes representation similarity between models, particularly focusing on improving Category 2 performance. Our adaptive fusion strategy dynamically weights models based on category-specific performance, with Category 2 assigned a GAT weight of 0.8. WR distance further guides the fusion process by measuring distributional differences between model representations, enabling more principled integration of complementary features.\n  Experimental results show WR-EFM achieves balanced accuracy across categories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2), outperforming both single models and standard fusion approaches. The coefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6% lower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM improves Category 2 accuracy by 5.5% compared to GCN, verifying the effectiveness of WR-guided fusion in capturing complex structural patterns. This work provides a novel paradigm for handling class-imbalanced graph classification tasks. To promote the research community, we release our project at https://github.com/s010m00n/GASEM4NC.",
      "authors": [
        "Zihang Ma and Qitian Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:40:04+00:00",
          "link": "https://arxiv.org/abs/2507.15784v1",
          "size": "2414kb",
          "version": "v1"
        }
      ],
      "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15784",
        "HTML": "https://arxiv.org/html/2507.15784",
        "PDF": "https://arxiv.org/pdf/2507.15784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores graph node classification using a novel fusion model for GNNs, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17181",
      "abstract": "Large Language Models (LLMs) are increasingly used to generate code, influencing users' choices of libraries and programming languages in critical real-world projects. However, little is known about their systematic biases or preferences toward certain libraries and programming languages, which can significantly impact software development practices. To fill this gap, we perform the first empirical study of LLMs' preferences for libraries and programming languages when generating code, covering eight diverse LLMs. Our results reveal that LLMs exhibit a strong tendency to overuse widely adopted libraries such as NumPy; in up to 48% of cases, this usage is unnecessary and deviates from the ground-truth solutions. LLMs also exhibit a significant preference toward Python as their default language. For high-performance project initialisation tasks where Python is not the optimal language, it remains the dominant choice in 58% of cases, and Rust is not used a single time. These results indicate that LLMs may prioritise familiarity and popularity over suitability and task-specific optimality. This will introduce security vulnerabilities and technical debt, and limit exposure to newly developed, better-suited tools and languages. Understanding and addressing these biases is essential for the responsible integration of LLMs into software development workflows.",
      "authors": [
        "Lukas Twist",
        "Jie M. Zhang",
        "Mark Harman",
        "Don Syme",
        "Joost Noppen",
        "Helen Yannakoudakis and Detlef Nauck"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T14:29:35+00:00",
          "link": "https://arxiv.org/abs/2503.17181v1",
          "size": "715kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:58:26+00:00",
          "link": "https://arxiv.org/abs/2503.17181v2",
          "size": "349kb",
          "version": "v2"
        }
      ],
      "title": "A Study of LLMs' Preferences for Libraries and Programming Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17181",
        "HTML": "https://arxiv.org/html/2503.17181",
        "PDF": "https://arxiv.org/pdf/2503.17181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates LLMs' preferences for programming languages and libraries, but it does not discuss or contribute to training data processing techniques for LLMs."
      },
      "tasks": [
        "Code Generation"
      ],
      "repo_urls": [
        "https://github.com/itsluketwist/llms-love-python"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12249",
      "abstract": "The application of artificial intelligence (AI) in medical imaging has revolutionized diagnostic practices, enabling advanced analysis and interpretation of radiological data. This study presents a comprehensive evaluation of radiomics-based and deep learning-based approaches for disease detection in chest radiography, focusing on COVID-19, lung opacity, and viral pneumonia. While deep learning models, particularly convolutional neural networks and vision transformers, learn directly from image data, radiomics-based models extract handcrafted features, offering potential advantages in data-limited scenarios. We systematically compared the diagnostic performance of various AI models, including Decision Trees, Gradient Boosting, Random Forests, Support Vector Machines, and Multi-Layer Perceptrons for radiomics, against state-of-the-art deep learning models such as InceptionV3, EfficientNetL, and ConvNeXtXLarge. Performance was evaluated across multiple sample sizes. At 24 samples, EfficientNetL achieved an AUC of 0.839, outperforming SVM (AUC = 0.762). At 4000 samples, InceptionV3 achieved the highest AUC of 0.996, compared to 0.885 for Random Forest. A Scheirer-Ray-Hare test confirmed significant main and interaction effects of model type and sample size on all metrics. Post hoc Mann-Whitney U tests with Bonferroni correction further revealed consistent performance advantages for deep learning models across most conditions. These findings provide statistically validated, data-driven recommendations for model selection in diagnostic AI. Deep learning models demonstrated higher performance and better scalability with increasing data availability, while radiomics-based models may remain useful in low-data contexts. This study addresses a critical gap in AI-based diagnostic research by offering practical guidance for deploying AI models across diverse clinical environments.",
      "authors": [
        "Zhijin He",
        "Alan B. McMillan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T16:54:37+00:00",
          "link": "https://arxiv.org/abs/2504.12249v1",
          "size": "1843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T23:10:18+00:00",
          "link": "https://arxiv.org/abs/2504.12249v2",
          "size": "1826kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T15:57:00+00:00",
          "link": "https://arxiv.org/abs/2504.12249v3",
          "size": "1832kb",
          "version": "v3"
        }
      ],
      "title": "Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12249",
        "PDF": "https://arxiv.org/pdf/2504.12249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates AI models for disease detection in chest radiography, which is not related to LLM training data processing. It focuses on model performance and selection in diagnostic AI, not on training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09822",
      "abstract": "Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.",
      "authors": [
        "Darshan Gadginmath",
        "Farhad Nawaz",
        "Minjun Sung",
        "Faizan M Tariq",
        "Sangjae Bae",
        "David Isele",
        "Fabio Pasqualetti",
        "Jovin D'sa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:06:46+00:00",
          "link": "https://arxiv.org/abs/2507.09822v1",
          "size": "653kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T19:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.09822v2",
          "size": "653kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T19:53:18+00:00",
          "link": "https://arxiv.org/abs/2507.09822v3",
          "size": "654kb",
          "version": "v3"
        }
      ],
      "title": "Active Probing with Multimodal Predictions for Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09822",
        "HTML": "https://arxiv.org/html/2507.09822",
        "PDF": "https://arxiv.org/pdf/2507.09822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a framework for motion planning using multimodal predictions and active probing, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14144",
      "abstract": "The Recursive KalmanNet, recently introduced by the authors, is a recurrent neural network guided by a Kalman filter, capable of estimating the state variables and error covariance of stochastic dynamic systems from noisy measurements, without prior knowledge of the noise characteristics. This paper explores its generalization capabilities in out-of-distribution scenarios, where the temporal dynamics of the test measurements differ from those encountered during training.\n  Le Recursive KalmanNet, r\\'ecemment introduit par les auteurs, est un r\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman, capable d'estimer les variables d'\\'etat et la covariance des erreurs des syst\\`emes dynamiques stochastiques \\`a partir de mesures bruit\\'ees, sans connaissance pr\\'ealable des caract\\'eristiques des bruits. Cet article explore ses capacit\\'es de g\\'en\\'eralisation dans des sc\\'enarios hors distribution, o\\`u les dynamiques temporelles des mesures de test diff\\`erent de celles rencontr\\'ees \\`a l'entra\\^inement.",
      "authors": [
        "Cyril Falcon",
        "Hassan Mortada",
        "Math\\'eo Clavaud and Jean-Philippe Michel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T10:38:00+00:00",
          "link": "https://arxiv.org/abs/2507.14144v1",
          "size": "1251kb",
          "version": "v1"
        }
      ],
      "title": "Recursive KalmanNet: Analyse des capacit\\'es de g\\'en\\'eralisation d'un r\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14144",
        "HTML": "https://arxiv.org/html/2507.14144",
        "PDF": "https://arxiv.org/pdf/2507.14144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the generalization capabilities of a recurrent neural network guided by a Kalman filter, focusing on stochastic dynamic systems, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14445",
      "abstract": "One approach to study the pseudorandomness properties of walks on expander graphs is to label the vertices of an expander with elements from an alphabet $\\Sigma$, and study the mean of functions over $\\Sigma^n$. We say expander walks $\\varepsilon$-fool a function if, for any unbiased labeling of the vertices, the expander walk mean is $\\varepsilon$-close to the true mean. We show that:\n  - The class of symmetric functions is $O(|\\Sigma|\\cdot\\lambda)$-fooled by expander walks over any generic $\\lambda$-expander, and any alphabet $\\Sigma$ . This generalizes the result of Cohen, Peri, Ta-Shma [STOC'21] which analyzes it for $|\\Sigma| =2$, and exponentially improves the previous bound of $O(|\\Sigma|^{O(|\\Sigma|)}\\cdot \\lambda)$, by Golowich and Vadhan [CCC'22]. Additionally, if the expander is a Cayley graph over $\\mathbb{Z}_{|\\Sigma|}$, we get a further improved bound of $O(\\sqrt{|\\Sigma|}\\cdot\\lambda)$.\n  Morever, when $\\Sigma$ is a finite group $G$, we show the following for functions over $G^n$:\n  - The class of symmetric class functions is $O\\Big({\\frac{\\sqrt{|G|}}{D}\\cdot\\lambda}\\Big)$-fooled by expander walks over \"structured\" $\\lambda$-expanders, if $G$ is $D$-quasirandom.\n  - We show a lower bound of $\\Omega(\\lambda)$ for symmetric functions for any finite group $G$ (even for \"structured\" $\\lambda$-expanders).\n  - We study the Fourier spectrum of a class of non-symmetric functions arising from word maps, and show that they are exponentially fooled by expander walks.\n  Our proof employs Fourier analysis over general groups, which contrasts with earlier works that have studied either the case of $\\mathbb{Z}_2$ or $\\mathbb{Z}$. This enables us to get quantitatively better bounds even for unstructured sets.",
      "authors": [
        "Fernando Granha Jeronimo",
        "Tushant Mittal",
        "and Sourya Roy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.14445v1",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "title": "Pseudorandomness of Expander Walks via Fourier Analysis on Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14445",
        "HTML": "https://arxiv.org/html/2507.14445",
        "PDF": "https://arxiv.org/pdf/2507.14445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the pseudorandomness properties of expander walks via Fourier analysis on groups. It doesn't relate to LLM training data processing or associated data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14960",
      "abstract": "The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.",
      "authors": [
        "Ivan Letteri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Trading and Market Microstructure (q-fin.TR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:42:36+00:00",
          "link": "https://arxiv.org/abs/2507.14960v1",
          "size": "675kb",
          "version": "v1"
        }
      ],
      "title": "A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14960",
        "HTML": "https://arxiv.org/html/2507.14960",
        "PDF": "https://arxiv.org/pdf/2507.14960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes outlier detection in cryptocurrency limit order books, which does not relate to LLM training data processing or involve pertinent data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15223",
      "abstract": "Advancements in 3D vision have increased the impact of blood vessel modeling on medical applications. However, accurately representing the complex geometry and topology of blood vessels remains a challenge due to their intricate branching patterns, curvatures, and irregular shapes. In this study, we propose a hierarchical part-based frame work for 3D vessel generation that separates the global binary tree-like topology from local geometric details. Our approach proceeds in three stages: (1) key graph generation to model the overall hierarchical struc ture, (2) vessel segment generation conditioned on geometric properties, and (3) hierarchical vessel assembly by integrating the local segments according to the global key graph. We validate our framework on real world datasets, demonstrating superior performance over existing methods in modeling complex vascular networks. This work marks the first successful application of a part-based generative approach for 3D vessel modeling, setting a new benchmark for vascular data generation. The code is available at: https://github.com/CybercatChen/PartVessel.git.",
      "authors": [
        "Siqi Chen",
        "Guoqing Zhang",
        "Jiahao Lai",
        "Bingzhi Shen",
        "Sihong Zhang",
        "Caixia Dong",
        "Xuejin Chen and Yang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:52:25+00:00",
          "link": "https://arxiv.org/abs/2507.15223v1",
          "size": "1200kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15223",
        "HTML": "https://arxiv.org/html/2507.15223",
        "PDF": "https://arxiv.org/pdf/2507.15223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with 3D blood vessel modeling in medical applications and does not relate to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15330",
      "abstract": "We introduce Cognitive Degradation as a novel vulnerability class in agentic AI systems. Unlike traditional adversarial external threats such as prompt injection, these failures originate internally, arising from memory starvation, planner recursion, context flooding, and output suppression. These systemic weaknesses lead to silent agent drift, logic collapse, and persistent hallucinations over time. To address this class of failures, we introduce the Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10), a lifecycle-aware defense framework defined by a six-stage cognitive degradation lifecycle. The framework includes seven runtime controls (QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger proactive mitigation through fallback routing, starvation detection, and memory integrity enforcement. Drawing from cognitive neuroscience, we map agentic architectures to human analogs, enabling early detection of fatigue, starvation, and role collapse. By introducing a formal lifecycle and real-time mitigation controls, this work establishes Cognitive Degradation as a critical new class of AI system vulnerability and proposes the first cross-platform defense model for resilient agentic behavior.",
      "authors": [
        "Hammad Atta",
        "Muhammad Zeeshan Baig",
        "Yasir Mehmood",
        "Nadeem Shahzad",
        "Ken Huang",
        "Muhammad Aziz Ul Haq",
        "Muhammad Awais",
        "Kamal Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:41:58+00:00",
          "link": "https://arxiv.org/abs/2507.15330v1",
          "size": "491kb",
          "version": "v1"
        }
      ],
      "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15330",
        "HTML": "https://arxiv.org/html/2507.15330",
        "PDF": "https://arxiv.org/pdf/2507.15330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a mitigation framework for cognitive degradation in AI systems, which is unrelated to LLM training data processing operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.12887",
      "abstract": "We study the convergence of gradient flow for the training of deep neural networks. If Residual Neural Networks are a popular example of very deep architectures, their training constitutes a challenging optimization problem due notably to the non-convexity and the non-coercivity of the objective. Yet, in applications, those tasks are successfully solved by simple optimization algorithms such as gradient descent. To better understand this phenomenon, we focus here on a ``mean-field'' model of infinitely deep and arbitrarily wide ResNet, parameterized by probability measures over the product set of layers and parameters and with constant marginal on the set of layers. Indeed, in the case of shallow neural networks, mean field models have proven to benefit from simplified loss-landscapes and good theoretical guarantees when trained with gradient flow for the Wasserstein metric on the set of probability measures. Motivated by this approach, we propose to train our model with gradient flow w.r.t. the conditional Optimal Transport distance: a restriction of the classical Wasserstein distance which enforces our marginal condition. Relying on the theory of gradient flows in metric spaces we first show the well-posedness of the gradient flow equation and its consistency with the training of ResNets at finite width. Performing a local Polyak-\\L{}ojasiewicz analysis, we then show convergence of the gradient flow for well-chosen initializations: if the number of features is finite but sufficiently large and the risk is sufficiently small at initialization, the gradient flow converges towards a global minimizer. This is the first result of this type for infinitely deep and arbitrarily wide ResNets.",
      "authors": [
        "Rapha\\\"el Barboni (ENS-PSL)",
        "Gabriel Peyr\\'e (CNRS and ENS-PSL)",
        "Fran\\c{c}ois-Xavier Vialard (LIGM)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T16:34:31+00:00",
          "link": "https://arxiv.org/abs/2403.12887v1",
          "size": "78kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:49:38+00:00",
          "link": "https://arxiv.org/abs/2403.12887v2",
          "size": "74kb",
          "version": "v2"
        }
      ],
      "title": "Understanding the training of infinitely deep and wide ResNets with Conditional Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.12887",
        "PDF": "https://arxiv.org/pdf/2403.12887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies gradient flow and training dynamics of infinitely deep ResNets, with no relevance to LLM training data processing or dataset-related improvements."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.12540",
      "abstract": "Brain-computer interfaces offer significant therapeutic opportunities for a variety of neurophysiological and neuropsychiatric disorders and may perhaps one day lead to augmenting the cognition and decision-making of the healthy brain. However, existing regulatory frameworks designed for implantable medical devices are inadequate to address the unique ethical, legal, and social risks associated with next-generation networked brain-computer interfaces. In this article, we make nine recommendations to support developers in the design of BCIs and nine recommendations to support policymakers in the application of BCIs, drawing insights from the regulatory history of IMDs and principles from AI ethics. We begin by outlining the historical development of IMDs and the regulatory milestones that have shaped their oversight. Next, we summarize similarities between IMDs and emerging implantable BCIs, identifying existing provisions for their regulation. We then use two case studies of emerging cutting-edge BCIs, the HALO and SCALO computer systems, to highlight distinctive features in the design and application of next-generation BCIs arising from contemporary chip architectures, which necessitate reevaluating regulatory approaches. We identify critical ethical considerations for these BCIs, including unique conceptions of autonomy, identity, and mental privacy. Based on these insights, we suggest potential avenues for the ethical regulation of BCIs, emphasizing the importance of interdisciplinary collaboration and proactive mitigation of potential harms. The goal is to support the responsible design and application of new BCIs, ensuring their safe and ethical integration into medical practice.",
      "authors": [
        "Renee Sirbu",
        "Jessica Morley",
        "Tyler Schroder",
        "Raghavendra Pradyumna Pothukuchi",
        "Muhammed Ugur",
        "Abhishek Bhattacharjee",
        "Luciano Floridi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T15:29:41+00:00",
          "link": "https://arxiv.org/abs/2506.12540v1",
          "size": "411kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:25:50+00:00",
          "link": "https://arxiv.org/abs/2506.12540v2",
          "size": "410kb",
          "version": "v2"
        }
      ],
      "title": "Regulating Next-Generation Implantable Brain-Computer Interfaces: Recommendations for Ethical Development and Implementation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12540",
        "PDF": "https://arxiv.org/pdf/2506.12540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is related to ethical development and regulation of brain-computer interfaces and does not involve LLM training data processing or associated methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14605",
      "abstract": "Online optimal control of quadrupedal robots would enable them to plan their movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged as a practical approach for real-time control. In LMPC, an optimization problem with a quadratic cost and linear constraints is formulated over a finite horizon and solved on the fly. However, LMPC relies on linearizing the equations of motion (EOM), which may lead to poor solution quality. In this paper, we use Koopman operator theory and the Extended Dynamic Mode Decomposition (EDMD) to create a linear model of the system in high dimensional space, thus retaining the nonlinearity of the EOM. We model the aerial phase and ground contact phases using different linear models. Then, using LMPC, we demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait transitions in level and rough terrains. The main novelty is the use of Koopman operator theory to create hybrid models of a quadrupedal system and demonstrate the online generation of multiple gaits and gaits transitions.",
      "authors": [
        "Chun-Ming Yang and Pranav A. Bhounsule"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.14605v1",
          "size": "2314kb",
          "version": "v1"
        }
      ],
      "title": "Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14605",
        "HTML": "https://arxiv.org/html/2507.14605",
        "PDF": "https://arxiv.org/pdf/2507.14605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on control methods for quadrupedal robots using Koopman operator theory, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15553",
      "abstract": "The rising demand for Large Language Model (LLM) inference services has intensified pressure on computational resources, resulting in latency and cost challenges. This paper introduces a novel routing algorithm based on the Non-dominated Sorting Genetic Algorithm II (NSGA-II) to distribute inference requests across heterogeneous LLM instances in a cloud-edge computing environment. Formulated as a multi-objective optimization problem, the algorithm balances response quality, response time, and inference cost, adapting to request heterogeneity (e.g., varying complexity and prompt lengths) and node diversity (e.g., edge vs. cloud resources). This adaptive routing algorithm optimizes performance under dynamic workloads. We benchmark the approach using a testbed with datasets including Stanford Question Answering Dataset (SQuAD), Mostly Basic Python Problems (MBPP), Hella Situations With Adversarial Generations (HellaSwag), and Grade School Math 8K (GSM8K). Experimental results show our solution, compared to the baselines, achieves up to 95.2% and 34.9% improvements in terms of response time and cost, respectively. These findings validate the algorithm's effectiveness for scalable LLM deployments.",
      "authors": [
        "Shibo Yu",
        "Mohammad Goudarzi",
        "and Adel Nadjaran Toosi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:32:30+00:00",
          "link": "https://arxiv.org/abs/2507.15553v1",
          "size": "98kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Routing of Inference Requests across LLM Instances in Cloud-Edge Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15553",
        "HTML": "https://arxiv.org/html/2507.15553",
        "PDF": "https://arxiv.org/pdf/2507.15553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a routing algorithm for efficient LLM inference in cloud-edge environments. The focus is on computational resource optimization, not on data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15643",
      "abstract": "Shared mobility systems, such as bike-sharing networks, play a crucial role in urban transportation. Identifying anomalies in these systems is essential for optimizing operations, improving service reliability, and enhancing user experience. This paper presents an interpretable anomaly detection framework that integrates multi-source data, including bike-sharing trip records, weather conditions, and public transit availability. The Isolation Forest algorithm is employed for unsupervised anomaly detection, along with the Depth-based Isolation Forest Feature Importance (DIFFI) algorithm providing interpretability. Results show that station-level analysis offers a robust understanding of anomalies, highlighting the influence of external factors such as adverse weather and limited transit availability. Our findings contribute to improving decision-making in shared mobility operations.",
      "authors": [
        "Elnur Isgandarov",
        "Matteo Cederle",
        "Federico Chiariotti",
        "and Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:06:42+00:00",
          "link": "https://arxiv.org/abs/2507.15643v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15643",
        "HTML": "https://arxiv.org/html/2507.15643",
        "PDF": "https://arxiv.org/pdf/2507.15643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on anomaly detection in shared mobility systems and does not address LLM training data processing in terms of data collection or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.06717",
      "abstract": "High-level automation is increasingly critical in AI, driven by rapid advances in large language models (LLMs) and AI agents. However, LLMs, despite their general reasoning power, struggle significantly in specialized, data-sensitive tasks such as designing Graph Neural Networks (GNNs). This difficulty arises from (1) the inherent knowledge gaps in modeling the intricate, varying relationships between graph properties and suitable architectures and (2) the external noise from misleading descriptive inputs, often resulting in generic or even misleading model suggestions. Achieving proficiency in designing data-aware models -- defined as the meta-level capability to systematically accumulate, interpret, and apply data-specific design knowledge -- remains challenging for existing automated approaches, due to their inefficient construction and application of meta-knowledge. To achieve the meta-level proficiency, we propose DesiGNN, a knowledge-centered framework that systematically converts past model design experiences into structured, fine-grained knowledge priors well fitted to meta-learning with LLMs. To account for the inherent variability and external noise, DesiGNN aligns empirical property filtering from extensive benchmarks with adaptive elicitation of literature insights via LLMs. By constructing a solid meta-knowledge between unseen graph understanding and known effective architecture patterns, DesiGNN can deliver top-5.77% initial model proposals for unseen datasets within seconds, and achieve consistently superior performance with minimal search costs against baselines.",
      "authors": [
        "Jialiang Wang",
        "Hanmo Liu",
        "Shimin Di",
        "Zhili Wang",
        "Jiachuan Wang",
        "Lei Chen",
        "Xiaofang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T08:22:01+00:00",
          "link": "https://arxiv.org/abs/2408.06717v1",
          "size": "1043kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:23:07+00:00",
          "link": "https://arxiv.org/abs/2408.06717v2",
          "size": "1039kb",
          "version": "v2"
        }
      ],
      "title": "Proficient Graph Neural Network Design by Accumulating Knowledge on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06717",
        "HTML": "https://arxiv.org/html/2408.06717",
        "PDF": "https://arxiv.org/pdf/2408.06717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves designing Graph Neural Networks using knowledge from LLMs but does not directly contribute to LLM training data processing techniques."
      },
      "tasks": [
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12601",
      "abstract": "To broaden the dissemination of scientific knowledge to diverse audiences, it is desirable for scientific document summarization systems to simultaneously control multiple attributes such as length and empirical focus. However, existing research typically focuses on controlling single attributes, leaving the compositional control of multiple attributes underexplored. To address this gap, we introduce CCSBench, the first evaluation benchmark for compositional controllable summarization in the scientific domain. Our benchmark enables fine-grained control over both explicit attributes (e.g., length), which are objective and straightforward, and implicit attributes (e.g., conceptual or empirical focus), which are more subjective and abstract. We conduct extensive experiments using various large language models (LLMs) under various settings, including in-context learning, parameter-efficient fine-tuning, and two-stage modular methods for balancing control over different attributes. Our findings reveal significant limitations in LLMs capabilities in balancing trade-offs between control attributes, especially implicit ones that require deeper understanding and abstract reasoning.",
      "authors": [
        "Yixi Ding",
        "Jiaying Wu",
        "Tongyao Zhu",
        "Yanxia Qin",
        "Qian Liu",
        "Min-Yen Kan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T14:21:52+00:00",
          "link": "https://arxiv.org/abs/2410.12601v1",
          "size": "313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:34:09+00:00",
          "link": "https://arxiv.org/abs/2410.12601v2",
          "size": "345kb",
          "version": "v2"
        }
      ],
      "title": "CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12601",
        "HTML": "https://arxiv.org/html/2410.12601",
        "PDF": "https://arxiv.org/pdf/2410.12601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark (CCSBench) for evaluating compositional controllability in LLMs related to scientific summarization, the main focus is on evaluation and model capabilities rather than on training data processing itself."
      },
      "tasks": [
        "Document Summarization",
        "Scientific Document Summarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05641",
      "abstract": "Combining existing pre-trained expert LLMs is a promising avenue for scalably tackling large-scale and diverse tasks. However, selecting task-level experts is often too coarse-grained, as heterogeneous tasks may require different expertise per instance. To enable adaptive instance-level mixing of pre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and gradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained approach to selection by emphasizing skills, e.g., algebra in math or molecular biology in biomedical reasoning. We propose a skill-based recruiting strategy that dynamically selects the most relevant set of expert LLMs for diverse reasoning tasks based on their strengths. Each selected expert then generates its own reasoning, resulting in k outputs from k experts, which are then synthesized into a final high-quality response by an aggregator chosen based on its ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's instance-level expert selection improves performance by a large margin but -- when implemented naively -- can introduce a high computational overhead due to the need for constant model loading and offloading. To address this, we implement a batch strategy that groups instances based on their assigned experts, loading each model only once. This allows us to integrate 16 expert models on 1 GPU with a time cost comparable to or better than prior multi-agent baselines using 4 GPUs. Through extensive evaluations on diverse benchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we show that Symbolic-MoE beats strong LLMs like GPT4o-mini, as well as multi-agent approaches, with an absolute avg. gain of 8.15% over the best multi-agent baseline. Moreover, Symbolic-MoE generalizes well to unseen tasks and removes the need for expensive multi-round discussions, outperforming discussion baselines with less computation.",
      "authors": [
        "Justin Chih-Yao Chen",
        "Sukwon Yun",
        "Elias Stengel-Eskin",
        "Tianlong Chen",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T18:03:13+00:00",
          "link": "https://arxiv.org/abs/2503.05641v1",
          "size": "883kb",
          "version": "v1"
        },
        {
          "date": "2025-03-11T21:40:43+00:00",
          "link": "https://arxiv.org/abs/2503.05641v2",
          "size": "883kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T18:50:23+00:00",
          "link": "https://arxiv.org/abs/2503.05641v3",
          "size": "892kb",
          "version": "v3"
        }
      ],
      "title": "Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05641",
        "HTML": "https://arxiv.org/html/2503.05641",
        "PDF": "https://arxiv.org/pdf/2503.05641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for combining pre-trained LLMs via a Mixture-of-Experts model. It does not address data processing for LLM training, focusing instead on model architecture and task adaptation."
      },
      "tasks": [
        "Math",
        "Mixture-of-Experts",
        "MMLU"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20887",
      "abstract": "When optimising for conditional value at risk (CVaR) using policy gradients (PG), current methods rely on discarding a large proportion of trajectories, resulting in poor sample efficiency. We propose a reformulation of the CVaR optimisation problem by capping the total return of trajectories used in training, rather than simply discarding them, and show that this is equivalent to the original problem if the cap is set appropriately. We show, with empirical results in an number of environments, that this reformulation of the problem results in consistently improved performance compared to baselines. We have made all our code available here: https://github.com/HarryMJMead/cvar-return-capping.",
      "authors": [
        "Harry Mead",
        "Clarissa Costen",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T16:04:16+00:00",
          "link": "https://arxiv.org/abs/2504.20887v1",
          "size": "493kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:55:34+00:00",
          "link": "https://arxiv.org/abs/2504.20887v2",
          "size": "495kb",
          "version": "v2"
        }
      ],
      "title": "Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20887",
        "HTML": "https://arxiv.org/html/2504.20887",
        "PDF": "https://arxiv.org/pdf/2504.20887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses CVaR optimisation in policy gradients for reinforcement learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20560",
      "abstract": "We present a numerical method for the approximation of the inverse of the fractional Laplacian $(-\\Delta)^{s}$, based on its spectral definition, using rational functions to approximate the fractional power $A^{-s}$ of a matrix $A$, for $0<s<1$. The proposed numerical method is fast and accurate, benefiting from the fact that the matrix $A$ arises from a finite element approximation of the Laplacian $-\\Delta$, which makes it applicable to a wide range of domains with potentially irregular shapes. We make use of state-of-the-art software to compute the best rational approximation of a fractional power. We analyze the convergence rate of our method and validate our findings through a series of numerical experiments with a range of exponents $s \\in (0,1)$. Additionally, we apply the proposed numerical method to different evolution problems that involve the fractional Laplacian through an interaction potential: the fractional porous medium equation and the fractional Keller-Segel equation. We then investigate the accuracy of the resulting numerical method, focusing in particular on the accurate reproduction of qualitative properties of the associated analytical solutions to these partial differential equations.",
      "authors": [
        "Jos\\'e A. Carrillo",
        "Stefano Fronzoni",
        "Yuji Nakatsukasa and Endre S\\\"uli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T22:49:52+00:00",
          "link": "https://arxiv.org/abs/2505.20560v1",
          "size": "2149kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:16:13+00:00",
          "link": "https://arxiv.org/abs/2505.20560v2",
          "size": "2342kb",
          "version": "v2"
        }
      ],
      "title": "A minimax method for the spectral fractional Laplacian and related evolution problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20560",
        "PDF": "https://arxiv.org/pdf/2505.20560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a numerical method for the spectral fractional Laplacian related to evolution problems. It is unrelated to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14304",
      "abstract": "Multilingual large language models (LLMs) often demonstrate a performance gap between English and non-English languages, particularly in low-resource settings. Aligning these models to low-resource languages is essential yet challenging due to limited high-quality data. While English alignment datasets are readily available, curating equivalent data in other languages is expensive and time-consuming. A common workaround is to translate existing English alignment data; however, standard translation techniques often fail to preserve critical elements such as code, mathematical expressions, and structured formats like JSON. In this work, we investigate LLM-based selective translation, a technique that selectively translates only the translatable parts of a text while preserving non-translatable content and sentence structure. We conduct a systematic study to explore key questions around this approach, including its effectiveness compared to vanilla translation, the importance of filtering noisy outputs, and the benefits of mixing translated samples with original English data during alignment. Our experiments focus on the low-resource Indic language Hindi and compare translations generated by Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the promise of selective translation as a practical and effective method for improving multilingual alignment in LLMs.",
      "authors": [
        "Rakesh Paul",
        "Anusha Kamath",
        "Kanishk Singla",
        "Raviraj Joshi",
        "Utkarsh Vaidya",
        "Sanjay Singh Chauhan",
        "Niranjan Wartikar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:21:52+00:00",
          "link": "https://arxiv.org/abs/2507.14304v1",
          "size": "687kb",
          "version": "v1"
        }
      ],
      "title": "Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14304",
        "HTML": "https://arxiv.org/html/2507.14304",
        "PDF": "https://arxiv.org/pdf/2507.14304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to LLM training data processing by introducing an LLM-based selective translation method for low-resource languages. It focuses on improving dataset quality and alignment through selective translation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14462",
      "abstract": "We study lower bounds for approximating the Single Source Personalized PageRank (SSPPR) query, which measures the probability distribution of an $\\alpha$-decay random walk starting from a source node $s$. Existing lower bounds remain loose-$\\Omega\\left(\\min(m, 1/\\delta)\\right)$ for relative error (SSPPR-R) and $\\Omega\\left(\\min(n, 1/\\epsilon)\\right)$ for additive error (SSPPR-A). To close this gap, we establish tighter bounds for both settings. For SSPPR-R, we show a lower bound of $\\Omega\\left(\\min\\left(m, \\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$ for any $\\delta \\in (0,1)$. For SSPPR-A, we prove a lower bound of $\\Omega\\left(\\min\\left(m, \\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$ for any $\\epsilon \\in (0,1)$, assuming the graph has $m \\in \\mathcal{O}(n^{2-\\beta})$ edges for any arbitrarily small constant $\\beta \\in (0,1)$.",
      "authors": [
        "Xinpeng Jiang",
        "Haoyu Liu",
        "Siqiang Luo and Xiaokui Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:32:08+00:00",
          "link": "https://arxiv.org/abs/2507.14462v1",
          "size": "933kb",
          "version": "v1"
        }
      ],
      "title": "Tighter Lower Bounds for Single Source Personalized PageRank",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14462",
        "HTML": "https://arxiv.org/html/2507.14462",
        "PDF": "https://arxiv.org/pdf/2507.14462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on lower bounds for approximating Single Source Personalized PageRank (SSPPR) queries, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14544",
      "abstract": "This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA 2025 Challenge, which targets visual question answering (VQA) for gastrointestinal endoscopy. We adopt the Florence model-a large-scale multimodal foundation model-as the backbone of our VQA pipeline, pairing a powerful vision encoder with a text encoder to interpret endoscopic images and produce clinically relevant answers. To improve generalization, we apply domain-specific augmentations that preserve medical features while increasing training diversity. Experiments on the KASVIR dataset show that fine-tuning Florence yields accurate responses on the official challenge metrics. Our results highlight the potential of large multimodal models in medical VQA and provide a strong baseline for future work on explainability, robustness, and clinical integration. The code is publicly available at: https://github.com/TiwariLaxuu/VQA-Florence.git",
      "authors": [
        "Sujata Gaihre",
        "Amir Thapa Magar",
        "Prasuna Pokharel",
        "and Laxmi Tiwari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:04:13+00:00",
          "link": "https://arxiv.org/abs/2507.14544v1",
          "size": "677kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14544",
        "HTML": "https://arxiv.org/html/2507.14544",
        "PDF": "https://arxiv.org/pdf/2507.14544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal AI for gastrointestinal diagnostics, specifically visual question answering, without discussing LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14692",
      "abstract": "In this study, we present a comprehensive global spectral analysis of the convection dispersion equation, which is also referred to in specific contexts as the Korteweg de Vries (KdV) equation, to investigate the behaviour of high order numerical schemes across a wide range of nondimensional parameters. The motivation for this analysis stems from the equation's importance in modeling wave propagation and transport phenomena, where accurate resolution of dispersive effects is critical, and traditional numerical schemes often suffer from spurious artifacts. We analyze one sixth order and two eighth order compact spatial discretization schemes, encompassing both node centered and cell centered formulations, combined with a third order strong stability preserving Runge Kutta (SSPRK3) time integrator. The analysis is performed in terms of key nondimensional parameters such as the wavenumber, Courant Friedrichs Lewy number $N_c$, and dispersion number $D_{\\alpha}$ over the full spectral plane for both one and two dimensional cases. Key numerical indicators, including the amplification factor, normalized phase speed, and normalized group velocity, are evaluated to characterize stability, dispersion error, errors in energy transport, and directional anisotropy. Critical dispersion thresholds and Courant numbers are identified, beyond which numerical instability and nonphysical phenomena such as spurious q waves and reversed phase or energy transport arise. Theoretical predictions are validated through numerical experiments involving linear and nonlinear one and two dimensional test problems, including cases with exact solutions and established benchmark results. This comprehensive analysis uncovers subtle numerical errors and offers practical guidance for selecting reliable discretization parameters, ensuring accurate and stable simulations of convection dispersion systems.",
      "authors": [
        "Lavanya V Salian",
        "Vivek S Yadav",
        "Rathan Samala",
        "Rakesh Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:53:22+00:00",
          "link": "https://arxiv.org/abs/2507.14692v1",
          "size": "4594kb",
          "version": "v1"
        }
      ],
      "title": "Spectral Analysis of Node- and Cell-Centered Higher-Order Compact Schemes for Fully Discrete One and Two-Dimensional Convection-Dispersion Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14692",
        "HTML": "https://arxiv.org/html/2507.14692",
        "PDF": "https://arxiv.org/pdf/2507.14692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper performs spectral analysis of numerical schemes for convection dispersion equations, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14813",
      "abstract": "Temporal graphs serve as a critical foundation for modeling evolving interactions in domains ranging from financial networks to social media. Mining temporal motifs is essential for applications such as fraud detection, cybersecurity, and dynamic network analysis. However, conventional motif mining approaches treat each query independently, incurring significant redundant computations when similar substructures exist across multiple motifs. In this paper, we propose Mayura, a novel framework that unifies the mining of multiple temporal motifs by exploiting their inherent structural and temporal commonalities. Central to our approach is the Motif-Group Tree (MG-Tree), a hierarchical data structure that organizes related motifs and enables the reuse of common search paths, thereby reducing redundant computation. We propose a co-mining algorithm that leverages the MG-Tree and develop a flexible runtime capable of exploiting both CPU and GPU architectures for scalable performance. Empirical evaluations on diverse real-world datasets demonstrate that Mayura achieves substantial improvements over the state-of-the-art techniques that mine each motif individually, with an average speed-up of 2.4x on the CPU and 1.7x on the GPU, while maintaining the exactness required for high-stakes applications.",
      "authors": [
        "Sanjay Sri Vallabh Singapuram",
        "Ronald Dreslinski",
        "Nishil Talati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:02:24+00:00",
          "link": "https://arxiv.org/abs/2507.14813v1",
          "size": "1582kb",
          "version": "v1"
        }
      ],
      "title": "Mayura: Exploiting Similarities in Motifs for Temporal Co-Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14813",
        "HTML": "https://arxiv.org/html/2507.14813",
        "PDF": "https://arxiv.org/pdf/2507.14813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for mining temporal motifs in graphs, focusing on efficiency improvements in motif mining tasks. It does not cover any aspects of LLM training data processing or operations related to language model datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14860",
      "abstract": "This study investigates the strategic and epistemically responsible integration of AI-powered chatbots into physics teacher education by employing a TPACK-guided SWOT framework across three structured learning activities. Conducted within a university-level capstone course on innovative tools for physics instruction, the activities targeted key intersections of technological, pedagogical, and content knowledge (TPACK) through chatbot-assisted tasks: simplifying abstract physics concepts, constructing symbolic concept maps, and designing instructional scenarios. Drawing on participant reflections, classroom artifacts, and iterative feedback, the results highlight internal strengths such as enhanced information-seeking behavior, scaffolded pedagogical planning, and support for symbolic reasoning. At the same time, internal weaknesses emerged, including domain-specific inaccuracies, symbolic limitations (e.g., LaTeX misrendering), and risks of overreliance on AI outputs. External opportunities were found in promoting inclusive education, multilingual engagement, and expanded zones of proximal development (ZPD), while external threats included prompt injection risks, institutional access gaps, and cybersecurity vulnerabilities. By extending existing TPACK-based models with constructs such as AI literacy, prompt-crafting competence, and epistemic verification protocols, this research offers a theoretically grounded and practically actionable roadmap for embedding AI in STEM teacher preparation. The findings affirm that, when critically scaffolded, AI chatbots can support metacognitive reflection, ethical reasoning, and instructional innovation in physics education if implementation is paired with digital fluency training and institutional support.",
      "authors": [
        "N. Mohammadipour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Physics Education (physics.ed-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T08:04:07+00:00",
          "link": "https://arxiv.org/abs/2507.14860v1",
          "size": "4032kb",
          "version": "v1"
        }
      ],
      "title": "Strategic Integration of AI Chatbots in Physics Teacher Preparation: A TPACK-SWOT Analysis of Pedagogical, Epistemic, and Cybersecurity Dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14860",
        "PDF": "https://arxiv.org/pdf/2507.14860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the integration of AI chatbots in physics teacher preparation, focusing on pedagogical benefits, but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15084",
      "abstract": "Machine learning allows unfolding high-dimensional spaces without binning at the LHC. The new SPINUP method extracts the unfolded distribution based on a neural network encoding the forward mapping, making it independent of the prior from the simulated training data. It is made efficient through neural importance sampling, and ensembling can be used to estimate the effect of information loss in the forward process. We showcase SPINUP for unfolding detector effects on jet substructure observables and for unfolding to parton level of associated Higgs and single-top production.",
      "authors": [
        "Anja Butter",
        "Theo Heimel",
        "Nathan Huetsch",
        "Michael Kagan",
        "and Tilman Plehn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:43:03+00:00",
          "link": "https://arxiv.org/abs/2507.15084v1",
          "size": "5421kb",
          "version": "v1"
        }
      ],
      "title": "Simulation-Prior Independent Neural Unfolding Procedure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15084",
        "PDF": "https://arxiv.org/pdf/2507.15084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method called SPINUP for high-dimensional data unfolding at the LHC, focusing on particle physics. It does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15321",
      "abstract": "Depth estimation is a fundamental task in computer vision with diverse applications. Recent advancements in deep learning have led to powerful depth foundation models (DFMs), yet their evaluation remains challenging due to inconsistencies in existing protocols. Traditional benchmarks rely on alignment-based metrics that introduce biases, favor certain depth representations, and complicate fair comparisons. In this work, we propose BenchDepth, a new benchmark that evaluates DFMs through five carefully selected downstream proxy tasks: depth completion, stereo matching, monocular feed-forward 3D scene reconstruction, SLAM, and vision-language spatial understanding. Unlike conventional evaluation protocols, our approach assesses DFMs based on their practical utility in real-world applications, bypassing problematic alignment procedures. We benchmark eight state-of-the-art DFMs and provide an in-depth analysis of key findings and observations. We hope our work sparks further discussion in the community on best practices for depth model evaluation and paves the way for future research and advancements in depth estimation.",
      "authors": [
        "Zhenyu Li",
        "Haotong Lin",
        "Jiashi Feng",
        "Peter Wonka",
        "Bingyi Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:23:14+00:00",
          "link": "https://arxiv.org/abs/2507.15321v1",
          "size": "1045kb",
          "version": "v1"
        }
      ],
      "title": "BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15321",
        "HTML": "https://arxiv.org/html/2507.15321",
        "PDF": "https://arxiv.org/pdf/2507.15321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on evaluating depth foundation models in computer vision, which does not have any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15709",
      "abstract": "Face image quality assessment (FIQA) is essential for various face-related applications. Although FIQA has been extensively studied and achieved significant progress, the computational complexity of FIQA algorithms remains a key concern for ensuring scalability and practical deployment in real-world systems. In this paper, we aim to develop a computationally efficient FIQA method that can be easily deployed in real-world applications. Specifically, our method consists of two stages: training a powerful teacher model and distilling a lightweight student model from it. To build a strong teacher model, we adopt a self-training strategy to improve its capacity. We first train the teacher model using labeled face images, then use it to generate pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are used in two ways: (1) to distill knowledge into the student model, and (2) to combine with the original labeled images to further enhance the teacher model through self-training. The enhanced teacher model is used to further pseudo-label another set of unlabeled images for distilling the student models. The student model is trained using a combination of labeled images, pseudo-labeled images from the original teacher model, and pseudo-labeled images from the enhanced teacher model. Experimental results demonstrate that our student model achieves comparable performance to the teacher model with an extremely low computational overhead. Moreover, our method achieved first place in the ICCV 2025 VQualA FIQA Challenge. The code is available at https://github.com/sunwei925/Efficient-FIQA.git.",
      "authors": [
        "Wei Sun and Weixia Zhang and Linhan Cao and Jun Jia and Xiangyang Zhu and Dandan Zhu and Xiongkuo Min and Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:17:01+00:00",
          "link": "https://arxiv.org/abs/2507.15709v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15709",
        "HTML": "https://arxiv.org/html/2507.15709",
        "PDF": "https://arxiv.org/pdf/2507.15709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on face image quality assessment using self-training and knowledge distillation, which is not related to training data processing for LLMs. It primarily addresses improving computational efficiency and model performance in the context of face image applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.14629",
      "abstract": "In reinforcement learning (RL) with experience replay, experiences stored in a replay buffer influence the RL agent's performance. Information about how these experiences influence the agent's performance is valuable for various purposes, such as identifying experiences that negatively influence underperforming agents. One method for estimating the influence of experiences is the leave-one-out (LOO) method. However, this method is usually computationally prohibitive. In this paper, we present Policy Iteration with Turn-over Dropout (PIToD), which efficiently estimates the influence of experiences. We evaluate how correctly PIToD estimates the influence of experiences and its efficiency compared to LOO. We then apply PIToD to amend underperforming RL agents, i.e., we use PIToD to estimate negatively influential experiences for the RL agents and to delete the influence of these experiences. We show that RL agents' performance is significantly improved via amendments with PIToD.",
      "authors": [
        "Takuya Hiraoka",
        "Guanquan Wang",
        "Takashi Onishi",
        "Yoshimasa Tsuruoka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-23T14:35:56+00:00",
          "link": "https://arxiv.org/abs/2405.14629v1",
          "size": "2184kb",
          "version": "v1"
        },
        {
          "date": "2024-10-04T12:47:03+00:00",
          "link": "https://arxiv.org/abs/2405.14629v2",
          "size": "5872kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T15:31:00+00:00",
          "link": "https://arxiv.org/abs/2405.14629v3",
          "size": "4267kb",
          "version": "v3"
        }
      ],
      "title": "Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14629",
        "PDF": "https://arxiv.org/pdf/2405.14629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning and estimating the influence of experiences on RL agents, which is not related to LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/takuyahiraoka/which-experiences-are-influential-for-rl-agents",
        "https://github.com/takuyahiraoka/which-experiences-are-influential-for-your-agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18023",
      "abstract": "Vision Language Models (VLMs) extend remarkable capabilities of text-only large language models and vision-only models, and are able to learn from and process multi-modal vision-text input. While modern VLMs perform well on a number of standard image classification and image-text matching tasks, they still struggle with a number of crucial vision-language (VL) reasoning abilities such as counting and spatial reasoning. Moreover, while they might be very brittle to small variations in instructions and/or evaluation protocols, existing benchmarks fail to evaluate their robustness (or rather the lack of it). In order to couple challenging VL scenarios with comprehensive robustness evaluation, we introduce DARE, Diverse Visual Question Answering with Robustness Evaluation, a carefully created and curated multiple-choice VQA benchmark. DARE evaluates VLM performance on five diverse categories and includes four robustness-oriented evaluations based on the variations of: prompts, the subsets of answer options, the output format and the number of correct answers. Among a spectrum of other findings, we report that state-of-the-art VLMs still struggle with questions in most categories and are unable to consistently deliver their peak performance across the tested robustness evaluations. The worst case performance across the subsets of options is up to 34% below the performance in the standard case. The robustness of the open-source VLMs such as LLaVA 1.6 and Idefics2 cannot match the closed-source models such as GPT-4 and Gemini, but even the latter remain very brittle to different variations.",
      "authors": [
        "Hannah Sterz",
        "Jonas Pfeiffer",
        "Ivan Vuli\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T16:31:50+00:00",
          "link": "https://arxiv.org/abs/2409.18023v1",
          "size": "10864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:20:03+00:00",
          "link": "https://arxiv.org/abs/2409.18023v2",
          "size": "10789kb",
          "version": "v2"
        }
      ],
      "title": "DARE: Diverse Visual Question Answering with Robustness Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18023",
        "HTML": "https://arxiv.org/html/2409.18023",
        "PDF": "https://arxiv.org/pdf/2409.18023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for visual question-answering systems focusing on robustness evaluation, which does not pertain to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "cambridgeltl/DARE",
          "downloads": "40",
          "likes": "5",
          "link": "https://huggingface.co/datasets/cambridgeltl/DARE"
        }
      ],
      "tasks": [
        "image-classification",
        "Image Classification",
        "Image-text matching",
        "Multiple-choice",
        "Question Answering",
        "Spatial Reasoning",
        "Text Matching",
        "Visual Question Answering",
        "Visual Question Answering (VQA)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14165",
      "abstract": "The widespread adoption of Internet of Things (IoT) technologies has significantly advanced environmental monitoring (EM) by enabling cost-effective and scalable sensing solutions. Concurrently, machine learning (ML) and artificial intelligence (AI) are introducing powerful tools for the efficient and accurate analysis of complex environmental data. However, current IoT platforms for environmental sensing are typically limited to a narrow set of sensors, preventing a comprehensive assessment of environmental conditions and lacking sufficient computational capabilities to support the deployment of advanced ML and AI algorithms on the edge. To overcome these limitations, we introduce a compact (17x38 mm2), multi-modal, MCU-based environmental IoT node integrating 11 sensors, including CO2 concentration, volatile organic compounds (VOCs), light intensity, UV radiation, pressure, temperature, humidity, visual sensing via an RGB camera, and precise geolocation through a GNSS module. It features GAP9, a parallel ultra-low-power system-on-chip, enabling real-time, energy-efficient edge processing of advanced ML models directly on-device. We implemented a YOLOv5-based occupancy detection pipeline (0.3 M parameters, 42 MOP per inference), demonstrating 42% energy savings over raw data streaming. Additionally, we present a smart indoor air quality (IAQ) monitoring setup that combines occupancy detection with adaptive sample rates, achieving operational times of up to 143 h on a single compact 600 mAh, 3.7 V battery. Our platform lays the groundwork for innovative applications such as predictive indoor IAQ, enabling efficient AI-driven on-edge forecasting for energy-efficient and autonomous, proactive pollution-mitigation control strategies",
      "authors": [
        "Philip Wiese",
        "Victor Kartsch",
        "Marco Guermandi and Luca Benini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Image and Video Processing (eess.IV)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:49:46+00:00",
          "link": "https://arxiv.org/abs/2507.14165v1",
          "size": "2769kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Modal IoT Node for Energy-Efficient Environmental Monitoring with Edge AI Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14165",
        "PDF": "https://arxiv.org/pdf/2507.14165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an IoT node for environmental monitoring, focusing on energy-efficient AI processing for environmental data. There is no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14181",
      "abstract": "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe operation of industrial machinery and improving production efficiency. However, traditional supervised deep learning methods require a large amount of training data and labels, which are often located in different clients. Additionally, the cost of data labeling is high, making labels difficult to acquire. Meanwhile, differences in data distribution among clients may also hinder the model's performance. To tackle these challenges, this paper proposes a semi-supervised federated learning framework, SSFL-DCSL, which integrates dual contrastive loss and soft labeling to address data and label scarcity for distributed clients with few labeled samples while safeguarding user privacy. It enables representation learning using unlabeled data on the client side and facilitates joint learning among clients through prototypes, thereby achieving mutual knowledge sharing and preventing local model divergence. Specifically, first, a sample weighting function based on the Laplace distribution is designed to alleviate bias caused by low confidence in pseudo labels during the semi-supervised training process. Second, a dual contrastive loss is introduced to mitigate model divergence caused by different data distributions, comprising local contrastive loss and global contrastive loss. Third, local prototypes are aggregated on the server with weighted averaging and updated with momentum to share knowledge among clients. To evaluate the proposed SSFL-DCSL framework, experiments are conducted on two publicly available datasets and a dataset collected on motors from the factory. In the most challenging task, where only 10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by 1.15% to 7.85% over state-of-the-art methods.",
      "authors": [
        "Yajiao Dai",
        "Jun Li",
        "Zhen Mei",
        "Yiyang Ni",
        "Shi Jin",
        "Zengxiang Li",
        "Sheng Guo",
        "Wei Xiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T10:54:23+00:00",
          "link": "https://arxiv.org/abs/2507.14181v1",
          "size": "17087kb",
          "version": "v1"
        }
      ],
      "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14181",
        "HTML": "https://arxiv.org/html/2507.14181",
        "PDF": "https://arxiv.org/pdf/2507.14181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses semi-supervised federated learning for fault diagnosis and does not relate to LLM training data processing or any relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14799",
      "abstract": "This work demonstrates that LLM-based web navigation agents offer powerful automation capabilities but are vulnerable to Indirect Prompt Injection (IPI) attacks. We show that adversaries can embed universal adversarial triggers in webpage HTML to hijack agent behavior that utilizes the accessibility tree to parse HTML, causing unintended or malicious actions. Using the Greedy Coordinate Gradient (GCG) algorithm and a Browser Gym agent powered by Llama-3.1, our system demonstrates high success rates across real websites in both targeted and general attacks, including login credential exfiltration and forced ad clicks. Our empirical results highlight critical security risks and the need for stronger defenses as LLM-driven autonomous web agents become more widely adopted. The system software (https://github.com/sej2020/manipulating-web-agents) is released under the MIT License, with an accompanying publicly available demo website (http://lethaiq.github.io/attack-web-llm-agent).",
      "authors": [
        "Sam Johnson",
        "Viet Pham",
        "Thai Le"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.14799v1",
          "size": "3818kb",
          "version": "v1"
        }
      ],
      "title": "Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14799",
        "HTML": "https://arxiv.org/html/2507.14799",
        "PDF": "https://arxiv.org/pdf/2507.14799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses security vulnerabilities in LLM web agents via indirect prompt injection attacks, not about training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15230",
      "abstract": "Unstructured meshes present challenges in scientific data analysis due to irregular distribution and complex connectivity. Computing and storing connectivity information is a major bottleneck for visualization algorithms, affecting both time and memory performance. Recent task-parallel data structures address this by precomputing connectivity information at runtime while the analysis algorithm executes, effectively hiding computation costs and improving performance. However, existing approaches are CPU-bound, forcing the data structure and analysis algorithm to compete for the same computational resources, limiting potential speedups. To overcome this limitation, we introduce a novel task-parallel approach optimized for heterogeneous CPU-GPU systems. Specifically, we offload the computation of mesh connectivity information to GPU threads, enabling CPU threads to focus on executing the visualization algorithm. Following this paradigm, we propose GALE (GPU-Aided Localized data structurE), the first open-source CUDA-based data structure designed for heterogeneous task parallelism. Experiments on two 20-core CPUs and an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over state-of-the-art localized data structures while maintaining memory efficiency.",
      "authors": [
        "Guoxi Liu",
        "Thomas Randall",
        "Rong Ge",
        "and Federico Iuricich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:20:12+00:00",
          "link": "https://arxiv.org/abs/2507.15230v1",
          "size": "8909kb",
          "version": "v1"
        }
      ],
      "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15230",
        "HTML": "https://arxiv.org/html/2507.15230",
        "PDF": "https://arxiv.org/pdf/2507.15230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses efficient data analysis of unstructured mesh data using heterogeneous systems, which is not connected to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15443",
      "abstract": "To understand and quantify the quality of mixed-presence collaboration around wall-sized displays, robust evaluation methodologies are needed, that are adapted for a room-sized experience and are not perceived as obtrusive. In this paper, we propose our approach for measuring joint attention based on head gaze data. We describe how it has been implemented for a user study on mixed presence collaboration with two wall-sized displays and report on the insights we gained so far from its implementation, with a preliminary focus on the data coming from one particular session.",
      "authors": [
        "Adrien Coppens",
        "Val\\'erie Maquil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:53:24+00:00",
          "link": "https://arxiv.org/abs/2507.15443v1",
          "size": "1436kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Joint Attention for Mixed-Presence Collaboration on Wall-Sized Displays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15443",
        "HTML": "https://arxiv.org/html/2507.15443",
        "PDF": "https://arxiv.org/pdf/2507.15443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is about evaluating joint attention in mixed-presence collaborations on wall-sized displays, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15783",
      "abstract": "As Generative Artificial Intelligence (GenAI) driven chatbots like Character.AI become embedded in adolescent life, they raise concerns about emotional dependence and digital overreliance. While studies have investigated the overreliance of adults on these chatbots, they have not investigated teens' interactions with chatbots with customizable personas. We analyzed 318 Reddit posts made by users self-reported as 13-17 years old on the Character.AI subreddit to understand patterns of overreliance. We found teens commonly begin using chatbots for emotional support or creative expression, but many develop strong attachments that interfere with offline relationships and daily routines. Their posts revealed recurring signs of psychological distress, cycles of relapse, and difficulty disengaging. Teens reported that their overreliance often ended when they reflect on the harm, return to in-person social settings, or become frustrated by platform restrictions. Based on the implications of our findings, we provide recommendations for future chatbot design so they can promote self-awareness, support real-world engagement, and involve teens in developing safer digital tools.",
      "authors": [
        "Mohammad 'Matt' Namvarpour",
        "Brandon Brofsky",
        "Jessica Medina",
        "Mamtaj Akter",
        "and Afsaneh Razi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:39:33+00:00",
          "link": "https://arxiv.org/abs/2507.15783v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15783",
        "HTML": "https://arxiv.org/html/2507.15783",
        "PDF": "https://arxiv.org/pdf/2507.15783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates adolescents' overreliance on AI-driven chatbots and its psychological impact, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.10789",
      "abstract": "Low-level 3D representations, such as point clouds, meshes, NeRFs and 3D Gaussians, are commonly used for modeling 3D objects and scenes. However, cognitive studies indicate that human perception operates at higher levels and interprets 3D environments by decomposing them into meaningful structural parts, rather than low-level elements like points or voxels. Structured geometric decomposition enhances scene interpretability and facilitates downstream tasks requiring component-level manipulation. In this work, we introduce PartGS, a self-supervised part-aware reconstruction framework that integrates 2D Gaussians and superquadrics to parse objects and scenes into an interpretable decomposition, leveraging multi-view image inputs to uncover 3D structural information. Our method jointly optimizes superquadric meshes and Gaussians by coupling their parameters within a hybrid representation. On one hand, superquadrics enable the representation of a wide range of shape primitives, facilitating flexible and meaningful decompositions. On the other hand, 2D Gaussians capture detailed texture and geometric details, ensuring high-fidelity appearance and geometry reconstruction. Operating in a self-supervised manner, our approach demonstrates superior performance compared to state-of-the-art methods across extensive experiments on the DTU, ShapeNet, and real-world datasets.",
      "authors": [
        "Zhirui Gao",
        "Renjiao Yi",
        "Yuhang Huang",
        "Wei Chen",
        "Chenyang Zhu",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T12:30:37+00:00",
          "link": "https://arxiv.org/abs/2408.10789v1",
          "size": "5028kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T17:04:07+00:00",
          "link": "https://arxiv.org/abs/2408.10789v2",
          "size": "13672kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:40:39+00:00",
          "link": "https://arxiv.org/abs/2408.10789v3",
          "size": "7703kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T07:32:02+00:00",
          "link": "https://arxiv.org/abs/2408.10789v4",
          "size": "10507kb",
          "version": "v4"
        }
      ],
      "title": "Self-supervised Learning of Hybrid Part-aware 3D Representations of 2D Gaussians and Superquadrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10789",
        "HTML": "https://arxiv.org/html/2408.10789",
        "PDF": "https://arxiv.org/pdf/2408.10789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with self-supervised learning for 3D object modeling and decomposition, targeting 3D representations. It does not involve LLM training data processing or any related operations."
      },
      "tasks": [
        "3D Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04534",
      "abstract": "Modeling late reverberation in real-time interactive applications is a challenging task when multiple sound sources and listeners are present in the same environment. This is especially problematic when the environment is geometrically complex and/or features uneven energy absorption (e.g. coupled volumes), because in such cases the late reverberation is dependent on the sound sources' and listeners' positions, and therefore must be adapted to their movements in real time. We present a novel approach to the task, named modal decomposition of acoustic radiance transfer (MoD-ART), which can handle highly complex scenarios with efficiency. The approach is based on the geometrical acoustics method of acoustic radiance transfer, from which we extract a set of energy decay modes and their positional relationships with sources and listeners. In this paper, we describe the physical and mathematical significance of MoD-ART, highlighting its advantages and applicability to different scenarios. Through an analysis of the method's computational complexity, we show that it compares very favorably with ray-tracing. We also present simulation results showing that MoD-ART can capture multiple decay slopes and flutter echoes.",
      "authors": [
        "Matteo Scerbo",
        "Sebastian J. Schlecht",
        "Randall Ali",
        "Lauri Savioja",
        "Enzo De Sena"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Systems and Control (cs.SY)",
        "Audio and Speech Processing (eess.AS)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T17:44:41+00:00",
          "link": "https://arxiv.org/abs/2412.04534v1",
          "size": "1144kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:17:13+00:00",
          "link": "https://arxiv.org/abs/2412.04534v2",
          "size": "254kb",
          "version": "v2"
        }
      ],
      "title": "Modeling nonuniform energy decay through the modal decomposition of acoustic radiance transfer (MoD-ART)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04534",
        "PDF": "https://arxiv.org/pdf/2412.04534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for acoustic modeling using MoD-ART, focusing on sound in interactive applications. It does not relate to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18665",
      "abstract": "Autoregressive and recurrent networks have achieved remarkable progress across various fields, from weather forecasting to molecular generation and Large Language Models. Despite their strong predictive capabilities, these models lack a rigorous framework for addressing uncertainty, which is key in scientific applications such as PDE solving, molecular generation and Machine Learning Force Fields. To address this shortcoming we present BARNN: a variational Bayesian Autoregressive and Recurrent Neural Network. BARNNs aim to provide a principled way to turn any autoregressive or recurrent model into its Bayesian version. BARNN is based on the variational dropout method, allowing to apply it to large recurrent neural networks as well. We also introduce a temporal version of the \"Variational Mixtures of Posteriors\" prior (tVAMP-prior) to make Bayesian inference efficient and well-calibrated. Extensive experiments on PDE modelling and molecular generation demonstrate that BARNN not only achieves comparable or superior accuracy compared to existing methods, but also excels in uncertainty quantification and modelling long-range dependencies.",
      "authors": [
        "Dario Coscia",
        "Max Welling",
        "Nicola Demo",
        "Gianluigi Rozza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T15:44:04+00:00",
          "link": "https://arxiv.org/abs/2501.18665v1",
          "size": "2249kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T23:49:21+00:00",
          "link": "https://arxiv.org/abs/2501.18665v2",
          "size": "2243kb",
          "version": "v2"
        }
      ],
      "title": "BARNN: A Bayesian Autoregressive and Recurrent Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18665",
        "HTML": "https://arxiv.org/html/2501.18665",
        "PDF": "https://arxiv.org/pdf/2501.18665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents BARNN, a Bayesian version of autoregressive and recurrent neural networks with a focus on uncertainty quantification. It doesn't discuss LLM training data processing or data engineering techniques relevant to LLMs."
      },
      "tasks": [
        "Bayesian Inference",
        "Uncertainty Quantification",
        "Weather Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02065",
      "abstract": "Explainable AI (XAI) holds significant promise for enhancing the transparency and trustworthiness of AI-driven threat detection in Security Operations Centers (SOCs). However, identifying the appropriate level and format of explanation, particularly in environments that demand rapid decision-making under high-stakes conditions, remains a complex and underexplored challenge. To address this gap, we conducted a three-month mixed-methods study combining an online survey (N1=248) with in-depth interviews (N2=24) to examine (1) how SOC analysts conceptualize AI-generated explanations and (2) which types of explanations are perceived as actionable and trustworthy across different analyst roles. Our findings reveal that participants were consistently willing to accept XAI outputs, even in cases of lower predictive accuracy, when explanations were perceived as relevant and evidence-backed. Analysts repeatedly emphasized the importance of understanding the rationale behind AI decisions, expressing a strong preference for contextual depth over a mere presentation of outcomes on dashboards. Building on these insights, this study re-evaluates current explanation methods within security contexts and demonstrates that role-aware, context-rich XAI designs aligned with SOC workflows can substantially improve practical utility. Such tailored explainability enhances analyst comprehension, increases triage efficiency, and supports more confident responses to evolving threats.",
      "authors": [
        "Nidhi Rastogi",
        "Shirid Pant",
        "Devang Dhanuka",
        "Amulya Saxena",
        "Pranjal Mairal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T21:39:15+00:00",
          "link": "https://arxiv.org/abs/2503.02065v1",
          "size": "630kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T21:15:33+00:00",
          "link": "https://arxiv.org/abs/2503.02065v2",
          "size": "235kb",
          "version": "v2"
        }
      ],
      "title": "Too Much to Trust? Measuring the Security and Cognitive Impacts of Explainability in AI-Driven SOCs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02065",
        "HTML": "https://arxiv.org/html/2503.02065",
        "PDF": "https://arxiv.org/pdf/2503.02065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores explainability in AI-driven Security Operations Centers, which pertains to enhancing AI transparency rather than processing data for LLM training."
      },
      "tasks": [
        "Decision Making",
        "Navigate",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22814",
      "abstract": "Conventional frame-based cameras often struggle with limited dynamic range, leading to saturation and loss of detail when capturing scenes with significant brightness variations. Neuromorphic cameras, inspired by human retina, offer a solution by providing an inherently high dynamic range. This capability enables them to capture both bright and faint celestial objects without saturation effects, preserving details across a wide range of luminosities. This paper investigates the application of neuromorphic imaging technology for capturing celestial bodies across a wide range of flux levels. Its advantages are demonstrated through examples such as the bright planet Saturn with its faint moons and the bright star Sirius A alongside its faint companion, Sirius B.",
      "authors": [
        "Satyapreet Singh Yadav",
        "Nirupam Roy",
        "Chetan Singh Thakur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T18:22:16+00:00",
          "link": "https://arxiv.org/abs/2503.22814v1",
          "size": "484kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Celestial Imaging: High Dynamic Range with Neuromorphic Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22814",
        "PDF": "https://arxiv.org/pdf/2503.22814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the use of neuromorphic cameras for high dynamic range celestial imaging, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14308",
      "abstract": "Purpose: This study aims to improve 0.55T T2-weighted PROPELLER lung MRI through a self-supervised joint reconstruction and denoising model.\n  Methods: T2-weighted 0.55T lung MRI dataset including 44 patients with previous covid infection were used. A self-supervised learning framework was developed, where each blade of the PROPELLER acquisition was split along the readout direction into two partitions. One subset trains the unrolled reconstruction network, while the other subset is used for loss calculation, enabling self-supervised training without clean targets and leveraging matched noise statistics for denoising. For comparison, Marchenko-Pastur Principal Component Analysis (MPPCA) was performed along the coil dimension, followed by conventional parallel imaging reconstruction. The quality of the reconstructed lung MRI was assessed visually by two experienced radiologists independently.\n  Results: The proposed self-supervised model improved the clarity and structural integrity of the lung images. For cases with available CT scans, the reconstructed images demonstrated strong alignment with corresponding CT images. Additionally, the proposed model enables further scan time reduction by requiring only half the number of blades. Reader evaluations confirmed that the proposed method outperformed MPPCA-denoised images across all categories (Wilcoxon signed-rank test, p<0.001), with moderate inter-reader agreement (weighted Cohen's kappa=0.55; percentage of exact and within +/-1 point agreement=91%).\n  Conclusion: By leveraging intrinsic structural redundancies between two disjoint splits of k-space subsets, the proposed self-supervised learning model effectively reconstructs the image while suppressing the noise for 0.55T T2-weighted lung MRI with PROPELLER sampling.",
      "authors": [
        "Jingjia Chen",
        "Haoyang Pei",
        "Christoph Maier",
        "Mary Bruno",
        "Qiuting Wen",
        "Seon-Hi Shin",
        "William Moore",
        "Hersh Chandarana",
        "Li Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.14308v1",
          "size": "12718kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Joint Reconstruction and Denoising of T2-Weighted PROPELLER MRI of the Lungs at 0.55T",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14308",
        "PDF": "https://arxiv.org/pdf/2507.14308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving MRI reconstruction and denoising through self-supervised learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15578",
      "abstract": "Change detection from satellite images typically incurs a delay ranging from several hours up to days because of latency in downlinking the acquired images and generating orthorectified image products at the ground stations; this may preclude real- or near real-time applications. To overcome this limitation, we propose shifting the entire change detection workflow onboard satellites. This requires to simultaneously solve challenges in data storage, image registration and change detection with a strict complexity constraint. In this paper, we present a novel and efficient framework for onboard change detection that addresses the aforementioned challenges in an end-to-end fashion with a deep neural network composed of three interlinked submodules: (1) image compression, tailored to minimize onboard data storage resources; (2) lightweight co-registration of non-orthorectified multi-temporal image pairs; and (3) a novel temporally-invariant and computationally efficient change detection model. This is the first approach in the literature combining all these tasks in a single end-to-end framework with the constraints dictated by onboard processing. Experimental results compare each submodule with the current state-of-the-art, and evaluate the performance of the overall integrated system in realistic setting on low-power hardware. Compelling change detection results are obtained in terms of F1 score as a function of compression rate, sustaining a throughput of 0.7 Mpixel/s on a 15W accelerator.",
      "authors": [
        "Gabriele Inzerillo",
        "Diego Valsesia",
        "Aniello Fiengo",
        "Enrico Magli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:58:32+00:00",
          "link": "https://arxiv.org/abs/2507.15578v1",
          "size": "6326kb",
          "version": "v1"
        }
      ],
      "title": "Compress-Align-Detect: onboard change detection from unregistered images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15578",
        "HTML": "https://arxiv.org/html/2507.15578",
        "PDF": "https://arxiv.org/pdf/2507.15578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for onboard change detection from satellite images. It deals with image processing challenges and does not relate to LLM training data or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15624",
      "abstract": "React is a JavaScript library used to build user interfaces for single-page applications. Although recent studies have shown the popularity and advantages of React in web development, the specific challenges users face remain unknown. Thus, this study aims to analyse the React-related questions shared on Stack Overflow. The study utilizes an exploratory data analysis to investigate the most frequently discussed keywords, error classification, and user reputation-based errors, which is the novelty of this work. The results show the top eight most frequently used keywords on React-related questions, namely, code, link, vir, href, connect, azure, windows, and website. The error classification of questions from the sample shows that algorithmic error is the most frequent issue faced by all groups of users, where mid-reputation users contribute the most, accounting for 55.77%. This suggests the need for the community to provide guidance materials in solving algorithm-related problems. We expect that the results of this study will provide valuable insight into future research to support the React community during the early stages of implementation, facilitating their ability to effectively overcome challenges to adoption.",
      "authors": [
        "Yusuf Sulistyo Nugroho",
        "Ganno Tribuana Kurniaji",
        "Syful Islam",
        "Mohammed Humayun Kabir",
        "Vanesya Aura Ardity",
        "Md. Kamal Uddin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:49:20+00:00",
          "link": "https://arxiv.org/abs/2507.15624v1",
          "size": "895kb",
          "version": "v1"
        }
      ],
      "title": "Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15624",
        "PDF": "https://arxiv.org/pdf/2507.15624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes discussions on Stack Overflow related to the React library, focusing on user challenges and common errors. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15698",
      "abstract": "Process Reward Models (PRMs) play a central role in evaluating and guiding multi-step reasoning in large language models (LLMs), especially for mathematical problem solving. However, we identify a pervasive length bias in existing PRMs: they tend to assign higher scores to longer reasoning steps, even when the semantic content and logical validity are unchanged. This bias undermines the reliability of reward predictions and leads to overly verbose outputs during inference. To address this issue, we propose CoLD(Counterfactually-Guided Length Debiasing), a unified framework that mitigates length bias through three components: an explicit length-penalty adjustment, a learned bias estimator trained to capture spurious length-related signals, and a joint training strategy that enforces length-invariance in reward predictions. Our approach is grounded in counterfactual reasoning and informed by causal graph analysis. Extensive experiments on MATH500 and GSM-Plus show that CoLD consistently reduces reward-length correlation, improves accuracy in step selection, and encourages more concise, logically valid reasoning. These results demonstrate the effectiveness and practicality of CoLD in improving the fidelity and robustness of PRMs.",
      "authors": [
        "Congmin Zheng",
        "Jiachen Zhu",
        "Jianghao Lin",
        "Xinyi Dai",
        "Yong Yu",
        "Weinan Zhang",
        "Mengyue Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:07:59+00:00",
          "link": "https://arxiv.org/abs/2507.15698v1",
          "size": "831kb",
          "version": "v1"
        }
      ],
      "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15698",
        "HTML": "https://arxiv.org/html/2507.15698",
        "PDF": "https://arxiv.org/pdf/2507.15698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on counterfactual reasoning and debiasing techniques in Process Reward Models, particularly for mathematical problem-solving, and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.15333",
      "abstract": "This paper presents a formation control approach for contactless gesture-based Human-Swarm Interaction (HSI) between a team of multi-rotor Unmanned Aerial Vehicles (UAVs) and a human worker. The approach is designed to monitor the safety of human workers, particularly those operating at heights. In the proposed dynamic formation scheme, one UAV acts as the formation leader, equipped with sensors for detecting human workers and recognizing gestures. The follower UAVs maintain a predetermined formation relative to the worker's position, providing additional perspectives of the monitored scene. Hand gestures enable the human worker to specify movement and action commands for the UAV team and to initiate other mission-related tasks without requiring additional communication channels or specific markers. Combined with a novel unified human detection and tracking algorithm, a human position estimation method, and a gesture detection pipeline, the proposed approach represents the first instance of an HSI system incorporating all these modules onboard real-world UAVs. Simulations and field experiments involving three UAVs and a human worker in a mock-up scenario demonstrate the effectiveness and responsiveness of the proposed approach.",
      "authors": [
        "V\\'it Kr\\'atk\\'y",
        "Giuseppe Silano",
        "Matou\\v{s} Vrba",
        "Christos Papaioannidis",
        "Ioannis Mademlis",
        "Robert P\\v{e}ni\\v{c}ka",
        "Ioannis Pitas",
        "Martin Saska"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-22T16:39:13+00:00",
          "link": "https://arxiv.org/abs/2403.15333v1",
          "size": "5841kb",
          "version": "v1"
        },
        {
          "date": "2024-09-11T10:10:37+00:00",
          "link": "https://arxiv.org/abs/2403.15333v2",
          "size": "17045kb",
          "version": "v2"
        },
        {
          "date": "2025-07-06T14:31:29+00:00",
          "link": "https://arxiv.org/abs/2403.15333v3",
          "size": "17190kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T10:11:39+00:00",
          "link": "https://arxiv.org/abs/2403.15333v4",
          "size": "7361kb",
          "version": "v4"
        }
      ],
      "title": "Gesture-Controlled Aerial Robot Formation for Human-Swarm Interaction in Safety Monitoring Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15333",
        "HTML": "https://arxiv.org/html/2403.15333",
        "PDF": "https://arxiv.org/pdf/2403.15333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on gesture-based human-swarm interaction using UAVs for safety monitoring, without any discussion on LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.00614",
      "abstract": "To enable robots to use tools, the initial step is teaching robots to employ dexterous gestures for touching specific areas precisely where tasks are performed. Affordance features of objects serve as a bridge in the functional interaction between agents and objects. However, leveraging these affordance cues to help robots achieve functional tool grasping remains unresolved. To address this, we propose a granularity-aware affordance feature extraction method for locating functional affordance areas and predicting dexterous coarse gestures. We study the intrinsic mechanisms of human tool use. On one hand, we use fine-grained affordance features of object-functional finger contact areas to locate functional affordance regions. On the other hand, we use highly activated coarse-grained affordance features in hand-object interaction regions to predict grasp gestures. Additionally, we introduce a model-based post-processing module that transforms affordance localization and gesture prediction into executable robotic actions. This forms GAAF-Dex, a complete framework that learns Granularity-Aware Affordances from human-object interaction to enable tool-based functional grasping with dexterous hands. Unlike fully-supervised methods that require extensive data annotation, we employ a weakly supervised approach to extract relevant cues from exocentric (Exo) images of hand-object interactions to supervise feature extraction in egocentric (Ego) images. To support this approach, we have constructed a small-scale dataset, Functional Affordance Hand-object Interaction Dataset (FAH), which includes nearly 6K images of functional hand-object interaction Exo images and Ego images. Extensive experiments on the dataset demonstrate that our method outperforms state-of-the-art methods. The source code and the established dataset are available at https://github.com/yangfan293/GAAF-DEX.",
      "authors": [
        "Fan Yang",
        "Wenrui Chen",
        "Kailun Yang",
        "Haoran Lin",
        "Dongsheng Luo",
        "Conghui Tang",
        "Zhiyong Li",
        "Yaonan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-30T07:42:57+00:00",
          "link": "https://arxiv.org/abs/2407.00614v1",
          "size": "2031kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T14:17:38+00:00",
          "link": "https://arxiv.org/abs/2407.00614v2",
          "size": "14172kb",
          "version": "v2"
        }
      ],
      "title": "Learning Granularity-Aware Affordances from Human-Object Interaction for Tool-Based Functional Dexterous Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.00614",
        "HTML": "https://arxiv.org/html/2407.00614",
        "PDF": "https://arxiv.org/pdf/2407.00614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on affordance feature extraction for robotic dexterous grasping, which is unrelated to LLM training data processing or any contribution to datasets for such models."
      },
      "tasks": [
        "Human-Object Interaction Detection",
        "Object"
      ],
      "repo_urls": [
        "https://github.com/yangfan293/gaaf-dex"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04300",
      "abstract": "Handling incomplete and heterogeneous data remains a central challenge in real-world machine learning, where missing values may follow complex mechanisms (MCAR, MAR, MNAR) and features can be of mixed types (numerical and categorical). Existing methods often rely on imputation, which may introduce bias or privacy risks, or fail to jointly address data heterogeneity and structured missingness. We propose the \\textbf{H}eterogeneous \\textbf{I}ncomplete \\textbf{P}robability \\textbf{M}ass \\textbf{K}ernel (\\textbf{HI-PMK}), a novel data-dependent representation learning approach that eliminates the need for imputation. HI-PMK introduces two key innovations: (1) a probability mass-based dissimilarity measure that adapts to local data distributions across heterogeneous features (numerical, ordinal, nominal), and (2) a missingness-aware uncertainty strategy (MaxU) that conservatively handles all three missingness mechanisms by assigning maximal plausible dissimilarity to unobserved entries. Our approach is privacy-preserving, scalable, and readily applicable to downstream tasks such as classification and clustering. Extensive experiments on over 15 benchmark datasets demonstrate that HI-PMK consistently outperforms traditional imputation-based pipelines and kernel methods across a wide range of missing data settings. Code is available at: https://github.com/echoid/Incomplete-Heter-Kernel",
      "authors": [
        "Youran Zhou",
        "Mohamed Reda Bouadjenek",
        "Jonathan Wells",
        "Sunil Aryal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T06:18:32+00:00",
          "link": "https://arxiv.org/abs/2501.04300v1",
          "size": "254kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T00:58:22+00:00",
          "link": "https://arxiv.org/abs/2501.04300v2",
          "size": "403kb",
          "version": "v2"
        }
      ],
      "title": "HI-PMK: A Data-Dependent Kernel for Incomplete Heterogeneous Data Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04300",
        "HTML": "https://arxiv.org/html/2501.04300",
        "PDF": "https://arxiv.org/pdf/2501.04300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a kernel method for heterogeneous and incomplete data representation in machine learning, specifically enhancing data representations without imputation. It does not address LLM training data processing."
      },
      "tasks": [
        "Missing Values"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05742",
      "abstract": "Urban traffic congestion, exacerbated by inefficient parking management and cruising for parking, significantly hampers mobility and sustainability in smart cities. Drivers often face delays searching for parking spaces, influenced by factors such as accessibility, cost, distance, and available services such as charging facilities in the case of electric vehicles. These inefficiencies contribute to increased urban congestion, fuel consumption, and environmental impact. Addressing these challenges, this paper proposes a feedback control incentivisation-based system that aims to better distribute vehicles between city and suburban parking facilities offering park-and-charge/-ride services. Individual driver behaviours are captured via discrete choice models incorporating factors of importance to parking location choice among drivers, such as distance to work, public transport connectivity, charging infrastructure availability, and amount of incentive offered; and are regulated through principles of ergodic control theory. The proposed framework is applied to an electric vehicle park-and-charge/-ride problem, and demonstrates how predictable long-term behaviour of the system can be guaranteed.",
      "authors": [
        "Abdul Baseer Satti",
        "James Saunderson",
        "Wynita Griggs",
        "S. M. Nawazish Ali",
        "Nameer Al Khafaf",
        "Saman Ahmadi",
        "Mahdi Jalili",
        "Jakub Marecek",
        "Robert Shorten"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T02:51:27+00:00",
          "link": "https://arxiv.org/abs/2505.05742v1",
          "size": "916kb",
          "version": "v1"
        }
      ],
      "title": "A Feedback Control Framework for Incentivised Suburban Parking Utilisation and Urban Core Traffic Relief",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05742",
        "HTML": "https://arxiv.org/html/2505.05742",
        "PDF": "https://arxiv.org/pdf/2505.05742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses urban traffic management and parking solutions, which are unrelated to LLM training data processing."
      },
      "tasks": [
        "Discrete Choice Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13023",
      "abstract": "Recent advances in generative AI have led to remarkable interest in using systems that rely on large language models (LLMs) for practical applications. However, meaningful evaluation of these systems in real-world scenarios comes with a distinct set of challenges, which are not well-addressed by synthetic benchmarks and de-facto metrics that are often seen in the literature. We present a practical evaluation framework which outlines how to proactively curate representative datasets, select meaningful evaluation metrics, and employ meaningful evaluation methodologies that integrate well with practical development and deployment of LLM-reliant systems that must adhere to real-world requirements and meet user-facing needs.",
      "authors": [
        "Ethan M. Rudd",
        "Christopher Andrews and Philip Tully"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T01:18:16+00:00",
          "link": "https://arxiv.org/abs/2506.13023v1",
          "size": "521kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:15:39+00:00",
          "link": "https://arxiv.org/abs/2506.13023v2",
          "size": "521kb",
          "version": "v2"
        }
      ],
      "title": "A Practical Guide for Evaluating LLMs and LLM-Reliant Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13023",
        "HTML": "https://arxiv.org/html/2506.13023",
        "PDF": "https://arxiv.org/pdf/2506.13023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the evaluation framework for LLMs and mentions dataset curation, which is a data processing step. However, it primarily targets evaluation methodologies rather than making a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14418",
      "abstract": "One challenge in technical interviews is the think-aloud process, where candidates verbalize their thought processes while solving coding tasks. Despite its importance, opportunities for structured practice remain limited. Conversational AI offers potential assistance, but limited research explores user perceptions of its role in think-aloud practice. To address this gap, we conducted a study with 17 participants using an LLM-based technical interview practice tool. Participants valued AI's role in simulation, feedback, and learning from generated examples. Key design recommendations include promoting social presence in conversational AI for technical interview simulation, providing feedback beyond verbal content analysis, and enabling crowdsourced think-aloud examples through human-AI collaboration. Beyond feature design, we examined broader considerations, including intersectional challenges and potential strategies to address them, how AI-driven interview preparation could promote equitable learning in computing careers, and the need to rethink AI's role in interview practice by suggesting a research direction that integrates human-AI collaboration.",
      "authors": [
        "Taufiq Daryanto",
        "Sophia Stil",
        "Xiaohan Ding",
        "Daniel Manesh",
        "Sang Won Lee",
        "Tim Lee",
        "Stephanie Lunn",
        "Sarah Rodriguez",
        "Chris Brown and Eugenia Rho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T00:15:05+00:00",
          "link": "https://arxiv.org/abs/2507.14418v1",
          "size": "4207kb",
          "version": "v1"
        }
      ],
      "title": "Designing Conversational AI to Support Think-Aloud Practice in Technical Interview Preparation for CS Students",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14418",
        "HTML": "https://arxiv.org/html/2507.14418",
        "PDF": "https://arxiv.org/pdf/2507.14418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's main focus is on designing conversational AI to support technical interview preparation. It does not address LLM training data processing, data collection, or improvement in dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14643",
      "abstract": "Modern multispectral feature fusion for object detection faces two critical limitations: (1) Excessive preference for local complementary features over cross-modal shared semantics adversely affects generalization performance; and (2) The trade-off between the receptive field size and computational complexity present critical bottlenecks for scalable feature modeling. Addressing these issues, a novel Multispectral State-Space Feature Fusion framework, dubbed MS2Fusion, is proposed based on the state space model (SSM), achieving efficient and effective fusion through a dual-path parametric interaction mechanism. More specifically, the first cross-parameter interaction branch inherits the advantage of cross-attention in mining complementary information with cross-modal hidden state decoding in SSM. The second shared-parameter branch explores cross-modal alignment with joint embedding to obtain cross-modal similar semantic features and structures through parameter sharing in SSM. Finally, these two paths are jointly optimized with SSM for fusing multispectral features in a unified framework, allowing our MS2Fusion to enjoy both functional complementarity and shared semantic space. In our extensive experiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our MS2Fusion significantly outperforms other state-of-the-art multispectral object detection methods, evidencing its superiority. Moreover, MS2Fusion is general and applicable to other multispectral perception tasks. We show that, even without specific design, MS2Fusion achieves state-of-the-art results on RGB-T semantic segmentation and RGBT salient object detection, showing its generality. The source code will be available at https://github.com/61s61min/MS2Fusion.git.",
      "authors": [
        "Jifeng Shen",
        "Haibo Zhan",
        "Shaohua Dong",
        "Xin Zuo",
        "Wankou Yang",
        "Haibin Ling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:38:03+00:00",
          "link": "https://arxiv.org/abs/2507.14643v1",
          "size": "4680kb",
          "version": "v1"
        }
      ],
      "title": "Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14643",
        "HTML": "https://arxiv.org/html/2507.14643",
        "PDF": "https://arxiv.org/pdf/2507.14643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on multispectral feature fusion for object detection and generalization performance, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14857",
      "abstract": "This paper examines the impact of solar farm fluctuations on grid stability, focusing on maintaining an optimal power factor. ETAP-based simulations and case studies are used to analyze real-time grid performance under solar variability. Reactive power control strategies and advanced inverter functions are proposed for stabilization. Theoretical analysis and simulation results highlight effective integration techniques. Artificial intelligence is trailed for controlling the SVC in adaptive reactive power compensation. The study provides practical solutions for improving reliability in renewable-integrated power systems.",
      "authors": [
        "Hassan Osseily"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:55:20+00:00",
          "link": "https://arxiv.org/abs/2507.14857v1",
          "size": "962kb",
          "version": "v1"
        }
      ],
      "title": "Grid Stability and Power Factor Dynamics in Solar Farms Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14857",
        "PDF": "https://arxiv.org/pdf/2507.14857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the integration of solar farms in power grids and the stability of grid systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14976",
      "abstract": "Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent generalization abilities. However, adapting these large-scale models to downstream tasks while preserving their generalization capabilities remains challenging. Although prompt learning methods have shown promise, they suffer from two fundamental bottlenecks that limit generalization: (a) modality isolation, and (b) hierarchical semantic decay. To address these limitations, we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that establishes bidirectional knowledge flow between text and vision modalities, enabling them to refine their semantics mutually. HiCroPL routes knowledge flows by leveraging the complementary strengths of text and vision. In early layers, text prompts inject relatively clear semantics into visual prompts through a hierarchical knowledge mapper, enhancing the representation of low-level visual semantics. In later layers, visual prompts encoding specific task-relevant objects flow back to refine text prompts, enabling deeper alignment. Crucially, our hierarchical knowledge mapper allows representations at multi-scales to be fused, ensuring that deeper representations retain transferable shallow semantics thereby enhancing generalization. We further introduce a lightweight layer-specific knowledge proxy to enable efficient cross-modal interactions. Extensive evaluations across four tasks demonstrate HiCroPL's superior performance, achieving state-of-the-art results on 11 benchmarks with significant improvements. Code is available at: https://github.com/zzeoZheng/HiCroPL.",
      "authors": [
        "Hao Zheng",
        "Shunzhi Yang",
        "Zhuoxin He",
        "Jinfeng Yang",
        "Zhenhua Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:18:04+00:00",
          "link": "https://arxiv.org/abs/2507.14976v1",
          "size": "614kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14976",
        "HTML": "https://arxiv.org/html/2507.14976",
        "PDF": "https://arxiv.org/pdf/2507.14976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on cross-modal prompt learning for vision-language models (VLMs) and doesn't involve training data processing operations crucial for LLM data training stages or dataset creation or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15092",
      "abstract": "Synthetic text generated by Large Language Models (LLMs) is increasingly used for further training and improvement of LLMs. Diversity is crucial for the effectiveness of synthetic data, and researchers rely on prompt engineering to improve diversity. However, the impact of prompt variations on response text length, and, more importantly, the consequential effect on lexical diversity measurements, remain underexplored. In this work, we propose Penalty-Adjusted Type-Token Ratio (PATTR), a diversity metric robust to length variations. We generate a large synthetic corpus of over 20M words using seven models from the LLaMA, OLMo, and Phi families, focusing on a creative writing task of video script generation, where diversity is crucial. We evaluate per-response lexical diversity using PATTR and compare it against existing metrics of Moving-Average TTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length variations introduce biases favoring shorter responses. Unlike existing metrics, PATTR explicitly considers the task-specific target response length ($L_T$) to effectively mitigate length biases. We further demonstrate the utility of PATTR in filtering the top-10/100/1,000 most lexically diverse responses, showing that it consistently outperforms MATTR and CR by yielding on par or better diversity with high adherence to $L_T$.",
      "authors": [
        "Vijeta Deshpande",
        "Ishita Dasgupta",
        "Uttaran Bhattacharya",
        "Somdeb Sarkhel",
        "Saayan Mitra",
        "Anna Rumshisky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:14:43+00:00",
          "link": "https://arxiv.org/abs/2507.15092v1",
          "size": "1290kb",
          "version": "v1"
        }
      ],
      "title": "A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15092",
        "HTML": "https://arxiv.org/html/2507.15092",
        "PDF": "https://arxiv.org/pdf/2507.15092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses a new diversity metric, PATTR, for evaluating and filtering synthetic text generated by LLMs, improving lexical diversity\u2014a crucial aspect of training data processing for model fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15197",
      "abstract": "In requirements engineering (RE), personas are now being used to represent user expectations and needs. This systematic mapping study (SMS) aims to explore the most recent studies and to cover recent changes in trends, especially related to the recent evolution of Generative AI approaches. Our SMS covers the period between April 2023 and April 2025. We identified 22 relevant publications and analysed persona representation, construction, validation, as well as RE activities covered by personas. We identified that a number of studies applied AI-based solutions for persona construction and validation. We observed that template-based personas are becoming more popular nowadays. We also observed an increase in the proportion of studies covering validation aspects.",
      "authors": [
        "Chowdhury Shahriar Muzammel",
        "Maria Spichkova",
        "James Harland"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:52:30+00:00",
          "link": "https://arxiv.org/abs/2507.15197v1",
          "size": "89kb",
          "version": "v1"
        }
      ],
      "title": "Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15197",
        "HTML": "https://arxiv.org/html/2507.15197",
        "PDF": "https://arxiv.org/pdf/2507.15197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses personas in requirements engineering and the evolution of Generative AI in this context. It does not address LLM training data processing or any relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15491",
      "abstract": "Enabling efficient text-video retrieval on edge-end devices is critical for real-world applications. Yet, existing methods face a critical challenge in balancing accuracy and computational efficiency: uniform frame sampling methods ensure content coverage but incur prohibitive computational costs, while salient-frame sampling methods reduce overhead but suffer from query-agnostic frame selection that biases retrieval results. To address this, we propose ProCLIP, a user-centric framework that achieves state-of-the-art accuracy with significantly improved efficiency. We design a prompt-aware frame sampling strategy that dynamically guides lightweight feature extractors using textual prompts to select semantically relevant frames, overcoming the limitations of existing salient-frame sampling methods which rely on static, query-agnostic selection criteria. Moreover, we adopt a two-stage candidate pruning strategy that combines rapid coarse filtering via a lightweight module with CLIP-powered fine-grained re-ranking, enhancing retrieval efficiency while preserving accuracy. Experiments across benchmarks show ProCLIP achieves 75.3% latency reduction versus baselines while maintaining competitive accuracy, i.e., R@1=49.0 in MSR-VTT dataset. Code is available at https://github.com/tiffylong/ProCLIP.",
      "authors": [
        "Deyu Zhang",
        "Tingting Long",
        "Jinrui Zhang",
        "Ligeng Chen",
        "Ju Ren",
        "Yaoxue Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:46:49+00:00",
          "link": "https://arxiv.org/abs/2507.15491v1",
          "size": "1934kb",
          "version": "v1"
        }
      ],
      "title": "Prompt-aware of Frame Sampling for Efficient Text-Video Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15491",
        "HTML": "https://arxiv.org/html/2507.15491",
        "PDF": "https://arxiv.org/pdf/2507.15491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for efficient text-video retrieval by improving frame sampling strategies. It does not relate to LLM training data processing or the creation of datasets specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15821",
      "abstract": "LLM use in annotation is becoming widespread, and given LLMs' overall promising performance and speed, simply \"reviewing\" LLM annotations in interpretive tasks can be tempting. In subjective annotation tasks with multiple plausible answers, reviewing LLM outputs can change the label distribution, impacting both the evaluation of LLM performance, and analysis using these labels in a social science task downstream. We conducted a pre-registered experiment with 410 unique annotators and over 7,000 annotations testing three AI assistance conditions against controls, using two models, and two datasets. We find that presenting crowdworkers with LLM-generated annotation suggestions did not make them faster, but did improve their self-reported confidence in the task. More importantly, annotators strongly took the LLM suggestions, significantly changing the label distribution compared to the baseline. When these labels created with LLM assistance are used to evaluate LLM performance, reported model performance significantly increases. We believe our work underlines the importance of understanding the impact of LLM-assisted annotation on subjective, qualitative tasks, on the creation of gold data for training and testing, and on the evaluation of NLP systems on subjective tasks.",
      "authors": [
        "Hope Schroeder",
        "Deb Roy",
        "Jad Kabbara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:29:21+00:00",
          "link": "https://arxiv.org/abs/2507.15821v1",
          "size": "1990kb",
          "version": "v1"
        }
      ],
      "title": "Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15821",
        "HTML": "https://arxiv.org/html/2507.15821",
        "PDF": "https://arxiv.org/pdf/2507.15821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the impact of LLM-assisted annotation on subjective tasks, which may relate to data processing; however, its primary focus is on annotation workflow and its effect on labeling outcomes rather than on core data processing improvements for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.07984",
      "abstract": "Scalable annotation approaches are crucial for constructing extensive 3D-text datasets, facilitating a broader range of applications. However, existing methods sometimes lead to the generation of hallucinated captions, compromising caption quality. This paper explores the issue of hallucination in 3D object captioning, with a focus on Cap3D method, which renders 3D objects into 2D views for captioning using pre-trained models. We pinpoint a major challenge: certain rendered views of 3D objects are atypical, deviating from the training data of standard image captioning models and causing hallucinations. To tackle this, we present DiffuRank, a method that leverages a pre-trained text-to-3D model to assess the alignment between 3D objects and their 2D rendered views, where the view with high alignment closely represent the object's characteristics. By ranking all rendered views and feeding the top-ranked ones into GPT4-Vision, we enhance the accuracy and detail of captions, enabling the correction of 200k captions in the Cap3D dataset and extending it to 1 million captions across Objaverse and Objaverse-XL datasets. Additionally, we showcase the adaptability of DiffuRank by applying it to pre-trained text-to-image models for a Visual Question Answering task, where it outperforms the CLIP model.",
      "authors": [
        "Tiange Luo",
        "Justin Johnson",
        "Honglak Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-11T17:58:11+00:00",
          "link": "https://arxiv.org/abs/2404.07984v1",
          "size": "14763kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:27:29+00:00",
          "link": "https://arxiv.org/abs/2404.07984v2",
          "size": "2278kb",
          "version": "v2"
        }
      ],
      "title": "View Selection for 3D Captioning via Diffusion Ranking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07984",
        "HTML": "https://arxiv.org/html/2404.07984",
        "PDF": "https://arxiv.org/pdf/2404.07984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses generating higher-quality 3D object captions, which involves some data processing, its primary focus is on view selection and improving 3D captioning, rather than LLM data processing per se."
      },
      "datasets": [
        {
          "dataset_name": "tiange/Cap3D",
          "downloads": "22116",
          "likes": "114",
          "link": "https://huggingface.co/datasets/tiange/Cap3D"
        }
      ],
      "tasks": [
        "3D Object Captioning",
        "Hallucination",
        "Image Captioning",
        "Question Answering",
        "Text to 3D",
        "Visual Question Answering"
      ],
      "repo_urls": [
        "https://github.com/crockwell/cap3d",
        "https://github.com/chenguolin/DiffSplat"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.01655",
      "abstract": "General-purpose object placement is a fundamental capability of an intelligent generalist robot: being capable of rearranging objects following precise human instructions even in novel environments. This work is dedicated to achieving general-purpose object placement with ``something something'' instructions. Specifically, we break the entire process down into three parts, including object localization, goal imagination and robot control, and propose a method named SPORT. SPORT leverages a pre-trained large vision model for broad semantic reasoning about objects, and learns a diffusion-based pose estimator to ensure physically-realistic results in 3D space. Only object types (movable or reference) are communicated between these two parts, which brings two benefits. One is that we can fully leverage the powerful ability of open-set object recognition and localization since no specific fine-tuning is needed for the robotic scenario. Moreover, the diffusion-based estimator only need to ``imagine\" the object poses after the placement, while no necessity for their semantic information. Thus the training burden is greatly reduced and no massive training is required. The training data for the goal pose estimation is collected in simulation and annotated by using GPT-4. Experimental results demonstrate the effectiveness of our approach. SPORT can not only generate promising 3D goal poses for unseen simulated objects, but also be seamlessly applied to real-world settings.",
      "authors": [
        "Jianyang Wu",
        "Jie Gu",
        "Xiaokang Ma",
        "Fangzhou Qiu",
        "Chu Tang",
        "Jingmin Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-03T03:53:05+00:00",
          "link": "https://arxiv.org/abs/2408.01655v1",
          "size": "2353kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:01:15+00:00",
          "link": "https://arxiv.org/abs/2408.01655v2",
          "size": "2783kb",
          "version": "v2"
        }
      ],
      "title": "Stimulating Imagination: Towards General-purpose \"Something Something Placement\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01655",
        "HTML": "https://arxiv.org/html/2408.01655",
        "PDF": "https://arxiv.org/pdf/2408.01655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a method for object placement with robots using diffusion-based estimators, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Object",
        "Object Localization",
        "Object Rearrangement",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.12431",
      "abstract": "Recent texture generation methods achieve impressive results due to the powerful generative prior they leverage from large-scale text-to-image diffusion models. However, abstract textual prompts are limited in providing global textural or shape information, which results in the texture generation methods producing blurry or inconsistent patterns. To tackle this, we present FlexiTex, embedding rich information via visual guidance to generate a high-quality texture. The core of FlexiTex is the Visual Guidance Enhancement module, which incorporates more specific information from visual guidance to reduce ambiguity in the text prompt and preserve high-frequency details. To further enhance the visual guidance, we introduce a Direction-Aware Adaptation module that automatically designs direction prompts based on different camera poses, avoiding the Janus problem and maintaining semantically global consistency. Benefiting from the visual guidance, FlexiTex produces quantitatively and qualitatively sound results, demonstrating its potential to advance texture generation for real-world applications.",
      "authors": [
        "DaDong Jiang",
        "Xianghui Yang",
        "Zibo Zhao",
        "Sheng Zhang",
        "Jiaao Yu",
        "Zeqiang Lai",
        "Shaoxiong Yang",
        "Chunchao Guo",
        "Xiaobo Zhou",
        "Zhihui Ke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-19T03:24:22+00:00",
          "link": "https://arxiv.org/abs/2409.12431v1",
          "size": "62688kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T02:23:44+00:00",
          "link": "https://arxiv.org/abs/2409.12431v2",
          "size": "26307kb",
          "version": "v2"
        },
        {
          "date": "2024-09-25T08:45:56+00:00",
          "link": "https://arxiv.org/abs/2409.12431v3",
          "size": "26307kb",
          "version": "v3"
        },
        {
          "date": "2024-12-27T12:18:55+00:00",
          "link": "https://arxiv.org/abs/2409.12431v4",
          "size": "21216kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T06:28:56+00:00",
          "link": "https://arxiv.org/abs/2409.12431v5",
          "size": "15283kb",
          "version": "v5"
        }
      ],
      "title": "FlexiTex: Enhancing Texture Generation via Visual Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12431",
        "HTML": "https://arxiv.org/html/2409.12431",
        "PDF": "https://arxiv.org/pdf/2409.12431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "FlexiTex focuses on enhancing texture generation via visual guidance, utilizing text-to-image diffusion models, without discussing any aspect of LLM training data processing."
      },
      "tasks": [
        "Texture Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.13532",
      "abstract": "Various numerical methods used for solving partial differential equations (PDE) result in tridiagonal systems. Solving tridiagonal systems on distributed-memory environments is not straightforward, and often requires significant amount of communication. In this article, we present a novel distributed-memory tridiagonal solver algorithm, DistD2-TDS, based on a specialised data structure. DistD2-TDS algorithm takes advantage of the diagonal dominance in tridiagonal systems to reduce the communications in distributed-memory environments. The underlying data structure plays a crucial role for the performance of the algorithm. First, the data structure improves data localities and makes it possible to minimise data movements via cache blocking and kernel fusion strategies. Second, data continuity enables a contiguous data access pattern and results in efficient utilisation of the available memory bandwidth. Finally, the data layout supports vectorisation on CPUs and thread level parallelisation on GPUs for improved performance. In order to demonstrate the robustness of the algorithm, we implemented and benchmarked the algorithm on CPUs and GPUs. We investigated the single rank performance and compared against existing algorithms. Furthermore, we analysed the strong scaling of the implementation up to 384 NVIDIA H100 GPUs and up to 8192 AMD EPYC 7742 CPUs. Finally, we demonstrated a practical use case of the algorithm by using compact finite difference schemes to solve a 3D non-linear PDE. The results demonstrate that DistD2 algorithm can sustain around 66% of the theoretical peak bandwidth at scale on CPU and GPU based supercomputers.",
      "authors": [
        "Semih Akkurt and S\\'ebastien Lemaire and Paul Bartholomew and Sylvain Laizet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T18:31:39+00:00",
          "link": "https://arxiv.org/abs/2411.13532v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "A Distributed-memory Tridiagonal Solver Based on a Specialised Data Structure Optimised for CPU and GPU Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13532",
        "PDF": "https://arxiv.org/pdf/2411.13532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a distributed-memory solver for tridiagonal systems in numerical methods. It does not relate to LLM training data processing or involve data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06369",
      "abstract": "We consider the Stokes-Darcy coupled problem, which models the interaction between free-flow and porous medium flow. By enforcing the normal flux continuity interface condition directly within the finite-element spaces, we establish unified well-posedness results for the coupled system under various boundary condition scenarios. Using the operator preconditioning framework, we develop a parameter-robust preconditioner that avoids the use of fractional operators. Numerical experiments employing both $H(\\operatorname{div})$-conforming and nonconforming finite-element methods are presented to confirm the theoretical findings and demonstrate the robustness of the proposed block preconditioners with respect to the physical parameters and mesh size.",
      "authors": [
        "Wietse M. Boon",
        "Xiaozhe Hu",
        "Xue Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T22:41:25+00:00",
          "link": "https://arxiv.org/abs/2501.06369v1",
          "size": "532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T05:23:45+00:00",
          "link": "https://arxiv.org/abs/2501.06369v2",
          "size": "366kb",
          "version": "v2"
        }
      ],
      "title": "Parameter-robust Preconditioners for the Stokes-Darcy Coupled Problem without Fractional Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06369",
        "HTML": "https://arxiv.org/html/2501.06369",
        "PDF": "https://arxiv.org/pdf/2501.06369"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses parameter-robust preconditioners for Stokes-Darcy coupled problems and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18109",
      "abstract": "Purpose: This study examines the core traits of image-to-image translation (I2I) networks, focusing on their effectiveness and adaptability in everyday clinical settings. Methods: We have analyzed data from 794 patients diagnosed with prostate cancer (PCa), using ten prominent 2D/3D I2I networks to convert ultrasound (US) images into MRI scans. We also introduced a new analysis of Radiomic features (RF) via the Spearman correlation coefficient to explore whether networks with high performance (SSIM>85%) could detect subtle RFs. Our study further examined synthetic images by 7 invited physicians. As a final evaluation study, we have investigated the improvement that are achieved using the synthetic MRI data on two traditional machine learning and one deep learning method. Results: In quantitative assessment, 2D-Pix2Pix network substantially outperformed the other 7 networks, with an average SSIM~0.855. The RF analysis revealed that 76 out of 186 RFs were identified using the 2D-Pix2Pix algorithm alone, although half of the RFs were lost during the translation process. A detailed qualitative review by 7 medical doctors noted a deficiency in low-level feature recognition in I2I tasks. Furthermore, the study found that synthesized image-based classification outperformed US image-based classification with an average accuracy and AUC~0.93. Conclusion: This study showed that while 2D-Pix2Pix outperformed cutting-edge networks in low-level feature discovery and overall error and similarity metrics, it still requires improvement in low-level feature performance, as highlighted by Group 3. Further, the study found using synthetic image-based classification outperformed original US image-based methods.",
      "authors": [
        "Mohammad R. Salmanpour",
        "Amin Mousavi",
        "Yixi Xu",
        "William B Weeks",
        "Ilker Hacihaliloglu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T03:23:10+00:00",
          "link": "https://arxiv.org/abs/2501.18109v1",
          "size": "973kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T23:22:17+00:00",
          "link": "https://arxiv.org/abs/2501.18109v2",
          "size": "1227kb",
          "version": "v2"
        }
      ],
      "title": "Influence of High-Performance Image-to-Image Translation Networks on Clinical Visual Assessment and Outcome Prediction: Utilizing Ultrasound to MRI Translation in Prostate Cancer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18109",
        "PDF": "https://arxiv.org/pdf/2501.18109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines image-to-image translation networks for clinical visual assessment, such as ultrasound to MRI conversion in prostate cancer cases. It is unrelated to LLM training data processing or data quality improvement methods."
      },
      "tasks": [
        "Image-to-Image Translation",
        "SSIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14627",
      "abstract": "Wireless-powered underground communication networks (WPUCNs), which allow underground devices (UDs) to harvest energy from wireless signals for battery-free communication, offer a promising solution for sustainable underground monitoring. However, the severe wireless signal attenuation in challenging underground environments and the costly acquisition of channel state information (CSI) make large-scale WPUCNs economically infeasible in practice. To address this challenge, we introduce flexible unmanned aerial vehicles (UAVs) into WPUCNs, leading to UAV-enabled WPUCN systems. In this system, a UAV is first charged by a terrestrial hybrid access point (HAP), then flies to the monitoring area to wirelessly charge UDs. Afterwards, the UAV collects data from the UDs and finally returns to the HAP for data offloading. Based on the proposed UAV-enabled WPUCN system, we first propose its energy consumption model and a hybrid wireless energy transfer (WET) approach (i.e., UDs can harvest energy from both the HAP and the UAV) relying on full-CSI and CSI-free multi-antenna beamforming. Then, we formulate and address a time allocation problem to minimize the energy consumption of UAV, while ensuring that the throughput requirements of all UDs are met and all sensor data is offloaded. Through simulations of a realistic farming scenario, we demonstrate that the proposed hybrid WET approach outperforms other WET approaches, with performance gains influenced by the number of antennas, communication distance, number of UDs, and underground conditions. Additionally, under the optimized time allocation, we found that the proposed hybrid WET approach based on a CSI-free multi-antenna scheme achieves the lowest UAV's energy consumption among all WET mechanisms, thereby enabling sustainable underground monitoring in WPUCNs.",
      "authors": [
        "Kaiqiang Lin",
        "Yijie Mao",
        "Onel Luis Alcaraz L\\'opez",
        "Mohamed-Slim Alouini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:46:37+00:00",
          "link": "https://arxiv.org/abs/2507.14627v1",
          "size": "1367kb",
          "version": "v1"
        }
      ],
      "title": "UAV-Enabled Wireless-Powered Underground Communication Networks: A Novel Time Allocation Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14627",
        "HTML": "https://arxiv.org/html/2507.14627",
        "PDF": "https://arxiv.org/pdf/2507.14627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on UAV-enabled underground communication networks and time allocation for energy efficiency, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15483",
      "abstract": "The reawakened era of lunar exploration is defined by a strategic shift from temporary visits to a sustained international and commercial presence, resulting in an unprecedented demand for a robust and continuously available communication infrastructure. The conventional direct-to-Earth communication architecture relies on limited and oversubscribed deep space networks, which are further challenged by the radiative environment and insufficient visibility in certain areas of the cislunar domain. We address these issues by proposing a foundational move toward inter-domain space network cooperation by introducing architectures based on near space networks. They can directly service lunar surface users or, via cislunar relays, by forming a resilient and multi-layered communication backbone. First, we establish a unified link analysis framework incorporating frequently disregarded environmental factors, such as the Moon's variable illumination, to provide a high-fidelity performance evaluation. Second, we assess architectures' reliability based on the outage risk, essential for quantifying the operational robustness of communication links. Finally, to manage the inherent dynamism of architectures, we propose an inter-domain space digital twin$-$a dynamic decision-making engine that performs real-time analysis to autonomously select the best communication path, ensuring high and stable reliability while simultaneously optimizing power consumption. Overall, our paper provides a holistic architectural and conceptual management framework, emphasizing the necessity of lunar communications to support a permanent human and economic foothold on the Moon.",
      "authors": [
        "Selen Gecgel Cetin",
        "Baris Donmez",
        "Gunes Karabulut Kurt"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.15483v1",
          "size": "17275kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Lunar Communication through Inter-domain Space Networks and Dynamic Orchestration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15483",
        "HTML": "https://arxiv.org/html/2507.15483",
        "PDF": "https://arxiv.org/pdf/2507.15483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses communication infrastructure for lunar exploration. It does not relate to LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15718",
      "abstract": "Electric vehicles (EV) charging stations are one of the critical infrastructures needed to support the transition to renewable-energy-based mobility, but ensuring their reliability and efficiency requires effective anomaly detection to identify irregularities in charging behavior. However, in such a productive scenario, it is also crucial to determine the underlying cause behind the detected anomalies. To achieve this goal, this study investigates unsupervised anomaly detection techniques for EV charging infrastructure, integrating eXplainable Artificial Intelligence techniques to enhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies Isolation Forest to detect anomalies and employs the Depth-based Isolation Forest Feature Importance (DIFFI) method to identify the most important features contributing to such anomalies. The efficacy of the proposed approach is evaluated in a real industrial case.",
      "authors": [
        "Matteo Cederle",
        "Andrea Mazzucco",
        "Andrea Demartini",
        "Eugenio Mazza",
        "Eugenia Suriani",
        "Federico Vitti",
        "and Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:27:48+00:00",
          "link": "https://arxiv.org/abs/2507.15718v1",
          "size": "112kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15718",
        "HTML": "https://arxiv.org/html/2507.15718",
        "PDF": "https://arxiv.org/pdf/2507.15718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on anomaly detection techniques for electric vehicle charging stations, involving explainable AI and feature importance methods, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15836",
      "abstract": "In this work we study black-box privacy auditing, where the goal is to lower bound the privacy parameter of a differentially private learning algorithm using only the algorithm's outputs (i.e., final trained model). For DP-SGD (the most successful method for training differentially private deep learning models), the canonical approach auditing uses membership inference-an auditor comes with a small set of special \"canary\" examples, inserts a random subset of them into the training set, and then tries to discern which of their canaries were included in the training set (typically via a membership inference attack). The auditor's success rate then provides a lower bound on the privacy parameters of the learning algorithm. Our main contribution is a method for optimizing the auditor's canary set to improve privacy auditing, leveraging recent work on metagradient optimization. Our empirical evaluation demonstrates that by using such optimized canaries, we can improve empirical lower bounds for differentially private image classification models by over 2x in certain instances. Furthermore, we demonstrate that our method is transferable and efficient: canaries optimized for non-private SGD with a small model architecture remain effective when auditing larger models trained with DP-SGD.",
      "authors": [
        "Matteo Boglioni and Terrance Liu and Andrew Ilyas and Zhiwei Steven Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:47:33+00:00",
          "link": "https://arxiv.org/abs/2507.15836v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Canaries for Privacy Auditing with Metagradient Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15836",
        "HTML": "https://arxiv.org/html/2507.15836",
        "PDF": "https://arxiv.org/pdf/2507.15836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy auditing and improving privacy parameter bounds using optimized canaries for DP-SGD models. It does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09245",
      "abstract": "Stringent demands for timely information delivery, driven by the widespread adoption of real-time applications and the Internet of Things, have established the age of information (AoI) as a critical metric for quantifying data freshness. Existing AoI models often assume multi-hop communication networks with fully reliable nodes, which may not accurately capture scenarios involving node transmission failures. This paper presents an analytical framework for two configurations of tandem queue systems, where status updates generated by a single sensor are relayed to a destination monitor through unreliable intermediate nodes. Using the probability generating function, we first derive the sojourn time distribution for an infinite-buffer M/M/1 tandem system with two unreliable nodes. We then extend our analysis to an M/G/1 tandem system with an arbitrary number of unreliable nodes, employing the supplementary variable technique while assuming that only the first node has an infinite buffer. Numerical results demonstrate the impact of key system parameters on the average AoI in unreliable tandem queues with Markovian and non-Markovian service times.",
      "authors": [
        "Muthukrishnan Senthilkumar",
        "Aresh Dadlani",
        "Hina Tabassum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T21:02:32+00:00",
          "link": "https://arxiv.org/abs/2506.09245v1",
          "size": "1004kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T19:36:30+00:00",
          "link": "https://arxiv.org/abs/2506.09245v2",
          "size": "1050kb",
          "version": "v2"
        }
      ],
      "title": "Age of Information in Unreliable Tandem Queues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09245",
        "HTML": "https://arxiv.org/html/2506.09245",
        "PDF": "https://arxiv.org/pdf/2506.09245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops an analytical framework for measuring the age of information in tandem queue systems. It does not involve LLM training data processing or any relevant data engineering techniques for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14679",
      "abstract": "The exponential growth of spam text on the Internet necessitates robust detection mechanisms to mitigate risks such as information leakage and social instability. This work addresses two principal challenges: adversarial strategies employed by spammers and the scarcity of labeled data. We propose a novel spam-text detection framework GCC-Spam, which integrates three core innovations. First, a character similarity network captures orthographic and phonetic features to counter character-obfuscation attacks and furthermore produces sentence embeddings for downstream classification. Second, contrastive learning enhances discriminability by optimizing the latent-space distance between spam and normal texts. Third, a Generative Adversarial Network (GAN) generates realistic pseudo-spam samples to alleviate data scarcity while improving model robustness and classification accuracy. Extensive experiments on real-world datasets demonstrate that our model outperforms baseline approaches, achieving higher detection rates with significantly fewer labeled examples.",
      "authors": [
        "Zixin Xu",
        "Zhijie Wang",
        "Zhiyuan Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:09:48+00:00",
          "link": "https://arxiv.org/abs/2507.14679v1",
          "size": "1097kb",
          "version": "v1"
        }
      ],
      "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14679",
        "HTML": "https://arxiv.org/html/2507.14679",
        "PDF": "https://arxiv.org/pdf/2507.14679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "GCC-Spam addresses spam detection using GANs, contrastive learning, and similarity networks, focusing on robustness against spam strategies. It does not relate to LLM training data processing or relevant operations within that domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14738",
      "abstract": "Diabetic retinopathy (DR) is a leading cause of preventable blindness, affecting over 100 million people worldwide. In the United States, individuals from lower-income communities face a higher risk of progressing to advanced stages before diagnosis, largely due to limited access to screening. Comorbid conditions further accelerate disease progression. We propose MultiRetNet, a novel pipeline combining retinal imaging, socioeconomic factors, and comorbidity profiles to improve DR staging accuracy, integrated with a clinical deferral system for a clinical human-in-the-loop implementation. We experiment with three multimodal fusion methods and identify fusion through a fully connected layer as the most versatile methodology. We synthesize adversarial, low-quality images and use contrastive learning to train the deferral system, guiding the model to identify out-of-distribution samples that warrant clinician review. By maintaining diagnostic accuracy on suboptimal images and integrating critical health data, our system can improve early detection, particularly in underserved populations where advanced DR is often first identified. This approach may reduce healthcare costs, increase early detection rates, and address disparities in access to care, promoting healthcare equity.",
      "authors": [
        "Jeannie She and Katie Spivakovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:00:31+00:00",
          "link": "https://arxiv.org/abs/2507.14738v1",
          "size": "2173kb",
          "version": "v1"
        }
      ],
      "title": "MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14738",
        "HTML": "https://arxiv.org/html/2507.14738",
        "PDF": "https://arxiv.org/pdf/2507.14738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a system for staging diabetic retinopathy using multimodal data and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14812",
      "abstract": "In a typical online resource allocation problem, we start with a fixed inventory of resources and make online allocation decisions in response to resource requests that arrive sequentially over a finite horizon. We consider settings where the inventory is replenished over time according to an unknown exogenous process. We introduce black-box methods that extend any existing algorithm, originally designed without considering replenishment, into one that works with an arbitrary (adversarial or stochastic) replenishment process. Our approach preserves the original algorithm's competitive ratio in regimes with large initial inventory, thereby enabling the seamless integration of exogenous replenishment into a large body of existing algorithmic results for both adversarial and stochastic arrival models.",
      "authors": [
        "Suho Kang",
        "Ziyang Liu",
        "and Rajan Udwani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:02:18+00:00",
          "link": "https://arxiv.org/abs/2507.14812v1",
          "size": "377kb",
          "version": "v1"
        }
      ],
      "title": "A Black-Box Approach for Exogenous Replenishment in Online Resource Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14812",
        "HTML": "https://arxiv.org/html/2507.14812",
        "PDF": "https://arxiv.org/pdf/2507.14812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces methods for online resource allocation with inventory replenishment, focusing on algorithmic improvements. It is not related to LLM training data processing or data handling in the context of language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14846",
      "abstract": "The rapid evolution of lightweight consumer augmented reality (AR) smart glasses (a.k.a. optical see-through head-mounted displays) offers novel opportunities for learning, particularly through their unique capability to deliver multimodal information in just-in-time, micro-learning scenarios. This research investigates how such devices can support mobile second-language acquisition by presenting progressive sentence structures in multimodal formats. In contrast to the commonly used vocabulary (i.e., word) learning approach for novice learners, we present a \"progressive presentation\" method that combines both word and sentence learning by sequentially displaying sentence components (subject, verb, object) while retaining prior context. Pilot and formal studies revealed that progressive presentation enhances recall, particularly in mobile scenarios such as walking. Additionally, incorporating timed gaps between word presentations further improved learning effectiveness under multitasking conditions. Our findings demonstrate the utility of progressive presentation and provide usage guidelines for educational applications-even during brief, on-the-go learning moments.",
      "authors": [
        "Nuwan Janaka",
        "Shengdong Zhao",
        "Ashwin Ram",
        "Ruoxin Sun",
        "Sherisse Tan Jing Wen",
        "Danae Li",
        "David Hsu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.14846v1",
          "size": "1195kb",
          "version": "v1"
        }
      ],
      "title": "Progressive Sentences: Combining the Benefits of Word and Sentence Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14846",
        "HTML": "https://arxiv.org/html/2507.14846",
        "PDF": "https://arxiv.org/pdf/2507.14846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores language learning through augmented reality devices, focusing on combining word and sentence learning, which is not pertinent to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14894",
      "abstract": "Large Language Models (LLMs) have impressive multilingual capabilities, but they suffer from unexpected code-switching, also known as language mixing, which involves switching to unexpected languages in the model response. This problem leads to poor readability and degrades the usability of model responses. However, existing work on this issue lacks a mechanistic analysis and shows limited effectiveness. In this paper, we first provide an in-depth analysis of unexpected code-switching using sparse autoencoders and find that when LLMs switch to a language, the features of that language exhibit excessive pre-activation values. Based on our findings, we propose $\\textbf{S}$parse $\\textbf{A}$utoencoder-guided $\\textbf{S}$upervised $\\textbf{F}$ine$\\textbf{t}$uning (SASFT), which teaches LLMs to maintain appropriate pre-activation values of specific language features during training. Experiments on five models across three languages demonstrate that SASFT consistently reduces unexpected code-switching by more than 50\\% compared to standard supervised fine-tuning, with complete elimination in four cases. Moreover, SASFT maintains or even improves the models' performance on six multilingual benchmarks, showing its effectiveness in addressing code-switching while preserving multilingual capabilities.",
      "authors": [
        "Boyi Deng",
        "Yu Wan",
        "Baosong Yang",
        "Fei Huang",
        "Wenjie Wang",
        "Fuli Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:20:01+00:00",
          "link": "https://arxiv.org/abs/2507.14894v1",
          "size": "253kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14894",
        "HTML": "https://arxiv.org/html/2507.14894",
        "PDF": "https://arxiv.org/pdf/2507.14894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a supervised finetuning approach to mitigate unexpected code-switching in LLMs, involving data processing techniques to maintain language feature pre-activation values. However, its main focus is on model behavior modification rather than on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14958",
      "abstract": "Large Language Models (LLMs) have achieved impressive performance on reasoning-intensive tasks, yet optimizing their reasoning efficiency remains an open challenge. While Test-Time Scaling (TTS) improves reasoning quality, it often leads to overthinking, wasting tokens on redundant computations. This work investigates how to efficiently and adaptively guide LLM test-time scaling without additional training. Inspired by the concept of momentum in physics, we propose Momentum Uncertainty-guided Reasoning (MUR), which dynamically allocates thinking budgets to critical reasoning steps by tracking and aggregating stepwise uncertainty over time. To support flexible inference-time control, we introduce gamma-control, a simple mechanism that tunes the reasoning budget via a single hyperparameter. We provide in-depth theoretical proof to support the superiority of MUR in terms of stability and biases. MUR is comprehensively evaluated against various TTS methods across four challenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using different sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate that MUR reduces computation by over 50% on average while improving accuracy by 0.62-3.37%.",
      "authors": [
        "Hang Yan",
        "Fangzhi Xu",
        "Rongman Xu",
        "Yifei Li",
        "Jian Zhang",
        "Haoran Luo",
        "Xiaobao Wu",
        "Luu Anh Tuan",
        "Haiteng Zhao",
        "Qika Lin",
        "Jun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:36:19+00:00",
          "link": "https://arxiv.org/abs/2507.14958v1",
          "size": "746kb",
          "version": "v1"
        }
      ],
      "title": "MUR: Momentum Uncertainty guided Reasoning for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14958",
        "HTML": "https://arxiv.org/html/2507.14958",
        "PDF": "https://arxiv.org/pdf/2507.14958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for optimizing test-time reasoning in LLMs using Momentum Uncertainty-guided Reasoning (MUR). It does not discuss training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14967",
      "abstract": "Manipulation surfaces indirectly control and reposition objects by actively modifying their shape or properties rather than directly gripping objects. These surfaces, equipped with dense actuator arrays, generate dynamic deformations. However, a high-density actuator array introduces considerable complexity due to increased degrees of freedom (DOF), complicating control tasks. High DOF restrict the implementation and utilization of manipulation surfaces in real-world applications as the maintenance and control of such systems exponentially increase with array/surface size. Learning-based control approaches may ease the control complexity, but they require extensive training samples and struggle to generalize for heterogeneous objects. In this study, we introduce a simple, precise and robust PID-based linear close-loop feedback control strategy for heterogeneous object manipulation on MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation density). Our approach employs a geometric transformation-driven PID controller, directly mapping tilt angle control outputs(1D/2D) to actuator commands to eliminate the need for extensive black-box training. We validate the proposed method through simulations and experiments on a physical system, successfully manipulating objects with diverse geometries, weights and textures, including fragile objects like eggs and apples. The outcomes demonstrate that our approach is highly generalized and offers a practical and reliable solution for object manipulation on soft robotic manipulation, facilitating real-world implementation without prohibitive training demands.",
      "authors": [
        "Pratik Ingle",
        "Kasper St{\\o}y",
        "Andres Fai\\~na"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:53:35+00:00",
          "link": "https://arxiv.org/abs/2507.14967v1",
          "size": "16621kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous object manipulation on nonlinear soft surface through linear controller",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14967",
        "HTML": "https://arxiv.org/html/2507.14967",
        "PDF": "https://arxiv.org/pdf/2507.14967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study addresses object manipulation on a soft surface using a geometric transformation-driven PID controller. It does not relate to LLM training or data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15577",
      "abstract": "Mixup has become a popular augmentation strategy for image classification, yet its naive pixel-wise interpolation often produces unrealistic images that can hinder learning, particularly in high-stakes medical applications. We propose GeMix, a two-stage framework that replaces heuristic blending with a learned, label-aware interpolation powered by class-conditional GANs. First, a StyleGAN2-ADA generator is trained on the target dataset. During augmentation, we sample two label vectors from Dirichlet priors biased toward different classes and blend them via a Beta-distributed coefficient. Then, we condition the generator on this soft label to synthesize visually coherent images that lie along a continuous class manifold. We benchmark GeMix on the large-scale COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101, EfficientNet-B0). When combined with real data, our method increases macro-F1 over traditional mixup for all backbones, reducing the false negative rate for COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup, delivering stronger regularization and greater semantic fidelity, without disrupting existing training pipelines. We publicly release our code at https://github.com/hugocarlesso/GeMix to foster reproducibility and further research.",
      "authors": [
        "Hugo Carlesso",
        "Maria Eliza Patulea",
        "Moncef Garouani",
        "Radu Tudor Ionescu",
        "Josiane Mothe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:58:05+00:00",
          "link": "https://arxiv.org/abs/2507.15577v1",
          "size": "1481kb",
          "version": "v1"
        }
      ],
      "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15577",
        "HTML": "https://arxiv.org/html/2507.15577",
        "PDF": "https://arxiv.org/pdf/2507.15577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on GeMix, a GAN-based image augmentation technique for medical image datasets. It does not make contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00709",
      "abstract": "Lane segment topology reasoning constructs a comprehensive road network by capturing the topological relationships between lane segments and their semantic types. This enables end-to-end autonomous driving systems to perform road-dependent maneuvers such as turning and lane changing. However, the limitations in consistent positional embedding and temporal multiple attribute learning in existing methods hinder accurate roadnet reconstruction. To address these issues, we propose TopoStreamer, an end-to-end temporal perception model for lane segment topology reasoning. Specifically, TopoStreamer introduces three key improvements: streaming attribute constraints, dynamic lane boundary positional encoding, and lane segment denoising. The streaming attribute constraints enforce temporal consistency in both centerline and boundary coordinates, along with their classifications. Meanwhile, dynamic lane boundary positional encoding enhances the learning of up-to-date positional information within queries, while lane segment denoising helps capture diverse lane segment patterns, ultimately improving model performance. Additionally, we assess the accuracy of existing models using a lane boundary classification metric, which serves as a crucial measure for lane-changing scenarios in autonomous driving. On the OpenLane-V2 dataset, TopoStreamer demonstrates significant improvements over state-of-the-art methods, achieving substantial performance gains of +3.0% mAP in lane segment perception and +1.7% OLS in centerline perception tasks.",
      "authors": [
        "Yiming Yang",
        "Yueru Luo",
        "Bingkun He",
        "Hongbin Lin",
        "Suzhong Fu",
        "Chao Zheng",
        "Zhipeng Cao",
        "Erlong Li",
        "Chao Yan",
        "Shuguang Cui",
        "Zhen Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T12:10:46+00:00",
          "link": "https://arxiv.org/abs/2507.00709v1",
          "size": "4888kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T08:35:35+00:00",
          "link": "https://arxiv.org/abs/2507.00709v2",
          "size": "4889kb",
          "version": "v2"
        }
      ],
      "title": "TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00709",
        "HTML": "https://arxiv.org/html/2507.00709",
        "PDF": "https://arxiv.org/pdf/2507.00709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "TopoStreamer is focused on lane segment topology reasoning for autonomous driving, emphasizing temporal perception models and lane-segment processing, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14151",
      "abstract": "Foundation Models (FMs) are large-scale machine learning models trained on extensive, diverse datasets that can be adapted to a wide range of downstream tasks with minimal fine-tuning. In the last two years, interest in FMs has also grown for applications in the cardiological field to analyze the electrocardiogram (ECG) signals. One of the key properties of FMs is their transferability to a wide range of downstream scenarios. With the spread of wearable and portable devices, keen interest in learning from reduced-channel configurations has arisen. However, the adaptation of ECG FMs to downstream scenarios with fewer available channels still has to be properly investigated. In this work, we propose Self-DANA, a novel, easy-to-integrate solution that makes self-supervised architectures adaptable to a reduced number of input channels, ensuring resource efficiency and high performance. We also introduce Random Lead Selection, a novel augmentation technique to pre-train models in a more robust and channel-agnostic way. Our experimental results on five reduced-channel configurations demonstrate that Self-DANA significantly enhances resource efficiency while reaching state-of-the-art performance. It requires up to 69.3% less peak CPU memory, 34.4% less peak GPU memory, about 17% less average epoch CPU time, and about 24% less average epoch GPU time.",
      "authors": [
        "Giuliana Monachino",
        "Nicol\\`o La Porta",
        "Beatrice Zanchi",
        "Luigi Fiorillo",
        "Alvise Dei Rossi",
        "Georgiy Farina",
        "Francesca Dalia Faraci"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T20:39:30+00:00",
          "link": "https://arxiv.org/abs/2507.14151v1",
          "size": "614kb",
          "version": "v1"
        }
      ],
      "title": "Self-DANA: A Resource-Efficient Channel-Adaptive Self-Supervised Approach for ECG Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14151",
        "HTML": "https://arxiv.org/html/2507.14151",
        "PDF": "https://arxiv.org/pdf/2507.14151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on ECG foundation models, specifically a self-supervised approach that adapts to reduced-channel configurations. It does not address any aspects of LLM training data processing, such as dataset collection or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14230",
      "abstract": "Advanced intelligent automation becomes an important feature to deal with the increased complexity in managing wireless networks. This paper proposes a novel automation approach of intent-based network for Radio Access Networks (RANs) management by leveraging Large Language Models (LLMs). The proposed method enhances intent translation, autonomously interpreting high-level objectives, reasoning over complex network states, and generating precise configurations of the RAN by integrating LLMs within an agentic architecture. We propose a structured prompt engineering technique and demonstrate that the network can automatically improve its energy efficiency by dynamically optimizing critical RAN parameters through a closed-loop mechanism. It showcases the potential to enable robust resource management in RAN by adapting strategies based on real-time feedback via LLM-orchestrated agentic systems.",
      "authors": [
        "Fransiscus Asisi Bimo",
        "Maria Amparo Canaveras Galdon",
        "Chun-Kai Lai",
        "Ray-Guang Cheng and Edwin K. P. Chong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:57:55+00:00",
          "link": "https://arxiv.org/abs/2507.14230v1",
          "size": "249kb",
          "version": "v1"
        }
      ],
      "title": "Intent-Based Network for RAN Management with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14230",
        "HTML": "https://arxiv.org/html/2507.14230",
        "PDF": "https://arxiv.org/pdf/2507.14230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for managing Radio Access Networks (RANs) via intent-based networks and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14798",
      "abstract": "State-of-the-art 3D computer vision algorithms continue to advance in handling sparse, unordered image sets. Recently developed foundational models for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction (DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry Grounded Transformer (VGGT), have attracted attention due to their ability to handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical aerial images matters, as these models may handle extremely low image overlaps, stereo occlusions, and textureless regions. For redundant collections, they can accelerate 3D reconstruction by using extremely sparsified image sets. Despite tests on various computer vision benchmarks, their potential on photogrammetric aerial blocks remains unexplored. This paper conducts a comprehensive evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of the UseGeo dataset for pose estimation and dense 3D reconstruction. Results show these methods can accurately reconstruct dense point clouds from very sparse image sets (fewer than 10 images, up to 518 pixels resolution), with completeness gains up to +50% over COLMAP. VGGT also demonstrates higher computational efficiency, scalability, and more reliable camera pose estimation. However, all exhibit limitations with high-resolution images and large sets, as pose reliability declines with more images and geometric complexity. These findings suggest transformer-based methods cannot fully replace traditional SfM and MVS, but offer promise as complementary approaches, especially in challenging, low-resolution, and sparse scenarios.",
      "authors": [
        "Xinyi Wu",
        "Steven Landgraf",
        "Markus Ulrich",
        "Rongjun Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.14798v1",
          "size": "2316kb",
          "version": "v1"
        }
      ],
      "title": "An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14798",
        "PDF": "https://arxiv.org/pdf/2507.14798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates models for 3D reconstruction on photogrammetric aerial images. This does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15364",
      "abstract": "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure onsets can significantly impact patients' quality of life and health. However, wearable seizure-predicting devices are still limited, partly due to the bulky size of EEG-collecting devices. To relieve the problem, we proposed a novel two-stage channel-aware Set Transformer Network that could perform seizure prediction with fewer EEG channel sensors. We also tested a seizure-independent division method which could prevent the adjacency of training and test data. Experiments were performed on the CHB-MIT dataset which includes 22 patients with 88 merged seizures. The mean sensitivity before channel selection was 76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection, dominant channels emerged in 20 out of 22 patients; the average number of channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1% with an FPR of 0.11/hour. Furthermore, experimental results on the seizure-independent division supported our assertion that a more rigorous seizure-independent division should be used for patients with abundant EEG recordings.",
      "authors": [
        "Ruifeng Zheng",
        "Cong Chen",
        "Shuang Wang",
        "Yiming Liu",
        "Lin You",
        "Jindong Lu",
        "Ruizhe Zhu",
        "Guodao Zhang",
        "Kejie Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:16:19+00:00",
          "link": "https://arxiv.org/abs/2507.15364v1",
          "size": "1306kb",
          "version": "v1"
        }
      ],
      "title": "EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15364",
        "HTML": "https://arxiv.org/html/2507.15364",
        "PDF": "https://arxiv.org/pdf/2507.15364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper relates to EEG-based epileptic prediction and not to LLM training data processing, focusing instead on a novel method for seizure prediction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15758",
      "abstract": "Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\% while improving accuracy by 2.3\\%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.",
      "authors": [
        "Xingyu Wu",
        "Yuchen Yan",
        "Shangke Lyu",
        "Linjuan Wu",
        "Yiwen Qiu",
        "Yongliang Shen",
        "Weiming Lu",
        "Jian Shao",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:14:41+00:00",
          "link": "https://arxiv.org/abs/2507.15758v1",
          "size": "2189kb",
          "version": "v1"
        }
      ],
      "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15758",
        "HTML": "https://arxiv.org/html/2507.15758",
        "PDF": "https://arxiv.org/pdf/2507.15758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on length-adaptive reasoning in models through reinforcement learning, which is concerned with model reasoning efficiency rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15848",
      "abstract": "We develop time integration methods in low-rank representation that can adaptively adjust approximation ranks to achieve a prescribed accuracy, while ensuring that these ranks remain proportional to the corresponding best approximation ranks. Our approach relies on an iterative scheme combined with soft thresholding of the iterates. A model case of a time-dependent Schr\\\"odinger equation with low-rank matrix approximation is analyzed in detail, and the required modifications for second-order parabolic problems are described. Numerical tests illustrate the results for both cases.",
      "authors": [
        "Markus Bachmayr",
        "Matthieu Dolbeault and Polina Sachsenmaier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:55:23+00:00",
          "link": "https://arxiv.org/abs/2507.15848v1",
          "size": "228kb",
          "version": "v1"
        }
      ],
      "title": "Iterative thresholding low-rank time integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15848",
        "HTML": "https://arxiv.org/html/2507.15848",
        "PDF": "https://arxiv.org/pdf/2507.15848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses time integration methods in low-rank representation, with applications to specific mathematical problems. It does not connect to LLM training data processing or involve any contributions to enhancing data quality or creating datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.06831",
      "abstract": "We study the generalized linear contextual bandit problem within the constraints of limited adaptivity. In this paper, we present two algorithms, $\\texttt{B-GLinCB}$ and $\\texttt{RS-GLinCB}$, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its course. For the first setting, we design an algorithm $\\texttt{B-GLinCB}$, that incurs $\\tilde{O}(\\sqrt{T})$ regret when $M = \\Omega( \\log{\\log T} )$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorithm $\\texttt{RS-GLinCB}$ that updates its policy $\\tilde{O}(\\log^2 T)$ times and achieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\\kappa$, that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest.",
      "authors": [
        "Ayush Sawarni",
        "Nirjhar Das",
        "Siddharth Barman",
        "Gaurav Sinha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T08:47:57+00:00",
          "link": "https://arxiv.org/abs/2404.06831v1",
          "size": "509kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T13:38:13+00:00",
          "link": "https://arxiv.org/abs/2404.06831v2",
          "size": "509kb",
          "version": "v2"
        },
        {
          "date": "2024-06-14T08:11:11+00:00",
          "link": "https://arxiv.org/abs/2404.06831v3",
          "size": "927kb",
          "version": "v3"
        },
        {
          "date": "2025-02-25T15:24:55+00:00",
          "link": "https://arxiv.org/abs/2404.06831v4",
          "size": "913kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T06:42:01+00:00",
          "link": "https://arxiv.org/abs/2404.06831v5",
          "size": "913kb",
          "version": "v5"
        }
      ],
      "title": "Generalized Linear Bandits with Limited Adaptivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.06831",
        "PDF": "https://arxiv.org/pdf/2404.06831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for generalized linear bandit problems under limited adaptivity, with no discussion on training data processing for LLMs."
      },
      "tasks": [
        "Multi-Armed Bandits"
      ],
      "repo_urls": [
        "https://github.com/nirjhar-das/glbandit_limited_adaptivity",
        "https://github.com/nick-jhlee/logistic_bandit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17262",
      "abstract": "We present CROSS-GAiT, a novel algorithm for quadruped robots that uses Cross Attention to fuse terrain representations derived from visual and time-series inputs; including linear accelerations, angular velocities, and joint efforts. These fused representations are used to continuously adjust two critical gait parameters (step height and hip splay), enabling adaptive gaits that respond dynamically to varying terrain conditions. To generate terrain representations, we process visual inputs through a masked Vision Transformer (ViT) encoder and time-series data through a dilated causal convolutional encoder. The Cross Attention mechanism then selects and integrates the most relevant features from each modality, combining terrain characteristics with robot dynamics for informed gait adaptation. This fused representation allows CROSS-GAiT to continuously adjust gait parameters in response to unpredictable terrain conditions in real-time. We train CROSS-GAiT on a diverse set of terrains including asphalt, concrete, brick pavements, grass, dense vegetation, pebbles, gravel, and sand and validate its generalization ability on unseen environments. Our hardware implementation on the Ghost Robotics Vision 60 demonstrates superior performance in challenging terrains, such as high-density vegetation, unstable surfaces, sandbanks, and deformable substrates. We observe at least a 7.04% reduction in IMU energy density and a 27.3% reduction in total joint effort, which directly correlates with increased stability and reduced energy usage when compared to state-of-the-art methods. Furthermore, CROSS-GAiT demonstrates at least a 64.5% increase in success rate and a 4.91% reduction in time to reach the goal in four complex scenarios. Additionally, the learned representations perform 4.48% better than the state-of-the-art on a terrain classification task.",
      "authors": [
        "Gershom Seneviratne",
        "Kasun Weerakoon",
        "Mohamed Elnoor",
        "Vignesh Rajgopal",
        "Harshavarthan Varatharajan",
        "Mohamed Khalid M Jaffar",
        "Jason Pusey",
        "Dinesh Manocha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-25T18:20:05+00:00",
          "link": "https://arxiv.org/abs/2409.17262v1",
          "size": "14629kb",
          "version": "v1"
        },
        {
          "date": "2024-09-30T19:02:16+00:00",
          "link": "https://arxiv.org/abs/2409.17262v2",
          "size": "14816kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T22:44:23+00:00",
          "link": "https://arxiv.org/abs/2409.17262v3",
          "size": "3079kb",
          "version": "v3"
        }
      ],
      "title": "CROSS-GAiT: Cross-Attention-Based Multimodal Representation Fusion for Parametric Gait Adaptation in Complex Terrains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17262",
        "HTML": "https://arxiv.org/html/2409.17262",
        "PDF": "https://arxiv.org/pdf/2409.17262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gait adaptation algorithms for quadruped robots using cross-attention mechanisms, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08263",
      "abstract": "Tangled code changes, commits that conflate unrelated modifications such as bug fixes, refactorings, and enhancements, introduce significant noise into bug datasets and adversely affect the performance of bug prediction models. Addressing this issue at a fine-grained, method-level granularity remains underexplored. This is critical to address, as recent bug prediction models, driven by practitioner demand, are increasingly focusing on finer granularity rather than traditional class- or file-level predictions. This study investigates the utility of Large Language Models (LLMs) for detecting tangled code changes by leveraging both commit messages and method-level code diffs. We formulate the problem as a binary classification task and evaluate multiple prompting strategies, including zero-shot, few-shot, and chain-of-thought prompting, using state-of-the-art proprietary LLMs such as GPT-4o and Gemini-2.0-Flash. Our results demonstrate that combining commit messages with code diffs significantly enhances model performance, with the combined few-shot and chain-of-thought prompting achieving an F1-score of 0.88. Additionally, we explore machine learning models trained on LLM-generated embeddings, where a multi-layer perceptron classifier achieves superior performance (F1-score: 0.906, MCC: 0.807). Applying our approach to 49 open-source projects improves the distributional separability of code metrics between buggy and non-buggy methods, demonstrating the promise of LLMs for method-level commit untangling and potentially contributing to improving the accuracy of future bug prediction models.",
      "authors": [
        "Md Nahidul Islam Opu",
        "Shaowei Wang",
        "Shaiful Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T06:26:13+00:00",
          "link": "https://arxiv.org/abs/2505.08263v1",
          "size": "1767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:36:19+00:00",
          "link": "https://arxiv.org/abs/2505.08263v2",
          "size": "2033kb",
          "version": "v2"
        }
      ],
      "title": "LLM-Based Detection of Tangled Code Changes for Higher-Quality Method-Level Bug Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08263",
        "HTML": "https://arxiv.org/html/2505.08263",
        "PDF": "https://arxiv.org/pdf/2505.08263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs to detect tangled code changes, which could indirectly improve dataset quality for training models, but does not focus on training data processing operations for LLMs themselves."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14240",
      "abstract": "Large language models (LLMs) leverage deep learning to process and predict sequences of words from context, enabling them to perform various NLP tasks, such as translation, summarization, question answering, and content generation. However, the growing size and complexity of developing, training, and deploying advanced LLMs require extensive computational resources and large datasets. This creates a barrier for users. As a result, platforms that host models and datasets are widely used. For example, Hugging Face, one of the most popular platforms, hosted 1.8 million models and 450K datasets by June 2025, with no sign of slowing down. Since many LLMs are built from base models, pre-trained models, and external datasets, they can inherit vulnerabilities, biases, or malicious components from earlier models or datasets. Therefore, it is critical to understand the origin and development of these components to better detect potential risks, improve model fairness, and ensure compliance. Motivated by this, our project aims to study the relationships between models and datasets, which are core components of the LLM supply chain. First, we design a method to systematically collect LLM supply chain data. Using this data, we build a directed heterogeneous graph to model the relationships between models and datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We then perform various analyses and uncover several findings, such as: (i) the LLM supply chain graph is large, sparse, and follows a power-law degree distribution; (ii) it features a densely connected core and a fragmented periphery; (iii) datasets play pivotal roles in training; (iv) strong interdependence exists between models and datasets; and (v) the graph is dynamic, with daily updates reflecting the ecosystem's ongoing evolution.",
      "authors": [
        "Mohammad Shahedur Rahman",
        "Peng Gao",
        "Yuede Ji"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:34:13+00:00",
          "link": "https://arxiv.org/abs/2507.14240v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14240",
        "HTML": "https://arxiv.org/html/2507.14240",
        "PDF": "https://arxiv.org/pdf/2507.14240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper analyzes the supply chain of LLMs by building a graph to understand model and dataset relationships, highlighting the importance of datasets in training. However, it doesn't introduce new data processing techniques or datasets, elaborating more on the structural analysis of existing models and data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14897",
      "abstract": "Language model (LM) agents have gained significant attention for their ability to autonomously complete tasks through interactions with environments, tools, and APIs. LM agents are primarily built with prompt engineering or supervised finetuning. At the same time, reinforcement learning (RL) has been explored to enhance LM's capabilities, such as reasoning and factuality. However, the combination of the LM agents and reinforcement learning (Agent-RL) remains underexplored and lacks systematic study. To this end, we built AgentFly, a scalable and extensible Agent-RL framework designed to empower LM agents with a variety of RL algorithms. Our framework supports multi-turn interactions by adapting traditional RL methods with token-level masking. It features a decorator-based interface for defining tools and reward functions, enabling seamless extension and ease of use. To support high-throughput training, we implement asynchronous execution of tool calls and reward computations, and design a centralized resource management system for scalable environment coordination. We also provide a suite of prebuilt tools and environments, demonstrating the framework's effectiveness through successful agent training across multiple tasks.",
      "authors": [
        "Renxi Wang",
        "Rifo Ahmad Genadi",
        "Bilal El Bouardi",
        "Yongxin Wang",
        "Fajri Koto",
        "Zhengzhong Liu",
        "Timothy Baldwin",
        "Haonan Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:22:36+00:00",
          "link": "https://arxiv.org/abs/2507.14897v1",
          "size": "947kb",
          "version": "v1"
        }
      ],
      "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14897",
        "HTML": "https://arxiv.org/html/2507.14897",
        "PDF": "https://arxiv.org/pdf/2507.14897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "AgentFly is about integrating reinforcement learning into LM agents, focusing on multi-turn interactions and tool integration. It doesn't involve the creation or processing of training datasets, thus not contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15433",
      "abstract": "Wall-Sized Displays have spatial characteristics that are difficult to address during user interface design. The design at scale 1:1 could be part of the solution. In this paper, we present the results of two user studies and one technology review, exploring the usability of popular, desktop-optimized prototyping tools, for designing at scale on Wall-Sized Displays. We considered two wall-sized display setups, and three different interaction methods: touch, a keyboard equipped with a touchpad, and a tablet. We observed that designing at scale 1:1 was appreciated. Tablet-based interaction proved to be the most comfortable interaction method, and a mix of interaction modalities is promising. In addition, care must be given to the surrounding environment, such as furniture. We propose twelve design guidelines for a design tool dedicated to this specific context. Overall, existing user interface design tools do not yet fully support design on and for wall-sized displays and require further considerations in terms of placement of user interface elements and the provision of additional features.",
      "authors": [
        "Lou Schwartz",
        "Mohammad Ghoniem",
        "Val\\'erie Maquil",
        "Adrien Coppens",
        "Johannes Hermen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.15433v1",
          "size": "32752kb",
          "version": "v1"
        }
      ],
      "title": "Designing at 1:1 Scale on Wall-Sized Displays Using Existing UI Design Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15433",
        "HTML": "https://arxiv.org/html/2507.15433",
        "PDF": "https://arxiv.org/pdf/2507.15433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores designing user interfaces on wall-sized displays using existing tools, which is not connected to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03441",
      "abstract": "As chatbots become integral to daily life, personalizing systems is key for fostering trust, engagement, and inclusivity. This study examines how linguistic similarity affects chatbot performance, focusing on integrating African American English (AAE) into virtual agents to better serve the African American community. We develop text-based and spoken chatbots using large language models and text-to-speech technology, then evaluate them with AAE speakers against standard English chatbots. Our results show that while text-based AAE chatbots often underperform, spoken chatbots benefit from an African American voice and AAE elements, improving performance and preference. These findings underscore the complexities of linguistic personalization and the dynamics between text and speech modalities, highlighting technological limitations that affect chatbots' AA speech generation and pointing to promising future research directions.",
      "authors": [
        "Sarah E. Finch",
        "Ellie S. Paek",
        "Ikseon Choi",
        "Jinho D. Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T00:07:01+00:00",
          "link": "https://arxiv.org/abs/2501.03441v1",
          "size": "810kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T18:57:52+00:00",
          "link": "https://arxiv.org/abs/2501.03441v2",
          "size": "1228kb",
          "version": "v2"
        }
      ],
      "title": "Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03441",
        "HTML": "https://arxiv.org/html/2501.03441",
        "PDF": "https://arxiv.org/pdf/2501.03441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While primarily about chatbot performance using African American English, the paper does involve creating specialized datasets and text-to-speech models, which partially touches on data processing for LLMs."
      },
      "tasks": [
        "Chatbot",
        "Diversity"
      ],
      "repo_urls": [
        "https://github.com/emorynlp/aave-chat"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15867",
      "abstract": "Detecting DeepFakes has become a crucial research area as the widespread use of AI image generators enables the effortless creation of face-manipulated and fully synthetic content, yet existing methods are often limited to binary classification (real vs. fake) and lack interpretability. To address these challenges, we propose TruthLens, a novel and highly generalizable framework for DeepFake detection that not only determines whether an image is real or fake but also provides detailed textual reasoning for its predictions. Unlike traditional methods, TruthLens effectively handles both face-manipulated DeepFakes and fully AI-generated content while addressing fine-grained queries such as \"Does the eyes/nose/mouth look real or fake?\"\n  The architecture of TruthLens combines the global contextual understanding of multimodal large language models like PaliGemma2 with the localized feature extraction capabilities of vision-only models like DINOv2. This hybrid design leverages the complementary strengths of both models, enabling robust detection of subtle manipulations while maintaining interpretability. Extensive experiments on diverse datasets demonstrate that TruthLens outperforms state-of-the-art methods in detection accuracy (by 2-14%) and explainability, in both in-domain and cross-data settings, generalizing effectively across traditional and emerging manipulation techniques.",
      "authors": [
        "Rohit Kundu",
        "Shan Jia",
        "Vishal Mohanty",
        "Athula Balachandran",
        "Amit K. Roy-Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T05:40:42+00:00",
          "link": "https://arxiv.org/abs/2503.15867v1",
          "size": "8758kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T05:46:35+00:00",
          "link": "https://arxiv.org/abs/2503.15867v2",
          "size": "8752kb",
          "version": "v2"
        }
      ],
      "title": "TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15867",
        "HTML": "https://arxiv.org/html/2503.15867",
        "PDF": "https://arxiv.org/pdf/2503.15867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes TruthLens, a framework for DeepFake detection focusing on interpretability and detection accuracy. It involves combining features from different models but does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "DeepFake Detection",
        "Face Swapping"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14397",
      "abstract": "This paper presents a limit study of transformer-based large language model (LLM) inference, focusing on the fundamental performance bottlenecks imposed by memory bandwidth, memory capacity, and synchronization overhead in distributed inference systems. We develop a hardware-agnostic performance model that abstracts away implementation details, enabling the analysis of a wide range of current and near-future hardware technologies. Our analysis spans from current HBM3 memory technology used in AI accelerators like GPUs and TPUs to systems based on advanced HBM4 and advanced 3D-stacked DRAM technology. It also covers SRAM-based designs and scaling techniques from distributed clusters with varying numbers of chips to wafer-scale integration. Our key findings for auto-regressive decoding are: i) serving LLMs requires 100s of GB per server to serve a model instance; ii) high memory bandwidth is critical for high per-user throughput; iii) exposed synchronization latencies to achieve collective communication must be around 1us else they make the memory bandwidth ineffective; iv) DRAM-based designs have a fundamental advantage in terms of system-level efficiency as measured in throughput per cost or watt; and v) hardware designs can easily reach 2000+ user token/sec but getting to 10,000+ tokens/sec will need smaller models, smaller context, or other forms of algorithmic advances. This study provides valuable insights into the fundamental performance limits of LLM inference, highlighting the potential benefits of future hardware advancements and guiding the optimization of LLM deployment strategies.",
      "authors": [
        "Michael Davies",
        "Neal Crago",
        "Karthikeyan Sankaralingam",
        "Christos Kozyrakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:58:55+00:00",
          "link": "https://arxiv.org/abs/2507.14397v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "Efficient LLM Inference: Bandwidth, Compute, Synchronization, and Capacity are all you need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14397",
        "HTML": "https://arxiv.org/html/2507.14397",
        "PDF": "https://arxiv.org/pdf/2507.14397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies transformer-based LLM inference and performance bottlenecks related to hardware and memory. It neither mentions training data processing operations nor contributes to data quality improvement techniques for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15137",
      "abstract": "In this paper, a theoretical framework is presented\n  for the use of a Kansa-like method to numerically solve elliptic\n  partial differential equations on spheres and other manifolds. The\n  theory addresses both the stability of the method and provides error\n  estimates for two different approximation methods. A Kansa-like\n  matrix is obtained by replacing the test point set $X$, used in the\n  traditional Kansa method, by a larger set $Y$, which is a norming\n  set for the underlying trial space. This gives rise to a rectangular\n  matrix. In addition, if a basis of Lagrange (or local Lagrange)\n  functions is used for the trial space, then it is shown\n  that the stability of the matrix is comparable to the stability of\n  the elliptic operator acting on the trial space. Finally, two\n  different types of error estimates are given. Discrete least squares\n  estimates of very high accuracy are obtained for solutions that are\n  sufficiently smooth. The second method, giving similar error\n  estimates, uses a rank revealing factorization to create a\n  ``thinning algorithm'' that reduces $\\#Y$ to $\\#X$. In practice,\n  this algorithm doesn't need $Y$ to be a norming set.",
      "authors": [
        "Thomas Hangelbroek",
        "Francis J. Narcowich",
        "Joseph D. Ward"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:20:16+00:00",
          "link": "https://arxiv.org/abs/2507.15137v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Extending Data to Improve Stability and Error Estimates Using Asymmetric Kansa-like Methods to Solve PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15137",
        "HTML": "https://arxiv.org/html/2507.15137",
        "PDF": "https://arxiv.org/pdf/2507.15137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on extending data for solving partial differential equations using Kansa-like methods, which does not relate to LLM training data processing or improvements in data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15277",
      "abstract": "Hand-optimizing linear algebra kernels for different GPU devices and applications is complex and labor-intensive. Instead, many developers use automatic performance tuning (autotuning) to achieve high performance on a variety of devices. However, autotuning \"overfits\", and must be redone if any part of the environment changes, such as if the device or input characteristics change.\n  In most non-trivial cases, a single compute kernel cannot maintain near-optimal performance across all environments. Changing the kernel to specialize it to the current execution environment is possible, but on GPUs, runtime tuning and compilation can be expensive.\n  In this work, we use multi-versioning -- producing several variants of the same code -- as a way to generate performance portable code. We describe a framework called portability tuning that can automatically generate multi-versioned code whose performance is portable, requiring no retuning.\n  We evaluate our framework on a dataset of execution times for GEMM kernels from the CLBlast linear algebra library. We find our portability tuning techniques outperform CLBlast's default kernels -- often approaching within 10% of the theoretical maximum performance -- despite CLBlast using autotuning techniques. Further, we find that our generated programs generalize well to new and unseen devices, matching the performance of autotuning without ever portability tuning for those devices.",
      "authors": [
        "Robert Hochgraf (1)",
        "Sreepathi Pai (2) ((1) Rochester Institute of Technology",
        "(2) University of Rochester)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:29:28+00:00",
          "link": "https://arxiv.org/abs/2507.15277v1",
          "size": "733kb",
          "version": "v1"
        }
      ],
      "title": "A Few Fit Most: Improving Performance Portability of SGEMM on GPUs using Multi-Versioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15277",
        "PDF": "https://arxiv.org/pdf/2507.15277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on improving performance portability for SGEMM on GPUs through multi-versioning, with no connection to LLM training data processing operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15296",
      "abstract": "The emergence of the tool agent paradigm has broadened the capability boundaries of the Large Language Model (LLM), enabling it to complete more complex tasks. However, the effectiveness of this paradigm is limited due to the issue of parameter failure during its execution. To explore this phenomenon and propose corresponding suggestions, we first construct a parameter failure taxonomy in this paper. We derive five failure categories from the invocation chain of a mainstream tool agent. Then, we explore the correlation between three different input sources and failure categories by applying 15 input perturbation methods to the input. Experimental results show that parameter name hallucination failure primarily stems from inherent LLM limitations, while issues with input sources mainly cause other failure patterns. To improve the reliability and effectiveness of tool-agent interactions, we propose corresponding improvement suggestions, including standardizing tool return formats, improving error feedback mechanisms, and ensuring parameter consistency.",
      "authors": [
        "Qian Xiong and Yuekai Huang and Ziyou Jiang and Zhiyuan Chang and Yujia Zheng and Tianhao Li and Mingyang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.15296v1",
          "size": "570kb",
          "version": "v1"
        }
      ],
      "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15296",
        "PDF": "https://arxiv.org/pdf/2507.15296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates parameter filling failures in LLM tool-agent systems, which does not relate to LLM training data processing activities like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15600",
      "abstract": "Narratives are key interpretative devices by which humans make sense of political reality. In this work, we show how the analysis of conflicting narratives, i.e. conflicting interpretive lenses through which political reality is experienced and told, provides insight into the discursive mechanisms of polarization and issue alignment in the public sphere. Building upon previous work that has identified ideologically polarized issues in the German Twittersphere between 2021 and 2023, we analyze the discursive dimension of polarization by extracting textual signals of conflicting narratives from tweets of opposing opinion groups. Focusing on a selection of salient issues and events (the war in Ukraine, Covid, climate change), we show evidence for conflicting narratives along two dimensions: (i) different attributions of actantial roles to the same set of actants (e.g. diverging interpretations of the role of NATO in the war in Ukraine), and (ii) emplotment of different actants for the same event (e.g. Bill Gates in the right-leaning Covid narrative). Furthermore, we provide first evidence for patterns of narrative alignment, a discursive strategy that political actors employ to align opinions across issues. These findings demonstrate the use of narratives as an analytical lens into the discursive mechanisms of polarization.",
      "authors": [
        "Armin Pournaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:22:57+00:00",
          "link": "https://arxiv.org/abs/2507.15600v1",
          "size": "365kb",
          "version": "v1"
        }
      ],
      "title": "Conflicting narratives and polarization on social media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15600",
        "HTML": "https://arxiv.org/html/2507.15600",
        "PDF": "https://arxiv.org/pdf/2507.15600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with social media polarization and narrative analysis, not LLM training data processing. There's no mention of pretraining or fine-tuning datasets or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15608",
      "abstract": "For non-robot-programming experts, kinesthetic guiding can be an intuitive input method, as robot programming of in-contact tasks is becoming more prominent. However, imprecise and noisy input signals from human demonstrations pose problems when reproducing motions directly or using the signal as input for machine learning methods. This paper explores optimizing force signals to correspond better to the human intention of the demonstrated signal. We compare different signal filtering methods and propose a peak detection method for dealing with first-contact deviations in the signal. The evaluation of these methods considers a specialized error criterion between the input and the human-intended signal. In addition, we analyze the critical parameters' influence on the filtering methods. The quality for an individual motion could be increased by up to \\SI{20}{\\percent} concerning the error criterion. The proposed contribution can improve the usability of robot programming and the interaction between humans and robots.",
      "authors": [
        "Johannes Hartwig and Fabian Viessmann and Dominik Henrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:33:24+00:00",
          "link": "https://arxiv.org/abs/2507.15608v1",
          "size": "559kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Force Signals from Human Demonstrations of In-Contact Motions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15608",
        "HTML": "https://arxiv.org/html/2507.15608",
        "PDF": "https://arxiv.org/pdf/2507.15608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work investigates optimizing force signals in kinesthetic guiding for robot programming, not involving LLMs or processing their training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15729",
      "abstract": "The rapid development of Large Language Models (LLMs) creates an exciting potential for flexible, general knowledge-driven Human-Robot Interaction (HRI) systems for assistive robots. Existing HRI systems demonstrate great progress in interpreting and following user instructions, action generation, and robot task solving. On the other hand, bi-directional, multi-modal, and context-aware support of the user in collaborative tasks still remains an open challenge. In this paper, we present a gaze- and speech-informed interface to the assistive robot, which is able to perceive the working environment from multiple vision inputs and support the dynamic user in their tasks. Our system is designed to be modular and transferable to adapt to diverse tasks and robots, and it is capable of real-time use of language-based interaction state representation and fast on board perception modules. Its development was supported by multiple public dissemination events, contributing important considerations for improved robustness and user experience. Furthermore, in two lab studies, we compare the performance and user ratings of our system with those of a traditional scripted HRI pipeline. Our findings indicate that an LLM-based approach enhances adaptability and marginally improves user engagement and task execution metrics but may produce redundant output, while a scripted pipeline is well suited for more straightforward tasks.",
      "authors": [
        "Jens V. R\\\"uppel",
        "Andrey Rudenko",
        "Tim Schreiter",
        "Martin Magnusson",
        "Achim J. Lilienthal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:38:25+00:00",
          "link": "https://arxiv.org/abs/2507.15729v1",
          "size": "9758kb",
          "version": "v1"
        }
      ],
      "title": "Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15729",
        "HTML": "https://arxiv.org/html/2507.15729",
        "PDF": "https://arxiv.org/pdf/2507.15729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving human-robot interaction using gaze- and speech-informed interfaces, which involves real-time language-based interaction but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2109.14883",
      "abstract": "As the need to understand and formalise business processes into a model has grown over the last years, the process discovery research field has gained more and more importance, developing two different classes of approaches to model representation: procedural and declarative. Orthogonally to this classification, the vast majority of works envisage the discovery task as a one-class supervised learning process guided by the traces that are recorded into an input log. In this work instead, we focus on declarative processes and embrace the less-popular view of process discovery as a binary supervised learning task, where the input log reports both examples of the normal system execution, and traces representing \"stranger\" behaviours according to the domain semantics. We therefore deepen how the valuable information brought by both these two sets can be extracted and formalised into a model that is \"optimal\" according to user-defined goals. Our approach, namely NegDis, is evaluated w.r.t. other relevant works in this field, and shows promising results as regards both the performance and the quality of the obtained solution.",
      "authors": [
        "Federico Chesani",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Daniela Loreti",
        "Fabrizio Maria Maggi",
        "Paola Mello",
        "Marco Montali",
        "Sergio Tessaris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-30T06:58:34+00:00",
          "link": "https://arxiv.org/abs/2109.14883v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "Process discovery on deviant traces and other stranger things",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.14883",
        "PDF": "https://arxiv.org/pdf/2109.14883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses process discovery in business processes using declarative approaches. It does not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.01663",
      "abstract": "Oversmoothing is a common challenge in learning graph neural networks (GNN), where, as layers increase, embedding features learned from GNNs quickly become similar or indistinguishable, making them incapable of differentiating network proximity. A GNN with shallow layer architectures can only learn short-term relation or localized structure information, limiting its power of learning long-term connection, evidenced by their inferior learning performance on heterophilous graphs. Tackling oversmoothing is crucial for harnessing deep-layer architectures for GNNs. To date, many methods have been proposed to alleviate oversmoothing. The vast difference behind their design principles, combined with graph complications, make it difficult to understand and even compare the difference between different approaches in tackling the oversmoothing. In this paper, we propose ATNPA, a unified view with five key steps: Augmentation, Transformation, Normalization, Propagation, and Aggregation, to summarize GNN oversmoothing alleviation approaches. We first propose a taxonomy for GNN oversmoothing alleviation which includes three themes to tackle oversmoothing. After that, we separate all methods into six categories, followed by detailed reviews of representative methods, including their relation to ATNPA, and discussion of their niche, strength, and weakness. The review not only draws an in-depth understanding of existing methods in the field but also shows a clear road map for future study.",
      "authors": [
        "Yufei Jin and Xingquan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-02T18:33:41+00:00",
          "link": "https://arxiv.org/abs/2405.01663v1",
          "size": "324kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:52:22+00:00",
          "link": "https://arxiv.org/abs/2405.01663v2",
          "size": "5034kb",
          "version": "v2"
        }
      ],
      "title": "Oversmoothing Alleviation in Graph Neural Networks: A Survey and Unified View",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.01663",
        "HTML": "https://arxiv.org/html/2405.01663",
        "PDF": "https://arxiv.org/pdf/2405.01663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with oversmoothing alleviation in Graph Neural Networks (GNNs) and does not relate to LLM training data processing or involve any relevant data processing techniques."
      },
      "tasks": [
        "Graph Neural Network",
        "Relation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07623",
      "abstract": "Platooning represents an advanced driving technology designed to assist drivers in traffic convoys of varying lengths, enhancing road safety, reducing driver fatigue, and improving fuel efficiency. Sophisticated automated driving assistance systems have facilitated this innovation. Recent advancements in platooning emphasize cooperative mechanisms within both centralized and decentralized architectures enabled by vehicular communication technologies. This study introduces a cooperative route planning optimization framework aimed at promoting the adoption of platooning through a centralized platoon formation strategy at the system level. This approach is envisioned as a transitional phase from individual (ego) driving to fully collaborative driving. Additionally, this research formulates and incorporates travel cost metrics related to fuel consumption, driver fatigue, and travel time, considering regulatory constraints on consecutive driving durations. The performance of these cost metrics has been evaluated using Dijkstra's and A* shortest path algorithms within a network graph framework. The results indicate that the proposed architecture achieves an average cost improvement of 14 % compared to individual route planning for long road trips.",
      "authors": [
        "Akif Adas",
        "Stefano Arrigoni",
        "Mattia Brambilla",
        "Monica Barbara Nicoli",
        "Edoardo Sabbioni"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T10:13:20+00:00",
          "link": "https://arxiv.org/abs/2504.07623v1",
          "size": "1330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:26:40+00:00",
          "link": "https://arxiv.org/abs/2504.07623v2",
          "size": "746kb",
          "version": "v2"
        }
      ],
      "title": "Joint Travel Route Optimization Framework for Platooning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07623",
        "HTML": "https://arxiv.org/html/2504.07623",
        "PDF": "https://arxiv.org/pdf/2504.07623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a travel route optimization framework for vehicle platooning, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15170",
      "abstract": "Large language models (LLMs) are rapidly evolving from single-modal systems to multimodal LLMs and intelligent agents, significantly expanding their capabilities while introducing increasingly severe security risks. This paper presents a systematic survey of the growing complexity of jailbreak attacks and corresponding defense mechanisms within the expanding LLM ecosystem. We first trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting the core security challenges emerging at each stage. Next, we categorize mainstream jailbreak techniques from both the attack impact and visibility perspectives, and provide a comprehensive analysis of representative attack methods, related datasets, and evaluation metrics. On the defense side, we organize existing strategies based on response timing and technical approach, offering a structured understanding of their applicability and implementation. Furthermore, we identify key limitations in existing surveys, such as insufficient attention to agent-specific security issues, the absence of a clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of experimental setups, and outdated coverage of recent advancements. To address these limitations, we provide an updated synthesis of recent work and outline future research directions in areas such as dataset construction, evaluation framework optimization, and strategy generalization. Our study seeks to enhance the understanding of jailbreak mechanisms and facilitate the advancement of more resilient and adaptive defense strategies in the context of ever more capable LLMs.",
      "authors": [
        "Yanxu Mao",
        "Tiehan Cui",
        "Peipei Liu",
        "Datao You",
        "Hongsong Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T06:33:19+00:00",
          "link": "https://arxiv.org/abs/2506.15170v1",
          "size": "1528kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T12:54:16+00:00",
          "link": "https://arxiv.org/abs/2506.15170v2",
          "size": "1528kb",
          "version": "v2"
        }
      ],
      "title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15170",
        "HTML": "https://arxiv.org/html/2506.15170",
        "PDF": "https://arxiv.org/pdf/2506.15170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys jailbreak attacks and defenses in LLMs, mentioning 'dataset construction' as a future research direction. However, the primary focus is on security within the LLM ecosystem, not on LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14155",
      "abstract": "Interference prediction that accounts for extreme and rare events remains a key challenge for ultra-densely deployed sub-networks (SNs) requiring hyper-reliable low-latency communication (HRLLC), particularly under dynamic mobility, rapidly varying channel statistics, and sporadic traffic. This paper proposes a novel calibrated interference tail prediction framework, a hybrid statistical and machine learning (ML) approach that integrates an inverted quantile patch transformer (iQPTransformer) within extreme value theory (EVT). It captures interference dynamics and tail behavior while quantifying uncertainty to provide statistical coverage guarantees. Its effectiveness is demonstrated by leveraging the estimated interference tail distribution to design predictive, risk-aware resource allocation. In resource-constrained SN scenarios, we introduce the split-iQPTransformer, enabling collaborative training by distributing neural network components between sensor-actuator (SA) pairs and the SN controller, while maintaining minimal performance disparity compared to the centralized iQPTransformer. The framework effectively handles deep fading, random traffic, and time-division duplexing (TDD) misalignments and is resilient to rare and extreme interference events. Extensive evaluations are performed under two mobility models and two realistic SN traffic patterns, using a spatially consistent 3GPP channel model across all scenarios. Experimental results show consistent achievement of block error rate (BLER) targets beyond the 95th percentile in the hyper-reliable regime, significantly outperforming baseline approaches.",
      "authors": [
        "Pramesh Gautam",
        "Sushmita Sapkota",
        "Carsten Bockelmann",
        "Shashi Raj Pandey",
        "Armin Dekorsy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T10:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.14155v1",
          "size": "2662kb",
          "version": "v1"
        }
      ],
      "title": "Extreme Value Theory-based Distributed Interference Prediction for 6G Industrial Sub-networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14155",
        "HTML": "https://arxiv.org/html/2507.14155",
        "PDF": "https://arxiv.org/pdf/2507.14155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a framework for interference prediction in 6G networks using a hybrid statistical and ML approach, which is unrelated to LLM training data processing or data quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14769",
      "abstract": "Modern web interfaces are unnecessarily complex to use as they overwhelm users with excessive text and visuals unrelated to their current goals. This problem particularly impacts screen reader users (SRUs), who navigate content sequentially and may spend minutes traversing irrelevant elements before reaching desired information compared to vision users (VUs) who visually skim in seconds. We present Task Mode, a system that dynamically filters web content based on user-specified goals using large language models to identify and prioritize relevant elements while minimizing distractions. Our approach preserves page structure while offering multiple viewing modes tailored to different access needs. Our user study with 12 participants (6 VUs, 6 SRUs) demonstrates that our approach reduced task completion time for SRUs while maintaining performance for VUs, decreasing the completion time gap between groups from 2x to 1.2x. 11 of 12 participants wanted to use Task Mode in the future, reporting that Task Mode supported completing tasks with less effort and fewer distractions. This work demonstrates how designing new interactions simultaneously for visual and non-visual access can reduce rather than reinforce accessibility disparities in future technology created by human-computer interaction researchers and practitioners.",
      "authors": [
        "Ananya Gubbi Mohanbabu",
        "Yotam Sechayk",
        "Amy Pavel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T23:41:08+00:00",
          "link": "https://arxiv.org/abs/2507.14769v1",
          "size": "6032kb",
          "version": "v1"
        }
      ],
      "title": "Task Mode: Dynamic Filtering for Task-Specific Web Navigation using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14769",
        "HTML": "https://arxiv.org/html/2507.14769",
        "PDF": "https://arxiv.org/pdf/2507.14769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on using LLMs for dynamic filtering of web content in a task-specific manner primarily to enhance accessibility for users but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15319",
      "abstract": "Kleinberg and Mullainathan (2024) recently proposed a formal framework called language generation in the limit and showed that given a sequence of example strings from an unknown target language drawn from any countable collection, an algorithm can correctly generate unseen strings from the target language within finite time. This notion was further refined by Li, Raman, and Tewari (2024), who defined stricter categories of non-uniform and uniform generation. They showed that a finite union of uniformly generatable collections is generatable in the limit, and asked if the same is true for non-uniform generation.\n  We begin by resolving the question in the negative: we give a uniformly generatable collection and a non-uniformly generatable collection whose union is not generatable in the limit. We then use facets of this construction to further our understanding of several variants of language generation. The first two, generation with noise and without samples, were introduced by Raman and Raman (2025) and Li, Raman, and Tewari (2024) respectively. We show the equivalence of these models for uniform and non-uniform generation, and provide a characterization of non-uniform noisy generation. The former paper asked if there is any separation between noisy and non-noisy generation in the limit -- we show that such a separation exists even with a single noisy string. Finally, we study the framework of generation with feedback, introduced by Charikar and Pabbaraju (2025), where the algorithm is strengthened by allowing it to ask membership queries. We show finite queries add no power, but infinite queries yield a strictly more powerful model.\n  In summary, the results in this paper resolve the union-closedness of language generation in the limit, and leverage those techniques (and others) to give precise characterizations for natural variants that incorporate noise, loss, and feedback.",
      "authors": [
        "Yannan Bai and Debmalya Panigrahi and Ian Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:18:04+00:00",
          "link": "https://arxiv.org/abs/2507.15319v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "Language Generation in the Limit: Noise, Loss, and Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15319",
        "HTML": "https://arxiv.org/html/2507.15319",
        "PDF": "https://arxiv.org/pdf/2507.15319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses language generation in the limit and its mathematical framework, which does not involve any aspect of LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.11798",
      "abstract": "Backdoor learning is a critical research topic for understanding the vulnerabilities of deep neural networks. While the diffusion model (DM) has been broadly deployed in public over the past few years, the understanding of its backdoor vulnerability is still in its infancy compared to the extensive studies in discriminative models. Recently, many different backdoor attack and defense methods have been proposed for DMs, but a comprehensive benchmark for backdoor learning on DMs is still lacking. This absence makes it difficult to conduct fair comparisons and thorough evaluations of the existing approaches, thus hindering future research progress. To address this issue, we propose \\textit{BackdoorDM}, the first comprehensive benchmark designed for backdoor learning on DMs. It comprises nine state-of-the-art (SOTA) attack methods, four SOTA defense strategies, and three useful visualization analysis tools. We first systematically classify and formulate the existing literature in a unified framework, focusing on three different backdoor attack types and five backdoor target types, which are restricted to a single type in discriminative models. Then, we systematically summarize the evaluation metrics for each type and propose a unified backdoor evaluation method based on multimodal large language model (MLLM). Finally, we conduct a comprehensive evaluation and highlight several important conclusions. We believe that BackdoorDM will help overcome current barriers and contribute to building a trustworthy artificial intelligence generated content (AIGC) community. The codes are released in https://github.com/linweiii/BackdoorDM.",
      "authors": [
        "Weilin Lin",
        "Nanjun Zhou",
        "Yanyun Wang",
        "Jianze Li",
        "Hui Xiong",
        "Li Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T13:39:05+00:00",
          "link": "https://arxiv.org/abs/2502.11798v1",
          "size": "6273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:53:02+00:00",
          "link": "https://arxiv.org/abs/2502.11798v2",
          "size": "5501kb",
          "version": "v2"
        }
      ],
      "title": "BackdoorDM: A Comprehensive Benchmark for Backdoor Learning on Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11798",
        "HTML": "https://arxiv.org/html/2502.11798",
        "PDF": "https://arxiv.org/pdf/2502.11798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a benchmark for backdoor learning on diffusion models, focusing on security vulnerabilities rather than on LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/linweiii/backdoordm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.14260",
      "abstract": "As free-space optical systems grow in scale and complexity, troubleshooting becomes increasingly time-consuming and, in the case of remote installations, perhaps impractical. An example of a task that is often laborious is the alignment of a high-finesse optical resonator, which is highly sensitive to the mode of the input beam. In this work, we demonstrate how machine learning can be used to achieve autonomous mode-matching of a free-space optical resonator with minimal supervision. Our approach leverages sample-efficient algorithms to reduce data requirements while maintaining a simple architecture for easy deployment. The reinforcement learning scheme that we have developed shows that automation is feasible even in systems prone to drift in experimental parameters, as may well be the case in real-world applications.",
      "authors": [
        "Arindam Saha",
        "Baramee Charoensombutamon",
        "Thibault Michel",
        "V. Vijendran",
        "Lachlan Walker",
        "Akira Furusawa",
        "Syed M. Assad",
        "Ben C. Buchler",
        "Ping Koy Lam and Aaron D. Tranter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T13:50:44+00:00",
          "link": "https://arxiv.org/abs/2503.14260v1",
          "size": "1485kb",
          "version": "v1"
        }
      ],
      "title": "Automating Experimental Optics with Sample Efficient Machine Learning Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14260",
        "HTML": "https://arxiv.org/html/2503.14260",
        "PDF": "https://arxiv.org/pdf/2503.14260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses automation in optical systems using machine learning methods but does not involve LLM training data processing or related operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.15475",
      "abstract": "Foundation models trained on vast amounts of data have demonstrated remarkable reasoning and generation capabilities in the domains of text, images, audio and video. Our goal at Roblox is to build such a foundation model for 3D intelligence, a model that can support developers in producing all aspects of a Roblox experience, from generating 3D objects and scenes to rigging characters for animation to producing programmatic scripts describing object behaviors. We discuss three key design requirements for such a 3D foundation model and then present our first step towards building such a model. We expect that 3D geometric shapes will be a core data type and describe our solution for 3D shape tokenizer. We show how our tokenization scheme can be used in applications for text-to-shape generation, shape-to-text generation and text-to-scene generation. We demonstrate how these applications can collaborate with existing large language models (LLMs) to perform scene analysis and reasoning. We conclude with a discussion outlining our path to building a fully unified foundation model for 3D intelligence.",
      "authors": [
        "Foundation AI Team Roblox: Kiran Bhat",
        "Nishchaie Khanna",
        "Karun Channa",
        "Tinghui Zhou",
        "Yiheng Zhu",
        "Xiaoxia Sun",
        "Charles Shang",
        "Anirudh Sudarshan",
        "Maurice Chu",
        "Daiqing Li",
        "Kangle Deng",
        "Jean-Philippe Fauconnier",
        "Tijmen Verhulsdonck",
        "Maneesh Agrawala",
        "Kayvon Fatahalian",
        "Alexander Weiss",
        "Christian Reiser",
        "Ravi Kiran Chirravuri",
        "Ravali Kandur",
        "Alejandro Pelaez",
        "Akash Garg",
        "Michael Palleschi",
        "Jessica Wang",
        "Skylar Litz",
        "Leon Liu",
        "Anying Li",
        "David Harmon",
        "Derek Liu",
        "Liangjun Feng",
        "Denis Goupil",
        "Lukas Kuczynski",
        "Jihyun Yoon",
        "Naveen Marri",
        "Peiye Zhuang",
        "Yinan Zhang",
        "Brian Yin",
        "Haomiao Jiang",
        "Marcel van Workum",
        "Thomas Lane",
        "Bryce Erickson",
        "Salil Pathare",
        "Kyle Price",
        "Steve Han",
        "Yiqing Wang",
        "Anupam Singh",
        "David Baszucki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T17:52:17+00:00",
          "link": "https://arxiv.org/abs/2503.15475v1",
          "size": "10472kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T19:52:06+00:00",
          "link": "https://arxiv.org/abs/2503.15475v2",
          "size": "10472kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T17:57:24+00:00",
          "link": "https://arxiv.org/abs/2503.15475v3",
          "size": "11611kb",
          "version": "v3"
        }
      ],
      "title": "Cube: A Roblox View of 3D Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15475",
        "HTML": "https://arxiv.org/html/2503.15475",
        "PDF": "https://arxiv.org/pdf/2503.15475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores building a foundation model for 3D intelligence and focuses on 3D geometric shape tokenization for applications like text-to-shape generation. It does not address LLM training data processing."
      },
      "models": [
        {
          "model_path": "Roblox/cube3d-v0.1",
          "downloads": "0",
          "likes": "76",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Roblox/cube3d-v0.1"
        },
        {
          "model_path": "Roblox/cube3d-v0.5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Roblox/cube3d-v0.5"
        }
      ],
      "tasks": [
        "Scene Generation",
        "Text Generation",
        "Text-to-Shape Generation"
      ],
      "repo_urls": [
        "https://github.com/roblox/cube"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14197",
      "abstract": "We introduce DM-RSA (Dual Modulus RSA), a variant of the RSA cryptosystem that employs two distinct moduli symmetrically to enhance security. By leveraging the Chinese Remainder Theorem (CRT) for decryption, DM-RSA provides increased robustness against side-channel attacks while preserving the efficiency of classical RSA. This approach improves resistance to partial compromise of a modulus and integrates easily into existing infrastructures.",
      "authors": [
        "Andriamifidisoa Ramamonjy",
        "Rufine Marius Lalasoa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:09:53+00:00",
          "link": "https://arxiv.org/abs/2507.14197v1",
          "size": "3kb",
          "version": "v1"
        }
      ],
      "title": "DM-RSA: An Extension of RSA with Dual Modulus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14197",
        "HTML": "https://arxiv.org/html/2507.14197",
        "PDF": "https://arxiv.org/pdf/2507.14197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a cryptographic system enhancement called DM-RSA, which has no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14260",
      "abstract": "This work concerns a detailed review of data analysis methods used for remotely sensed images of large areas of the Earth and of other solid astronomical objects. In detail, it focuses on the problem of inferring the materials that cover the surfaces captured by hyper-spectral images and estimating their abundances and spatial distributions within the region. The most successful and relevant hyper-spectral unmixing methods are reported as well as compared, as an addition to analysing the most recent methodologies. The most important public data-sets in this setting, which are vastly used in the testing and validation of the former, are also systematically explored. Finally, open problems are spotlighted and concrete recommendations for future research are provided.",
      "authors": [
        "Alfredo Gimenez Zapiola",
        "Andrea Boselli",
        "Alessandra Menafoglio and Simone Vantini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Earth and Planetary Astrophysics (astro-ph.EP)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:46:40+00:00",
          "link": "https://arxiv.org/abs/2507.14260v1",
          "size": "1354kb",
          "version": "v1"
        }
      ],
      "title": "Hyper-spectral Unmixing algorithms for remote compositional surface mapping: a review of the state of the art",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14260",
        "HTML": "https://arxiv.org/html/2507.14260",
        "PDF": "https://arxiv.org/pdf/2507.14260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work reviews hyperspectral unmixing methods for remote sensing and does not pertain to LLM training data processing, nor does it discuss any relevant data engineering operations or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14651",
      "abstract": "Hybrid vision transformers combine the elements of conventional neural networks (NN) and vision transformers (ViT) to enable lightweight and accurate detection. However, several challenges remain for their efficient deployment on resource-constrained edge devices. The hybrid models suffer from a widely diverse set of NN layer types and large intermediate data tensors, hampering efficient hardware acceleration. To enable their execution at the edge, this paper proposes innovations across the hardware-scheduling stack: a.) At the lowest level, a configurable PE array supports all hybrid ViT layer types; b.) temporal loop re-ordering within one layer, enabling hardware support for normalization and softmax layers, minimizing on-chip data transfers; c.) further scheduling optimization employs layer fusion across inverted bottleneck layers to drastically reduce off-chip memory transfers. The resulting accelerator is implemented in 28nm CMOS, achieving a peak energy efficiency of 1.39 TOPS/W at 25.6 GMACs/s.",
      "authors": [
        "Joren Dumoulin",
        "Pouya Houshmand",
        "Vikram Jain",
        "Marian Verhelst"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:57:23+00:00",
          "link": "https://arxiv.org/abs/2507.14651v1",
          "size": "4719kb",
          "version": "v1"
        }
      ],
      "title": "Enabling Efficient Hardware Acceleration of Hybrid Vision Transformer (ViT) Networks at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14651",
        "HTML": "https://arxiv.org/html/2507.14651",
        "PDF": "https://arxiv.org/pdf/2507.14651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with hardware acceleration for hybrid vision transformer networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15442",
      "abstract": "This work proposes a training algorithm based on adaptive random Fourier features (ARFF) with Metropolis sampling and resampling \\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and diffusion components of stochastic differential equations from snapshot data. Specifically, this study considers It\\^{o} diffusion processes and a likelihood-based loss function derived from the Euler-Maruyama integration introduced in \\cite{Dietrich2023} and \\cite{dridi2021learningstochasticdynamicalsystems}.\n  This work evaluates the proposed method against benchmark problems presented in \\cite{Dietrich2023}, including polynomial examples, underdamped Langevin dynamics, a stochastic susceptible-infected-recovered model, and a stochastic wave equation. Across all cases, the ARFF-based approach matches or surpasses the performance of conventional Adam-based optimization in both loss minimization and convergence speed. These results highlight the potential of ARFF as a compelling alternative for data-driven modeling of stochastic dynamics.",
      "authors": [
        "Owen Douglas and Aku Kammonen and Anamika Pandey and Ra\\'ul Tempone"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:52:33+00:00",
          "link": "https://arxiv.org/abs/2507.15442v1",
          "size": "8648kb",
          "version": "v1"
        }
      ],
      "title": "An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15442",
        "HTML": "https://arxiv.org/html/2507.15442",
        "PDF": "https://arxiv.org/pdf/2507.15442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method involving adaptive random Fourier features for learning stochastic differential equations, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15586",
      "abstract": "Retrieval-Augmented Generation (RAG) effectively improves the accuracy of Large Language Models (LLMs). However, retrieval noises significantly impact the quality of LLMs' generation, necessitating the development of denoising mechanisms. Previous methods extract evidence straightforwardly without explicit thinking, which risks filtering out key clues and struggles with generalization. To this end, we propose LEAR, which learns to extract rational evidence by (1) explicitly reasoning to identify potential cues within retrieval contents first, and then (2) consciously extracting to avoid omitting any key cues helpful for answering questions. Specifically, we frame evidence reasoning and evidence extraction into one unified response for end-to-end training; apply knowledge token masks for disentanglement to derive reasoning-based and extraction-based answers; and devise three types of verifiable reward functions, including answer, length, and format, to update the model via the policy optimization algorithm. Extensive experiments on three benchmark datasets show the effectiveness of LEAR, providing compact and high-quality evidence, improving the accuracy of downstream tasks, and promoting effective application in online RAG systems.",
      "authors": [
        "Xinping Zhao",
        "Shouzheng Huang",
        "Yan Zhong",
        "Xinshuo Hu",
        "Baotian Hu",
        "Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.15586v1",
          "size": "4218kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15586",
        "HTML": "https://arxiv.org/html/2507.15586",
        "PDF": "https://arxiv.org/pdf/2507.15586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method (LEAR) for extracting rational evidence in retrieval-augmented LLMs, which impacts downstream task performance, but it primarily focuses on algorithmic improvements rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15621",
      "abstract": "Wireless users with different characteristics will be expected to share spectrum in next generation communication networks. One of the great strengths of wireless networks based on Orthogonal Frequency Division Multiplexing (OFDM) is the ease with which different non-overlapping time-frequency (TF) resources can be allocated to different users by simply shifting each user's signal in time and frequency. However, a significant weaknesses of OFDM is the inflexibility of sub-carrier spacing. Since OFDM does not allow users to have different sub-carrier spacing, a single user subject to inter-carrier interference causes carrier spacing to increase for all users. Zak-OTFS is an alternative delay-Doppler (DD) domain modulation scheme, where, in contrast to OFDM, the Input-Output (I/O) relation is predictable. We match the strength of OFDM by designing a novel DD domain method of shaping the transmitted Zak-OTFS pulse on the uplink that enables flexible non-overlapping TF resource allocation. The base station (BS) receives a superposition of uplink signals and applies individual matched filters to obtain the data specific to individual users. We develop theoretical measures of interference between users, and present numerical simulations for a vehicular channel model representative of next generation propagation environments. We demonstrate single-user performance in a multiuser Zak-OTFS uplink system without needing to provision guard bands between TF resources allocated to different users. These performance results demonstrate that the benefits of a predictable Zak-OTFS waveform can be realized within an architecture for uplink communication.",
      "authors": [
        "Imran Ali Khan",
        "Saif Khan Mohammed",
        "Ronny Hadani",
        "Ananthanarayanan Chockalingam and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:44:51+00:00",
          "link": "https://arxiv.org/abs/2507.15621v1",
          "size": "976kb",
          "version": "v1"
        }
      ],
      "title": "Zak-OTFS based Multiuser Uplink in Doubly-Spread Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15621",
        "HTML": "https://arxiv.org/html/2507.15621",
        "PDF": "https://arxiv.org/pdf/2507.15621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses signal processing in wireless communications using Zak-OTFS in multiuser uplink scenarios, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15680",
      "abstract": "Image Quality Assessment (IQA) is a core task in computer vision. Multimodal methods based on vision-language models, such as CLIP, have demonstrated exceptional generalization capabilities in IQA tasks. To address the issues of excessive parameter burden and insufficient ability to identify local distorted features in CLIP for IQA, this study proposes a visual-language model knowledge distillation method aimed at guiding the training of models with architectural advantages using CLIP's IQA knowledge. First, quality-graded prompt templates were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned to enhance its capabilities in IQA tasks. Finally, a modality-adaptive knowledge distillation strategy is proposed to achieve guidance from the CLIP teacher model to the student model. Our experiments were conducted on multiple IQA datasets, and the results show that the proposed method significantly reduces model complexity while outperforming existing IQA methods, demonstrating strong potential for practical deployment.",
      "authors": [
        "Yongkang Hou",
        "Jiarun Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:44:46+00:00",
          "link": "https://arxiv.org/abs/2507.15680v1",
          "size": "853kb",
          "version": "v1"
        }
      ],
      "title": "Visual-Language Model Knowledge Distillation Method for Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15680",
        "PDF": "https://arxiv.org/pdf/2507.15680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a knowledge distillation method using a visual-language model like CLIP for IQA tasks, which involves enhancing model capabilities through fine-tuning. However, the primary focus is on image quality assessment rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19545",
      "abstract": "The deployment of Large Language Models (LLMs) in customer support is constrained by hallucination (generating false information) and the high cost of proprietary models. To address these challenges, we propose a retrieval-augmented question-answering (QA) pipeline and explore how to balance human input and automation. Using a dataset of questions about a Samsung Smart TV user manual, we demonstrate that synthetic data generated by LLMs outperforms crowdsourced data in reducing hallucination in finetuned models. We also compare self-training (fine-tuning models on their own outputs) and knowledge distillation (fine-tuning on stronger models' outputs, e.g., GPT-4o), and find that self-training achieves comparable hallucination reduction. We conjecture that this surprising finding can be attributed to increased exposure bias issues in the knowledge distillation case and support this conjecture with post hoc analysis. We also improve robustness to unanswerable questions and retrieval failures with contextualized \"I don't know\" responses. These findings show that scalable, cost-efficient QA systems can be built using synthetic data and self-training with open-source models, reducing reliance on proprietary tools or costly human annotations.",
      "authors": [
        "Ashley Lewis",
        "Michael White",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T20:34:58+00:00",
          "link": "https://arxiv.org/abs/2502.19545v1",
          "size": "2027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:24:26+00:00",
          "link": "https://arxiv.org/abs/2502.19545v2",
          "size": "2021kb",
          "version": "v2"
        }
      ],
      "title": "Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in Product QA Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19545",
        "HTML": "https://arxiv.org/html/2502.19545",
        "PDF": "https://arxiv.org/pdf/2502.19545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of synthetic data for fine-tuning product QA agents to reduce hallucination. However, the primary focus is on model training approaches like self-training and knowledge distillation rather than on the data processing itself."
      },
      "tasks": [
        "Hallucination",
        "Knowledge Distillation",
        "Question Answering",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14558",
      "abstract": "The combination of computer vision and artificial intelligence is fundamentally transforming a broad spectrum of industries by enabling machines to interpret and act upon visual data with high levels of accuracy. As the biggest and by far the most popular open-source computer vision library, OpenCV library provides an extensive suite of programming functions supporting real-time computer vision. Bugs in the OpenCV library can affect the downstream computer vision applications, and it is critical to ensure the reliability of the OpenCV library. This paper introduces VISTAFUZZ, a novel technique for harnessing large language models (LLMs) for document-guided fuzzing of the OpenCV library. VISTAFUZZ utilizes LLMs to parse API documentation and obtain standardized API information. Based on this standardized information, VISTAFUZZ extracts constraints on individual input parameters and dependencies between these. Using these constraints and dependencies, VISTAFUZZ then generates new input values to systematically test each target API. We evaluate the effectiveness of VISTAFUZZ in testing 330 APIs in the OpenCV library, and the results show that VISTAFUZZ detected 17 new bugs, where 10 bugs have been confirmed, and 5 of these have been fixed.",
      "authors": [
        "Bin Duan",
        "Tarek Mahmud",
        "Meiru Che",
        "Yan Yan",
        "Naipeng Dong",
        "Dan Dongseong Kim",
        "Guowei Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:44:01+00:00",
          "link": "https://arxiv.org/abs/2507.14558v1",
          "size": "718kb",
          "version": "v1"
        }
      ],
      "title": "Harnessing LLMs for Document-Guided Fuzzing of OpenCV Library",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14558",
        "HTML": "https://arxiv.org/html/2507.14558",
        "PDF": "https://arxiv.org/pdf/2507.14558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents VISTAFUZZ, a technique for document-guided fuzzing of OpenCV using LLMs. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15066",
      "abstract": "Time series anomaly detection is critical across various domains, yet current approaches often limit analysis to mere binary anomaly classification without detailed categorization or further explanatory reasoning. To address these limitations, we propose a novel task, Time-series Reasoning for Anomaly (Time-RA) that transforms classical time series anomaly detection from a discriminative into a generative, reasoning-intensive task leveraging Large Language Models (LLMs). Also, we introduce the first real-world multimodal benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning, comprising approximately 40,000 samples across 10 real-world domains. Each sample includes numeric time series data, contextual text information, and visual representations, each annotated with fine-grained categories (14 types for univariate anomalies and 6 for multivariate anomalies) and structured explanatory reasoning. We develop a sophisticated annotation framework utilizing ensemble-generated labels refined through GPT-4-driven feedback, ensuring accuracy and interpretability. Extensive benchmarking of LLMs and multimodal LLMs demonstrates the capabilities and limitations of current models, highlighting the critical role of supervised fine-tuning. Our dataset and task pave the way for significant advancements in interpretable time series anomaly detection and reasoning.",
      "authors": [
        "Yiyuan Yang",
        "Zichuan Liu",
        "Lei Song",
        "Kai Ying",
        "Zhiguang Wang",
        "Tom Bamford",
        "Svitlana Vyetrenko",
        "Jiang Bian",
        "Qingsong Wen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:02:50+00:00",
          "link": "https://arxiv.org/abs/2507.15066v1",
          "size": "4074kb",
          "version": "v1"
        }
      ],
      "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15066",
        "PDF": "https://arxiv.org/pdf/2507.15066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a new anomaly reasoning dataset, RATs40K, and the development of an annotation framework utilizing LLM feedback. While it contributes to dataset creation and data processing through annotation refinement, its primary focus is on anomaly detection, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15293",
      "abstract": "Inertial localization is regarded as a promising positioning solution for consumer-grade IoT devices due to its cost-effectiveness and independence from external infrastructure. However, data-driven inertial localization methods often rely on increasingly complex network architectures to improve accuracy, which challenges the limited computational resources of IoT devices. Moreover, these methods frequently overlook the importance of modeling long-term dependencies in inertial measurements - a critical factor for accurate trajectory reconstruction - thereby limiting localization performance. To address these challenges, we propose a reparameterized inertial localization network that uses a multi-branch structure during training to enhance feature extraction. At inference time, this structure is transformed into an equivalent single-path architecture to improve parameter efficiency. To further capture long-term dependencies in motion trajectories, we introduce a temporal-scale sparse attention mechanism that selectively emphasizes key trajectory segments while suppressing noise. Additionally, a gated convolutional unit is incorporated to effectively integrate long-range dependencies with local fine-grained features. Extensive experiments on public benchmarks demonstrate that our method achieves a favorable trade-off between accuracy and model compactness. For example, on the RoNIN dataset, our approach reduces the Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while reducing the number of parameters by 3.86%.",
      "authors": [
        "Shanshan Zhang",
        "Tianshui Wen",
        "Siyue Wang",
        "Qi Zhang",
        "Ziheng Zhou",
        "Lingxiang Zheng",
        "Yu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:48:45+00:00",
          "link": "https://arxiv.org/abs/2507.15293v1",
          "size": "1175kb",
          "version": "v1"
        }
      ],
      "title": "RepILN: Reparameterized Inertial Localization Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15293",
        "HTML": "https://arxiv.org/html/2507.15293",
        "PDF": "https://arxiv.org/pdf/2507.15293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper targets inertial localization for IoT devices and develops a neural network to improve positioning accuracy, without any connection to LLM data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.06566",
      "abstract": "This paper explores the use of Maximum Causal Entropy Inverse Reinforcement Learning (IRL) within the context of discrete-time stationary Mean-Field Games (MFGs) characterized by finite state spaces and an infinite-horizon, discounted-reward setting. Although the resulting optimization problem is non-convex with respect to policies, we reformulate it as a convex optimization problem in terms of state-action occupation measures by leveraging the linear programming framework of Markov Decision Processes. Based on this convex reformulation, we introduce a gradient descent algorithm with a guaranteed convergence rate to efficiently compute the optimal solution. Moreover, we develop a new method that conceptualizes the MFG problem as a Generalized Nash Equilibrium Problem (GNEP), enabling effective computation of the mean-field equilibrium for forward reinforcement learning (RL) problems and marking an advancement in MFG solution techniques. We further illustrate the practical applicability of our GNEP approach by employing this algorithm to generate data for numerical MFG examples.",
      "authors": [
        "Berkay Anahtarci",
        "Can Deha Kariksiz",
        "Naci Saldi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-12T13:22:03+00:00",
          "link": "https://arxiv.org/abs/2401.06566v1",
          "size": "367kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T09:43:59+00:00",
          "link": "https://arxiv.org/abs/2401.06566v2",
          "size": "45kb",
          "version": "v2"
        }
      ],
      "title": "Maximum Causal Entropy IRL in Mean-Field Games and GNEP Framework for Forward RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.06566",
        "HTML": "https://arxiv.org/html/2401.06566",
        "PDF": "https://arxiv.org/pdf/2401.06566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines Maximum Causal Entropy IRL and its application in Mean-Field Games and not in the domain of LLM training data processing or dataset creation for language models."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.08495",
      "abstract": "Classical data can be copied and re-used for computation, with adverse consequences economically and in terms of data privacy. Motivated by this, we formulate problems in one-way communication complexity where Alice holds some data $x$ and Bob holds $m$ inputs $y_1,... , y_m$. They want to compute $m$ instances of a bipartite relation $R$ on every pair $(x, y_1),\\ldots, (x, y_m)$. We call this the asymmetric direct sum question for one-way communication. We give a number of examples where the quantum communication complexity of such problems scales polynomially with $m$, while the classical communication complexity depends at most logarithmically on $m$. Thus, for such problems, data behaves like a consumable resource that is effectively destroyed upon use when the owner stores and transmits it as quantum states, but not when transmitted classically. We show an application to a strategic data-selling game, and discuss other potential economic implications.",
      "authors": [
        "Dar Gilboa",
        "Siddhartha Jain and Jarrod R. McClean"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T02:42:29+00:00",
          "link": "https://arxiv.org/abs/2409.08495v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T02:09:23+00:00",
          "link": "https://arxiv.org/abs/2409.08495v2",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:18:49+00:00",
          "link": "https://arxiv.org/abs/2409.08495v3",
          "size": "40kb",
          "version": "v3"
        }
      ],
      "title": "Consumable Data via Quantum Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08495",
        "HTML": "https://arxiv.org/html/2409.08495",
        "PDF": "https://arxiv.org/pdf/2409.08495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates quantum communication complexities in data handling, which does not relate to training data processing for LLMs or involve any relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.09218",
      "abstract": "The challenging deployment of compute- and memory-intensive methods from Deep Neural Network (DNN)-based Continual Learning (CL) underscores the critical need for a paradigm shift towards more efficient approaches. Neuromorphic Continual Learning (NCL) appears as an emerging solution, by leveraging the principles of Spiking Neural Networks (SNNs) which enable efficient CL algorithms executed in dynamically-changed environments with resource-constrained computing systems. Motivated by the need for a holistic study of NCL, in this survey, we first provide a detailed background on CL, encompassing the desiderata, settings, metrics, scenario taxonomy, Online Continual Learning (OCL) paradigm, recent DNN-based methods to address catastrophic forgetting (CF). Then, we analyze these methods considering CL desiderata, computational and memory costs, as well as network complexity, hence emphasizing the need for energy-efficient CL. Afterward, we provide background of low-power neuromorphic systems including encoding techniques, neuronal dynamics, network architectures, learning rules, hardware processors, software and hardware frameworks, datasets, benchmarks, and evaluation metrics. Then, this survey comprehensively reviews and analyzes state-of-the-art in NCL. The key ideas, implementation frameworks, and performance assessments are also provided. This survey covers several hybrid approaches that combine supervised and unsupervised learning paradigms. It also covers optimization techniques including SNN operations reduction, weight quantization, and knowledge distillation. Then, this survey discusses the progress of real-world NCL applications. Finally, this paper provides a future perspective on the open research challenges for NCL, since the purpose of this study is to be useful for the wider neuromorphic AI research community and to inspire future research in bio-plausible OCL.",
      "authors": [
        "Mishal Fatima Minhas",
        "Rachmad Vidya Wicaksana Putra",
        "Falah Awwad",
        "Osman Hasan",
        "Muhammad Shafique"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T19:49:53+00:00",
          "link": "https://arxiv.org/abs/2410.09218v1",
          "size": "2362kb",
          "version": "v1"
        },
        {
          "date": "2024-10-28T04:52:01+00:00",
          "link": "https://arxiv.org/abs/2410.09218v2",
          "size": "3429kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T03:19:37+00:00",
          "link": "https://arxiv.org/abs/2410.09218v3",
          "size": "4907kb",
          "version": "v3"
        }
      ],
      "title": "Continual Learning with Neuromorphic Computing: Foundations, Methods, and Emerging Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09218",
        "HTML": "https://arxiv.org/html/2410.09218",
        "PDF": "https://arxiv.org/pdf/2410.09218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys continuous learning with neuromorphic computing, emphasizing energy-efficient CL systems and not LLM training data processing or related data operations for LLM training."
      },
      "tasks": [
        "Continual Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16711",
      "abstract": "Spiking Neural Networks (SNNs) with their bio-inspired Leaky Integrate-and-Fire (LIF) neurons inherently capture temporal information. This makes them well-suited for sequential tasks like processing event-based data from Dynamic Vision Sensors (DVS) and event-based speech tasks. Harnessing the temporal capabilities of SNNs requires mitigating vanishing spikes during training, capturing spatio-temporal patterns and enhancing precise spike timing. To address these challenges, we propose TSkips, augmenting SNN architectures with forward and backward skip connections that incorporate explicit temporal delays. These connections capture long-term spatio-temporal dependencies and facilitate better spike flow over long sequences. The introduction of TSkips creates a vast search space of possible configurations, encompassing skip positions and time delay values. To efficiently navigate this search space, this work leverages training-free Neural Architecture Search (NAS) to identify optimal network structures and corresponding delays. We demonstrate the effectiveness of our approach on four event-based datasets: DSEC-flow for optical flow estimation, DVS128 Gesture for hand gesture recognition and Spiking Heidelberg Digits (SHD) and Spiking Speech Commands (SSC) for speech recognition. Our method achieves significant improvements across these datasets: up to 18% reduction in Average Endpoint Error (AEE) on DSEC-flow, 8% increase in classification accuracy on DVS128 Gesture, and up to 8% and 16% higher classification accuracy on SHD and SSC, respectively.",
      "authors": [
        "Prajna G. Malettira",
        "Shubham Negi",
        "Wachirawit Ponghiran",
        "Kaushik Roy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T18:58:18+00:00",
          "link": "https://arxiv.org/abs/2411.16711v1",
          "size": "2175kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:41:57+00:00",
          "link": "https://arxiv.org/abs/2411.16711v2",
          "size": "2315kb",
          "version": "v2"
        }
      ],
      "title": "TSkips: Efficiency Through Explicit Temporal Delay Connections in Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16711",
        "HTML": "https://arxiv.org/html/2411.16711",
        "PDF": "https://arxiv.org/pdf/2411.16711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses improvements in Spiking Neural Networks (SNNs) through the introduction of temporal delay connections. It is centered on neural architecture and efficiency, with no focus on LLM training data processing."
      },
      "tasks": [
        "Gesture Recognition",
        "Hand Gesture Recognition",
        "Hand-Gesture Recognition",
        "Navigate",
        "Neural Architecture Search",
        "Optical Flow Estimation",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17646",
      "abstract": "It is well recognized that the safety of compiler optimizations is at risk in a concurrent context. Existing approaches primarily rely on context-free thread-local guarantees, and prohibit optimizations that introduce a data-race. However, compilers utilize global context-specific information, exposing safe optimizations that may violate such guarantees as well as introduce a race. Such optimizations need to individually be proven safe for each language model. An alternate approach to this would be proving them safe for an intuitive model (like interleaving semantics), and then determine their portability across other concurrent models. In this paper, we address this problem of porting across models of concurrency. We first identify a global guarantee on optimizations portable from Sequential Consistency (SC) to Total Store Order (TSO). Our guarantee is in the form of constraints specifying the syntactic changes an optimization must not incur. We then show these constraints correlate to prohibiting the introduction of triangular races, a subset of data-race relevant to TSO. We conclude by showing how such race inducing optimizations relate to porting across Strong Release Acquire (SRA), a known causally consistent memory model.",
      "authors": [
        "Akshay Gopalakrishnan",
        "Clark Verbrugge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T15:16:17+00:00",
          "link": "https://arxiv.org/abs/2504.17646v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "Portability of Optimizations from SC to TSO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17646",
        "PDF": "https://arxiv.org/pdf/2504.17646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work deals with concurrency models in compiler optimizations, not related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14488",
      "abstract": "Lin, Chan (High order entropy stable discontinuous Galerkin spectral element methods through subcell limiting, 2024) enforces a cell entropy inequality for nodal discontinuous Galerkin methods by combining flux corrected transport (FCT)-type limiting and a knapsack solver, which determines optimal limiting coefficients that result in a semi-discrete cell entropy inequality while preserving nodal bounds. In this work, we provide a slight modification of this approach, where we utilize a quadratic knapsack problem instead of a standard linear knapsack problem. We prove that this quadratic knapsack problem can be reduced to efficient scalar root-finding. Numerical results demonstrate that the proposed quadratic knapsack limiting strategy is efficient and results in a semi-discretization with improved regularity in time compared with linear knapsack limiting, while resulting in fewer adaptive timesteps in shock-type problems.",
      "authors": [
        "Brian Christner",
        "Jesse Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:12:59+00:00",
          "link": "https://arxiv.org/abs/2507.14488v1",
          "size": "8137kb",
          "version": "v1"
        }
      ],
      "title": "Entropy Stable Nodal Discontinuous Galerkin Methods via Quadratic Knapsack Limiting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14488",
        "PDF": "https://arxiv.org/pdf/2507.14488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses entropy stable nodal discontinuous Galerkin methods using quadratic knapsack limiting. It does not address LLM training data processing or any data-related operations pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14597",
      "abstract": "Processing data at high speeds is becoming increasingly critical as digital economies generate enormous data. The current paradigms for timely data processing are edge computing and data stream processing (DSP). Edge computing places resources closer to where data is generated, while stream processing analyzes the unbounded high-speed data in motion. However, edge stream processing faces rapid workload fluctuations, complicating resource provisioning. Inadequate resource allocation leads to bottlenecks, whereas excess allocation results in wastage. Existing reactive methods, such as threshold-based policies and queuing theory scale only after performance degrades, potentially violating SLAs. Although reinforcement learning (RL) offers a proactive approach through agents that learn optimal runtime adaptation policies, it requires extensive simulation. Furthermore, predictive machine learning models face online distribution and concept drift that minimize their accuracy. We propose a three-step solution to the proactive edge stream processing autoscaling problem. Firstly, a GRU neural network forecasts the upstream load using real-world and synthetic DSP datasets. Secondly, a transfer learning framework integrates the predictive model into an online stream processing system using the DTW algorithm and joint distribution adaptation to handle the disparities between offline and online domains. Finally, a horizontal autoscaling module dynamically adjusts the degree of operator parallelism, based on predicted load while considering edge resource constraints. The lightweight GRU model for load predictions recorded up to 1.3\\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and Prophet on the SMAPE and RMSE evaluation metrics, with lower training time than the computationally intensive RL models.",
      "authors": [
        "Eugene Armah",
        "Linda Amoako Bannning"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:47:50+00:00",
          "link": "https://arxiv.org/abs/2507.14597v1",
          "size": "1206kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14597",
        "HTML": "https://arxiv.org/html/2507.14597",
        "PDF": "https://arxiv.org/pdf/2507.14597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses proactive autoscaling for data stream processing at the edge using GRU and transfer learning. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14791",
      "abstract": "Repository-level code generation aims to generate code within the context of a specified repository. Existing approaches typically employ retrieval-augmented generation (RAG) techniques to provide LLMs with relevant contextual information extracted from the repository. However, these approaches often struggle with effectively identifying truly relevant contexts that capture the rich semantics of the repository, and their contextual perspectives remains narrow. Moreover, most approaches fail to account for the structural relationships in the retrieved code during prompt construction, hindering the LLM's ability to accurately interpret the context. To address these issues, we propose RepoScope, which leverages call chain-aware multi-view context for repository-level code generation. RepoScope constructs a Repository Structural Semantic Graph (RSSG) and retrieves a comprehensive four-view context, integrating both structural and similarity-based contexts. We propose a novel call chain prediction method that utilizes the repository's structural semantics to improve the identification of callees in the target function. Additionally, we present a structure-preserving serialization algorithm for prompt construction, ensuring the coherence of the context for the LLM. Notably, RepoScope relies solely on static analysis, eliminating the need for additional training or multiple LLM queries, thus ensuring both efficiency and generalizability. Evaluation on widely-used repository-level code generation benchmarks (CoderEval and DevEval) demonstrates that RepoScope outperforms state-of-the-art methods, achieving up to a 36.35% relative improvement in pass@1 scores. Further experiments emphasize RepoScope's potential to improve code generation across different tasks and its ability to integrate effectively with existing approaches.",
      "authors": [
        "Yang Liu",
        "Li Zhang",
        "Fang Liu",
        "Zhuohang Wang",
        "Donglin Wei",
        "Zhishuo Yang",
        "Kechi Zhang",
        "Jia Li",
        "Lin Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:35:36+00:00",
          "link": "https://arxiv.org/abs/2507.14791v1",
          "size": "415kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14791",
        "PDF": "https://arxiv.org/pdf/2507.14791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses repository-level code generation by enhancing context retrieval for LLMs. While it involves context preparation for LLMs, it does not contribute to training data processing as defined by the task, such as data collection or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14853",
      "abstract": "Federated Learning (FL) enables collaborative model training without sharing raw data, making it a promising approach for privacy-sensitive domains. Despite its potential, FL faces significant challenges, particularly in terms of communication overhead and data privacy. Privacy-preserving Techniques (PPTs) such as Homomorphic Encryption (HE) have been used to mitigate these concerns. However, these techniques introduce substantial computational and communication costs, limiting their practical deployment. In this work, we explore how Hybrid Homomorphic Encryption (HHE), a cryptographic protocol that combines symmetric encryption with HE, can be effectively integrated with FL to address both communication and privacy challenges, paving the way for scalable and secure decentralized learning system.",
      "authors": [
        "Khoa Nguyen",
        "Tanveer Khan",
        "Antonis Michalas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:46:53+00:00",
          "link": "https://arxiv.org/abs/2507.14853v1",
          "size": "129kb",
          "version": "v1"
        }
      ],
      "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14853",
        "HTML": "https://arxiv.org/html/2507.14853",
        "PDF": "https://arxiv.org/pdf/2507.14853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around federated learning and privacy, specifically using hybrid homomorphic encryption, without relevance to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15221",
      "abstract": "Recent breakthroughs in intelligent speech and digital human technologies have primarily targeted mainstream adult users, often overlooking the distinct vocal patterns and interaction styles of seniors and children. These demographics possess distinct vocal characteristics, linguistic styles, and interaction patterns that challenge conventional ASR, TTS, and LLM systems. To address this, we introduce EchoVoices, an end-to-end digital human pipeline dedicated to creating persistent digital personas for seniors and children, ensuring their voices and memories are preserved for future generations. Our system integrates three core innovations: a k-NN-enhanced Whisper model for robust speech recognition of atypical speech; an age-adaptive VITS model for high-fidelity, speaker-aware speech synthesis; and an LLM-driven agent that automatically generates persona cards and leverages a RAG-based memory system for conversational consistency. Our experiments, conducted on the SeniorTalk and ChildMandarin datasets, demonstrate significant improvements in recognition accuracy, synthesis quality, and speaker similarity. EchoVoices provides a comprehensive framework for preserving generational voices, offering a new means of intergenerational connection and the creation of lasting digital legacies.",
      "authors": [
        "Haiying Xu",
        "Haoze Liu",
        "Mingshi Li",
        "Siyu Cai",
        "Guangxuan Zheng",
        "Yuhuang Jia",
        "Jinghua Zhao",
        "Yong Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.15221v1",
          "size": "2025kb",
          "version": "v1"
        }
      ],
      "title": "EchoVoices: Preserving Generational Voices and Memories for Seniors and Children",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15221",
        "HTML": "https://arxiv.org/html/2507.15221",
        "PDF": "https://arxiv.org/pdf/2507.15221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on speech and digital human technologies, specifically for preserving voices of seniors and children. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14516",
      "abstract": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware metric function for time series self-supervised representation learning. Most Self-Supervised Learning (SSL) methods for signals commonly adopt distance-based objectives such as mean squared error (MSE), which are sensitive to amplitude, invariant to waveform polarity, and unbounded in scale. These properties hinder semantic alignment and reduce interpretability. SDSC addresses this by quantifying structural agreement between temporal signals based on the intersection of signed amplitudes, derived from the Dice Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware metric, it can be used as a loss by subtracting from 1 and applying a differentiable approximation of the Heaviside function for gradient-based optimization. A hybrid loss formulation is also proposed to combine SDSC with MSE, improving stability and preserving amplitude where necessary. Experiments on forecasting and classification benchmarks demonstrate that SDSC-based pre-training achieves comparable or improved performance over MSE, particularly in in-domain and low-resource scenarios. The results suggest that structural fidelity in signal representations enhances the semantic representation quality, supporting the consideration of structure-aware metrics as viable alternatives to conventional distance-based methods.",
      "authors": [
        "Jeyoung Lee and Hochul Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:32:00+00:00",
          "link": "https://arxiv.org/abs/2507.14516v1",
          "size": "715kb",
          "version": "v1"
        }
      ],
      "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14516",
        "HTML": "https://arxiv.org/html/2507.14516",
        "PDF": "https://arxiv.org/pdf/2507.14516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a metric for signal representation learning in time series data. It is not related to any stage of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14560",
      "abstract": "The self-attention mechanism, now central to deep learning architectures such as Transformers, is a modern instance of a more general computational principle: learning and using pairwise affinity matrices to control how information flows through a model. This paper traces the conceptual origins of self-attention across multiple domains, including computer vision, natural language processing, and graph learning, through their shared reliance on an affinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS) as a foundational approach that generalizes the idea of affinity-based weighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS defines A either through domain knowledge or by learning, and computes feature relevance through multi-hop propagation over the affinity graph. From this perspective, self-attention can be seen as a special case of Inf-FS: it uses a single-hop affinity computation where A is dynamically built from token similarities. We argue that the underlying structure, reasoning over pairwise relationships, is preserved across both approaches, and the key differences lie in how the affinity matrix is defined and applied. By situating self-attention within the broader paradigm of affinity-based computation, we unify several strands of machine learning research and highlight a common mathematical foundation that underpins diverse models and tasks.",
      "authors": [
        "Giorgio Roffo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:51:03+00:00",
          "link": "https://arxiv.org/abs/2507.14560v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14560",
        "HTML": "https://arxiv.org/html/2507.14560",
        "PDF": "https://arxiv.org/pdf/2507.14560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the conceptual origins of self-attention in Transformers, highlighting affinity matrices as a computational principle, without relating to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14755",
      "abstract": "We introduce a risk assessment framework for digital identification systems, as well as recommended best practices to enhance privacy, security, and other desirable properties in these systems. To generate these resources, we created a casebook of a wide range of digital identification systems, and we then applied expert analysis and critique to identify patterns. We piloted the framework on several reviews within our organization over a period of approximately one year, and found it to be robust and helpful for those reviews. This work is intended to inform product review and development, product policy, and standards efforts, and to help guide a consistent responsible approach to digital identification across the broader digital identification ecosystem.",
      "authors": [
        "Allison Woodruff",
        "Dirk Balfanz",
        "Will Drewry",
        "Mariana Raykova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:04:34+00:00",
          "link": "https://arxiv.org/abs/2507.14755v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "A Risk Assessment Framework for Digital Identification Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14755",
        "HTML": "https://arxiv.org/html/2507.14755",
        "PDF": "https://arxiv.org/pdf/2507.14755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a risk assessment framework for digital identification systems, which is not related to LLM training data processing or any data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15007",
      "abstract": "This research introduces an innovative voice-assisted debugging plugin for Python that transforms silent runtime errors into actionable audible diagnostics. By implementing a global exception hook architecture with pyttsx3 text-to-speech conversion and Tkinter-based GUI visualization, the solution delivers multimodal error feedback through parallel auditory and visual channels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01, n=50) compared to traditional stack-trace debugging, while enabling 78% faster error identification through vocalized exception classification and contextualization. The system achieves sub-1.2 second voice latency with under 18% CPU overhead during exception handling, vocalizing error types and consequences while displaying interactive tracebacks with documentation deep links. Criteria validate compatibility across Python 3.7+ environments on Windows, macOS, and Linux platforms. Needing only two lines of integration code, the plugin significantly boosts availability for aesthetically impaired designers and supports multitasking workflows through hands-free error medical diagnosis. Educational applications show particular promise, with pilot studies indicating 45% faster debugging skill acquisition among novice programmers. Future development will incorporate GPT-based repair suggestions and real-time multilingual translation to further advance auditory debugging paradigms. The solution represents a fundamental shift toward human-centric error diagnostics, bridging critical gaps in programming accessibility while establishing new standards for cognitive efficiency in software development workflows.",
      "authors": [
        "Sayed Mahbub Hasan Amiri",
        "Md. Mainul Islam",
        "Mohammad Shakhawat Hossen",
        "Sayed Majhab Hasan Amiri",
        "Mohammad Shawkat Ali Mamun",
        "Sk. Humaun Kabir and Naznin Akter"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:24:35+00:00",
          "link": "https://arxiv.org/abs/2507.15007v1",
          "size": "1137kb",
          "version": "v1"
        }
      ],
      "title": "Hear Your Code Fail, Voice-Assisted Debugging for Python",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15007",
        "PDF": "https://arxiv.org/pdf/2507.15007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a voice-assisted debugging tool for Python, focusing on error diagnostics and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15251",
      "abstract": "Large Language Models (LLMs) have shown great potential in Automated Program Repair (APR). Test inputs, being crucial for reasoning the root cause of failures, are always included in the prompt for LLM-based APR. Unfortunately, LLMs struggle to retain key information in long prompts. When the test inputs are extensive in the prompt, this may trigger the \"lost-in-the-middle\" issue, compromising repair performance. To address this, we propose ReduceFix, an LLM-based APR approach with a built-in component that automatically reduces test inputs while retaining their failure-inducing behavior. ReduceFix prompts an LLM to generate a reducer that minimizes failure-inducing test inputs without human effort, and then feeds the reduced failure-inducing inputs to guide patch generation.\n  For targeted evaluation, we constructed LFTBench, the first long-input APR benchmark with 200 real bugs from 20 programming tasks, each paired with a failure-inducing input whose median size is 1 MB. On this benchmark, ReduceFix shrinks inputs by 89.1% on average and improves overall pass@10 by up to 53.8% relative to a prompt that includes the original test, and by 17.6% compared with omitting the test entirely. Adding the same reduction step to ChatRepair increases its fix rate by 21.3% without other changes. Ablation studies further highlight the impact of input length and compressed failure information on repair success. These results underscore that automatically reducing failing inputs is a practical and powerful complement to LLM-based APR, significantly improving its scalability and effectiveness.",
      "authors": [
        "Boyang Yang",
        "Luyao Ren",
        "Xin Yin",
        "Jiadong Ren",
        "Haoye Tian",
        "Shunfu Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:26:32+00:00",
          "link": "https://arxiv.org/abs/2507.15251v1",
          "size": "556kb",
          "version": "v1"
        }
      ],
      "title": "Input Reduction Enhanced LLM-based Program Repair",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15251",
        "HTML": "https://arxiv.org/html/2507.15251",
        "PDF": "https://arxiv.org/pdf/2507.15251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes ReduceFix for automated program repair using LLMs, focusing on reduction of test inputs to improve repair performance. It tangentially involves data processing by minimizing test input, but does not contribute directly to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15452",
      "abstract": "We propose a geometry-aware strategy for training neural preconditioners tailored to parametrized linear systems arising from the discretization of mixed-dimensional partial differential equations (PDEs). These systems are typically ill-conditioned because of the presence of embedded lower-dimensional structures and are solved using Krylov subspace methods. Our approach yields an approximation of the inverse operator employing a learning algorithm consisting of a two-stage training framework: an initial static pre-training phase, based on residual minimization, followed by a dynamic fine-tuning phase that incorporates solver convergence dynamics into training via a novel loss functional. This dynamic loss is defined by the principal angles between the residuals and the Krylov subspaces. It is evaluated using a differentiable implementation of the Flexible GMRES algorithm, which enables backpropagation through both the Arnoldi process and Givens rotations. The resulting neural preconditioner is explicitly optimized to improve early-stage convergence and reduce iteration counts in a family of 3D-1D mixed-dimensional problems with geometric variability of the 1D domain. Numerical experiments show that our solver-aligned approach significantly improves convergence rate, robustness, and generalization.",
      "authors": [
        "Nunzio Dimola",
        "Alessandro Coclite",
        "Paolo Zunino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.15452v1",
          "size": "591kb",
          "version": "v1"
        }
      ],
      "title": "Neural Preconditioning via Krylov Subspace Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15452",
        "HTML": "https://arxiv.org/html/2507.15452",
        "PDF": "https://arxiv.org/pdf/2507.15452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses neural preconditioning for parametrized linear systems and does not focus on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15813",
      "abstract": "We propose a nonlinear elasto-plastic model, for which a specific class of hyperbolic elasticity arises as a straight consequence of the yield criterion invariance on the plasticity level. We superimpose this nonlinear elastic (or hyperelastic) behavior with plasticity obeying the associated flow rule. Interestingly, we find that a linear yield criterion on the thermodynamical force associated with plasticity results in a quadratic yield criterion in the stress space. This suggests a specific hyperelastic connection between Mohr-Coulomb and Hoek-Brown (or alternatively between Drucker-Prager and Pan-Hudson) yield criteria. We compare the elasto-plastic responses of standard tests for the Drucker-Prager yield criterion using either linear or the suggested hyperbolic elasticity. Notably, the nonlinear case stands out due to dilatancy saturation observed during cyclic loading in the triaxial compression test. We conclude this study with structural finite element simulations that clearly demonstrate the numerical applicability of the proposed model.",
      "authors": [
        "Ilaria Fontana",
        "Goustan Bacquaert",
        "Daniele A. Di Pietro",
        "Kyrylo Kazymyrenko"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Classical Physics (physics.class-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:20:41+00:00",
          "link": "https://arxiv.org/abs/2507.15813v1",
          "size": "4905kb",
          "version": "v1"
        }
      ],
      "title": "Hyperelastic nature of the Hoek-Brown criterion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15813",
        "HTML": "https://arxiv.org/html/2507.15813",
        "PDF": "https://arxiv.org/pdf/2507.15813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a nonlinear elasto-plastic model and hyperelasticity in material science, specifically focusing on yield criteria. It does not contribute to LLM training data processing or any aspect of language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18161",
      "abstract": "Scientific user facilities, such as synchrotron beamlines, are equipped with a wide array of hardware and software tools that require a codebase for human-computer-interaction. This often necessitates developers to be involved to establish connection between users/researchers and the complex instrumentation. The advent of generative AI presents an opportunity to bridge this knowledge gap, enabling seamless communication and efficient experimental workflows. Here we present a modular architecture for the Virtual Scientific Companion (VISION) by assembling multiple AI-enabled cognitive blocks that each scaffolds large language models (LLMs) for a specialized task. With VISION, we performed LLM-based operation on the beamline workstation with low latency and demonstrated the first voice-controlled experiment at an X-ray scattering beamline. The modular and scalable architecture allows for easy adaptation to new instrument and capabilities. Development on natural language-based scientific experimentation is a building block for an impending future where a science exocortex -- a synthetic extension to the cognition of scientists -- may radically transform scientific practice and discovery.",
      "authors": [
        "Shray Mathur and Noah van der Vleuten and Kevin Yager and Esther Tsai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T04:37:07+00:00",
          "link": "https://arxiv.org/abs/2412.18161v1",
          "size": "4811kb",
          "version": "v1"
        }
      ],
      "title": "VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18161",
        "HTML": "https://arxiv.org/html/2412.18161",
        "PDF": "https://arxiv.org/pdf/2412.18161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a modular AI assistant for human-instrument interaction at scientific facilities, focusing on LLM usage for natural language tasks, but not on training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.11475",
      "abstract": "This paper introduces LUCID-MA (Learning and Understanding Crime through Dialogue of Multiple Agents), an innovative AI powered framework where multiple AI agents collaboratively analyze and understand crime data. Our system that consists of three core components: an analysis assistant that highlights spatiotemporal crime patterns; a feedback component that reviews and refines analytical results; and a prediction component that forecasts future crime trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it runs completely offline and allows the agents undergo self-improvement through 100 rounds of communication with less human interaction. A scoring function is incorporated to evaluate agent performance, providing visual plots to track learning progress. This work demonstrates the potential of AutoGen-style agents for autonomous, scalable, and iterative analysis in social science domains, maintaining data privacy through offline execution. It also showcases a computational model with emergent intelligence, where the system's global behavior emerges from the interactions of its agents. This emergent behavior manifests as enhanced individual agent performance, driven by collaborative dialogue between the LLM-based agents.",
      "authors": [
        "Syeda Kisaa Fatima",
        "Tehreem Zubair",
        "Noman Ahmed and Asifullah Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T05:39:28+00:00",
          "link": "https://arxiv.org/abs/2506.11475v1",
          "size": "741kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T10:54:02+00:00",
          "link": "https://arxiv.org/abs/2506.11475v2",
          "size": "839kb",
          "version": "v2"
        }
      ],
      "title": "AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11475",
        "PDF": "https://arxiv.org/pdf/2506.11475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a multi-agent framework for crime data analysis and prediction. It focuses on agent collaboration and dialogue but does not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06060",
      "abstract": "Realistic, high-fidelity 3D facial animations are crucial for expressive avatar systems in human-computer interaction and accessibility. Although prior methods show promising quality, their reliance on the mesh domain limits their ability to fully leverage the rapid visual innovations seen in 2D computer vision and graphics. We propose VisualSpeaker, a novel method that bridges this gap using photorealistic differentiable rendering, supervised by visual speech recognition, for improved 3D facial animation. Our contribution is a perceptual lip-reading loss, derived by passing photorealistic 3D Gaussian Splatting avatar renders through a pre-trained Visual Automatic Speech Recognition model during training. Evaluation on the MEAD dataset demonstrates that VisualSpeaker improves both the standard Lip Vertex Error metric by 56.1% and the perceptual quality of the generated animations, while retaining the controllability of mesh-driven animation. This perceptual focus naturally supports accurate mouthings, essential cues that disambiguate similar manual signs in sign language avatars.",
      "authors": [
        "Alexandre Symeonidis-Herzig",
        "\\\"Ozge Mercano\\u{g}lu Sincan",
        "and Richard Bowden"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:04:17+00:00",
          "link": "https://arxiv.org/abs/2507.06060v1",
          "size": "3800kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:19:17+00:00",
          "link": "https://arxiv.org/abs/2507.06060v2",
          "size": "3800kb",
          "version": "v2"
        }
      ],
      "title": "VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06060",
        "HTML": "https://arxiv.org/html/2507.06060",
        "PDF": "https://arxiv.org/pdf/2507.06060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D avatar lip synthesis using visually-guided methods for facial animation, which is unrelated to LLM training data processing involving data collection, filtering, or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15222",
      "abstract": "Multidimensional item response theory is a statistical test theory used to estimate the latent skills of learners and the difficulty levels of problems based on test results. Both compensatory and non-compensatory models have been proposed in the literature. Previous studies have revealed the substantial underestimation of higher skills when the non-compensatory model is misspecified as the compensatory model. However, the underlying mechanism behind this phenomenon has not been fully elucidated. It remains unclear whether overestimation also occurs and whether issues arise regarding the variance of the estimated parameters. In this paper, we aim to provide a comprehensive understanding of both underestimation and overestimation through a theoretical approach. In addition to the previously identified underestimation of the skills, we newly discover that the overestimation of skills occurs around the origin. Furthermore, we investigate the extent to which the asymptotic variance of the estimated parameters differs when considering model misspecification compared to when it is not taken into account.",
      "authors": [
        "Hiroshi Tamano",
        "Hideitsu Hino and Daichi Mochihashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:52:09+00:00",
          "link": "https://arxiv.org/abs/2507.15222v1",
          "size": "687kb",
          "version": "v1"
        }
      ],
      "title": "Misspecifying non-compensatory as compensatory IRT: analysis of estimated skills and variance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15222",
        "HTML": "https://arxiv.org/html/2507.15222",
        "PDF": "https://arxiv.org/pdf/2507.15222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on multidimensional item response theory and statistical analysis of test theories, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.06830",
      "abstract": "Cookies maintain state across related web traffic. As such, cookies are commonly used for authentication by storing a user's session ID and replacing the need to re-enter credentials in subsequent traffic. These so-called ``session cookies'' are prime targets for attacks that aim to steal them to gain unauthorized access to user accounts. To mitigate these attacks, the Secure and HttpOnly cookie attributes limit a cookie's accessibility from malicious networks and websites. However, these controls overlook browser extensions: third-party HTML/JavaScript add-ons with access to privileged browser APIs and the ability to operate across multiple websites. Thus malicious or compromised extensions can provide unrestricted access to a user's session cookies.\n  In this work, we first analyze the prevalence of extensions with access to ``risky'' APIs (those that enable cookie modification and theft) and find that they have hundreds of millions of users. Motivated by this, we propose a mechanism to protect cookies from malicious extensions by introducing two new cookie attributes: BrowserOnly and Monitored. The BrowserOnly attribute prevents extension access to cookies altogether. While effective, not all cookies can be made inaccessible. Thus cookies with the Monitored attribute remain accessible but are tied to a single browser and any changes made to the cookie are logged. As a result, stolen Monitored cookies are unusable outside their original browser and servers can validate the modifications performed. To demonstrate the proposed functionalities, we design and implement CREAM (Cookie Restrictions for Extension Abuse Mitigation) a modified version of the open-source Chromium browser realizing these controls. Our evaluation indicates that CREAM effectively protects cookies from malicious extensions while incurring little run-time overheads.",
      "authors": [
        "Liam Tyler",
        "Ivan De Oliveira Nunes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-10T22:04:56+00:00",
          "link": "https://arxiv.org/abs/2405.06830v1",
          "size": "411kb",
          "version": "v1"
        },
        {
          "date": "2024-09-18T19:03:29+00:00",
          "link": "https://arxiv.org/abs/2405.06830v2",
          "size": "370kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:21:42+00:00",
          "link": "https://arxiv.org/abs/2405.06830v3",
          "size": "234kb",
          "version": "v3"
        }
      ],
      "title": "Towards Browser Controls to Protect Cookies from Malicious Extensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.06830",
        "HTML": "https://arxiv.org/html/2405.06830",
        "PDF": "https://arxiv.org/pdf/2405.06830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on designing browser controls to protect cookies from malicious extensions, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01511",
      "abstract": "The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and the complexities of constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated four advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%. All framework code, agent code, and task datasets are publicly available at https://github.com/camel-ai/crab.",
      "authors": [
        "Tianqi Xu",
        "Linyao Chen",
        "Dai-Jie Wu",
        "Yanjun Chen",
        "Zecheng Zhang",
        "Xiang Yao",
        "Zhiqiang Xie",
        "Yongchao Chen",
        "Shilong Liu",
        "Bochen Qian",
        "Anjie Yang",
        "Zhaoxuan Jin",
        "Jianbo Deng",
        "Philip Torr",
        "Bernard Ghanem",
        "Guohao Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T17:55:04+00:00",
          "link": "https://arxiv.org/abs/2407.01511v1",
          "size": "30775kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T11:29:39+00:00",
          "link": "https://arxiv.org/abs/2407.01511v2",
          "size": "30817kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T17:01:09+00:00",
          "link": "https://arxiv.org/abs/2407.01511v3",
          "size": "31241kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T13:42:07+00:00",
          "link": "https://arxiv.org/abs/2407.01511v4",
          "size": "31241kb",
          "version": "v4"
        }
      ],
      "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01511",
        "HTML": "https://arxiv.org/html/2407.01511",
        "PDF": "https://arxiv.org/pdf/2407.01511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces CRAB, a benchmark for evaluating Multimodal Language Models (MLMs) across environments. Although it involves constructing tasks and evaluators, the primary focus is on benchmarking and evaluation framework rather than training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/camel-ai/crab"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.05191",
      "abstract": "We prove that for any integers $\\alpha, \\beta > 1$, the existential fragment of the first-order theory of the structure $\\langle \\mathbb{Z}; 0,1,<, +, \\alpha^{\\mathbb{N}}, \\beta^{\\mathbb{N}}\\rangle$ is decidable (where $\\alpha^{\\mathbb{N}}$ is the set of positive integer powers of $\\alpha$, and likewise for $\\beta^{\\mathbb{N}}$). On the other hand, we show by way of hardness that decidability of the existential fragment of the theory of $\\langle \\mathbb{N}; 0,1, <, +, x\\mapsto \\alpha^x, x \\mapsto \\beta^x\\rangle$ for any multiplicatively independent $\\alpha,\\beta > 1$ would lead to mathematical breakthroughs regarding base-$\\alpha$ and base-$\\beta$ expansions of certain transcendental numbers.",
      "authors": [
        "Toghrul Karimov",
        "Florian Luca",
        "Joris Nieuwveld",
        "Jo\\\"el Ouaknine",
        "James Worrell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-06T21:30:27+00:00",
          "link": "https://arxiv.org/abs/2407.05191v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T14:27:49+00:00",
          "link": "https://arxiv.org/abs/2407.05191v2",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "title": "On the Decidability of Presburger Arithmetic Expanded with Powers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05191",
        "PDF": "https://arxiv.org/pdf/2407.05191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around mathematical logic and the decidability of Presburger Arithmetic, which is not related to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08493",
      "abstract": "Traditional robot navigation systems primarily utilize occupancy grid maps and laser-based sensing technologies, as demonstrated by the popular move_base package in ROS. Unlike robots, humans navigate not only through spatial awareness and physical distances but also by integrating external information, such as elevator maintenance updates from public notification boards and experiential knowledge, like the need for special access through certain doors. With the development of Large Language Models (LLMs), which possesses text understanding and intelligence close to human performance, there is now an opportunity to infuse robot navigation systems with a level of understanding akin to human cognition. In this study, we propose using osmAG (Area Graph in OpensStreetMap textual format), an innovative semantic topometric hierarchical map representation, to bridge the gap between the capabilities of ROS move_base and the contextual understanding offered by LLMs. Our methodology employs LLMs as an actual copilot in robot navigation, enabling the integration of a broader range of informational inputs while maintaining the robustness of traditional robotic navigation systems. Our code, demo, map, experiment results can be accessed at https://github.com/xiexiexiaoxiexie/Intelligent-LiDAR-Navigation-LLM-as-Copilot.",
      "authors": [
        "Fujing Xie",
        "Jiajie Zhang",
        "S\\\"oren Schwertfeger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T02:37:28+00:00",
          "link": "https://arxiv.org/abs/2409.08493v1",
          "size": "2836kb",
          "version": "v1"
        },
        {
          "date": "2025-03-23T07:53:53+00:00",
          "link": "https://arxiv.org/abs/2409.08493v2",
          "size": "2803kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T03:34:13+00:00",
          "link": "https://arxiv.org/abs/2409.08493v3",
          "size": "2804kb",
          "version": "v3"
        }
      ],
      "title": "Intelligent LiDAR Navigation: Leveraging External Information and Semantic Maps with LLM as Copilot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08493",
        "HTML": "https://arxiv.org/html/2409.08493",
        "PDF": "https://arxiv.org/pdf/2409.08493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves the use of LLMs to improve robot navigation by integrating external information, without any contribution to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/xiexiexiaoxiexie/intelligent-lidar-navigation-llm-as-copilot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10864",
      "abstract": "Objectives: Timely and accurate detection of colorectal polyps plays a crucial role in diagnosing and preventing colorectal cancer, a major cause of mortality worldwide. This study introduces a new, lightweight, and efficient framework for polyp detection that combines the Local Outlier Factor (LOF) algorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier removal techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene. Since these datasets originally lacked bounding box annotations, we converted their segmentation masks into suitable detection labels. To enhance the robustness and generalizability of our model, we apply 5-fold cross-validation and remove anomalous samples using the LOF method configured with 30 neighbors and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a fast and resource-efficient object detection architecture optimized for real-time applications. We train the model using a combination of modern augmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance, achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5 of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods, our model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited for real-time colonoscopy support in clinical settings. Overall, the study underscores how crucial data preprocessing and model efficiency are when designing effective AI systems for medical imaging.",
      "authors": [
        "Saadat Behzadi",
        "Danial Sharifrazi",
        "Bita Mesbahzadeh",
        "Javad Hassannataj Joloudari",
        "Roohallah Alizadehsani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:36:54+00:00",
          "link": "https://arxiv.org/abs/2507.10864v1",
          "size": "751kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:37:42+00:00",
          "link": "https://arxiv.org/abs/2507.10864v2",
          "size": "751kb",
          "version": "v2"
        }
      ],
      "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10864",
        "PDF": "https://arxiv.org/pdf/2507.10864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for real-time colorectal polyp detection, focusing on medical imaging and YOLO deep learning model improvements, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15100",
      "abstract": "Natural Language Inference (NLI) is the task of determining the semantic entailment of a premise for a given hypothesis. The task aims to develop systems that emulate natural human inferential processes where commonsense knowledge plays a major role. However, existing commonsense resources lack sufficient coverage for a variety of premise-hypothesis pairs. This study explores the potential of Large Language Models as commonsense knowledge generators for NLI along two key dimensions: their reliability in generating such knowledge and the impact of that knowledge on prediction accuracy. We adapt and modify existing metrics to assess LLM factuality and consistency in generating in this context. While explicitly incorporating commonsense knowledge does not consistently improve overall results, it effectively helps distinguish entailing instances and moderately improves distinguishing contradictory and neutral inferences.",
      "authors": [
        "Chathuri Jayaweera",
        "Brianna Yanqui",
        "Bonnie Dorr"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:42:45+00:00",
          "link": "https://arxiv.org/abs/2507.15100v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15100",
        "PDF": "https://arxiv.org/pdf/2507.15100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the use of LLMs to generate commonsense knowledge for NLI but primarily evaluates model performance rather than explicitly contributing to data processing methodologies for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2108.00452",
      "abstract": "Deciding the amalgamation property for a given class of finite structures is an important subroutine in classifying countable finitely homogeneous structures. We study the computational complexity of the amalgamation decision problem for finitely bounded classes, i.e., classes specified by a finite set of forbidden finite substructures, or equivalently by a finite set of universal axioms. We link the amalgamation decision problem to the problem of testing the containment between the reducts of two given finitely bounded amalgamation classes to a given common subset of their signatures. On the one hand, this link enables polynomial-time reductions from various decision problems that can be represented within the reduct containment problem for finitely bounded amalgamation classes, e.g., the 2-exponential square tiling problem, leading to a new lower bound for the complexity of the amalgamation decision problem: 2NEXPTIME-hardness. On the other hand, the link also allows us to show that the amalgamation decision problem is decidable under the assumption that every finitely bounded strong amalgamation class has a computable finitely bounded Ramsey expansion. The runtime of our conditional decision procedure depends double-exponentially on the size of a minimal Ramsey expansion. We subsequently prove that the closely related problem of testing homogenizability is already undecidable, by a polynomial-time reduction from the regularity of context-free languages. Our results indicate that the relationship between finitely bounded amalgamation classes and arbitrary finitely bounded classes shares similarities with the relationship between regular grammars and context-free grammars. A key difference is that the regularity of context-free grammars can be tested in linear time, while the problem of testing the amalgamation property for finitely bounded classes is 2NEXPTIME-hard.",
      "authors": [
        "Jakub Rydval"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-01T13:11:43+00:00",
          "link": "https://arxiv.org/abs/2108.00452v1",
          "size": "71kb",
          "version": "v1"
        },
        {
          "date": "2021-09-14T15:37:40+00:00",
          "link": "https://arxiv.org/abs/2108.00452v2",
          "size": "21kb",
          "version": "v2"
        },
        {
          "date": "2023-02-13T11:12:29+00:00",
          "link": "https://arxiv.org/abs/2108.00452v3",
          "size": "27kb",
          "version": "v3"
        },
        {
          "date": "2023-03-26T23:22:50+00:00",
          "link": "https://arxiv.org/abs/2108.00452v4",
          "size": "41kb",
          "version": "v4"
        },
        {
          "date": "2023-03-30T15:55:23+00:00",
          "link": "https://arxiv.org/abs/2108.00452v5",
          "size": "42kb",
          "version": "v5"
        },
        {
          "date": "2023-11-13T16:38:09+00:00",
          "link": "https://arxiv.org/abs/2108.00452v6",
          "size": "48kb",
          "version": "v6"
        },
        {
          "date": "2024-02-14T15:05:01+00:00",
          "link": "https://arxiv.org/abs/2108.00452v7",
          "size": "610kb",
          "version": "v7"
        },
        {
          "date": "2024-07-29T09:18:17+00:00",
          "link": "https://arxiv.org/abs/2108.00452v8",
          "size": "138kb",
          "version": "v8"
        },
        {
          "date": "2024-08-19T12:31:56+00:00",
          "link": "https://arxiv.org/abs/2108.00452v9",
          "size": "138kb",
          "version": "v9"
        },
        {
          "date": "2025-02-14T13:48:51+00:00",
          "link": "https://arxiv.org/abs/2108.00452v10",
          "size": "128kb",
          "version": "v10"
        },
        {
          "date": "2025-07-21T10:12:25+00:00",
          "link": "https://arxiv.org/abs/2108.00452v11",
          "size": "133kb",
          "version": "v11"
        }
      ],
      "title": "Finitely Bounded Homogeneity Turned Inside-Out",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.00452",
        "HTML": "https://arxiv.org/html/2108.00452",
        "PDF": "https://arxiv.org/pdf/2108.00452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computational complexity of the amalgamation decision problem for finitely bounded classes, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.16242",
      "abstract": "Knowledge Distillation (KD) transfers knowledge from large models to small models and has recently achieved remarkable success. However, the reliability of existing KD methods in real-world applications, especially under distribution shift, remains underexplored. Distribution shift refers to the data distribution drifts between the training and testing phases, and this can adversely affect the efficacy of KD. In this paper, we propose a unified and systematic framework \\textsc{ShiftKD} to benchmark KD against two general distributional shifts: diversity and correlation shift. The evaluation benchmark covers more than 30 methods from algorithmic, data-driven, and optimization perspectives for five benchmark datasets. Our development of \\textsc{ShiftKD} conducts extensive experiments and reveals strengths and limitations of current SOTA KD methods. More importantly, we thoroughly analyze key factors in student model training process, including data augmentation, pruning methods, optimizers, and evaluation metrics. We believe \\textsc{ShiftKD} could serve as an effective benchmark for assessing KD in real-world scenarios, thus driving the development of more robust KD methods in response to evolving demands. The code will be made available upon publication.",
      "authors": [
        "Songming Zhang and Yuxiao Luo and Ziyu Lyu and Xiaofeng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-25T10:43:31+00:00",
          "link": "https://arxiv.org/abs/2312.16242v1",
          "size": "1817kb",
          "version": "v1"
        },
        {
          "date": "2024-01-07T08:52:37+00:00",
          "link": "https://arxiv.org/abs/2312.16242v2",
          "size": "1815kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T01:30:46+00:00",
          "link": "https://arxiv.org/abs/2312.16242v3",
          "size": "11594kb",
          "version": "v3"
        }
      ],
      "title": "ShiftKD: Benchmarking Knowledge Distillation under Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.16242",
        "HTML": "https://arxiv.org/html/2312.16242",
        "PDF": "https://arxiv.org/pdf/2312.16242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking Knowledge Distillation (KD) under distribution shift, which is unrelated to LLM training data processing, as it does not address data preprocessing, collection, or dataset creation for LLMs."
      },
      "tasks": [
        "Data Augmentation",
        "Diversity",
        "Knowledge Distillation"
      ],
      "repo_urls": [
        "https://github.com/zzhangsm/ookd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05351",
      "abstract": "In recent years, miniature wall-climbing robots have attracted widespread attention due to their significant potential in equipment inspection and in-situ repair applications. Traditional wall-climbing systems typically rely on electromagnetic, electrostatic, vacuum suction, or van der Waals forces for controllable adhesion. However, these conventional methods impose limitations when striving for both a compact design and high-speed mobility. This paper proposes a novel Vibration-Based Adhesion (VBA) technique, which utilizes a flexible disk vibrating near a surface to generate a strong and controllable attractive force without direct contact. By employing an electric motor as the vibration source, the constructed VBA system was experimentally evaluated, achieving an adhesion-to-weight ratio exceeding 51 times. The experimental results demonstrate that this adhesion mechanism not only provides a high normal force but also maintains minimal shear force, making it particularly suitable for high-speed movement and heavy load applications in miniature wall-climbing robots.",
      "authors": [
        "Siqian Li",
        "Xi Wang",
        "Jung-Che Chang",
        "Xin Dong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T16:51:36+00:00",
          "link": "https://arxiv.org/abs/2504.05351v1",
          "size": "401kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T21:32:24+00:00",
          "link": "https://arxiv.org/abs/2504.05351v2",
          "size": "279kb",
          "version": "v2"
        }
      ],
      "title": "Design and Characterization of a Micro-Vibration Adhesion System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05351",
        "PDF": "https://arxiv.org/pdf/2504.05351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel adhesion technology for wall-climbing robots, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12087",
      "abstract": "Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned Aerial Vehicle (UAV) perspective is a highly challenging computer vision task. The difficulty stems from three main sources: the extreme scarcity of target appearance features, the complex motion entanglement caused by the combined dynamics of the camera and the targets themselves, and the frequent occlusions and identity ambiguity arising from dense flocking behavior. This paper details our championship-winning solution in the MVA 2025 \"Finding Birds\" Small Multi-Object Tracking Challenge (SMOT4SB), which adopts the tracking-by-detection paradigm with targeted innovations at both the detection and association levels. On the detection side, we propose a systematic training enhancement framework named \\textbf{SliceTrain}. This framework, through the synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic augmentation, effectively addresses the problem of insufficient learning for small objects in high-resolution image training. On the tracking side, we designed a robust tracker that is completely independent of appearance information. By integrating a \\textbf{motion direction maintenance (EMA)} mechanism and an \\textbf{adaptive similarity metric} combining \\textbf{bounding box expansion and distance penalty} into the OC-SORT framework, our tracker can stably handle irregular motion and maintain target identities. Our method achieves state-of-the-art performance on the SMOT4SB public test set, reaching an SO-HOTA score of \\textbf{55.205}, which fully validates the effectiveness and advancement of our framework in solving complex real-world SMOT problems. The source code will be made available at https://github.com/Salvatore-Love/YOLOv8-SMOT.",
      "authors": [
        "Xiang Yu and Xinyao Liu and Guang Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:51:19+00:00",
          "link": "https://arxiv.org/abs/2507.12087v1",
          "size": "362kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:16:24+00:00",
          "link": "https://arxiv.org/abs/2507.12087v2",
          "size": "361kb",
          "version": "v2"
        }
      ],
      "title": "YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12087",
        "HTML": "https://arxiv.org/html/2507.12087",
        "PDF": "https://arxiv.org/pdf/2507.12087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a framework for small object tracking in UAV perspectives and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14352",
      "abstract": "Recommender systems are known to exhibit fairness issues, particularly on the product side, where products and their associated suppliers receive unequal exposure in recommended results. While this problem has been widely studied in traditional recommendation settings, its implications for bundle recommendation (BR) remain largely unexplored. This emerging task introduces additional complexity: recommendations are generated at the bundle level, yet user satisfaction and product (or supplier) exposure depend on both the bundle and the individual items it contains. Existing fairness frameworks and metrics designed for traditional recommender systems may not directly translate to this multi-layered setting. In this paper, we conduct a comprehensive reproducibility study of product-side fairness in BR across three real-world datasets using four state-of-the-art BR methods. We analyze exposure disparities at both the bundle and item levels using multiple fairness metrics, uncovering important patterns. Our results show that exposure patterns differ notably between bundles and items, revealing the need for fairness interventions that go beyond bundle-level assumptions. We also find that fairness assessments vary considerably depending on the metric used, reinforcing the need for multi-faceted evaluation. Furthermore, user behavior plays a critical role: when users interact more frequently with bundles than with individual items, BR systems tend to yield fairer exposure distributions across both levels. Overall, our findings offer actionable insights for building fairer bundle recommender systems and establish a vital foundation for future research in this emerging domain.",
      "authors": [
        "Huy-Son Nguyen",
        "Yuanna Liu",
        "Masoud Mansoury",
        "Mohammad Alian Nejadi",
        "Alan Hanjalic and Maarten de Rijke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T20:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.14352v1",
          "size": "2234kb",
          "version": "v1"
        }
      ],
      "title": "A Reproducibility Study of Product-side Fairness in Bundle Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14352",
        "HTML": "https://arxiv.org/html/2507.14352",
        "PDF": "https://arxiv.org/pdf/2507.14352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses fairness in bundle recommendation systems, which is not related to LLM training data processing or the improvement of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14613",
      "abstract": "Recent advances in medical image segmentation have been driven by deep learning; however, most existing methods remain limited by modality-specific designs and exhibit poor adaptability to dynamic medical imaging scenarios. The Segment Anything Model 2 (SAM2) and its related variants, which introduce a streaming memory mechanism for real-time video segmentation, present new opportunities for prompt-based, generalizable solutions. Nevertheless, adapting these models to medical video scenarios typically requires large-scale datasets for retraining or transfer learning, leading to high computational costs and the risk of catastrophic forgetting. To address these challenges, we propose DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature extraction with minimal parameter overhead. This design enables effective fine-tuning of SAM2 on medical videos with limited training data. Unlike existing adapter-based methods focused solely on static images, DD-SAM2 fully exploits SAM2's streaming memory for medical video object tracking and segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation) and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best of our knowledge, this work provides an initial attempt at systematically exploring adapter-based SAM2 fine-tuning for medical video segmentation and tracking. Code, datasets, and models will be publicly available at https://github.com/apple1986/DD-SAM2.",
      "authors": [
        "Guoping Xu",
        "Christopher Kabat",
        "You Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:19:55+00:00",
          "link": "https://arxiv.org/abs/2507.14613v1",
          "size": "1674kb",
          "version": "v1"
        }
      ],
      "title": "Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14613",
        "PDF": "https://arxiv.org/pdf/2507.14613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes an adaptation framework for medical video segmentation models focusing on depthwise-dilated convolutions for SAM2. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15219",
      "abstract": "Despite their potential, recent research has demonstrated that LLM agents are vulnerable to prompt injection attacks, where malicious prompts are injected into the agent's input, causing it to perform an attacker-specified task rather than the intended task provided by the user. In this paper, we present PromptArmor, a simple yet effective defense against prompt injection attacks. Specifically, PromptArmor prompts an off-the-shelf LLM to detect and remove potential injected prompts from the input before the agent processes it. Our results show that PromptArmor can accurately identify and remove injected prompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves both a false positive rate and a false negative rate below 1% on the AgentDojo benchmark. Moreover, after removing injected prompts with PromptArmor, the attack success rate drops to below 1%. We also demonstrate PromptArmor's effectiveness against adaptive attacks and explore different strategies for prompting an LLM. We recommend that PromptArmor be adopted as a standard baseline for evaluating new defenses against prompt injection attacks.",
      "authors": [
        "Tianneng Shi",
        "Kaijie Zhu",
        "Zhun Wang",
        "Yuqi Jia",
        "Will Cai",
        "Weida Liang",
        "Haonan Wang",
        "Hend Alzahrani",
        "Joshua Lu",
        "Kenji Kawaguchi",
        "Basel Alomair",
        "Xuandong Zhao",
        "William Yang Wang",
        "Neil Gong",
        "Wenbo Guo",
        "Dawn Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:41:44+00:00",
          "link": "https://arxiv.org/abs/2507.15219v1",
          "size": "199kb",
          "version": "v1"
        }
      ],
      "title": "PromptArmor: Simple yet Effective Prompt Injection Defenses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15219",
        "HTML": "https://arxiv.org/html/2507.15219",
        "PDF": "https://arxiv.org/pdf/2507.15219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PromptArmor focuses on defending against prompt injection attacks on LLMs, which involves detection and removal of malicious prompts, not processing of pretraining or fine-tuning datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15520",
      "abstract": "Recent Transformer-based low-light enhancement methods have made promising progress in recovering global illumination. However, they still struggle with non-uniform lighting scenarios, such as backlit and shadow, appearing as over-exposure or inadequate brightness restoration. To address this challenge, we present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer) framework that enables accurate illumination restoration. Specifically, we propose a dynamic integral image representation to model the spatially-varying illumination, and further construct a novel Spatially-Adaptive Integral Illumination Estimator ($\\text{SAI}^2\\text{E}$). Moreover, we introduce an Illumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which leverages the illumination to calibrate the lightness-relevant features toward visual-pleased illumination enhancement. Extensive experiments on five standard low-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our SAIGFormer significantly outperforms state-of-the-art methods in both quantitative and qualitative metrics. In particular, our method achieves superior performance in non-uniform illumination enhancement while exhibiting strong generalization capabilities across multiple datasets. Code is available at https://github.com/LHTcode/SAIGFormer.git.",
      "authors": [
        "Hanting Li",
        "Fei Zhou",
        "Xin Sun",
        "Yang Hua",
        "Jungong Han",
        "Liang-Jie Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:38:56+00:00",
          "link": "https://arxiv.org/abs/2507.15520v1",
          "size": "24075kb",
          "version": "v1"
        }
      ],
      "title": "SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15520",
        "HTML": "https://arxiv.org/html/2507.15520",
        "PDF": "https://arxiv.org/pdf/2507.15520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a Transformer-based network for low-light image enhancement, unrelated to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15620",
      "abstract": "Constructing cell developmental trajectories is a critical task in single-cell RNA sequencing (scRNA-seq) analysis, enabling the inference of potential cellular progression paths. However, current automated methods are limited to establishing cell developmental trajectories within individual samples, necessitating biologists to manually link cells across samples to construct complete cross-sample evolutionary trajectories that consider cellular spatial dynamics. This process demands substantial human effort due to the complex spatial correspondence between each pair of samples. To address this challenge, we first proposed a GNN-based model to predict cross-sample cell developmental trajectories. We then developed TrajLens, a visual analytics system that supports biologists in exploring and refining the cell developmental trajectories based on predicted links. Specifically, we designed the visualization that integrates features on cell distribution and developmental direction across multiple samples, providing an overview of the spatial evolutionary patterns of cell populations along trajectories. Additionally, we included contour maps superimposed on the original cell distribution data, enabling biologists to explore them intuitively. To demonstrate our system's performance, we conducted quantitative evaluations of our model with two case studies and expert interviews to validate its usefulness and effectiveness.",
      "authors": [
        "Qipeng Wang",
        "Shaolun Ruan",
        "Rui Sheng",
        "Yong Wang",
        "Min Zhu",
        "Huamin Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:44:01+00:00",
          "link": "https://arxiv.org/abs/2507.15620v1",
          "size": "2841kb",
          "version": "v1"
        }
      ],
      "title": "TrajLens: Visual Analysis for Constructing Cell Developmental Trajectories in Cross-Sample Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15620",
        "HTML": "https://arxiv.org/html/2507.15620",
        "PDF": "https://arxiv.org/pdf/2507.15620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on constructing cell developmental trajectories using scRNA-seq analysis and visual analytics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.05182",
      "abstract": "An unsplittable multiflow routes the demand of each commodity along a single path from its source to its sink node. As our main result, we prove that in series-parallel digraphs, any given multiflow can be expressed as a convex combination of unsplittable multiflows, where the total flow on any arc deviates from the given flow by less than the maximum demand of any commodity. This result confirms a 25-year-old conjecture by Goemans for single-source unsplittable flows, as well as a stronger recent conjecture by Morell and Skutella, for series-parallel digraphs - even for general multiflow instances where commodities have distinct source and sink nodes. Previously, no non-trivial class of digraphs was known for which either conjecture holds. En route to proving this result, we also establish strong integrality results for multiflows on series-parallel digraphs, showing that their computation can be reduced to a simple single-commodity network flow problem.",
      "authors": [
        "Mohammed Majthoub Almoghrabi",
        "Martin Skutella",
        "Philipp Warode"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T17:02:34+00:00",
          "link": "https://arxiv.org/abs/2412.05182v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:54:12+00:00",
          "link": "https://arxiv.org/abs/2412.05182v2",
          "size": "38kb",
          "version": "v2"
        }
      ],
      "title": "Integer and Unsplittable Multiflows in Series-Parallel Digraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05182",
        "PDF": "https://arxiv.org/pdf/2412.05182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with unsplittable multiflows and series-parallel digraphs, which is a topic in network flow modeling and has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14376",
      "abstract": "Schema matching is essential for integrating heterogeneous data sources and enhancing dataset discovery, yet it remains a complex and resource-intensive problem. We introduce SCHEMORA, a schema matching framework that combines large language models with hybrid retrieval techniques in a prompt-based approach, enabling efficient identification of candidate matches without relying on labeled training data or exhaustive pairwise comparisons. By enriching schema metadata and leveraging both vector-based and lexical retrieval, SCHEMORA improves matching accuracy and scalability. Evaluated on the MIMIC-OMOP benchmark, it establishes new state-of-the-art performance, with gains of 7.49% in HitRate@5 and 3.75% in HitRate@3 over previous best results. To our knowledge, this is the first LLM-based schema matching method with an open-source implementation, accompanied by analysis that underscores the critical role of retrieval and provides practical guidance on model selection.",
      "authors": [
        "Osman Erman Gungor",
        "Derak Paulsen",
        "William Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.14376v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14376",
        "HTML": "https://arxiv.org/html/2507.14376",
        "PDF": "https://arxiv.org/pdf/2507.14376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on schema matching using LLMs, which involves dataset integration through schema matching but does not directly address LLM training data processing such as dataset creation or quality improvement operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14406",
      "abstract": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still occasionally make mistakes. However, adopting AI models in risk-sensitive domains often requires error rates near 0%. To address this gap, we propose collaboration between a reasoning model and a human expert who resolves queries the model cannot confidently answer. We find that quantifying the uncertainty of a reasoning model through the length of its reasoning trace yields an effective basis for deferral to a human, e.g., cutting the error rate of Qwen3 235B-A22B on difficult MATH problems from 3% to less than 1% when deferring 7.5% of queries. However, the high latency of reasoning models still makes them challenging to deploy on use cases with high query volume. To address this challenge, we explore fronting a reasoning model with a large non-reasoning model. We call this modified human-in-the-loop system \"Fail Fast, or Ask\", since the non-reasoning model may defer difficult queries to the human expert directly (\"failing fast\"), without incurring the reasoning model's higher latency. We show that this approach yields around 40% latency reduction and about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the accuracy-rejection curve. However, we observe that latency savings are lower than expected because of \"latency drag\", the phenomenon that processing easier queries with a non-reasoning model pushes the reasoning model's latency distribution towards longer latencies. Broadly, our results suggest that the deficiencies of state-of-the-art reasoning models -- nontrivial error rates and high latency -- can be substantially mitigated through black-box systems engineering, without requiring access to LLM internals.",
      "authors": [
        "Michael J. Zellinger and Matt Thomson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T23:25:26+00:00",
          "link": "https://arxiv.org/abs/2507.14406v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14406",
        "HTML": "https://arxiv.org/html/2507.14406",
        "PDF": "https://arxiv.org/pdf/2507.14406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reducing reasoning LLMs' error rates and latency through human-in-the-loop systems rather than discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14499",
      "abstract": "This paper introduces the Neural-Brownian Motion (NBM), a new class of stochastic processes for modeling dynamics under learned uncertainty. The NBM is defined axiomatically by replacing the classical martingale property with respect to linear expectation with one relative to a non-linear Neural Expectation Operator, $\\varepsilon^\\theta$, generated by a Backward Stochastic Differential Equation (BSDE) whose driver $f_\\theta$ is parameterized by a neural network. Our main result is a representation theorem for a canonical NBM, which we define as a continuous $\\varepsilon^\\theta$-martingale with zero drift under the physical measure. We prove that, under a key structural assumption on the driver, such a canonical NBM exists and is the unique strong solution to a stochastic differential equation of the form ${\\rm d} M_t = \\nu_\\theta(t, M_t) {\\rm d} W_t$. Crucially, the volatility function $\\nu_\\theta$ is not postulated a priori but is implicitly defined by the algebraic constraint $g_\\theta(t, M_t, \\nu_\\theta(t, M_t)) = 0$, where $g_\\theta$ is a specialization of the BSDE driver. We develop the stochastic calculus for this process and prove a Girsanov-type theorem for the quadratic case, showing that an NBM acquires a drift under a new, learned measure. The character of this measure, whether pessimistic or optimistic, is endogenously determined by the learned parameters $\\theta$, providing a rigorous foundation for models where the attitude towards uncertainty is a discoverable feature.",
      "authors": [
        "Qian Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:09:52+00:00",
          "link": "https://arxiv.org/abs/2507.14499v1",
          "size": "89kb",
          "version": "v1"
        }
      ],
      "title": "Neural Brownian Motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14499",
        "HTML": "https://arxiv.org/html/2507.14499",
        "PDF": "https://arxiv.org/pdf/2507.14499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Neural Brownian Motion for modeling dynamics with learned uncertainty, which is not related to LLM training data processing or dataset generation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15391",
      "abstract": "The MPLS Network Actions (MNA) framework enhances MPLS forwarding with a generalized encoding for manifold extensions such as network slicing and in-situ OAM (IOAM). Network actions in MNA are encoded in Label Stack Entries (LSEs) and are added to the MPLS stack. Routers have a physical limit on the number of LSEs they can read, called the readable label depth (RLD). With MNA, routers must be able to process a minimum number of LSEs which requires a relatively large RLD. In this paper, we perform a hardware analysis of an MNA implementation and identify the reason for a large RLD requirement in the MNA protocol design. Based on this, we present a mechanism that reduces the required RLD for MNA nodes by restructuring the MPLS stack during forwarding. We then introduce the novel stack management network action that enables the proposed mechanism as well as its integration in networks with MNA-incapable nodes. The feasibility of the mechanism on programmable hardware is verified by providing a P4-based implementation. Further, the effects on the required RLD, ECMP, and packet overhead are discussed.",
      "authors": [
        "Fabian Ihle and Michael Menth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:49:47+00:00",
          "link": "https://arxiv.org/abs/2507.15391v1",
          "size": "4160kb",
          "version": "v1"
        }
      ],
      "title": "Stack Management for MPLS Network Actions: Integration of Nodes with Limited Hardware Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15391",
        "HTML": "https://arxiv.org/html/2507.15391",
        "PDF": "https://arxiv.org/pdf/2507.15391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on stack management for MPLS networks, involving network protocols and hardware capabilities, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15576",
      "abstract": "Terahertz (THz) imaging enables non-invasive analysis for applications such as security screening and material classification, but effective image classification remains challenging due to limited annotations, low resolution, and visual ambiguity. We introduce In-Context Learning (ICL) with Vision-Language Models (VLMs) as a flexible, interpretable alternative that requires no fine-tuning. Using a modality-aligned prompting framework, we adapt two open-weight VLMs to the THz domain and evaluate them under zero-shot and one-shot settings. Our results show that ICL improves classification and interpretability in low-data regimes. This is the first application of ICL-enhanced VLMs to THz imaging, offering a promising direction for resource-constrained scientific domains. Code: \\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub repository}.",
      "authors": [
        "Nicolas Poggi",
        "Shashank Agnihotri",
        "Margret Keuper"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:57:49+00:00",
          "link": "https://arxiv.org/abs/2507.15576v1",
          "size": "4152kb",
          "version": "v1"
        }
      ],
      "title": "Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15576",
        "HTML": "https://arxiv.org/html/2507.15576",
        "PDF": "https://arxiv.org/pdf/2507.15576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper details the use of Vision-Language Models (VLMs) and In-Context Learning for THz imaging. It does not relate to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.08879",
      "abstract": "An equiangular tight frame (ETF) is a finite sequence of equal norm vectors in a Hilbert space that achieves equality in the Welch bound, and so has minimal coherence. The binder of an ETF is the set of all subsets of its indices whose corresponding vectors form a regular simplex. An ETF achieves equality in Donoho and Elad's spark bound if and only if its binder is nonempty. When this occurs, its binder is the set of all linearly dependent subsets of it of minimal size. Moreover, if members of the binder form a balanced incomplete block design (BIBD) then its incidence matrix can be phased to produce a sparse representation of its dual (Naimark complement). A few infinite families of ETFs are known to have this remarkable property. In this paper, we relate this property to the recently introduced concept of a doubly transitive equiangular tight frame (DTETF), namely an ETF for which the natural action of its symmetry group is doubly transitive. In particular, we show that the binder of any DTETF is either empty or forms a BIBD, and moreover that when the latter occurs, any member of the binder of its dual is an oval of this BIBD. We then apply this general theory to certain known infinite families of DTETFs. Specifically, any symplectic form on a finite vector space yields a DTETF, and we compute the binder of it and its dual, showing that the former is empty except in a single notable case, and that the latter consists of affine Lagrangian subspaces. This unifies and generalizes several results from the existing literature. We then consider the binders of four infinite families of DTETFs that arise from quadratic forms over the field of two elements, showing that two of these are empty except in a finite number of cases, whereas the other two form BIBDs that relate to each other, and to Lagrangian subspaces, in nonobvious ways.",
      "authors": [
        "Matthew Fickus and Evan C. Lake"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Functional Analysis (math.FA)",
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-17T13:53:45+00:00",
          "link": "https://arxiv.org/abs/2302.08879v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:01:31+00:00",
          "link": "https://arxiv.org/abs/2302.08879v2",
          "size": "60kb",
          "version": "v2"
        }
      ],
      "title": "Doubly transitive equiangular tight frames that contain regular simplices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.08879",
        "PDF": "https://arxiv.org/pdf/2302.08879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of equiangular tight frames and does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05255",
      "abstract": "In submodular multiway partition (SUB-MP), the input is a non-negative submodular function $f:2^V \\rightarrow \\mathbb{R}_{\\ge 0}$ given by an evaluation oracle along with $k$ terminals $t_1, t_2, \\ldots, t_k\\in V$. The goal is to find a partition $V_1, V_2, \\ldots, V_k$ of $V$ with $t_i\\in V_i$ for every $i\\in [k]$ in order to minimize $\\sum_{i=1}^k f(V_i)$. In this work, we focus on SUB-MP when the input function is monotone (termed MONO-SUB-MP). MONO-SUB-MP formulates partitioning problems over several interesting structures -- e.g., matrices, matroids, graphs, and hypergraphs. MONO-SUB-MP is NP-hard since the graph multiway cut problem can be cast as a special case. We investigate the approximability of MONO-SUB-MP: we show that it admits a $4/3$-approximation and does not admit a $(10/9-\\epsilon)$-approximation for every constant $\\epsilon>0$. Next, we study a special case of MONO-SUB-MP where the monotone submodular function of interest is the coverage function of an input graph, termed GRAPH-COVERAGE-MP. GRAPH-COVERAGE-MP is equivalent to the classic multiway cut problem for the purposes of exact optimization. We show that GRAPH-COVERAGE-MP admits a $1.125$-approximation and does not admit a $(1.00074-\\epsilon)$-approximation for every constant $\\epsilon>0$ assuming the Unique Games Conjecture. These results separate GRAPH-COVERAGE-MP from graph multiway cut in terms of approximability.",
      "authors": [
        "Richard Bi",
        "Karthekeyan Chandrasekaran and Soham Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T01:04:07+00:00",
          "link": "https://arxiv.org/abs/2411.05255v1",
          "size": "634kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:46:52+00:00",
          "link": "https://arxiv.org/abs/2411.05255v2",
          "size": "637kb",
          "version": "v2"
        }
      ],
      "title": "Monotone Submodular Multiway Partition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05255",
        "PDF": "https://arxiv.org/pdf/2411.05255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses the approximation algorithms for submodular multiway partition problems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.16348",
      "abstract": "Is it possible to articulate a conception of consciousness that is compatible with the exotic characteristics of contemporary, disembodied AI systems, and that can stand up to philosophical scrutiny? How would subjective time and selfhood show up for an entity that conformed to such a conception? Trying to answer these questions, even metaphorically, stretches the language of consciousness to breaking point. Ultimately, the attempt yields something like emptiness, in the Buddhist sense, and helps to undermine our dualistic inclinations towards subjectivity and selfhood.",
      "authors": [
        "Murray Shanahan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T17:05:16+00:00",
          "link": "https://arxiv.org/abs/2503.16348v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T12:35:35+00:00",
          "link": "https://arxiv.org/abs/2503.16348v2",
          "size": "61kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T13:42:04+00:00",
          "link": "https://arxiv.org/abs/2503.16348v3",
          "size": "58kb",
          "version": "v3"
        }
      ],
      "title": "Palatable Conceptions of Disembodied Being",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16348",
        "HTML": "https://arxiv.org/html/2503.16348",
        "PDF": "https://arxiv.org/pdf/2503.16348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a philosophical exploration of consciousness in AI and does not involve any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.01216",
      "abstract": "Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical settings, presenting opportunities for automated detection to identify patients. This study evaluates natural language processing approaches for detecting PTSD from clinical interview transcripts. We compared general and mental health-specific transformer models (BERT/RoBERTa), embedding-based methods (SentenceBERT/LLaMA), and large language model prompting strategies (zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset. Domain-specific end-to-end models significantly outperformed general models (Mental-RoBERTa AUPRC=0.675+/-0.084 vs. RoBERTa-base 0.599+/-0.145). SentenceBERT embeddings with neural networks achieved the highest overall performance (AUPRC=0.758+/-0.128). Few-shot prompting using DSM-5 criteria yielded competitive results with two examples (AUPRC=0.737). Performance varied significantly across symptom severity and comorbidity status with depression, with higher accuracy for severe PTSD cases and patients with comorbid depression. Our findings highlight the potential of domain-adapted embeddings and LLMs for scalable screening while underscoring the need for improved detection of nuanced presentations and offering insights for developing clinically viable AI tools for PTSD assessment.",
      "authors": [
        "Feng Chen",
        "Dror Ben-Zeev",
        "Gillian Sparks",
        "Arya Kadakia",
        "Trevor Cohen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T22:06:28+00:00",
          "link": "https://arxiv.org/abs/2504.01216v1",
          "size": "349kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:49:45+00:00",
          "link": "https://arxiv.org/abs/2504.01216v2",
          "size": "405kb",
          "version": "v2"
        }
      ],
      "title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01216",
        "PDF": "https://arxiv.org/pdf/2504.01216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates various NLP models for detecting PTSD, comparing general and mental health-specific models and LLM prompting strategies. However, its main focus is on model evaluation and PTSD detection, rather than on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14451",
      "abstract": "Reliability on cloud providers for ASR inference to support child-centered voice-based applications is becoming challenging due to regulatory and privacy challenges. Motivated by a privacy-preserving design, this study aims to develop a lightweight & efficient Whisper ASR system capable of running on a Raspberry Pi. Upon evaluation of the MyST corpus and by examining various filtering strategies to fine-tune the `tiny.en' model, a Word Error Rate (WER) of 15.9% was achieved (11.8% filtered). A low-rank compression reduces the encoder size by 0.51M with 1.26x faster inference in GPU, with 11% relative WER increase. During inference on Pi, the compressed version required ~2 GFLOPS fewer computations. The RTF for both the models ranged between [0.23-0.41] for various input audio durations. Analyzing the RAM usage and CPU temperature showed that the PI was capable of handling both the tiny models, however it was noticed that small models initiated additional overhead/thermal throttling.",
      "authors": [
        "Satwik Dutta",
        "Shruthigna Chandupatla",
        "John Hansen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Human-Computer Interaction (cs.HC)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:55:48+00:00",
          "link": "https://arxiv.org/abs/2507.14451v1",
          "size": "674kb",
          "version": "v1"
        }
      ],
      "title": "Adapting Whisper for Lightweight and Efficient Automatic Speech Recognition of Children for On-device Edge Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14451",
        "HTML": "https://arxiv.org/html/2507.14451",
        "PDF": "https://arxiv.org/pdf/2507.14451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper adapts Whisper for speech recognition with some mention of fine-tuning and filtering strategies; however, it primarily focuses on model compression and inference efficiency, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15003",
      "abstract": "The future of software engineering--SE 3.0--is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software engineering, AIDev offers structured, open data to support research in benchmarking, agent readiness, optimization, collaboration modeling, and AI governance. The dataset includes rich metadata on PRs, authorship, review timelines, code changes, and integration outcomes--enabling exploration beyond synthetic benchmarks like SWE-bench. For instance, although agents often outperform humans in speed, their PRs are accepted less frequently, revealing a trust and utility gap. Furthermore, while agents accelerate code submission--one developer submitted as many PRs in three days as they had in three years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for the SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev enables a new generation of research into AI-native workflows and supports building the next wave of symbiotic human-AI collaboration. The dataset is publicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering Agent",
      "authors": [
        "Hao Li",
        "Haoxiang Zhang",
        "Ahmed E. Hassan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:15:58+00:00",
          "link": "https://arxiv.org/abs/2507.15003v1",
          "size": "236kb",
          "version": "v1"
        }
      ],
      "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15003",
        "HTML": "https://arxiv.org/html/2507.15003",
        "PDF": "https://arxiv.org/pdf/2507.15003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on autonomous coding agents and introduces the AIDev dataset pertaining to software engineering, which is not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15308",
      "abstract": "Due to the limited training samples in few-shot object detection (FSOD), we observe that current methods may struggle to accurately extract effective features from each channel. Specifically, this issue manifests in two aspects: i) channels with high weights may not necessarily be effective, and ii) channels with low weights may still hold significant value. To handle this problem, we consider utilizing the inter-channel correlation to facilitate the novel model's adaptation process to novel conditions, ensuring the model can correctly highlight effective channels and rectify those incorrect ones. Since the channel sequence is also 1-dimensional, its similarity with the temporal sequence inspires us to take Mamba for modeling the correlation in the channel sequence. Based on this concept, we propose a Spatial-Channel State Space Modeling (SCSM) module for spatial-channel state modeling, which highlights the effective patterns and rectifies those ineffective ones in feature channels. In SCSM, we design the Spatial Feature Modeling (SFM) module to balance the learning of spatial relationships and channel relationships, and then introduce the Channel State Modeling (CSM) module based on Mamba to learn correlation in channels. Extensive experiments on the VOC and COCO datasets show that the SCSM module enables the novel detector to improve the quality of focused feature representation in channels and achieve state-of-the-art performance.",
      "authors": [
        "Zhimeng Xin",
        "Tianxu Wu",
        "Yixiong Zou",
        "Shiming Chen",
        "Dingjie Fu",
        "and Xinge You"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:08:19+00:00",
          "link": "https://arxiv.org/abs/2507.15308v1",
          "size": "4777kb",
          "version": "v1"
        }
      ],
      "title": "Few-Shot Object Detection via Spatial-Channel State Space Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15308",
        "HTML": "https://arxiv.org/html/2507.15308",
        "PDF": "https://arxiv.org/pdf/2507.15308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on few-shot object detection and feature extraction techniques, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15344",
      "abstract": "The regional inertia, which determines the regional rate of change of frequency (RoCoF), should be kept in a secure status in renewable-penetrated power systems. To break away from mapping the regional maximum RoCoF with regional inertia in a linearized form, this paper comprehensively studies the regional inertia security problem from formulation to applications. Firstly, the regional inertia security region (R-ISR) is defined, whose boundary is non-linear and non-convex. Then, a local linearized method is devised to calculate the global maximum of regional RoCoF. The non-convex ISR boundary is expressed by multiple simple boundaries corresponding to each local solution, which can be obtained by a simple search-based method. Finally, the convexified R-ISR constraint is formed by convex decomposition and embedded in an inertia optimal adjustment model. The results on a 3-region system show some counter-intuitive findings, such as increasing the inertia of one region may worsen its RoCoF.",
      "authors": [
        "Jiahao Liu",
        "Cheng Wang",
        "Tianshu Bi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:58:06+00:00",
          "link": "https://arxiv.org/abs/2507.15344v1",
          "size": "37984kb",
          "version": "v1"
        }
      ],
      "title": "RoCoF Constrained Regional Inertia Security Region: Formulation and Application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15344",
        "HTML": "https://arxiv.org/html/2507.15344",
        "PDF": "https://arxiv.org/pdf/2507.15344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies regional inertia in power systems, focusing on frequency stability in power grids. It is unrelated to LLM training or data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15670",
      "abstract": "Edge Computing (EC) is a computational paradigm that involves deploying resources such as CPUs and GPUs near end-users, enabling low-latency applications like augmented reality and real-time gaming. However, deploying and maintaining a vast network of EC nodes is costly, which can explain its limited deployment today. A new paradigm called Vehicular Cloud Computing (VCC) has emerged and inspired interest among researchers and industry. VCC opportunistically utilizes existing and idle vehicular computational resources for external task offloading. This work is the first to systematically address the following question: Can VCC replace EC for low-latency applications? Answering this question is highly relevant for Network Operators (NOs), as VCC could eliminate costs associated with EC given that it requires no infrastructural investment. Despite its potential, no systematic study has yet explored the conditions under which VCC can effectively support low-latency applications without relying on EC. This work aims to fill that gap. Extensive simulations allow for assessing the crucial scenario factors that determine when this EC-to-VCC substitution is feasible. Considered factors are load, vehicles mobility and density, and availability. Potential for substitution is assessed based on multiple criteria, such as latency, task completion success, and cost. Vehicle mobility is simulated in SUMO, and communication in NS3 5G-LENA. The findings show that VCC can effectively replace EC for low-latency applications, except in extreme cases when the EC is still required (latency < 16 ms).",
      "authors": [
        "Rosario Patan\\`e",
        "Nadjib Achir",
        "Andrea Araldo",
        "Lila Boukhatem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:33:40+00:00",
          "link": "https://arxiv.org/abs/2507.15670v1",
          "size": "2645kb",
          "version": "v1"
        }
      ],
      "title": "Vehicular Cloud Computing: A cost-effective alternative to Edge Computing in 5G networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15670",
        "PDF": "https://arxiv.org/pdf/2507.15670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Vehicular Cloud Computing as an alternative to Edge Computing for low-latency applications, which is unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15771",
      "abstract": "How does AI think about economic policy? While the use of large language models (LLMs) in economics is growing exponentially, their assumptions on economic issues remain a black box. This paper uses a conjoint experiment to tease out the main factors influencing LLMs' evaluation of economic policy. It finds that LLMs are most sensitive to unemployment, inequality, financial stability, and environmental harm and less sensitive to traditional macroeconomic concerns such as economic growth, inflation, and government debt. The results are remarkably consistent across scenarios and across models.",
      "authors": [
        "Maxim Chupilkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:27:16+00:00",
          "link": "https://arxiv.org/abs/2507.15771v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "Left Leaning Models: AI Assumptions on Economic Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15771",
        "PDF": "https://arxiv.org/pdf/2507.15771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates LLM assumptions on economic policy using conjoint experiments and does not touch upon any aspect of training data processing operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15828",
      "abstract": "[Context] An evidence briefing is a concise and objective transfer medium that can present the main findings of a study to software engineers in the industry. Although practitioners and researchers have deemed Evidence Briefings useful, their production requires manual labor, which may be a significant challenge to their broad adoption. [Goal] The goal of this registered report is to describe an experimental protocol for evaluating LLM-generated evidence briefings for secondary studies in terms of content fidelity, ease of understanding, and usefulness, as perceived by researchers and practitioners, compared to human-made briefings. [Method] We developed an RAG-based LLM tool to generate evidence briefings. We used the tool to automatically generate two evidence briefings that had been manually generated in previous research efforts. We designed a controlled experiment to evaluate how the LLM-generated briefings compare to the human-made ones regarding perceived content fidelity, ease of understanding, and usefulness. [Results] To be reported after the experimental trials. [Conclusion] Depending on the experiment results.",
      "authors": [
        "Mauro Marcelino",
        "Marcos Alves",
        "Bianca Trinkenreich",
        "Bruno Cartaxo",
        "S\\'ergio Soares",
        "Simone D.J. Barbosa",
        "Marcos Kalinowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.15828v1",
          "size": "174kb",
          "version": "v1"
        }
      ],
      "title": "Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15828",
        "HTML": "https://arxiv.org/html/2507.15828",
        "PDF": "https://arxiv.org/pdf/2507.15828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an experimental protocol for evaluating LLM-generated evidence briefings in software engineering. It discusses the application of LLMs for specific use cases but does not address any LLM training data processing contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.16191",
      "abstract": "This paper focuses on spatiotemporal (ST) traffic prediction using graph neural networks (GNNs). Given that ST data comprises non-stationary and complex temporal patterns, interpreting and predicting such trends is inherently challenging. Representing ST data in decomposed modes helps infer underlying behavior and assess the impact of noise on predictive performance. We propose a framework that decomposes ST data into interpretable modes using variational mode decomposition (VMD) and processes them through a neural network for future state forecasting. Unlike existing graph-based traffic forecasters that operate directly on raw or aggregated time series, the proposed hybrid approach, termed the Variational Mode Graph Convolutional Network (VMGCN), first decomposes non-stationary signals into interpretable variational modes by determining the optimal mode count via reconstruction-loss minimization and then learns both intramode and cross-mode spatiotemporal dependencies through a novel attention-augmented GCN. Additionally, we analyze the significance of each mode and the effect of bandwidth constraints on multi-horizon traffic flow predictions. The proposed two-stage design yields significant accuracy gains while providing frequency-level interpretability with demonstrated superior performance on the LargeST dataset for both short-term and long-term forecasting tasks. The implementation is publicly available on https://github.com/OsamaAhmad369/VMGCN.",
      "authors": [
        "Osama Ahmad and Lukas Wesemann and Fabian Waschkowski and Zubair Khalid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T01:09:30+00:00",
          "link": "https://arxiv.org/abs/2408.16191v1",
          "size": "17707kb",
          "version": "v1"
        },
        {
          "date": "2024-10-15T05:47:58+00:00",
          "link": "https://arxiv.org/abs/2408.16191v2",
          "size": "20994kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T06:53:30+00:00",
          "link": "https://arxiv.org/abs/2408.16191v3",
          "size": "15951kb",
          "version": "v3"
        }
      ],
      "title": "Variational Mode-Driven Graph Convolutional Network for Spatiotemporal Traffic Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16191",
        "HTML": "https://arxiv.org/html/2408.16191",
        "PDF": "https://arxiv.org/pdf/2408.16191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on spatiotemporal traffic forecasting using graph neural networks and variational mode decomposition. It does not involve any processes related to LLM training data."
      },
      "tasks": [
        "Traffic Prediction"
      ],
      "repo_urls": [
        "https://github.com/OsamaAhmad369/VMGCN"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10467",
      "abstract": "Recent advancements in LLMs indicate potential for novel applications, as evidenced by the reasoning capabilities in the latest OpenAI and DeepSeek models. To apply these models to domain-specific applications beyond text generation, LLM-based multi-agent systems can be utilized to solve complex tasks, particularly by combining reasoning techniques, code generation, and software execution across multiple, potentially specialized LLMs. However, while many evaluations are performed on LLMs, reasoning techniques, and applications individually, their joint specification and combined application are not well understood. Defined specifications for multi-agent LLM systems are required to explore their potential and suitability for specific applications, allowing for systematic evaluations of LLMs, reasoning techniques, and related aspects. This paper reports the results of exploratory research on (1.) multi-agent specification by introducing an agent schema language and (2.) the execution and evaluation of the specifications through a multi-agent system architecture and prototype. The specification language, system architecture, and prototype are first presented in this work, building on an LLM system from prior research. Test cases involving cybersecurity tasks indicate the feasibility of the architecture and evaluation approach. As a result, evaluations could be demonstrated for question answering, server security, and network security tasks completed correctly by agents with LLMs from OpenAI and DeepSeek.",
      "authors": [
        "Felix H\\\"arer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T08:16:17+00:00",
          "link": "https://arxiv.org/abs/2506.10467v1",
          "size": "953kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T17:32:42+00:00",
          "link": "https://arxiv.org/abs/2506.10467v2",
          "size": "955kb",
          "version": "v2"
        },
        {
          "date": "2025-06-16T05:03:49+00:00",
          "link": "https://arxiv.org/abs/2506.10467v3",
          "size": "953kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T20:15:06+00:00",
          "link": "https://arxiv.org/abs/2506.10467v4",
          "size": "953kb",
          "version": "v4"
        }
      ],
      "title": "Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10467",
        "HTML": "https://arxiv.org/html/2506.10467",
        "PDF": "https://arxiv.org/pdf/2506.10467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the specification and evaluation of multi-agent systems using LLMs for specific tasks such as cybersecurity, but it does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Code Generation",
        "Question Answering",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/fhaer/multi-agent-llm-system"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14768",
      "abstract": "Motivated by federated learning (FL), secure aggregation (SA) aims to securely compute, as efficiently as possible, the sum of a set of inputs distributed across many users. To understand the impact of network topology, hierarchical secure aggregation (HSA) investigated the communication and secret key generation efficiency in a 3-layer relay network, where clusters of users are connected to the aggregation server through an intermediate layer of relays. Due to the pre-aggregation of the messages at the relays, HSA reduces the communication burden on the relay-to-server links and is able to support a large number of users. However, as the number of users increases, a practical challenge arises from heterogeneous security requirements--for example, users in different clusters may require varying levels of input protection. Motivated by this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where instead of protecting all the inputs from any set of colluding users, only the inputs belonging to a predefined collection of user groups (referred to as security input sets) need to be protected against another predefined collection of user groups (referred to as collusion sets). Since the security input sets and collusion sets can be arbitrarily defined, our formulation offers a flexible framework for addressing heterogeneous security requirements in HSA. We characterize the optimal total key rate, i.e., the total number of independent key symbols required to ensure both server and relay security, for a broad range of parameter configurations. For the remaining cases, we establish lower and upper bounds on the optimal key rate, providing constant-factor gap optimality guarantees.",
      "authors": [
        "Zhou Li",
        "Xiang Zhang",
        "Jiawen Lv",
        "Jihao Fan",
        "Haiqiang Chen",
        "Giuseppe Caire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T23:09:57+00:00",
          "link": "https://arxiv.org/abs/2507.14768v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "Collusion-Resilient Hierarchical Secure Aggregation with Heterogeneous Security Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14768",
        "HTML": "https://arxiv.org/html/2507.14768",
        "PDF": "https://arxiv.org/pdf/2507.14768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is related to secure aggregation in federated learning and efficient communication, with a focus on security constraints. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15423",
      "abstract": "In the evolution towards 6G user-centric networking, the moving network (MN) paradigm can play an important role. In a MN, some small cell base stations (BS) are installed on top of vehicles, and enable a more dynamic, flexible and sustainable, network operation. By \"following\" the users movements and adapting dynamically to their requests, the MN paradigm enables a more efficient utilization of network resources, mitigating the need for dense small cell BS deployments at the cost of an increase in resource utilization due to wireless backhauling. This aspect is at least partly compensated by the shorter distance between users and BS, which allows for lower power and Line-of-Sight communications. While the MN paradigm has been investigated for some time, to date, it is still unclear in which conditions the advantages of MN outweigh the additional resource costs. In this paper, we propose a stochastic geometry framework for the characterization of the potential benefits of the MN paradigm as part of an HetNet in urban settings. Our approach allows the estimation of user-perceived performance, accounting for wireless backhaul connectivity as well as base station resource scheduling. We formulate an optimization problem for determining the resource-optimal network configurations and BS scheduling which minimize the overall amount of deployed BSs in a QoS-aware manner, and the minimum vehicular flow between different urban districts required to support them, and we propose an efficient stochastic heuristic to solve it. Our numerical assessment suggests that the MN paradigm, coupled with appropriate dynamic network management strategies, significantly reduces the amount of deployed network infrastructure while guaranteeing the target QoS perceived by users.",
      "authors": [
        "Laura Finarelli",
        "Falko Dressler",
        "Marco Ajmone Marsan",
        "Gianluca Rizzo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:24:13+00:00",
          "link": "https://arxiv.org/abs/2507.15423v1",
          "size": "198kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Benefits of Ground Vehicles as Moving Urban Base Stations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15423",
        "HTML": "https://arxiv.org/html/2507.15423",
        "PDF": "https://arxiv.org/pdf/2507.15423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a networking paradigm involving base stations on vehicles for urban settings. It focuses on resource optimization in networking, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15628",
      "abstract": "The explosive growth of video data in recent years has brought higher demands for video analytics, where accuracy and efficiency remain the two primary concerns. Deep neural networks (DNNs) have been widely adopted to ensure accuracy; however, improving their efficiency in video analytics remains an open challenge. Different from existing surveys that make summaries of DNN-based video mainly from the accuracy optimization aspect, in this survey, we aim to provide a thorough review of optimization techniques focusing on the improvement of the efficiency of DNNs in video analytics. We organize existing methods in a bottom-up manner, covering multiple perspectives such as hardware support, data processing, operational deployment, etc. Finally, based on the optimization framework and existing works, we analyze and discuss the problems and challenges in the performance optimization of DNN-based video analytics.",
      "authors": [
        "Shanjiang Tang and Rui Huang and Hsinyu Luo and Chunjiang Wang and Ce Yu and Yusen Li and Hao Fu and Chao Sun and and Jian Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:52:06+00:00",
          "link": "https://arxiv.org/abs/2507.15628v1",
          "size": "3026kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15628",
        "HTML": "https://arxiv.org/html/2507.15628",
        "PDF": "https://arxiv.org/pdf/2507.15628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey reviews efficiency optimization techniques for DNN-based video analytics, focusing on accuracy and efficiency improvements, which are not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12891",
      "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend the real world. However, existing works neglect the real-world challenges for temporal reasoning: (1) intensive temporal information, (2) fast-changing event dynamics, and (3) complex temporal dependencies in social interactions. To bridge this gap, we propose a multi-level benchmark TIME, designed for temporal reasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3 levels with 11 fine-grained sub-tasks. This benchmark encompasses 3 sub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News, and TIME-Dial. We conduct extensive experiments on reasoning models and non-reasoning models. And we conducted an in-depth analysis of temporal reasoning performance across diverse real-world scenarios and tasks, and summarized the impact of test-time scaling on temporal reasoning capabilities. Additionally, we release TIME-Lite, a human-annotated subset to foster future research and standardized evaluation in temporal reasoning. The code is available at https://github.com/sylvain-wei/TIME , and the dataset is available at https://huggingface.co/datasets/SylvainWei/TIME .",
      "authors": [
        "Shaohang Wei",
        "Wei Li",
        "Feifan Song",
        "Wen Luo",
        "Tianyi Zhuang",
        "Haochen Tan",
        "Zhijiang Guo",
        "Houfeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T09:22:02+00:00",
          "link": "https://arxiv.org/abs/2505.12891v1",
          "size": "15007kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T04:52:39+00:00",
          "link": "https://arxiv.org/abs/2505.12891v2",
          "size": "17889kb",
          "version": "v2"
        }
      ],
      "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12891",
        "HTML": "https://arxiv.org/html/2505.12891",
        "PDF": "https://arxiv.org/pdf/2505.12891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the TIME benchmark for temporal reasoning, useful for LLM evaluation. While it contributes a dataset, this benchmark focuses on evaluation and experimentation, not specifically on improving data processing operations for LLM training."
      },
      "datasets": [
        {
          "dataset_name": "SylvainWei/TIME",
          "downloads": "183",
          "likes": "3",
          "link": "https://huggingface.co/datasets/SylvainWei/TIME"
        },
        {
          "dataset_name": "SylvainWei/TIME-Lite",
          "downloads": "27",
          "likes": "2",
          "link": "https://huggingface.co/datasets/SylvainWei/TIME-Lite"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/sylvain-wei/time"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00683",
      "abstract": "The recently proposed physics-based framework by Huo and Johnson~\\cite{huo2024capturing} models the attention mechanism of Large Language Models (LLMs) as an interacting two-body spin system, offering a first-principles explanation for phenomena like repetition and bias. Building on this hypothesis, we extract the complete Query-Key weight matrices from a production-grade GPT-2 model and derive the corresponding effective Hamiltonian for every attention head. From these Hamiltonians, we obtain analytic phase boundaries and logit gap criteria that predict which token should dominate the next-token distribution for a given context. A systematic evaluation on 144 heads across 20 factual-recall prompts reveals a strong negative correlation between the theoretical logit gaps and the model's empirical token rankings ($r\\approx-0.70$, $p<10^{-3}$).Targeted ablations further show that suppressing the heads most aligned with the spin-bath predictions induces the anticipated shifts in output probabilities, confirming a causal link rather than a coincidental association. Taken together, our findings provide the first strong empirical evidence for the spin-bath analogy in a production-grade model. In this work, we utilize the context-field lens, which provides physics-grounded interpretability and motivates the development of novel generative models bridging theoretical condensed matter physics and artificial intelligence.",
      "authors": [
        "Satadeep Bhattacharjee and Seung-Cheol Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:33:39+00:00",
          "link": "https://arxiv.org/abs/2507.00683v1",
          "size": "779kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T16:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.00683v2",
          "size": "779kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:16:14+00:00",
          "link": "https://arxiv.org/abs/2507.00683v3",
          "size": "822kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T05:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.00683v4",
          "size": "824kb",
          "version": "v4"
        }
      ],
      "title": "Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00683",
        "PDF": "https://arxiv.org/pdf/2507.00683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a physics-based analysis of the GPT-2 model's self-attention mechanism and does not involve training data processing for LLMs, such as data filtering or creating datasets for training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14409",
      "abstract": "This paper presents a novel approach to solving the indirect influence problem in networked systems, in which cooperative nodes must regulate a target node with uncertain dynamics to follow a desired trajectory. We leverage the message-passing structure of a graph neural network (GNN), allowing nodes to collectively learn the unknown target dynamics in real time. We develop a novel GNN-based backstepping control strategy with formal stability guarantees derived from a Lyapunov-based analysis. Numerical simulations are included to demonstrate the performance of the developed controller.",
      "authors": [
        "Max L. Gardenswartz",
        "Brandon C. Fallin",
        "Cristian F. Nino",
        "and Warren E. Dixon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T23:31:49+00:00",
          "link": "https://arxiv.org/abs/2507.14409v1",
          "size": "149kb",
          "version": "v1"
        }
      ],
      "title": "Collaborative Indirect Influencing and Control on Graphs using Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14409",
        "HTML": "https://arxiv.org/html/2507.14409",
        "PDF": "https://arxiv.org/pdf/2507.14409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around using graph neural networks for indirect influence in networked systems, with no emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14417",
      "abstract": "We construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regression tasks with spurious features, deduction tasks with constraint tracking, and advanced AI risks. We identify five distinct failure modes when models reason for longer: 1) Claude models become increasingly distracted by irrelevant information; 2) OpenAI o-series models resist distractors but overfit to problem framings; 3) models shift from reasonable priors to spurious correlations; 4) all models show difficulties in maintaining focus on complex deductive tasks; and 5) extended reasoning may amplify concerning behaviors, with Claude Sonnet 4 showing increased expressions of self-preservation. These findings suggest that while test-time compute scaling remains promising for improving model capabilities, it may inadvertently reinforce problematic reasoning patterns. Our results demonstrate the importance of evaluating models across diverse reasoning lengths to identify and address these failure modes in LRMs.",
      "authors": [
        "Aryo Pradipta Gema and Alexander H\\\"agele and Runjin Chen and Andy Arditi and Jacob Goldman-Wetzler and Kit Fraser-Taliente and Henry Sleight and Linda Petrini and Julian Michael and Beatrice Alex and Pasquale Minervini and Yanda Chen and Joe Benton and Ethan Perez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T00:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.14417v1",
          "size": "1777kb",
          "version": "v1"
        }
      ],
      "title": "Inverse Scaling in Test-Time Compute",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14417",
        "PDF": "https://arxiv.org/pdf/2507.14417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on examining the inverse scaling relationship in reasoning tasks performed by large reasoning models, rather than on LLM training data processing, data collection, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14849",
      "abstract": "Reasoning distillation has emerged as an effective approach to enhance the reasoning capabilities of smaller language models. However, the impact of large-scale reasoning distillation on other critical abilities, particularly in-context retrieval and reasoning, remains unexplored. This gap in understanding is particularly significant given the increasing importance of Retrieval-Augmented Generation (RAG) systems, where efficient acquisition and utilization of contextual information are paramount for generating reliable responses. Motivated by the need to understand how the extended long-CoT process influences long-context comprehension, we conduct a comprehensive investigation using a series of open-source models distilled from Deepseek-R1, renowned for its exceptional reasoning capabilities. Our study focuses on evaluating these models' performance in extracting and integrating relevant information from extended contexts through multi-document question and answering tasks. Through rigorous experimentation, we demonstrate that distilled reasoning patterns significantly improve long-context understanding. Our analysis reveals that distillation fosters greater long-context awareness by promoting more detailed and explicit reasoning processes during context analysis and information parsing. This advancement effectively mitigates the persistent \"lost in the middle\" issue that has hindered long-context models.",
      "authors": [
        "Yifei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:43:16+00:00",
          "link": "https://arxiv.org/abs/2507.14849v1",
          "size": "2146kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14849",
        "HTML": "https://arxiv.org/html/2507.14849",
        "PDF": "https://arxiv.org/pdf/2507.14849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reasoning distillation for improving LLMs' reasoning capabilities and long-context understanding, without directly addressing training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.14474",
      "abstract": "Reservoir computation is a recurrent framework for learning and predicting time series data, that benefits from extremely simple training and interpretability, often as the the dynamics of a physical system. In this paper, we will study the impact of noise on the learning capabilities of analog reservoir computers. Recent work on reservoir computation has shown that the information processing capacity (IPC) is a useful metric for quantifying the degradation of the performance due to noise. We further this analysis and demonstrate that this degradation of the IPC limits the possible features that can be meaningfully constructed in an analog reservoir computing setting. We borrow a result from quantum complexity theory that relates the circuit model of computation to a continuous time model, and demonstrate an exponential reduction in the accessible volume of reservoir configurations. We conclude by relating this degradation in the IPC to the fat-shattering dimension of a family of functions describing the reservoir dynamics, which allows us to express our result in terms of a classification task. We conclude that any physical, analog reservoir computer that is exposed to noise can only be used to perform a polynomial amount of learning, despite the exponentially large latent space, even with an exponential amount of post-processing.",
      "authors": [
        "Anthony M. Polloreno"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-26T19:41:05+00:00",
          "link": "https://arxiv.org/abs/2307.14474v1",
          "size": "664kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T00:58:02+00:00",
          "link": "https://arxiv.org/abs/2307.14474v2",
          "size": "182kb",
          "version": "v2"
        },
        {
          "date": "2025-04-02T17:22:09+00:00",
          "link": "https://arxiv.org/abs/2307.14474v3",
          "size": "182kb",
          "version": "v3"
        },
        {
          "date": "2025-04-06T02:21:08+00:00",
          "link": "https://arxiv.org/abs/2307.14474v4",
          "size": "175kb",
          "version": "v4"
        },
        {
          "date": "2025-07-20T20:50:21+00:00",
          "link": "https://arxiv.org/abs/2307.14474v5",
          "size": "184kb",
          "version": "v5"
        }
      ],
      "title": "Restrictions on Physical Stochastic Reservoir Computers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.14474",
        "HTML": "https://arxiv.org/html/2307.14474",
        "PDF": "https://arxiv.org/pdf/2307.14474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes the impact of noise on analog reservoir computing and its capacity. It does not address any data processing for language model training."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.23969",
      "abstract": "We consider the problem of testing and learning from data in the presence of resource constraints, such as limited memory or weak data access, which place limitations on the efficiency and feasibility of testing or learning. In particular, we ask the following question: Could a resource-constrained learner/tester use interaction with a resource-unconstrained but untrusted party to solve a learning or testing problem more efficiently than they could without such an interaction? In this work, we answer this question both abstractly and for concrete problems, in two complementary ways: For a wide variety of scenarios, we prove that a resource-constrained learner cannot gain any advantage through classical interaction with an untrusted prover. As a special case, we show that for the vast majority of testing and learning problems in which quantum memory is a meaningful resource, a memory-constrained quantum algorithm cannot overcome its limitations via classical communication with a memory-unconstrained quantum prover. In contrast, when quantum communication is allowed, we construct a variety of interactive proof protocols, for specific learning and testing problems, which allow memory-constrained quantum verifiers to gain significant advantages through delegation to untrusted provers. These results highlight both the limitations and potential of delegating learning and testing problems to resource-rich but untrusted third parties.",
      "authors": [
        "Matthias C. Caro",
        "Jens Eisert",
        "Marcel Hinsche",
        "Marios Ioannou",
        "Alexander Nietner",
        "and Ryan Sweke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T14:22:52+00:00",
          "link": "https://arxiv.org/abs/2410.23969v1",
          "size": "785kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T10:49:30+00:00",
          "link": "https://arxiv.org/abs/2410.23969v2",
          "size": "788kb",
          "version": "v2"
        }
      ],
      "title": "Interactive proofs for verifying (quantum) learning and testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23969",
        "HTML": "https://arxiv.org/html/2410.23969",
        "PDF": "https://arxiv.org/pdf/2410.23969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses interactive proofs in resource-constrained learning and testing scenarios, but it does not involve LLM training data processing or data engineering operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.18765",
      "abstract": "This paper introduces Agent-Based Auto Research, a structured multi-agent framework designed to automate, coordinate, and optimize the full lifecycle of scientific research. Leveraging the capabilities of large language models (LLMs) and modular agent collaboration, the system spans all major research phases, including literature review, ideation, methodology planning, experimentation, paper writing, peer review response, and dissemination. By addressing issues such as fragmented workflows, uneven methodological expertise, and cognitive overload, the framework offers a systematic and scalable approach to scientific inquiry. Preliminary explorations demonstrate the feasibility and potential of Auto Research as a promising paradigm for self-improving, AI-driven research processes.",
      "authors": [
        "Chengwei Liu",
        "Chong Wang",
        "Jiayue Cao",
        "Jingquan Ge",
        "Kun Wang",
        "Lyuye Zhang",
        "Ming-Ming Cheng",
        "Penghai Zhao",
        "Tianlin Li",
        "Xiaojun Jia",
        "Xiang Li",
        "Xingshuai Li",
        "Yang Liu",
        "Yebo Feng",
        "Yihao Huang",
        "Yijia Xu",
        "Yuqiang Sun",
        "Zhenhong Zhou",
        "Zhengzi Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-26T02:06:10+00:00",
          "link": "https://arxiv.org/abs/2504.18765v1",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T15:27:05+00:00",
          "link": "https://arxiv.org/abs/2504.18765v2",
          "size": "105kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T16:30:25+00:00",
          "link": "https://arxiv.org/abs/2504.18765v3",
          "size": "105kb",
          "version": "v3"
        }
      ],
      "title": "A Vision for Auto Research with LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18765",
        "HTML": "https://arxiv.org/html/2504.18765",
        "PDF": "https://arxiv.org/pdf/2504.18765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for automating scientific research phases with LLM agents, without addressing any aspects of training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06174",
      "abstract": "In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.",
      "authors": [
        "Koki Yamane",
        "Yunhan Li",
        "Masashi Konosu",
        "Koki Inami",
        "Junji Oaki",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.06174v1",
          "size": "16600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.06174v2",
          "size": "16657kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:43:46+00:00",
          "link": "https://arxiv.org/abs/2507.06174v3",
          "size": "16665kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T00:20:11+00:00",
          "link": "https://arxiv.org/abs/2507.06174v4",
          "size": "16835kb",
          "version": "v4"
        }
      ],
      "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06174",
        "HTML": "https://arxiv.org/html/2507.06174",
        "PDF": "https://arxiv.org/pdf/2507.06174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses teleoperation and imitation learning with sensorless force control, which are unrelated to LLM training data processing tasks like data collection, filtering, or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14191",
      "abstract": "This paper presents EDURFID, an automated school attendance control system based on RFID technology designed for rural educational institutions in Peru. The system integrates open-source hardware (Raspberry Pi 5, Arduino UNO R3) with RC522 RFID modules operating at 13.56 MHz, implementing a web architecture developed in Python Django. The system demonstrates 100% precision in RFID readings with 0.03-second response time, achieving 94% cost reduction compared to commercial solutions. Validation at T\\'upac Amaru Secondary Educational Institution showed successful automation of attendance processes, saving 50 daily minutes of administrative time while providing real-time reporting capabilities.",
      "authors": [
        "Cliver Oliver Turpo Benique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:32:04+00:00",
          "link": "https://arxiv.org/abs/2507.14191v1",
          "size": "747kb",
          "version": "v1"
        }
      ],
      "title": "School Attendance Control System Based on RFID Technology with Raspberry Pi and Arduino: EDURFID",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14191",
        "HTML": "https://arxiv.org/html/2507.14191",
        "PDF": "https://arxiv.org/pdf/2507.14191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the development of an RFID-based school attendance system, unrelated to LLM training data processing or any relevant datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15640",
      "abstract": "Continual pre-training on small-scale task-specific data is an effective method for improving large language models in new target fields, yet it risks catastrophic forgetting of their original capabilities. A common solution is to re-weight training data mixtures from source and target fields on a domain space to achieve balanced performance. Previous domain reweighting strategies rely on manual designation with certain heuristics based on human intuition or empirical results. In this work, we prove that more general heuristics can be parameterized by proposing Data Mixing Agent, the first model-based, end-to-end framework that learns to re-weight domains. The agent learns generalizable heuristics through reinforcement learning on large quantities of data mixing trajectories with corresponding feedback from an evaluation environment. Experiments in continual pre-training on math reasoning show that Data Mixing Agent outperforms strong baselines in achieving balanced performance across source and target field benchmarks. Furthermore, it generalizes well across unseen source fields, target models, and domain spaces without retraining. Direct application to the code generation field also indicates its adaptability across target domains. Further analysis showcases the agents' well-aligned heuristics with human intuitions and their efficiency in achieving superior model performance with less source-field data.",
      "authors": [
        "Kailai Yang",
        "Xiao Liu",
        "Lei Ji",
        "Hao Li",
        "Yeyun Gong",
        "Peng Cheng",
        "Mao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.15640v1",
          "size": "9142kb",
          "version": "v1"
        }
      ],
      "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15640",
        "HTML": "https://arxiv.org/html/2507.15640",
        "PDF": "https://arxiv.org/pdf/2507.15640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes Data Mixing Agent, which is a framework that learns to re-weight training data for continual pre-training of LLMs. This involves training data processing through domain re-weighting and data mixing, making it a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.16891",
      "abstract": "Recently, significant progress has been made in understanding the generalization of neural networks (NNs) trained by gradient descent (GD) using the algorithmic stability approach. However, most of the existing research has focused on one-hidden-layer NNs and has not addressed the impact of different network scaling parameters. In this paper, we greatly extend the previous work \\cite{lei2022stability,richards2021stability} by conducting a comprehensive stability and generalization analysis of GD for multi-layer NNs. For two-layer NNs, our results are established under general network scaling parameters, relaxing previous conditions. In the case of three-layer NNs, our technical contribution lies in demonstrating its nearly co-coercive property by utilizing a novel induction strategy that thoroughly explores the effects of over-parameterization. As a direct application of our general findings, we derive the excess risk rate of $O(1/\\sqrt{n})$ for GD algorithms in both two-layer and three-layer NNs. This sheds light on sufficient or necessary conditions for under-parameterized and over-parameterized NNs trained by GD to attain the desired risk rate of $O(1/\\sqrt{n})$. Moreover, we demonstrate that as the scaling parameter increases or the network complexity decreases, less over-parameterization is required for GD to achieve the desired error rates. Additionally, under a low-noise condition, we obtain a fast risk rate of $O(1/n)$ for GD in both two-layer and three-layer NNs.",
      "authors": [
        "Puyu Wang",
        "Yunwen Lei",
        "Di Wang",
        "Yiming Ying",
        "Ding-Xuan Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-26T12:51:38+00:00",
          "link": "https://arxiv.org/abs/2305.16891v1",
          "size": "688kb",
          "version": "v1"
        },
        {
          "date": "2023-09-29T07:17:50+00:00",
          "link": "https://arxiv.org/abs/2305.16891v2",
          "size": "689kb",
          "version": "v2"
        }
      ],
      "title": "Generalization Guarantees of Gradient Descent for Multi-Layer Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.16891",
        "PDF": "https://arxiv.org/pdf/2305.16891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses generalization and stability in neural networks trained by gradient descent, specifically for multi-layer networks, without discussing any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.01260",
      "abstract": "Precisely classifying earthquake types is crucial for elucidating the relationship between volcanic earthquakes and volcanic activity. However, traditional methods rely on subjective human judgment, which requires considerable time and effort. To address this issue, we developed a deep learning model using a transformer encoder for a more objective and efficient classification. Tested on Mount Asama's diverse seismic activity, our model achieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency earthquakes, and 0.980 for noise), superior to a conventional CNN-based method. To enhance interpretability, attention weight visualizations were analyzed, revealing that the model focuses on key waveform features similarly to human experts. However, inconsistencies in training data, such as ambiguously labeled B-type events with S-waves, were found to influence classification accuracy and attention weight distributions. Experiments addressing data selection and augmentation demonstrated the importance of balancing data quality and diversity. In addition, stations within 3 km of the crater played an important role in improving model performance and interpretability. These findings highlight the potential of Transformer-based models for automated volcanic earthquake classification, particularly in improving efficiency and interpretability. By addressing challenges such as data imbalance and subjective labeling, our approach provides a robust framework for understanding seismic activity at Mount Asama. Moreover, this framework offers opportunities for transfer learning to other volcanic regions, paving the way for enhanced volcanic hazard assessments and disaster mitigation strategies.",
      "authors": [
        "Y. Suzuki",
        "Y. Yukutake",
        "T. Ohminato",
        "M. Yamasaki and Ahyi Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T00:37:07+00:00",
          "link": "https://arxiv.org/abs/2507.01260v1",
          "size": "8416kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.01260v2",
          "size": "8432kb",
          "version": "v2"
        }
      ],
      "title": "Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01260",
        "PDF": "https://arxiv.org/pdf/2507.01260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses data quality issues in the context of classifying volcanic earthquakes using transformer encoders. It lightly touches on data selection and augmentation, which are related to data processing, but the main focus is on model performance and interpretability rather than on systematic improvements in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14660",
      "abstract": "Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at https://github.com/renqibing/RogueAgent.",
      "authors": [
        "Qibing Ren",
        "Sitao Xie",
        "Longxuan Wei",
        "Zhenfei Yin",
        "Junchi Yan",
        "Lizhuang Ma",
        "Jing Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:17:30+00:00",
          "link": "https://arxiv.org/abs/2507.14660v1",
          "size": "5181kb",
          "version": "v1"
        }
      ],
      "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14660",
        "PDF": "https://arxiv.org/pdf/2507.14660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores multi-agent collusion and associated risks in social systems, without focusing on aspects of LLM training data processing such as data engineering or dataset construction for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14748",
      "abstract": "Self-supervised feature learning and pretraining methods in reinforcement learning (RL) often rely on information-theoretic principles, termed mutual information skill learning (MISL). These methods aim to learn a representation of the environment while also incentivizing exploration thereof. However, the role of the representation and mutual information parametrization in MISL is not yet well understood theoretically. Our work investigates MISL through the lens of identifiable representation learning by focusing on the Contrastive Successor Features (CSF) method. We prove that CSF can provably recover the environment's ground-truth features up to a linear transformation due to the inner product parametrization of the features and skill diversity in a discriminative sense. This first identifiability guarantee for representation learning in RL also helps explain the implications of different mutual information objectives and the downsides of entropy regularizers. We empirically validate our claims in MuJoCo and DeepMind Control and show how CSF provably recovers the ground-truth features both from states and pixels.",
      "authors": [
        "Patrik Reizinger",
        "B\\'alint Mucs\\'anyi",
        "Siyuan Guo",
        "Benjamin Eysenbach",
        "Bernhard Sch\\\"olkopf",
        "Wieland Brendel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:48:46+00:00",
          "link": "https://arxiv.org/abs/2507.14748v1",
          "size": "2270kb",
          "version": "v1"
        }
      ],
      "title": "Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14748",
        "PDF": "https://arxiv.org/pdf/2507.14748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on self-supervised feature learning in reinforcement learning using policy diversity, with no mention of LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14931",
      "abstract": "Forensic mental health care involves the treatment of individuals with severe mental disorders who have committed violent offences. These settings are often characterized by high levels of bureaucracy, risk avoidance, and restricted autonomy. Patients frequently experience a profound loss of control over their lives, leading to heightened psychological stress-sometimes resulting in isolation as a safety measure. In this study, we explore how co-design can be used to collaboratively develop a companion robot that helps monitor and regulate stress while maintaining tracking of the patients' interaction behaviours for long-term intervention. We conducted four co-design workshops in a forensic psychiatric clinic with patients, caregivers, and therapists. Our process began with the presentation of an initial speculative prototype to therapists, enabling reflection on shared concerns, ethical risks, and desirable features. This was followed by a creative ideation session with patients, a third workshop focused on defining desired functions and emotional responses, and we are planning a final prototype demo to gather direct patient feedback. Our findings emphasize the importance of empowering patients in the design process and adapting proposals based on their current emotional state. The goal was to empower the patient in the design process and ensure each patient's voice was heard.",
      "authors": [
        "Qiaoqiao Ren",
        "Remko Proesmans",
        "Arend Pissens",
        "Lara Dehandschutter",
        "William Denecker",
        "Lotte Rouckhout",
        "Joke Carrette",
        "Peter Vanhopplinus",
        "Tony Belpaeme and Francis wyffels"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:58:04+00:00",
          "link": "https://arxiv.org/abs/2507.14931v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14931",
        "HTML": "https://arxiv.org/html/2507.14931",
        "PDF": "https://arxiv.org/pdf/2507.14931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the co-design of robots in forensic psychiatry settings. It is unrelated to LLM training data processing as it focuses on robot design and patient interaction, with no mention of data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15093",
      "abstract": "The challenge of finding exact and finite-dimensional Koopman embeddings of nonlinear systems has been largely circumvented by employing data-driven techniques to learn models of different complexities (e.g., linear, bilinear, input affine). Although these models may provide good accuracy, selecting the model structure and dimension is still ad-hoc and it is difficult to quantify the error that is introduced. In contrast to the general trend of data-driven learning, in this paper, we develop a systematic technique for nonlinear systems that produces a finite-dimensional and exact embedding. If the nonlinear system is represented as a network of series and parallel linear and nonlinear (polynomial) blocks, one can derive an associated Koopman model that has constant state and output matrices and the input influence is polynomial. Furthermore, if the linear blocks do not have feedthrough, the Koopman representation simplifies to a bilinear model.",
      "authors": [
        "Lucian Cristian Iacob",
        "Roland T\\'oth",
        "Maarten Schoukens"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:18:17+00:00",
          "link": "https://arxiv.org/abs/2507.15093v1",
          "size": "890kb",
          "version": "v1"
        }
      ],
      "title": "Exact Finite Koopman Embedding of Block-Oriented Polynomial Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15093",
        "HTML": "https://arxiv.org/html/2507.15093",
        "PDF": "https://arxiv.org/pdf/2507.15093"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a technique for Koopman embeddings of nonlinear systems, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15489",
      "abstract": "This paper presents a novel quadratic programming (QP) approach for constrained control allocation that directly incorporates continuous-time actuator rate constraints without requiring slack variables. Over-actuated aircraft configurations, particularly prevalent in eVTOL and military applications, require control allocation algorithms to distribute commanded control moments among available actuators while respecting position and rate constraints. Existing methods such as direct allocation, pseudo-inverse, cascaded generalized inverse, and exact redistributed pseudo-inverse either cannot handle rate constraints in continuous time or require discretization approaches that compromise performance. Current QP methods that incorporate rate constraints rely on slack variables to ensure feasibility, which prevents full utilization of the attainable moment set and degrades allocation performance. The proposed methodology addresses this limitation by calculating the attainable moment set from both position and rate constraints through convex hull operations, then ensuring feasibility by scaling unattainable commanded moments to the boundary of the attainable moment set while preserving their direction. This approach guarantees the feasibility of the optimization problem without slack variables. The method is validated through simulation on an F-18 fighter aircraft control allocation problem, demonstrating equivalent performance to the established exact redistributed pseudo-inverse method while providing smoother actuator behavior and enhanced constraint satisfaction. Results show that incorporating continuous-time rate constraints leads to improved actuator tracking, reduced overshoot, and more precise adherence to position limits, which is essential for aircraft safety, ride comfort, and actuator longevity.",
      "authors": [
        "S\\\"uleyman \\\"Ozkurt and Adrian Grimm and Walter Fichter"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:45:44+00:00",
          "link": "https://arxiv.org/abs/2507.15489v1",
          "size": "871kb",
          "version": "v1"
        }
      ],
      "title": "Constrained Control Allocation With Continuous-Time Rate Constraints: Three-Dimensional Case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15489",
        "HTML": "https://arxiv.org/html/2507.15489",
        "PDF": "https://arxiv.org/pdf/2507.15489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with constrained control allocation in aircraft systems, focusing on actuator rate constraints. It does not address any aspect of LLM training data processing or related dataset improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15805",
      "abstract": "This work develops a framework to discover relations between the components of the solution to a given initial-value problem for a first-order system of ordinary differential equations. This is done by using sparse identification techniques on the data represented by the numerical solution of the initial-value problem at hand. The only assumption is that there are only a few terms that connects the components, so that the mathematical relations to be discovered are sparse in the set of possible functions. We illustrate the method through examples of applications.",
      "authors": [
        "Nicolae Tarfulea"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Information Theory (cs.IT)",
        "Numerical Analysis (cs.NA)",
        "Information Theory (math.IT)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:05:12+00:00",
          "link": "https://arxiv.org/abs/2507.15805v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Solution Constraints for ODE Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15805",
        "HTML": "https://arxiv.org/html/2507.15805",
        "PDF": "https://arxiv.org/pdf/2507.15805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a framework for finding solution constraints in ODE systems using sparse identification. It is not related to language models or training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14268",
      "abstract": "This paper presents a comparative analysis of algorithmic strategies for fitting tessellation models to 3D image data of materials such as polycrystals and foams. In this steadily advancing field, we review and assess optimization-based methods -- including linear and nonlinear programming, stochastic optimization via the cross-entropy method, and gradient descent -- for generating Voronoi, Laguerre, and generalized balanced power diagrams (GBPDs) that approximate voxelbased grain structures. The quality of fit is evaluated on real-world datasets using discrepancy measures that quantify differences in grain volume, surface area, and topology. Our results highlight trade-offs between model complexity, the complexity of the optimization routines involved, and the quality of approximation, providing guidance for selecting appropriate methods based on data characteristics and application needs.",
      "authors": [
        "Andreas Alpers",
        "Orkun Furat",
        "Christian Jung",
        "Matthias Neumann",
        "Claudia Redenbach",
        "Aigerim Saken and Volker Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:28:59+00:00",
          "link": "https://arxiv.org/abs/2507.14268v1",
          "size": "27399kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14268",
        "HTML": "https://arxiv.org/html/2507.14268",
        "PDF": "https://arxiv.org/pdf/2507.14268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses algorithms for fitting tessellation models to 3D image data and does not pertain to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14455",
      "abstract": "Time-delay embedding is a technique that uses snapshots of state history over time to build a linear state space model of a nonlinear smooth system. We demonstrate that periodic non-smooth or hybrid system can also be modeled as a linear state space system using this approach as long as its behavior is consistent in modes and timings. We extended time-delay embeddings to generate a linear model of two periodic hybrid systems: the bouncing pendulum and the simplest walker with control inputs. This leads to a novel state history augmented linear quadratic regulator (LQR) which uses current and past state history for feedback control.",
      "authors": [
        "Chun-Ming Yang",
        "Pranav A. Bhounsule"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:00:52+00:00",
          "link": "https://arxiv.org/abs/2507.14455v1",
          "size": "719kb",
          "version": "v1"
        }
      ],
      "title": "Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14455",
        "HTML": "https://arxiv.org/html/2507.14455",
        "PDF": "https://arxiv.org/pdf/2507.14455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores time-delay embeddings and control applications for hybrid systems like the bouncing pendulum, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14629",
      "abstract": "Though vertical federated learning (VFL) is generally considered to be privacy-preserving, recent studies have shown that VFL system is vulnerable to label inference attacks originating from various attack surfaces. Among these attacks, the model completion (MC) attack is currently the most powerful one. Existing defense methods against it either sacrifice model accuracy or incur impractical computational overhead. In this paper, we propose VMask, a novel label privacy protection framework designed to defend against MC attack from the perspective of layer masking. Our key insight is to disrupt the strong correlation between input data and intermediate outputs by applying the secret sharing (SS) technique to mask layer parameters in the attacker's model. We devise a strategy for selecting critical layers to mask, reducing the overhead that would arise from naively applying SS to the entire model. Moreover, VMask is the first framework to offer a tunable privacy budget to defenders, allowing for flexible control over the levels of label privacy according to actual requirements. We built a VFL system, implemented VMask on it, and extensively evaluated it using five model architectures and 13 datasets with different modalities, comparing it to 12 other defense methods. The results demonstrate that VMask achieves the best privacy-utility trade-off, successfully thwarting the MC attack (reducing the label inference accuracy to a random guessing level) while preserving model performance (e.g., in Transformer-based model, the averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up to 60,846 times faster than cryptography-based methods, and it only marginally exceeds that of standard VFL by 1.8 times in a large Transformer-based model, which is generally acceptable.",
      "authors": [
        "Juntao Tan",
        "Lan Zhang",
        "Zhonghao Hu",
        "Kai Yang",
        "Peng Ran",
        "Bo Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:51:09+00:00",
          "link": "https://arxiv.org/abs/2507.14629v1",
          "size": "2921kb",
          "version": "v1"
        }
      ],
      "title": "VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14629",
        "PDF": "https://arxiv.org/pdf/2507.14629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses label privacy protection in vertical federated learning, which does not involve training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15127",
      "abstract": "This paper develops a sequential-linearization feedback optimization framework for driving nonlinear dynamical systems to an\n  optimal steady state. A fundamental challenge in feedback optimization is the requirement of accurate first-order information\n  of the steady-state input-output mapping, which is computationally prohibitive for high-dimensional nonlinear systems and\n  often leads to poor performance when approximated around a fixed operating point. To address this limitation, we propose a\n  sequential algorithm that adaptively updates the linearization point during optimization, maintaining local accuracy throughout\n  the trajectory. We prove convergence to a neighborhood of the optimal steady state with explicit error bounds. To reduce the\n  computational burden of repeated linearization operations, we further develop a multi-timescale variant where linearization\n  updates occur at a slower timescale than optimization iterations, achieving significant computational savings while preserving\n  convergence guarantees. The effectiveness of the proposed framework is demonstrated via numerical simulations of a realistic\n  wind farm control problem. The results validate both the theoretical convergence predictions and the expected computational\n  advantages of our multi-timescale formulation.",
      "authors": [
        "Shijie Huang and Sergio Grammatico"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T21:31:27+00:00",
          "link": "https://arxiv.org/abs/2507.15127v1",
          "size": "598kb",
          "version": "v1"
        }
      ],
      "title": "Sequential feedback optimization with application to wind farm control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15127",
        "HTML": "https://arxiv.org/html/2507.15127",
        "PDF": "https://arxiv.org/pdf/2507.15127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sequential feedback optimization for nonlinear dynamical systems, specifically applied to wind farm control, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15598",
      "abstract": "We give an algorithm for finding the arboricity of a weighted, undirected graph, defined as the minimum number of spanning forests that cover all edges of the graph, in $\\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best bound of $\\tilde{O}(nm)$ for weighted graphs and $\\tilde{O}(m^{3/2}) $ for unweighted graphs (Gabow 1995) for this problem. The running time of our algorithm is dominated by a logarithmic number of calls to a directed global minimum cut subroutine -- if the running time of the latter problem improves to $m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running time of our arboricity algorithm would improve further to $m^{1+o(1)}$.\n  We also give a new algorithm for computing the entire cut hierarchy -- laminar multiway cuts with minimum cut ratio in recursively defined induced subgraphs -- in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge loads (Thorup 2001) in a fractional spanning tree packing of the graph which, we show, also corresponds to a max-entropy solution in the spanning tree polytope. For the cut hierarchy problem, the previous best bound was $\\tilde{O}(n^2 m)$ for weighted graphs and $\\tilde{O}(n m^{3/2})$ for unweighted graphs.",
      "authors": [
        "Ruoxu Cen",
        "Henry Fleischmann",
        "George Z. Li",
        "Jason Li",
        "and Debmalya Panigrahi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:19:11+00:00",
          "link": "https://arxiv.org/abs/2507.15598v1",
          "size": "95kb",
          "version": "v1"
        }
      ],
      "title": "Fast Algorithms for Graph Arboricity and Related Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15598",
        "HTML": "https://arxiv.org/html/2507.15598",
        "PDF": "https://arxiv.org/pdf/2507.15598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on algorithms for graph arboricity and related problems and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06967",
      "abstract": "A continuous-aperture array (CAPA)-based integrated sensing and communications (ISAC) framework is proposed for both downlink and uplink scenarios. Within this framework, continuous operator-based signal models are employed to describe the sensing and communication processes. The performance of communication and sensing is analyzed using two information-theoretic metrics: the communication rate (CR) and the sensing rate (SR). 1) For downlink ISAC, three continuous beamforming designs are proposed: i) the communications-centric (C-C) design that maximizes the CR, ii) the sensing-centric (S-C) design that maximizes the SR, and iii) the Pareto-optimal design that characterizes the Pareto boundary of the CR-SR region. A low-complexity signal subspace-based approach is proposed to derive the closed-form optimal beamformers for the considered designs. On this basis, closed-form expressions are derived for the achievable CRs and SRs, and the downlink rate region achieved by CAPAs is characterized. 2) For uplink ISAC, the C-C and S-C successive interference cancellation-based methods are proposed to manage inter-functionality interference. Using the subspace approach closed-form expressions for the optimal detectors as well as the achievable CRs and SRs are derived. The uplink SR-CR region is characterized based on the time-sharing technique. Numerical results demonstrate that, for both downlink and uplink, CAPA-based ISAC achieves higher CRs and SRs as well as larger CR-SR regions compared to conventional spatially discrete array-based ISAC.",
      "authors": [
        "Boqun Zhao",
        "Chongjun Ouyang",
        "Xingqi Zhang",
        "Hyundong Shin and Yuanwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T19:04:17+00:00",
          "link": "https://arxiv.org/abs/2502.06967v1",
          "size": "1823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T22:20:49+00:00",
          "link": "https://arxiv.org/abs/2502.06967v2",
          "size": "1838kb",
          "version": "v2"
        }
      ],
      "title": "Downlink and Uplink ISAC in Continuous-Aperture Array (CAPA) Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06967",
        "HTML": "https://arxiv.org/html/2502.06967",
        "PDF": "https://arxiv.org/pdf/2502.06967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrated sensing and communication (ISAC) in continuous-aperture array systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.14537",
      "abstract": "Learning-based 3D reconstruction has emerged as a transformative technique in autonomous driving, enabling precise modeling of both dynamic and static environments through advanced neural representations. Despite data augmentation, 3D reconstruction inspires pioneering solution for vital tasks in the field of autonomous driving, such as scene understanding and closed-loop simulation. We investigates the details of 3D reconstruction and conducts a multi-perspective, in-depth analysis of recent advancements. Specifically, we first provide a systematic introduction of preliminaries, including data modalities, benchmarks and technical preliminaries of learning-based 3D reconstruction, facilitating instant identification of suitable methods according to sensor suites. Then, we systematically review learning-based 3D reconstruction methods in autonomous driving, categorizing approaches by subtasks and conducting multi-dimensional analysis and summary to establish a comprehensive technical reference. The development trends and existing challenges are summarized in the context of learning-based 3D reconstruction in autonomous driving. We hope that our review will inspire future researches.",
      "authors": [
        "Liewen Liao",
        "Weihao Yan",
        "Ming Yang",
        "Songan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T13:56:03+00:00",
          "link": "https://arxiv.org/abs/2503.14537v1",
          "size": "1916kb",
          "version": "v1"
        },
        {
          "date": "2025-03-22T02:26:04+00:00",
          "link": "https://arxiv.org/abs/2503.14537v2",
          "size": "7120kb",
          "version": "v2"
        },
        {
          "date": "2025-06-16T02:16:35+00:00",
          "link": "https://arxiv.org/abs/2503.14537v3",
          "size": "9882kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T07:23:58+00:00",
          "link": "https://arxiv.org/abs/2503.14537v4",
          "size": "8096kb",
          "version": "v4"
        }
      ],
      "title": "Learning-based 3D Reconstruction in Autonomous Driving: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14537",
        "HTML": "https://arxiv.org/html/2503.14537",
        "PDF": "https://arxiv.org/pdf/2503.14537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a survey of learning-based 3D reconstruction techniques in autonomous driving, focusing on scene understanding and simulation, with no direct contribution to LLM training data processing."
      },
      "tasks": [
        "3D Reconstruction",
        "Autonomous Driving",
        "Data Augmentation",
        "Scene Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09948",
      "abstract": "Deep learning-based prediction models for High-Level Synthesis (HLS) of hardware designs often struggle to generalize. In this paper, we study how to close the generalizability gap of these models through pretraining on synthetic data and introduce Iceberg, a synthetic data augmentation approach that expands both large language model (LLM)-generated programs and weak labels of unseen design configurations. Our weak label generation method is integrated with an in-context model architecture, enabling meta-learning from actual and proximate labels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when adapt to six real-world applications with few-shot examples and achieves a $2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to two different test datasets. Our open-sourced code is here: https://github.com/UCLA-VAST/iceberg",
      "authors": [
        "Zijian Ding",
        "Tung Nguyen",
        "Weikai Li",
        "Aditya Grover",
        "Yizhou Sun",
        "Jason Cong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.09948v1",
          "size": "1351kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T21:32:24+00:00",
          "link": "https://arxiv.org/abs/2507.09948v2",
          "size": "1351kb",
          "version": "v2"
        }
      ],
      "title": "Iceberg: Enhancing HLS Modeling with Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09948",
        "HTML": "https://arxiv.org/html/2507.09948",
        "PDF": "https://arxiv.org/pdf/2507.09948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a synthetic data augmentation method for high-level synthesis models, leveraging LLM-generated programs. While it involves data generation, its primary focus is on improving model generalizability in HLS, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15724",
      "abstract": "Enabling image generation models to be spatially controlled is an important area of research, empowering users to better generate images according to their own fine-grained specifications via e.g. edge maps, poses. Although this task has seen impressive improvements in recent times, a focus on rapidly producing stronger models has come at the cost of detailed and fair scientific comparison. Differing training data, model architectures and generation paradigms make it difficult to disentangle the factors contributing to performance. Meanwhile, the motivations and nuances of certain approaches become lost in the literature. In this work, we aim to provide clear takeaways across generation paradigms for practitioners wishing to develop transformer-based systems for spatially-controlled generation, clarifying the literature and addressing knowledge gaps. We perform controlled experiments on ImageNet across diffusion-based/flow-based and autoregressive (AR) models. First, we establish control token prefilling as a simple, general and performant baseline approach for transformers. We then investigate previously underexplored sampling time enhancements, showing that extending classifier-free guidance to control, as well as softmax truncation, have a strong impact on control-generation consistency. Finally, we re-clarify the motivation of adapter-based approaches, demonstrating that they mitigate \"forgetting\" and maintain generation quality when trained on limited downstream data, but underperform full training in terms of generation-control consistency. Code will be released upon publication.",
      "authors": [
        "Guoxuan Xia",
        "Harleen Hanspal",
        "Petru-Daniel Tudosiu",
        "Shifeng Zhang",
        "Sarah Parisot"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:33:49+00:00",
          "link": "https://arxiv.org/abs/2507.15724v1",
          "size": "18044kb",
          "version": "v1"
        }
      ],
      "title": "A Practical Investigation of Spatially-Controlled Image Generation with Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15724",
        "HTML": "https://arxiv.org/html/2507.15724",
        "PDF": "https://arxiv.org/pdf/2507.15724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses spatially-controlled image generation with transformers and experimental evaluations on models, without addressing data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15815",
      "abstract": "We present the LLM Economist, a novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agents -- instantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statistics -- choose labor supply to maximize text-based utility functions learned in-context. At the upper level, a planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism design -- the ultimate nudging problem -- expressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while a periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing a tractable test bed for policy evaluation at the societal scale to help build better civilizations.",
      "authors": [
        "Seth Karten",
        "Wenzhe Li",
        "Zihan Ding",
        "Samuel Kleiner",
        "Yu Bai",
        "Chi Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:21:14+00:00",
          "link": "https://arxiv.org/abs/2507.15815v1",
          "size": "4908kb",
          "version": "v1"
        }
      ],
      "title": "LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15815",
        "HTML": "https://arxiv.org/html/2507.15815",
        "PDF": "https://arxiv.org/pdf/2507.15815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an agent-based modeling framework for economic policy design using LLMs in strategic environments. While it involves LLMs, it focuses on mechanism design and simulation rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.04958",
      "abstract": "Fake base stations (FBSes) pose a significant security threat by impersonating legitimate base stations (BSes). Though efforts have been made to defeat this threat, up to this day, the presence of FBSes and the multi-step attacks (MSAs) stemming from them can lead to unauthorized surveillance, interception of sensitive information, and disruption of network services. Therefore, detecting these malicious entities is crucial to ensure the security and reliability of cellular networks. Traditional detection methods often rely on additional hardware, rules, signal scanning, changing protocol specifications, or cryptographic mechanisms that have limitations and incur huge infrastructure costs. In this paper, we develop FBSDetector-an effective and efficient detection solution that can reliably detect FBSes and MSAs from layer-3 network traces using machine learning (ML) at the user equipment (UE) side. To develop FBSDetector, we create FBSAD and MSAD, the first-ever high-quality and large-scale datasets incorporating instances of FBSes and 21 MSAs. These datasets capture the network traces in different real-world cellular network scenarios (including mobility and different attacker capabilities) incorporating legitimate BSes and FBSes. Our novel ML framework, specifically designed to detect FBSes in a multi-level approach for packet classification using stateful LSTM with attention and trace level classification and MSAs using graph learning, can effectively detect FBSes with an accuracy of 96% and a false positive rate of 2.96%, and recognize MSAs with an accuracy of 86% and a false positive rate of 3.28%. We deploy FBSDetector as a real-world solution to protect end-users through a mobile app and validate it in real-world environments. Compared to the existing heuristic-based solutions that fail to detect FBSes, FBSDetector can detect FBSes in the wild in real-time.",
      "authors": [
        "Kazi Samin Mubasshir",
        "Imtiaz Karim",
        "Elisa Bertino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-10T06:57:00+00:00",
          "link": "https://arxiv.org/abs/2401.04958v1",
          "size": "6758kb",
          "version": "v1"
        },
        {
          "date": "2025-01-28T20:22:24+00:00",
          "link": "https://arxiv.org/abs/2401.04958v2",
          "size": "23042kb",
          "version": "v2"
        },
        {
          "date": "2025-01-30T05:00:52+00:00",
          "link": "https://arxiv.org/abs/2401.04958v3",
          "size": "23080kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T04:40:36+00:00",
          "link": "https://arxiv.org/abs/2401.04958v4",
          "size": "23119kb",
          "version": "v4"
        }
      ],
      "title": "Gotta Detect 'Em All: Fake Base Station and Multi-Step Attack Detection in Cellular Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.04958",
        "HTML": "https://arxiv.org/html/2401.04958",
        "PDF": "https://arxiv.org/pdf/2401.04958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a detection solution for fake base stations in cellular networks and provides related datasets. It does not target LLM training data processing or improve data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.23880",
      "abstract": "When explaining black-box machine learning models, it's often important for explanations to have certain desirable properties. Most existing methods `encourage' desirable properties in their construction of explanations. In this work, we demonstrate that these forms of encouragement do not consistently create explanations with the properties that are supposedly being targeted. Moreover, they do not allow for any control over which properties are prioritized when different properties are at odds with each other. We propose to directly optimize explanations for desired properties. Our direct approach not only produces explanations with optimal properties more consistently but also empowers users to control trade-offs between different properties, allowing them to create explanations with exactly what is needed for a particular task.",
      "authors": [
        "Hiwot Belay Tadesse",
        "Alihan H\\\"uy\\\"uk",
        "Yaniv Yacoby",
        "Weiwei Pan",
        "Finale Doshi-Velez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T12:40:38+00:00",
          "link": "https://arxiv.org/abs/2410.23880v1",
          "size": "9665kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T17:54:50+00:00",
          "link": "https://arxiv.org/abs/2410.23880v2",
          "size": "8549kb",
          "version": "v2"
        }
      ],
      "title": "Transparent Trade-offs between Properties of Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23880",
        "HTML": "https://arxiv.org/html/2410.23880",
        "PDF": "https://arxiv.org/pdf/2410.23880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing explanations for black-box machine learning models, without addressing any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.17769",
      "abstract": "In this work, we show that we only need a single parameter $\\omega$ to effectively control granularity in diffusion-based synthesis. This parameter is incorporated during the denoising steps of the diffusion model's reverse process. This simple approach does not require model retraining or architectural modifications and incurs negligible computational overhead, yet enables precise control over the level of details in the generated outputs. Moreover, spatial masks or denoising schedules with varying $\\omega$ values can be applied to achieve region-specific or timestep-specific granularity control. External control signals or reference images can guide the creation of precise $\\omega$ masks, allowing targeted granularity adjustments. Despite its simplicity, the method demonstrates impressive performance across various image and video synthesis tasks and is adaptable to advanced diffusion models. The code is available at https://github.com/itsmag11/Omegance.",
      "authors": [
        "Xinyu Hou",
        "Zongsheng Yue",
        "Xiaoming Li",
        "Chen Change Loy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T08:23:16+00:00",
          "link": "https://arxiv.org/abs/2411.17769v1",
          "size": "16334kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:35:17+00:00",
          "link": "https://arxiv.org/abs/2411.17769v2",
          "size": "16947kb",
          "version": "v2"
        }
      ],
      "title": "Omegance: A Single Parameter for Various Granularities in Diffusion-Based Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17769",
        "HTML": "https://arxiv.org/html/2411.17769",
        "PDF": "https://arxiv.org/pdf/2411.17769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on a parameter to control granularity in diffusion-based synthesis for image and video tasks. It involves model design and synthesis control, without contribution to LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "repo_urls": [
        "https://github.com/itsmag11/omegance"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13804",
      "abstract": "Encrypted traffic classification faces growing challenges as encryption renders traditional deep packet inspection ineffective. This study addresses binary VPN detection, distinguishing VPN-encrypted from non-VPN traffic using wavelet transform-based features across multiple machine learning models. Unlike previous studies focused on application-level classification within encrypted traffic, we specifically evaluate the fundamental task of VPN identification regardless of application type. We analyze the impact of wavelet decomposition levels and dataset filtering on classification performance across significantly imbalanced data, where filtering reduces some traffic categories by up to 95%. Our results demonstrate that Random Forest (RF) achieves superior performance with an F1-score of 99%, maintaining robust accuracy even after significant dataset filtering. Neural Networks (NN) show comparable effectiveness with an F1-score of 98% when trained on wavelet level 12, while Support Vector Machines (SVM) exhibit notable sensitivity to dataset reduction, with F1-scores dropping from 90% to 85% after filtering. Comparing wavelet decomposition at levels 5 and 12, we observe improved classification performance at level 12, particularly for variable traffic types, though the marginal gains may not justify the additional computational overhead. These findings establish RF as the most reliable model for VPN traffic classification while highlighting key performance tradeoffs in feature extraction and preprocessing.",
      "authors": [
        "Yasameen Sajid Razooqi and Adrian Pekar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T15:15:45+00:00",
          "link": "https://arxiv.org/abs/2502.13804v1",
          "size": "1595kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:42:33+00:00",
          "link": "https://arxiv.org/abs/2502.13804v2",
          "size": "1838kb",
          "version": "v2"
        }
      ],
      "title": "Binary VPN Traffic Detection Using Wavelet Features and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13804",
        "HTML": "https://arxiv.org/html/2502.13804",
        "PDF": "https://arxiv.org/pdf/2502.13804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses binary VPN traffic detection using wavelet features and machine learning, focusing on classification within encrypted traffic. It does not relate to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15873",
      "abstract": "Policymakers increasingly use development cost and compute as proxies for AI capabilities and risks. Recent laws have introduced regulatory requirements for models or developers that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting create loopholes that can undermine regulatory effectiveness. We propose seven principles for designing AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.",
      "authors": [
        "Stephen Casper",
        "Luke Bailey",
        "Tim Schreier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:59:47+00:00",
          "link": "https://arxiv.org/abs/2502.15873v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:12:40+00:00",
          "link": "https://arxiv.org/abs/2502.15873v2",
          "size": "137kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T02:03:11+00:00",
          "link": "https://arxiv.org/abs/2502.15873v3",
          "size": "137kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T20:35:11+00:00",
          "link": "https://arxiv.org/abs/2502.15873v4",
          "size": "137kb",
          "version": "v4"
        }
      ],
      "title": "Practical Principles for AI Cost and Compute Accounting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15873",
        "HTML": "https://arxiv.org/html/2502.15873",
        "PDF": "https://arxiv.org/pdf/2502.15873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes principles for AI cost and compute accounting and does not address training data processing for LLMs in any capacity."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.11192",
      "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration has ushered in a new era of observational astronomy, emphasizing the need for rapid and detailed parameter estimation and population-level analyses. Traditional Bayesian inference methods, particularly Markov chain Monte Carlo, face significant computational challenges when dealing with the high-dimensional parameter spaces and complex noise characteristics inherent in gravitational wave data. This review examines the emerging role of simulation-based inference methods in gravitational wave astronomy, with a focus on approaches that leverage machine-learning techniques such as normalizing flows and neural posterior estimation. We provide a comprehensive overview of the theoretical foundations underlying various simulation-based inference methods, including neural posterior estimation, neural ratio estimation, neural likelihood estimation, flow matching, and consistency models. We explore the applications of these methods across diverse gravitational wave data processing scenarios, from single-source parameter estimation and overlapping signal analysis to testing general relativity and conducting population studies. Although these techniques demonstrate speed improvements over traditional methods in controlled studies, their model-dependent nature and sensitivity to prior assumptions are barriers to their widespread adoption. Their accuracy, which is similar to that of conventional methods, requires further validation across broader parameter spaces and noise conditions.",
      "authors": [
        "Bo Liang",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:52:57+00:00",
          "link": "https://arxiv.org/abs/2507.11192v1",
          "size": "1358kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:00:34+00:00",
          "link": "https://arxiv.org/abs/2507.11192v2",
          "size": "1358kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T08:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.11192v3",
          "size": "1358kb",
          "version": "v3"
        }
      ],
      "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11192",
        "HTML": "https://arxiv.org/html/2507.11192",
        "PDF": "https://arxiv.org/pdf/2507.11192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews simulation-based inference methods for gravitational wave data analysis. It does not discuss training data processing for LLMs, thus is not relevant to the assessment."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14322",
      "abstract": "Federated Learning (FL) offers a paradigm for privacy-preserving collaborative AI, but its decentralized nature creates significant vulnerabilities to model poisoning attacks. While numerous static defenses exist, their effectiveness is highly context-dependent, often failing against adaptive adversaries or in heterogeneous data environments. This paper introduces FedStrategist, a novel meta-learning framework that reframes robust aggregation as a real-time, cost-aware control problem. We design a lightweight contextual bandit agent that dynamically selects the optimal aggregation rule from an arsenal of defenses based on real-time diagnostic metrics. Through comprehensive experiments, we demonstrate that no single static rule is universally optimal. We show that our adaptive agent successfully learns superior policies across diverse scenarios, including a ``Krum-favorable\" environment and against a sophisticated \"stealth\" adversary designed to neutralize specific diagnostic signals. Critically, we analyze the paradoxical scenario where a non-robust baseline achieves high but compromised accuracy, and demonstrate that our agent learns a conservative policy to prioritize model integrity. Furthermore, we prove the agent's policy is controllable via a single \"risk tolerance\" parameter, allowing practitioners to explicitly manage the trade-off between performance and security. Our work provides a new, practical, and analyzable approach to creating resilient and intelligent decentralized AI systems.",
      "authors": [
        "Md Rafid Haque",
        "Abu Raihan Mostofa Kamal",
        "Md. Azam Hossain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:53:26+00:00",
          "link": "https://arxiv.org/abs/2507.14322v1",
          "size": "2396kb",
          "version": "v1"
        }
      ],
      "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14322",
        "HTML": "https://arxiv.org/html/2507.14322",
        "PDF": "https://arxiv.org/pdf/2507.14322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a meta-learning framework for federated learning, focusing on model aggregation robustness, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14526",
      "abstract": "The paper introduces final state identification (synchronizing and homing) sequences for Timed Finite State Machines (TFSMs) with output delays and investigates their properties. We formally define the notions of homing sequences (HSs) and synchronizing sequences (SSs) for these TFSMs and demonstrate that several properties that hold for untimed machines do not necessarily apply to timed ones. Furthermore, we explore the applicability of various approaches for deriving SSs and HSs for Timed FSMs with output delays, such as truncated successor tree-based and FSM abstraction-based methods. Correspondingly, we identify the subclasses of TFSMs for which these approaches can be directly applied and those for which other methods are required. Additionally, we evaluate the complexity of existence check and derivation of (shortest) HSs / SSs for TFSMs with output delays.",
      "authors": [
        "Evgenii Vinarskii",
        "Jakub Ruszil",
        "Adam Roman",
        "Natalia Kushik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:03:14+00:00",
          "link": "https://arxiv.org/abs/2507.14526v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Studying homing and synchronizing sequences for Timed Finite State Machines with output delays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14526",
        "HTML": "https://arxiv.org/html/2507.14526",
        "PDF": "https://arxiv.org/pdf/2507.14526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on final state identification sequences in Timed Finite State Machines and doesn't address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14740",
      "abstract": "Training data attribution (TDA) provides insights into which training data is responsible for a learned model behavior. Gradient-based TDA methods such as influence functions and unrolled differentiation both involve a computation that resembles an inverse Hessian-vector product (iHVP), which is difficult to approximate efficiently. We introduce an algorithm (ASTRA) which uses the EKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP approximation for TDA. ASTRA is easy to tune, requires fewer iterations than Neumann series iterations, and is more accurate than EKFAC-based approximations. Using ASTRA, we show that improving the accuracy of the iHVP approximation can significantly improve TDA performance.",
      "authors": [
        "Andrew Wang",
        "Elisa Nguyen",
        "Runshi Yang",
        "Juhan Bae",
        "Sheila A. McIlraith",
        "Roger Grosse"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:18:51+00:00",
          "link": "https://arxiv.org/abs/2507.14740v1",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "title": "Better Training Data Attribution via Better Inverse Hessian-Vector Products",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14740",
        "HTML": "https://arxiv.org/html/2507.14740",
        "PDF": "https://arxiv.org/pdf/2507.14740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving training data attribution techniques via better inverse Hessian-vector products. It discusses methodological advancements in model behavior interpretation, not LLM training data processing operations like data collection, filtering, or deduplication."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.02277",
      "abstract": "This paper studies a class of convex Finite-sum Coupled Compositional Optimization (cFCCO) problems with applications including group distributionally robust optimization (GDRO) and learning with imbalanced data. To better address these problems, we introduce an efficient single-loop primal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm employs block-coordinate stochastic mirror ascent with extrapolation for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we derive lower complexity bounds, demonstrating the (near-)optimality of ALEXR within a broad class of stochastic algorithms for cFCCO. Experimental results on GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate the promising performance of our algorithm.",
      "authors": [
        "Bokun Wang and Tianbao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-04T19:00:07+00:00",
          "link": "https://arxiv.org/abs/2312.02277v1",
          "size": "1550kb",
          "version": "v1"
        },
        {
          "date": "2024-01-22T02:03:50+00:00",
          "link": "https://arxiv.org/abs/2312.02277v2",
          "size": "1319kb",
          "version": "v2"
        },
        {
          "date": "2024-03-01T18:26:57+00:00",
          "link": "https://arxiv.org/abs/2312.02277v3",
          "size": "1319kb",
          "version": "v3"
        },
        {
          "date": "2024-06-18T21:31:08+00:00",
          "link": "https://arxiv.org/abs/2312.02277v4",
          "size": "1319kb",
          "version": "v4"
        },
        {
          "date": "2025-05-01T15:59:22+00:00",
          "link": "https://arxiv.org/abs/2312.02277v5",
          "size": "1324kb",
          "version": "v5"
        },
        {
          "date": "2025-07-20T04:14:18+00:00",
          "link": "https://arxiv.org/abs/2312.02277v6",
          "size": "1328kb",
          "version": "v6"
        }
      ],
      "title": "A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.02277",
        "PDF": "https://arxiv.org/pdf/2312.02277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with optimization algorithms for convex finite-sum coupled compositional optimization problems, not related to any aspect of LLM training data processing."
      },
      "tasks": [
        "Learning-To-Rank",
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14261",
      "abstract": "We present Fast Approximate Minimum Spanning Tree (FAMST), a novel algorithm that addresses the computational challenges of constructing Minimum Spanning Trees (MSTs) for large-scale and high-dimensional datasets. FAMST utilizes a three-phase approach: Approximate Nearest Neighbor (ANN) graph construction, ANN inter-component connection, and iterative edge refinement. For a dataset of $n$ points in a $d$-dimensional space, FAMST achieves $\\mathcal{O}(dn \\log n)$ time complexity and $\\mathcal{O}(dn + kn)$ space complexity when $k$ nearest neighbors are considered, which is a significant improvement over the $\\mathcal{O}(n^2)$ time and space complexity of traditional methods.\n  Experiments across diverse datasets demonstrate that FAMST achieves remarkably low approximation errors while providing speedups of up to 1000$\\times$ compared to exact MST algorithms. We analyze how the key hyperparameters, $k$ (neighborhood size) and $\\lambda$ (inter-component edges), affect performance, providing practical guidelines for hyperparameter selection. FAMST enables MST-based analysis on datasets with millions of points and thousands of dimensions, extending the applicability of MST techniques to problem scales previously considered infeasible.",
      "authors": [
        "Mahmood K. M. Almansoori and Miklos Telek"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.14261v1",
          "size": "309kb",
          "version": "v1"
        }
      ],
      "title": "FAMST: Fast Approximate Minimum Spanning Tree Construction for Large-Scale and High-Dimensional Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14261",
        "HTML": "https://arxiv.org/html/2507.14261",
        "PDF": "https://arxiv.org/pdf/2507.14261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an algorithm for constructing Minimum Spanning Trees for high-dimensional datasets, which is unrelated to training data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14368",
      "abstract": "Ultrasound technology enables safe, non-invasive imaging of dynamic tissue behavior, making it a valuable tool in medicine, biomechanics, and sports science. However, accurately tracking tissue motion in B-mode ultrasound remains challenging due to speckle noise, low edge contrast, and out-of-plane movement. These challenges complicate the task of tracking anatomical landmarks over time, which is essential for quantifying tissue dynamics in many clinical and research applications. This manuscript introduces DUSTrack (Deep learning and optical flow-based toolkit for UltraSound Tracking), a semi-automated framework for tracking arbitrary points in B-mode ultrasound videos. We combine deep learning with optical flow to deliver high-quality and robust tracking across diverse anatomical structures and motion patterns. The toolkit includes a graphical user interface that streamlines the generation of high-quality training data and supports iterative model refinement. It also implements a novel optical-flow-based filtering technique that reduces high-frequency frame-to-frame noise while preserving rapid tissue motion. DUSTrack demonstrates superior accuracy compared to contemporary zero-shot point trackers and performs on par with specialized methods, establishing its potential as a general and foundational tool for clinical and biomechanical research. We demonstrate DUSTrack's versatility through three use cases: cardiac wall motion tracking in echocardiograms, muscle deformation analysis during reaching tasks, and fascicle tracking during ankle plantarflexion. As an open-source solution, DUSTrack offers a powerful, flexible framework for point tracking to quantify tissue motion from ultrasound videos. DUSTrack is available at https://github.com/praneethnamburi/DUSTrack.",
      "authors": [
        "Praneeth Namburi",
        "Roger Pallar\\`es-L\\'opez",
        "Jessica Rosendorf",
        "Duarte Folgado",
        "Brian W. Anthony"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:22:39+00:00",
          "link": "https://arxiv.org/abs/2507.14368v1",
          "size": "1127kb",
          "version": "v1"
        }
      ],
      "title": "DUSTrack: Semi-automated point tracking in ultrasound videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14368",
        "PDF": "https://arxiv.org/pdf/2507.14368"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The manuscript introduces DUSTrack for point tracking in ultrasound videos, emphasizing speckle noise reduction and motion analysis, which has no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15118",
      "abstract": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce neurologists and costly diagnostic tools. We propose a graph-based deep learning framework to detect epilepsy from low-cost Electroencephalography (EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus is on fair, accessible automatic assessment and explainability to shed light on epilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs, classify them, and identify interchannel relationships and temporal dynamics using graph attention networks (GAT). To emphasize connectivity biomarkers, we adapt the inherently node-focused GAT to analyze edges. We also designed signal preprocessing for low-fidelity recordings and a lightweight GAT architecture trained on Google Colab and deployed on RaspberryPi devices. Results: The approach achieves promising classification performance, outperforming a standard classifier based on random forest and graph convolutional networks in terms of accuracy and robustness over multiple sessions, but also highlighting specific connections in the fronto-temporal region. Conclusions: The results highlight the potential of GATs to provide insightful and scalable diagnostic support for epilepsy in underserved regions, paving the way for affordable and accessible neurodiagnostic tools.",
      "authors": [
        "Szymon Mazurek",
        "Stephen Moore",
        "Alessandro Crimi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:44:39+00:00",
          "link": "https://arxiv.org/abs/2507.15118v1",
          "size": "777kb",
          "version": "v1"
        }
      ],
      "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15118",
        "HTML": "https://arxiv.org/html/2507.15118",
        "PDF": "https://arxiv.org/pdf/2507.15118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using graph attention networks for epilepsy detection using EEG signals, which is outside the scope of LLM training data processing and does not address any data processing operations related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15181",
      "abstract": "Deep learning frameworks serve as the foundation for developing and deploying deep learning applications. To enhance the quality of deep learning frameworks, researchers have proposed numerous testing methods using deep learning models as test inputs. However, existing methods predominantly measure model bug detection effectiveness as heuristic indicators, presenting three critical limitations: Firstly, existing methods fail to quantitatively measure model's operator combination variety, potentially missing critical operator combinations that could trigger framework bugs. Secondly, existing methods neglect measuring model execution time, resulting in the omission of numerous models potential for detecting more framework bugs within limited testing time. Thirdly, existing methods overlook correlation between different model measurements, relying simply on single-indicator heuristic guidance without considering their trade-offs. To overcome these limitations, we propose DLMMM, the first deep learning framework testing method to include multiple model measurements into heuristic guidance and fuse these measurements to achieve their trade-off. DLMMM firstly quantitatively measures model's bug detection performance, operator combination variety, and model execution time. After that, DLMMM fuses the above measurements based on their correlation to achieve their trade-off. To further enhance testing effectiveness, DLMMM designs multi-level heuristic guidance for test input model generation.",
      "authors": [
        "Yinglong Zou",
        "Juan Zhai",
        "Chunrong Fang",
        "Yanzhou Mu",
        "Jiawei Liu",
        "Zhenyu Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T01:56:50+00:00",
          "link": "https://arxiv.org/abs/2507.15181v1",
          "size": "1258kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning Framework Testing via Heuristic Guidance Based on Multiple Model Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15181",
        "HTML": "https://arxiv.org/html/2507.15181",
        "PDF": "https://arxiv.org/pdf/2507.15181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses deep learning framework testing with a focus on model bug detection, rather than LLM training data processing tasks like dataset generation or data quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01813",
      "abstract": "This paper introduces the Shepherd Test, a new conceptual test for assessing the moral and relational dimensions of superintelligent artificial agents. The test is inspired by human interactions with animals, where ethical considerations about care, manipulation, and consumption arise in contexts of asymmetric power and self-preservation. We argue that AI crosses an important, and potentially dangerous, threshold of intelligence when it exhibits the ability to manipulate, nurture, and instrumentally use less intelligent agents, while also managing its own survival and expansion goals. This includes the ability to weigh moral trade-offs between self-interest and the well-being of subordinate agents. The Shepherd Test thus challenges traditional AI evaluation paradigms by emphasizing moral agency, hierarchical behavior, and complex decision-making under existential stakes. We argue that this shift is critical for advancing AI governance, particularly as AI systems become increasingly integrated into multi-agent environments. We conclude by identifying key research directions, including the development of simulation environments for testing moral behavior in AI, and the formalization of ethical manipulation within multi-agent systems.",
      "authors": [
        "Djallel Bouneffouf",
        "Matthew Riemer and Kush Varshney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T15:53:56+00:00",
          "link": "https://arxiv.org/abs/2506.01813v1",
          "size": "2758kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:26:42+00:00",
          "link": "https://arxiv.org/abs/2506.01813v2",
          "size": "30kb",
          "version": "v2"
        }
      ],
      "title": "The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01813",
        "HTML": "https://arxiv.org/html/2506.01813",
        "PDF": "https://arxiv.org/pdf/2506.01813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The Shepherd Test proposed in this paper is a conceptual test for moral and relational behavior in AI systems. The focus is on AI governance and ethical behavior, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14782",
      "abstract": "Machine learning (ML) surrogate models are increasingly used in engineering analysis and design to replace computationally expensive simulation models, significantly reducing computational cost and accelerating decision-making processes. However, ML predictions contain inherent errors, often estimated as model uncertainty, which is coupled with variability in model inputs. Accurately quantifying and propagating these combined uncertainties is essential for generating reliable engineering predictions. This paper presents a robust framework based on Polynomial Chaos Expansion (PCE) to handle joint input and model uncertainty propagation. While the approach applies broadly to general ML surrogates, we focus on Gaussian Process regression models, which provide explicit predictive distributions for model uncertainty. By transforming all random inputs into a unified standard space, a PCE surrogate model is constructed, allowing efficient and accurate calculation of the mean and standard deviation of the output. The proposed methodology also offers a mechanism for global sensitivity analysis, enabling the accurate quantification of the individual contributions of input variables and ML model uncertainty to the overall output variability. This approach provides a computationally efficient and interpretable framework for comprehensive uncertainty quantification, supporting trustworthy ML predictions in downstream engineering applications.",
      "authors": [
        "Xiaoping Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T01:47:50+00:00",
          "link": "https://arxiv.org/abs/2507.14782v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification for Machine Learning-Based Prediction: A Polynomial Chaos Expansion Approach for Joint Model and Input Uncertainty Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14782",
        "HTML": "https://arxiv.org/html/2507.14782",
        "PDF": "https://arxiv.org/pdf/2507.14782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a polynomial chaos expansion approach for uncertainty quantification in machine learning models, specifically Gaussian Process regression models, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15257",
      "abstract": "Image-to-point-cloud (I2P) registration is a fundamental problem in computer vision, focusing on establishing 2D-3D correspondences between an image and a point cloud. The differential perspective-n-point (PnP) has been widely used to supervise I2P registration networks by enforcing the projective constraints on 2D-3D correspondences. However, differential PnP is highly sensitive to noise and outliers in the predicted correspondences. This issue hinders the effectiveness of correspondence learning. Inspired by the robustness of blind PnP against noise and outliers in correspondences, we propose an approximated blind PnP based correspondence learning approach. To mitigate the high computational cost of blind PnP, we simplify blind PnP to an amenable task of minimizing Chamfer distance between learned 2D and 3D keypoints, called MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task learning module, named as MinCD-Net, which can be easily integrated into the existing I2P registration architectures. Extensive experiments on 7-Scenes, RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net outperforms state-of-the-art methods and achieves a higher inlier ratio (IR) and registration recall (RR) in both cross-scene and cross-dataset settings.",
      "authors": [
        "Pei An and Jiaqi Yang and Muyao Peng and You Yang and Qiong Liu and Xiaolin Wu and Liangliang Nan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:38:16+00:00",
          "link": "https://arxiv.org/abs/2507.15257v1",
          "size": "12108kb",
          "version": "v1"
        }
      ],
      "title": "MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15257",
        "HTML": "https://arxiv.org/html/2507.15257",
        "PDF": "https://arxiv.org/pdf/2507.15257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses learning 2D-3D correspondences between images and point clouds, a problem in computer vision, and does not involve LLM data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15504",
      "abstract": "Despite recent advances, Text-to-video retrieval (TVR) is still hindered by multiple inherent uncertainties, such as ambiguous textual queries, indistinct text-video mappings, and low-quality video frames. Although interactive systems have emerged to address these challenges by refining user intent through clarifying questions, current methods typically rely on heuristic or ad-hoc strategies without explicitly quantifying these uncertainties, limiting their effectiveness. Motivated by this gap, we propose UMIVR, an Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that explicitly quantifies three critical uncertainties-text ambiguity, mapping uncertainty, and frame uncertainty-via principled, training-free metrics: semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based Frame Sampler (TQFS). By adaptively generating targeted clarifying questions guided by these uncertainty measures, UMIVR iteratively refines user queries, significantly reducing retrieval ambiguity. Extensive experiments on multiple benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1 (69.2\\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby establishing an uncertainty-minimizing foundation for interactive TVR.",
      "authors": [
        "Bingqing Zhang",
        "Zhuo Cao",
        "Heming Du",
        "Yang Li",
        "Xue Li",
        "Jiajun Liu",
        "Sen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.15504v1",
          "size": "1827kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15504",
        "HTML": "https://arxiv.org/html/2507.15504",
        "PDF": "https://arxiv.org/pdf/2507.15504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interactive text-to-video retrieval by minimizing uncertainties in text-video mappings, rather than on training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.11538",
      "abstract": "Recent studies have made great progress in functional brain network classification by modeling the brain as a network of Regions of Interest (ROIs) and leveraging their connections to understand brain functionality and diagnose mental disorders. Various deep learning architectures, including Convolutional Neural Networks, Graph Neural Networks, and the recent Transformer, have been developed. However, despite the increasing complexity of these models, the performance gain has not been as salient. This raises a question: Does increasing model complexity necessarily lead to higher classification accuracy? In this paper, we revisit the simplest deep learning architecture, the Multi-Layer Perceptron (MLP), and propose a pure MLP-based method, named BrainNetMLP, for functional brain network classification, which capitalizes on the advantages of MLP, including efficient computation and fewer parameters. Moreover, BrainNetMLP incorporates a dual-branch structure to jointly capture both spatial connectivity and spectral information, enabling precise spatiotemporal feature fusion. We evaluate our proposed BrainNetMLP on two public and popular brain network classification datasets, the Human Connectome Project (HCP) and the Autism Brain Imaging Data Exchange (ABIDE). Experimental results demonstrate pure MLP-based methods can achieve state-of-the-art performance, revealing the potential of MLP-based models as more efficient yet effective alternatives in functional brain network classification. The code will be available at https://github.com/JayceonHo/BrainNetMLP.",
      "authors": [
        "Jiacheng Hou",
        "Zhenjie Song",
        "and Ercan Engin Kuruoglu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T10:55:51+00:00",
          "link": "https://arxiv.org/abs/2505.11538v1",
          "size": "1389kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:38:17+00:00",
          "link": "https://arxiv.org/abs/2505.11538v2",
          "size": "886kb",
          "version": "v2"
        }
      ],
      "title": "BrainNetMLP: An Efficient and Effective Baseline for Functional Brain Network Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11538",
        "HTML": "https://arxiv.org/html/2505.11538",
        "PDF": "https://arxiv.org/pdf/2505.11538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with functional brain network classification using an MLP-based model and does not address issues related to LLM training data processing or the creation of datasets for pretraining or fine-tuning LLMs."
      },
      "tasks": [
        "Classification"
      ],
      "repo_urls": [
        "https://github.com/jayceonho/brainnetmlp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14153",
      "abstract": "Parkinson's disease (PD) poses challenges in diagnosis and monitoring due to its progressive nature and complex symptoms. This study introduces a novel approach utilizing surface electromyography (sEMG) to objectively assess PD severity, focusing on the biceps brachii muscle. Initial analysis of sEMG data from five PD patients and five healthy controls revealed significant neuromuscular differences. A traditional Support Vector Machine (SVM) model achieved up to 83% accuracy, while enhancements with a Graph Convolutional Network-Support Vector Machine (GCN-SVM) model increased accuracy to 92%. Despite the preliminary nature of these results, the study outlines a detailed experimental methodology for future research with larger cohorts to validate these findings and integrate the approach into clinical practice. The proposed approach holds promise for advancing PD severity assessment and improving patient care in Parkinson's disease management.",
      "authors": [
        "Daniel Cie\\'slak",
        "Barbara Szyca",
        "Weronika Bajko",
        "Liwia Florkiewicz",
        "Kinga Grz\\k{e}da",
        "Mariusz Kaczmarek",
        "Helena Kamieniecka",
        "Hubert Lis",
        "Weronika Matwiejuk",
        "Anna Prus",
        "Michalina Razik",
        "Inga Rozumowicz and Wiktoria Ziembakowska"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T00:29:31+00:00",
          "link": "https://arxiv.org/abs/2507.14153v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "Surface EMG Profiling in Parkinson's Disease: Advancing Severity Assessment with GCN-SVM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14153",
        "PDF": "https://arxiv.org/pdf/2507.14153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study uses surface electromyography for assessing Parkinson's disease severity with machine learning models and does not relate to LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14163",
      "abstract": "We present UniPhyNet, a novel neural network architecture to classify cognitive load using multimodal physiological data -- specifically EEG, ECG and EDA signals -- without the explicit need for extracting hand-crafted features. UniPhyNet integrates multiscale parallel convolutional blocks and ResNet-type blocks enhanced with channel block attention module to focus on the informative features while a bidirectional gated recurrent unit is used to capture temporal dependencies. This architecture processes and combines signals in both unimodal and multimodal configurations via intermediate fusion of learned feature maps. On the CL-Drive dataset, UniPhyNet improves raw signal classification accuracy from 70% to 80% (binary) and 62% to 74% (ternary), outperforming feature-based models, demonstrating its effectiveness as an end-to-end solution for real-world cognitive state monitoring.",
      "authors": [
        "Renxiang Qiu",
        "Raghavendra Selvan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:13:45+00:00",
          "link": "https://arxiv.org/abs/2507.14163v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "UniPhyNet: A Unified Network For Multimodal Physiological Raw Signal Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14163",
        "HTML": "https://arxiv.org/html/2507.14163",
        "PDF": "https://arxiv.org/pdf/2507.14163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a neural network architecture, UniPhyNet, for classifying cognitive load using physiological signals. It relates to neural network design and classification tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14198",
      "abstract": "Large language models (LLMs) store vast amounts of knowledge, which often requires updates to correct factual errors, incorporate newly acquired information, or adapt model behavior. Model editing methods have emerged as efficient solutions for such updates, offering localized and precise knowledge modification at significantly lower computational cost than continual training. In parallel, LLMs are frequently fine-tuned for a wide range of downstream tasks. However, the effect of fine-tuning on previously edited knowledge remains poorly understood. In this work, we systematically investigate how different fine-tuning objectives interact with various model editing techniques. Our findings show that edited knowledge is substantially more susceptible to forgetting during fine-tuning than intrinsic knowledge acquired through pre-training. This analysis highlights a key limitation of current editing approaches and suggests that evaluating edit robustness under downstream fine-tuning is critical for their practical deployment. We further find that freezing layers associated with edited content can significantly improve knowledge retention, offering insight into how future editing methods might be made more robust.",
      "authors": [
        "Fufang Wen and Shichang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:51:19+00:00",
          "link": "https://arxiv.org/abs/2507.14198v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "Retention analysis of edited knowledge after fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14198",
        "HTML": "https://arxiv.org/html/2507.14198",
        "PDF": "https://arxiv.org/pdf/2507.14198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the retention of edited knowledge in LLMs during fine-tuning, discussing model editing methods and their impact on data processing. While it touches on training data aspects indirectly, the focus is primarily on knowledge retention and model behavior, not the core of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14518",
      "abstract": "We propose a novel mathematical framework for simulating the two-phase incompressible magnetohydrodynamic (MHD) problems. Focusing on low magnetic Reynolds number regimes, where induced magnetic fields are negligible compared to applied fields, an intrinsic sharp-interface system is first formulated. Subsequently, we utilize the phase-field approach to characterize the interface and derive a thermodynamically consistent phase-field model through the Onsager's variational principle. The resulting system couples the Abels--Garcke--Gr\\\"un (AGG) model of two-phase flows with a quasi-static formulation modeling the electromagnetic phenomena. Theoretically, the sharp-interface limit is investigated via asymptotic arguments, deducing that the sharp-interface system can be recovered in the limit of vanishing interface thickness. Consequently, this justifies the reliability of the phase-field approach as an approximated method. In addition, we present some three-dimensional numerical experiments of magnetic damping effects on bubble dynamics, where the observed results demonstrate the validity of the proposed framework in capturing complex MHD phenomena.",
      "authors": [
        "Jiancheng Wang",
        "Maojun Li",
        "Zeyu Xia",
        "Liwei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:35:20+00:00",
          "link": "https://arxiv.org/abs/2507.14518v1",
          "size": "18616kb",
          "version": "v1"
        }
      ],
      "title": "Mathematical modeling and simulation of two-phase magnetohydrodynamic flows at low magnetic Reynolds numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14518",
        "HTML": "https://arxiv.org/html/2507.14518",
        "PDF": "https://arxiv.org/pdf/2507.14518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for simulating magnetohydrodynamic flows. It does not relate to LLM or language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14901",
      "abstract": "Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.",
      "authors": [
        "Armin Keki\\'c",
        "Jan Schneider",
        "Dieter B\\\"uchler",
        "Bernhard Sch\\\"olkopf",
        "Michel Besserve"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:25:24+00:00",
          "link": "https://arxiv.org/abs/2507.14901v1",
          "size": "1036kb",
          "version": "v1"
        }
      ],
      "title": "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14901",
        "PDF": "https://arxiv.org/pdf/2507.14901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores reinforcement learning policies through a causal perspective, focusing on explaining agent behavior. It does not address language model training data processing or related datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14906",
      "abstract": "The ability of Large Language Models (LLMs) to extract context from natural language problem descriptions naturally raises questions about their suitability in autonomous decision-making settings. This paper studies the behaviour of these models within a Markov Decision Process (MDPs). While traditional reinforcement learning (RL) strategies commonly employed in this setting rely on iterative exploration, LLMs, pre-trained on diverse datasets, offer the capability to leverage prior knowledge for faster adaptation. We investigate online structured prompting strategies in sequential decision making tasks, comparing the zero-shot performance of LLM-based approaches to that of classical RL methods. Our findings reveal that although LLMs demonstrate improved initial performance in simpler environments, they struggle with planning and reasoning in complex scenarios without fine-tuning or additional guidance. Our results show that feedback mechanisms, intended to improve decision-making, often introduce confusion, leading to diminished performance in intricate environments. These insights underscore the need for further exploration into hybrid strategies, fine-tuning, and advanced memory integration to enhance LLM-based decision-making capabilities.",
      "authors": [
        "Xiao Yang",
        "Juxi Leitner",
        "Michael Burke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:38:56+00:00",
          "link": "https://arxiv.org/abs/2507.14906v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14906",
        "HTML": "https://arxiv.org/html/2507.14906",
        "PDF": "https://arxiv.org/pdf/2507.14906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the decision-making capabilities of LLMs within Markov Decision Processes and explores their performance with feedback mechanisms. It does not address any aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15411",
      "abstract": "Object-centric predictive process monitoring explores and utilizes object-centric event logs to enhance process predictions. The main challenge lies in extracting relevant information and building effective models. In this paper, we propose an end-to-end model that predicts future process behavior, focusing on two tasks: next activity prediction and next event time. The proposed model employs a graph attention network to encode activities and their relationships, combined with an LSTM network to handle temporal dependencies. Evaluated on one reallife and three synthetic event logs, the model demonstrates competitive performance compared to state-of-the-art methods.",
      "authors": [
        "Wissam Gherissi (LAMSADE)",
        "Mehdi Acheli",
        "Joyce El Haddad (LAMSADE)",
        "Daniela Grigori (LAMSADE)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:10:49+00:00",
          "link": "https://arxiv.org/abs/2507.15411v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15411",
        "PDF": "https://arxiv.org/pdf/2507.15411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on predictive process monitoring using object-centric graph embeddings, which does not relate to LLM training data processing or the operations involved therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.01658",
      "abstract": "With development of information technology and necessity for high security, using different identification methods has become very important. Each biometric feature has its own advantages and disadvantages and choosing each of them depends on our usage. Retinal scanning is a bio scale method for identification. The retina is composed of vessels and optical disk. The vessels distribution pattern is one the remarkable retinal identification methods. In this paper, a new approach is presented for identification via retinal images using LBP and hog methods. In the proposed method, it will be tried to separate the retinal vessels accurately via machine vision techniques which will have good sustainability in rotation and size change. HOG-based or LBP-based methods or their combination can be used for separation and also HSV color space can be used too. Having extracted the features, the similarity criteria can be used for identification. The implementation of proposed method and its comparison with one of the newly-presented methods in this area shows better performance of the proposed method.",
      "authors": [
        "Ali Noori"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-03T16:08:38+00:00",
          "link": "https://arxiv.org/abs/2206.01658v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "Identification via Retinal Vessels Combining LBP and HOG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.01658",
        "PDF": "https://arxiv.org/pdf/2206.01658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for identification via retinal images using machine vision techniques, unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2310.02554",
      "abstract": "Federated learning (FL) is a machine learning paradigm, which enables multiple and decentralized clients to collaboratively train a model under the orchestration of a central aggregator. FL can be a scalable machine learning solution in big data scenarios. Traditional FL relies on the trust assumption of the central aggregator, which forms cohorts of clients honestly. However, a malicious aggregator, in reality, could abandon and replace the client's training models, or insert fake clients, to manipulate the final training results. In this work, we introduce zkFL, which leverages zero-knowledge proofs to tackle the issue of a malicious aggregator during the training model aggregation process. To guarantee the correct aggregation results, the aggregator provides a proof per round, demonstrating to the clients that the aggregator executes the intended behavior faithfully. To further reduce the verification cost of clients, we use blockchain to handle the proof in a zero-knowledge way, where miners (i.e., the participants validating and maintaining the blockchain data) can verify the proof without knowing the clients' local and aggregated models. The theoretical analysis and empirical results show that zkFL achieves better security and privacy than traditional FL, without modifying the underlying FL network structure or heavily compromising the training speed.",
      "authors": [
        "Zhipeng Wang",
        "Nanqing Dong",
        "Jiahao Sun",
        "William Knottenbelt",
        "Yike Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-04T03:24:33+00:00",
          "link": "https://arxiv.org/abs/2310.02554v1",
          "size": "5040kb",
          "version": "v1"
        },
        {
          "date": "2023-10-17T15:08:43+00:00",
          "link": "https://arxiv.org/abs/2310.02554v2",
          "size": "5040kb",
          "version": "v2"
        },
        {
          "date": "2023-10-19T16:21:09+00:00",
          "link": "https://arxiv.org/abs/2310.02554v3",
          "size": "5112kb",
          "version": "v3"
        },
        {
          "date": "2024-05-10T19:31:42+00:00",
          "link": "https://arxiv.org/abs/2310.02554v4",
          "size": "5088kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T12:37:54+00:00",
          "link": "https://arxiv.org/abs/2310.02554v5",
          "size": "607kb",
          "version": "v5"
        }
      ],
      "title": "zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02554",
        "HTML": "https://arxiv.org/html/2310.02554",
        "PDF": "https://arxiv.org/pdf/2310.02554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores federated learning with zero-knowledge proofs to improve security and privacy during model aggregation. It does not address any aspect of training data processing for LLMs, thus is irrelevant to the task."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05986",
      "abstract": "Multi-agent systems, where specialized agents collaborate to solve a shared task hold great potential, from increased modularity to simulating complex environments. However, they also have a major caveat -- a single agent can cause the entire system to fail. Consider a simple game where the knowledge to solve the task is distributed between agents, which share information in a communication channel. At each round, any of the agents can terminate the game and make the final prediction, even if they are uncertain about the outcome of their action. Detection of such rogue agents before they act may prevent the system's failure. In this work, we propose to monitor agents during action prediction and intervene when a future error is likely to occur. To test our approach, we introduce WhoDunitEnv, a multi-agent collaboration environment that allows modular control over task complexity and communication structure. Experiments on WhoDunitEnv, code generation tasks and the GovSim environment for resource sustainability show that our approach leads to substantial performance gains up to 17.4%, 2.5% and 20%, respectively. Thorough analysis shows that our monitors successfully identify critical points of agent confusion and our interventions effectively stop agent errors from propagating.",
      "authors": [
        "Ohav Barbi",
        "Ori Yoran",
        "Mor Geva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-09T18:35:08+00:00",
          "link": "https://arxiv.org/abs/2502.05986v1",
          "size": "1478kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:51:31+00:00",
          "link": "https://arxiv.org/abs/2502.05986v2",
          "size": "1478kb",
          "version": "v2"
        }
      ],
      "title": "Preventing Rogue Agents Improves Multi-Agent Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05986",
        "PDF": "https://arxiv.org/pdf/2502.05986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses preventing rogue agents in multi-agent systems to enhance collaboration, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Action Detection"
      ],
      "repo_urls": [
        "https://github.com/Ohav/rogue-agents"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16110",
      "abstract": "This study investigates numerical methods to solve nonlinear transport problems characterized by various sorption isotherms with a focus on the Freundlich type of isotherms. We describe and compare second order accurate numerical schemes, focusing on implicit methods, to effectively model transport phenomena without stability restriction on the choice of time steps. Furthermore, a high resolution form of the method is proposed that limits a priori the second order accurate scheme towards first order accuracy to keep the values of numerical solutions in a physically acceptable range. Through numerical experiments, we demonstrate the effectiveness of high resolution methods in minimizing oscillations near discontinuities, thereby enhancing solution plausibility. The observed convergence rates confirm that the second order accurate schemes achieve expected accuracy for smooth solutions and that they yield significant improvements when compared with the results of the first order scheme. As the computational cost of the compact implicit method seems to be comparable to similar explicit ones with a clear profit of unconditional stability, this research provides a practical tool toward numerical simulations of nonlinear transport phenomena applicable in various fields such as contaminant transport in porous media or column liquid chromatography.",
      "authors": [
        "Dagmar Zakova",
        "Peter Frolkovic"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T12:59:55+00:00",
          "link": "https://arxiv.org/abs/2503.16110v1",
          "size": "2030kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:05:02+00:00",
          "link": "https://arxiv.org/abs/2503.16110v2",
          "size": "1934kb",
          "version": "v2"
        }
      ],
      "title": "Compact implicit high resolution numerical method for solving transport problems with sorption isotherms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16110",
        "HTML": "https://arxiv.org/html/2503.16110",
        "PDF": "https://arxiv.org/pdf/2503.16110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates numerical methods for solving nonlinear transport problems. It is focused on numerical schemes and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11704",
      "abstract": "In the developer community for large language models (LLMs), there is not yet a clean pattern analogous to a software library, to support very large scale collaboration. Even for the commonplace use case of Retrieval-Augmented Generation (RAG), it is not currently possible to write a RAG application against a well-defined set of APIs that are agreed upon by different LLM providers. Inspired by the idea of compiler intrinsics, we propose some elements of such a concept through introducing a library of LLM Intrinsics for RAG. An LLM intrinsic is defined as a capability that can be invoked through a well-defined API that is reasonably stable and independent of how the LLM intrinsic itself is implemented. The intrinsics in our library are released as LoRA adapters on HuggingFace, and through a software interface with clear structured input/output characteristics on top of vLLM as an inference platform, accompanied in both places with documentation and code. This article describes the intended usage, training details, and evaluations for each intrinsic, as well as compositions of multiple intrinsics.",
      "authors": [
        "Marina Danilevsky",
        "Kristjan Greenewald",
        "Chulaka Gunasekara",
        "Maeda Hanafi",
        "Lihong He",
        "Yannis Katsis",
        "Krishnateja Killamsetty",
        "Yulong Li",
        "Yatin Nandwani",
        "Lucian Popa",
        "Dinesh Raghu",
        "Frederick Reiss",
        "Vraj Shah",
        "Khoi-Nguyen Tran",
        "Huaiyu Zhu",
        "Luis Lastras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T02:02:22+00:00",
          "link": "https://arxiv.org/abs/2504.11704v1",
          "size": "207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T02:10:42+00:00",
          "link": "https://arxiv.org/abs/2504.11704v2",
          "size": "210kb",
          "version": "v2"
        }
      ],
      "title": "A Library of LLM Intrinsics for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11704",
        "HTML": "https://arxiv.org/html/2504.11704",
        "PDF": "https://arxiv.org/pdf/2504.11704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a library of intrinsics for retrieval-augmented generation with LLMs, focusing on software library patterns rather than any aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14495",
      "abstract": "Learned Cost Models (LCMs) have shown superior results over traditional database cost models as they can significantly improve the accuracy of cost predictions. However, LCMs still fail for some query plans, as prediction errors can be large in the tail. Unfortunately, recent LCMs are based on complex deep neural models, and thus, there is no easy way to understand where this accuracy drop is rooted, which critically prevents systematic troubleshooting. In this demo paper, we present the very first approach for opening the black box by bringing AI explainability approaches to LCMs. As a core contribution, we developed new explanation techniques that extend existing methods that are available for the general explainability of AI models and adapt them significantly to be usable for LCMs. In our demo, we provide an interactive tool to showcase how explainability for LCMs works. We believe this is a first step for making LCMs debuggable and thus paving the road for new approaches for systematically fixing problems in LCMs.",
      "authors": [
        "Roman Heinrich",
        "Oleksandr Havrylov",
        "Manisha Luthra",
        "Johannes Wehrstein",
        "Carsten Binnig"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:54:43+00:00",
          "link": "https://arxiv.org/abs/2507.14495v1",
          "size": "470kb",
          "version": "v1"
        }
      ],
      "title": "Opening The Black-Box: Explaining Learned Cost Models For Databases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14495",
        "HTML": "https://arxiv.org/html/2507.14495",
        "PDF": "https://arxiv.org/pdf/2507.14495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on explaining learned cost models for databases using AI explainability techniques. It does not involve LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.02373",
      "abstract": "This work focuses on player re-identification in broadcast videos of team sports. Specifically, we focus on identifying the same player in images captured from different camera viewpoints during any given moment of a match. This task differs from traditional applications of person re-id in a few important ways. Firstly, players from the same team wear highly similar clothes, thereby making it harder to tell them apart. Secondly, there are only a few number of samples for each identity, which makes it harder to train a re-id system. Thirdly, the resolutions of the images are often quite low and vary a lot. This combined with heavy occlusions and fast movements of players greatly increase the challenges for re-id. In this paper, we propose a simple but effective hierarchical data sampling procedure and a centroid loss function that, when used together, increase the mean average precision (mAP) by 7 - 11.5 and the rank-1 (R1) by 8.8 - 14.9 without any change in the network or hyper-parameters used. Our data sampling procedure improves the similarity of the training and test distributions, and thereby aids in creating better estimates of the centroids of the embeddings (or feature vectors). Surprisingly, our study shows that in the presence of severely limited data, as is the case for our application, a simple centroid loss function based on euclidean distances significantly outperforms the popular triplet-centroid loss function. We show comparable improvements for both convolutional networks and vision transformers. Our approach is among the top ranked methods in the SoccerNet Re-Identification Challenge 2022 leaderboard (test-split) with a mAP of 86.0 and a R1 of 81.5. On the sequestered challenge split, we achieve an mAP of 84.9 and a R1 of 80.1. Research on re-id for sports-related applications is very limited and our work presents one of the first discussions in the literature on this.",
      "authors": [
        "Bharath Comandur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-06T06:06:23+00:00",
          "link": "https://arxiv.org/abs/2206.02373v1",
          "size": "8825kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T01:10:26+00:00",
          "link": "https://arxiv.org/abs/2206.02373v2",
          "size": "8825kb",
          "version": "v2"
        }
      ],
      "title": "Sports Re-ID: Improving Re-Identification Of Players In Broadcast Videos Of Team Sports",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.02373",
        "HTML": "https://arxiv.org/html/2206.02373",
        "PDF": "https://arxiv.org/pdf/2206.02373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a data sampling procedure aimed at improving model performance for player re-identification in sports videos. While it involves data processing, its primary focus is not on LLM training data processing, but rather on sports video data."
      },
      "tasks": [
        "Person Re-Identification",
        "Triplet"
      ],
      "repo_urls": [
        "https://github.com/shallowlearn/sportsreid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.04598",
      "abstract": "None of the first-order modal logics between $\\mathsf{K}$ and $\\mathsf{S5}$ under the constant domain semantics enjoys Craig interpolation or projective Beth definability, even in the language restricted to a single individual variable. It follows that the existence of a Craig interpolant for a given implication or of an explicit definition for a given predicate cannot be directly reduced to validity as in classical first-order and many other logics. Our concern here is the decidability and computational complexity of the interpolant and definition existence problems. We first consider two decidable fragments of first-order modal logic $\\mathsf{S5}$: the one-variable fragment $\\mathsf{Q^1S5}$ and its extension $\\mathsf{S5}_{\\mathcal{ALC}^u}$ that combines $\\mathsf{S5}$ and the description logic$\\mathcal{ALC}$ with the universal role. We prove that interpolant and definition existence in $\\mathsf{Q^1S5}$ and $\\mathsf{S5}_{\\mathcal{ALC}^u}$ is decidable in coN2ExpTime, being 2ExpTime-hard, while uniform interpolant existence is undecidable. These results transfer to the two-variable fragment $\\mathsf{FO^2}$ of classical first-order logic without equality. We also show that interpolant and definition existence in the one-variable fragment $\\mathsf{Q^1K}$ of first-order modal logic $\\mathsf{K}$ is non-elementary decidable, while uniform interpolant existence is again undecidable.",
      "authors": [
        "Agi Kurucz",
        "Frank Wolter",
        "Michael Zakharyaschev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-08T14:10:59+00:00",
          "link": "https://arxiv.org/abs/2303.04598v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2024-06-05T12:03:35+00:00",
          "link": "https://arxiv.org/abs/2303.04598v2",
          "size": "94kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T14:21:46+00:00",
          "link": "https://arxiv.org/abs/2303.04598v3",
          "size": "148kb",
          "version": "v3"
        }
      ],
      "title": "Deciding the Existence of Interpolants and Definitions in First-Order Modal Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.04598",
        "PDF": "https://arxiv.org/pdf/2303.04598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the decidability and computational complexity of first-order modal logic interpolants, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.04371",
      "abstract": "Recent advancements in large language models (LLMs) have shown remarkable progress, yet their ability to solve complex problems remains limited. In this work, we introduce Cumulative Reasoning (CR), a structured framework that enhances LLM problem-solving by emulating human-like iterative and cumulative thought processes. CR orchestrates LLMs in three distinct roles--Proposer, Verifier(s), and Reporter--to systematically decompose tasks, generate and validate intermediate reasoning steps, and compose them into a solution by building a dynamic Directed Acyclic Graph (DAG) of verified propositions. This approach substantially enhances problem-solving capabilities. We demonstrate CR's advantage through several complex reasoning tasks: it outperforms existing methods in logical inference tasks with up to a 9.3% improvement, achieving 98.04% accuracy on the curated FOLIO wiki dataset. In the Game of 24, it achieves 98% accuracy, marking a 24% improvement over previous methods. In solving MATH problems, CR achieves a 4.2% increase from previous methods and a 43% relative improvement in the most challenging level 5 problems. When incorporating a code environment with CR, we further harness LLMs' reasoning capabilities and outperform the Program of Thought (PoT) method by 38.8%. The code is available at https://github.com/iiis-ai/cumulative-reasoning.",
      "authors": [
        "Yifan Zhang",
        "Jingqin Yang",
        "Yang Yuan",
        "Andrew Chi-Chih Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-08T16:18:20+00:00",
          "link": "https://arxiv.org/abs/2308.04371v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2023-08-09T14:37:37+00:00",
          "link": "https://arxiv.org/abs/2308.04371v2",
          "size": "62kb",
          "version": "v2"
        },
        {
          "date": "2023-08-10T08:24:09+00:00",
          "link": "https://arxiv.org/abs/2308.04371v3",
          "size": "62kb",
          "version": "v3"
        },
        {
          "date": "2023-08-25T02:40:37+00:00",
          "link": "https://arxiv.org/abs/2308.04371v4",
          "size": "67kb",
          "version": "v4"
        },
        {
          "date": "2023-12-02T02:59:12+00:00",
          "link": "https://arxiv.org/abs/2308.04371v5",
          "size": "467kb",
          "version": "v5"
        },
        {
          "date": "2024-04-02T03:37:39+00:00",
          "link": "https://arxiv.org/abs/2308.04371v6",
          "size": "487kb",
          "version": "v6"
        },
        {
          "date": "2025-03-12T02:55:36+00:00",
          "link": "https://arxiv.org/abs/2308.04371v7",
          "size": "449kb",
          "version": "v7"
        },
        {
          "date": "2025-07-20T09:11:20+00:00",
          "link": "https://arxiv.org/abs/2308.04371v8",
          "size": "458kb",
          "version": "v8"
        }
      ],
      "title": "Cumulative Reasoning with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.04371",
        "PDF": "https://arxiv.org/pdf/2308.04371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework called Cumulative Reasoning to enhance LLM problem-solving capabilities by structuring the reasoning process, with no mention of data processing, dataset creation, or data quality improvements for LLM training."
      },
      "tasks": [
        "Decision Making",
        "Logical Reasoning",
        "Math",
        "Math Word Problem Solving"
      ],
      "repo_urls": [
        "https://github.com/iiis-ai/cumulative-reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.16411",
      "abstract": "Recently, generative AI and reinforcement learning (RL) have been redefining what is possible for AI agents that take information flows as input and produce intelligent behavior. As a result, we are seeing similar advancements in embodied AI and robotics for control policy generation. Our review paper examines the integration of generative AI models with RL to advance robotics. Our primary focus is on the duality between generative AI and RL for robotics downstream tasks. Specifically, we investigate: (1) The role of prominent generative AI tools as modular priors for multi-modal input fusion in RL tasks. (2) How RL can train, fine-tune and distill generative models for policy generation, such as VLA models, similarly to RL applications in large language models. We then propose a new taxonomy based on a considerable amount of selected papers.\n  Lastly, we identify open challenges accounting for model scalability, adaptation and grounding, giving recommendations and insights on future research directions. We reflect on which generative AI models best fit the RL tasks and why. On the other side, we reflect on important issues inherent to RL-enhanced generative policies, such as safety concerns and failure modes, and what are the limitations of current methods. A curated collection of relevant research papers is maintained on our GitHub repository, serving as a resource for ongoing research and development in this field: https://github.com/clmoro/Robotics-RL-FMs-Integration.",
      "authors": [
        "Angelo Moroncelli",
        "Vishal Soni",
        "Marco Forgione",
        "Dario Piga",
        "Blerina Spahiu and Loris Roveda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T18:27:48+00:00",
          "link": "https://arxiv.org/abs/2410.16411v1",
          "size": "14527kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T16:46:30+00:00",
          "link": "https://arxiv.org/abs/2410.16411v2",
          "size": "78097kb",
          "version": "v2"
        }
      ],
      "title": "The Duality of Generative AI and Reinforcement Learning in Robotics: A Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16411",
        "HTML": "https://arxiv.org/html/2410.16411",
        "PDF": "https://arxiv.org/pdf/2410.16411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the integration of generative AI and reinforcement learning in robotics, discussing model scalability and policy generation, without mentioning LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/clmoro/robotics-rl-fms-integration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05022",
      "abstract": "A large body of simulation research suggests that model predictive control (MPC) and reinforcement learning (RL) for heating, ventilation, and air-conditioning (HVAC) in residential and commercial buildings could reduce energy costs, pollutant emissions, and strain on power grids. Despite this potential, neither MPC nor RL has seen widespread industry adoption. Field demonstrations could accelerate MPC and RL adoption by providing real-world data that support the business case for deployment. Here we review 24 papers that document field demonstrations of MPC and RL in residential buildings and 80 in commercial buildings. After presenting demographic information -- such as experiment scopes, locations, and durations -- this paper analyzes experiment protocols and their influence on performance estimates. We find that 71% of the reviewed field demonstrations use experiment protocols that may lead to unreliable performance estimates. Over the remaining 29% that we view as reliable, the weighted-average cost savings, weighted by experiment duration, are 16% in residential buildings and 13% in commercial buildings. While these savings are potentially attractive, making the business case for MPC and RL also requires characterizing the costs of deployment, operation, and maintenance. Only 13 of the 104 reviewed papers report these costs or discuss related challenges. Based on these observations, we recommend directions for future field research, including: Improving experiment protocols; reporting deployment, operation, and maintenance costs; designing algorithms and instrumentation to reduce these costs; controlling HVAC equipment alongside other distributed energy resources; and pursuing emerging objectives such as peak shaving, arbitraging wholesale energy prices, and providing power grid reliability services.",
      "authors": [
        "Arash J. Khabbazi",
        "Elias N. Pergantis",
        "Levi D. Reyes Premer",
        "Panagiotis Papageorgiou",
        "Alex H. Lee",
        "James E. Braun",
        "Gregor P. Henze",
        "Kevin J. Kircher"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T22:48:22+00:00",
          "link": "https://arxiv.org/abs/2503.05022v1",
          "size": "281kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T18:53:22+00:00",
          "link": "https://arxiv.org/abs/2503.05022v2",
          "size": "289kb",
          "version": "v2"
        },
        {
          "date": "2025-04-02T21:27:42+00:00",
          "link": "https://arxiv.org/abs/2503.05022v3",
          "size": "457kb",
          "version": "v3"
        },
        {
          "date": "2025-06-09T20:27:29+00:00",
          "link": "https://arxiv.org/abs/2503.05022v4",
          "size": "446kb",
          "version": "v4"
        },
        {
          "date": "2025-06-12T18:48:59+00:00",
          "link": "https://arxiv.org/abs/2503.05022v5",
          "size": "424kb",
          "version": "v5"
        },
        {
          "date": "2025-07-19T15:31:35+00:00",
          "link": "https://arxiv.org/abs/2503.05022v6",
          "size": "424kb",
          "version": "v6"
        }
      ],
      "title": "Lessons learned from field demonstrations of model predictive control and reinforcement learning for residential and commercial HVAC: A review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05022",
        "HTML": "https://arxiv.org/html/2503.05022",
        "PDF": "https://arxiv.org/pdf/2503.05022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews model predictive control and reinforcement learning for HVAC systems. It does not involve any LLM training data processing, dataset creation, or quality improvement methods."
      },
      "tasks": [
        "Model Predictive Control",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/arashjkh/field-demonstrations-of-mpc-and-rl-for-residential-and-commecial-hvac"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06505",
      "abstract": "Recent advances in text-to-image generation have driven interest in generating personalized human images that depict specific identities from reference images. Although existing methods achieve high-fidelity identity preservation, they are generally limited to single-ID scenarios and offer insufficient facial editability. We present DynamicID, a tuning-free framework that inherently facilitates both single-ID and multi-ID personalized generation with high fidelity and flexible facial editability. Our key innovations include: 1) Semantic-Activated Attention (SAA), which employs query-level activation gating to minimize disruption to the base model when injecting ID features and achieve multi-ID personalization without requiring multi-ID samples during training. 2) Identity-Motion Reconfigurator (IMR), which applies feature-space manipulation to effectively disentangle and reconfigure facial motion and identity features, supporting flexible facial editing. 3) a task-decoupled training paradigm that reduces data dependency, together with VariFace-10k, a curated dataset of 10k unique individuals, each represented by 35 distinct facial images. Experimental results demonstrate that DynamicID outperforms state-of-the-art methods in identity fidelity, facial editability, and multi-ID personalization capability. Our code will be released at https://github.com/ByteCat-bot/DynamicID.",
      "authors": [
        "Xirui Hu",
        "Jiahao Wang",
        "Hao Chen",
        "Weizhan Zhang",
        "Benqi Wang",
        "Yikun Li",
        "Haishun Nan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T08:16:19+00:00",
          "link": "https://arxiv.org/abs/2503.06505v1",
          "size": "22915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:21:24+00:00",
          "link": "https://arxiv.org/abs/2503.06505v2",
          "size": "23665kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T07:11:27+00:00",
          "link": "https://arxiv.org/abs/2503.06505v3",
          "size": "23669kb",
          "version": "v3"
        }
      ],
      "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06505",
        "HTML": "https://arxiv.org/html/2503.06505",
        "PDF": "https://arxiv.org/pdf/2503.06505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on image personalization for generating personalized human images from text-to-image models, including dataset creation for individuals' images. It does not contribute directly to LLM training data processing."
      },
      "models": [
        {
          "model_path": "meteorite2023/DynamicID",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/meteorite2023/DynamicID"
        }
      ],
      "tasks": [
        "Contrastive Learning",
        "Facial Editing",
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11720",
      "abstract": "We introduce Rich Preference Optimization (RPO), a novel pipeline that leverages rich feedback signals to improve the curation of preference pairs for fine-tuning text-to-image diffusion models. Traditional methods, like Diffusion-DPO, often rely solely on reward model labeling, which can be opaque, offer limited insights into the rationale behind preferences, and are prone to issues such as reward hacking or overfitting. In contrast, our approach begins with generating detailed critiques of synthesized images, from which we extract reliable and actionable image editing instructions. By implementing these instructions, we create refined images, resulting in synthetic, informative preference pairs that serve as enhanced tuning datasets. We demonstrate the effectiveness of our pipeline and the resulting datasets in fine-tuning state-of-the-art diffusion models. Our code is available at https://github.com/Diffusion-RLHF/RPO.",
      "authors": [
        "Hanyang Zhao",
        "Haoxian Chen",
        "Yucheng Guo",
        "Genta Indra Winata",
        "Tingting Ou",
        "Ziyu Huang",
        "David D. Yao",
        "Wenpin Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T21:10:29+00:00",
          "link": "https://arxiv.org/abs/2503.11720v1",
          "size": "17457kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T19:11:31+00:00",
          "link": "https://arxiv.org/abs/2503.11720v2",
          "size": "21129kb",
          "version": "v2"
        },
        {
          "date": "2025-04-16T15:28:55+00:00",
          "link": "https://arxiv.org/abs/2503.11720v3",
          "size": "21129kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T23:30:44+00:00",
          "link": "https://arxiv.org/abs/2503.11720v4",
          "size": "10002kb",
          "version": "v4"
        }
      ],
      "title": "Fine-Tuning Diffusion Generative Models via Rich Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11720",
        "HTML": "https://arxiv.org/html/2503.11720",
        "PDF": "https://arxiv.org/pdf/2503.11720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on a novel method for curating preference pairs for fine-tuning text-to-image diffusion models, which includes creating enhanced datasets. However, it specifically addresses image generation rather than text and may not be fully aligned with language model data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.15009",
      "abstract": "Omnidirectional aerial robots offer full 6-DoF independent control over position and orientation, making them popular for aerial manipulation. Although advancements in robotic autonomy, human operation remains essential in complex aerial environments. Existing teleoperation approaches for multirotors fail to fully leverage the additional DoFs provided by omnidirectional rotation. Additionally, the dexterity of human fingers should be exploited for more engaged interaction. In this work, we propose an aerial teleoperation system that brings the rotational flexibility of human hands into the unbounded aerial workspace. Our system includes two motion-tracking marker sets--one on the shoulder and one on the hand--along with a data glove to capture hand gestures. Using these inputs, we design four interaction modes for different tasks, including Spherical Mode and Cartesian Mode for long-range moving, Operation Mode for precise manipulation, as well as Locking Mode for temporary pauses, where the hand gestures are utilized for seamless mode switching. We evaluate our system on a vertically mounted valve-turning task in the real world, demonstrating how each mode contributes to effective aerial manipulation. This interaction framework bridges human dexterity with aerial robotics, paving the way for enhanced aerial teleoperation in unstructured environments.",
      "authors": [
        "Jinjie Li",
        "Jiaxuan Li",
        "Kotaro Kaneko",
        "Haokun Liu",
        "Liming Shu",
        "and Moju Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T22:36:36+00:00",
          "link": "https://arxiv.org/abs/2506.15009v1",
          "size": "4705kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:33:02+00:00",
          "link": "https://arxiv.org/abs/2506.15009v2",
          "size": "5997kb",
          "version": "v2"
        }
      ],
      "title": "Six-DoF Hand-Based Teleoperation for Omnidirectional Aerial Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15009",
        "PDF": "https://arxiv.org/pdf/2506.15009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on teleoperation systems for aerial robots, emphasizing human-robot interaction and motion tracking but not addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05519",
      "abstract": "We consider the problem of implementing deontic modal logic. We show how (deontic) modal operators can be expressed elegantly using default negation (negation-as-failure) and strong negation present in answer set programming (ASP). We propose using global constraints of ASP to represent obligations and impermissibilities of deontic modal logic. We show that our proposed representation results in the various paradoxes of deontic modal logic being elegantly resolved.",
      "authors": [
        "Gopal Gupta",
        "Abhiramon Rajasekharan",
        "Alexis R. Tudor",
        "Elmer Salazar",
        "Joaqu\\'in Arias"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:31:54+00:00",
          "link": "https://arxiv.org/abs/2507.05519v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:04:20+00:00",
          "link": "https://arxiv.org/abs/2507.05519v2",
          "size": "279kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T00:13:08+00:00",
          "link": "https://arxiv.org/abs/2507.05519v3",
          "size": "279kb",
          "version": "v3"
        }
      ],
      "title": "Modeling Deontic Modal Logic in the s(CASP) Goal-directed Predicate Answer Set Programming System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05519",
        "HTML": "https://arxiv.org/html/2507.05519",
        "PDF": "https://arxiv.org/pdf/2507.05519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the representation of deontic modal logic in answer set programming, unrelated to LLM training data processing, dataset creation, or data quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14961",
      "abstract": "AI solutionism is accelerated and substantiated by hype and HCI's elevation of novelty. Banning or abandoning technology is unlikely to work and probably not beneficial on the whole either -- but slow(er), deliberate use together with conscientious, critical engagement and non-engagement may help us navigate a post-AI hype world while contributing to a solid knowledge foundation and reducing harmful impacts in education and research.",
      "authors": [
        "Katja Rogers"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:46:12+00:00",
          "link": "https://arxiv.org/abs/2507.14961v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Emphasizing Deliberation and Critical Thinking in an AI Hype World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14961",
        "HTML": "https://arxiv.org/html/2507.14961",
        "PDF": "https://arxiv.org/pdf/2507.14961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI hype and the importance of deliberate, critical engagement with AI technologies in education and research. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15524",
      "abstract": "Accurate segmentation is crucial for clinical applications, but existing models often assume fixed, high-resolution inputs and degrade significantly when faced with lower-resolution data in real-world scenarios. To address this limitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation architecture that dynamically adapts its inference path to the spatial resolution of the input. Central to our design are multi-scale blocks integrated at multiple encoder depths, a resolution-aware routing mechanism, and consistency-driven training that aligns multi-resolution features with full-resolution representations. We evaluate RARE-UNet on two benchmark brain imaging tasks for hippocampus and tumor segmentation. Compared to standard UNet, its multi-resolution augmented variant, and nnUNet, our model achieves the highest average Dice scores of 0.84 and 0.65 across resolution, while maintaining consistent performance and significantly reduced inference time at lower resolutions. These results highlight the effectiveness and scalability of our architecture in achieving resolution-robust segmentation. The codes are available at: https://github.com/simonsejse/RARE-UNet.",
      "authors": [
        "Simon Winther Albertsen",
        "Hjalte Svaneborg Bj{\\o}rnstrup",
        "Mostafa Mehdipour Ghazi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:49:20+00:00",
          "link": "https://arxiv.org/abs/2507.15524v1",
          "size": "2021kb",
          "version": "v1"
        }
      ],
      "title": "RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15524",
        "HTML": "https://arxiv.org/html/2507.15524",
        "PDF": "https://arxiv.org/pdf/2507.15524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on medical image segmentation with a specific model architecture (RARE-UNet), which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15584",
      "abstract": "Despite the continuous proposal of new anomaly detection algorithms and extensive benchmarking efforts, progress seems to stagnate, with only minor performance differences between established baselines and new algorithms. In this position paper, we argue that this stagnation is due to limitations in how we evaluate anomaly detection algorithms. Current benchmarking does not, for example, sufficiently reflect the diversity of anomalies in applications ranging from predictive maintenance to scientific discovery. Consequently, we need to rethink benchmarking in anomaly detection. In our opinion, anomaly detection should be studied using scenarios that capture the relevant characteristics of different applications. We identify three key areas for improvement: First, we need to identify anomaly detection scenarios based on a common taxonomy. Second, anomaly detection pipelines should be analyzed end-to-end and by component. Third, evaluating anomaly detection algorithms should be meaningful regarding the scenario's objectives.",
      "authors": [
        "Philipp R\\\"ochner",
        "Simon Kl\\\"uttermann",
        "Franz Rothlauf",
        "Daniel Schl\\\"or"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:02:49+00:00",
          "link": "https://arxiv.org/abs/2507.15584v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "We Need to Rethink Benchmarking in Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15584",
        "HTML": "https://arxiv.org/html/2507.15584",
        "PDF": "https://arxiv.org/pdf/2507.15584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on benchmarking and evaluation of anomaly detection algorithms. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15779",
      "abstract": "Large Language Models (LLM) have dominated the science and media landscape duo to their impressive performance on processing large chunks of data and produce human-like levels of text. Nevertheless, their huge energy demand and slow processing still a bottleneck for further increasing quality while also making the models accessible to everyone. To solve this bottleneck, we will investigate how reservoir computing performs on natural text processing, which could enable fast and energy efficient hardware implementations. Studies investigating the use of reservoir computing as a language model remain sparse. In this paper, we compare three distinct approaches for character-level language modeling, two different reservoir computing approaches, where only an output layer is trainable, and the well-known transformer-based architectures, which fully learn an attention-based sequence representation. We explore the performance, computational cost and prediction accuracy for both paradigms by equally varying the number of trainable parameters for all models. Using a consistent pipeline for all three approaches, we demonstrate that transformers excel in prediction quality, whereas reservoir computers remain highly efficient reducing the training and inference speed. Furthermore, we investigate two types of reservoir computing: a traditional reservoir with a static linear readout, and an attention-enhanced reservoir that dynamically adapts its output weights via an attention mechanism. Our findings underline how these paradigms scale and offer guidelines to balance resource constraints with performance.",
      "authors": [
        "Felix K\\\"oster and Atsushi Uchida"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.15779v1",
          "size": "116kb",
          "version": "v1"
        }
      ],
      "title": "Reservoir Computing as a Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15779",
        "HTML": "https://arxiv.org/html/2507.15779",
        "PDF": "https://arxiv.org/pdf/2507.15779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates reservoir computing for natural text processing, focusing on computational models rather than on processing or improving datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03619",
      "abstract": "Today, the training of large language models (LLMs) can involve personally identifiable information and copyrighted material, incurring dataset misuse. To mitigate the problem of dataset misuse, this paper explores \\textit{dataset inference}, which aims to detect if a suspect model $\\mathcal{M}$ used a victim dataset $\\mathcal{D}$ in training. Previous research tackles dataset inference by aggregating results of membership inference attacks (MIAs) -- methods to determine whether individual samples are a part of the training dataset. However, restricted by the low accuracy of MIAs, previous research mandates grey-box access to $\\mathcal{M}$ to get intermediate outputs (probabilities, loss, perplexity, etc.) for obtaining satisfactory results. This leads to reduced practicality, as LLMs, especially those deployed for profits, have limited incentives to return the intermediate outputs.\n  In this paper, we propose a new method of dataset inference with only black-box access to the target model (i.e., assuming only the text-based responses of the target model are available). Our method is enabled by two sets of locally built reference models, one set involving $\\mathcal{D}$ in training and the other not. By measuring which set of reference model $\\mathcal{M}$ is closer to, we determine if $\\mathcal{M}$ used $\\mathcal{D}$ for training. Evaluations of real-world LLMs in the wild show that our method offers high accuracy in all settings and presents robustness against bypassing attempts.",
      "authors": [
        "Ruikai Zhou",
        "Kang Yang",
        "Xun Chen",
        "Wendy Hui Wang",
        "Guanhong Tao",
        "Jun Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T14:45:41+00:00",
          "link": "https://arxiv.org/abs/2507.03619v1",
          "size": "285kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T19:19:10+00:00",
          "link": "https://arxiv.org/abs/2507.03619v2",
          "size": "286kb",
          "version": "v2"
        }
      ],
      "title": "Blackbox Dataset Inference for LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03619",
        "HTML": "https://arxiv.org/html/2507.03619",
        "PDF": "https://arxiv.org/pdf/2507.03619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for dataset inference to detect dataset misuse, which involves determining if a model used a given dataset in its training. It does not directly contribute to training data processing related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10571",
      "abstract": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint is extensible to diagnostics, biology, and other trust-critical domains. All models, prompts, results, and system components including the complete software source code are openly released to support reproducibility, transparency, and community benchmarking at Github: https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust",
      "authors": [
        "Konstantinos I. Roumeliotis",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Nikolaos D. Tselikas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:39:29+00:00",
          "link": "https://arxiv.org/abs/2507.10571v1",
          "size": "7715kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:25:01+00:00",
          "link": "https://arxiv.org/abs/2507.10571v2",
          "size": "7724kb",
          "version": "v2"
        }
      ],
      "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10571",
        "HTML": "https://arxiv.org/html/2507.10571",
        "PDF": "https://arxiv.org/pdf/2507.10571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a modular Agentic AI visual classification system which integrates visual and language understanding. It discusses zero-shot learning and fine-tuning, but primarily focuses on multi-agent AI architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14302",
      "abstract": "Most current machine learning interatomic potentials (MLIPs) rely on short-range approximations, without explicit treatment of long-range electrostatics. To address this, we recently developed the Latent Ewald Summation (LES) method, which infers electrostatic interactions, polarization, and Born effective charges (BECs), just by learning from energy and force training data. Here, we present LES as a standalone library, compatible with any short-range MLIP, and demonstrate its integration with methods such as MACE, NequIP, CACE, and CHGNet. We benchmark LES-enhanced models on distinct systems, including bulk water, polar dipeptides, and gold dimer adsorption on defective substrates, and show that LES not only captures correct electrostatics but also improves accuracy. Additionally, we scale LES to large and chemically diverse data by training MACELES-OFF on the SPICE set containing molecules and clusters, making a universal MLIP with electrostatics for organic systems including biomolecules. MACELES-OFF is more accurate than its short-range counterpart (MACE-OFF) trained on the same dataset, predicts dipoles and BECs reliably, and has better descriptions of bulk liquids. By enabling efficient long-range electrostatics without directly training on electrical properties, LES paves the way for electrostatic foundation MLIPs.",
      "authors": [
        "Dongjin Kim",
        "Xiaoyu Wang",
        "Peichen Zhong",
        "Daniel S. King",
        "Theo Jaffrelot Inizan",
        "Bingqing Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:21:45+00:00",
          "link": "https://arxiv.org/abs/2507.14302v1",
          "size": "7391kb",
          "version": "v1"
        }
      ],
      "title": "A universal augmentation framework for long-range electrostatics in machine learning interatomic potentials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14302",
        "HTML": "https://arxiv.org/html/2507.14302",
        "PDF": "https://arxiv.org/pdf/2507.14302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving machine learning interatomic potentials (MLIPs) for predicting electrostatics in materials, which does not relate to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15280",
      "abstract": "Machine unlearning aims to remove knowledge of the specific training data in a well-trained model. Currently, machine unlearning methods typically handle all forgetting data in a single batch, removing the corresponding knowledge all at once upon request. However, in practical scenarios, requests for data removal often arise in a streaming manner rather than in a single batch, leading to reduced efficiency and effectiveness in existing methods. Such challenges of streaming forgetting have not been the focus of much research. In this paper, to address the challenges of performance maintenance, efficiency, and data access brought about by streaming unlearning requests, we introduce a streaming unlearning paradigm, formalizing the unlearning as a distribution shift problem. We then estimate the altered distribution and propose a novel streaming unlearning algorithm to achieve efficient streaming forgetting without requiring access to the original training data. Theoretical analyses confirm an $O(\\sqrt{T} + V_T)$ error bound on the streaming unlearning regret, where $V_T$ represents the cumulative total variation in the optimal solution over $T$ learning rounds. This theoretical guarantee is achieved under mild conditions without the strong restriction of convex loss function. Experiments across various models and datasets validate the performance of our proposed method.",
      "authors": [
        "Shaofei Shen",
        "Chenhao Zhang",
        "Yawen Zhao",
        "Alina Bialkowski",
        "Weitong Chen",
        "Miao Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:30:25+00:00",
          "link": "https://arxiv.org/abs/2507.15280v1",
          "size": "575kb",
          "version": "v1"
        }
      ],
      "title": "Machine Unlearning for Streaming Forgetting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15280",
        "HTML": "https://arxiv.org/html/2507.15280",
        "PDF": "https://arxiv.org/pdf/2507.15280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on machine unlearning for data removal in machine learning models and does not address data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07510",
      "abstract": "Data missingness is a practical challenge of sustained interest to the scientific community. In this paper, we present Shades-of-Null, an evaluation suite for responsible missing value imputation. Our work is novel in two ways (i) we model realistic and socially-salient missingness scenarios that go beyond Rubin's classic Missing Completely at Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR) settings, to include multi-mechanism missingness (when different missingness patterns co-exist in the data) and missingness shift (when the missingness mechanism changes between training and test) (ii) we evaluate imputers holistically, based on imputation quality and imputation fairness, as well as on the predictive performance, fairness and stability of the models that are trained and tested on the data post-imputation.\n  We use Shades-of-Null to conduct a large-scale empirical study involving 29,736 experimental pipelines, and find that while there is no single best-performing imputation approach for all missingness types, interesting trade-offs arise between predictive performance, fairness and stability, based on the combination of missingness scenario, imputer choice, and the architecture of the predictive model. We make Shades-of-Null publicly available, to enable researchers to rigorously evaluate missing value imputation methods on a wide range of metrics in plausible and socially meaningful scenarios.",
      "authors": [
        "Falaah Arif Khan",
        "Denys Herasymuk",
        "Nazar Protsiv",
        "Julia Stoyanovich"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T17:58:39+00:00",
          "link": "https://arxiv.org/abs/2409.07510v1",
          "size": "21872kb",
          "version": "v1"
        },
        {
          "date": "2024-10-30T01:06:42+00:00",
          "link": "https://arxiv.org/abs/2409.07510v2",
          "size": "16749kb",
          "version": "v2"
        },
        {
          "date": "2024-10-31T23:50:54+00:00",
          "link": "https://arxiv.org/abs/2409.07510v3",
          "size": "16749kb",
          "version": "v3"
        },
        {
          "date": "2025-02-05T00:42:46+00:00",
          "link": "https://arxiv.org/abs/2409.07510v4",
          "size": "26540kb",
          "version": "v4"
        },
        {
          "date": "2025-03-18T17:46:41+00:00",
          "link": "https://arxiv.org/abs/2409.07510v5",
          "size": "24803kb",
          "version": "v5"
        },
        {
          "date": "2025-07-18T20:08:32+00:00",
          "link": "https://arxiv.org/abs/2409.07510v6",
          "size": "16962kb",
          "version": "v6"
        }
      ],
      "title": "Still More Shades of Null: An Evaluation Suite for Responsible Missing Value Imputation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07510",
        "HTML": "https://arxiv.org/html/2409.07510",
        "PDF": "https://arxiv.org/pdf/2409.07510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an evaluation suite for missing value imputation, focusing on imputation quality and fairness in data pre-processing rather than LLM training data processing."
      },
      "tasks": [
        "Fairness",
        "Imputation"
      ],
      "repo_urls": [
        "https://github.com/falaaharifkhan/data-cleaning-stability"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14152",
      "abstract": "River water quality monitoring is important for aquatic life, livestock, and humans because clean water is critical to meeting food demand during the global food crisis. Excessive contaminants, including phosphate, deplete dissolved oxygen and trigger eutrophication, leading to serious health and ecological problems. Continuous sensors that track phosphate levels can therefore help prevent eutrophication. In this work we present a lithography-free phosphate sensor (P-sensor) that detects phosphate in river water at parts-per-billion levels. The device uses a solid-state indicator electrode formed by 3D-printed periodic polymer patterns (8 um feature size) coated with a thin phosphate ion-selective membrane. The P-sensor detects as little as 1 ppb phosphate across 0 - 475 ppm with a response time under 30 seconds. We validated the sensor on Rappahannock River water, Virginia (less than 0.8 ppm phosphate) at sites upstream and downstream of a sewage treatment plant and benchmarked the results against a commercial phosphate meter. A feed-forward neural network was trained to predict phosphate levels, achieving a mean-squared error below 1e-3, zero standard deviation, and a Pearson correlation coefficient of 0.997 for river samples. These results demonstrate a practical tool for continuous water-quality monitoring that can inform stakeholders and policymakers and ultimately improve public health.",
      "authors": [
        "Frank Efe Erukainure",
        "Feidra Gjata",
        "Matin Ataei Kachouei",
        "Henry Cox",
        "Md. Azahar Ali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T22:58:25+00:00",
          "link": "https://arxiv.org/abs/2507.14152v1",
          "size": "15583kb",
          "version": "v1"
        }
      ],
      "title": "Machine learning-enabled river water quality monitoring using lithography-free 3D-printed sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14152",
        "HTML": "https://arxiv.org/html/2507.14152",
        "PDF": "https://arxiv.org/pdf/2507.14152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses river water quality monitoring using 3D-printed sensors and machine learning but does not address any component of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14312",
      "abstract": "Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities but often fail to generalize under distribution shifts. Test-time adaptation (TTA) allows models to update at inference time without labeled data, typically via entropy minimization. However, this objective is fundamentally misaligned with the contrastive image-text training of VLMs, limiting adaptation performance and introducing failure modes such as pseudo-label drift and class collapse. We propose CLIPTTA, a new gradient-based TTA method for vision-language models that leverages a soft contrastive loss aligned with CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's gradients, showing how its batch-aware design mitigates the risk of collapse. We further extend CLIPTTA to the open-set setting, where both in-distribution (ID) and out-of-distribution (OOD) samples are encountered, using an Outlier Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75 datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms entropy-based objectives and is highly competitive with state-of-the-art TTA methods, outperforming them on a large number of datasets and exhibiting more stable performance across diverse shifts.",
      "authors": [
        "Marc Lafon",
        "Gustavo Adolfo Vargas Hakim",
        "Cl\\'ement Rambour",
        "Christian Desrosier",
        "Nicolas Thome"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:32:17+00:00",
          "link": "https://arxiv.org/abs/2507.14312v1",
          "size": "5192kb",
          "version": "v1"
        }
      ],
      "title": "CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14312",
        "HTML": "https://arxiv.org/html/2507.14312",
        "PDF": "https://arxiv.org/pdf/2507.14312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses vision-language models and test-time adaptation but does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.05932",
      "abstract": "Heart disease remains a significant threat to human health. As a non-invasive diagnostic tool, the electrocardiogram (ECG) is one of the most widely used methods for cardiac screening. However, the scarcity of high-quality ECG data, driven by privacy concerns and limited medical resources, creates a pressing need for effective ECG signal generation. Existing approaches for generating ECG signals typically rely on small training datasets, lack comprehensive evaluation frameworks, and overlook potential applications beyond data augmentation. To address these challenges, we propose DiffuSETS, a novel framework capable of generating ECG signals with high semantic alignment and fidelity. DiffuSETS accepts various modalities of clinical text reports and patient-specific information as inputs, enabling the creation of clinically meaningful ECG signals. Additionally, to address the lack of standardized evaluation in ECG generation, we introduce a comprehensive benchmarking methodology to assess the effectiveness of generative models in this domain. Our model achieve excellent results in tests, proving its superiority in the task of ECG generation. Furthermore, we showcase its potential to mitigate data scarcity while exploring novel applications in cardiology education and medical knowledge discovery, highlighting the broader impact of our work.",
      "authors": [
        "Yongfan Lai",
        "Jiabo Chen",
        "Deyun Zhang",
        "Yue Wang",
        "Shijia Geng",
        "Hongyan Li",
        "Shenda Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T12:55:34+00:00",
          "link": "https://arxiv.org/abs/2501.05932v1",
          "size": "2235kb",
          "version": "v1"
        }
      ],
      "title": "DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05932",
        "HTML": "https://arxiv.org/html/2501.05932",
        "PDF": "https://arxiv.org/pdf/2501.05932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on generating ECG signals conditioned on clinical text, focusing on medical data synthesis and evaluation frameworks, not related to LLM training data processing."
      },
      "models": [
        {
          "model_path": "PKUDigitalHealth/DiffuSETS_KT",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PKUDigitalHealth/DiffuSETS_KT"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Data Augmentation",
        "Diagnostic"
      ],
      "repo_urls": [
        "https://github.com/raiiyf/diffusets_exp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00024",
      "abstract": "Emotions have been shown to play a role in argument convincingness, yet this aspect is underexplored in the natural language processing (NLP) community. Unlike prior studies that use static analyses, focus on a single text domain or language, or treat emotion as just one of many factors, we introduce a dynamic framework inspired by manipulation checks commonly used in psychology and social science; leveraging LLM-based manipulation checks, this framework examines the extent to which perceived emotional intensity influences perceived convincingness. Through human evaluation of arguments across different languages, text domains, and topics, we find that in over half of cases, human judgments of convincingness remain unchanged despite variations in perceived emotional intensity; when emotions do have an impact, they more often enhance rather than weaken convincingness. We further analyze whether 11 LLMs behave like humans in the same scenario, finding that while LLMs generally mirror human patterns, they struggle to capture nuanced emotional effects in individual judgments.",
      "authors": [
        "Yanran Chen",
        "Steffen Eger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T10:04:44+00:00",
          "link": "https://arxiv.org/abs/2503.00024v1",
          "size": "1054kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:43:19+00:00",
          "link": "https://arxiv.org/abs/2503.00024v2",
          "size": "804kb",
          "version": "v2"
        }
      ],
      "title": "Do Emotions Really Affect Argument Convincingness? A Dynamic Approach with LLM-based Manipulation Checks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00024",
        "HTML": "https://arxiv.org/html/2503.00024",
        "PDF": "https://arxiv.org/pdf/2503.00024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on emotional intensity and convincingness in arguments, using LLM-based manipulation checks for evaluation rather than data processing for LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.20630",
      "abstract": "Multimodal immersive spatial drama generation focuses on creating continuous multi-speaker binaural speech with dramatic prosody based on multimodal prompts, with potential applications in AR, VR, and others. This task requires simultaneous modeling of spatial information and dramatic prosody based on multimodal inputs, with high data collection costs. To the best of our knowledge, our work is the first attempt to address these challenges. We construct MRSDrama, the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. Then, we propose ISDrama, the first immersive spatial drama generation model through multimodal prompting. ISDrama comprises these primary components: 1) Multimodal Pose Encoder, based on contrastive learning, considering the Doppler effect caused by moving speakers to extract unified pose information from multimodal prompts. 2) Immersive Drama Transformer, a flow-based mamba-transformer model that generates high-quality drama, incorporating Drama-MOE to select proper experts for enhanced prosody and pose control. We also design a context-consistent classifier-free guidance strategy to coherently generate complete drama. Experimental results show that ISDrama outperforms baseline models on objective and subjective metrics. The demos are available at https://aaronz345.github.io/ISDramaDemo. We provide the dataset and the evaluation code at https://huggingface.co/datasets/AaronZ345/MRSDrama and https://github.com/AaronZ345/ISDrama.",
      "authors": [
        "Yu Zhang",
        "Wenxiang Guo",
        "Changhao Pan",
        "Zhiyuan Zhu",
        "Tao Jin",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T10:56:44+00:00",
          "link": "https://arxiv.org/abs/2504.20630v1",
          "size": "3862kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T10:18:08+00:00",
          "link": "https://arxiv.org/abs/2504.20630v2",
          "size": "3714kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T03:12:00+00:00",
          "link": "https://arxiv.org/abs/2504.20630v3",
          "size": "3651kb",
          "version": "v3"
        }
      ],
      "title": "ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20630",
        "HTML": "https://arxiv.org/html/2504.20630",
        "PDF": "https://arxiv.org/pdf/2504.20630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a drama generation model and dataset called MRSDrama focusing on multimodal inputs, which does not relate to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "AaronZ345/MRSDrama",
          "downloads": "45230",
          "likes": "1",
          "link": "https://huggingface.co/datasets/AaronZ345/MRSDrama"
        }
      ],
      "tasks": [
        "Contrastive Learning",
        "Mamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06535",
      "abstract": "Robotic manipulation of unseen objects via natural language commands remains challenging. Language driven robotic grasping (LDRG) predicts stable grasp poses from natural language queries and RGB-D images. We propose MapleGrasp, a novel framework that leverages mask-guided feature pooling for efficient vision-language driven grasping. Our two-stage training first predicts segmentation masks from CLIP-based vision-language features. The second stage pools features within these masks to generate pixel-level grasp predictions, improving efficiency, and reducing computation. Incorporating mask pooling results in a 7% improvement over prior approaches on the OCID-VLG benchmark. Furthermore, we introduce RefGraspNet, an open-source dataset eight times larger than existing alternatives, significantly enhancing model generalization for open-vocabulary grasping. MapleGrasp scores a strong grasping accuracy of 89\\% when compared with competing methods in the RefGraspNet benchmark. Our method achieves comparable performance to larger Vision-Language-Action models on the LIBERO benchmark, and shows significantly better generalization to unseen tasks. Real-world experiments on a Franka arm demonstrate 73% success rate with unseen objects, surpassing competitive baselines by 11%. Code will be released after publication.",
      "authors": [
        "Vineet Bhat",
        "Naman Patel",
        "Prashanth Krishnamurthy",
        "Ramesh Karri",
        "Farshad Khorrami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T21:06:00+00:00",
          "link": "https://arxiv.org/abs/2506.06535v1",
          "size": "3932kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T06:51:18+00:00",
          "link": "https://arxiv.org/abs/2506.06535v2",
          "size": "21042kb",
          "version": "v2"
        }
      ],
      "title": "MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06535",
        "HTML": "https://arxiv.org/html/2506.06535",
        "PDF": "https://arxiv.org/pdf/2506.06535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for robotic grasping guided by language commands and introduces a dataset to improve model generalization in this task. It does not involve any training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14419",
      "abstract": "Prior work proposed simple test-time scaling, a method for replicating this scaling behavior with models distilled from o1-like models by manually controlling test-time compute: either scaling down by enforcing a maximum length or scaling up by iteratively appending \"Wait\" when the model is about to terminate its generation. This paper presents an analysis of simple test-time scaling and finds that the scaling behavior is largely attributed to scaling down by enforcing a maximum length. In contrast, fine-tuning on long CoT data distilled from o1-like models has no significant impact on scaling behavior, and scaling up by appending \"Wait\" leads to inconsistencies, as the model may oscillate between solutions. A key distinction exists between scaling down by enforcing a maximum length and scaling up test-time compute in o1-like models, such as DeepSeek-R1\\@. These models are typically allowed to utilize as much compute as needed, with the only constraint being the model's maximum supported length. By learning to naturally scale up test-time compute during reinforcement learning, o1-like models surpass their peak performance when scaling up. In contrast, simple test-time scaling progressively imposes a lower upper limit on model performance as it scales down. While replicating the test-time scaling behavior of o1 models can be straightforward by scaling down, it is crucial to recognize that the goal of scaling test-time compute is to unlock higher performance -- beyond what the model could originally achieve -- rather than merely reproducing the appearance of scaling behavior.",
      "authors": [
        "Guojun Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T00:28:10+00:00",
          "link": "https://arxiv.org/abs/2507.14419v1",
          "size": "680kb",
          "version": "v1"
        }
      ],
      "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14419",
        "HTML": "https://arxiv.org/html/2507.14419",
        "PDF": "https://arxiv.org/pdf/2507.14419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines test-time scaling methods for deep learning models, particularly focusing on compute strategies. It lacks focus on LLM training data processing, data collection, or dataset improvement techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15700",
      "abstract": "The rate-distortion (RD) theory is one of the key concepts in information theory, providing theoretical limits for compression performance and guiding the source coding design, with both theoretical and practical significance. The Blahut-Arimoto (BA) algorithm, as a classical algorithm to compute RD functions, encounters computational challenges when applied to high-dimensional scenarios. In recent years, many neural methods have attempted to compute high-dimensional RD problems from the perspective of implicit generative models. Nevertheless, these approaches often neglect the reconstruction of the optimal conditional distribution or rely on unreasonable prior assumptions. In face of these issues, we propose an innovative energy-based modeling framework that leverages the connection between the RD dual form and the free energy in statistical physics, achieving effective reconstruction of the optimal conditional distribution.The proposed algorithm requires training only a single neural network and circumvents the challenge of computing the normalization factor in energy-based models using the Markov chain Monte Carlo (MCMC) sampling. Experimental results demonstrate the significant effectiveness of the proposed algorithm in estimating high-dimensional RD functions and reconstructing the optimal conditional distribution.",
      "authors": [
        "Shitong Wu",
        "Sicheng Xu",
        "Lingyi Chen",
        "Huihui Wu",
        "and Wenyi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:09:50+00:00",
          "link": "https://arxiv.org/abs/2507.15700v1",
          "size": "249kb",
          "version": "v1"
        }
      ],
      "title": "Estimating Rate-Distortion Functions Using the Energy-Based Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15700",
        "HTML": "https://arxiv.org/html/2507.15700",
        "PDF": "https://arxiv.org/pdf/2507.15700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses estimating rate-distortion functions using an energy-based model and focuses on information theory and model computation efficiency without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2304.02062",
      "abstract": "This paper derives an a posteriori error estimator for the nonlinear first-order optimality conditions associated with the electrically and flexoelectrically coupled Frank-Oseen model of liquid crystals, building on previous results for elastic systems. The estimator is proposed for a penalty approach to imposing the unit-length constraint required by the model. Moreover, theory is proven establishing that the estimator provides a reliable estimate of global approximation error and an efficient measure of local error, suitable for use in adaptive refinement. Numerical experiments demonstrate significant improvements in efficiency with adaptive refinement guided by the proposed estimator in a multilevel, nested-iteration framework and superior physical properties for challenging electrically coupled systems.",
      "authors": [
        "J.H. Adler and D. B. Emerson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-04T18:25:25+00:00",
          "link": "https://arxiv.org/abs/2304.02062v1",
          "size": "1203kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:00:33+00:00",
          "link": "https://arxiv.org/abs/2304.02062v2",
          "size": "1537kb",
          "version": "v2"
        }
      ],
      "title": "An A Posteriori Error Estimator for Electrically Coupled Liquid Crystal Equilibrium Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.02062",
        "HTML": "https://arxiv.org/html/2304.02062",
        "PDF": "https://arxiv.org/pdf/2304.02062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an error estimator for liquid crystal model configurations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.03034",
      "abstract": "We propose a novel framework for representing neural fields on triangle meshes that is multi-resolution across both spatial and frequency domains. Inspired by the Neural Fourier Filter Bank (NFFB), our architecture decomposes the spatial and frequency domains by associating finer spatial resolution levels with higher frequency bands, while coarser resolutions are mapped to lower frequencies. To achieve geometry-aware spatial decomposition we leverage multiple DiffusionNet components, each associated with a different spatial resolution level. Subsequently, we apply a Fourier feature mapping to encourage finer resolution levels to be associated with higher frequencies. The final signal is composed in a wavelet-inspired manner using a sine-activated MLP, aggregating higher-frequency signals on top of lower-frequency ones. Our architecture attains high accuracy in learning complex neural fields and is robust to discontinuities, exponential scale variations of the target field, and mesh modification. We demonstrate the effectiveness of our approach through its application to diverse neural fields, such as synthetic RGB functions, UV texture coordinates, and vertex normals, illustrating different challenges. To validate our method, we compare its performance against two alternatives, showcasing the advantages of our multi-resolution architecture.",
      "authors": [
        "Avigail Cohen Rimon",
        "Tal Shnitzer",
        "and Mirela Ben Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T19:08:13+00:00",
          "link": "https://arxiv.org/abs/2409.03034v1",
          "size": "45886kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:20:41+00:00",
          "link": "https://arxiv.org/abs/2409.03034v2",
          "size": "140235kb",
          "version": "v2"
        }
      ],
      "title": "MDNF: Multi-Diffusion-Nets for Neural Fields on Meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03034",
        "HTML": "https://arxiv.org/html/2409.03034",
        "PDF": "https://arxiv.org/pdf/2409.03034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for neural fields on meshes focused on multi-resolution spatial and frequency domains. It does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.02482",
      "abstract": "Software practitioners often encounter workplace unfairness, such as unequal recognition and gender bias. While the link between fairness and job satisfaction has been established in other fields, its relevance to software professionals remains underexplored. This study examines how fairness perceptions relate to job satisfaction among software practitioners, focusing on both general trends and demographic-specific differences. We conducted an online survey of 108 software practitioners, followed by ordinal logistic regression to analyze the relationship between fairness perceptions and job satisfaction in software engineering contexts, with moderation analysis examining how this relationship varies across demographic groups. Our findings indicate that all four fairness dimensions (namely distributive, procedural, interpersonal, and informational fairness) significantly affect overall job satisfaction and satisfaction with job security. Among these, interpersonal fairness has the biggest impact. The relationship between fairness and job satisfaction is stronger for female, ethnically underrepresented, less experienced practitioners, and those with work limitations. Fairness in authorship emerged as an important factor for job satisfaction collectively, while fairness in policy implementation, high-demand situations, and working hours impacted specific demographic groups. This study highlights the role of fairness among software practitioners, offering strategies for organizations to promote fair practices and targeted approaches for certain demographic groups.",
      "authors": [
        "Emeralda Sesari",
        "Federica Sarro",
        "Ayushi Rastogi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T13:40:00+00:00",
          "link": "https://arxiv.org/abs/2410.02482v1",
          "size": "1432kb",
          "version": "v1"
        },
        {
          "date": "2024-12-04T17:56:08+00:00",
          "link": "https://arxiv.org/abs/2410.02482v2",
          "size": "938kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T09:31:55+00:00",
          "link": "https://arxiv.org/abs/2410.02482v3",
          "size": "900kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T18:44:21+00:00",
          "link": "https://arxiv.org/abs/2410.02482v4",
          "size": "733kb",
          "version": "v4"
        }
      ],
      "title": "It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02482",
        "HTML": "https://arxiv.org/html/2410.02482",
        "PDF": "https://arxiv.org/pdf/2410.02482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines the relationship between fairness perceptions and job satisfaction among software practitioners, without any focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12462",
      "abstract": "We present SpatialTrackerV2, a feed-forward 3D point tracking method for monocular videos. Going beyond modular pipelines built on off-the-shelf components for 3D tracking, our approach unifies the intrinsic connections between point tracking, monocular depth, and camera pose estimation into a high-performing and feedforward 3D point tracker. It decomposes world-space 3D motion into scene geometry, camera ego-motion, and pixel-wise object motion, with a fully differentiable and end-to-end architecture, allowing scalable training across a wide range of datasets, including synthetic sequences, posed RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms existing 3D tracking methods by 30%, and matches the accuracy of leading dynamic 3D reconstruction approaches while running 50$\\times$ faster.",
      "authors": [
        "Yuxi Xiao",
        "Jianyuan Wang",
        "Nan Xue",
        "Nikita Karaev",
        "Yuri Makarov",
        "Bingyi Kang",
        "Xing Zhu",
        "Hujun Bao",
        "Yujun Shen",
        "Xiaowei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:03+00:00",
          "link": "https://arxiv.org/abs/2507.12462v1",
          "size": "13458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T02:07:12+00:00",
          "link": "https://arxiv.org/abs/2507.12462v2",
          "size": "13458kb",
          "version": "v2"
        }
      ],
      "title": "SpatialTrackerV2: 3D Point Tracking Made Easy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12462",
        "HTML": "https://arxiv.org/html/2507.12462",
        "PDF": "https://arxiv.org/pdf/2507.12462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for 3D point tracking using videos, which does not relate to LLM training data processing or involve any data operations for pretraining or fine-tuning language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14650",
      "abstract": "In this article we propose an extension to the typed natural deduction calculus TNDPQ to model verification of individual fairness and intersectionality in probabilistic classifiers. Their interpretation is obtained by formulating specific conditions for the application of the structural rule of Weakening. Such restrictions are given by causal labels used to check for conditional independence between protected and target variables.",
      "authors": [
        "Leonardo Ceragioli and Giuseppe Primiero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:51:36+00:00",
          "link": "https://arxiv.org/abs/2507.14650v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "A Proof System with Causal Labels (Part I): checking Individual Fairness and Intersectionality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14650",
        "HTML": "https://arxiv.org/html/2507.14650",
        "PDF": "https://arxiv.org/pdf/2507.14650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a proof system for checking fairness in classifiers, with no mention of LLM training data or data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15212",
      "abstract": "In this paper, we introduce MeshMamba, a neural network model for learning 3D articulated mesh models by employing the recently proposed Mamba State Space Models (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large number of input tokens, enabling the generation and reconstruction of body mesh models with more than 10,000 vertices, capturing clothing and hand geometries. The key to effectively learning MeshMamba is the serialization technique of mesh vertices into orderings that are easily processed by Mamba. This is achieved by sorting the vertices based on body part annotations or the 3D vertex locations of a template mesh, such that the ordering respects the structure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D, a denoising diffusion model for generating 3D articulated meshes and 2) Mamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape and pose from a single image. Experimental results showed that MambaDiff3D can generate dense 3D human meshes in clothes, with grasping hands, etc., and outperforms previous approaches in the 3D human shape generation task. Additionally, Mamba-HMR extends the capabilities of previous non-parametric human mesh recovery approaches, which were limited to handling body-only poses using around 500 vertex tokens, to the whole-body setting with face and hands, while achieving competitive performance in (near) real-time.",
      "authors": [
        "Yusuke Yoshiyasu",
        "Leyuan Sun",
        "Ryusuke Sagawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:24:30+00:00",
          "link": "https://arxiv.org/abs/2507.15212v1",
          "size": "10363kb",
          "version": "v1"
        }
      ],
      "title": "MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15212",
        "HTML": "https://arxiv.org/html/2507.15212",
        "PDF": "https://arxiv.org/pdf/2507.15212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MeshMamba for learning 3D mesh models and associated applications; it is centered on 3D mesh generation and reconstruction, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.06950",
      "abstract": "In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots. Most previous work in exploration assumes that robot localization is solved. However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself. Furthermore, actions that reduce localization errors may be at direct odds with the exploration task. We propose a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent. In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots. Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments. From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90% in translation and approximately 75% in yaw, and the uncertainties in pose estimates and semantic maps by over 70% and 65%, respectively. Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available.",
      "authors": [
        "Yuezhan Tao",
        "Xu Liu",
        "Igor Spasojevic",
        "Saurav Agarwal",
        "Vijay Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-13T13:33:03+00:00",
          "link": "https://arxiv.org/abs/2309.06950v1",
          "size": "6929kb",
          "version": "v1"
        },
        {
          "date": "2023-10-13T04:28:49+00:00",
          "link": "https://arxiv.org/abs/2309.06950v2",
          "size": "6928kb",
          "version": "v2"
        },
        {
          "date": "2024-02-13T15:35:16+00:00",
          "link": "https://arxiv.org/abs/2309.06950v3",
          "size": "6765kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T15:06:04+00:00",
          "link": "https://arxiv.org/abs/2309.06950v4",
          "size": "6765kb",
          "version": "v4"
        }
      ],
      "title": "3D Active Metric-Semantic SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.06950",
        "HTML": "https://arxiv.org/html/2309.06950",
        "PDF": "https://arxiv.org/pdf/2309.06950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for 3D metric-semantic SLAM, primarily focusing on mapping and localization in GPS-denied environments, with no relation to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.18593",
      "abstract": "We present a novel, power- & hardware-efficient, multiuser, multibeam RIS (Reflective Intelligent Surface) architecture for multiuser MIMO, especially for very high frequency bands (e.g., high mmWave and sub-THz), where channels are typically sparse in the beamspace and LOS is the dominant component. The key module is formed by an active multiantenna feeder (AMAF) with a small number of active antennas, placed in the near field of a RIS with a much larger number of passive controllable reflecting elements. We propose a pragmatic approach to obtain a steerable beam with high gain and very low sidelobes. Then K independently controlled beams can be achieved by closely stacking K such AMAF-RIS modules. Our analysis includes the mutual interference between the modules and the fact that, due to the delay difference of propagation through the AMAF-RIS structure, the resulting channel matrix is frequency selective even for pure LOS propagation. We consider a 3D geometry and show that \"beam focusing\" is in fact possible (and much more effective in terms of coverage) also in the far-field, by creating spotbeams with limited footprint both in angle and in range. Our results show that: 1) simple RF beamforming (BF) without computationally expensive baseband multiuser precoding is sufficient to practically eliminate multiuser interference when the users are chosen with sufficient angular/range separation, thanks to the extremely low sidelobe beams; 2) the impact of beam pointing errors with standard deviation as large as 2.5 deg and RIS quantized phase-shifters with quantization bits > 2 is essentially negligible; 3) The proposed architecture is more power efficient & much simpler from a hardware implementation viewpoint than standard active arrays with the same BF performance. We show also that the array gain of the proposed AMAF-RIS structure is linear with the RIS aperture.",
      "authors": [
        "Krishan Kumar Tiwari",
        "Giuseppe Caire"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-30T14:37:06+00:00",
          "link": "https://arxiv.org/abs/2311.18593v1",
          "size": "3415kb",
          "version": "v1"
        },
        {
          "date": "2023-12-04T19:39:30+00:00",
          "link": "https://arxiv.org/abs/2311.18593v2",
          "size": "3415kb",
          "version": "v2"
        }
      ],
      "title": "A New Old Idea: Beam-Steering Reflectarrays for Efficient Sub-THz Multiuser MIMO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.18593",
        "PDF": "https://arxiv.org/pdf/2311.18593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a multiuser MIMO architecture for high-frequency communication systems. It does not address LLM training data processing strategies or operations."
      },
      "tasks": [
        "3D geometry",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08622",
      "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have revolutionized visual content creation across various applications, including advertising, personalized media, and design prototyping. However, crafting effective textual prompts to guide these models remains challenging, often requiring extensive trial and error. Existing prompt inversion approaches, such as soft and hard prompt techniques, are not so effective due to the limited interpretability and incoherent prompt generation. To address these issues, we propose Visually Guided Decoding (VGD), a gradient-free approach that leverages large language models (LLMs) and CLIP-based guidance to generate coherent and semantically aligned prompts. In essence, VGD utilizes the robust text generation capabilities of LLMs to produce human-readable prompts. Further, by employing CLIP scores to ensure alignment with user-specified visual concepts, VGD enhances the interpretability, generalization, and flexibility of prompt generation without the need for additional training. Our experiments demonstrate that VGD outperforms existing prompt inversion techniques in generating understandable and contextually relevant prompts, facilitating more intuitive and controllable interactions with text-to-image models.",
      "authors": [
        "Donghoon Kim",
        "Minji Bae",
        "Kyuhong Shim",
        "Byonghyo Shim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T14:40:22+00:00",
          "link": "https://arxiv.org/abs/2505.08622v1",
          "size": "22250kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:47:57+00:00",
          "link": "https://arxiv.org/abs/2505.08622v2",
          "size": "22250kb",
          "version": "v2"
        }
      ],
      "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08622",
        "HTML": "https://arxiv.org/html/2505.08622",
        "PDF": "https://arxiv.org/pdf/2505.08622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for generating prompts to guide text-to-image models and does not relate to LLM training data processing."
      },
      "tasks": [
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07778",
      "abstract": "Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks.",
      "authors": [
        "Wooseong Jeong",
        "Jegyeong Cho",
        "Youngho Yoon",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:58:32+00:00",
          "link": "https://arxiv.org/abs/2507.07778v1",
          "size": "2554kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:48:40+00:00",
          "link": "https://arxiv.org/abs/2507.07778v2",
          "size": "2555kb",
          "version": "v2"
        }
      ],
      "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07778",
        "HTML": "https://arxiv.org/html/2507.07778",
        "PDF": "https://arxiv.org/pdf/2507.07778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses synchronizing multiple tasks during test-time training. It focuses on the adaptation of neural networks during deployment, not on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13346",
      "abstract": "We introduce AutoPartGen, a model that generates objects composed of 3D parts in an autoregressive manner. This model can take as input an image of an object, 2D masks of the object's parts, or an existing 3D object, and generate a corresponding compositional 3D reconstruction. Our approach builds upon 3DShape2VecSet, a recent latent 3D representation with powerful geometric expressiveness. We observe that this latent space exhibits strong compositional properties, making it particularly well-suited for part-based generation tasks. Specifically, AutoPartGen generates object parts autoregressively, predicting one part at a time while conditioning on previously generated parts and additional inputs, such as 2D images, masks, or 3D objects. This process continues until the model decides that all parts have been generated, thus determining automatically the type and number of parts. The resulting parts can be seamlessly assembled into coherent objects or scenes without requiring additional optimization. We evaluate both the overall 3D generation capabilities and the part-level generation quality of AutoPartGen, demonstrating that it achieves state-of-the-art performance in 3D part generation.",
      "authors": [
        "Minghao Chen",
        "Jianyuan Wang",
        "Roman Shapovalov",
        "Tom Monnier",
        "Hyunyoung Jung",
        "Dilin Wang",
        "Rakesh Ranjan",
        "Iro Laina",
        "Andrea Vedaldi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:47+00:00",
          "link": "https://arxiv.org/abs/2507.13346v1",
          "size": "15452kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T22:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.13346v2",
          "size": "15451kb",
          "version": "v2"
        }
      ],
      "title": "AutoPartGen: Autogressive 3D Part Generation and Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13346",
        "HTML": "https://arxiv.org/html/2507.13346",
        "PDF": "https://arxiv.org/pdf/2507.13346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "AutoPartGen deals with 3D part generation and does not touch upon aspects of data processing specifically for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15397",
      "abstract": "Denoiser models have become powerful tools for inverse problems, enabling the use of pretrained networks to approximate the score of a smoothed prior distribution. These models are often used in heuristic iterative schemes aimed at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal operator of the negative log-prior plays a central role. In practice, this operator is intractable, and practitioners plug in a pretrained denoiser as a surrogate-despite the lack of general theoretical justification for this substitution. In this work, we show that a simple algorithm, closely related to several used in practice, provably converges to the proximal operator under a log-concavity assumption on the prior $p$. We show that this algorithm can be interpreted as a gradient descent on smoothed proximal objectives. Our analysis thus provides a theoretical foundation for a class of empirically successful but previously heuristic methods.",
      "authors": [
        "Scott Pesme",
        "Giacomo Meanti",
        "Michael Arbel",
        "Julien Mairal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:59:33+00:00",
          "link": "https://arxiv.org/abs/2507.15397v1",
          "size": "1352kb",
          "version": "v1"
        }
      ],
      "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15397",
        "HTML": "https://arxiv.org/html/2507.15397",
        "PDF": "https://arxiv.org/pdf/2507.15397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on denoiser models for solving inverse problems in MAP optimization, with no mention of LLM training data processing operations like dataset creation or quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15676",
      "abstract": "This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.",
      "authors": [
        "Reza Vatankhah Barenji and Sina Khoshgoftar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:39:08+00:00",
          "link": "https://arxiv.org/abs/2507.15676v1",
          "size": "932kb",
          "version": "v1"
        }
      ],
      "title": "Agentic AI for autonomous anomaly management in complex systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15676",
        "PDF": "https://arxiv.org/pdf/2507.15676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses agentic AI for anomaly management, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15742",
      "abstract": "Term frequency-inverse document frequency, or TF-IDF for short, is arguably the most celebrated mathematical expression in the history of information retrieval. Conceived as a simple heuristic quantifying the extent to which a given term's occurrences are concentrated in any one given document out of many, TF-IDF and its many variants are routinely used as term-weighting schemes in diverse text analysis applications. There is a growing body of scholarship dedicated to placing TF-IDF on a sound theoretical foundation. Building on that tradition, this paper justifies the use of TF-IDF to the statistics community by demonstrating how the famed expression can be understood from a significance testing perspective. We show that the common TF-IDF variant TF-ICF is, under mild regularity conditions, closely related to the negative logarithm of the $p$-value from a one-tailed version of Fisher's exact test of statistical significance. As a corollary, we establish a connection between TF-IDF and the said negative log-transformed $p$-value under certain idealized assumptions. We further demonstrate, as a limiting case, that this same quantity converges to TF-IDF in the limit of an infinitely large document collection. The Fisher's exact test justification of TF-IDF equips the working statistician with a ready explanation of the term-weighting scheme's long-established effectiveness.",
      "authors": [
        "Paul Sheridan",
        "Zeyad Ahmed",
        "Aitazaz A. Farooque"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:54:23+00:00",
          "link": "https://arxiv.org/abs/2507.15742v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "A Fisher's exact test justification of the TF-IDF term-weighting scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15742",
        "HTML": "https://arxiv.org/html/2507.15742",
        "PDF": "https://arxiv.org/pdf/2507.15742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on providing a statistical justification for the TF-IDF term-weighting scheme, which is unrelated to the processing of training data for LLMs or relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18202",
      "abstract": "This paper leverages machine learning algorithms to forecast and analyze financial time series. The process begins with a denoising autoencoder to filter out random noise fluctuations from the main contract price data. Then, one-dimensional convolution reduces the dimensionality of the filtered data and extracts key information. The filtered and dimensionality-reduced price data is fed into a GANs network, and its output serve as input of a fully connected network. Through cross-validation, a model is trained to capture features that precede large price fluctuations. The model predicts the likelihood and direction of significant price changes in real-time price sequences, placing trades at moments of high prediction accuracy. Empirical results demonstrate that using autoencoders and convolution to filter and denoise financial data, combined with GANs, achieves a certain level of predictive performance, validating the capabilities of machine learning algorithms to discover underlying patterns in financial sequences. Keywords - CNN;GANs; Cryptocurrency; Prediction.",
      "authors": [
        "Zhuohuan Hu",
        "Richard Yu",
        "Zizhou Zhang",
        "Haoran Zheng",
        "Qianying Liu",
        "Yining Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T06:14:34+00:00",
          "link": "https://arxiv.org/abs/2412.18202v1",
          "size": "546kb",
          "version": "v1"
        },
        {
          "date": "2024-12-27T05:28:43+00:00",
          "link": "https://arxiv.org/abs/2412.18202v2",
          "size": "545kb",
          "version": "v2"
        },
        {
          "date": "2025-01-22T18:21:07+00:00",
          "link": "https://arxiv.org/abs/2412.18202v3",
          "size": "548kb",
          "version": "v3"
        },
        {
          "date": "2025-02-01T07:22:53+00:00",
          "link": "https://arxiv.org/abs/2412.18202v4",
          "size": "548kb",
          "version": "v4"
        },
        {
          "date": "2025-05-29T05:52:32+00:00",
          "link": "https://arxiv.org/abs/2412.18202v5",
          "size": "1238kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T06:18:58+00:00",
          "link": "https://arxiv.org/abs/2412.18202v6",
          "size": "263kb",
          "version": "v6"
        }
      ],
      "title": "Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18202",
        "PDF": "https://arxiv.org/pdf/2412.18202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research utilizes machine learning algorithms for cryptocurrency trading strategies, focusing on financial time series data rather than LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15220",
      "abstract": "Identifying claims requiring verification is a critical task in automated fact-checking, especially given the proliferation of misinformation on social media platforms. Despite notable progress, challenges remain-particularly in handling multilingual data prevalent in online discourse. Recent efforts have focused on fine-tuning pre-trained multilingual language models to address this. While these models can handle multiple languages, their ability to effectively transfer cross-lingual knowledge for detecting claims spreading on social media remains under-explored. In this paper, we introduce EX-Claim, an entity-aware cross-lingual claim detection model that generalizes well to handle multilingual claims. The model leverages entity information derived from named entity recognition and entity linking techniques to improve the language-level performance of both seen and unseen languages during training. Extensive experiments conducted on three datasets from different social media platforms demonstrate that our proposed model stands out as an effective solution, demonstrating consistent performance gains across 27 languages and robust knowledge transfer between languages seen and unseen during training.",
      "authors": [
        "Rrubaa Panchendrarajan and Arkaitz Zubiaga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T14:00:55+00:00",
          "link": "https://arxiv.org/abs/2503.15220v1",
          "size": "802kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T11:33:29+00:00",
          "link": "https://arxiv.org/abs/2503.15220v2",
          "size": "802kb",
          "version": "v2"
        },
        {
          "date": "2025-07-04T08:31:47+00:00",
          "link": "https://arxiv.org/abs/2503.15220v3",
          "size": "911kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T09:12:52+00:00",
          "link": "https://arxiv.org/abs/2503.15220v4",
          "size": "900kb",
          "version": "v4"
        }
      ],
      "title": "Entity-aware Cross-lingual Claim Detection for Automated Fact-checking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15220",
        "HTML": "https://arxiv.org/html/2503.15220",
        "PDF": "https://arxiv.org/pdf/2503.15220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on claim detection for automated fact-checking, particularly in a multilingual context, but does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Entity Linking",
        "Fact Checking",
        "Misinformation",
        "named-entity-recognition",
        "Named Entity Recognition",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/RubaP/Ex-Claim"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12498",
      "abstract": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction, which effectively balances rendering quality, efficiency, and speed. However, existing 3DGS approaches usually generate plausible outputs and face significant challenges in complex scene reconstruction, manifesting as incomplete holistic structural outlines and unclear local lighting effects. To address these issues simultaneously, we propose a novel decoupled optimization framework, which integrates wavelet decomposition into 3D Gaussian Splatting and 2D sampling. Technically, through 3D wavelet decomposition, our approach divides point clouds into high-frequency and low-frequency components, enabling targeted optimization for each. The low-frequency component captures global structural outlines and manages the distribution of Gaussians through voxelization. In contrast, the high-frequency component restores intricate geometric and textural details while incorporating a relight module to mitigate lighting artifacts and enhance photorealistic rendering. Additionally, a 2D wavelet decomposition is applied to the training images, simulating radiance variations. This provides critical guidance for high-frequency detail reconstruction, ensuring seamless integration of details with the global structure. Extensive experiments on challenging datasets demonstrate our method achieves state-of-the-art performance across various metrics, surpassing existing approaches and advancing the field of 3D scene reconstruction.",
      "authors": [
        "Beizhen Zhao",
        "Yifan Zhou",
        "Sicheng Yu",
        "Zijian Wang",
        "Hao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.12498v1",
          "size": "24707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T01:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.12498v2",
          "size": "24702kb",
          "version": "v2"
        }
      ],
      "title": "Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12498",
        "HTML": "https://arxiv.org/html/2507.12498",
        "PDF": "https://arxiv.org/pdf/2507.12498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes improvements for 3D scene reconstruction using wavelet decomposition, which is not related to LLM training data processing or any operations like data curation or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12630",
      "abstract": "Channel estimation is crucial in wireless communications. However, in many papers neural networks are frequently tested by training and testing on one example channel or similar channels. This is because data-driven methods often degrade on new data which they are not trained on, as they cannot extrapolate their training knowledge. This is despite the fact physical channels are often assumed to be time-variant. However, due to the low latency requirements and limited computing resources, neural networks may not have enough time and computing resources to execute online training to fine-tune the parameters. This motivates us to design offline-trained neural networks that can perform robustly over wireless channels, but without any actual channel information being known at design time. In this paper, we propose design criteria to generate synthetic training datasets for neural networks, which guarantee that after training the resulting networks achieve a certain mean squared error (MSE) on new and previously unseen channels. Therefore, trained neural networks require no prior channel information or parameters update for real-world implementations. Based on the proposed design criteria, we further propose a benchmark design which ensures intelligent operation for different channel profiles. To demonstrate general applicability, we use neural networks with different levels of complexity to show that the generalization achieved appears to be independent of neural network architecture. From simulations, neural networks achieve robust generalization to wireless channels with both fixed channel profiles and variable delay spreads.",
      "authors": [
        "Dianxin Luan and John Thompson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:04:37+00:00",
          "link": "https://arxiv.org/abs/2507.12630v1",
          "size": "2484kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T21:16:40+00:00",
          "link": "https://arxiv.org/abs/2507.12630v2",
          "size": "2484kb",
          "version": "v2"
        }
      ],
      "title": "Achieving Robust Channel Estimation Neural Networks by Designed Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12630",
        "HTML": "https://arxiv.org/html/2507.12630",
        "PDF": "https://arxiv.org/pdf/2507.12630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes design criteria for generating synthetic training datasets to improve the generalization of neural networks over wireless channels, making a direct contribution to training data processing through dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14504",
      "abstract": "The #2-SAT and #3-SAT problems involve counting the number of satisfying assignments (also called models) for instances of 2-SAT and 3-SAT, respectively. In 2010, Zhou et al. proposed an $\\mathcal{O}^*(1.1892^m)$-time algorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes the number of clauses. In this paper, we show that the weighted versions of #2-SAT and #3-SAT can be solved in $\\mathcal{O}^*(1.1082^m)$ and $\\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to the unweighted cases and achieve substantial improvements over the previous results. These advancements are enabled by the introduction of novel reduction rules, a refined analysis of branching operations, and the application of path decompositions on the primal and dual graphs of the formula.",
      "authors": [
        "Junqiang Peng",
        "Zimo Sheng",
        "Mingyu Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:32:36+00:00",
          "link": "https://arxiv.org/abs/2507.14504v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "New Algorithms for #2-SAT and #3-SAT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14504",
        "HTML": "https://arxiv.org/html/2507.14504",
        "PDF": "https://arxiv.org/pdf/2507.14504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents algorithms for the #2-SAT and #3-SAT problems, focusing on algorithmic improvements in satisfiability problems, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14722",
      "abstract": "Automated theorem proving (ATP) has been a classical problem in artificial intelligence since its inception, yet it remains challenging due to its vast state and action space. Large language models (LLMs) have recently emerged as a promising heuristic for ATP, but they lack correctness guarantees and thus require interaction with a proof verifier. Such interactions typically follow one of two approaches: black-box interaction, which does not utilize intermediate proof states, or white-box approaches, which allow for incremental proof construction and examination of intermediate states. While black-box approaches have directly benefited from recent LLM advances, white-box methods have comparatively lagged behind. In this paper, we address this gap by introducing LeanTree, which consists of (i) a tool built in the Lean 4 language that factorizes complex proof states into simpler, independent branches, and (ii) a dataset of these factorized intermediate states. Our white-box tooling offers several advantages over black-box approaches: it simplifies evaluation, reduces necessary context, generates richer training data, enables parallel search across multiple states, supports efficient reuse of states, and provides feedback in case of errors. Our preliminary results hint that white-box approaches outperform black-box alternatives in some settings.",
      "authors": [
        "Mat\\v{e}j Kripner",
        "Michal \\v{S}ustr",
        "Milan Straka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.14722v1",
          "size": "235kb",
          "version": "v1"
        }
      ],
      "title": "LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14722",
        "HTML": "https://arxiv.org/html/2507.14722",
        "PDF": "https://arxiv.org/pdf/2507.14722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces LeanTree for automated theorem proving with LLMs, focusing on factorized proof states. It does not pertain to LLM training data operations such as dataset creation or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15659",
      "abstract": "This paper presents a cost-effective and distributed flow monitoring platform for collecting unsampled IPFIX data exclusively using open-source tools, which is implemented at the University of T\\\"ubingen. An overview of all tools is given and their use is explained.",
      "authors": [
        "Gabriel Paradzik",
        "Benjamin Steinert",
        "Heinrich Abele",
        "Michael Menth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.15659v1",
          "size": "495kb",
          "version": "v1"
        }
      ],
      "title": "SENSOR: A Cost-Efficient Open-Source Flow Monitoring Platform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15659",
        "HTML": "https://arxiv.org/html/2507.15659",
        "PDF": "https://arxiv.org/pdf/2507.15659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a flow monitoring platform for IPFIX data using open-source tools, focusing on networking and flow monitoring rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09183",
      "abstract": "Few-Shot Class-Incremental Learning (FSCIL) faces dual challenges of data scarcity and incremental learning in real-world scenarios. While pool-based prompting methods have demonstrated success in traditional incremental learning, their effectiveness in FSCIL settings remains unexplored. This paper presents the first study of current prompt pool methods in FSCIL tasks, revealing an unanticipated performance degradation in incremental sessions. Through comprehensive analysis, we identify that this phenomenon stems from token-dimension saturation: with limited data, excessive prompts compete for task-relevant information, leading to model overfitting. Based on this finding, we propose LGSP-Prompt (Local-Global Spatial Prompting), which innovatively shifts pool-based prompt learning from the token dimension to the spatial dimension. LGSP-Prompt generates spatial prompts by synergistically combining local spatial features and global frequency-domain representations to highlight key patterns in input images. We construct two spatial prompt pools enabling dynamic prompt selection to maintain acquired knowledge while effectively learning novel sessions. Extensive experiments demonstrate that our approach achieves state-of-the-art performance across multiple FSCIL benchmarks, showing significant advantages in both base knowledge preservation and incremental learning. Our implementation is available at https://github.com/Jywsuperman/LGSP.",
      "authors": [
        "Yongwei Jiang",
        "Yixiong Zou",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:08:34+00:00",
          "link": "https://arxiv.org/abs/2507.09183v1",
          "size": "29714kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:01:51+00:00",
          "link": "https://arxiv.org/abs/2507.09183v2",
          "size": "29714kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Pool-based Prompt Learning for Few-shot Class-incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09183",
        "HTML": "https://arxiv.org/html/2507.09183",
        "PDF": "https://arxiv.org/pdf/2507.09183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores prompt learning methods for few-shot class-incremental learning. The study and methodology are focused on prompt strategies and incremental learning challenges, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14219",
      "abstract": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has emerged as a promising strategic pathway toward decarbonisation, particularly in solar-rich arid regions. However, identifying optimal locations for hydrogen production requires the integration of complex environmental, atmospheric, and infrastructural factors, often compounded by limited availability of direct hydrogen yield data. This study presents a novel Artificial Intelligence (AI) framework for computing green hydrogen yield and site suitability index using mean absolute SHAP (SHapley Additive exPlanations) values. This framework consists of a multi-stage pipeline of unsupervised multi-variable clustering, supervised machine learning classifier and SHAP algorithm. The pipeline trains on an integrated meteorological, topographic and temporal dataset and the results revealed distinct spatial patterns of suitability and relative influence of the variables. With model predictive accuracy of 98%, the result also showed that water proximity, elevation and seasonal variation are the most influential factors determining green hydrogen site suitability in Oman with mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively. Given limited or absence of ground-truth yield data in many countries that have green hydrogen prospects and ambitions, this study offers an objective and reproducible alternative to subjective expert weightings, thus allowing the data to speak for itself and potentially discover novel latent groupings without pre-imposed assumptions. This study offers industry stakeholders and policymakers a replicable and scalable tool for green hydrogen infrastructure planning and other decision making in data-scarce regions.",
      "authors": [
        "Obumneme Zimuzor Nwafor and Mohammed Abdul Majeed Al Hooti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T10:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.14219v1",
          "size": "1532kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14219",
        "PDF": "https://arxiv.org/pdf/2507.14219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an AI framework for predicting green hydrogen yield and site suitability, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14631",
      "abstract": "Given an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the classic $k$-PCA (Principle Component Analysis) approximates the affine \\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear subspace that minimizes its sum of squared Euclidean distances ($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances. The \\emph{$k$-subspace median} is the subspace that minimizes its sum of (non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their median. The median subspace is usually more sparse and robust to noise/outliers than the mean, but also much harder to approximate since, unlike the $\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.\n  We provide the first polynomial-time deterministic algorithm whose both running time and approximation factor are not exponential in $k$. More precisely, the multiplicative approximation factor is $\\sqrt{d}$, and the running time is polynomial in the size of the input. We expect that our technique would be useful for many other related problems, such as $\\ell_{2,z}$ norm of distances for $z\\not \\in \\br{1,2}$, e.g., $z=\\infty$, and handling outliers/sparsity.\n  Open code and experimental results on real-world datasets are also provided.",
      "authors": [
        "Daniel Greenhut and Dan Feldman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:00:50+00:00",
          "link": "https://arxiv.org/abs/2507.14631v1",
          "size": "449kb",
          "version": "v1"
        }
      ],
      "title": "$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14631",
        "HTML": "https://arxiv.org/html/2507.14631",
        "PDF": "https://arxiv.org/pdf/2507.14631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a polynomial-time algorithm for $k$-PCA approximation focusing on Euclidean distances, unrelated to LLM training or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15666",
      "abstract": "The subject of the article is the study and comparison of two approaches to modelling the battery discharge of a CubeSat satellite: analytical using equivalent circuit and machine learning. The article aims to make a reasoned choice of the approach to modelling the battery discharge of a CubeSat satellite. Modelling the battery discharge of a satellite will enable the prediction of the consequences of disconnecting the autonomous power system and ensure the fault tolerance of equipment in orbit. Therefore, the selected study is relevant and promising. This study focuses on the analysis of CubeSat satellite data, based explicitly on orbital data samples of the power system, which include data available at the time of the article publication. The dataset contains data on the voltage, current, and temperature of the battery and solar panels attached to the five sides of the satellite. In this context, two approaches are considered: analytical modelling based on physical laws and machine learning, which uses empirical data to create a predictive model. Results: A comparative analysis of the modeling results reveals that the equivalent circuit approach has the advantage of transparency, as it identifies possible parameters that facilitate understanding of the relationships. However, the model is less flexible to environmental changes or non-standard satellite behavior. The machine learning model demonstrated more accurate results, as it can account for complex dependencies and adapt to actual conditions, even when they deviate from theoretical assumptions.",
      "authors": [
        "Igor Turkin",
        "Lina Volobuieva",
        "Andriy Chukhray",
        "Oleksandr Liubimov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:31:39+00:00",
          "link": "https://arxiv.org/abs/2507.15666v1",
          "size": "1790kb",
          "version": "v1"
        }
      ],
      "title": "Modeling CubeSat Storage Battery Discharge: Equivalent Circuit Versus Machine Learning Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15666",
        "PDF": "https://arxiv.org/pdf/2507.15666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study compares approaches for modeling CubeSat battery discharge and focuses on machine learning applications, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.05166",
      "abstract": "Novel view synthesis (NVS) in dynamic scenes faces persistent challenges in memory consumption, model complexity, training efficiency, and rendering quality. Offline methods offer high fidelity but suffer from high memory usage and limited scalability, while online approaches often trade quality for speed and compactness. We propose Continual Dynamic Neural Graphics Primitives (CD-NGP), a continual learning framework that reduces memory overhead and enhances scalability through parameter reuse. To avoid feature interference in dynamic scenes and improve rendering quality, our method combines spatial and temporal hash encodings, which compactly represent scene structures and motion patterns. We also introduce a new dataset comprising multi-view, long-duration ($>1200$ frames) videos with both rigid and non-rigid motion, which is not found in existing benchmarks. CD-NGP is evaluated on public datasets and our long video dataset, demonstrating superior scalability and reconstruction quality. It significantly reduces training memory usage to <14GB and requires only 0.4MB/frame in streaming bandwidth on DyNeRF -- substantially lower than most online baselines.",
      "authors": [
        "Zhenhuan Liu",
        "Shuai Liu",
        "Zhiwei Ning",
        "Jie Yang",
        "Yifan Zuo",
        "Yuming Fang",
        "Wei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-08T17:35:48+00:00",
          "link": "https://arxiv.org/abs/2409.05166v1",
          "size": "38888kb",
          "version": "v1"
        },
        {
          "date": "2024-10-01T14:19:38+00:00",
          "link": "https://arxiv.org/abs/2409.05166v2",
          "size": "43055kb",
          "version": "v2"
        },
        {
          "date": "2024-10-11T16:16:24+00:00",
          "link": "https://arxiv.org/abs/2409.05166v3",
          "size": "43172kb",
          "version": "v3"
        },
        {
          "date": "2024-10-23T02:10:29+00:00",
          "link": "https://arxiv.org/abs/2409.05166v4",
          "size": "44264kb",
          "version": "v4"
        },
        {
          "date": "2024-12-18T03:14:55+00:00",
          "link": "https://arxiv.org/abs/2409.05166v5",
          "size": "44071kb",
          "version": "v5"
        },
        {
          "date": "2025-07-19T15:24:53+00:00",
          "link": "https://arxiv.org/abs/2409.05166v6",
          "size": "42051kb",
          "version": "v6"
        }
      ],
      "title": "CD-NGP: A Fast Scalable Continual Representation for Dynamic Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05166",
        "HTML": "https://arxiv.org/html/2409.05166",
        "PDF": "https://arxiv.org/pdf/2409.05166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new dataset for evaluating novel view synthesis in dynamic scenes, it is mainly focused on continual learning frameworks and view synthesis methods rather than LLM training data processing."
      },
      "tasks": [
        "3D Reconstruction",
        "Continual Learning",
        "Novel View Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01655",
      "abstract": "Object detection in sonar images is crucial for underwater robotics applications including autonomous navigation and resource exploration. However, complex noise patterns inherent in sonar imagery, particularly speckle, reverberation, and non-Gaussian noise, significantly degrade detection accuracy. While denoising techniques have achieved remarkable success in optical imaging, their applicability to sonar data remains underexplored. This study presents the first systematic evaluation of nine state-of-the-art deep denoising models with distinct architectures, including Neighbor2Neighbor with varying noise parameters, Blind2Unblind with different noise configurations, and DSPNet, for sonar image preprocessing. We establish a rigorous benchmark using five publicly available sonar datasets and assess their impact on four representative detection algorithms: YOLOX, Faster R-CNN, SSD300, and SSDMobileNetV2. Our evaluation addresses three unresolved questions: first, how effectively optical denoising architectures transfer to sonar data; second, which model families perform best against sonar noise; and third, whether denoising truly improves detection accuracy in practical pipelines. Extensive experiments demonstrate that while denoising generally improves detection performance, effectiveness varies across methods due to their inherent biases toward specific noise types. To leverage complementary denoising effects, we propose a mutually-supervised multi-source denoising fusion framework where outputs from different denoisers mutually supervise each other at the pixel level, creating a synergistic framework that produces cleaner images.",
      "authors": [
        "Ziyu Wang (1)",
        "Tao Xue (1)",
        "Jingyuan Li (1)",
        "Haibin Zhang (1)",
        "Zhiqiang Xu (3)",
        "Gaofei Xu (4)",
        "Zhen Wang (5)",
        "Yanbin Wang (2)",
        "Zhiquan Liu (6) ((1) Xidian University",
        "(2) Shenzhen MSU-BIT University",
        "(3) Jiangxi University of Science and Technology",
        "(4) Institute of Deep-sea Science and Engineering,(5) Northwestern Polytechnical University",
        "(6) Jinan University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T15:30:39+00:00",
          "link": "https://arxiv.org/abs/2503.01655v1",
          "size": "11246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T12:00:19+00:00",
          "link": "https://arxiv.org/abs/2503.01655v2",
          "size": "3225kb",
          "version": "v2"
        }
      ],
      "title": "Can Optical Denoising Clean Sonar Images? A Benchmark and Fusion Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01655",
        "HTML": "https://arxiv.org/html/2503.01655",
        "PDF": "https://arxiv.org/pdf/2503.01655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates denoising techniques in sonar image processing for object detection, which does not pertain to LLM training data processing operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10524",
      "abstract": "Scaling language models unlocks impressive capabilities, but the accompanying computational and memory demands make both training and deployment expensive. Existing efficiency efforts typically target either parameter sharing or adaptive computation, leaving open the question of how to attain both simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework that combines the two axes of efficiency inside a single Recursive Transformer. MoR reuses a shared stack of layers across recursion steps to achieve parameter efficiency, while lightweight routers enable adaptive token-level thinking by dynamically assigning different recursion depths to individual tokens. This allows MoR to focus quadratic attention computation only among tokens still active at a given recursion depth, further improving memory access efficiency by selectively caching only their key-value pairs. Beyond these core mechanisms, we also propose a KV sharing variant that reuses KV pairs from the first recursion, specifically designed to decrease prefill latency and memory footprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms a new Pareto frontier: at equal training FLOPs and smaller model sizes, it significantly lowers validation perplexity and improves few-shot accuracy, while delivering higher throughput compared with vanilla and existing recursive baselines. These gains demonstrate that MoR is an effective path towards large-model quality without incurring large-model cost.",
      "authors": [
        "Sangmin Bae",
        "Yujin Kim",
        "Reza Bayat",
        "Sungnyun Kim",
        "Jiyoun Ha",
        "Tal Schuster",
        "Adam Fisch",
        "Hrayr Harutyunyan",
        "Ziwei Ji",
        "Aaron Courville",
        "Se-Young Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:49:00+00:00",
          "link": "https://arxiv.org/abs/2507.10524v1",
          "size": "704kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:45:14+00:00",
          "link": "https://arxiv.org/abs/2507.10524v2",
          "size": "696kb",
          "version": "v2"
        }
      ],
      "title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10524",
        "HTML": "https://arxiv.org/html/2507.10524",
        "PDF": "https://arxiv.org/pdf/2507.10524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Mixture-of-Recursions (MoR), focusing on efficiency in language model training. It mentions improvements in training efficiency and prefill latency, but does not primarily focus on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14300",
      "abstract": "This paper introduces a novel distributed consensus-based observer design that enables a group of agents in an undirected communication network to solve the problem of target tracking, where the target is modeled as a chain of integrators of arbitrary order. Each agent is assumed to know its own position and simultaneously measure bearing vectors relative to the target. We start by introducing a general continuous time observer design tailored to systems whose state dynamics are modeled as chains of integrators and whose measurement model follows a particular nonlinear but observer-suited form. This design leverages a correction term that combines innovation and consensus components, allowing each agent to broadcast only a part of the state estimate to its neighbours, which effectively reduces the data flowing across the network. To provide uniform exponential stability guarantees, a novel result for a class of nonlinear closed-loop systems in a generalized observer form is introduced and subsequently used as the main tool to derive stability conditions on the observer gains. Then, by exploring the properties of orthogonal projection matrices, the proposed design is used to solve the distributed target tracking problem and provide explicit stability conditions that depend on the target-agents geometric formation. Practical examples are derived for a target modeled as first-, second-, and third-order integrator dynamics, highlighting the design procedure and the stability conditions imposed. Finally, numerical results showcase the properties of the proposed algorithm.",
      "authors": [
        "Marcelo Jacinto",
        "Pedro Trindade",
        "Francisco Rego",
        "Rita Cunha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:19:02+00:00",
          "link": "https://arxiv.org/abs/2507.14300v1",
          "size": "1828kb",
          "version": "v1"
        }
      ],
      "title": "Distributed consensus-based observer design for target state estimation with bearing measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14300",
        "HTML": "https://arxiv.org/html/2507.14300",
        "PDF": "https://arxiv.org/pdf/2507.14300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered on distributed consensus and observer design for target tracking, which does not pertain to LLM training data processing in terms of dataset creation or data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14354",
      "abstract": "We derive a decomposition for the gradient of the innovation loss with respect to the filter gain in a linear time-invariant system, decomposing as a product of an observability Gramian and a term quantifying the ``non-orthogonality\" between the estimation error and the innovation. We leverage this decomposition to give a convergence proof of gradient descent to the optimal Kalman gain, specifically identifying how recovery of the Kalman gain depends on a non-standard observability condition, and obtaining an interpretable geometric convergence rate.",
      "authors": [
        "M.A. Belabbas",
        "A. Olshevsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T20:20:06+00:00",
          "link": "https://arxiv.org/abs/2507.14354v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Gradient Descent for Kalman Gain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14354",
        "HTML": "https://arxiv.org/html/2507.14354",
        "PDF": "https://arxiv.org/pdf/2507.14354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about gradient descent for optimizing Kalman gain in linear systems, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14367",
      "abstract": "Generative super-resolution (GSR) currently sets the state-of-the-art in terms of perceptual image quality, overcoming the \"regression-to-the-mean\" blur of prior non-generative models. However, from a human perspective, such models do not fully conform to the optimal balance between quality and fidelity. Instead, a different class of artifacts, in which generated details fail to perceptually match the low resolution image (LRI) or ground-truth image (GTI), is a critical but under studied issue in GSR, limiting its practical deployments. In this work, we focus on measuring, analyzing, and mitigating these artifacts (i.e., \"hallucinations\"). We observe that hallucinations are not well-characterized with existing image metrics or quality models, as they are orthogonal to both exact fidelity and no-reference quality. Instead, we take advantage of a multimodal large language model (MLLM) by constructing a prompt that assesses hallucinatory visual elements and generates a \"Hallucination Score\" (HS). We find that our HS is closely aligned with human evaluations, and also provides complementary insights to prior image metrics used for super-resolution (SR) models. In addition, we find certain deep feature distances have strong correlations with HS. We therefore propose to align the GSR models by using such features as differentiable reward functions to mitigate hallucinations.",
      "authors": [
        "Weiming Ren",
        "Raghav Goyal",
        "Zhiming Hu",
        "Tristan Ty Aumentado-Armstrong",
        "Iqbal Mohomed",
        "Alex Levinshtein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:13:50+00:00",
          "link": "https://arxiv.org/abs/2507.14367v1",
          "size": "39391kb",
          "version": "v1"
        }
      ],
      "title": "Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14367",
        "HTML": "https://arxiv.org/html/2507.14367",
        "PDF": "https://arxiv.org/pdf/2507.14367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with generative super-resolution and mitigation of hallucinations in image quality. It uses a multimodal LLM for a novel metric but does not contribute to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14640",
      "abstract": "A two-part affine approximation has been found to be a good approximation for transformer computations over certain subject object relations. Adapting the Bigger Analogy Test Set, we show that the linear transformation Ws, where s is a middle layer representation of a subject token and W is derived from model derivatives, is also able to accurately reproduce final object states for many relations. This linear technique is able to achieve 90% faithfulness on morphological relations, and we show similar findings multi-lingually and across models. Our findings indicate that some conceptual relationships in language models, such as morphology, are readily interpretable from latent space, and are sparsely encoded by cross-layer linear transformations.",
      "authors": [
        "Eric Xia",
        "Jugal Kalita"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:35:15+00:00",
          "link": "https://arxiv.org/abs/2507.14640v1",
          "size": "838kb",
          "version": "v1"
        }
      ],
      "title": "Linear Relational Decoding of Morphology in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14640",
        "HTML": "https://arxiv.org/html/2507.14640",
        "PDF": "https://arxiv.org/pdf/2507.14640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses morphological decoding in language models through linear transformations, focusing on interpretability of model processes. It does not involve data processing for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14742",
      "abstract": "In contemporary digital markets, personal data often reveals not just isolated traits, but complex, intersectional identities based on combinations of race, gender, disability, and other protected characteristics. This exposure generates a privacy externality: firms benefit economically from profiling, prediction, and personalization, while users face hidden costs in the form of social risk and discrimination. We introduce a formal pricing rule that quantifies and internalizes this intersectional privacy loss using mutual information, assigning monetary value to the entropy reduction induced by each datum. The result is a Pigouvian-style surcharge that discourages harmful data trades and rewards transparency. Our formulation has the advantage that it operates independently of the underlying statistical model of the intersectional variables, be it parametric, nonparametric, or learned, and can be approximated in practice by discretizing the intersectional joint probability distributions. We illustrate how regulators can calibrate this surcharge to reflect different societal values, and argue that it provides not just a technical fix to market failures, but also a redistributive shield that empowers vulnerable groups in the face of asymmetric digital power.",
      "authors": [
        "Eduardo C. Garrido-Merch\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:29:41+00:00",
          "link": "https://arxiv.org/abs/2507.14742v1",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "title": "An Information-Theoretic Intersectional Data Valuation Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14742",
        "HTML": "https://arxiv.org/html/2507.14742",
        "PDF": "https://arxiv.org/pdf/2507.14742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a data valuation theory for pricing personal data based on intersectionality. It does not discuss LLM training data processing tasks such as data engineering or improvement of data quality for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14822",
      "abstract": "Recently, low-altitude wireless networks (LAWNs) have emerged as a critical backbone for supporting the low-altitude economy, particularly with the densification of unmanned aerial vehicles (UAVs) and high-altitude platforms (HAPs). To meet growing data demands, some LAWN deployments incorporate free-space optical (FSO) links, which offer exceptional bandwidth and beam directivity. However, without strong security measures in place, both conventional radio frequency channels and FSO beams remain vulnerable to interception and spoofing and FSO in particular can suffer from turbulence, misalignment, and weather-related attenuation. To address these challenges in the quantum era, a quantum-secure architecture called Quantum Skyshield is proposed to enable reliable communication between the base transceiver station (BTS) and LAWN. The proposed design integrates BB84 quantum key distribution (QKD) with post-quantum authentication mechanisms. Simulation results confirm the reliable generation of a 128-bit symmetric key when the quantum bit error rate (QBER) remains below the threshold of 11%. Authentication is enforced using Lamport one-time signatures and hash-based message authentication codes (HMAC) to ensure message integrity. A Grover-inspired threat detection mechanism identifies anomalies with up to 89% probability in a single iteration, enabling real-time trust evaluation. Lastly, future research challenges have also been identified and discussed to guide further development in this area.",
      "authors": [
        "Zeeshan Kaleem",
        "Misha Urooj Khan",
        "Ahmad Suleman",
        "Waqas Khalid",
        "Kai-Kit Wong",
        "Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:43:33+00:00",
          "link": "https://arxiv.org/abs/2507.14822v1",
          "size": "6381kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Skyshield: Quantum Key Distribution and Post-Quantum Authentication for Low-Altitude Wireless Networks in Adverse Skies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14822",
        "HTML": "https://arxiv.org/html/2507.14822",
        "PDF": "https://arxiv.org/pdf/2507.14822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a quantum-secure architecture for wireless networks, focusing on quantum key distribution and authentication. It doesn't address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15016",
      "abstract": "We present an $\\textit{a priori}$ error analysis for the kinematic pressure in a fully-discrete finite-differences/-elements discretization of the unsteady $p$-Stokes equations, modelling non-Newtonian fluids. This system is subject to both impermeability and perfect Navier slip boundary conditions, which are incorporated either weakly via Lagrange multipliers or strongly in the discrete velocity space. A central aspect of the $\\textit{a priori}$ error analysis is the discrete Leray projection, constructed to quantitatively approximate its continuous counterpart. The discrete Leray projection enables a Helmholtz-type decomposition at the discrete level and plays a key role in deriving error decay rates for the kinematic pressure. We derive (in some cases optimal) error decay rates for both the velocity vector field and kinematic pressure, with the error for the kinematic pressure measured in an $\\textit{ad hoc}$ norm informed by the projection framework. The $\\textit{a priori}$ error analysis remains robust even under reduced regularity of the velocity vector field and the kinematic pressure, and illustrates how the interplay of boundary conditions and projection stability governs the accuracy of pressure approximations.",
      "authors": [
        "Alex Kaltenbach and J\\\"orn Wichmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.15016v1",
          "size": "421kb",
          "version": "v1"
        }
      ],
      "title": "$\\textit{A Priori}$ Error Analysis for the $p$-Stokes Equations with Slip Boundary Conditions: A Discrete Leray Projection Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15016",
        "PDF": "https://arxiv.org/pdf/2507.15016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on error analysis for $p$-Stokes equations, relating to non-Newtonian fluid modeling, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15047",
      "abstract": "This paper studies a set-theoretic generalization of Lyapunov and Lagrange stability for abstract systems described by set-valued maps. Lyapunov stability is characterized as the property of inversely mapping filters to filters, Lagrange stability as that of mapping ideals to ideals. These abstract definitions unveil a deep duality between the two stability notions, enable a definition of global stability for abstract systems, and yield an agile generalization of the stability theorems for basic series, parallel, and feedback interconnections, including a small-gain theorem. Moreover, it is shown that Lagrange stability is abstractly identical to other properties of interest in control theory, such as safety and positivity, whose preservation under interconnections can be thus studied owing to the developed stability results.",
      "authors": [
        "Michelangelo Bin and David Angeli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:02:41+00:00",
          "link": "https://arxiv.org/abs/2507.15047v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "On an Abstraction of Lyapunov and Lagrange Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15047",
        "HTML": "https://arxiv.org/html/2507.15047",
        "PDF": "https://arxiv.org/pdf/2507.15047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Lyapunov and Lagrange stability in abstract systems, which is focused on systems theory and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15189",
      "abstract": "Depth information which specifies the distance between objects and current position of the robot is essential for many robot tasks such as navigation. Recently, researchers have proposed depth completion frameworks to provide dense depth maps that offer comprehensive information about the surrounding environment. However, existing methods show significant trade-offs between computational efficiency and accuracy during inference. The substantial memory and computational requirements make them unsuitable for real-time applications, highlighting the need to improve the completeness and accuracy of depth information while improving processing speed to enhance robot performance in various tasks. To address these challenges, in this paper, we propose CHADET(cross-hierarchical-attention depth-completion transformer), a lightweight depth-completion network that can generate accurate dense depth maps from RGB images and sparse depth points. For each pair, its feature is extracted from the depthwise blocks and passed to the equally lightweight transformer-based decoder. In the decoder, we utilize the novel cross-hierarchical-attention module that refines the image features from the depth information. Our approach improves the quality and reduces memory usage of the depth map prediction, as validated in both KITTI, NYUv2, and VOID datasets.",
      "authors": [
        "Kevin Christiansen Marsim",
        "Jinwoo Jeon",
        "Yeeun Kim",
        "Myeongwoo Jeong",
        "Hyun Myung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:22:39+00:00",
          "link": "https://arxiv.org/abs/2507.15189v1",
          "size": "14976kb",
          "version": "v1"
        }
      ],
      "title": "CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15189",
        "HTML": "https://arxiv.org/html/2507.15189",
        "PDF": "https://arxiv.org/pdf/2507.15189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a depth-completion network for generating dense depth maps from RGB images, focusing on computational efficiency and accuracy in robotic navigation tasks, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15480",
      "abstract": "Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable zero-shot performance, yet their downstream potential hinges on effective fine-tuning. Most adaptation methods typically focus on refining representation from separate modalities (text or vision) but neglect the critical role of their fused representations in the decision-making process, \\emph{\\ie} rational matrix that drives the final prediction. To bridge the gap, we propose a simple yet effective \\textbf{R}ational \\textbf{Ada}ptaion ({RAda}) to explicitly exploit the final fused representation during fine-tuning. RAda employs a learned mask, obtained from a lightweight attention layer attached at the end of a VLM, to dynamically calibrate the contribution of each element in the rational matrix, enabling targeted adjustments to the final cross-modal interactions without incurring costly modifications to intermediate features. Experiments in different settings (i.e., updating, or freezing pretrained encoders in adaptation, and test-time training that can only access the unlabeled test data) show that RAda serves as a versatile fine-tuning technique, improving the baseline with minimal code and performing comparably against current arts in most settings. Code is available at \\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.",
      "authors": [
        "Liang Chen",
        "Ghazi Shazan Ahmad",
        "Tianjun Yao",
        "Lingqiao Liu",
        "Zhiqiang Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:35:32+00:00",
          "link": "https://arxiv.org/abs/2507.15480v1",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "title": "One Last Attention for Your Vision-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15480",
        "HTML": "https://arxiv.org/html/2507.15480",
        "PDF": "https://arxiv.org/pdf/2507.15480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces RAda, a fine-tuning technique for vision-language models focusing on the alignment of fused representations, touching upon fine-tuning but not directly addressing LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15629",
      "abstract": "3D Gaussian splatting (3DGS) has shown its detailed expressive ability and highly efficient rendering speed in the novel view synthesis (NVS) task. The application to inverse rendering still faces several challenges, as the discrete nature of Gaussian primitives makes it difficult to apply geometry constraints. Recent works introduce the signed distance field (SDF) as an extra continuous representation to regularize the geometry defined by Gaussian primitives. It improves the decomposition quality, at the cost of increasing memory usage and complicating training. Unlike these works, we introduce a discretized SDF to represent the continuous SDF in a discrete manner by encoding it within each Gaussian using a sampled value. This approach allows us to link the SDF with the Gaussian opacity through an SDF-to-opacity transformation, enabling rendering the SDF via splatting and avoiding the computational cost of ray marching.The key challenge is to regularize the discrete samples to be consistent with the underlying SDF, as the discrete representation can hardly apply the gradient-based constraints (\\eg Eikonal loss). For this, we project Gaussians onto the zero-level set of SDF and enforce alignment with the surface from splatting, namely a projection-based consistency loss. Thanks to the discretized SDF, our method achieves higher relighting quality, while requiring no extra memory beyond GS and avoiding complex manually designed optimization. The experiments reveal that our method outperforms existing Gaussian-based inverse rendering methods. Our code is available at https://github.com/NK-CS-ZZL/DiscretizedSDF.",
      "authors": [
        "Zuo-Liang Zhu",
        "Jian Yang",
        "Beibei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:52:33+00:00",
          "link": "https://arxiv.org/abs/2507.15629v1",
          "size": "34031kb",
          "version": "v1"
        }
      ],
      "title": "Gaussian Splatting with Discretized SDF for Relightable Assets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15629",
        "HTML": "https://arxiv.org/html/2507.15629",
        "PDF": "https://arxiv.org/pdf/2507.15629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses techniques in 3D Gaussian splatting for inverse rendering and relightable asset creation, which does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15733",
      "abstract": "We consider pushdown systems that store, instead of a single word, a Mazurkiewicz trace on its stack. These systems are special cases of valence automata over graph monoids and subsume multi-stack systems. We identify a class of such systems that allow to decide the first-order theory of their configuration graph with reachability.\n  This result complements results by D'Osualdo, Meyer, and Zetzsche (namely the decidability for arbitrary pushdown systems under a severe restriction on the dependence alphabet).",
      "authors": [
        "Dietrich Kuske"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:41:32+00:00",
          "link": "https://arxiv.org/abs/2507.15733v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "The theory of reachability in trace-pushdown systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15733",
        "HTML": "https://arxiv.org/html/2507.15733",
        "PDF": "https://arxiv.org/pdf/2507.15733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the theoretical aspects of trace-pushdown systems related to configuration graph reachability, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15757",
      "abstract": "We consider the problem of synthesizing a memoryless channel between an unobserved source and a remote terminal. An encoder has access to a partial or noisy version $Z^n = (Z_1, \\ldots, Z_n)$ of a remote source sequence $X^n = (X_1, \\ldots, X_n),$ with $(X_i,Z_i)$ independent and identically distributed with joint distribution $q_{X,Z}.$ The encoder communicates through a noiseless link to a decoder which aims to produce an output $Y^n$ coordinated with the remote source; that is, the total variation distance between the joint distribution of $X^n$ and $Y^n$ and some i.i.d. target distribution $q_{X,Y}^{\\otimes n}$ is required to vanish as $n$ goes to infinity. The two terminals may have access to a source of rate-limited common randomness. We present a single-letter characterization of the optimal compression and common randomness rates. We also show that when the common randomness rate is small, then in most cases, coordinating $Z^n$ and $Y^n$ using a standard channel synthesis scheme is strictly sub-optimal. In other words, schemes for which the joint distribution of $Z^n$ and $Y^n$ approaches a product distribution asymptotically are strictly sub-optimal.",
      "authors": [
        "Yassine Hamdi and Deniz G\\\"und\\\"uz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:13:13+00:00",
          "link": "https://arxiv.org/abs/2507.15757v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "Remote Channel Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15757",
        "HTML": "https://arxiv.org/html/2507.15757",
        "PDF": "https://arxiv.org/pdf/2507.15757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses memoryless channel synthesis between a source and a terminal, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15843",
      "abstract": "Closure conversion is a program transformation at work in compilers for functional languages to turn inner functions into global ones, by building closures pairing the transformed functions with the environment of their free variables. Abstract machines rely on similar and yet different concepts of closures and environments.\n  In this paper, we study the relationship between the two approaches. We adopt a very simple {\\lambda}-calculus with tuples as source language and study abstract machines for both the source language and the target of closure conversion. Moreover, we focus on the simple case of flat closures/environments, that is, with no sharing of environments. We provide three contributions.\n  Firstly, a new simple proof technique for the correctness of closure conversion, inspired by abstract machines.\n  Secondly, we show how the closure invariants of the target language allow us to design a new way of handling environments in abstract machines, not suffering the shortcomings of other styles.\n  Thirdly, we study the machines from the point of view of time complexity, adapting analyses by Accattoli and co-authors. We show that closure conversion decreases various dynamic costs while increasing the size of the initial code. Despite these changes, the overall complexity of the machines before and after closure conversion turns out to be the same.",
      "authors": [
        "Beniamino Accattoli (1)",
        "Dan Ghica (2 and 3)",
        "Giulio Guerrieri (4)",
        "Cl\\'audio Belo Louren\\c{c}o (2)",
        "Claudio Sacerdoti Coen (5) ((1) Inria & LIX",
        "\\'Ecole Polytechnique",
        "(2) Huawei Central Software Institute",
        "(3) University of Birmingham",
        "(4) University of Sussex",
        "(5) Universit\\`a di Bologna)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:52:29+00:00",
          "link": "https://arxiv.org/abs/2507.15843v1",
          "size": "263kb",
          "version": "v1"
        }
      ],
      "title": "Closure Conversion, Flat Environments, and the Complexity of Abstract Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15843",
        "PDF": "https://arxiv.org/pdf/2507.15843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies closure conversion and abstract machines in compilers for functional programming, without any relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00091",
      "abstract": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV) swarms to perform complex tasks in urban environments, system design now faces major challenges, including efficient semantic understanding, flexible task planning, and the ability to dynamically adjust coordination strategies in response to evolving environmental conditions and continuously changing task requirements. To address the limitations of existing methods, this paper proposes CoordField, a coordination field agent system for coordinating heterogeneous drone swarms in complex urban scenarios. In this system, large language models (LLMs) is responsible for interpreting high-level human instructions and converting them into executable commands for the UAV swarms, such as patrol and target tracking. Subsequently, a Coordination field mechanism is proposed to guide UAV motion and task selection, enabling decentralized and adaptive allocation of emergent tasks. A total of 50 rounds of comparative testing were conducted across different models in a 2D simulation space to evaluate their performance. Experimental results demonstrate that the proposed system achieves superior performance in terms of task coverage, response time, and adaptability to dynamic changes.",
      "authors": [
        "Tengchao Zhang",
        "Yonglin Tian",
        "Fei Lin",
        "Jun Huang",
        "Patrik P. S\\\"uli",
        "Qinghua Ni",
        "Rui Qin",
        "Xiao Wang and Fei-Yue Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T18:02:45+00:00",
          "link": "https://arxiv.org/abs/2505.00091v1",
          "size": "1362kb",
          "version": "v1"
        },
        {
          "date": "2025-05-03T16:45:20+00:00",
          "link": "https://arxiv.org/abs/2505.00091v2",
          "size": "1664kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T23:31:13+00:00",
          "link": "https://arxiv.org/abs/2505.00091v3",
          "size": "1664kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T12:45:28+00:00",
          "link": "https://arxiv.org/abs/2505.00091v4",
          "size": "1133kb",
          "version": "v4"
        }
      ],
      "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00091",
        "HTML": "https://arxiv.org/html/2505.00091",
        "PDF": "https://arxiv.org/pdf/2505.00091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "CoordField aims to enhance UAV task allocation using LLMs for command interpretation but does not involve any LLM training data processing activities."
      },
      "tasks": [
        "Task Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14223",
      "abstract": "Explainable intrusion detection systems (IDS) are now recognized as essential for mission-critical networks, yet most \"XAI\" pipelines still bolt an approximate explainer onto an opaque classifier, leaving analysts with partial and sometimes misleading insights. The Interpretable Generalization (IG) mechanism, published in IEEE Transactions on Information Forensics and Security, eliminates that bottleneck by learning coherent patterns - feature combinations unique to benign or malicious traffic - and turning them into fully auditable rules. IG already delivers outstanding precision, recall, and AUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the data. To raise precision further without sacrificing transparency, we introduce Multi-Granular Discretization (IG-MD), which represents every continuous feature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts precision by greater than or equal to 4 percentage points across all nine train-test splits while preserving recall approximately equal to 1.0, demonstrating that a single interpretation-ready model can scale across domains without bespoke tuning.",
      "authors": [
        "Wen-Cheng Chung",
        "Shu-Ting Huang",
        "Hao-Ting Pai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:57:38+00:00",
          "link": "https://arxiv.org/abs/2507.14223v1",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14223",
        "HTML": "https://arxiv.org/html/2507.14223",
        "PDF": "https://arxiv.org/pdf/2507.14223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for cyberattack identification through explainable intrusion detection, not involving any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14334",
      "abstract": "OWL (Web Ontology Language) ontologies which are able to formally represent complex knowledge and support semantic reasoning have been widely adopted across various domains such as healthcare and bioinformatics. Recently, ontology embeddings have gained wide attention due to its potential to infer plausible new knowledge and approximate complex reasoning. However, existing methods face notable limitations: geometric model-based embeddings typically overlook valuable textual information, resulting in suboptimal performance, while the approaches that incorporate text, which are often based on language models, fail to preserve the logical structure. In this work, we propose a new ontology embedding method OnT, which tunes a Pretrained Language Model (PLM) via geometric modeling in a hyperbolic space for effectively incorporating textual labels and simultaneously preserving class hierarchies and other logical relationships of Description Logic EL. Extensive experiments on four real-world ontologies show that OnT consistently outperforms the baselines including the state-of-the-art across both tasks of prediction and inference of axioms. OnT also demonstrates strong potential in real-world applications, indicated by its robust transfer learning abilities and effectiveness in real cases of constructing a new ontology from SNOMED CT. Data and code are available at https://github.com/HuiYang1997/OnT.",
      "authors": [
        "Hui Yang",
        "Jiaoyan Chen",
        "Yuan He",
        "Yongsheng Gao",
        "Ian Horrocks"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:26:16+00:00",
          "link": "https://arxiv.org/abs/2507.14334v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Language Models as Ontology Encoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14334",
        "HTML": "https://arxiv.org/html/2507.14334",
        "PDF": "https://arxiv.org/pdf/2507.14334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus is on ontology embedding using language models, the paper involves fine-tuning a PLM and potentially contributes to dataset creation in transferring learning, which are related to but not primarily focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14700",
      "abstract": "Safe navigation in unknown and cluttered environments remains a challenging problem in robotics. Model Predictive Contour Control (MPCC) has shown promise for performant obstacle avoidance by enabling precise and agile trajectory tracking, however, existing methods lack formal safety assurances. To address this issue, we propose a general Control Lyapunov Function (CLF) and Control Barrier Function (CBF) enabled MPCC framework that enforces safety constraints derived from a free-space corridor around the planned trajectory. To enhance feasibility, we dynamically adapt the CBF parameters at runtime using a Soft Actor-Critic (SAC) policy. The approach is validated with extensive simulations and an experiment on mobile robot navigation in unknown cluttered environments.",
      "authors": [
        "Nicholas Mohammad",
        "Nicola Bezzo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:26:16+00:00",
          "link": "https://arxiv.org/abs/2507.14700v1",
          "size": "5264kb",
          "version": "v1"
        }
      ],
      "title": "Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14700",
        "PDF": "https://arxiv.org/pdf/2507.14700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses safe navigation in mobile robots using control barrier functions, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15340",
      "abstract": "High-resolution volumetric computed tomography (CT) is essential for accurate diagnosis and treatment planning in thoracic diseases; however, it is limited by radiation dose and hardware costs. We present the Transformer Volumetric Super-Resolution Network (\\textbf{TVSRN-V2}), a transformer-based super-resolution (SR) framework designed for practical deployment in clinical lung CT analysis. Built from scalable components, including Through-Plane Attention Blocks (TAB) and Swin Transformer V2 -- our model effectively reconstructs fine anatomical details in low-dose CT volumes and integrates seamlessly with downstream analysis pipelines. We evaluate its effectiveness on three critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis -- across multiple clinical cohorts. To enhance robustness across variable acquisition protocols, we introduce pseudo-low-resolution augmentation, simulating scanner diversity without requiring private data. TVSRN-V2 demonstrates a significant improvement in segmentation accuracy (+4\\% Dice), higher radiomic feature reproducibility, and enhanced predictive performance (+0.06 C-index and AUC). These results indicate that SR-driven recovery of structural detail significantly enhances clinical decision support, positioning TVSRN-V2 as a well-engineered, clinically viable system for dose-efficient imaging and quantitative analysis in real-world CT workflows.",
      "authors": [
        "Marc Boubnovski Martell",
        "Kristofer Linton-Reid",
        "Mitchell Chen",
        "Sumeet Hindocha",
        "Benjamin Hunter",
        "Marco A. Calzado",
        "Richard Lee",
        "Joram M. Posma",
        "Eric O. Aboagye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:53:49+00:00",
          "link": "https://arxiv.org/abs/2507.15340v1",
          "size": "655kb",
          "version": "v1"
        }
      ],
      "title": "MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15340",
        "HTML": "https://arxiv.org/html/2507.15340",
        "PDF": "https://arxiv.org/pdf/2507.15340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a super-resolution framework for lung CT scans in the context of clinical analysis but does not address any aspects of data processing related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15476",
      "abstract": "Surface defect detection of steel, especially the recognition of multi-scale defects, has always been a major challenge in industrial manufacturing. Steel surfaces not only have defects of various sizes and shapes, which limit the accuracy of traditional image processing and detection methods in complex environments. However, traditional defect detection methods face issues of insufficient accuracy and high miss-detection rates when dealing with small target defects. To address this issue, this study proposes a detection framework based on deep learning, specifically YOLOv9s, combined with the C3Ghost module, SCConv module, and CARAFE upsampling operator, to improve detection accuracy and model performance. First, the SCConv module is used to reduce feature redundancy and optimize feature representation by reconstructing the spatial and channel dimensions. Second, the C3Ghost module is introduced to enhance the model's feature extraction ability by reducing redundant computations and parameter volume, thereby improving model efficiency. Finally, the CARAFE upsampling operator, which can more finely reorganize feature maps in a content-aware manner, optimizes the upsampling process and ensures detailed restoration of high-resolution defect regions. Experimental results demonstrate that the proposed model achieves higher accuracy and robustness in steel surface defect detection tasks compared to other methods, effectively addressing defect detection problems.",
      "authors": [
        "Cong Chen",
        "Ming Chen",
        "Hoileong Lee",
        "Yan Li",
        "and Jiyang Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:30:38+00:00",
          "link": "https://arxiv.org/abs/2507.15476v1",
          "size": "2096kb",
          "version": "v1"
        }
      ],
      "title": "A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15476",
        "PDF": "https://arxiv.org/pdf/2507.15476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a steel surface defect detection method using deep learning and optimization techniques, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18317",
      "abstract": "Tropical cyclones (TCs) are highly dynamic natural disasters that travel vast distances and occupy a large spatial scale, leading to loss of life, economic strife, and destruction of infrastructure. The severe impact of TCs makes them crucial to monitor such that the collected data contributes to forecasting their trajectory and severity, as well as the provision of information to relief agencies. Among the various methods used to monitor TCs, Earth observation satellites are the most flexible, allowing for frequent observations with a wide variety of instruments. Traditionally, satellite scheduling algorithms assume nadir-directional observations, a limitation that can be alleviated by incorporating satellite agility and constellation reconfigurability -- two state-of-the-art concepts of operations (CONOPS) that extend the amount of time TCs can be observed from orbit. This paper conducts a systematic comparative analysis between both CONOPS to present the performance of each relative to baseline nadir-directional observations in monitoring TCs. A dataset of 100 historical TCs is used to provide a benchmark concerning real-world data through maximizing the number of quality observations. The results of the comparative analysis indicate that constellation reconfigurability allowing plane-change maneuvers outperforms satellite agility in the majority of TCs analyzed.",
      "authors": [
        "Brycen D. Pearl",
        "Logan P. Gold",
        "Hang Woon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T13:13:27+00:00",
          "link": "https://arxiv.org/abs/2411.18317v1",
          "size": "4374kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Agility and Reconfigurability in Satellite Systems for Tropical Cyclone Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18317",
        "HTML": "https://arxiv.org/html/2411.18317",
        "PDF": "https://arxiv.org/pdf/2411.18317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is centered on satellite systems for tropical cyclone monitoring and does not discuss LLM training data processing or any relevant data engineering operations for LLMs."
      },
      "tasks": [
        "Benchmarking",
        "Earth Observation",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23644",
      "abstract": "We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
      "authors": [
        "Junze Hu",
        "Xiangyu Jin",
        "Yizhe Zeng",
        "Yuling Liu",
        "Yunpeng Li",
        "Dan Du",
        "Kaiyu Xie",
        "Hongsong Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:14:49+00:00",
          "link": "https://arxiv.org/abs/2506.23644v1",
          "size": "3165kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:38:25+00:00",
          "link": "https://arxiv.org/abs/2506.23644v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T04:22:39+00:00",
          "link": "https://arxiv.org/abs/2506.23644v3",
          "size": "3165kb",
          "version": "v3"
        }
      ],
      "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23644",
        "HTML": "https://arxiv.org/html/2506.23644",
        "PDF": "https://arxiv.org/pdf/2506.23644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a vulnerability detection framework, QLPro, using LLMs for code analysis and presents a new dataset for validation but doesn't address LLM training data processing operations like dataset creation for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08224",
      "abstract": "Large language models (LLMs) have shown promise in robotic procedural planning, yet their human-centric reasoning often omits the low-level, grounded details needed for robotic execution. Vision-language models (VLMs) offer a path toward more perceptually grounded plans, but current methods either rely on expensive, large-scale models or are constrained to narrow simulation settings. We introduce SelfReVision, a lightweight and scalable self-improvement framework for vision-language procedural planning. SelfReVision enables small VLMs to iteratively critique, revise, and verify their own plans-without external supervision or teacher models-drawing inspiration from chain-of-thought prompting and self-instruct paradigms. Through this self-distillation loop, models generate higher-quality, execution-ready plans that can be used both at inference and for continued fine-tuning. Using models varying from 3B to 72B, our results show that SelfReVision not only boosts performance over weak base VLMs but also outperforms models 100X the size, yielding improved control in downstream embodied tasks.",
      "authors": [
        "Chan Young Park",
        "Jillian Fisher",
        "Marius Memmel",
        "Dipika Khullar",
        "Seoho Yun",
        "Abhishek Gupta",
        "Yejin Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T00:17:08+00:00",
          "link": "https://arxiv.org/abs/2507.08224v1",
          "size": "27057kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T05:22:14+00:00",
          "link": "https://arxiv.org/abs/2507.08224v2",
          "size": "27057kb",
          "version": "v2"
        }
      ],
      "title": "Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08224",
        "HTML": "https://arxiv.org/html/2507.08224",
        "PDF": "https://arxiv.org/pdf/2507.08224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper presents SelfReVision, a framework for improving vision-language models in robotic planning. While it highlights self-improvement and fine-tuning, it primarily focuses on model performance rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14512",
      "abstract": "The rapid proliferation of satellite constellations in Space-Air-Ground Integrated Networks (SAGIN) presents significant challenges for network management. Conventional flat network architectures struggle with synchronization and data transmission across massive distributed nodes. In response, hierarchical domain-based satellite network architectures have emerged as a scalable solution, highlighting the critical importance of controller provisioning strategies. However, existing network management architectures and traditional search-based algorithms fail to generate efficient controller provisioning solutions due to limited computational resources in satellites and strict time constraints. To address these challenges, we propose a three-layer domain-based architecture that enhances both scalability and adaptability. Furthermore, we introduce Dora, a reinforcement learning-based controller provisioning strategy designed to optimize network performance while minimizing computational overhead. Our comprehensive experimental evaluation demonstrates that Dora significantly outperforms state-of-the-art benchmarks, achieving 10% improvement in controller provisioning quality while requiring only 1/30 to 1/90 of the computation time compared to traditional algorithms. These results underscore the potential of reinforcement learning approaches for efficient satellite network management in next-generation SAGIN deployments.",
      "authors": [
        "Qiyuan Peng",
        "Qi Zhang",
        "Yue Gao",
        "Kun Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:20:17+00:00",
          "link": "https://arxiv.org/abs/2507.14512v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "Dora: A Controller Provisioning Strategy in Hierarchical Domain-based Satellite Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14512",
        "HTML": "https://arxiv.org/html/2507.14512",
        "PDF": "https://arxiv.org/pdf/2507.14512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses network management challenges in satellite constellations using reinforcement learning. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15103",
      "abstract": "We develop and analyze numerical methods for a stochastic Keller-Segel system perturbed by Stratonovich noise, which models chemotactic behavior under randomly fluctuating environmental conditions. The proposed fully discrete scheme couples a Crank-Nicolson time discretization with a splitting mixed finite element method in space. We rigorously prove the stability of the numerical scheme and establish strong convergence rates of order $O(k^{1/2} + k^{-1/2}h^2)$, where $k$ and $h$ denote the time and spatial step sizes, respectively. Notably, the presence of stochastic forcing leads to an inverse dependence on $k$ in the error estimates, distinguishing the convergence behavior from that of the deterministic case. Numerical experiments are presented to validate the theoretical results and demonstrate the effectiveness and accuracy of the proposed methods.",
      "authors": [
        "Liet Vo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:54:43+00:00",
          "link": "https://arxiv.org/abs/2507.15103v1",
          "size": "871kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of fully discrete Crank-Nicolson finite element methods for a stochastic Keller-Segel chemotaxis system with gradient-type multiplicative noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15103",
        "PDF": "https://arxiv.org/pdf/2507.15103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical methods for a stochastic Keller-Segel system in a chemotaxis context and does not relate to LLM training data processing or the creation/improvement of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15232",
      "abstract": "Recent advances have sparked significant interest in the development of privacy-preserving Principal Component Analysis (PCA). However, many existing approaches rely on restrictive assumptions, such as assuming sub-Gaussian data or being vulnerable to data contamination. Additionally, some methods are computationally expensive or depend on unknown model parameters that must be estimated, limiting their accessibility for data analysts seeking privacy-preserving PCA. In this paper, we propose a differentially private PCA method applicable to heavy-tailed and potentially contaminated data. Our approach leverages the property that the covariance matrix of properly rescaled data preserves eigenvectors and their order under elliptical distributions, which include Gaussian and heavy-tailed distributions. By applying a bounded transformation, we enable straightforward computation of principal components in a differentially private manner. Additionally, boundedness guarantees robustness against data contamination. We conduct both theoretical analysis and empirical evaluations of the proposed method, focusing on its ability to recover the subspace spanned by the leading principal components. Extensive numerical experiments demonstrate that our method consistently outperforms existing approaches in terms of statistical utility, particularly in non-Gaussian or contaminated data settings.",
      "authors": [
        "Minwoo Kim",
        "Sungkyu Jung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:27:09+00:00",
          "link": "https://arxiv.org/abs/2507.15232v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "Robust and Differentially Private PCA for non-Gaussian data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15232",
        "HTML": "https://arxiv.org/html/2507.15232",
        "PDF": "https://arxiv.org/pdf/2507.15232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on privacy-preserving PCA for non-Gaussian data, which is unrelated to LLM training data processing techniques or operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15855",
      "abstract": "The International Mathematical Olympiad (IMO) poses uniquely challenging problems requiring deep insight, creativity, and formal reasoning. While Large Language Models (LLMs) perform well on mathematical benchmarks like AIME, they struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly released IMO 2025 problems, avoiding data contamination. With pipeline design and prompt engineering, 5 (out of 6) problems are solved correctly (up to a caveat discussed below), highlighting the importance of finding the optimal way of using powerful models.",
      "authors": [
        "Yichen Huang and Lin F. Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.15855v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15855",
        "HTML": "https://arxiv.org/html/2507.15855",
        "PDF": "https://arxiv.org/pdf/2507.15855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the performance of an LLM on solving IMO 2025 problems with a particular model and using optimal pipeline design and prompt engineering. It does not address data processing for LLM training or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03038",
      "abstract": "In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.",
      "authors": [
        "Taekyung Kim",
        "Randal W. Beard",
        "Dimitra Panagou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T21:32:32+00:00",
          "link": "https://arxiv.org/abs/2504.03038v1",
          "size": "1151kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T05:03:36+00:00",
          "link": "https://arxiv.org/abs/2504.03038v2",
          "size": "1150kb",
          "version": "v2"
        }
      ],
      "title": "How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03038",
        "HTML": "https://arxiv.org/html/2504.03038",
        "PDF": "https://arxiv.org/pdf/2504.03038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on adapting Control Barrier Functions for safe control in VTOL quadplane operations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14347",
      "abstract": "High level Automated Driving Systems (ADS) can handle many situations, but they still encounter situations where human intervention is required. In systems where a physical driver is present in the vehicle, typically SAE Level 3 systems, this intervention is relatively straightforward and is handled by the in-vehicle driver. However, the complexity increases for Level 4 systems, where, in most cases, no physical driver remains in the vehicle. The two common industry solutions for this challenge are the integration of a remote support system, such as a Remote Driving System (RDS) or Remote Assistance System (RAS). While it is clear that ADS will require one of these systems, it is less clear how the suitability of either system for a particular ADS application should be evaluated. Currently, the selection process often focuses on system architecture as well as its design and integration challenges. Furthermore, since many ADS developers choose to develop remote system solutions in-house, it is advantageous to select the simpler approach to streamline development and integration efforts. While these decision points are certainly relevant, this approach overlooks the most critical factors: the use cases and the complementarity of the ADS and the remote support system within the context of the Operational Design Design Domain (ODD). This paper proposes a structured approach for selecting between RDS and RAS as an ADS support system, based on the defined ODD and use case analysis. To achieve this, the paper applies the PEGASUS framework to systematically describe and analyze the ODD. A structured framework is introduced to evaluate and select the most suitable remote support system for an ADS based on clearly defined criteria.",
      "authors": [
        "Ole Hans and Benedikt Walter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:54:26+00:00",
          "link": "https://arxiv.org/abs/2507.14347v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "Remote Assistance or Remote Driving: The Impact of Operational Design Domains on ADS-Supporting Systems Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14347",
        "HTML": "https://arxiv.org/html/2507.14347",
        "PDF": "https://arxiv.org/pdf/2507.14347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Automated Driving Systems and remote support systems, with no mention of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14770",
      "abstract": "Context: The increasing reliance on Code Generation Tools (CGTs), such as Windsurf and GitHub Copilot, are revamping programming workflows and raising critical questions about fairness and inclusivity. While CGTs offer potential productivity enhancements, their effectiveness across diverse user groups have not been sufficiently investigated. Objectives: We hypothesize that developers' interactions with CGTs vary based on gender, influencing task outcomes and cognitive load, as prior research suggests that gender differences can affect technology use and cognitive processing. Methods: The study will employ a mixed-subjects design with 54 participants, evenly divided by gender for a counterbalanced design. Participants will complete two programming tasks (medium to hard difficulty) with only CGT assistance and then with only internet access. Task orders and conditions will be counterbalanced to mitigate order effects. Data collection will include cognitive load surveys, screen recordings, and task performance metrics such as completion time, code correctness, and CGT interaction behaviors. Statistical analyses will be conducted to identify statistically significant differences in CGT usage. Expected Contributions: Our work can uncover gender differences in CGT interaction and performance among developers. Our findings can inform future CGT designs and help address usability and potential disparities in interaction patterns across diverse user groups. Conclusion: While results are not yet available, our proposal lays the groundwork for advancing fairness, accountability, transparency, and ethics (FATE) in CGT design. The outcomes are anticipated to contribute to inclusive AI practices and equitable tool development for all users.",
      "authors": [
        "Manaal Basha",
        "Ivan Beschastnikh",
        "Gema Rodriguez-Perez",
        "Cleidson R. B. de Souza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T23:53:27+00:00",
          "link": "https://arxiv.org/abs/2507.14770v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "Toward Inclusive AI-Driven Development: Exploring Gender Differences in Code Generation Tool Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14770",
        "HTML": "https://arxiv.org/html/2507.14770",
        "PDF": "https://arxiv.org/pdf/2507.14770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gender differences in interactions with code generation tools, which is unrelated to LLM training data processing. It does not discuss data engineering operations or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15226",
      "abstract": "Code clone detection, which aims to identify functionally equivalent code fragments, plays a critical role in software maintenance and vulnerability analysis. Substantial methods have been proposed to detect code clones, but they fall short in capturing code semantics or relying on language-specific analyzers. Inspired by the remarkable success of AlphaFold in predicting three-dimensional protein structures from protein sequences, in this paper, we leverage AlphaFold for code clone detection based on the insight that protein sequences and token sequences share a common linear sequential structure. In particular, we propose AlphaCC, which represents code fragments as token sequences to ensure multi-language applicability and adapts AlphaFold's sequence-to-structure modeling capability to infer code semantics. The pipeline of AlphaCC goes through three steps. First, AlphaCC transforms each input code fragment into a token sequence and, motivated by AlphaFold's use of multiple sequence alignment (MSA) to enhance contextual understanding, constructs an MSA from lexically similar token sequences. Second, AlphaCC adopts a modified attention-based encoder based on AlphaFold to model dependencies within and across token sequences. Finally, unlike AlphaFold's protein structure prediction task, AlphaCC computes similarity scores between token sequences through a late interaction strategy and performs binary classification to determine code clone pairs. Comprehensive evaluations on three language-diverse datasets demonstrate AlphaCC's applicability across multiple programming languages. On two semantic clone detection datasets, it consistently outperforms all baselines, showing strong semantic understanding. Moreover, AlphaCC maintains competitive efficiency, enabling practical usage in large-scale clone detection tasks.",
      "authors": [
        "Changguo Jia",
        "Yi Zhan",
        "Tianqi Zhao",
        "Hengzhi Ye",
        "Minghui Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.15226v1",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "title": "Code Clone Detection via an AlphaFold-Inspired Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15226",
        "HTML": "https://arxiv.org/html/2507.15226",
        "PDF": "https://arxiv.org/pdf/2507.15226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on code clone detection using an AlphaFold-inspired framework and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15239",
      "abstract": "Novel AI-based arc fault diagnosis models have demonstrated outstanding performance in terms of classification accuracy. However, an inherent problem is whether these models can actually be trusted to find arc faults. In this light, this work proposes a soft evaluation indicator that explains the outputs of arc fault diagnosis models, by defining the the correct explanation of arc faults and leveraging Explainable Artificial Intelligence and real arc fault experiments. Meanwhile, a lightweight balanced neural network is proposed to guarantee competitive accuracy and soft feature extraction score. In our experiments, several traditional machine learning methods and deep learning methods across two arc fault datasets with different sample times and noise levels are utilized to test the effectiveness of the soft evaluation indicator. Through this approach, the arc fault diagnosis models are easy to understand and trust, allowing practitioners to make informed and trustworthy decisions.",
      "authors": [
        "Qianchao Wang",
        "Yuxuan Ding",
        "Chuanzhen Jia",
        "Zhe Li",
        "Yaping Du"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:52:43+00:00",
          "link": "https://arxiv.org/abs/2507.15239v1",
          "size": "1657kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15239",
        "PDF": "https://arxiv.org/pdf/2507.15239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an explainable AI-based evaluation indicator for arc fault diagnosis. It does not pertain to LLM training data processing or operations related to LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15300",
      "abstract": "3D Gaussian Splatting (3DGS) has emerged as a leading neural rendering technique for high-fidelity view synthesis, prompting the development of dedicated 3DGS accelerators for mobile applications. Through in-depth analysis, we identify two major limitations in the conventional decoupled preprocessing-rendering dataflow adopted by existing accelerators: 1) a significant portion of preprocessed Gaussians are not used in rendering, and 2) the same Gaussian gets repeatedly loaded across different tile renderings, resulting in substantial computational and data movement overhead. To address these issues, we propose GCC, a novel accelerator designed for fast and energy-efficient 3DGS inference. At the dataflow level, GCC introduces: 1) cross-stage conditional processing, which interleaves preprocessing and rendering to dynamically skip unnecessary Gaussian preprocessing; and 2) Gaussian-wise rendering, ensuring that all rendering operations for a given Gaussian are completed before moving to the next, thereby eliminating duplicated Gaussian loading. We also propose an alpha-based boundary identification method to derive compact and accurate Gaussian regions, thereby reducing rendering costs. We implement our GCC accelerator in 28nm technology. Extensive experiments demonstrate that GCC significantly outperforms the state-of-the-art 3DGS inference accelerator, GSCore, in both performance and energy efficiency.",
      "authors": [
        "Minnan Pei",
        "Gang Li",
        "Junwen Si",
        "Zeyu Zhu",
        "Zitao Mo",
        "Peisong Wang",
        "Zhuoran Song",
        "Xiaoyao Liang",
        "Jian Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:56:34+00:00",
          "link": "https://arxiv.org/abs/2507.15300v1",
          "size": "1830kb",
          "version": "v1"
        }
      ],
      "title": "GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15300",
        "HTML": "https://arxiv.org/html/2507.15300",
        "PDF": "https://arxiv.org/pdf/2507.15300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D Gaussian Splatting and the design of accelerators for neural rendering in mobile applications. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15492",
      "abstract": "After a family murder in rural Germany, authorities failed to locate the suspect in a vast forest despite a massive search. To aid the search, a research aircraft captured high-resolution aerial imagery. Due to dense vegetation obscuring small clues, automated analysis was ineffective, prompting a crowd-search initiative. This effort produced a unique dataset of labeled, hard-to-detect anomalies under occluded, real-world conditions. It can serve as a benchmark for improving anomaly detection approaches in complex forest environments, supporting manhunts and rescue operations. Initial benchmark tests showed existing methods performed poorly, highlighting the need for context-aware approaches. The dataset is openly accessible for offline processing. An additional interactive web interface supports online viewing and dynamic growth by allowing users to annotate and submit new findings.",
      "authors": [
        "Rakesh John Amala Arokia Nathan",
        "Matthias Gessner",
        "Nurullah \\\"Ozkan",
        "Marius Bock",
        "Mohamed Youssef",
        "Maximilian Mews",
        "Bj\\\"orn Piltz",
        "Ralf Berger",
        "and Oliver Bimber"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:52:27+00:00",
          "link": "https://arxiv.org/abs/2507.15492v1",
          "size": "4069kb",
          "version": "v1"
        }
      ],
      "title": "An aerial color image anomaly dataset for search missions in complex forested terrain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15492",
        "HTML": "https://arxiv.org/html/2507.15492",
        "PDF": "https://arxiv.org/pdf/2507.15492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a dataset for anomaly detection in aerial imagery captured during search missions in forests. It focuses on anomaly detection tasks unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.13763",
      "abstract": "Hydroelectricity accounted for roughly 61.4% of Brazil's total generation in 2024 and addressed most of the intermittency of wind and solar generation. Thus, inflow forecasting plays a critical role in the operation, planning, and market in this country, as well as in any other hydro-dependent power system. These forecasts influence generation schedules, reservoir management, and market pricing, shaping the dynamics of the entire electricity sector. The objective of this paper is to measure and present empirical evidence of a systematic optimistic bias in the official inflow forecast methodology, which is based on the PAR(p)-A model. Additionally, we discuss possible sources of this bias and recommend ways to mitigate it. By analyzing 14 years of historical data from the Brazilian system through rolling-window multistep (out-of-sample) forecasts, results indicate that the official forecast model exhibits statistically significant biases of 1.28, 3.83, 5.39, and 6.73 average GW for 1-, 6-, 12-, and 24-step-ahead forecasts in the Southeast subsystem, and 0.54, 1.66, 2.32, and 3.17 average GW in the Northeast subsystem. These findings uncover the limitations of current inflow forecasting methodologies used in Brazil and call for new governance and monitoring policies.",
      "authors": [
        "Arthur Brigatto",
        "Alexandre Street",
        "Cristiano Fernandes",
        "Davi Valladao",
        "Guilherme Bodin",
        "Joaquim Dias Garcia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T16:59:07+00:00",
          "link": "https://arxiv.org/abs/2410.13763v1",
          "size": "988kb",
          "version": "v1"
        },
        {
          "date": "2024-12-29T21:21:55+00:00",
          "link": "https://arxiv.org/abs/2410.13763v2",
          "size": "994kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T20:08:03+00:00",
          "link": "https://arxiv.org/abs/2410.13763v3",
          "size": "1362kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T01:16:51+00:00",
          "link": "https://arxiv.org/abs/2410.13763v4",
          "size": "1360kb",
          "version": "v4"
        }
      ],
      "title": "Assessing the Optimistic Bias in the Natural Inflow Forecasts: A Call for Model Monitoring in Brazil",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13763",
        "HTML": "https://arxiv.org/html/2410.13763",
        "PDF": "https://arxiv.org/pdf/2410.13763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with inflow forecasts for hydroelectric generation in Brazil, examining biases in statistical models, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Scheduling"
      ],
      "repo_urls": [
        "https://github.com/arthur-brigatto/inflowforecastbias_data"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.09493",
      "abstract": "Conversational recommender systems (CRSs) integrate both recommendation and dialogue tasks, making their evaluation uniquely challenging. Existing approaches primarily assess CRS performance by separately evaluating item recommendation and dialogue management using rule-based metrics. However, these methods fail to capture the real human experience, and they cannot draw direct conclusions about the system's overall performance. As conversational recommender systems become increasingly vital in e-commerce, social media, and customer support, the ability to evaluate both recommendation accuracy and dialogue management quality using a single metric, thereby authentically reflecting user experience, has become the principal challenge impeding progress in this field.\n  In this work, we propose a user-centric evaluation framework based on large language models (LLMs) for CRSs, namely Conversational Recommendation Evaluator (CoRE). CoRE consists of two main components: (1) LLM-As-Evaluator. Firstly, we comprehensively summarize 12 key factors influencing user experience in CRSs and directly leverage LLM as an evaluator to assign a score to each factor. (2) Multi-Agent Debater. Secondly, we design a multi-agent debate framework with four distinct roles (common user, domain expert, linguist, and HCI expert) to discuss and synthesize the 12 evaluation factors into a unified overall performance score.\n  Furthermore, we apply the proposed framework to evaluate four CRSs on two benchmark datasets. The experimental results show that CoRE aligns well with human evaluation in most of the 12 factors and the overall assessment. Especially, CoRE's overall evaluation scores demonstrate significantly better alignment with human feedback compared to existing rule-based metrics.",
      "authors": [
        "Nuo Chen",
        "Quanyu Dai",
        "Xiaoyu Dong",
        "Piaohong Wang",
        "Qinglin Jia",
        "Zhaocheng Du",
        "Zhenhua Dong",
        "Xiao-Ming Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-16T12:06:56+00:00",
          "link": "https://arxiv.org/abs/2501.09493v1",
          "size": "6544kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T10:46:28+00:00",
          "link": "https://arxiv.org/abs/2501.09493v2",
          "size": "9669kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T10:23:44+00:00",
          "link": "https://arxiv.org/abs/2501.09493v3",
          "size": "4958kb",
          "version": "v3"
        }
      ],
      "title": "Evaluating Conversational Recommender Systems via Large Language Models: A User-Centric Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09493",
        "HTML": "https://arxiv.org/html/2501.09493",
        "PDF": "https://arxiv.org/pdf/2501.09493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a user-centric evaluation framework for conversational recommender systems using LLMs, but it does not address training data processing for LLMs."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10342",
      "abstract": "Epilepsy is a prevalent neurological disorder globally, impacting around 50 million people \\cite{WHO_epilepsy_50million}. Epileptic seizures result from sudden abnormal electrical activity in the brain, which can be read as sudden and significant changes in the EEG signal of the brain. The signal can vary in severity and frequency, which results in loss of consciousness and muscle contractions for a short period of time \\cite{epilepsyfoundation_myoclonic}. Individuals with epilepsy often face significant employment challenges due to safety concerns in certain work environments. Many jobs that involve working at heights, operating heavy machinery, or in other potentially hazardous settings may be restricted for people with seizure disorders. This certainly limits job options and economic opportunities for those living with epilepsy.",
      "authors": [
        "Mohammed Guhdar",
        "Ramadhan J. Mstafa",
        "Abdulhakeem O. Mohammed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T18:33:58+00:00",
          "link": "https://arxiv.org/abs/2501.10342v1",
          "size": "706kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Deep Learning Model for epileptic seizure classification by using 1D-CNN with multi-head attention mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10342",
        "HTML": "https://arxiv.org/html/2501.10342",
        "PDF": "https://arxiv.org/pdf/2501.10342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on using a hybrid deep learning model for epileptic seizure classification, specifically leveraging EEG signals, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "EEG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16215",
      "abstract": "Large language models (LLMs) have shown promising capabilities in visually interpreting medical time-series data. However, their general-purpose design can limit domain-specific precision, and the proprietary nature of many models poses challenges for fine-tuning on specialized clinical datasets. Conversely, small specialized models (SSMs) offer strong performance on focused tasks but lack the broader reasoning needed for complex medical decision-making. To address these complementary limitations, we introduce \\ConMIL{} (Conformalized Multiple Instance Learning), a novel decision-support framework distinctively synergizes three key components: (1) a new Multiple Instance Learning (MIL) mechanism, QTrans-Pooling, designed for per-class interpretability in identifying clinically relevant physiological signal segments; (2) conformal prediction, integrated with MIL to generate calibrated, set-valued outputs with statistical reliability guarantees; and (3) a structured approach for these interpretable and uncertainty-quantified SSM outputs to enhance the visual inspection capabilities of LLMs. Our experiments on arrhythmia detection and sleep stage classification demonstrate that \\ConMIL{} can enhance the accuracy of LLMs such as ChatGPT4.0, Qwen2-VL-7B, and MiMo-VL-7B-RL. For example, \\ConMIL{}-supported Qwen2-VL-7B and MiMo-VL-7B-RL both achieves 94.92% and 96.82% precision on confident samples and (70.61% and 78.02%)/(78.10% and 71.98%) on uncertain samples for the two tasks, compared to 46.13% and 13.16% using the LLM alone. These results suggest that integrating task-specific models with LLMs may offer a promising pathway toward more interpretable and trustworthy AI-driven clinical decision support.",
      "authors": [
        "Huayu Li",
        "Zhengxiao He",
        "Xiwen Chen",
        "Ci Zhang",
        "Stuart F. Quan",
        "William D.S. Killgore",
        "Shu-Fen Wung",
        "Chen X. Chen",
        "Geng Yuan",
        "Jin Lu",
        "Ao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T17:07:20+00:00",
          "link": "https://arxiv.org/abs/2501.16215v1",
          "size": "4327kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T21:37:05+00:00",
          "link": "https://arxiv.org/abs/2501.16215v2",
          "size": "9345kb",
          "version": "v2"
        }
      ],
      "title": "Smarter Together: Combining Large Language Models and Small Models for Physiological Signals Visual Inspection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16215",
        "HTML": "https://arxiv.org/html/2501.16215",
        "PDF": "https://arxiv.org/pdf/2501.16215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces \\ConMIL{}, a framework for integrating large language models and small models to improve physiological signal visual inspection. The focus is on model integration and decision-making enhancement rather than training data processing for LLMs."
      },
      "tasks": [
        "Arrhythmia Detection",
        "Conformal Prediction",
        "Decision Making",
        "Multiple Instance Learning",
        "Sleep Staging",
        "Time Series",
        "Time Series Analysis"
      ],
      "repo_urls": [
        "https://github.com/HuayuLiArizona/Conformalized-Multiple-Instance-Learning-For-MedTS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14657",
      "abstract": "The integration of Artificial Intelligence (AI) into sports officiating represents a paradigm shift in how decisions are made in competitive environments. Traditional manual systems, even when supported by Instant Video Replay (IVR), often suffer from latency, subjectivity, and inconsistent enforcement, undermining fairness and athlete trust. This paper introduces FST.ai, a novel AI-powered framework designed to enhance officiating in Sport Taekwondo, particularly focusing on the complex task of real-time head kick detection and scoring. Leveraging computer vision, deep learning, and edge inference, the system automates the identification and classification of key actions, significantly reducing decision time from minutes to seconds while improving consistency and transparency. Importantly, the methodology is not limited to Taekwondo. The underlying framework -- based on pose estimation, motion classification, and impact analysis -- can be adapted to a wide range of sports requiring action detection, such as judo, karate, fencing, or even team sports like football and basketball, where foul recognition or performance tracking is critical. By addressing one of Taekwondo's most challenging scenarios -- head kick scoring -- we demonstrate the robustness, scalability, and sport-agnostic potential of FST.ai to transform officiating standards across multiple disciplines.",
      "authors": [
        "Keivan Shariatmadar",
        "Ahmad Osman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.14657v1",
          "size": "7870kb",
          "version": "v1"
        }
      ],
      "title": "AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14657",
        "HTML": "https://arxiv.org/html/2507.14657",
        "PDF": "https://arxiv.org/pdf/2507.14657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AI-powered system for improving officiating in sports, specifically focusing on action detection in Taekwondo, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14757",
      "abstract": "Spiking Neural Networks (SNNs) offer energy-efficient and biologically plausible alternatives to traditional artificial neural networks, but their performance depends critically on the tuning of neuron model parameters. In this work, we identify and characterize an operational space - a constrained region in the neuron hyperparameter domain (specifically membrane time constant tau and voltage threshold vth) - within which the network exhibits meaningful activity and functional behavior. Operating inside this manifold yields optimal trade-offs between classification accuracy and spiking activity, while stepping outside leads to degeneration: either excessive energy use or complete network silence.\n  Through systematic exploration across datasets and architectures, we visualize and quantify this manifold and identify efficient operating points. We further assess robustness to adversarial noise, showing that SNNs exhibit increased spike correlation and internal synchrony when operating outside their optimal region. These findings highlight the importance of principled hyperparameter tuning to ensure both task performance and energy efficiency. Our results offer practical guidelines for deploying robust and efficient SNNs, particularly in neuromorphic computing scenarios.",
      "authors": [
        "Szymon Mazurek and Jakub Caputa and Maciej Wielgosz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:13:53+00:00",
          "link": "https://arxiv.org/abs/2507.14757v1",
          "size": "10026kb",
          "version": "v1"
        }
      ],
      "title": "Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14757",
        "HTML": "https://arxiv.org/html/2507.14757",
        "PDF": "https://arxiv.org/pdf/2507.14757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about optimizing neuron parameters in Spiking Neural Networks for energy efficiency and robustness, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15420",
      "abstract": "In recent years, there have been many developments for GDPR-compliant data access and sharing based on consent. For more complex data sharing scenarios, where consent might not be sufficient, many parties rely on contracts. Before a contract is signed, it must undergo the process of contract negotiation within the contract lifecycle, which consists of negotiating the obligations associated with the contract. Contract compliance verification (CCV) provides a means to verify whether a contract is GDPR-compliant, i.e., adheres to legal obligations and there are no violations. The rise of knowledge graph (KG) adoption, enabling semantic interoperability using well-defined semantics, allows CCV to be applied on KGs. In the scenario of different participants negotiating obligations, there is a need for data consistency to ensure that CCV is done correctly. Recent work introduced the automated contracting tool (ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in the Horizon 2020 project smashHit (https://smashhit.eu). Although the tool reports violations with respect to obligations, it had limitations in verifying and ensuring compliance, as it did not use an interoperable semantic formalism, such as SHACL, and did not support users in resolving data inconsistencies. In this work, we propose a novel approach to overcome these limitations of ACT. We semi-automatically resolve CCV inconsistencies by providing repair strategies, which automatically propose (optimal) solutions to the user to re-establish data consistency and thereby support them in managing GDPR-compliant contract lifecycle data. We have implemented the approach, integrated it into ACT and tested its correctness and performance against basic CCV consistency requirements.",
      "authors": [
        "Robert David",
        "Albin Ahmeti",
        "Geni Bushati",
        "Amar Tauqeer",
        "Anna Fensel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:21:42+00:00",
          "link": "https://arxiv.org/abs/2507.15420v1",
          "size": "570kb",
          "version": "v1"
        }
      ],
      "title": "A SHACL-based Data Consistency Solution for Contract Compliance Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15420",
        "HTML": "https://arxiv.org/html/2507.15420",
        "PDF": "https://arxiv.org/pdf/2507.15420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with data consistency solutions for contract compliance verification in GDPR scenarios, focusing on semantic interoperability and knowledge graphs, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15650",
      "abstract": "Computer aided formative assessment can be used to enhance a learning process, for instance by providing feedback. There are many design choices for delivering feedback, that lead to a feedback strategy. In an informative feedback strategy, students do not immediately receive information about the correct response, but are offered the opportunity to retry a task to apply feedback information. In this small-scale qualitative study, we explore an informative feedback strategy designed to offer a balance between room for exploration and mitigation of learning barriers. The research questions concern the ways in which students interact with the feedback strategy and their appreciation of error-specific feedback as opposed to worked-out solutions. To answer these questions, twenty-five 15-to-17-year-old senior general secondary education students worked for approximately 20 minutes on linear and exponential extrapolation tasks in an online environment. Data included screen captures of students working with the environment and post-intervention interviews. Results showed that room for exploration offered opportunities for self-guidance while mitigation of learning barriers prevented disengagement. Furthermore, students appreciated balanced feedback. We conclude that the balanced feedback strategy yielded fruitful student-environment interactions.",
      "authors": [
        "Gerben van der Hoek",
        "Bastiaan Heeren",
        "Rogier Bos",
        "Paul Drijvers",
        "and Johan Jeuring"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:14:56+00:00",
          "link": "https://arxiv.org/abs/2507.15650v1",
          "size": "965kb",
          "version": "v1"
        }
      ],
      "title": "Chapter 11 Students' interaction with and appreciation of automated informative tutoring feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15650",
        "PDF": "https://arxiv.org/pdf/2507.15650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on feedback strategies in educational contexts and does not contribute to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.13153",
      "abstract": "We investigate a combinatorial optimization problem that involves patrolling the edges of an acute triangle using a unit-speed agent. The goal is to minimize the maximum (1-gap) idle time of any edge, which is defined as the time gap between consecutive visits to that edge. This problem has roots in a centuries-old optimization problem posed by Fagnano in 1775, who sought to determine the inscribed triangle of an acute triangle with the minimum perimeter. It is well-known that the orthic triangle, giving rise to a periodic and cyclic trajectory obeying the laws of geometric optics, is the optimal solution to Fagnano's problem. Such trajectories are known as Fagnano orbits, or more generally as billiard trajectories. We demonstrate that the orthic triangle is also an optimal solution to the patrolling problem.\n  Our main contributions pertain to new connections between billiard trajectories and optimal patrolling schedules in combinatorial optimization. In particular, as an artifact of our arguments, we introduce a novel 2-gap patrolling problem that seeks to minimize the visitation time of objects every three visits. We prove that there exist infinitely many well-structured billiard-type optimal trajectories for this problem, including the orthic trajectory, which has the special property of minimizing the visitation time gap between any two consecutively visited edges. Complementary to that, we also examine the cost of dynamic, sub-optimal trajectories to the 1-gap patrolling optimization problem. These trajectories result from a greedy algorithm and can be implemented by a computationally primitive mobile agent.",
      "authors": [
        "Konstantinos Georgiou",
        "Somnath Kundu",
        "Pawel Pralat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-24T22:39:39+00:00",
          "link": "https://arxiv.org/abs/2307.13153v1",
          "size": "97kb",
          "version": "v1"
        },
        {
          "date": "2024-04-14T15:14:29+00:00",
          "link": "https://arxiv.org/abs/2307.13153v2",
          "size": "93kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T22:59:54+00:00",
          "link": "https://arxiv.org/abs/2307.13153v3",
          "size": "87kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T15:44:01+00:00",
          "link": "https://arxiv.org/abs/2307.13153v4",
          "size": "88kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T14:04:20+00:00",
          "link": "https://arxiv.org/abs/2307.13153v5",
          "size": "79kb",
          "version": "v5"
        }
      ],
      "title": "The Fagnano Triangle Patrolling Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.13153",
        "HTML": "https://arxiv.org/html/2307.13153",
        "PDF": "https://arxiv.org/pdf/2307.13153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates a combinatorial optimization problem related to patrolling an acute triangle's edges, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.10945",
      "abstract": "Conventional vehicle dynamics estimation methods suffer from the drawback of employing independent, separately calibrated filtering modules for each variable. To address this limitation, a recent proposal introduces a unified Twin-in-the-Loop (TiL) Observer architecture. This architecture replaces the simplified control-oriented vehicle model with a full-fledged vehicle simulator (digital twin), and employs a real-time correction mechanism using a linear time-invariant output error law. Bayesian Optimization is utilized to tune the observer due to the simulator's black-box nature, leading to a high-dimensional optimization problem. This paper focuses on developing a procedure to reduce the observer's complexity by exploring both supervised and unsupervised learning approaches. The effectiveness of these strategies is validated for longitudinal and lateral vehicle dynamics using real-world data.",
      "authors": [
        "Giacomo Delcaro",
        "Riccardo Poli",
        "Federico Dett\\`u",
        "Simone Formentin",
        "Sergio Matteo Savaresi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-18T10:14:21+00:00",
          "link": "https://arxiv.org/abs/2401.10945v1",
          "size": "7421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T17:13:38+00:00",
          "link": "https://arxiv.org/abs/2401.10945v2",
          "size": "2859kb",
          "version": "v2"
        }
      ],
      "title": "Automatic dimensionality reduction of Twin-in-the-Loop Observers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.10945",
        "HTML": "https://arxiv.org/html/2401.10945",
        "PDF": "https://arxiv.org/pdf/2401.10945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a procedure to reduce the complexity of vehicle dynamics estimation using supervised and unsupervised learning. It is not related to LLM training data processing, pretraining, or fine-tuning."
      },
      "tasks": [
        "Bayesian Optimization",
        "Dimensionality Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11922",
      "abstract": "This paper is concerned with the convergence of a two-step modified Newton method for solving the nonlinear system arising from the minimal nonnegative solution of nonsymmetric algebraic Riccati equations from neutron transport theory. We show the monotonic convergence of the two-step modified Newton method under mild assumptions. When the Jacobian of the nonlinear operator at the minimal positive solution is singular, we present a convergence analysis of the two-step modified Newton method in this context. Numerical experiments are conducted to demonstrate that the proposed method yields comparable results to several existing Newton-type methods and that it brings a significant reduction in computation time for nearly singular and large-scale problems.",
      "authors": [
        "Juan Liang and Yonghui Ling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T06:54:53+00:00",
          "link": "https://arxiv.org/abs/2501.11922v1",
          "size": "155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T09:28:22+00:00",
          "link": "https://arxiv.org/abs/2501.11922v2",
          "size": "310kb",
          "version": "v2"
        }
      ],
      "title": "On the convergence of two-step modified Newton method for nonsymmetric algebraic Riccati equations from transport theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11922",
        "HTML": "https://arxiv.org/html/2501.11922",
        "PDF": "https://arxiv.org/pdf/2501.11922"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus on a two-step modified Newton method for solving Riccati equations from transport theory does not pertain to processing data for large language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.09384",
      "abstract": "For effective image segmentation, it is crucial to employ constraints informed by prior knowledge about the characteristics of the areas to be segmented to yield favorable segmentation outcomes. However, the existing methods have primarily focused on priors of specific properties or shapes, lacking consideration of the general global shape similarity from a Contour Flow (CF) perspective. Furthermore, naturally integrating this contour flow prior image segmentation model into the activation functions of deep convolutional networks through mathematical methods is currently unexplored. In this paper, we establish a concept of global shape similarity based on the premise that two shapes exhibit comparable contours. Furthermore, we mathematically derive a contour flow constraint that ensures the preservation of global shape similarity. We propose two implementations to integrate the constraint with deep neural networks. Firstly, the constraint is converted to a shape loss, which can be seamlessly incorporated into the training phase for any learning-based segmentation framework. Secondly, we add the constraint into a variational segmentation model and derive its iterative schemes for solution. The scheme is then unrolled to get the architecture of the proposed CFSSnet. Validation experiments on diverse datasets are conducted on classic benchmark deep network segmentation models. The results indicate a great improvement in segmentation accuracy and shape similarity for the proposed shape loss, showcasing the general adaptability of the proposed loss term regardless of specific network architectures. CFSSnet shows robustness in segmenting noise-contaminated images, and inherent capability to preserve global shape similarity.",
      "authors": [
        "Shengzhe Chen",
        "Zhaoxuan Dong",
        "Jun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T00:34:47+00:00",
          "link": "https://arxiv.org/abs/2504.09384v1",
          "size": "10745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:23:18+00:00",
          "link": "https://arxiv.org/abs/2504.09384v2",
          "size": "3642kb",
          "version": "v2"
        }
      ],
      "title": "Contour Flow Constraint: Preserving Global Shape Similarity for Deep Learning based Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09384",
        "HTML": "https://arxiv.org/html/2504.09384",
        "PDF": "https://arxiv.org/pdf/2504.09384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on image segmentation using constraints for deep learning models. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19099",
      "abstract": "We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.",
      "authors": [
        "Kun Xiang and Heng Li and Terry Jingchen Zhang and Yinya Huang and Zirong Liu and Peixin Qu and Jixi He and Jiaqi Chen and Yu-Jie Yuan and Jianhua Han and Hang Xu and Hanhui Li and Mrinmaya Sachan and Xiaodan Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Physics Education (physics.ed-ph)",
        "Popular Physics (physics.pop-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T11:28:34+00:00",
          "link": "https://arxiv.org/abs/2505.19099v1",
          "size": "7284kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T12:02:43+00:00",
          "link": "https://arxiv.org/abs/2505.19099v2",
          "size": "7884kb",
          "version": "v2"
        },
        {
          "date": "2025-05-30T18:22:56+00:00",
          "link": "https://arxiv.org/abs/2505.19099v3",
          "size": "7411kb",
          "version": "v3"
        },
        {
          "date": "2025-06-17T14:31:36+00:00",
          "link": "https://arxiv.org/abs/2505.19099v4",
          "size": "7410kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T12:44:10+00:00",
          "link": "https://arxiv.org/abs/2505.19099v5",
          "size": "7410kb",
          "version": "v5"
        }
      ],
      "title": "SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19099",
        "HTML": "https://arxiv.org/html/2505.19099",
        "PDF": "https://arxiv.org/pdf/2505.19099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for assessing physics reasoning capabilities in multimodal models. It does not discuss any aspect of LLM training data processing, instead focusing on evaluating model performance on visual tasks."
      },
      "datasets": [
        {
          "dataset_name": "SeePhys/SeePhys",
          "downloads": "255",
          "likes": "6",
          "link": "https://huggingface.co/datasets/SeePhys/SeePhys"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/seephys/seephys-project"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11055",
      "abstract": "Medical language-guided segmentation, integrating textual clinical reports as auxiliary guidance to enhance image segmentation, has demonstrated significant improvements over unimodal approaches. However, its inherent reliance on paired image-text input, which we refer to as ``textual reliance\", presents two fundamental limitations: 1) many medical segmentation datasets lack paired reports, leaving a substantial portion of image-only data underutilized for training; and 2) inference is limited to retrospective analysis of cases with paired reports, limiting its applicability in most clinical scenarios where segmentation typically precedes reporting. To address these limitations, we propose ProLearn, the first Prototype-driven Learning framework for language-guided segmentation that fundamentally alleviates textual reliance. At its core, we introduce a novel Prototype-driven Semantic Approximation (PSA) module to enable approximation of semantic guidance from textual input. PSA initializes a discrete and compact prototype space by distilling segmentation-relevant semantics from textual reports. Once initialized, it supports a query-and-respond mechanism which approximates semantic guidance for images without textual input, thereby alleviating textual reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn outperforms state-of-the-art language-guided methods when limited text is available.",
      "authors": [
        "Shuchang Ye",
        "Usman Naseem",
        "Mingyuan Meng",
        "Jinman Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.11055v1",
          "size": "3707kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T08:27:43+00:00",
          "link": "https://arxiv.org/abs/2507.11055v2",
          "size": "3707kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T01:01:24+00:00",
          "link": "https://arxiv.org/abs/2507.11055v3",
          "size": "3707kb",
          "version": "v3"
        }
      ],
      "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11055",
        "HTML": "https://arxiv.org/html/2507.11055",
        "PDF": "https://arxiv.org/pdf/2507.11055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for medical image segmentation focused on semantic approximation and prototype-driven learning, and it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14384",
      "abstract": "In this study, we investigate the use of large language models (LLMs), specifically ChatGPT, for structured deductive qualitative coding. While most current research emphasizes inductive coding applications, we address the underexplored potential of LLMs to perform deductive classification tasks aligned with established human-coded schemes. Using the Comparative Agendas Project (CAP) Master Codebook, we classified U.S. Supreme Court case summaries into 21 major policy domains. We tested four intervention methods: zero-shot, few-shot, definition-based, and a novel Step-by-Step Task Decomposition strategy, across repeated samples. Performance was evaluated using standard classification metrics (accuracy, F1-score, Cohen's kappa, Krippendorff's alpha), and construct validity was assessed using chi-squared tests and Cramer's V. Chi-squared and effect size analyses confirmed that intervention strategies significantly influenced classification behavior, with Cramer's V values ranging from 0.359 to 0.613, indicating moderate to strong shifts in classification patterns. The Step-by-Step Task Decomposition strategy achieved the strongest reliability (accuracy = 0.775, kappa = 0.744, alpha = 0.746), achieving thresholds for substantial agreement. Despite the semantic ambiguity within case summaries, ChatGPT displayed stable agreement across samples, including high F1 scores in low-support subclasses. These findings demonstrate that with targeted, custom-tailored interventions, LLMs can achieve reliability levels suitable for integration into rigorous qualitative coding workflows.",
      "authors": [
        "Angjelin Hila and Elliott Hauser"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.14384v1",
          "size": "2574kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14384",
        "HTML": "https://arxiv.org/html/2507.14384",
        "PDF": "https://arxiv.org/pdf/2507.14384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper studies LLMs for qualitative coding, which involves some aspects of dataset classification, it primarily focuses on model evaluation metrics rather than contributions to LLM training data processing like dataset creation or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14624",
      "abstract": "Reconstructing photo-realistic large-scale scenes from images, for example at city scale, is a long-standing problem in computer graphics. Neural rendering is an emerging technique that enables photo-realistic image synthesis from previously unobserved viewpoints; however, state-of-the-art neural rendering methods have difficulty efficiently rendering a high complex large-scale scene because these methods typically trade scene size, fidelity, and rendering speed for quality. The other stream of techniques utilizes scene geometries for reconstruction. But the cost of building and maintaining a large set of geometry data increases as scene size grows. Our work explores novel view synthesis methods that efficiently reconstruct complex scenes without explicit use of scene geometries. Specifically, given sparse images of the scene (captured from the real world), we reconstruct intermediate, multi-scale, implicit representations of scene geometries. In this way, our method avoids explicitly relying on scene geometry, significantly reducing the computational cost of maintaining large 3D data. Unlike current methods, we reconstruct the scene using a probe data structure. Probe data hold highly accurate depth information of dense data points, enabling the reconstruction of highly complex scenes. By reconstructing the scene using probe data, the rendering cost is independent of the complexity of the scene. As such, our approach combines geometry reconstruction and novel view synthesis. Moreover, when rendering large-scale scenes, compressing and streaming probe data is more efficient than using explicit scene geometry. Therefore, our neural representation approach can potentially be applied to virtual reality (VR) and augmented reality (AR) applications.",
      "authors": [
        "Yaru Liu",
        "Derek Nowrouzezahri",
        "Morgan Mcguire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:43:30+00:00",
          "link": "https://arxiv.org/abs/2507.14624v1",
          "size": "21358kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Scene Reconstruction using Light Field Probes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14624",
        "HTML": "https://arxiv.org/html/2507.14624",
        "PDF": "https://arxiv.org/pdf/2507.14624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for scene reconstruction using image data in computer graphics. It does not pertain to LLM data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14756",
      "abstract": "This study evaluates the role of grid-connected hydrogen electrolyzers in advancing a cost-effective and in particular an equitable green hydrogen industry in Kenya to serve both domestic and international needs and markets. Using a multi-nodal capacity expansion model with county-level spatial resolution, we assess how electrolyzer deployment affects electricity cost, grid flexibility, and carbon intensity under various renewable and demand scenarios. Results show that electrolyzers enable up to 30 percent reduction in levelized cost of electricity (LCOE) and US\\$460 million in cumulative system cost savings by 2050 compared to a business-as-usual scenario. As a flexible demand available to absorb surplus generation, electrolyzers reduce curtailment and support large-scale wind integration while still requiring a diverse mix of renewable electricity. The resulting hydrogen reaches a levelized cost of \\$3.2 per kg by 2050, and its carbon intensity from electricity use falls below one kg carbon dioxide per kg of hydrogen, suggesting likely compliance with international certification thresholds. Benefits persist across all demand trajectories, though their scale depends on the pace of wind expansion. Spatial analyses reveal unequal distribution of infrastructure gains, underscoring the need for equity-oriented planning. These findings suggest that grid-integrated hydrogen, if planned in coordination with wind investment, transmission, and equitable infrastructure deployment, can reduce costs, support certification, and promote a more equitable model of hydrogen development. In other words, connecting electrolyzers to the grid will not only make green hydrogen in Kenya but also for Kenya.",
      "authors": [
        "Xi Xi",
        "Boniface Kinyanjui",
        "Daniel M. Kammen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:07:04+00:00",
          "link": "https://arxiv.org/abs/2507.14756v1",
          "size": "1438kb",
          "version": "v1"
        }
      ],
      "title": "Preventing an Extractive Green Hydrogen Industry: Risks and Benefits of Grid Expansion and Green Hydrogen in and for Kenya",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14756",
        "PDF": "https://arxiv.org/pdf/2507.14756"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses green hydrogen production and grid expansion in Kenya, which does not pertain to LLM training data processing or any related data engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14826",
      "abstract": "Image dehazing aims to remove unwanted hazy artifacts in images. Although previous research has collected paired real-world hazy and haze-free images to improve dehazing models' performance in real-world scenarios, these models often experience significant performance drops when handling unseen real-world hazy images due to limited training data. This issue motivates us to develop a flexible domain adaptation method to enhance dehazing performance during testing. Observing that predicting haze patterns is generally easier than recovering clean content, we propose the Physics-guided Haze Transfer Network (PHATNet) which transfers haze patterns from unseen target domains to source-domain haze-free images, creating domain-specific fine-tuning sets to update dehazing models for effective domain adaptation. Additionally, we introduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to enhance PHATNet's disentanglement ability. Experimental results demonstrate that PHATNet significantly boosts state-of-the-art dehazing models on benchmark real-world image dehazing datasets.",
      "authors": [
        "Fu-Jen Tsai",
        "Yan-Tsung Peng",
        "Yen-Yu Lin",
        "and Chia-Wen Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T05:26:30+00:00",
          "link": "https://arxiv.org/abs/2507.14826v1",
          "size": "4531kb",
          "version": "v1"
        }
      ],
      "title": "PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14826",
        "HTML": "https://arxiv.org/html/2507.14826",
        "PDF": "https://arxiv.org/pdf/2507.14826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research tackles image dehazing using a domain adaptation method in computer vision. The focus is on improving image processing rather than LLM training data processing or text-based dataset handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14965",
      "abstract": "Low-overlap point cloud registration (PCR) remains a significant challenge in 3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become ineffective under extremely low inlier ratios. In this paper, we revisit the registration result evaluation problem and identify the Decision version of the PCR task as the fundamental problem. To address this Decision PCR task, we propose a data-driven approach. First, we construct a corresponding dataset based on the 3DMatch dataset. Then, a deep learning-based classifier is trained to reliably assess registration quality, overcoming the limitations of traditional metrics. To our knowledge, this is the first comprehensive study to address this task through a deep learning framework. We incorporate this classifier into standard PCR pipelines. When integrated with our approach, existing state-of-the-art PCR methods exhibit significantly enhanced registration performance. For example, combining our framework with GeoTransformer achieves a new SOTA registration recall of 86.97\\% on the challenging 3DLoMatch benchmark. Our method also demonstrates strong generalization capabilities on the unseen outdoor ETH dataset.",
      "authors": [
        "Yaojie Zhang",
        "Tianlun Huang",
        "Weijun Wang",
        "Wei Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:51:42+00:00",
          "link": "https://arxiv.org/abs/2507.14965v1",
          "size": "7955kb",
          "version": "v1"
        }
      ],
      "title": "Decision PCR: Decision version of the Point Cloud Registration task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14965",
        "HTML": "https://arxiv.org/html/2507.14965",
        "PDF": "https://arxiv.org/pdf/2507.14965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on point cloud registration in 3D vision, involving dataset creation for a deep learning-based approach. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15774",
      "abstract": "While boundaries between data modalities are vanishing, the usual successful deep models are still challenged by simple ones in the time-series forecasting task. Our hypothesis is that this task needs models that are able to learn the data underlying dynamics. We propose to validate it through both systemic and empirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to analyze existing models through the lens of dynamics. Two observations thus emerged: $\\textbf{1}$. under-performing architectures learn dynamics at most partially, $\\textbf{2}$. the location of the dynamics block at the model end is of prime importance. We conduct extensive experiments to confirm our observations on a set of performance-varying models with diverse backbones. Results support the need to incorporate a learnable dynamics block and its use as the final predictor.",
      "authors": [
        "Alexis-Raja Brachet",
        "Pierre-Yves Richard and C\\'eline Hudelot"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:29:29+00:00",
          "link": "https://arxiv.org/abs/2507.15774v1",
          "size": "4058kb",
          "version": "v1"
        }
      ],
      "title": "Dynamics is what you need for time-series forecasting!",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15774",
        "HTML": "https://arxiv.org/html/2507.15774",
        "PDF": "https://arxiv.org/pdf/2507.15774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses time-series forecasting models in terms of dynamic learning but does not involve LLM training data processing techniques or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2204.06686",
      "abstract": "We give an alternative, simple method to prove isoperimetric inequalities over the hypercube. In particular, we show:\n  1. An elementary proof of classical isoperimetric inequalities of Talagrand, as well as a stronger isoperimetric result conjectured by Talagrand and recently proved by Eldan and Gross.\n  2. A strengthening of the Friedgut junta theorem, asserting that if the $p$-moment of the sensitivity of a function is constant for some $1/2 + \\varepsilon\\leq p\\leq 1$, then the function is close to a junta. In this language, Friedgut's theorem is the special case that $p=1$.",
      "authors": [
        "Ronen Eldan",
        "Guy Kindler",
        "Noam Lifshitz",
        "Dor Minzer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2022-04-14T01:11:05+00:00",
          "link": "https://arxiv.org/abs/2204.06686v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2023-02-13T10:04:44+00:00",
          "link": "https://arxiv.org/abs/2204.06686v2",
          "size": "17kb",
          "version": "v2"
        },
        {
          "date": "2024-08-01T10:28:41+00:00",
          "link": "https://arxiv.org/abs/2204.06686v3",
          "size": "20kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T12:01:37+00:00",
          "link": "https://arxiv.org/abs/2204.06686v4",
          "size": "51kb",
          "version": "v4"
        }
      ],
      "title": "Isoperimetric Inequalities Made Simpler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2204.06686",
        "HTML": "https://arxiv.org/html/2204.06686",
        "PDF": "https://arxiv.org/pdf/2204.06686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical methods for proving isoperimetric inequalities and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.01425",
      "abstract": "Controlling the movements of dynamic objects and the camera within generated videos is a meaningful yet challenging task. Due to the lack of datasets with comprehensive 6D pose annotations, existing text-to-video methods can not simultaneously control the motions of both camera and objects in 3D-aware manner, resulting in limited controllability over generated contents. To address this issue and facilitate the research in this field, we introduce a Synthetic Dataset for Free-Form Motion Control (SynFMC). The proposed SynFMC dataset includes diverse object and environment categories and covers various motion patterns according to specific rules, simulating common and complex real-world scenarios. The complete 6D pose information facilitates models learning to disentangle the motion effects from objects and the camera in a video.~To provide precise 3D-aware motion control, we further propose a method trained on SynFMC, Free-Form Motion Control (FMC). FMC can control the 6D poses of objects and camera independently or simultaneously, producing high-fidelity videos. Moreover, it is compatible with various personalized text-to-image (T2I) models for different content styles. Extensive experiments demonstrate that the proposed FMC outperforms previous methods across multiple scenarios.",
      "authors": [
        "Xincheng Shuai",
        "Henghui Ding",
        "Zhenyuan Qin",
        "Hao Luo",
        "Xingjun Ma",
        "Dacheng Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T18:59:45+00:00",
          "link": "https://arxiv.org/abs/2501.01425v1",
          "size": "9685kb",
          "version": "v1"
        },
        {
          "date": "2025-01-03T05:42:56+00:00",
          "link": "https://arxiv.org/abs/2501.01425v2",
          "size": "9685kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T08:17:15+00:00",
          "link": "https://arxiv.org/abs/2501.01425v3",
          "size": "7936kb",
          "version": "v3"
        }
      ],
      "title": "Free-Form Motion Control: Controlling the 6D Poses of Camera and Objects in Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01425",
        "HTML": "https://arxiv.org/html/2501.01425",
        "PDF": "https://arxiv.org/pdf/2501.01425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on video generation with synthetic datasets for 6D pose control. It does not involve language model training or data processing for LLMs."
      },
      "tasks": [
        "Form",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17259",
      "abstract": "Benchmark contamination poses a significant challenge to the reliability of Large Language Models (LLMs) evaluations, as it is difficult to assert whether a model has been trained on a test set. We introduce a solution to this problem by watermarking benchmarks before their release. The embedding involves reformulating the original questions with a watermarked LLM, in a way that does not alter the benchmark utility. During evaluation, we can detect ``radioactivity'', \\ie traces that the text watermarks leave in the model during training, using a theoretically grounded statistical test. We test our method by pre-training 1B models from scratch on 10B tokens with controlled benchmark contamination, and validate its effectiveness in detecting contamination on ARC-Easy, ARC-Challenge, and MMLU. Results show similar benchmark utility post-watermarking and successful contamination detection when models are contaminated enough to enhance performance, \\eg $p$-val $=10^{-3}$ for +5$\\%$ on ARC-Easy.",
      "authors": [
        "Tom Sander",
        "Pierre Fernandez",
        "Saeed Mahloujifar",
        "Alain Durmus",
        "Chuan Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T15:39:31+00:00",
          "link": "https://arxiv.org/abs/2502.17259v1",
          "size": "498kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:24:27+00:00",
          "link": "https://arxiv.org/abs/2502.17259v2",
          "size": "539kb",
          "version": "v2"
        }
      ],
      "title": "Detecting Benchmark Contamination Through Watermarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17259",
        "HTML": "https://arxiv.org/html/2502.17259",
        "PDF": "https://arxiv.org/pdf/2502.17259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents a novel technique for watermarking benchmarks to detect contamination in LLM evaluations, directly addressing the issue of data quality assurance in LLM training data processing by ensuring reliable test set usage."
      },
      "tasks": [
        "ARC",
        "MMLU"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14596",
      "abstract": "3D semantic segmentation provides high-level scene understanding for applications in robotics, autonomous systems, \\textit{etc}. Traditional methods adapt exclusively to either task-specific goals (open-vocabulary segmentation) or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the first method addressing the broader problem of 3D Open-Vocabulary Sub-concepts Discovery, which aims to provide a 3D semantic segmentation that adapts to both the scene and user queries. We build DiSCO-3D on Neural Fields representations, combining unsupervised segmentation with weak open-vocabulary guidance. Our evaluations demonstrate that DiSCO-3D achieves effective performance in Open-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in the edge cases of both open-vocabulary and unsupervised segmentation.",
      "authors": [
        "Doriand Petit",
        "Steve Bourgeois",
        "Vincent Gay-Bellile",
        "Florian Chabot and Lo\\\"ic Barthe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:46:20+00:00",
          "link": "https://arxiv.org/abs/2507.14596v1",
          "size": "5389kb",
          "version": "v1"
        }
      ],
      "title": "DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14596",
        "HTML": "https://arxiv.org/html/2507.14596",
        "PDF": "https://arxiv.org/pdf/2507.14596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D semantic segmentation and sub-concept discovery in NeRF. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14969",
      "abstract": "The vision of End-User Software Engineering (EUSE) is to empower non-professional users with full control over the software development lifecycle. It aims to enable users to drive generative software development using only natural language requirements. However, since end-users often lack knowledge of software engineering, their requirement descriptions are frequently ambiguous, raising significant challenges to generative software development. Although existing approaches utilize structured languages like Gherkin to clarify user narratives, they still struggle to express the causal logic between preconditions and behavior actions. This paper introduces RequireCEG, a requirement elicitation and self-review agent that embeds causal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture. RequireCEG first uses a feature tree to analyze user narratives hierarchically, clearly defining the scope of software components and their system behavior requirements. Next, it constructs the self-healing CEGs based on the elicited requirements, capturing the causal relationships between atomic preconditions and behavioral actions. Finally, the constructed CEGs are used to review and optimize Gherkin scenarios, ensuring consistency between the generated Gherkin requirements and the system behavior requirements elicited from user narratives. To evaluate our method, we created the RGPair benchmark dataset and conducted extensive experiments. It achieves an 87% coverage rate and raises diversity by 51.88%.",
      "authors": [
        "Sai Zhang",
        "Zhenchang Xing",
        "Jieshan Chen",
        "Dehai Zhao",
        "Zizhong Zhu",
        "Xiaowang Zhang",
        "Zhiyong Feng",
        "Xiaohong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:59:00+00:00",
          "link": "https://arxiv.org/abs/2507.14969v1",
          "size": "27240kb",
          "version": "v1"
        }
      ],
      "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14969",
        "HTML": "https://arxiv.org/html/2507.14969",
        "PDF": "https://arxiv.org/pdf/2507.14969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses software requirements elicitation with a neuro-symbolic agent, focusing on improving collaboration and understanding in software development, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15796",
      "abstract": "In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.",
      "authors": [
        "Nuria Rodr\\'iguez-Barroso and Mario Garc\\'ia-M\\'arquez and M. Victoria Luz\\'on and Francisco Herrera"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:57:06+00:00",
          "link": "https://arxiv.org/abs/2507.15796v1",
          "size": "2527kb",
          "version": "v1"
        }
      ],
      "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15796",
        "HTML": "https://arxiv.org/html/2507.15796",
        "PDF": "https://arxiv.org/pdf/2507.15796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with the challenges of making Federated Learning (FL) trustworthy and aligned with TAI frameworks, which does not directly relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10622",
      "abstract": "Purpose: We present an updated study evaluating the performance of large language models (LLMs) in answering radiation oncology physics questions, focusing on the recently released models.\n  Methods: A set of 100 multiple-choice radiation oncology physics questions, previously created by a well-experienced physicist, was used for this study. The answer options of the questions were randomly shuffled to create \"new\" exam sets. Five LLMs -- OpenAI o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude 3.5 Sonnet -- with the versions released before September 30, 2024, were queried using these new exam sets. To evaluate their deductive reasoning ability, the correct answer options in the questions were replaced with \"None of the above.\" Then, the explain-first and step-by-step instruction prompts were used to test if this strategy improved their reasoning ability. The performance of the LLMs was compared with the answers from medical physicists.\n  Results: All models demonstrated expert-level performance on these questions, with o1-preview even surpassing medical physicists with a majority vote. When replacing the correct answer options with 'None of the above', all models exhibited a considerable decline in performance, suggesting room for improvement. The explain-first and step-by-step instruction prompts helped enhance the reasoning ability of the LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude 3.5 Sonnet models.\n  Conclusion: These recently released LLMs demonstrated expert-level performance in answering radiation oncology physics questions, exhibiting great potential to assist in radiation oncology physics education and training.",
      "authors": [
        "Peilong Wang",
        "Jason Holmes",
        "Zhengliang Liu",
        "Dequan Chen",
        "Tianming Liu",
        "Jiajian Shen",
        "Wei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-14T00:05:42+00:00",
          "link": "https://arxiv.org/abs/2412.10622v1",
          "size": "701kb",
          "version": "v1"
        },
        {
          "date": "2025-01-03T02:12:37+00:00",
          "link": "https://arxiv.org/abs/2412.10622v2",
          "size": "509kb",
          "version": "v2"
        },
        {
          "date": "2025-01-21T17:20:31+00:00",
          "link": "https://arxiv.org/abs/2412.10622v3",
          "size": "531kb",
          "version": "v3"
        },
        {
          "date": "2025-07-18T23:41:43+00:00",
          "link": "https://arxiv.org/abs/2412.10622v4",
          "size": "512kb",
          "version": "v4"
        }
      ],
      "title": "A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10622",
        "HTML": "https://arxiv.org/html/2412.10622",
        "PDF": "https://arxiv.org/pdf/2412.10622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates LLMs on their performance with radiation oncology questions, involving data format changes. Although it deals with the use of LLMs and impacts performance evaluation, it does not contribute directly to data processing techniques or methodologies for LLMs."
      },
      "tasks": [
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.15310",
      "abstract": "Input-driven pushdown automata with translucent input letters are investigated. Here, the use of translucent input letters means that the input is processed in several sweeps and that, depending on the current state of the automaton, some input symbols are visible and can be processed, whereas some other symbols are invisible, and may be processed in another sweep. Additionally, the returning mode as well as the non-returning mode are considered, where in the former mode a new sweep must start after processing a visible input symbol. Input-driven pushdown automata differ from traditional pushdown automata by the fact that the actions on the pushdown store (push, pop, nothing) are dictated by the input symbols. We obtain the result that the input-driven nondeterministic model is computationally stronger than the deterministic model both in the returning mode and in the non-returning mode, whereas it is known that the deterministic and the nondeterministic model are equivalent for input-driven pushdown automata without translucency. It also turns out that the non-returning model is computationally stronger than the returning model both in the deterministic and nondeterministic case. Furthermore, we investigate the closure properties of the language families introduced under the Boolean operations. We obtain a complete picture in the deterministic case, whereas in the nondeterministic case the language families are shown to be not closed under complementation. Finally, we look at decidability questions and obtain the non-semidecidability of the questions of universality, inclusion, equivalence, and regularity in the nondeterministic case. ",
      "authors": [
        "Martin Kutrib",
        "Andreas Malcher",
        "Matthias Wendlandt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:13:49+00:00",
          "link": "https://arxiv.org/abs/2507.15310v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Input-Driven Pushdown Automata with Translucent Input Letters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15310",
        "PDF": "https://arxiv.org/pdf/2507.15310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the computational properties of input-driven pushdown automata with translucent input letters, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15545",
      "abstract": "The success of Machine Learning is increasingly tempered by its significant resource footprint, driving interest in efficient paradigms like TinyML. However, the inherent complexity of designing TinyML systems hampers their broad adoption. To reduce this complexity, we introduce \"Data Aware Differentiable Neural Architecture Search\". Unlike conventional Differentiable Neural Architecture Search, our approach expands the search space to include data configuration parameters alongside architectural choices. This enables Data Aware Differentiable Neural Architecture Search to co-optimize model architecture and input data characteristics, effectively balancing resource usage and system performance for TinyML applications. Initial results on keyword spotting demonstrate that this novel approach to TinyML system design can generate lean but highly accurate systems.",
      "authors": [
        "Yujia Shi",
        "Emil Njor",
        "Pablo Mart\\'inez-Nuevo",
        "Sven Ewan Shepstone",
        "Xenofon Fafoutis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:18:38+00:00",
          "link": "https://arxiv.org/abs/2507.15545v1",
          "size": "125kb",
          "version": "v1"
        }
      ],
      "title": "Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15545",
        "HTML": "https://arxiv.org/html/2507.15545",
        "PDF": "https://arxiv.org/pdf/2507.15545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel approach for differentiable neural architecture search targeting TinyML applications. It does not make contributions to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02192",
      "abstract": "Customized text-to-video generation with pre-trained large-scale models has recently garnered significant attention by focusing on identity and motion consistency. Existing works typically follow the isolated customized paradigm, where the subject identity or motion dynamics are customized exclusively. However, this paradigm completely ignores the intrinsic mutual constraints and synergistic interdependencies between identity and motion, resulting in identity-motion conflicts throughout the generation process that systematically degrade. To address this, we introduce DualReal, a novel framework that employs adaptive joint training to construct interdependencies between dimensions collaboratively. Specifically, DualReal is composed of two units: (1) Dual-aware Adaptation dynamically switches the training step (i.e., identity or motion), learns the current information guided by the frozen dimension prior, and employs a regularization strategy to avoid knowledge leakage; (2) StageBlender Controller leverages the denoising stages and Diffusion Transformer depths to guide different dimensions with adaptive granularity, avoiding conflicts at various stages and ultimately achieving lossless fusion of identity and motion patterns. We constructed a more comprehensive evaluation benchmark than existing methods. The experimental results show that DualReal improves CLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves top performance on nearly all motion metrics. Page: https://wenc-k.github.io/dualreal-customization",
      "authors": [
        "Wenchuan Wang",
        "Mengqi Huang",
        "Yijing Tu",
        "Zhendong Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T17:19:20+00:00",
          "link": "https://arxiv.org/abs/2505.02192v1",
          "size": "10114kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T07:07:13+00:00",
          "link": "https://arxiv.org/abs/2505.02192v2",
          "size": "16004kb",
          "version": "v2"
        }
      ],
      "title": "DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02192",
        "HTML": "https://arxiv.org/html/2505.02192",
        "PDF": "https://arxiv.org/pdf/2505.02192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces DualReal, a framework for video customization using pre-trained large-scale models, which involves adaptive joint training. While it partially relates to training techniques, it primarily focuses on video generation rather than LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Text-to-Video Generation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14638",
      "abstract": "For many decades, musicologists have engaged in creating large databases serving different purposes for musicological research and scholarship. With the rise of fields like music information retrieval and digital musicology, there is now a constant and growing influx of musicologically relevant datasets and corpora. In historical or observational settings, however, these datasets are necessarily incomplete, and the true extent of a collection of interest remains unknown -- silent. Here, we apply, for the first time, so-called Unseen Species models (USMs) from ecology to areas of musicological activity. After introducing the models formally, we show in four case studies how USMs can be applied to musicological data to address quantitative questions like: How many composers are we missing in RISM? What percentage of medieval sources of Gregorian chant have we already cataloged? How many differences in music prints do we expect to find between editions? How large is the coverage of songs from genres of a folk music tradition? And, finally, how close are we in estimating the size of the harmonic vocabulary of a large number of composers?",
      "authors": [
        "Fabian C. Moss",
        "Jan Haji\\v{c} jr.",
        "Adrian Nachtwey",
        "and Laurent Pugin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:34:47+00:00",
          "link": "https://arxiv.org/abs/2507.14638v1",
          "size": "504kb",
          "version": "v1"
        }
      ],
      "title": "The Rest is Silence: Leveraging Unseen Species Models for Computational Musicology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14638",
        "HTML": "https://arxiv.org/html/2507.14638",
        "PDF": "https://arxiv.org/pdf/2507.14638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying Unseen Species models to musicology data, which does not pertain to LLM training data processing. It explores data management in musicological contexts rather than contributing to LLM data collection, generation, or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14662",
      "abstract": "Quantifying post-consumer food waste in institutional dining settings is essential for supporting data-driven sustainability strategies. This study presents a cost-effective computer vision framework that estimates plate-level food waste by utilizing semantic segmentation of RGB images taken before and after meal consumption across five Iranian dishes. Four fully supervised models (U-Net, U-Net++, and their lightweight variants) were trained using a capped dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a custom-defined Distributional Pixel Agreement (DPA) metric tailored to the task. All models achieved satisfying performance, and for each food type, at least one model approached or surpassed 90% DPA, demonstrating strong alignment in pixel-wise proportion estimates. Lighter models with reduced parameter counts offered faster inference, achieving real-time throughput on an NVIDIA T4 GPU. Further analysis showed superior segmentation performance for dry and more rigid components (e.g., rice and fries), while more complex, fragmented, or viscous dishes, such as stews, showed reduced performance, specifically post-consumption. Despite limitations such as reliance on 2D imaging, constrained food variety, and manual data collection, the proposed framework is pioneering and represents a scalable, contactless solution for continuous monitoring of food consumption. This research lays foundational groundwork for automated, real-time waste tracking systems in large-scale food service environments and offers actionable insights and outlines feasible future directions for dining hall management and policymakers aiming to reduce institutional food waste.",
      "authors": [
        "Shayan Rokhva",
        "Babak Teimourpour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:21:29+00:00",
          "link": "https://arxiv.org/abs/2507.14662v1",
          "size": "2412kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14662",
        "PDF": "https://arxiv.org/pdf/2507.14662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on food waste estimation using computer vision and semantic segmentation, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15601",
      "abstract": "Federated learning (FL) has emerged as a popular approach for collaborative machine learning in sixth-generation (6G) networks, primarily due to its privacy-preserving capabilities. The deployment of FL algorithms is expected to empower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous driving, augmented reality, and healthcare. The mission-critical and time-sensitive nature of these applications necessitates the design of low-latency FL frameworks that guarantee high learning performance. In practice, achieving low-latency FL faces two challenges: the overhead of computing and transmitting high-dimensional model updates, and the heterogeneity in communication-and-computation (C$^2$) capabilities across devices. To address these challenges, we propose a novel C$^2$-aware framework for optimal batch-size control that minimizes end-to-end (E2E) learning latency while ensuring convergence. The framework is designed to balance a fundamental C$^2$ tradeoff as revealed through convergence analysis. Specifically, increasing batch sizes improves the accuracy of gradient estimation in FL and thus reduces the number of communication rounds required for convergence, but results in higher per-round latency, and vice versa. The associated problem of latency minimization is intractable; however, we solve it by designing an accurate and tractable surrogate for convergence speed, with parameters fitted to real data. This approach yields two batch-size control strategies tailored to scenarios with slow and fast fading, while also accommodating device heterogeneity. Extensive experiments using real datasets demonstrate that the proposed strategies outperform conventional batch-size adaptation schemes that do not consider the C$^2$ tradeoff or device heterogeneity.",
      "authors": [
        "Huiling Yang",
        "Zhanwei Wang",
        "and Kaibin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:24:38+00:00",
          "link": "https://arxiv.org/abs/2507.15601v1",
          "size": "1228kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15601",
        "HTML": "https://arxiv.org/html/2507.15601",
        "PDF": "https://arxiv.org/pdf/2507.15601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on federated learning with batch-size control to minimize latency in heterogeneous devices, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15662",
      "abstract": "We consider the sensor network localization problem, also known as multidimensional scaling or Euclidean distance matrix completion. Given a ground truth configuration of $n$ points in $\\mathbb{R}^\\ell$, we observe a subset of the pairwise distances and aim to recover the underlying configuration (up to rigid transformations). We show with a simple counterexample that the associated optimization problem is nonconvex and may admit spurious local minimizers, even when all distances are known. Yet, inspired by numerical experiments, we argue that all second-order critical points become global minimizers when the problem is relaxed by optimizing over configurations in dimension $k > \\ell$. Specifically, we show this for two settings, both when all pairwise distances are known: (1) for arbitrary ground truth points, and $k= O(\\sqrt{\\ell n})$, and: (2) for isotropic random ground truth points, and $k = O(\\ell + \\log n)$. To prove these results, we identify and exploit key properties of the linear map which sends inner products to squared distances.",
      "authors": [
        "Christopher Criscitiello",
        "Andrew D. McRae",
        "Quentin Rebjock",
        "Nicolas Boumal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:23:05+00:00",
          "link": "https://arxiv.org/abs/2507.15662v1",
          "size": "1861kb",
          "version": "v1"
        }
      ],
      "title": "Sensor network localization has a benign landscape after low-dimensional relaxation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15662",
        "HTML": "https://arxiv.org/html/2507.15662",
        "PDF": "https://arxiv.org/pdf/2507.15662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on sensor network localization and optimization problems, without discussing any LLM training data processing activities or dataset improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14215",
      "abstract": "This study aims to develop a deep learning system for an accessibility device for the deaf or hearing impaired. The device will accurately localize and identify sound sources in real time. This study will fill an important gap in current research by leveraging machine learning techniques to target the underprivileged community. The system includes three main components. 1. JerryNet: A custom designed CNN architecture that determines the direction of arrival (DoA) for nine possible directions. 2. Audio Classification: This model is based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model to identify the exact sound classes only based on audio. 3. Multimodal integration model: This is an accurate sound localization model that combines audio, visual, and text data to locate the exact sound sources in the images. The part consists of two modules, one object detection using Yolov9 to generate all the bounding boxes of the objects, and an audio visual localization model to identify the optimal bounding box using complete Intersection over Union (CIoU). The hardware consists of a four-microphone rectangular formation and a camera mounted on glasses with a wristband for displaying necessary information like direction. On a custom collected data set, JerryNet achieved a precision of 91. 1% for the sound direction, outperforming all the baseline models. The CLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets, respectively. The audio-visual localization model within component 3 yielded a cIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are many future potentials to this study, paving the way to creating a new generation of accessibility devices.",
      "authors": [
        "Jiayu (Jerry) Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:03:33+00:00",
          "link": "https://arxiv.org/abs/2507.14215v1",
          "size": "9219kb",
          "version": "v1"
        }
      ],
      "title": "Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14215",
        "HTML": "https://arxiv.org/html/2507.14215",
        "PDF": "https://arxiv.org/pdf/2507.14215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study concentrates on developing an accessibility device for the deaf using models like JerryNet and CLAP for sound classification and integration, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14623",
      "abstract": "This study examines cross-cultural interactions between Chinese users and self-identified \"TikTok Refugees\"(foreign users who migrated to RedNote after TikTok's U.S. ban). Based on a dataset of 1,862 posts and 403,054 comments, we use large language model-based sentiment classification and BERT-based topic modelling to explore how both groups engage with the TikTok refugee phenomenon. We analyse what themes foreign users express, how Chinese users respond, how stances (Pro-China, Neutral, Pro-Foreign) shape emotional expression, and how affective responses differ across topics and identities. Results show strong affective asymmetry: Chinese users respond with varying emotional intensities across topics and stances: pride and praise dominate cultural threads, while political discussions elicit high levels of contempt and anger, especially from Pro-China commenters. Pro-Foreign users exhibit the strongest negative emotions across all topics, whereas neutral users express curiosity and joy but still reinforce mainstream discursive norms. Cross-topic comparisons reveal that appearance-related content produces the most emotionally balanced interactions, while politics generates the highest polarization. Our findings reveal distinct emotion-stance structures in Sino-foreign online interactions and offer empirical insights into identity negotiation in transnational digital publics.",
      "authors": [
        "Mingchen Li",
        "Wenbo Xu",
        "Wenqing Gu",
        "Yixuan Xie",
        "Yao Zhou",
        "Yunsong Dai",
        "Cheng Tan",
        "Pan Hui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:38:33+00:00",
          "link": "https://arxiv.org/abs/2507.14623v1",
          "size": "2709kb",
          "version": "v1"
        }
      ],
      "title": "Rejection or Inclusion in the Emotion-Identity Dynamics of TikTok Refugees on RedNote",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14623",
        "HTML": "https://arxiv.org/html/2507.14623",
        "PDF": "https://arxiv.org/pdf/2507.14623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines cross-cultural interactions and emotions on social media platforms. It does not relate to data processing for LLM training, as it focuses on sentiment analysis and topic modeling rather than LLM dataset creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15087",
      "abstract": "Currently, many studies view DNA sequences as a special type of language and utilize Transformers to model them. These studies use fixed-length k-mer segmentation and BPE subword tokenization but lack a systematic evaluation to determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a 4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal, AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and 24-layer Transformer encoders and evaluated on GUE benchmark dataset. In general, BPE delivers higher and more stable performance across tasks by compressing frequent motifs into variable-length tokens, reducing sequence length, and improving model generalization. RoPE excels at capturing periodic motifs and extrapolating to long sequences, while AliBi also performs well on tasks driven by local dependencies. In terms of depth, we observe significant gains when increasing layers from 3 to 12, with only marginal improvements or slight overfitting at 24 layers. This study provides practical guidance for designing tokenization and positional encoding in DNA Transformer models.",
      "authors": [
        "Chenlei Gong",
        "Yuanhe Tian",
        "Lei Mao",
        "Yan Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.15087v1",
          "size": "1570kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15087",
        "HTML": "https://arxiv.org/html/2507.15087",
        "PDF": "https://arxiv.org/pdf/2507.15087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves the evaluation of coding schemes for Transformer-based gene sequence modeling. It does not address training data processing for LLMs related to pretraining or fine-tuning for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15846",
      "abstract": "Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism that calibrates reward distributions based on element dimensions. This framework transforms GUI grounding from sparse binary classification to dense continuous optimization, where Gaussian distributions generate rich gradient signals that guide models toward optimal interaction positions. Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro benchmarks demonstrate that GUI-G$^2$, substantially outperforms state-of-the-art method UI-TARS-72B, with the most significant improvement of 24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides superior robustness to interface variations and enhanced generalization to unseen layouts, establishing a new paradigm for spatial reasoning in GUI interaction tasks.",
      "authors": [
        "Fei Tang",
        "Zhangxuan Gu",
        "Zhengxi Lu",
        "Xuyang Liu",
        "Shuheng Shen",
        "Changhua Meng",
        "Wen Wang",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:53:42+00:00",
          "link": "https://arxiv.org/abs/2507.15846v1",
          "size": "2762kb",
          "version": "v1"
        }
      ],
      "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15846",
        "HTML": "https://arxiv.org/html/2507.15846",
        "PDF": "https://arxiv.org/pdf/2507.15846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces GUI Gaussian Grounding Rewards for GUI interaction tasks, focusing on reward modeling for GUI element localization. It does not involve LLM training data processing or relate to data engineering techniques relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.01138",
      "abstract": "Joint source-channel coding (JSCC) offers a promising avenue for enhancing transmission efficiency by jointly incorporating source and channel statistics into the system design. A key advancement in this area is the deep joint source and channel coding (DeepJSCC) technique that designs a direct mapping of input signals to channel symbols parameterized by a neural network, which can be trained for arbitrary channel models and semantic quality metrics. This paper advances the DeepJSCC framework toward a semantics-aligned, high-fidelity transmission approach, called semantics-guided diffusion DeepJSCC (SGD-JSCC). Existing schemes that integrate diffusion models (DMs) with JSCC face challenges in transforming random generation into accurate reconstruction and adapting to varying channel conditions. SGD-JSCC incorporates two key innovations: (1) utilizing some inherent information that contributes to the semantics of an image, such as text description or edge map, to guide the diffusion denoising process; and (2) enabling seamless adaptability to varying channel conditions with the help of a semantics-guided DM for channel denoising. The DM is guided by diverse semantic information and integrates seamlessly with DeepJSCC. In a slow fading channel, SGD-JSCC dynamically adapts to the instantaneous signal-to-noise ratio (SNR) directly estimated from the channel output, thereby eliminating the need for additional pilot transmissions for channel estimation. In a fast fading channel, we introduce a training-free denoising strategy, allowing SGD-JSCC to effectively adjust to fluctuations in channel gains. Numerical results demonstrate that, guided by semantic information and leveraging the powerful DM, our method outperforms existing DeepJSCC schemes, delivering satisfactory reconstruction performance even at extremely poor channel conditions.",
      "authors": [
        "Maojun Zhang",
        "Haotian Wu",
        "Guangxu Zhu",
        "Richeng Jin",
        "Xiaoming Chen",
        "Deniz G\\\"und\\\"uz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T08:42:55+00:00",
          "link": "https://arxiv.org/abs/2501.01138v1",
          "size": "3987kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:29:21+00:00",
          "link": "https://arxiv.org/abs/2501.01138v2",
          "size": "7382kb",
          "version": "v2"
        }
      ],
      "title": "Semantics-Guided Diffusion for Deep Joint Source-Channel Coding in Wireless Image Transmission",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01138",
        "HTML": "https://arxiv.org/html/2501.01138",
        "PDF": "https://arxiv.org/pdf/2501.01138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving wireless image transmission using Joint Source-Channel Coding techniques, and does not relate to training data processing for large language models."
      },
      "repo_urls": [
        "https://github.com/maurozmj/sgdjscc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14533",
      "abstract": "The rapid advancement of educational applications, artistic creation, and AI-generated content (AIGC) technologies has substantially increased practical requirements for comprehensive Image Aesthetics Assessment (IAA), particularly demanding methods capable of delivering both quantitative scoring and professional understanding. Multimodal Large Language Model (MLLM)-based IAA methods demonstrate stronger perceptual and generalization capabilities compared to traditional approaches, yet they suffer from modality bias (score-only or text-only) and lack fine-grained attribute decomposition, thereby failing to support further aesthetic assessment. In this paper, we present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main categories and 15 subcategories, each annotated by professional experts with 8-dimensional attributes analysis and a holistic score. Both the model and dataset will be made public to advance the field.",
      "authors": [
        "Shuo Cao",
        "Nan Ma",
        "Jiayang Li",
        "Xiaohui Li",
        "Lihao Shao",
        "Kaiwen Zhu",
        "Yu Zhou",
        "Yuandong Pu",
        "Jiarui Wu",
        "Jiaquan Wang",
        "Bo Qu",
        "Wenhai Wang",
        "Yu Qiao",
        "Dajuin Yao",
        "Yihao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:27:21+00:00",
          "link": "https://arxiv.org/abs/2507.14533v1",
          "size": "15697kb",
          "version": "v1"
        }
      ],
      "title": "ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14533",
        "PDF": "https://arxiv.org/pdf/2507.14533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ArtiMuse, an MLLM-based model for image aesthetics assessment and an expert-curated dataset. While it involves data related to model training, its primary focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14928",
      "abstract": "Collaboration among multiple large language model (LLM) agents is a promising approach to overcome inherent limitations of single-agent systems, such as hallucinations and single points of failure. As LLM agents are increasingly deployed on open blockchain platforms, multi-agent systems capable of tolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven coordination, which suffers from two major drawbacks. First, they are inherently vulnerable to targeted attacks against the leader. If consecutive leaders behave maliciously, the system repeatedly fails to achieve consensus, forcing new consensus rounds, which is particularly costly given the high latency of LLM invocations. Second, an underperforming proposal from the leader can be accepted as the final answer even when higher-quality alternatives are available, as existing methods finalize the leader's proposal once it receives a quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized consensus approach for multi-agent LLM systems, where worker agents generate answers concurrently and evaluator agents independently score and rank these answers to select the best available one. This decentralized architecture enables faster consensus despite the presence of Byzantine agents and consistently selects higher-quality answers through Byzantine-robust aggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates Byzantine agents and significantly improves the quality of selected answers.",
      "authors": [
        "Yongrae Jo",
        "Chanik Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:55:26+00:00",
          "link": "https://arxiv.org/abs/2507.14928v1",
          "size": "12927kb",
          "version": "v1"
        }
      ],
      "title": "Byzantine-Robust Decentralized Coordination of LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14928",
        "HTML": "https://arxiv.org/html/2507.14928",
        "PDF": "https://arxiv.org/pdf/2507.14928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Byzantine-robust coordination for multi-agent systems with LLM agents on blockchain platforms, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15059",
      "abstract": "The field of pan-sharpening has recently seen a trend towards increasingly large and complex models, often trained on single, specific satellite datasets. This approach, however, leads to high computational overhead and poor generalization on full resolution data, a paradigm we challenge in this paper. In response to this issue, we propose PanTiny, a lightweight, single-step pan-sharpening framework designed for both efficiency and robust performance. More critically, we introduce multiple-in-one training paradigm, where a single, compact model is trained simultaneously on three distinct satellite datasets (WV2, WV3, and GF2) with different resolution and spectral information. Our experiments show that this unified training strategy not only simplifies deployment but also significantly boosts generalization on full-resolution data. Further, we introduce a universally powerful composite loss function that elevates the performance of almost all of models for pan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny model, benefiting from these innovations, achieves a superior performance-to-efficiency balance, outperforming most larger, specialized models. Through extensive ablation studies, we validate that principled engineering in model design, training paradigms, and loss functions can surpass brute-force scaling. Our work advocates for a community-wide shift towards creating efficient, generalizable, and data-conscious models for pan-sharpening. The code is available at https://github.com/Zirconium233/PanTiny .",
      "authors": [
        "Ran Zhang",
        "Xuanhua He",
        "Li Xueheng",
        "Ke Cao",
        "Liu Liu",
        "Wenbo Xu",
        "Fang Jiabin",
        "Yang Qize",
        "and Jie Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:50:49+00:00",
          "link": "https://arxiv.org/abs/2507.15059v1",
          "size": "1535kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15059",
        "HTML": "https://arxiv.org/html/2507.15059",
        "PDF": "https://arxiv.org/pdf/2507.15059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pan-sharpening for satellite imagery and improving computational efficiency, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15109",
      "abstract": "One of the main challenges in the Simultaneous Localization and Mapping (SLAM) loop closure problem is the recognition of previously visited places. In this work, we tackle the two main problems of real-time SLAM systems: 1) loop closure detection accuracy and 2) real-time computation constraints on the embedded hardware. Our LoopNet method is based on a multitasking variant of the classical ResNet architecture, adapted for online retraining on a dynamic visual dataset and optimized for embedded devices. The online retraining is designed using a few-shot learning approach. The architecture provides both an index into the queried visual dataset, and a measurement of the prediction quality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors, LoopNet surpasses the limitations of handcrafted features and traditional deep learning methods, offering better performance under varying conditions. Code is available at https://github.com/RovisLab/LoopNet. Additinally, we introduce a new loop closure benchmarking dataset, coined LoopDB, which is available at https://github.com/RovisLab/LoopDB.",
      "authors": [
        "Mohammad-Maher Nakshbandi",
        "Ziad Sharawy",
        "Sorin Grigorescu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:11:37+00:00",
          "link": "https://arxiv.org/abs/2507.15109v1",
          "size": "3256kb",
          "version": "v1"
        }
      ],
      "title": "LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15109",
        "HTML": "https://arxiv.org/html/2507.15109",
        "PDF": "https://arxiv.org/pdf/2507.15109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LoopNet, a few-shot learning approach for SLAM loop closure. While it mentions a new dataset, its main focus isn't on LLM training data processing or substantial contributions to LLM dataset quality improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.06945",
      "abstract": "We propose to approximate a (possibly discontinuous) multivariate function f (x) on a compact set by the partial minimizer arg miny p(x, y) of an appropriate polynomial p whose construction can be cast in a univariate sum of squares (SOS) framework, resulting in a highly structured convex semidefinite program. In a number of non-trivial cases (e.g. when f is a piecewise polynomial) we prove that the approximation is exact with a low-degree polynomial p. Our approach has three distinguishing features: (i) It is mesh-free and does not require the knowledge of the discontinuity locations. (ii) It is model-free in the sense that we only assume that the function to be approximated is available through samples (point evaluations). (iii) The size of the semidefinite program is independent of the ambient dimension and depends linearly on the number of samples. We also analyze the sample complexity of the approach, proving a generalization error bound in a probabilistic setting. This allows for a comparison with machine learning approaches.",
      "authors": [
        "Didier Henrion (LAAS-POP)",
        "Milan Korda (LAAS-POP)",
        "Jean-Bernard Lasserre (LAAS-POP)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-14T10:02:41+00:00",
          "link": "https://arxiv.org/abs/2302.06945v1",
          "size": "5383kb",
          "version": "v1"
        },
        {
          "date": "2023-11-02T09:04:43+00:00",
          "link": "https://arxiv.org/abs/2302.06945v2",
          "size": "5133kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T09:14:08+00:00",
          "link": "https://arxiv.org/abs/2302.06945v3",
          "size": "5381kb",
          "version": "v3"
        }
      ],
      "title": "Polynomial argmin for recovery and approximation of multivariate discontinuous functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.06945",
        "PDF": "https://arxiv.org/pdf/2302.06945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for function approximation using polynomial argmin, which does not connect to LLM training data processing tasks such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.06656",
      "abstract": "Sortformer is an encoder-based speaker diarization model designed for supervising speaker tagging in speech-to-text models. Instead of relying solely on permutation invariant loss (PIL), Sortformer introduces Sort Loss to resolve the permutation problem, either independently or in tandem with PIL. In addition, we propose a streamlined multi-speaker speech-to-text architecture that leverages Sortformer for speaker supervision, embedding speaker labels into the encoder using sinusoidal kernel functions. This design addresses the speaker permutation problem through sorted objectives, effectively bridging timestamps and tokens to supervise speaker labels in the output transcriptions. Experiments demonstrate that Sort Loss can boost speaker diarization performance, and incorporating the speaker supervision from Sortformer improves multi-speaker transcription accuracy. We anticipate that the proposed Sortformer and multi-speaker architecture will enable the seamless integration of speaker tagging capabilities into foundational speech-to-text systems and multimodal large language models (LLMs), offering an easily adoptable and user-friendly mechanism to enhance their versatility and performance in speaker-aware tasks. The code and trained models are made publicly available through the NVIDIA NeMo Framework.",
      "authors": [
        "Taejin Park",
        "Ivan Medennikov",
        "Kunal Dhawan",
        "Weiqing Wang",
        "He Huang",
        "Nithin Rao Koluguri",
        "Krishna C. Puvvada",
        "Jagadeesh Balam",
        "Boris Ginsburg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T17:20:11+00:00",
          "link": "https://arxiv.org/abs/2409.06656v1",
          "size": "2560kb",
          "version": "v1"
        },
        {
          "date": "2024-12-10T04:23:11+00:00",
          "link": "https://arxiv.org/abs/2409.06656v2",
          "size": "2587kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T18:18:34+00:00",
          "link": "https://arxiv.org/abs/2409.06656v3",
          "size": "1716kb",
          "version": "v3"
        }
      ],
      "title": "Sortformer: A Novel Approach for Permutation-Resolved Speaker Supervision in Speech-to-Text Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06656",
        "HTML": "https://arxiv.org/html/2409.06656",
        "PDF": "https://arxiv.org/pdf/2409.06656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces Sortformer for speaker tagging in speech-to-text systems. It focuses on mechanisms for diarization and transcription accuracy, not on training data processing for LLMs."
      },
      "models": [
        {
          "model_path": "nvidia/diar_sortformer_4spk-v1",
          "downloads": "34211",
          "likes": "67",
          "trending_score": "1.0",
          "link": "https://huggingface.co/nvidia/diar_sortformer_4spk-v1"
        },
        {
          "model_path": "nvidia/ssl_en_nest_large_v1.0",
          "downloads": "174",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/ssl_en_nest_large_v1.0"
        },
        {
          "model_path": "nvidia/ssl_en_nest_xlarge_v1.0",
          "downloads": "139",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/ssl_en_nest_xlarge_v1.0"
        }
      ],
      "tasks": [
        "speaker-diarization",
        "Speaker Diarization"
      ],
      "repo_urls": [
        "https://github.com/NVIDIA/NeMo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01816",
      "abstract": "The tradeoff between reconstruction quality and compute required for video super-resolution (VSR) remains a formidable challenge in its adoption for deployment on resource-constrained edge devices. While transformer-based VSR models have set new benchmarks for reconstruction quality in recent years, these require substantial computational resources. On the other hand, lightweight models that have been introduced even recently struggle to deliver state-of-the-art reconstruction. We propose a novel lightweight and parameter-efficient neural architecture for VSR that achieves state-of-the-art reconstruction accuracy with just 2.3 million parameters. Our model enhances information utilization based on several architectural attributes. Firstly, it uses 2D wavelet decompositions strategically interlayered with learnable convolutional layers to utilize the inductive prior of spatial sparsity of edges in visual data. Secondly, it uses a single memory tensor to capture inter-frame temporal information while avoiding the computational cost of previous memory-based schemes. Thirdly, it uses residual deformable convolutions for implicit inter-frame object alignment that improve upon deformable convolutions by enhancing spatial information in inter-frame feature differences. Architectural insights from our model can pave the way for real-time VSR on the edge, such as display devices for streaming data.",
      "authors": [
        "Kavitha Viswanathan",
        "Shashwat Pathak",
        "Piyush Bharambe",
        "Harsh Choudhary",
        "Amit Sethi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T20:46:15+00:00",
          "link": "https://arxiv.org/abs/2502.01816v1",
          "size": "2855kb",
          "version": "v1"
        },
        {
          "date": "2025-03-16T20:16:00+00:00",
          "link": "https://arxiv.org/abs/2502.01816v2",
          "size": "12277kb",
          "version": "v2"
        },
        {
          "date": "2025-06-19T22:49:16+00:00",
          "link": "https://arxiv.org/abs/2502.01816v3",
          "size": "6923kb",
          "version": "v3"
        }
      ],
      "title": "Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01816",
        "HTML": "https://arxiv.org/html/2502.01816",
        "PDF": "https://arxiv.org/pdf/2502.01816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for video super-resolution employing architectural advancements, but it does not deal with LLM training data processing or any related dataset operations."
      },
      "tasks": [
        "SSIM",
        "Super-Resolution",
        "Video Super-Resolution"
      ],
      "repo_urls": [
        "https://github.com/kavi1388/RCDM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10871",
      "abstract": "This study explores how large language models (LLMs) encode interwoven scientific knowledge, using chemical elements and LLaMA-series models as a case study. We identify a 3D spiral structure in the hidden states that aligns with the conceptual structure of the periodic table, suggesting that LLMs can reflect the geometric organization of scientific concepts learned from text. Linear probing reveals that middle layers encode continuous, overlapping attributes that enable indirect recall, while deeper layers sharpen categorical distinctions and incorporate linguistic context. These findings suggest that LLMs represent symbolic knowledge not as isolated facts, but as structured geometric manifolds that intertwine semantic information across layers. We hope this work inspires further exploration of how LLMs represent and reason about scientific knowledge, particularly in domains such as materials science.",
      "authors": [
        "Ge Lei",
        "Samuel J. Cooper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-15T18:08:51+00:00",
          "link": "https://arxiv.org/abs/2502.10871v1",
          "size": "10464kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T21:24:29+00:00",
          "link": "https://arxiv.org/abs/2502.10871v2",
          "size": "13987kb",
          "version": "v2"
        }
      ],
      "title": "Layerwise Recall and the Geometry of Interwoven Knowledge in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10871",
        "HTML": "https://arxiv.org/html/2502.10871",
        "PDF": "https://arxiv.org/pdf/2502.10871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes how LLMs encode scientific knowledge and conceptual structures but does not address any data processing aspect for LLM training."
      },
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/tldr-group/LLM-knowledge-representation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03601",
      "abstract": "Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In the first phase, our agentic pipeline produces detailed task blueprints with ground-truth actions, leveraging a committee of LLM reviewers and iterative feedback loops. These blueprints are then transformed into complete interaction trajectories through simulated human-agent interplay. We train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B to 70B parameters. Our models outperform frontier models such as GPT-4o and Claude 3.5 on $\\tau$-bench and BFCL benchmarks, with the smaller models surpassing their larger counterparts, particularly in multi-turn settings, while maintaining superior consistency across multiple trials. Comprehensive experiments demonstrate that our verified blueprint-to-details approach yields high-quality training data, enabling the development of more reliable, efficient, and capable agents. We open-source 5K synthetic data trajectories and the trained xLAM-2-fc-r models to advance research in AI agents.\n  Models at https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4; Dataset at https://huggingface.co/datasets/Salesforce/APIGen-MT-5k and Website at https://apigen-mt.github.io",
      "authors": [
        "Akshara Prabhakar",
        "Zuxin Liu",
        "Ming Zhu",
        "Jianguo Zhang",
        "Tulika Awalgaonkar",
        "Shiyu Wang",
        "Zhiwei Liu",
        "Haolin Chen",
        "Thai Hoang",
        "Juan Carlos Niebles",
        "Shelby Heinecke",
        "Weiran Yao",
        "Huan Wang",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T17:13:57+00:00",
          "link": "https://arxiv.org/abs/2504.03601v1",
          "size": "2782kb",
          "version": "v1"
        },
        {
          "date": "2025-04-08T17:46:44+00:00",
          "link": "https://arxiv.org/abs/2504.03601v2",
          "size": "2782kb",
          "version": "v2"
        },
        {
          "date": "2025-05-05T11:54:13+00:00",
          "link": "https://arxiv.org/abs/2504.03601v3",
          "size": "2795kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T17:39:17+00:00",
          "link": "https://arxiv.org/abs/2504.03601v4",
          "size": "2795kb",
          "version": "v4"
        }
      ],
      "title": "APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03601",
        "HTML": "https://arxiv.org/html/2504.03601",
        "PDF": "https://arxiv.org/pdf/2504.03601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents APIGen-MT, a framework for generating synthetic multi-turn interaction data for training AI agents. It discusses the generation of high-quality training data, which directly contributes to LLM training data processing."
      },
      "models": [
        {
          "model_path": "Salesforce/Llama-xLAM-2-8b-fc-r",
          "downloads": "19648",
          "likes": "33",
          "trending_score": "3.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r"
        },
        {
          "model_path": "Salesforce/Llama-xLAM-2-70b-fc-r",
          "downloads": "6659",
          "likes": "36",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-70b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-3b-fc-r",
          "downloads": "2795",
          "likes": "11",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-3b-fc-r"
        },
        {
          "model_path": "Salesforce/Llama-xLAM-2-8b-fc-r-gguf",
          "downloads": "1339",
          "likes": "8",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r-gguf"
        },
        {
          "model_path": "Salesforce/xLAM-2-32b-fc-r",
          "downloads": "3661",
          "likes": "22",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-32b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-1b-fc-r",
          "downloads": "1943",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-1b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-3b-fc-r-gguf",
          "downloads": "303",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-3b-fc-r-gguf"
        },
        {
          "model_path": "Salesforce/xLAM-2-1b-fc-r-gguf",
          "downloads": "310",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-1b-fc-r-gguf"
        },
        {
          "model_path": "amd/Llama-xLAM-2-8b-fc-r-awq-g128-int4-asym-bfp16-onnx-hybrid",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/amd/Llama-xLAM-2-8b-fc-r-awq-g128-int4-asym-bfp16-onnx-hybrid"
        },
        {
          "model_path": "kmhalvin/xLAM-2-1b-fc-r-SpinQuant-ET",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/kmhalvin/xLAM-2-1b-fc-r-SpinQuant-ET"
        },
        {
          "model_path": "licongwei/xLAM-2-3b-fc-r-SpinQuant-ET",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/licongwei/xLAM-2-3b-fc-r-SpinQuant-ET"
        },
        {
          "model_path": "Mungert/xLAM-2-32b-fc-r-GGUF",
          "downloads": "3915",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/xLAM-2-32b-fc-r-GGUF"
        },
        {
          "model_path": "Mungert/xLAM-2-3b-fc-r-GGUF",
          "downloads": "765",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/xLAM-2-3b-fc-r-GGUF"
        },
        {
          "model_path": "Mungert/Llama-xLAM-2-8b-fc-r-GGUF",
          "downloads": "586",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/Llama-xLAM-2-8b-fc-r-GGUF"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Salesforce/APIGen-MT-5k",
          "downloads": "1418",
          "likes": "57",
          "link": "https://huggingface.co/datasets/Salesforce/APIGen-MT-5k"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/SalesforceAIResearch/xLAM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01990",
      "abstract": "In a distinguishing problem, the input is a sample drawn from one of two distributions and the algorithm is tasked with identifying the source distribution. The performance of a distinguishing algorithm is measured by its advantage, i.e., its incremental probability of success over a random guess. A classic example of a distinguishing problem is the Planted Clique problem, where the input is a graph sampled from either $G(n,1/2)$ -- the standard Erd\\H{o}s-R\\'{e}nyi model, or $G(n,1/2,k)$ -- the Erd\\H{o}s-R\\'{e}nyi model with a clique planted on a random subset of $k$ vertices. The Planted Clique Hypothesis asserts that efficient algorithms cannot achieve advantage better than some absolute constant, say $1/4$, whenever $k=n^{1/2-\\Omega(1)}$. In this work, we aim to precisely understand the optimal distinguishing advantage achievable by efficient algorithms on Planted Clique. We show the following results under the Planted Clique hypothesis:\n  1. Optimality of low-degree polynomials: No efficient algorithm can beat the advantage the optimal low-degree polynomial. Concretely, this means that the advantage of any efficient algorithm is at most $(1+o(1))\\cdot k^2/(\\sqrt{\\pi}n)$, which is optimal in light of a simple edge-counting algorithm achieving this bound.\n  2. Harder planted distributions: There is an efficiently sampleable distribution $\\mathcal{P}^*$ supported on graphs containing $k$-cliques such that no efficient algorithm can distinguish $\\mathcal{P}^*$ from $G(n,1/2)$ with advantage $n^{-d}$ for an arbitrarily large constant $d$. In other words, there exist alternate planted distributions that are much harder than $G(n,1/2,k)$. Along the way, we prove a constructive hard-core lemma for a broad class of distributions with respect to low-degree polynomials. This result is applicable much more widely beyond Planted Clique and might be of independent interest.",
      "authors": [
        "Ansh Nagda",
        "Prasad Raghavendra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T05:36:07+00:00",
          "link": "https://arxiv.org/abs/2505.01990v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T00:31:14+00:00",
          "link": "https://arxiv.org/abs/2505.01990v2",
          "size": "60kb",
          "version": "v2"
        }
      ],
      "title": "On optimal distinguishers for Planted Clique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01990",
        "HTML": "https://arxiv.org/html/2505.01990",
        "PDF": "https://arxiv.org/pdf/2505.01990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Planted Clique problem, discussing optimal distinguishers and algorithms but does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.04843",
      "abstract": "Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.",
      "authors": [
        "Sebasti\\'an R. Castro",
        "Roberto Campbell",
        "Nancy Lau",
        "Octavio Villalobos",
        "Jiaqi Duan",
        "Alvaro A. Cardenas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T22:42:37+00:00",
          "link": "https://arxiv.org/abs/2505.04843v1",
          "size": "595kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T14:35:05+00:00",
          "link": "https://arxiv.org/abs/2505.04843v2",
          "size": "595kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Models are Autonomous Cyber Defenders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04843",
        "HTML": "https://arxiv.org/html/2505.04843",
        "PDF": "https://arxiv.org/pdf/2505.04843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on using LLMs in autonomous cyber defense for incident response, not on LLM training data processing or relevant data engineering techniques."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/r4wd3r/llms-are-acd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16122",
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in complex reasoning tasks, but their inference remains computationally inefficient. We observe a common failure mode in many prevalent LLMs, overthinking, where models generate verbose and tangential reasoning traces even for simple queries. Recent works have tried to mitigate this by enforcing fixed token budgets, however, this can lead to underthinking, especially on harder problems. Through empirical analysis, we identify that this inefficiency often stems from unclear problem-solving strategies. To formalize this, we develop a theoretical model, BBAM (Bayesian Budget Allocation Model), which models reasoning as a sequence of sub-questions with varying uncertainty, and introduce the $E^3$ metric to capture the trade-off between correctness and computation efficiency. Building on theoretical results from BBAM, we propose Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex queries into sub-questions and allocates token budgets based on estimated complexity using adaptive scheduling. Plan-and-Budget improves reasoning efficiency across a range of tasks and models, achieving up to +70% accuracy gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close performance gaps without retraining. Our code is available at https://github.com/junhongmit/P-and-B.",
      "authors": [
        "Junhong Lin",
        "Xinyue Zeng",
        "Jie Zhu",
        "Song Wang",
        "Julian Shun",
        "Jun Wu",
        "Dawei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T01:56:29+00:00",
          "link": "https://arxiv.org/abs/2505.16122v1",
          "size": "2406kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T04:32:22+00:00",
          "link": "https://arxiv.org/abs/2505.16122v2",
          "size": "2406kb",
          "version": "v2"
        }
      ],
      "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16122",
        "PDF": "https://arxiv.org/pdf/2505.16122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces Plan-and-Budget, a framework to improve inference efficiency in LLM reasoning tasks, emphasizing computation efficiency and reasoning strategies rather than training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Scheduling",
        "Token Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12251",
      "abstract": "Autoregressive Transformers are increasingly being deployed as end-to-end robot and autonomous vehicle (AV) policy architectures, owing to their scalability and potential to leverage internet-scale pretraining for generalization. Accordingly, tokenizing sensor data efficiently is paramount to ensuring the real-time feasibility of such architectures on embedded hardware. To this end, we present an efficient triplane-based multi-camera tokenization strategy that leverages recent advances in 3D neural reconstruction and rendering to produce sensor tokens that are agnostic to the number of input cameras and their resolution, while explicitly accounting for their geometry around an AV. Experiments on a large-scale AV dataset and state-of-the-art neural simulator demonstrate that our approach yields significant savings over current image patch-based tokenization strategies, producing up to 72% fewer tokens, resulting in up to 50% faster policy inference while achieving the same open-loop motion planning accuracy and improved offroad rates in closed-loop driving simulations.",
      "authors": [
        "Boris Ivanovic",
        "Cristiano Saltori",
        "Yurong You",
        "Yan Wang",
        "Wenjie Luo",
        "Marco Pavone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T21:56:52+00:00",
          "link": "https://arxiv.org/abs/2506.12251v1",
          "size": "8063kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T17:22:35+00:00",
          "link": "https://arxiv.org/abs/2506.12251v2",
          "size": "7822kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Multi-Camera Tokenization with Triplanes for End-to-End Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12251",
        "HTML": "https://arxiv.org/html/2506.12251",
        "PDF": "https://arxiv.org/pdf/2506.12251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sensor data tokenization for autonomous vehicles and discusses efficiency in representation rather than contributions related to LLM training data processing."
      },
      "tasks": [
        "Motion Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14863",
      "abstract": "Consider a graph $G$ with a long path $P$. When is it the case that $G$ also contains a long induced path? This question has been investigated in general as well as within a number of different graph classes since the 80s. We have recently observed in a companion paper (Long induced paths in sparse graphs and graphs with forbidden patterns, arXiv:2411.08685, 2024) that most existing results can recovered in a simple way by considering forbidden ordered patterns of edges along the path $P$. In particular we proved that if we forbid some fixed ordered matching along a path of order $n$ in a graph $G$, then $G$ must contain an induced path of order $(\\log n)^{\\Omega(1)}$. Moreover, we completely characterized the forbidden ordered patterns forcing the existence of an induced path of polynomial size.\n  The purpose of the present paper is to completely characterize the ordered patterns $H$ such that forbidding $H$ along a path $P$ of order $n$ implies the existence of an induced path of order $(\\log n)^{\\Omega(1)}$. These patterns are star forests with some specific ordering, which we called constellations.\n  As a direct consequence of our result, we show that if a graph $G$ has a path of length $n$ and does not contain $K_t$ as a topological minor, then $G$ contains an induced path of order $(\\log n)^{\\Omega(1/t \\log^2 t)}$. The previously best known bound was $(\\log n)^{f(t)}$ for some unspecified function $f$ depending on the Topological Minor Structure Theorem of Grohe and Marx (2015).",
      "authors": [
        "Julien Duron",
        "Louis Esperet",
        "Jean-Florent Raymond"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T13:58:20+00:00",
          "link": "https://arxiv.org/abs/2412.14863v1",
          "size": "88kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:59:15+00:00",
          "link": "https://arxiv.org/abs/2412.14863v2",
          "size": "126kb",
          "version": "v2"
        }
      ],
      "title": "Long induced paths and forbidden patterns: Polylogarithmic bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14863",
        "HTML": "https://arxiv.org/html/2412.14863",
        "PDF": "https://arxiv.org/pdf/2412.14863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research targets graph theory and the characteristics of induced paths in graphs with forbidden patterns. It does not relate to any process of handling or curating data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.07098",
      "abstract": "Segment Anything Model 2 (SAM2) has emerged as a strong base model in various pinhole imaging segmentation tasks. However, when applying it to $360^\\circ$ domain, the significant field-of-view (FoV) gap between pinhole ($70^\\circ \\times 70^\\circ$) and panoramic images ($180^\\circ \\times 360^\\circ$) poses unique challenges. Two major concerns for this application includes 1) inevitable distortion and object deformation brought by the large FoV disparity between domains; 2) the lack of pixel-level semantic understanding that the original SAM2 cannot provide. To address these issues, we propose a novel OmniSAM framework, which makes the first attempt to apply SAM2 for panoramic semantic segmentation. Specifically, to bridge the first gap, OmniSAM first divides the panorama into sequences of patches. These patches are then treated as image sequences in similar manners as in video segmentation tasks. We then leverage the SAM2's memory mechanism to extract cross-patch correspondences that embeds the cross-FoV dependencies, improving feature continuity and the prediction consistency along mask boundaries. For the second gap, OmniSAM fine-tunes the pretrained image encoder and reutilize the mask decoder for semantic prediction. An FoV-based prototypical adaptation module with dynamic pseudo label update mechanism is also introduced to facilitate the alignment of memory and backbone features, thereby improving model generalization ability across different sizes of source models. Extensive experimental results demonstrate that OmniSAM outperforms the state-of-the-art methods by large margins, e.g., 79.06% (+10.22%) on SPin8-to-SPan8, 62.46% (+6.58%) on CS13-to-DP13.",
      "authors": [
        "Ding Zhong",
        "Xu Zheng",
        "Chenfei Liao",
        "Yuanhuiyi Lyu",
        "Jialei Chen",
        "Shengyang Wu",
        "Linfeng Zhang",
        "Xuming Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T09:21:08+00:00",
          "link": "https://arxiv.org/abs/2503.07098v1",
          "size": "37400kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:04:17+00:00",
          "link": "https://arxiv.org/abs/2503.07098v2",
          "size": "36802kb",
          "version": "v2"
        }
      ],
      "title": "OmniSAM: Omnidirectional Segment Anything Model for UDA in Panoramic Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07098",
        "HTML": "https://arxiv.org/html/2503.07098",
        "PDF": "https://arxiv.org/pdf/2503.07098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adapting a segmentation model for panoramic semantic segmentation, tackling challenges related to field-of-view disparities and deformations. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Pseudo Label",
        "Semantic Segmentation",
        "Video Segmentation",
        "Video Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.21313",
      "abstract": "Reconstructing hand-held objects in 3D from monocular images remains a significant challenge in computer vision. Most existing approaches rely on implicit 3D representations, which produce overly smooth reconstructions and are time-consuming to generate explicit 3D shapes. While more recent methods directly reconstruct point clouds with diffusion models, the multi-step denoising makes high-resolution reconstruction inefficient. To address these limitations, we propose a transformer-based model to efficiently reconstruct dense 3D point clouds of hand-held objects. Our method follows a coarse-to-fine strategy, first generating a sparse point cloud from the image and progressively refining it into a dense representation using pixel-aligned image features. To enhance reconstruction accuracy, we integrate image features with 3D hand geometry to jointly predict the object point cloud and its pose relative to the hand. Our model is trained end-to-end for optimal performance. Experimental results on both synthetic and real datasets demonstrate that our method achieves state-of-the-art accuracy with much faster inference speed, while generalizing well to in-the-wild images.",
      "authors": [
        "Zerui Chen",
        "Rolandos Alexandros Potamias",
        "Shizhe Chen",
        "Cordelia Schmid"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T09:45:09+00:00",
          "link": "https://arxiv.org/abs/2503.21313v1",
          "size": "11153kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:20:41+00:00",
          "link": "https://arxiv.org/abs/2503.21313v2",
          "size": "11810kb",
          "version": "v2"
        }
      ],
      "title": "HORT: Monocular Hand-held Objects Reconstruction with Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21313",
        "HTML": "https://arxiv.org/html/2503.21313",
        "PDF": "https://arxiv.org/pdf/2503.21313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D reconstruction of hand-held objects using transformer models, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05108",
      "abstract": "Historical documents represent an invaluable cultural heritage, yet have undergone significant degradation over time through tears, water erosion, and oxidation. Existing Historical Document Restoration (HDR) methods primarily focus on single modality or limited-size restoration, failing to meet practical needs. To fill this gap, we present a full-page HDR dataset (FPHDR) and a novel automated HDR solution (AutoHDR). Specifically, FPHDR comprises 1,633 real and 6,543 synthetic images with character-level and line-level locations, as well as character annotations in different damage grades. AutoHDR mimics historians' restoration workflows through a three-stage approach: OCR-assisted damage localization, vision-language context text prediction, and patch autoregressive appearance restoration. The modular architecture of AutoHDR enables seamless human-machine collaboration, allowing for flexible intervention and optimization at each restoration stage. Experiments demonstrate AutoHDR's remarkable performance in HDR. When processing severely damaged documents, our method improves OCR accuracy from 46.83% to 84.05%, with further enhancement to 94.25% through human-machine collaboration. We believe this work represents a significant advancement in automated historical document restoration and contributes substantially to cultural heritage preservation. The model and dataset are available at https://github.com/SCUT-DLVCLab/AutoHDR.",
      "authors": [
        "Yuyi Zhang",
        "Peirong Zhang",
        "Zhenhua Yang",
        "Pengyu Yan",
        "Yongxin Shi",
        "Pengwei Liu",
        "Fengjun Guo",
        "Lianwen Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:26:17+00:00",
          "link": "https://arxiv.org/abs/2507.05108v1",
          "size": "47525kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:18:42+00:00",
          "link": "https://arxiv.org/abs/2507.05108v2",
          "size": "47525kb",
          "version": "v2"
        }
      ],
      "title": "Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05108",
        "HTML": "https://arxiv.org/html/2507.05108",
        "PDF": "https://arxiv.org/pdf/2507.05108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on historical document restoration through a dataset and method called AutoHDR, which is not related to LLM training data processing or enhancement activities such as dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14164",
      "abstract": "In the field of cardiac electrophysiology (EP), effectively reducing noise in intra-cardiac signals is crucial for the accurate diagnosis and treatment of arrhythmias and cardiomyopathies. However, traditional noise reduction techniques fall short in addressing the diverse noise patterns from various sources, often non-linear and non-stationary, present in these signals. This work introduces a Variational Autoencoder (VAE) model, aimed at improving the quality of intra-ventricular monophasic action potential (MAP) signal recordings. By constructing representations of clean signals from a dataset of 5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our approach demonstrates superior denoising performance when compared to conventional filtering methods commonly employed in clinical settings. We assess the effectiveness of our VAE model using various metrics, indicating its superior capability to denoise signals across different noise types, including time-varying non-linear noise frequently found in clinical settings. These results reveal that VAEs can eliminate diverse sources of noise in single beats, outperforming state-of-the-art denoising techniques and potentially improving treatment efficacy in cardiac EP.",
      "authors": [
        "Samuel Ruip\\'erez-Campillo",
        "Alain Ryser",
        "Thomas M. Sutter",
        "Ruibin Feng",
        "Prasanth Ganesan",
        "Brototo Deb",
        "Kelly A. Brennan",
        "Maxime Pedron",
        "Albert J. Rogers",
        "Maarten Z.H. Kolk",
        "Fleur V.Y. Tjong",
        "Sanjiv M. Narayan",
        "Julia E. Vogt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:27:31+00:00",
          "link": "https://arxiv.org/abs/2507.14164v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14164",
        "HTML": "https://arxiv.org/html/2507.14164",
        "PDF": "https://arxiv.org/pdf/2507.14164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a Variational Autoencoder (VAE) model for denoising intra-cardiac time series signals. It primarily addresses noise reduction in medical signal processing, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14584",
      "abstract": "The use of Bidirectional Encoder Representations from Transformers (BERT) model and its variants for classifying collaborative problem solving (CPS) has been extensively explored within the AI in Education community. However, limited attention has been given to understanding how individual tokenised words in the dataset contribute to the model's classification decisions. Enhancing the explainability of BERT-based CPS diagnostics is essential to better inform end users such as teachers, thereby fostering greater trust and facilitating wider adoption in education. This study undertook a preliminary step towards model transparency and explainability by using SHapley Additive exPlanations (SHAP) to examine how different tokenised words in transcription data contributed to a BERT model's classification of CPS processes. The findings suggested that well-performing classifications did not necessarily equate to a reasonable explanation for the classification decisions. Particular tokenised words were used frequently to affect classifications. The analysis also identified a spurious word, which contributed positively to the classification but was not semantically meaningful to the class. While such model transparency is unlikely to be useful to an end user to improve their practice, it can help them not to overrely on LLM diagnostics and ignore their human expertise. We conclude the workshop paper by noting that the extent to which the model appropriately uses the tokens for its classification is associated with the number of classes involved. It calls for an investigation into the exploration of ensemble model architectures and the involvement of human-AI complementarity for CPS diagnosis, since considerable human reasoning is still required for fine-grained discrimination of CPS subskills.",
      "authors": [
        "Kester Wong",
        "Sahan Bulathwela and Mutlu Cukurova"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T11:57:24+00:00",
          "link": "https://arxiv.org/abs/2507.14584v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14584",
        "HTML": "https://arxiv.org/html/2507.14584",
        "PDF": "https://arxiv.org/pdf/2507.14584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores model transparency and explainability using BERT for collaborative problem solving diagnostics. It does not involve any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14721",
      "abstract": "This study addresses the problem of occluded grasping, where primary grasp configurations of an object are not available due to occlusion with environment. Simple parallel grippers often struggle with such tasks due to limited dexterity and actuation constraints. Prior works have explored object pose reorientation such as pivoting by utilizing extrinsic contacts between an object and an environment feature like a wall, to make the object graspable. However, such works often assume the presence of a short wall, and this assumption may not always hold in real-world scenarios. If the wall available for interaction is too large or too tall, the robot may still fail to grasp the object even after pivoting, and the robot must combine different types of actions to grasp. To address this, we propose a hierarchical reinforcement learning (RL) framework. We use Q-learning to train a high-level policy that selects the type of action expected to yield the highest reward. The selected low-level skill then samples a specific robot action in continuous space. To guide the robot to an appropriate location for executing the selected action, we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on the object point cloud and the skill ID, enabling it to infer a suitable location based on the object geometry and the selected skill. To promote generalization, we apply domain randomization during the training of low-level skills. The RL policy is trained entirely in simulation with a box-like object and deployed to six objects in real world. We conduct experiments to evaluate our method and demonstrate both its generalizability and robust sim-to-real transfer performance with promising success rates.",
      "authors": [
        "Keita Kobashi and Masayoshi Tomizuka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:49:47+00:00",
          "link": "https://arxiv.org/abs/2507.14721v1",
          "size": "16500kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14721",
        "HTML": "https://arxiv.org/html/2507.14721",
        "PDF": "https://arxiv.org/pdf/2507.14721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research discusses a robotic framework for occluded grasping tasks and does not involve any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10090",
      "abstract": "We introduce InteractPro, a comprehensive framework for dynamic motion-aware image composition. At its core is InteractPlan, an intelligent planner that leverages a Large Vision Language Model (LVLM) for scenario analysis and object placement, determining the optimal composition strategy to achieve realistic motion effects. Based on each scenario, InteractPlan selects between our two specialized modules: InteractPhys and InteractMotion. InteractPhys employs an enhanced Material Point Method (MPM)-based simulation to produce physically faithful and controllable object-scene interactions, capturing diverse and abstract events that require true physical modeling. InteractMotion, in contrast, is a training-free method based on pretrained video diffusion. Traditional composition approaches suffer from two major limitations: requiring manual planning for object placement and generating static, motionless outputs. By unifying simulation-based and diffusion-based methods under planner guidance, InteractPro overcomes these challenges, ensuring richly motion-aware compositions. Extensive quantitative and qualitative evaluations demonstrate InteractPro's effectiveness in producing controllable, and coherent compositions across varied scenarios.",
      "authors": [
        "Weijing Tao",
        "Xiaofeng Yang",
        "Miaomiao Cui",
        "Guosheng Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T08:44:17+00:00",
          "link": "https://arxiv.org/abs/2409.10090v1",
          "size": "16930kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:23:53+00:00",
          "link": "https://arxiv.org/abs/2409.10090v2",
          "size": "11161kb",
          "version": "v2"
        }
      ],
      "title": "InteractPro: A Unified Framework for Motion-Aware Image Composition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10090",
        "HTML": "https://arxiv.org/html/2409.10090",
        "PDF": "https://arxiv.org/pdf/2409.10090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces InteractPro, a framework for motion-aware image composition using a Large Vision Language Model, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/weijing-tao/MotionCom"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09287",
      "abstract": "Digital textbooks are widely used in various educational contexts, such as university courses and online lectures. Such textbooks yield learning log data that have been used in numerous educational data mining (EDM) studies for student behavior analysis and performance prediction. However, these studies have faced challenges in integrating confidential data, such as academic records and learning logs, across schools due to privacy concerns. Consequently, analyses are often conducted with data limited to a single school, which makes developing high-performing and generalizable models difficult. This study proposes a method that combines federated learning and differential features to address these issues. Federated learning enables model training without centralizing data, thereby preserving student privacy. Differential features, which utilize relative values instead of absolute values, enhance model performance and generalizability. To evaluate the proposed method, a model for predicting at-risk students was trained using data from 1,136 students across 12 courses conducted over 4 years, and validated on hold-out test data from 5 other courses. Experimental results demonstrated that the proposed method addresses privacy concerns while achieving performance comparable to that of models trained via centralized learning in terms of Top-n precision, nDCG, and PR-AUC. Furthermore, using differential features improved prediction performance across all evaluation datasets compared to non-differential approaches. The trained models were also applicable for early prediction, achieving high performance in detecting at-risk students in earlier stages of the semester within the validation datasets.",
      "authors": [
        "Shunsuke Yoneda",
        "Valdemar \\v{S}v\\'abensk\\'y",
        "Gen Li",
        "Daisuke Deguchi",
        "Atsushi Shimada"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T11:12:30+00:00",
          "link": "https://arxiv.org/abs/2505.09287v1",
          "size": "551kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:02:30+00:00",
          "link": "https://arxiv.org/abs/2505.09287v2",
          "size": "551kb",
          "version": "v2"
        }
      ],
      "title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09287",
        "HTML": "https://arxiv.org/html/2505.09287",
        "PDF": "https://arxiv.org/pdf/2505.09287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using federated learning and differential features for student prediction and does not involve LLM training data processing operations."
      },
      "tasks": [
        "Federated Learning"
      ],
      "repo_urls": [
        "https://github.com/limu-research/2025-edm-fl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09782",
      "abstract": "This paper introduces a framework based on physics-informed neural networks (PINNs) for addressing key challenges in nonlinear lattices, including solution approximation, bifurcation diagram construction, and linear stability analysis. We first employ PINNs to approximate solutions of nonlinear systems arising from lattice models, using the Levenberg-Marquardt algorithm to optimize network weights for greater accuracy. To enhance computational efficiency in high-dimensional settings, we integrate a stochastic sampling strategy. We then extend the method by coupling PINNs with a continuation approach to compute snaking bifurcation diagrams, incorporating an auxiliary equation to effectively track successive solution branches. For linear stability analysis, we adapt PINNs to compute eigenvectors, introducing output constraints to enforce positivity, in line with Sturm-Liouville theory. Numerical experiments are conducted on the discrete Allen-Cahn equation with cubic and quintic nonlinearities in one to five spatial dimensions. The results demonstrate that the proposed approach achieves accuracy comparable to, or better than, traditional numerical methods, especially in high-dimensional regimes where computational resources are a limiting factor. These findings highlight the potential of neural networks as scalable and efficient tools for the study of complex nonlinear lattice systems.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Fidya Almira Suheri",
        "Rudy Kusdiantara",
        "Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.09782v1",
          "size": "868kb",
          "version": "v1"
        }
      ],
      "title": "Physics-informed neural networks for high-dimensional solutions and snaking bifurcations in nonlinear lattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09782",
        "HTML": "https://arxiv.org/html/2507.09782",
        "PDF": "https://arxiv.org/pdf/2507.09782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on physics-informed neural networks for solutions in nonlinear lattices and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14481",
      "abstract": "Data-Free Quantization (DFQ) enables the quantization of Vision Transformers (ViTs) without requiring access to data, allowing for the deployment of ViTs on devices with limited resources. In DFQ, the quantization model must be calibrated using synthetic samples, making the quality of these synthetic samples crucial. Existing methods fail to fully capture and balance the global and local features within the samples, resulting in limited synthetic data quality. Moreover, we have found that during inference, there is a significant difference in the distributions of intermediate layer activations between the quantized and full-precision models. These issues lead to a severe performance degradation of the quantized model. To address these problems, we propose a pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT). Specifically, we synthesize samples in order of increasing difficulty, effectively enhancing the quality of synthetic data. During the calibration and inference stage, we introduce the activation correction matrix for the quantized model to align the intermediate layer activations with those of the full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves remarkable superiority over existing DFQ methods and its performance is on par with models quantized through real data. For example, the performance of DeiT-T with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our method eliminates the need for fine-tuning, which not only reduces computational overhead but also lowers the deployment barriers for edge devices. This characteristic aligns with the principles of Green Learning by improving energy efficiency and facilitating real-world applications in resource-constrained environments.",
      "authors": [
        "Yujia Tong",
        "Jingling Yuan",
        "Tian Zhang",
        "Jianquan Liu",
        "Chuang Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:32:04+00:00",
          "link": "https://arxiv.org/abs/2507.14481v1",
          "size": "695kb",
          "version": "v1"
        }
      ],
      "title": "DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14481",
        "PDF": "https://arxiv.org/pdf/2507.14481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses Data-Free Quantization for Vision Transformers, primarily dealing with model quantization and calibration improvements rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14608",
      "abstract": "Facial expression recognition is crucial for human-computer interaction applications such as face animation, video surveillance, affective computing, medical analysis, etc. Since the structure of facial attributes varies with facial expressions, incorporating structural information into facial attributes is essential for facial expression recognition. In this paper, we propose Exp-Graph, a novel framework designed to represent the structural relationships among facial attributes using graph-based modeling for facial expression recognition. For facial attributes graph representation, facial landmarks are used as the graph's vertices. At the same time, the edges are determined based on the proximity of the facial landmark and the similarity of the local appearance of the facial attributes encoded using the vision transformer. Additionally, graph convolutional networks are utilized to capture and integrate these structural dependencies into the encoding of facial attributes, thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph learns from the facial attribute graphs highly expressive semantic representations. On the other hand, the vision transformer and graph convolutional blocks help the framework exploit the local and global dependencies among the facial attributes that are essential for the recognition of facial expressions. We conducted comprehensive evaluations of the proposed Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW. The model achieved recognition accuracies of 98.09\\%, 79.01\\%, and 56.39\\%, respectively. These results indicate that Exp-Graph maintains strong generalization capabilities across both controlled laboratory settings and real-world, unconstrained environments, underscoring its effectiveness for practical facial expression recognition applications.",
      "authors": [
        "Nandani Sharma",
        "Dinesh Singh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.14608v1",
          "size": "2172kb",
          "version": "v1"
        }
      ],
      "title": "Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14608",
        "HTML": "https://arxiv.org/html/2507.14608",
        "PDF": "https://arxiv.org/pdf/2507.14608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about facial expression recognition using graph-based modeling and vision transformers, which does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14625",
      "abstract": "Vertical federated learning (VFL) enables multiple parties with disjoint features to collaboratively train models without sharing raw data. While privacy vulnerabilities of VFL are extensively-studied, its security threats-particularly targeted label attacks-remain underexplored. In such attacks, a passive party perturbs inputs at inference to force misclassification into adversary-chosen labels. Existing methods rely on unrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore anomaly detectors deployed in real-world systems. To bridge this gap, we introduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly designed to evade detector-enhanced VFL inference. During the preparation stage, the attacker selects a minimal set of high-expressiveness samples (via maximum mean discrepancy), submits them through VFL protocol to collect predicted labels, and uses these pseudo-labels to train estimated detector and surrogate model on local features. In attack stage, these models guide gradient-based perturbations of remaining samples, crafting adversarial instances that induce targeted misclassifications and evade detection. We implement VTarbel and evaluate it against four model architectures, seven multimodal datasets, and two anomaly detectors. Across all settings, VTarbel outperforms four state-of-the-art baselines, evades detection, and retains effective against three representative privacy-preserving defenses. These results reveal critical security blind spots in current VFL deployments and underscore urgent need for robust, attack-aware defenses.",
      "authors": [
        "Juntao Tan",
        "Anran Li",
        "Quanchao Liu",
        "Peng Ran",
        "Lan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.14625v1",
          "size": "461kb",
          "version": "v1"
        }
      ],
      "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14625",
        "HTML": "https://arxiv.org/html/2507.14625",
        "PDF": "https://arxiv.org/pdf/2507.14625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses security threats in vertical federated learning with a focus on targeted label attacks. It does not involve any LLM training data processing or dataset creation operations relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14694",
      "abstract": "3D human motion forecasting aims to enable autonomous applications. Estimating uncertainty for each prediction (i.e., confidence based on probability density or quantile) is essential for safety-critical contexts like human-robot collaboration to minimize risks. However, existing diverse motion forecasting approaches struggle with uncertainty quantification due to implicit probabilistic representations hindering uncertainty modeling. We propose ProbHMI, which introduces invertible networks to parameterize poses in a disentangled latent space, enabling probabilistic dynamics modeling. A forecasting module then explicitly predicts future latent distributions, allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI achieves strong performance for both deterministic and diverse prediction while validating uncertainty calibration, critical for risk-aware decision making.",
      "authors": [
        "Yue Ma",
        "Kanglei Zhou",
        "Fuyang Yu",
        "Frederick W. B. Li",
        "and Xiaohui Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.14694v1",
          "size": "2292kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14694",
        "HTML": "https://arxiv.org/html/2507.14694",
        "PDF": "https://arxiv.org/pdf/2507.14694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on 3D human motion forecasting and uncertainty quantification using invertible networks, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14918",
      "abstract": "Multi-label image classification, an important research area in computer vision, focuses on identifying multiple labels or concepts within an image. Existing approaches often employ attention mechanisms or graph convolutional networks (GCNs) to learn image representation. However, this representation may contain noise and may not locate objects precisely. Therefore, this paper proposes a Semantic-Aware Representation Learning (SARL) for multi-label image classification. First, a label semantic-related feature learning module is utilized to extract semantic-related features. Then, an optimal transport-based attention mechanism is designed to obtain semantically aligned image representation. Finally, a regional score aggregation strategy is used for multi-label prediction. Experimental results on two benchmark datasets, PASCAL VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing methods.",
      "authors": [
        "Ren-Dong Xie",
        "Zhi-Fen He",
        "Bo Li",
        "Bin Liu",
        "Jin-Yan Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:15:24+00:00",
          "link": "https://arxiv.org/abs/2507.14918v1",
          "size": "18008kb",
          "version": "v1"
        }
      ],
      "title": "Semantic-Aware Representation Learning for Multi-label Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14918",
        "HTML": "https://arxiv.org/html/2507.14918",
        "PDF": "https://arxiv.org/pdf/2507.14918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with multi-label image classification and representation learning techniques. It does not involve LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15236",
      "abstract": "This work investigates the impact of multi-task, multi-lingual, and multi-source learning approaches on the robustness and performance of pretrained language models. To enhance this analysis, we introduce Subsets of Interest (SOI), a novel categorization framework that identifies six distinct learning behavior patterns during training, including forgettable examples, unlearned examples, and always correct examples. Through SOI transition heatmaps and dataset cartography visualization, we analyze how examples shift between these categories when transitioning from single-setting to multi-setting configurations. We perform comprehensive experiments across three parallel comparisons: multi-task vs. single-task learning using English tasks (entailment, paraphrase, sentiment), multi-source vs. single-source learning using sentiment analysis datasets, and multi-lingual vs. single-lingual learning using intent classification in French, English, and Persian. Our results demonstrate that multi-source learning consistently improves out-of-distribution performance by up to 7%, while multi-task learning shows mixed results with notable gains in similar task combinations. We further introduce a two-stage fine-tuning approach where the second stage leverages SOI-based subset selection to achieve additional performance improvements. These findings provide new insights into training dynamics and offer practical approaches for optimizing multi-setting language model performance.",
      "authors": [
        "Shayan Vassef",
        "Amirhossein Dabiriaghdam",
        "Mohammadreza Bakhtiari",
        "Yadollah Yaghoobzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:43:21+00:00",
          "link": "https://arxiv.org/abs/2507.15236v1",
          "size": "3664kb",
          "version": "v1"
        }
      ],
      "title": "SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15236",
        "HTML": "https://arxiv.org/html/2507.15236",
        "PDF": "https://arxiv.org/pdf/2507.15236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores training dynamics in pretrained language models and introduces a fine-tuning approach using SOI-based subset selection, its main focus is on learning behavior and model performance optimization, not specifically on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15287",
      "abstract": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to learn from reward-free interactions and alternative supervision signals, such as unlabeled or incomplete demonstrations, rather than relying solely on explicit reward maximization. Additionally, developing generalist agents that can adapt efficiently in real-world environments often requires leveraging these reward-free signals to guide learning and behavior. However, while intrinsic motivation techniques provide a means for agents to seek out novel or uncertain states in the absence of explicit rewards, they are often challenged by dense reward environments or the complexity of high-dimensional state and action spaces. Furthermore, most existing approaches rely directly on the unprocessed intrinsic reward signals, which can make it difficult to shape or control the agent's exploration effectively. We propose a framework that can effectively utilize expert demonstrations, even when they are incomplete and imperfect. By applying a mapping function to transform the similarity between an agent's state and expert data into a shaped intrinsic reward, our method allows for flexible and targeted exploration of expert-like behaviors. We employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors and accommodate missing information in demonstrations. Experiments show our approach enables robust exploration and strong performance in both sparse and dense reward environments, even when demonstrations are sparse or incomplete. This provides a practical framework for RL in realistic settings where optimal data is unavailable and precise reward control is needed.",
      "authors": [
        "Elias Malomgr\\'e and Pieter Simoens"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:38:46+00:00",
          "link": "https://arxiv.org/abs/2507.15287v1",
          "size": "2907kb",
          "version": "v1"
        }
      ],
      "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15287",
        "HTML": "https://arxiv.org/html/2507.15287",
        "PDF": "https://arxiv.org/pdf/2507.15287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning and the use of autoencoders for exploration, with no direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15798",
      "abstract": "The paper investigates the performance of state-of-the-art low-parameter deep neural networks for computer vision, focusing on bottleneck architectures and their behavior using superlinear activation functions. We address interference in feature maps, a phenomenon associated with superposition, where neurons simultaneously encode multiple characteristics. Our research suggests that limiting interference can enhance scaling and accuracy in very low-scaled networks (under 1.5M parameters). We identify key design elements that reduce interference by examining various bottleneck architectures, leading to a more efficient neural network. Consequently, we propose a proof-of-concept architecture named NoDepth Bottleneck built on mechanistic insights from our experiments, demonstrating robust scaling accuracy on the ImageNet dataset. These findings contribute to more efficient and scalable neural networks for the low-parameter range and advance the understanding of bottlenecks in computer vision.  https://caiac.pubpub.org/pub/3dh6rsel",
      "authors": [
        "Lilian Hollard",
        "Lucas Mohimont",
        "Nathalie Gaveau",
        "Luiz-Angelo Steffenel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:57:25+00:00",
          "link": "https://arxiv.org/abs/2507.15798v1",
          "size": "16590kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15798",
        "HTML": "https://arxiv.org/html/2507.15798",
        "PDF": "https://arxiv.org/pdf/2507.15798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The investigation into low-parameter vision models and bottleneck architectures for computer vision does not involve LLM training data processing or related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15842",
      "abstract": "We consider identifying a conditional causal effect when a graph is known up to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG represents an equivalence class of graphs that is restricted by background knowledge and where all variables in the causal model are observed. We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects.",
      "authors": [
        "Sara LaPlante",
        "Emilija Perkovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:52:28+00:00",
          "link": "https://arxiv.org/abs/2507.15842v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Conditional Causal Effects in MPDAGs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15842",
        "PDF": "https://arxiv.org/pdf/2507.15842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on identifying conditional causal effects in MPDAGs, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "0910.3580",
      "abstract": "A common assumption in modern microeconomic theory is that choice should be rationalizable via a binary preference relation, which \\citeauthor{Sen71a} showed to be equivalent to two consistency conditions, namely $\\alpha$ (contraction) and $\\gamma$ (expansion). Within the context of \\emph{social} choice, however, rationalizability and similar notions of consistency have proved to be highly problematic, as witnessed by a range of impossibility results, among which Arrow's is the most prominent. Since choice functions select \\emph{sets} of alternatives rather than single alternatives, we propose to rationalize choice functions by preference relations over sets (set-rationalizability). We also introduce two consistency conditions, $\\hat\\alpha$ and $\\hat\\gamma$, which are defined in analogy to $\\alpha$ and $\\gamma$, and find that a choice function is set-rationalizable if and only if it satisfies $\\hat\\alpha$. Moreover, a choice function satisfies $\\hat\\alpha$ and $\\hat\\gamma$ if and only if it is \\emph{self-stable}, a new concept based on earlier work by \\citeauthor{Dutt88a}. The class of self-stable social choice functions contains a number of appealing Condorcet extensions such as the minimal covering set and the essential set.",
      "authors": [
        "Felix Brandt",
        "Paul Harrenstein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2009-10-19T15:02:54+00:00",
          "link": "https://arxiv.org/abs/0910.3580v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2009-11-23T13:19:01+00:00",
          "link": "https://arxiv.org/abs/0910.3580v2",
          "size": "21kb",
          "version": "v2"
        },
        {
          "date": "2010-02-24T14:52:26+00:00",
          "link": "https://arxiv.org/abs/0910.3580v3",
          "size": "24kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T14:01:59+00:00",
          "link": "https://arxiv.org/abs/0910.3580v4",
          "size": "15kb",
          "version": "v4"
        }
      ],
      "title": "Set-Rationalizable Choice and Self-Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/0910.3580",
        "HTML": "https://arxiv.org/html/0910.3580",
        "PDF": "https://arxiv.org/pdf/0910.3580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses concepts in microeconomic and social choice theory and does not discuss data processing for LLM pretraining or fine-tuning, nor any relevant data engineering operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.07760",
      "abstract": "Explainability is motivated by the lack of transparency of black-box Machine Learning approaches, which do not foster trust and acceptance of Machine Learning algorithms. This also happens in the Predictive Process Monitoring field, where predictions, obtained by applying Machine Learning techniques, need to be explained to users, so as to gain their trust and acceptance. In this work, we carry on a user evaluation on explanation approaches for Predictive Process Monitoring aiming at investigating whether and how the explanations provided (i) are understandable; (ii) are useful in decision making tasks;(iii) can be further improved for process analysts, with different Machine Learning expertise levels. The results of the user evaluation show that, although explanation plots are overall understandable and useful for decision making tasks for Business Process Management users -- with and without experience in Machine Learning -- differences exist in the comprehension and usage of different plots, as well as in the way users with different Machine Learning expertise understand and use them.",
      "authors": [
        "Williams Rizzi",
        "Marco Comuzzi",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Suhwan Lee",
        "Fabrizio Maria Maggi",
        "Alexander Nolte"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-15T22:24:21+00:00",
          "link": "https://arxiv.org/abs/2202.07760v1",
          "size": "2929kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Predictive Process Monitoring: A User Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.07760",
        "PDF": "https://arxiv.org/pdf/2202.07760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates explainability approaches in predictive process monitoring, focusing on user understanding and trust but not on LLM training data processing."
      },
      "tasks": [
        "BIG-bench Machine Learning",
        "Decision Making",
        "Management",
        "Predictive Process Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.06703",
      "abstract": "This paper introduces a simple yet effective strategy for exercise classification and muscle group activation prediction (MGAP). These tasks have significant implications for personal fitness, facilitating more affordable, accessible, safer, and simpler exercise routines. This is particularly relevant for novices and individuals with disabilities. Previous research in the field is mostly dominated by the reliance on mounted sensors and a limited scope of exercises, reducing practicality for everyday use. Furthermore, existing MGAP methodologies suffer from a similar dependency on sensors and a restricted range of muscle groups, often excluding strength training exercises, which are pivotal for a comprehensive fitness regimen. Addressing these limitations, our research employs a video-based deep learning framework that encompasses a broad spectrum of exercises and muscle groups, including those vital for strength training. Utilizing the \"Workout/Exercises Video\" dataset, our approach integrates the X3D and SlowFast video activity recognition models in an effective way to enhance exercise classification and MGAP performance. Our findings demonstrate that this hybrid method, obtained via weighted ensemble, outperforms existing baseline models in accuracy. Pretrained models play a crucial role in enhancing overall performance, with optimal channel reduction values for the SlowFast model identified near 10. Through an ablation study that explores fine-tuning, we further elucidate the interrelation between the two tasks. Our composite model, a weighted-average ensemble of X3D and SlowFast, sets a new benchmark in both exercise classification and MGAP across all evaluated categories, offering a robust solution to the limitations of previous approaches.",
      "authors": [
        "Manvik Pasula and Pramit Saha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-10T18:05:02+00:00",
          "link": "https://arxiv.org/abs/2406.06703v1",
          "size": "3615kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:56:21+00:00",
          "link": "https://arxiv.org/abs/2406.06703v2",
          "size": "153kb",
          "version": "v2"
        }
      ],
      "title": "Video-based Exercise Classification and Activated Muscle Group Prediction with Hybrid X3D-SlowFast Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06703",
        "HTML": "https://arxiv.org/html/2406.06703",
        "PDF": "https://arxiv.org/pdf/2406.06703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on exercise classification and muscle group activation prediction using video-based deep learning frameworks. It does not address LLM training data processing activities related to pretraining or fine-tuning."
      },
      "tasks": [
        "Activity Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.12644",
      "abstract": "Assessing the effectiveness of large language models (LLMs) in performing different tasks is crucial for understanding their strengths and weaknesses. This paper presents Hierarchical Prompting Taxonomy (HPT), grounded on human cognitive principles and designed to assess LLMs by examining the cognitive demands of various tasks. The HPT utilizes the Hierarchical Prompting Framework (HPF), which structures five unique prompting strategies in a hierarchical order based on their cognitive requirement on LLMs when compared to human mental capabilities. It assesses the complexity of tasks with the Hierarchical Prompting Index (HPI), which demonstrates the cognitive competencies of LLMs across diverse datasets and offers insights into the cognitive demands that datasets place on different LLMs. This approach enables a comprehensive evaluation of an LLMs problem solving abilities and the intricacy of a dataset, offering a standardized metric for task complexity. Extensive experiments with multiple datasets and LLMs show that HPF enhances LLM performance by 2% to 63% compared to baseline performance, with GSM8k being the most cognitively complex task among reasoning and coding tasks with an average HPI of 3.20 confirming the effectiveness of HPT. To support future research and reproducibility in this domain, the implementations of HPT and HPF are available here.",
      "authors": [
        "Devichand Budagam",
        "Ashutosh Kumar",
        "Mahsa Khoshnoodi",
        "Sankalp KJ",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T14:12:27+00:00",
          "link": "https://arxiv.org/abs/2406.12644v1",
          "size": "1005kb",
          "version": "v1"
        },
        {
          "date": "2024-06-27T14:32:07+00:00",
          "link": "https://arxiv.org/abs/2406.12644v2",
          "size": "1005kb",
          "version": "v2"
        },
        {
          "date": "2024-12-01T17:45:28+00:00",
          "link": "https://arxiv.org/abs/2406.12644v3",
          "size": "912kb",
          "version": "v3"
        },
        {
          "date": "2024-12-12T02:37:52+00:00",
          "link": "https://arxiv.org/abs/2406.12644v4",
          "size": "3640kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T01:47:18+00:00",
          "link": "https://arxiv.org/abs/2406.12644v5",
          "size": "516kb",
          "version": "v5"
        }
      ],
      "title": "Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned with Human Cognitive Principles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12644",
        "HTML": "https://arxiv.org/html/2406.12644",
        "PDF": "https://arxiv.org/pdf/2406.12644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework for evaluating LLMs' cognitive abilities and task complexity through hierarchical prompting. Although it talks about datasets, it focuses primarily on LLM evaluation rather than core data processing for training."
      },
      "tasks": [
        "Arithmetic Reasoning",
        "Code Generation",
        "Common Sense Reasoning",
        "GSM8K",
        "Machine Translation",
        "Math",
        "Multi-task Language Understanding",
        "Prompt Engineering",
        "Question Answering",
        "Summarization",
        "Text Summarization",
        "Translation"
      ],
      "repo_urls": [
        "https://github.com/devichand579/HPT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.04489",
      "abstract": "We investigate the phenomenon of grokking -- delayed generalization accompanied by non-monotonic test loss behavior -- in a simple binary logistic classification task, for which \"memorizing\" and \"generalizing\" solutions can be strictly defined. Surprisingly, we find that grokking arises naturally even in this minimal model when the parameters of the problem are close to a critical point, and provide both empirical and analytical insights into its mechanism. Concretely, by appealing to the implicit bias of gradient descent, we show that logistic regression can exhibit grokking when the training dataset is nearly linearly separable from the origin and there is strong noise in the perpendicular directions. The underlying reason is that near the critical point, \"flat\" directions in the loss landscape with nearly zero gradient cause training dynamics to linger for arbitrarily long times near quasi-stable solutions before eventually reaching the global minimum. Finally, we highlight similarities between our findings and the recent literature, strengthening the conjecture that grokking generally occurs in proximity to the interpolation threshold, reminiscent of critical phenomena often observed in physical systems.",
      "authors": [
        "Alon Beck",
        "Noam Levi",
        "Yohai Bar-Sinai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-06T14:08:42+00:00",
          "link": "https://arxiv.org/abs/2410.04489v1",
          "size": "804kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T01:23:58+00:00",
          "link": "https://arxiv.org/abs/2410.04489v2",
          "size": "1082kb",
          "version": "v2"
        }
      ],
      "title": "Grokking at the Edge of Linear Separability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04489",
        "HTML": "https://arxiv.org/html/2410.04489",
        "PDF": "https://arxiv.org/pdf/2410.04489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the grokking phenomenon in logistic classification tasks and does not address LLM training data processing or dataset-related contributions."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zhaoolee/garss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17593",
      "abstract": "Generative AI offers potential for educational support, but often lacks pedagogical grounding and awareness of the student's learning context. Furthermore, researching student interactions with these tools within authentic learning environments remains challenging. To address this, we present JELAI, an open-source platform architecture designed to integrate fine-grained Learning Analytics (LA) with Large Language Model (LLM)-based tutoring directly within a Jupyter Notebook environment. JELAI employs a modular, containerized design featuring JupyterLab extensions for telemetry and chat, alongside a central middleware handling LA processing and context-aware LLM prompt enrichment. This architecture enables the capture of integrated code interaction and chat data, facilitating real-time, context-sensitive AI scaffolding and research into student behaviour. We describe the system's design, implementation, and demonstrate its feasibility through system performance benchmarks and two proof-of-concept use cases illustrating its capabilities for logging multi-modal data, analysing help-seeking patterns, and supporting A/B testing of AI configurations. JELAI's primary contribution is its technical framework, providing a flexible tool for researchers and educators to develop, deploy, and study LA-informed AI tutoring within the widely used Jupyter ecosystem.",
      "authors": [
        "Manuel Valle Torre",
        "Thom van der Velden",
        "Marcus Specht",
        "Catharine Oertel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T07:58:53+00:00",
          "link": "https://arxiv.org/abs/2505.17593v1",
          "size": "885kb",
          "version": "v1"
        }
      ],
      "title": "JELAI: Integrating AI and Learning Analytics in Jupyter Notebooks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17593",
        "HTML": "https://arxiv.org/html/2505.17593",
        "PDF": "https://arxiv.org/pdf/2505.17593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents JELAI, a platform for integrating AI and learning analytics in Jupyter Notebooks, focusing on educational support and interactions within learning environments, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14267",
      "abstract": "Materials discovery relies on high-throughput, high-fidelity simulation techniques such as Density Functional Theory (DFT), which require years of training, extensive parameter fine-tuning and systematic error handling. To address these challenges, we introduce the DFT-based Research Engine for Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for DFT simulation that combines a central Large Language Model (LLM) planner agent with domain-specific LLM agents for atomistic structure generation, systematic DFT convergence testing, High-Performance Computing (HPC) scheduling, and error handling. In addition, a shared canvas helps the LLM agents to structure their discussions, preserve context and prevent hallucination. We validate DREAMS capabilities on the Sol27LC lattice-constant benchmark, achieving average errors below 1\\% compared to the results of human DFT experts. Furthermore, we apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating its long-term and complex problem-solving capabilities. The framework again reproduces expert-level literature adsorption-energy differences. Finally, DREAMS is employed to quantify functional-driven uncertainties with Bayesian ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS approaches L3-level automation - autonomous exploration of a defined design space - and significantly reduces the reliance on human expertise and intervention, offering a scalable path toward democratized, high-throughput, high-fidelity computational materials discovery.",
      "authors": [
        "Ziqi Wang",
        "Hongshuo Huang",
        "Hancheng Zhao",
        "Changwen Xu",
        "Shang Zhu",
        "Jan Janssen",
        "Venkatasubramanian Viswanathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T15:26:04+00:00",
          "link": "https://arxiv.org/abs/2507.14267v1",
          "size": "11672kb",
          "version": "v1"
        }
      ],
      "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14267",
        "HTML": "https://arxiv.org/html/2507.14267",
        "PDF": "https://arxiv.org/pdf/2507.14267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a simulation framework for materials discovery using Density Functional Theory and LLM agents, but it does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14521",
      "abstract": "The accurate modelling and simulation of electric devices involving ferromagnetic materials requires the appropriate consideration of magnetic hysteresis. We discuss the systematic incorporation of the energy-based vector hysteresis model of Henrotte et al. into vector potential formulations for the governing magnetic field equations. The field model describing a single step in a load cycle is phrased as a convex minimization problem which allows us to establish existence and uniqueness of solutions and to obtain accurate approximations by finite element discretization. Consistency of the model with the governing field equations is deduced from the first order optimality conditions. In addition, two globally convergent iterative methods are presented for the solution of the underlying minimization problems. The efficiency of the approach is illustrated by numerical tests for a typical benchmark problem.",
      "authors": [
        "Herbert Egger and Felix Engertsberger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:50:27+00:00",
          "link": "https://arxiv.org/abs/2507.14521v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "On the vector potential formulation with an energy-based hysteresis model and its numerical solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14521",
        "HTML": "https://arxiv.org/html/2507.14521",
        "PDF": "https://arxiv.org/pdf/2507.14521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with electric device modeling and magnetic hysteresis using vector potential formulations, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.01483",
      "abstract": "Adaptive task planning is fundamental to ensuring effective and seamless human-robot collaboration. This paper introduces a robot task planning framework that takes into account both human leading/following preferences and performance, specifically focusing on task allocation and scheduling in collaborative settings. We present a proactive task allocation approach with three primary objectives: enhancing team performance, incorporating human preferences, and upholding a positive human perception of the robot and the collaborative experience. Through a user study, involving an autonomous mobile manipulator robot working alongside participants in a collaborative scenario, we confirm that the task planning framework successfully attains all three intended goals, thereby contributing to the advancement of adaptive task planning in human-robot collaboration. This paper mainly focuses on the first two objectives, and we discuss the third objective, participants' perception of the robot, tasks, and collaboration in a companion paper.",
      "authors": [
        "Ali Noormohammadi-Asl",
        "Stephen L. Smith",
        "Kerstin Dautenhahn"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-03T01:15:55+00:00",
          "link": "https://arxiv.org/abs/2401.01483v1",
          "size": "1344kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T07:13:34+00:00",
          "link": "https://arxiv.org/abs/2401.01483v2",
          "size": "9056kb",
          "version": "v2"
        }
      ],
      "title": "To Lead or to Follow? Adaptive Robot Task Planning in Human-Robot Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01483",
        "PDF": "https://arxiv.org/pdf/2401.01483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with adaptive task planning for human-robot collaboration, which does not involve concepts of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06959",
      "abstract": "Music source separation demixes a piece of music into its individual sound sources (vocals, percussion, melodic instruments, etc.), a task with no simple mathematical solution. It requires deep learning methods involving training on large datasets of isolated music stems. The most commonly available datasets are made from commercial Western music, limiting the models' applications to non-Western genres like Carnatic music. Carnatic music is a live tradition, with the available multi-track recordings containing overlapping sounds and bleeds between the sources. This poses a challenge to commercially available source separation models like Spleeter and Hybrid Demucs. In this work, we introduce 'Sanidha', the first open-source novel dataset for Carnatic music, offering studio-quality, multi-track recordings with minimal to no overlap or bleed. Along with the audio files, we provide high-definition videos of the artists' performances. Additionally, we fine-tuned Spleeter, one of the most commonly used source separation models, on our dataset and observed improved SDR performance compared to fine-tuning on a pre-existing Carnatic multi-track dataset. The outputs of the fine-tuned model with 'Sanidha' are evaluated through a listening study.",
      "authors": [
        "Venkatakrishnan Vaidyanathapuram Krishnan",
        "Noel Alben",
        "Anish Nair",
        "Nathaniel Condit-Schultz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Digital Libraries (cs.DL)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T22:39:58+00:00",
          "link": "https://arxiv.org/abs/2501.06959v1",
          "size": "9266kb",
          "version": "v1"
        }
      ],
      "title": "Sanidha: A Studio Quality Multi-Modal Dataset for Carnatic Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06959",
        "HTML": "https://arxiv.org/html/2501.06959",
        "PDF": "https://arxiv.org/pdf/2501.06959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces 'Sanidha', a dataset for Carnatic music source separation, which involves data generation and fine-tuning of a model, but it is targeted at music source separation rather than LLM training data processing."
      },
      "tasks": [
        "Music Source Separation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14555",
      "abstract": "Understanding 3D scenes goes beyond simply recognizing objects; it requires reasoning about the spatial and semantic relationships between them. Current 3D scene-language models often struggle with this relational understanding, particularly when visual embeddings alone do not adequately convey the roles and interactions of objects. In this paper, we introduce Descrip3D, a novel and powerful framework that explicitly encodes the relationships between objects using natural language. Unlike previous methods that rely only on 2D and 3D embeddings, Descrip3D enhances each object with a textual description that captures both its intrinsic attributes and contextual relationships. These relational cues are incorporated into the model through a dual-level integration: embedding fusion and prompt-level injection. This allows for unified reasoning across various tasks such as grounding, captioning, and question answering, all without the need for task-specific heads or additional supervision. When evaluated on five benchmark datasets, including ScanRefer, Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms strong baseline models, demonstrating the effectiveness of language-guided relational representation for understanding complex indoor scenes.",
      "authors": [
        "Jintang Xue",
        "Ganning Zhao",
        "Jie-En Yao",
        "Hong-En Chen",
        "Yue Hu",
        "Meida Chen",
        "Suya You",
        "C.-C. Jay Kuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:19:16+00:00",
          "link": "https://arxiv.org/abs/2507.14555v1",
          "size": "1182kb",
          "version": "v1"
        }
      ],
      "title": "Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14555",
        "PDF": "https://arxiv.org/pdf/2507.14555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing 3D scene understanding with object-level text descriptions, a task related to improving relational representation in 3D models rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14929",
      "abstract": "Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a sustainable transition to electric vehicles by enabling a closed-loop supply chain. Currently, the manual disassembly process exposes workers to hazards, including electrocution and toxic chemicals. We propose a teleoperated system for the safe disassembly and sorting of EVBs. A human-in-the-loop can create and save disassembly sequences for unknown EVB types, enabling future automation. An RGB camera aligns the physical and digital twins of the EVB, and the digital twin of the robot is based on the Robot Operating System (ROS) middleware. This hybrid approach combines teleoperation and automation to improve safety, adaptability, and efficiency in EVB disassembly and sorting. The economic contribution is realized by reducing labor dependency and increasing throughput in battery recycling. An online pilot study was set up to evaluate the usability of the presented approach, and the results demonstrate the potential as a user-friendly solution.",
      "authors": [
        "Tero Kaarlela",
        "Sami Salo",
        "Jose Outeiro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:56:59+00:00",
          "link": "https://arxiv.org/abs/2507.14929v1",
          "size": "2713kb",
          "version": "v1"
        }
      ],
      "title": "Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14929",
        "HTML": "https://arxiv.org/html/2507.14929",
        "PDF": "https://arxiv.org/pdf/2507.14929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on teleoperation systems for disassembling electric vehicle batteries, using digital twins and extended reality. It does not address LLM training data processing or related topics in any capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15015",
      "abstract": "Large language models (LLMs) have demonstrated significant potential as educational tutoring agents, capable of tailoring hints, orchestrating lessons, and grading with near-human finesse across various academic domains. However, current LLM-based educational systems exhibit critical limitations in promoting genuine critical thinking, failing on over one-third of multi-hop questions with counterfactual premises, and remaining vulnerable to adversarial prompts that trigger biased or factually incorrect responses. To address these gaps, we propose EDU-Prompting, a novel multi-agent framework that bridges established educational critical thinking theories with LLM agent design to generate critical, bias-aware explanations while fostering diverse perspectives. Our systematic evaluation across theoretical benchmarks and practical college-level critical writing scenarios demonstrates that EDU-Prompting significantly enhances both content truthfulness and logical soundness in AI-generated educational responses. The framework's modular design enables seamless integration into existing prompting frameworks and educational applications, allowing practitioners to directly incorporate critical thinking catalysts that promote analytical reasoning and introduce multiple perspectives without requiring extensive system modifications.",
      "authors": [
        "Xinmeng Hou",
        "Zhouquan Lu",
        "Wenli Chen",
        "Hai Hu and Qing Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:55:13+00:00",
          "link": "https://arxiv.org/abs/2507.15015v1",
          "size": "3574kb",
          "version": "v1"
        }
      ],
      "title": "EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15015",
        "HTML": "https://arxiv.org/html/2507.15015",
        "PDF": "https://arxiv.org/pdf/2507.15015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents EDU-Prompting, a framework using LLMs for educational purposes. It touches on LLM application to critical educational content generation, but the primary focus is on educational agent design, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15056",
      "abstract": "Historically, a $\\sqrt{N}log^{1/2}(N)$ distance barrier for quantum low-density parity-check (LDPC) codes with $N$ qubits persisted for nearly two decades, until the recent discovery of the fibre-bundle code. An open question is whether such a distance barrier can be broken while preserving the ability to perform transversal non-Clifford gates. In this direction, another long-standing distance barrier of $N^{1/3}$ for LDPC stabilizer codes -- present since the discovery of the 3D color code -- was only recently overcome by a construction achieving an $\\Omega(\\sqrt{N})$ distance (arXiv:2501.19375). The present work further breaks the $\\sqrt{N}$ distance barrier by taking a homological product of three good qLDPC codes, combined with the Freedman-Hastings code-to-manifold mapping and the triple cup product to implement transversal CCZ gates. The resulting code achieves an $\\Omega(N^{2/3})$ distance (a linear $X$-distance of $\\Theta(N)$) and a dimension of $\\Theta(N^{2/3})$, which enables fault-tolerant preparation of $\\Theta(N^{1/3})$ independent logical CCZ magic states in a single shot, without distillation (`magic state fountain'). This new quantum code also inspires the discovery of a family of exotic $3q$-dimensional manifolds $\\mathcal{M}$, which exhibit both a power-law $\\mathbb{Z}_2$-($q$, $2q$)-systolic freedom and $\\Theta(vol(\\mathcal{M}))$ triple intersection points of $2q$-dimensional submanifolds.",
      "authors": [
        "Guanyu Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Information Theory (cs.IT)",
        "High Energy Physics - Theory (hep-th)",
        "Geometric Topology (math.GT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.15056v1",
          "size": "3010kb",
          "version": "v1"
        }
      ],
      "title": "Transversal non-Clifford gates on qLDPC codes breaking the $\\sqrt{N}$ distance barrier and quantum-inspired geometry with $\\mathbb{Z}_2$ systolic freedom",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15056",
        "HTML": "https://arxiv.org/html/2507.15056",
        "PDF": "https://arxiv.org/pdf/2507.15056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses quantum LDPC codes and their properties related to transversal non-Clifford gates, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15549",
      "abstract": "We present a quasi polynomial time approximation scheme (Q-PTAS) for the capacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane for arbitrary capacity $c$. The running time is $n^{f(\\epsilon)\\cdot\\log\\log n}$ for any $c$, and where $f$ is a function of $\\epsilon$ only. This is a major improvement over the so far best known running time of $n^{\\log^{O(1/\\epsilon)}n}$ time and a big step towards a PTAS for Euclidean CVRP.\n  In our algorithm, we first give a polynomial time reduction of the CVRP in $\\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in $\\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find exactly $m$ paths between two points $a$ and $b$, covering all the given points in the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the pane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem is most likely to imply a PTAS for the Euclidean CVRP.",
      "authors": [
        "Ren\\'e Sitters"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:28:05+00:00",
          "link": "https://arxiv.org/abs/2507.15549v1",
          "size": "3539kb",
          "version": "v1"
        }
      ],
      "title": "An $n^{O(\\log\\log n)}$ time approximation scheme for capacitated VRP in the Euclidean plane",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15549",
        "HTML": "https://arxiv.org/html/2507.15549",
        "PDF": "https://arxiv.org/pdf/2507.15549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a time approximation scheme for the capacitated vehicle routing problem in the Euclidean plane. It does not contribute to data processing operations for LLMs or involve dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15825",
      "abstract": "This paper presents adaptive conformal selection (ACS), an interactive framework for model-free selection with guaranteed error control. Building on conformal selection (Jin and Cand\\`es, 2023b), ACS generalizes the approach to support human-in-the-loop adaptive data analysis. Under the ACS framework, we can partially reuse the data to boost the selection power, make decisions on the fly while exploring the data, and incorporate new information or preferences as they arise. The key to ACS is a carefully designed principle that controls the information available for decision making, allowing the data analyst to explore the data adaptively while maintaining rigorous control of the false discovery rate (FDR). Based on the ACS framework, we provide concrete selection algorithms for various goals, including model update/selection, diversified selection, and incorporating newly available labeled data. The effectiveness of ACS is demonstrated through extensive numerical simulations and real-data applications in large language model (LLM) deployment and drug discovery.",
      "authors": [
        "Yu Gui",
        "Ying Jin",
        "Yash Nair and Zhimei Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:33:15+00:00",
          "link": "https://arxiv.org/abs/2507.15825v1",
          "size": "5248kb",
          "version": "v1"
        }
      ],
      "title": "ACS: An interactive framework for conformal selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15825",
        "HTML": "https://arxiv.org/html/2507.15825",
        "PDF": "https://arxiv.org/pdf/2507.15825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "ACS is a framework for model-free selection that mentions its application in LLM deployment. While it involves data analysis, the main contribution is more about selection strategies than directly improving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.14725",
      "abstract": "In the field of computational logic, two classes of finite automata are considered fundamental: deterministic and nondeterministic automata (DFAs and NFAs). In a more fine-grained approach three natural intermediate classes were introduced, defined by restricting the number of accepting runs of the input NFA. The classes are called: unambiguous, finitely ambiguous, and polynomially ambiguous finite automata. It was observed that central problems, like equivalence, become tractable when the input NFA is restricted to some of these classes. This naturally brought interest into problems determining whether an input NFA belongs to the intermediate classes.\n  Our first result is a nearly complete characterization of the fine-grained complexity of these problems. We show that the respective quadratic and cubic running times of Allauzen et al. are optimal under the Orthogonal Vectors hypothesis or the k-Cycle hypothesis, for alphabets with at least two symbols. In contrast, for unary alphabets we show that all aforementioned variants of ambiguity can be decided in almost linear time.\n  Finally, we study determinisability of unambiguous weighted automata. We positively resolve a conjecture of Allauzen and Mohri, proving that their quadratic-time algorithm for verifying determinisability of unambiguous weighted automata is optimal, assuming the Orthogonal Vectors hypothesis or the k-Cycle hypothesis. We additionally show that for unary alphabets, this can be decided in linear time.",
      "authors": [
        "Karolina Drabik and Anita D\\\"urr and Fabian Frei and Filip Mazowiecki and Karol W\\k{e}grzycki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T18:59:12+00:00",
          "link": "https://arxiv.org/abs/2501.14725v1",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:16:01+00:00",
          "link": "https://arxiv.org/abs/2501.14725v2",
          "size": "195kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T11:25:54+00:00",
          "link": "https://arxiv.org/abs/2501.14725v3",
          "size": "195kb",
          "version": "v3"
        }
      ],
      "title": "Fine-Grained Complexity of Ambiguity Problems on Automata and Directed Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14725",
        "PDF": "https://arxiv.org/pdf/2501.14725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the complexity of ambiguity problems in automata theory and does not make any contributions to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.11484",
      "abstract": "System identification is normally involved in augmenting time series data by time shifting and nonlinearisation (e.g., polynomial basis), both of which introduce redundancy in features and samples. Many research works focus on reducing redundancy feature-wise, while less attention is paid to sample-wise redundancy. This paper proposes a novel data pruning method, called mini-batch FastCan, to reduce sample-wise redundancy based on dictionary learning. Time series data is represented by some representative samples, called atoms, via dictionary learning. The useful samples are selected based on their correlation with the atoms. The method is tested on one simulated dataset and two benchmark datasets. The R-squared between the coefficients of models trained on the full datasets and the coefficients of models trained on pruned datasets is adopted to evaluate the performance of data pruning methods. It is found that the proposed method significantly outperforms the random pruning method.",
      "authors": [
        "Tingna Wang (1 and 2)",
        "Sikai Zhang (4)",
        "Mingming Song (1 and 3)",
        "Limin Sun (1",
        "2 and 3) ((1) College of Civil Engineering",
        "Tongji University",
        "Shanghai",
        "China",
        "(2) Shanghai Qi Zhi Institute",
        "Shanghai",
        "China",
        "(3) State Key Laboratory of Disaster Reduction in Civil Engineering",
        "Tongji University",
        "Shanghai",
        "China",
        "(2) Baosight Software",
        "Shanghai",
        "China)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T06:38:43+00:00",
          "link": "https://arxiv.org/abs/2502.11484v1",
          "size": "859kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:33:31+00:00",
          "link": "https://arxiv.org/abs/2502.11484v2",
          "size": "1403kb",
          "version": "v2"
        }
      ],
      "title": "Dictionary-Learning-Based Data Pruning for System Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11484",
        "HTML": "https://arxiv.org/html/2502.11484",
        "PDF": "https://arxiv.org/pdf/2502.11484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a data pruning method for system identification using dictionary learning. It focuses on reducing redundancy in time series data, which is not specific to LLM training data processing."
      },
      "tasks": [
        "Dictionary Learning",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20734",
      "abstract": "We consider a bandit optimization problem for nonconvex and non-smooth functions, where in each trial the loss function is the sum of a linear function and a small but arbitrary perturbation chosen after observing the player's choice. We give both expected and high probability regret bounds for the problem. Our result also implies an improved high-probability regret bound for the bandit linear optimization, a special case with no perturbation. We also give a lower bound on the expected regret.",
      "authors": [
        "Zhuoyu Cheng",
        "Kohei Hatano",
        "Eiji Takimoto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T05:22:01+00:00",
          "link": "https://arxiv.org/abs/2505.20734v1",
          "size": "101kb",
          "version": "v1"
        },
        {
          "date": "2025-06-01T06:19:26+00:00",
          "link": "https://arxiv.org/abs/2505.20734v2",
          "size": "114kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T05:08:36+00:00",
          "link": "https://arxiv.org/abs/2505.20734v3",
          "size": "114kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T01:53:31+00:00",
          "link": "https://arxiv.org/abs/2505.20734v4",
          "size": "115kb",
          "version": "v4"
        }
      ],
      "title": "Adversarial bandit optimization for approximately linear functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20734",
        "HTML": "https://arxiv.org/html/2505.20734",
        "PDF": "https://arxiv.org/pdf/2505.20734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bandit optimization problems for approximately linear functions. It does not address any aspects of LLM training data processing or dataset-related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20923",
      "abstract": "In this paper, we propose KaLM-Embedding-V2, a versatile and compact embedding model, which achieves impressive performance in general-purpose text embedding tasks by leveraging superior training techniques and data. Our key innovations include: (1) To better align the architecture with representation learning, we remove the causal attention mask and adopt a fully bidirectional transformer with simple yet effective mean-pooling to produce fixed-length embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on large-scale weakly supervised open-source corpora; (ii) fine-tuning on high-quality retrieval and non-retrieval datasets; and (iii) model-soup parameter averaging for robust generalization. Besides, we introduce a focal-style reweighting mechanism that concentrates learning on difficult samples and an online hard-negative mixing strategy to continuously enrich hard negatives without expensive offline mining; (3) We collect over 20 categories of data for pre-training and 100 categories of data for fine-tuning, to boost both the performance and generalization of the embedding model. Extensive evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English show that our model significantly outperforms others of comparable size, and competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new standard for a versatile and compact embedding model with less than 1B parameters.",
      "authors": [
        "Xinping Zhao",
        "Xinshuo Hu",
        "Zifei Shan",
        "Shouzheng Huang",
        "Yao Zhou",
        "Zetian Sun",
        "Zhenyu Liu",
        "Dongfang Li",
        "Xinyuan Wei",
        "Qian Chen",
        "Youcheng Pan",
        "Yang Xiang",
        "Meishan Zhang",
        "Haofen Wang",
        "Jun Yu",
        "Baotian Hu",
        "Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T01:09:44+00:00",
          "link": "https://arxiv.org/abs/2506.20923v1",
          "size": "355kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:02:25+00:00",
          "link": "https://arxiv.org/abs/2506.20923v2",
          "size": "355kb",
          "version": "v2"
        }
      ],
      "title": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20923",
        "HTML": "https://arxiv.org/html/2506.20923",
        "PDF": "https://arxiv.org/pdf/2506.20923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper details a multi-stage training pipeline for KaLM-Embedding-V2, which includes pre-training on large-scale data and fine-tuning on curated datasets. It involves data collection and processing efforts integral to LLM training."
      },
      "models": [
        {
          "model_path": "HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v2",
          "downloads": "362",
          "likes": "23",
          "trending_score": "0.0",
          "link": "https://huggingface.co/HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v2"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14257",
      "abstract": "We introduce the Linearized Diffusion Map (LDM), a novel linear dimensionality reduction method constructed via a linear approximation of the diffusion-map kernel. LDM integrates the geometric intuition of diffusion-based nonlinear methods with the computational simplicity, efficiency, and interpretability inherent in linear embeddings such as PCA and classical MDS. Through comprehensive experiments on synthetic datasets (Swiss roll and hyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that LDM captures distinct geometric features of datasets compared to PCA, offering complementary advantages. Specifically, LDM embeddings outperform PCA in datasets exhibiting explicit manifold structures, particularly in high-dimensional regimes, whereas PCA remains preferable in scenarios dominated by variance or noise. Furthermore, the complete positivity of LDM's kernel matrix allows direct applicability of Non-negative Matrix Factorization (NMF), suggesting opportunities for interpretable latent-structure discovery. Our analysis positions LDM as a valuable new linear dimensionality reduction technique with promising theoretical and practical extensions.",
      "authors": [
        "Julio Candanedo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:56:41+00:00",
          "link": "https://arxiv.org/abs/2507.14257v1",
          "size": "624kb",
          "version": "v1"
        }
      ],
      "title": "Linearized Diffusion Map",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14257",
        "HTML": "https://arxiv.org/html/2507.14257",
        "PDF": "https://arxiv.org/pdf/2507.14257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel linear dimensionality reduction method but does not relate to LLM training data processing or involve any relevant dataset creation or data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14392",
      "abstract": "Large Language Models (LLMs) built on transformer architectures have transformed natural language processing, achieving remarkable performance across diverse applications. While distributed inference frameworks enable practical deployment of these models, inter-GPU communication creates significant performance constraints that limit service quality in real-world systems. This paper investigates communication dynamics in distributed LLM serving-analyzing how various parallelization approaches coordinate data exchange between GPU workers during inference. We study dense transformer-based models as representative examples of contemporary architectures widely used in operational deployments. Our work combines detailed profiling measurements with predictive analytical models to characterize communication behavior across different parallelization configurations. Results show that tensor parallelism incurs substantial network overhead but delivers superior response times for brief sequences, pipeline parallelism minimizes data transfer requirements while increasing total latency, and combined approaches demand careful tuning to achieve balanced performance. These insights offer practical recommendations for selecting appropriate parallelization schemes in production LLM services and identify key opportunities for optimizing inference frameworks and communication infrastructure.",
      "authors": [
        "Lang Xu",
        "Kaushik Kandadi Suresh",
        "Quentin Anthony",
        "Nawras Alnaasan",
        "Dhabaleswar K. Panda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:43:38+00:00",
          "link": "https://arxiv.org/abs/2507.14392v1",
          "size": "683kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing Communication Patterns in Distributed Large Language Model Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14392",
        "HTML": "https://arxiv.org/html/2507.14392",
        "PDF": "https://arxiv.org/pdf/2507.14392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates communication patterns in distributed LLM inference, concentrating on performance constraints due to inter-GPU communication. It does not discuss any aspect of training data processing for LLMs, such as data engineering or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14520",
      "abstract": "Language models are often said to face a symbol grounding problem. While some argue that world understanding can emerge from text alone, others suggest grounded learning is more efficient. We explore this through Othello, where the board state defines a simplified, rule-based world. Building on prior work, we introduce VISOTHELLO, a multi-modal model trained on move histories and board images. Using next-move prediction, we compare it to mono-modal baselines and test robustness to semantically irrelevant perturbations. We find that multi-modal training improves both performance and the robustness of internal representations. These results suggest that grounding language in visual input helps models infer structured world representations.",
      "authors": [
        "Xinyi Chen",
        "Yifei Yuan",
        "Jiaang Li",
        "Serge Belongie",
        "Maarten de Rijke",
        "Anders S{\\o}gaard"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T07:47:55+00:00",
          "link": "https://arxiv.org/abs/2507.14520v1",
          "size": "514kb",
          "version": "v1"
        }
      ],
      "title": "What if Othello-Playing Language Models Could See?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14520",
        "HTML": "https://arxiv.org/html/2507.14520",
        "PDF": "https://arxiv.org/pdf/2507.14520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores multi-modal training in language models using the Othello board game and does not concern itself with LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15417",
      "abstract": "Chromatic Correlation Clustering (CCC) generalizes Correlation Clustering by assigning multiple categorical relationships (colors) to edges and imposing chromatic constraints on the clusters. Unlike traditional Correlation Clustering, which only deals with binary $(+/-)$ relationships, CCC captures richer relational structures. Despite its importance, improving the approximation for CCC has been difficult due to the limitations of standard LP relaxations. We present a randomized $1.64$-approximation algorithm to the CCC problem, significantly improving the previous factor of $2.15$. Our approach extends the cluster LP framework to the chromatic setting by introducing a chromatic cluster LP relaxation and an rounding algorithm that utilizes both a cluster-based and a greedy pivot-based strategy. The analysis bypasses the integrality gap of $2$ for the CCC version of standard LP and highlights the potential of the cluster LP framework to address other variants of clustering problems.",
      "authors": [
        "Dahoon Lee",
        "Chenglin Fan",
        "Euiwoong Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:19:30+00:00",
          "link": "https://arxiv.org/abs/2507.15417v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "1.64-Approximation for Chromatic Correlation Clustering via Chromatic Cluster LP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15417",
        "PDF": "https://arxiv.org/pdf/2507.15417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on approximation algorithms for chromatic correlation clustering, which does not pertain to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15594",
      "abstract": "Autonomous vehicles require reliable hazard detection. However, primary sensor systems may miss near-field obstacles, resulting in safety risks. Although a dedicated fast-reacting near-field monitoring system can mitigate this, it typically suffers from false positives. To mitigate these, in this paper, we introduce three monitoring strategies based on dynamic spatial properties, relevant object sizes, and motion-aware prediction. In experiments in a validated simulation, we compare the initial monitoring strategy against the proposed improvements. The results demonstrate that the proposed strategies can significantly improve the reliability of near-field monitoring systems.",
      "authors": [
        "Junnan Pan",
        "Prodromos Sotiriadis",
        "Vladislav Nenchev",
        "Ferdinand Englberger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:17:44+00:00",
          "link": "https://arxiv.org/abs/2507.15594v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "Improving Functional Reliability of Near-Field Monitoring for Emergency Braking in Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15594",
        "HTML": "https://arxiv.org/html/2507.15594",
        "PDF": "https://arxiv.org/pdf/2507.15594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving reliability of near-field monitoring systems for autonomous vehicles, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15681",
      "abstract": "Handling missing values is a common challenge in biostatistical analyses, typically addressed by imputation methods. We propose a novel, fast, and easy-to-use imputation method called missing value imputation with adversarial random forests (MissARF), based on generative machine learning, that provides both single and multiple imputation. MissARF employs adversarial random forest (ARF) for density estimation and data synthesis. To impute a missing value of an observation, we condition on the non-missing values and sample from the estimated conditional distribution generated by ARF. Our experiments demonstrate that MissARF performs comparably to state-of-the-art single and multiple imputation methods in terms of imputation quality and fast runtime with no additional costs for multiple imputation.",
      "authors": [
        "Pegah Golchian",
        "Jan Kapar",
        "David S. Watson",
        "Marvin N. Wright"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:44:51+00:00",
          "link": "https://arxiv.org/abs/2507.15681v1",
          "size": "6939kb",
          "version": "v1"
        }
      ],
      "title": "Missing value imputation with adversarial random forests -- MissARF",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15681",
        "PDF": "https://arxiv.org/pdf/2507.15681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for imputation of missing data using adversarial random forests, a technique relevant to biostatistical data analysis but unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.01182",
      "abstract": "While transformers demonstrate outstanding performance across various audio tasks, their application to neural vocoders remains challenging. Neural vocoders require the generation of long audio signals at the sample level, which demands high temporal resolution. This results in significant computational costs for attention map generation and limits their ability to efficiently process both global and local information. Additionally, the sequential nature of sample generation in neural vocoders poses difficulties for real-time processing, making the direct adoption of transformers impractical. To address these challenges, we propose RingFormer, a neural vocoder that incorporates the ring attention mechanism into a lightweight transformer variant, the convolution-augmented transformer (Conformer). Ring attention effectively captures local details while integrating global information, making it well-suited for processing long sequences and enabling real-time audio generation. RingFormer is trained using adversarial training with two discriminators. The proposed model is applied to the decoder of the text-to-speech model VITS and compared with state-of-the-art vocoders such as HiFi-GAN, iSTFT-Net, and BigVGAN under identical conditions using various objective and subjective metrics. Experimental results show that RingFormer achieves comparable or superior performance to existing models, particularly excelling in real-time audio generation. Our code and audio samples are available on GitHub.",
      "authors": [
        "Seongho Hong and Yong-Hoon Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T10:18:57+00:00",
          "link": "https://arxiv.org/abs/2501.01182v1",
          "size": "1249kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T06:41:48+00:00",
          "link": "https://arxiv.org/abs/2501.01182v2",
          "size": "1305kb",
          "version": "v2"
        }
      ],
      "title": "RingFormer: A Neural Vocoder with Ring Attention and Convolution-Augmented Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01182",
        "PDF": "https://arxiv.org/pdf/2501.01182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents RingFormer, a neural vocoder for real-time audio generation, focusing on an audio processing task unrelated to large language model training data processing."
      },
      "tasks": [
        "Audio Generation",
        "text-to-speech",
        "Text to Speech"
      ],
      "repo_urls": [
        "https://github.com/seongho608/ringformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.19027",
      "abstract": "Explainable artificial intelligence (XAI) has become increasingly important in decision-critical domains such as healthcare, finance, and law. Counterfactual (CF) explanations, a key approach in XAI, provide users with actionable insights by suggesting minimal modifications to input features that lead to different model outcomes. Despite significant advancements, existing CF generation methods often struggle to balance proximity, diversity, and robustness, limiting their real-world applicability. A widely adopted framework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but lacks robustness, making CF explanations sensitive to perturbations and domain constraints. To address these challenges, we introduce DiCE-Extended, an enhanced CF explanation framework that integrates multi-objective optimization techniques to improve robustness while maintaining interpretability. Our approach introduces a novel robustness metric based on the Dice-S{\\o}rensen coefficient, enabling stability under small input variations. Additionally, we refine CF generation using weighted loss components (lambda_p, lambda_d, lambda_r) to balance proximity, diversity, and robustness. We empirically validate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German Credit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch, TensorFlow). Results demonstrate improved CF validity, stability, and alignment with decision boundaries compared to standard DiCE-generated explanations. Our findings highlight the potential of DiCE-Extended in generating more reliable and interpretable CFs for high-stakes applications. Future work could explore adaptive optimization techniques and domain-specific constraints to further enhance CF generation in real-world scenarios",
      "authors": [
        "Volkan Bakir",
        "Polat Goktas",
        "and Sureyya Akyuz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-26T21:22:44+00:00",
          "link": "https://arxiv.org/abs/2504.19027v1",
          "size": "270kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T02:51:21+00:00",
          "link": "https://arxiv.org/abs/2504.19027v2",
          "size": "59kb",
          "version": "v2"
        }
      ],
      "title": "DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19027",
        "HTML": "https://arxiv.org/html/2504.19027",
        "PDF": "https://arxiv.org/pdf/2504.19027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with counterfactual explanations in machine learning, emphasizing robustness in CF generation rather than LLM training data processing."
      },
      "tasks": [
        "counterfactual",
        "Diversity",
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11742",
      "abstract": "High Performance Computing (HPC) centers provide resources to users who require greater scale to \"get science done\". They deploy infrastructure with singular hardware architectures, cutting-edge software environments, and stricter security measures as compared with users' own resources. As a result, users often create and configure digital artifacts in ways that are specialized for the unique infrastructure at a given HPC center. Each user of that center will face similar challenges as they develop specialized solutions to take full advantages of the center's resources, potentially resulting in significant duplication of effort. Much duplicated effort could be avoided, however, if users of these centers found it easier to discover others' solutions and artifacts as well as share their own.\n  The FAIR principles address this problem by presenting guidelines focused around metadata practices to be implemented by vaguely defined \"communities\"; in practice, these tend to gather by domain (e.g. bioinformatics, geosciences, agriculture). Domain-based communities can unfortunately end up functioning as silos that tend both to inhibit sharing of solutions and best practices as well as to encourage fragile and unsustainable improvised solutions in the absence of best-practice guidance. We propose that these communities pursuing \"science at scale\" be nurtured both individually and collectively by HPC centers so that users can take advantage of shared challenges across disciplines and potentially across HPC centers. We describe an architecture based on the EOSC-Life FAIR Workflows Collaboratory, specialized for use with and inside HPC centers such as the Oak Ridge Leadership Computing Facility (OLCF), and we speculate on user incentives to encourage adoption. We note that a focus on FAIR workflow components rather than FAIR workflows is more likely to benefit the users of HPC centers.",
      "authors": [
        "Sean R. Wilkinson and Patrick Widener"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T23:02:25+00:00",
          "link": "https://arxiv.org/abs/2505.11742v1",
          "size": "167kb",
          "version": "v1"
        }
      ],
      "title": "FAIR Ecosystems for Science at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11742",
        "HTML": "https://arxiv.org/html/2505.11742",
        "PDF": "https://arxiv.org/pdf/2505.11742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses FAIR principles and architectures for scalable science at HPC centers. It is concerned with resource usage and metadata practices rather than LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13334",
      "abstract": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1400 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.",
      "authors": [
        "Lingrui Mei",
        "Jiayu Yao",
        "Yuyao Ge",
        "Yiwei Wang",
        "Baolong Bi",
        "Yujun Cai",
        "Jiazhi Liu",
        "Mingyu Li",
        "Zhong-Zhi Li",
        "Duzhen Zhang",
        "Chenlin Zhou",
        "Jiayi Mao",
        "Tianze Xia",
        "Jiafeng Guo",
        "Shenghua Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.13334v1",
          "size": "2126kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T17:48:18+00:00",
          "link": "https://arxiv.org/abs/2507.13334v2",
          "size": "2131kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Context Engineering for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13334",
        "HTML": "https://arxiv.org/html/2507.13334",
        "PDF": "https://arxiv.org/pdf/2507.13334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The survey introduces Context Engineering, encompassing context retrieval and generation, which may relate to optimizing input during inference for LLMs. However, the primary focus is on model performance and context management rather than direct training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14263",
      "abstract": "The Internet is poised to host billions to trillions of autonomous AI agents that negotiate, delegate, and migrate in milliseconds and workloads that will strain DNS-centred identity and discovery. In this paper, we describe the NANDA index architecture, which we envision as a means for discoverability, identifiability and authentication in the internet of AI agents. We present an architecture where a minimal lean index resolves to dynamic, cryptographically verifiable AgentFacts that supports multi-endpoint routing, load balancing, privacy-preserving access, and credentialed capability assertions. Our architecture design delivers five concrete guarantees: (1) A quilt-like index proposal that supports both NANDA-native agents as well as third party agents being discoverable via the index, (2) rapid global resolution for newly spawned AI agents, (3) sub-second revocation and key rotation, (4) schema-validated capability assertions, and (5) privacy-preserving discovery across organisational boundaries via verifiable, least-disclosure queries. We formalize the AgentFacts schema, specify a CRDT-based update protocol, and prototype adaptive resolvers. The result is a lightweight, horizontally scalable foundation that unlocks secure, trust-aware collaboration for the next generation of the Internet of AI agents, without abandoning existing web infrastructure.",
      "authors": [
        "Ramesh Raskar",
        "Pradyumna Chari",
        "John Zinky",
        "Mahesh Lambe",
        "Jared James Grogan",
        "Sichao Wang",
        "Rajesh Ranjan",
        "Rekha Singhal",
        "Shailja Gupta",
        "Robert Lincourt",
        "Raghu Bala",
        "Aditi Joshi",
        "Abhishek Singh",
        "Ayush Chopra",
        "Dimitris Stripelis",
        "Bhuwan B",
        "Sumit Kumar",
        "Maria Gorskikh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T13:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.14263v1",
          "size": "1224kb",
          "version": "v1"
        }
      ],
      "title": "Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14263",
        "PDF": "https://arxiv.org/pdf/2507.14263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the NANDA index architecture for the identity and discovery of AI agents on the internet, which does not involve data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14426",
      "abstract": "We introduce CRAFT, a neuro-symbolic framework for interpretable affordance grounding, which identifies the objects in a scene that enable a given action (e.g., \"cut\"). CRAFT integrates structured commonsense priors from ConceptNet and language models with visual evidence from CLIP, using an energy-based reasoning loop to refine predictions iteratively. This process yields transparent, goal-driven decisions to ground symbolic and perceptual structures. Experiments in multi-object, label-free settings demonstrate that CRAFT enhances accuracy while improving interpretability, providing a step toward robust and trustworthy scene understanding.",
      "authors": [
        "Zhou Chen",
        "Joe Lin",
        "Sathyanarayanan N. Aakur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T01:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.14426v1",
          "size": "1972kb",
          "version": "v1"
        }
      ],
      "title": "CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14426",
        "HTML": "https://arxiv.org/html/2507.14426",
        "PDF": "https://arxiv.org/pdf/2507.14426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "CRAFT is a framework for affordance grounding focused on visual and symbolic reasoning, not LLM training data processing, data collection, or dataset enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15548",
      "abstract": "Background: Radiomics shows promise in characterizing glioblastoma, but its added value over clinical and molecular predictors has yet to be proven. This study assessed the added value of conventional radiomics (CR) and deep learning (DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on a large multi-center dataset.\n  Methods: After patient selection, our curated dataset gathers 1152 glioblastoma (WHO 2016) patients from five Swiss centers and one public source. It included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI data (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were developed using standard methods and evaluated on internal and external cohorts. Sub-analyses assessed models with different feature sets (imaging-only, clinical/molecular-only, combined-features) and patient subsets (S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).\n  Results: The best performance was observed in the full cohort (S-1). In external validation, the combined-feature CR model achieved an AUC of 0.75, slightly, but significantly outperforming clinical-only (0.74) and imaging-only (0.68) models. DL models showed similar trends, though without statistical significance. In S-2 and S-3, combined models did not outperform clinical-only models. Exploratory analysis of CR models for overall survival prediction suggested greater relevance of imaging data: across all subsets, combined-feature models significantly outperformed clinical-only models, though with a modest advantage of 2-4 C-index points.\n  Conclusions: While confirming the predictive value of anatomical MRI sequences for glioblastoma prognosis, this multi-center study found standard CR and DL radiomics approaches offer minimal added value over demographic predictors such as age and gender.",
      "authors": [
        "D. Abler",
        "O. Pusterla",
        "A. Joye-K\\\"uhnis",
        "N. Andratschke",
        "M. Bach",
        "A. Bink",
        "S. M. Christ",
        "P. Hagmann",
        "B. Pouymayou",
        "E. Pravat\\`a",
        "P. Radojewski",
        "M. Reyes",
        "L. Ruinelli",
        "R. Schaer",
        "B. Stieltjes",
        "G. Treglia",
        "W. Valenzuela",
        "R. Wiest",
        "S. Zoergiebel",
        "M. Guckenberger",
        "S. Tanadini-Lang",
        "A. Depeursinge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:27:07+00:00",
          "link": "https://arxiv.org/abs/2507.15548v1",
          "size": "5738kb",
          "version": "v1"
        }
      ],
      "title": "The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15548",
        "PDF": "https://arxiv.org/pdf/2507.15548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on radiomics and deep learning for glioblastoma prognosis using MRI and clinical data. There is no discussion of data processing relevant to LLMs or creation of datasets used for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.14549",
      "abstract": "In this manuscript, we introduce a novel Decision Flow (DF) framework for sampling decisions from a target distribution while incorporating additional guidance from a prior sampler. DF can be viewed as an AI-driven algorithmic reincarnation of the Markov Decision Process (MDP) approach in stochastic optimal control. It extends the continuous-space, continuous-time Path Integral Diffusion sampling technique of [Behjoo, Chertkov 2025] to discrete time and space, while also generalizing the Generative Flow Network (GFN) framework of [Bengio, et al 2021]. In its most basic form an explicit formulation that does not require Neural Networks (NNs), DF leverages the linear solvability of the underlying MDP [Todorov, 2007] to adjust the transition probabilities of the prior sampler. The resulting Markov process is expressed as a convolution of the reverse-time Green's function of the prior sampling with the target distribution. We illustrate the DF framework through an example of sampling from the Ising model -- compare DF to Metropolis-Hastings to quantify its efficiency, discuss potential NN-based extensions, and outline how DF can enhance guided sampling across various applications.",
      "authors": [
        "Michael Chertkov",
        "Sungsoo Ahn and Hamidreza Behjoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T19:32:22+00:00",
          "link": "https://arxiv.org/abs/2503.14549v1",
          "size": "273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:53:21+00:00",
          "link": "https://arxiv.org/abs/2503.14549v2",
          "size": "220kb",
          "version": "v2"
        }
      ],
      "title": "Sampling Decisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14549",
        "HTML": "https://arxiv.org/html/2503.14549",
        "PDF": "https://arxiv.org/pdf/2503.14549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This manuscript introduces a novel framework for sampling decisions, which involves AI-driven algorithmic methods, but does not relate to the data processing for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/hamidrezabehjoo/DecisionFlow"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08784",
      "abstract": "Distributed optimization is pivotal for large-scale signal processing and machine learning, yet communication overhead remains a major bottleneck. Low-rank gradient compression, in which the transmitted gradients are approximated by low-rank matrices to reduce communication, offers a promising remedy. Existing methods typically adopt either randomized or greedy compression strategies: randomized approaches project gradients onto randomly chosen subspaces, introducing high variance and degrading empirical performance; greedy methods select the most informative subspaces, achieving strong empirical results but lacking convergence guarantees. To address this gap, we propose GreedyLore--the first Greedy Low-Rank gradient compression algorithm for distributed learning with rigorous convergence guarantees. GreedyLore incorporates error feedback to correct the bias introduced by greedy compression and introduces a semi-lazy subspace update that ensures the compression operator remains contractive throughout all iterations. With these techniques, we prove that GreedyLore achieves a convergence rate of $\\mathcal{O}(\\sigma/\\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD and Adam--marking the first linear speedup convergence rate for low-rank gradient compression. Extensive experiments are conducted to validate our theoretical findings.",
      "authors": [
        "Chuyan Chen",
        "Yutong He",
        "Pengrui Li",
        "Weichen Jia",
        "Kun Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:46:12+00:00",
          "link": "https://arxiv.org/abs/2507.08784v1",
          "size": "586kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T14:53:50+00:00",
          "link": "https://arxiv.org/abs/2507.08784v2",
          "size": "585kb",
          "version": "v2"
        }
      ],
      "title": "Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08784",
        "HTML": "https://arxiv.org/html/2507.08784",
        "PDF": "https://arxiv.org/pdf/2507.08784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Greedy Low-Rank Gradient Compression for distributed learning to address communication overhead. It focuses on optimization techniques rather than LLM training data processing, making it irrelevant."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10233",
      "abstract": "Quantum digital signatures ensure unforgeable message authenticity and integrity using quantum principles, offering unconditional security against both classical and quantum attacks. They are crucial for secure communication in high-stakes environments, ensuring trust and long-term protection in the quantum era. Nowadays, the majority of arbitrated quantum signature (AQS) protocols encrypt data qubit by qubit using the quantum one-time pad (QOTP). Despite providing robust data encryption, QOTP is not a good fit for AQS because of its susceptibility to many types of attacks. In this work, we present an efficient AQS protocol to encrypt quantum message ensembles using a distinct encryption technique, the chained controlled unitary operations. In contrast to existing protocols, our approach successfully prevents disavowal and forgery attacks. We hope this contributes to advancing future investigations into the development of AQS protocols.",
      "authors": [
        "Debnath Ghosh",
        "Soumit Roy",
        "Prithwi Bagchi",
        "Indranil Chakrabarty",
        "Ashok Kumar Das"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:56:09+00:00",
          "link": "https://arxiv.org/abs/2507.10233v1",
          "size": "872kb",
          "version": "v1"
        }
      ],
      "title": "Secure and Efficient Quantum Signature Scheme Based on the Controlled Unitary Operations Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10233",
        "HTML": "https://arxiv.org/html/2507.10233",
        "PDF": "https://arxiv.org/pdf/2507.10233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an efficient quantum signature scheme using controlled unitary operations encryption, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14176",
      "abstract": "Artificial intelligence (AI) systems increasingly inform medical decision-making, yet concerns about algorithmic bias and inequitable outcomes persist, particularly for historically marginalized populations. This paper introduces the concept of Predictive Representativity (PR), a framework of fairness auditing that shifts the focus from the composition of the data set to outcomes-level equity. Through a case study in dermatology, we evaluated AI-based skin cancer classifiers trained on the widely used HAM10000 dataset and on an independent clinical dataset (BOSQUE Test set) from Colombia. Our analysis reveals substantial performance disparities by skin phototype, with classifiers consistently underperforming for individuals with darker skin, despite proportional sampling in the source data. We argue that representativity must be understood not as a static feature of datasets but as a dynamic, context-sensitive property of model predictions. PR operationalizes this shift by quantifying how reliably models generalize fairness across subpopulations and deployment contexts. We further propose an External Transportability Criterion that formalizes the thresholds for fairness generalization. Our findings highlight the ethical imperative for post-hoc fairness auditing, transparency in dataset documentation, and inclusive model validation pipelines. This work offers a scalable tool for diagnosing structural inequities in AI systems, contributing to discussions on equity, interpretability, and data justice and fostering a critical re-evaluation of fairness in data-driven healthcare.",
      "authors": [
        "Andr\\'es Morales-Forero (1)",
        "Lili J. Rueda (2)",
        "Ronald Herrera (3)",
        "Samuel Bassetto (1)",
        "Eric Coatanea (4) ((1) Polytechnique Montr\\'eal",
        "(2) Universidad El Bosque",
        "(3) Boehringer Ingelheim International GmbH",
        "(4) Tampere University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:21:06+00:00",
          "link": "https://arxiv.org/abs/2507.14176v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14176",
        "HTML": "https://arxiv.org/html/2507.14176",
        "PDF": "https://arxiv.org/pdf/2507.14176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on fairness auditing and racial bias in AI models for skin cancer detection, which is unrelated to LLM training data processing or dataset development for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14179",
      "abstract": "Large Language Models (LLMs) exhibit significant activation sparsity, where only a subset of neurons are active for a given input. Although this sparsity presents opportunities to reduce computational cost, efficiently utilizing it requires predicting activation patterns in a scalable manner. However, direct prediction at the neuron level is computationally expensive due to the vast number of neurons in modern LLMs. To enable efficient prediction and utilization of activation sparsity, we propose a clustering-based activation pattern compression framework. Instead of treating each neuron independently, we group similar activation patterns into a small set of representative clusters. Our method achieves up to 79.34% clustering precision, outperforming standard binary clustering approaches while maintaining minimal degradation in perplexity (PPL) scores. With a sufficiently large number of clusters, our approach attains a PPL score as low as 12.49, demonstrating its effectiveness in preserving model quality while reducing computational overhead. By predicting cluster assignments rather than individual neuron states, future models can efficiently infer activation patterns from pre-computed centroids. We detail the clustering algorithm, analyze its effectiveness in capturing meaningful activation structures, and demonstrate its potential to improve sparse computation efficiency. This clustering-based formulation serves as a foundation for future work on activation pattern prediction, paving the way for efficient inference in large-scale language models.",
      "authors": [
        "Nobel Dhar",
        "Bobin Deng",
        "Md Romyull Islam",
        "Xinyue Zhang",
        "Kazi Fahim Ahmad Nasif",
        "and Kun Suo"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:07:29+00:00",
          "link": "https://arxiv.org/abs/2507.14179v1",
          "size": "1058kb",
          "version": "v1"
        }
      ],
      "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14179",
        "HTML": "https://arxiv.org/html/2507.14179",
        "PDF": "https://arxiv.org/pdf/2507.14179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a sparsity predicting method for large language models, focusing on computation efficiency rather than LLM training data processing or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14233",
      "abstract": "We present an agent-based model (ABM) simulating proactive community adaptation to climate change in an urban context. The model is applied to Bergen, Norway, represented as a complex socio-ecological system. It integrates multiple agent types: municipal government (urban planners and political actors), civil society (individual citizens), environmental NGOs and activists, and media. Agents interact during urban planning processes - particularly the evaluation and approval of new development proposals. Urban planners provide technical assessments, while politicians (organized by party) make final decisions to approve, modify, or reject projects. Environmental NGOs, activist groups, and the media shape public perception and influence policymakers through campaigns, lobbying, protests, and news coverage. Individual citizens decide whether to engage in collective action based on personal values and social influences. The model captures the resulting decision-making ecosystem and reveals feedback loops and leverage points that determine climate-adaptive outcomes. By analyzing these dynamics, we identify critical intervention points where targeted policy measures can facilitate systemic transformation toward more climate-resilient urban development.",
      "authors": [
        "\\\"Onder G\\\"urcan and David Eric John Herbert and F. LeRon Shults and Christopher Frantz and Ivan Puga-Gonzalez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:00:31+00:00",
          "link": "https://arxiv.org/abs/2507.14233v1",
          "size": "311kb",
          "version": "v1"
        }
      ],
      "title": "Towards an ABM on Proactive Community Adaptation for Climate Change",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14233",
        "HTML": "https://arxiv.org/html/2507.14233",
        "PDF": "https://arxiv.org/pdf/2507.14233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an agent-based model for climate adaptation in urban areas, focusing on social interactions and decision-making, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14248",
      "abstract": "Vision transformer (ViT) models, when coupled with interpretation models, are regarded as secure and challenging to deceive, making them well-suited for security-critical domains such as medical applications, autonomous vehicles, drones, and robotics. However, successful attacks on these systems can lead to severe consequences. Recent research on threats targeting ViT models primarily focuses on generating the smallest adversarial perturbations that can deceive the models with high confidence, without considering their impact on model interpretations. Nevertheless, the use of interpretation models can effectively assist in detecting adversarial examples. This study investigates the vulnerability of transformer models to adversarial attacks, even when combined with interpretation models. We propose an attack called \"AdViT\" that generates adversarial examples capable of misleading both a given transformer model and its coupled interpretation model. Through extensive experiments on various transformer models and two transformer-based interpreters, we demonstrate that AdViT achieves a 100% attack success rate in both white-box and black-box scenarios. In white-box scenarios, it reaches up to 98% misclassification confidence, while in black-box scenarios, it reaches up to 76% misclassification confidence. Remarkably, AdViT consistently generates accurate interpretations in both scenarios, making the adversarial examples more difficult to detect.",
      "authors": [
        "Eldor Abdukhamidov",
        "Mohammed Abuhamad",
        "Simon S. Woo",
        "Hyoungshick Kim",
        "Tamer Abuhmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T05:11:11+00:00",
          "link": "https://arxiv.org/abs/2507.14248v1",
          "size": "53274kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14248",
        "HTML": "https://arxiv.org/html/2507.14248",
        "PDF": "https://arxiv.org/pdf/2507.14248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the vulnerability of Vision Transformers to adversarial attacks, which pertain to model robustness rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15337",
      "abstract": "When evaluating Large Language Models (LLMs) in question-answering domains, it is common to ask the model to choose among a fixed set of choices (so-called multiple-choice question-answering, or MCQA). Although downstream tasks of interest typically do not provide systems with explicit options among which to choose, this approach is nevertheless widely used because it makes it makes automatic grading straightforward and has tended to produce challenging benchmarks that correlate sufficiently well with downstream performance. This paper investigates the extent to which this trend continues to hold for state-of-the-art reasoning models, describing a systematic evaluation of $15$ different question-answering benchmarks (e.g., MMLU, HLE) and $25$ different LLMs (including small models such as Qwen 7B and relatively large models such as Llama 70B). For each model-benchmark pair, we considered $5$ ways of presenting the model with questions, including variations on whether multiple choices were offered to the model at all; whether \"none of the above\" sometimes replaced the right answer; and whether the model was permitted to perform chain-of-thought reasoning before and/or after the choices were presented. MCQA remained a good proxy for the downstream performance of models as long as they were allowed to perform chain-of-thought reasoning only before being presented with the options among which they had to select. On the other hand, large models that were able to perform reasoning after being given a set of options tended to significantly outperform their free-text performance due to exploiting the information in the options. We conclude that MCQA is no longer a good proxy for assessing downstream performance of state-of-the-art models, and offer practical guidelines for designing more robust, bias-resistant benchmarks that better reflect LLMs' genuine reasoning capabilities.",
      "authors": [
        "Narun Raman",
        "Taylor Lundy",
        "Kevin Leyton-Brown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:49:32+00:00",
          "link": "https://arxiv.org/abs/2507.15337v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning Models are Test Exploiters: Rethinking Multiple-Choice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15337",
        "HTML": "https://arxiv.org/html/2507.15337",
        "PDF": "https://arxiv.org/pdf/2507.15337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating LLMs in question-answering tasks, specifically in the context of multiple-choice formats, but does not involve any aspect of data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.09209",
      "abstract": "Prescriptive Process Monitoring is a prominent problem in Process Mining, which consists in identifying a set of actions to be recommended with the goal of optimising a target measure of interest or Key Performance Indicator (KPI). One challenge that makes this problem difficult is the need to provide Prescriptive Process Monitoring techniques only based on temporally annotated (process) execution data, stored in, so-called execution logs, due to the lack of well crafted and human validated explicit models. In this paper we aim at proposing an AI based approach that learns, by means of Reinforcement Learning (RL), an optimal policy (almost) only from the observation of past executions and recommends the best activities to carry on for optimizing a KPI of interest. This is achieved first by learning a Markov Decision Process for the specific KPIs from data, and then by using RL training to learn the optimal policy. The approach is validated on real and synthetic datasets and compared with off-policy Deep RL approaches. The ability of our approach to compare with, and often overcome, Deep RL approaches provides a contribution towards the exploitation of white box RL techniques in scenarios where only temporal execution data are available.",
      "authors": [
        "Stefano Branchi",
        "Andrei Buliga",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Francesca Meneghello",
        "Massimiliano Ronzani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-16T10:30:36+00:00",
          "link": "https://arxiv.org/abs/2303.09209v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Recommending the optimal policy by learning to act from temporal data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.09209",
        "PDF": "https://arxiv.org/pdf/2303.09209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on recommending policies using reinforcement learning from temporal data, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.09823",
      "abstract": "This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.",
      "authors": [
        "Angel Felipe Magnoss\\~ao de Paula",
        "Imene Bensalem",
        "Paolo Rosso",
        "Wajdi Zaghouani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-17T08:02:54+00:00",
          "link": "https://arxiv.org/abs/2303.09823v1",
          "size": "101kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T08:05:19+00:00",
          "link": "https://arxiv.org/abs/2303.09823v2",
          "size": "425kb",
          "version": "v2"
        }
      ],
      "title": "Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.09823",
        "PDF": "https://arxiv.org/pdf/2303.09823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes methods for hate speech detection using transformers and ensemble methods, without focusing on LLM training data processing techniques."
      },
      "tasks": [
        "Hate Speech Detection"
      ],
      "repo_urls": [
        "https://github.com/angelfelipemp/arabic-hate-speech-covid-19"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12899",
      "abstract": "Language Models (LMs) are widely used in software engineering for code generation, but they may produce code with errors. Rather than repairing the generated code, an alternative way is to address the underlying failures of models. LM repair offers a lightweight solution to this challenge: it requires minimal data, reduces computational costs, and reduces the side effects. Unlike retraining, LM repair focuses on applying tailored updates to targeted neurons, making it ideal for scenarios with limited resources, high-performance demands, or strict safety requirements. In this paper, we propose Semantic Targeting for Analytical Repair (STAR), a pioneering and novel semantic-based optimization approach for repairing LLMs. STAR realizes the main operations of repairing LMs in an optimization process, including locating ``buggy neurons'', solving ``neuron patches'', and patching ``buggy neurons''. Correspondingly, it computes the deltas of weight matrix as the prior information to guide optimization; and attributes the targeted layers and neurons leveraging statistical insights. The neuron patches are computed with a solid semantic-based analytical formula, which directly bridges the changes to logits with the deltas of neurons, by steering latent representations. Compared to the prior work of LM repair (MINT) and optimization methods (SGD), STAR integrates their strengths while mitigating their limitations. STAR supports solving multiple failures together, significantly improving the usefulness. Evaluated on coding tasks using popular code LMs, STAR exhibits superior effectiveness (10.5%-19.9% improvements) and efficiency (2.4-7.0 times speedup). In terms of side effects, namely the balance between generalization and specificity, STAR outperforms prior work by a significant margin. Additionally, we conducted assessments on the overfitting risk of LM repair as well as the cumulative impact.",
      "authors": [
        "Jian Gu",
        "Aldeida Aleti",
        "Chunyang Chen",
        "Hongyu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T07:59:42+00:00",
          "link": "https://arxiv.org/abs/2503.12899v1",
          "size": "3673kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T13:57:28+00:00",
          "link": "https://arxiv.org/abs/2503.12899v2",
          "size": "3673kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T21:02:25+00:00",
          "link": "https://arxiv.org/abs/2503.12899v3",
          "size": "2483kb",
          "version": "v3"
        }
      ],
      "title": "A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12899",
        "PDF": "https://arxiv.org/pdf/2503.12899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with optimizing and repairing LLMs for code generation errors rather than focusing on training data processing. Its emphasis is on model repair rather than data collection or dataset enhancement."
      },
      "tasks": [
        "Code Generation",
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19555",
      "abstract": "Deterministic communications are essential for industrial automation, ensuring strict latency requirements and minimal jitter in packet transmission. Modern production lines, specializing in robotics, require higher flexibility and mobility, which drives the integration of Time-Sensitive Networking (TSN) and 5G networks in Industry 4.0. TSN achieves deterministic communications by using mechanisms such as the IEEE 802.1Qbv Time-Aware Shaper (TAS), which schedules packet transmissions within precise cycles, thereby reducing latency, jitter, and congestion. 5G networks complement TSN by providing wireless mobility and supporting ultra-Reliable Low-Latency Communications. However, 5G channel effects such as fast fading, interference, and network-induced latency and jitter can disrupt TSN traffic, potentially compromising deterministic scheduling and performance. This paper presents an empirical analysis of 5G network latency and jitter on IEEE 802.1Qbv performance in a 5G-TSN network. We evaluate the impact of 5G integration on TSN's deterministic scheduling through a testbed combining IEEE 802.1Qbv-enabled switches, TSN translators, and a commercial 5G system. Our results show that, with proper TAS configuration in the TSN switch aligned with the 5G system, jitter can be mitigated, maintaining deterministic performance.",
      "authors": [
        "Pablo Rodriguez-Martin",
        "Oscar Adamuz-Hinojosa",
        "Pablo Mu\\~noz",
        "Julia Caleya-Sanchez",
        "Jorge Navarro-Ortiz",
        "Pablo Ameigeiras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T11:17:04+00:00",
          "link": "https://arxiv.org/abs/2503.19555v1",
          "size": "3642kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T17:11:30+00:00",
          "link": "https://arxiv.org/abs/2503.19555v2",
          "size": "3642kb",
          "version": "v2"
        }
      ],
      "title": "Empirical Analysis of the Impact of 5G Jitter on Time-Aware Shaper Scheduling in a 5G-TSN Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19555",
        "HTML": "https://arxiv.org/html/2503.19555",
        "PDF": "https://arxiv.org/pdf/2503.19555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts an empirical analysis of 5G network performance on TSN scheduling, which involves communications technology and is irrelevant to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01405",
      "abstract": "The identification of drug-target interactions (DTI) is critical for drug discovery and repositioning, as it reveals potential therapeutic uses of existing drugs, accelerating development and reducing costs. However, most existing models focus only on direct similarity in homogeneous graphs, failing to exploit the rich similarity in heterogeneous graphs. To address this gap, inspired by real-world social interaction behaviors, we propose SOC-DGL, which comprises two specialized modules: the Affinity-Driven Graph Learning (ADGL) module, learning global similarity through an affinity-enhanced drug-target graph, and the Equilibrium-Driven Graph Learning (EDGL) module, capturing higher-order similarity by amplifying the influence of even-hop neighbors using an even-polynomial graph filter based on balance theory. This dual approach enables SOC-DGL to effectively capture similarity information across multiple interaction scales within affinity and association matrices. To address the issue of imbalance in DTI datasets, we propose an adjustable imbalance loss function that adjusts the weight of negative samples by the parameter. Extensive experiments on four benchmark datasets demonstrate that SOC-DGL consistently outperforms existing state-of-the-art methods across both balanced and imbalanced scenarios. Moreover, SOC-DGL successfully predicts the top 9 drugs known to bind ABL1, and further analyzed the 10th drug, which has not been experimentally confirmed to interact with ABL1, providing supporting evidence for its potential binding.",
      "authors": [
        "Xiang Zhao",
        "Ruijie Li",
        "Qiao Ning",
        "Shikai Guo",
        "Hui Li",
        "Qian Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T08:00:24+00:00",
          "link": "https://arxiv.org/abs/2506.01405v1",
          "size": "41094kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:33:18+00:00",
          "link": "https://arxiv.org/abs/2506.01405v2",
          "size": "27107kb",
          "version": "v2"
        }
      ],
      "title": "SOC-DGL: Social Interaction Behavior Inspired Dual Graph Learning Framework for Drug-Target Interaction Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01405",
        "HTML": "https://arxiv.org/html/2506.01405",
        "PDF": "https://arxiv.org/pdf/2506.01405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SOC-DGL is focused on drug-target interaction identification using graph learning techniques. It does not address any aspect of LLM training data processing or improvements in data quality relevant to LLMs."
      },
      "tasks": [
        "Drug Discovery",
        "Graph Learning"
      ],
      "repo_urls": [
        "https://github.com/Zhaoxiang0422/SOC-DGL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14301",
      "abstract": "The widespread deployment of cameras has led to an exponential increase in video data, creating vast opportunities for applications such as traffic management and crime surveillance. However, querying specific objects from large-scale video datasets presents challenges, including (1) processing massive and continuously growing data volumes, (2) supporting complex query requirements, and (3) ensuring low-latency execution. Existing video analysis methods struggle with either limited adaptability to unseen object classes or suffer from high query latency. In this paper, we present LOVO, a novel system designed to efficiently handle comp$\\underline{L}$ex $\\underline{O}$bject queries in large-scale $\\underline{V}$ide$\\underline{O}$ datasets. Agnostic to user queries, LOVO performs one-time feature extraction using pre-trained visual encoders, generating compact visual embeddings for key frames to build an efficient index. These visual embeddings, along with associated bounding boxes, are organized in an inverted multi-index structure within a vector database, which supports queries for any objects. During the query phase, LOVO transforms object queries to query embeddings and conducts fast approximate nearest-neighbor searches on the visual embeddings. Finally, a cross-modal rerank is performed to refine the results by fusing visual features with detailed textual features. Evaluation on real-world video datasets demonstrates that LOVO outperforms existing methods in handling complex queries, with near-optimal query accuracy and up to 85x lower search latency, while significantly reducing index construction costs. This system redefines the state-of-the-art object query approaches in video analysis, setting a new benchmark for complex object queries with a novel, scalable, and efficient approach that excels in dynamic environments.",
      "authors": [
        "Yuxin Liu",
        "Yuezhang Peng",
        "Hefeng Zhou",
        "Hongze Liu",
        "Xinyu Lu",
        "Jiong Lou",
        "Chentao Wu",
        "Wei Zhao",
        "Jie Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:21:43+00:00",
          "link": "https://arxiv.org/abs/2507.14301v1",
          "size": "4647kb",
          "version": "v1"
        }
      ],
      "title": "LOVO: Efficient Complex Object Query in Large-Scale Video Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14301",
        "HTML": "https://arxiv.org/html/2507.14301",
        "PDF": "https://arxiv.org/pdf/2507.14301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper aims at efficient querying in video datasets through visual embeddings but does not relate to any improvement or processing of LLM training data, thus being irrelevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14487",
      "abstract": "We investigate a Federated Reinforcement Learning with Environment Heterogeneity (FRL-EH) framework, where local environments exhibit statistical heterogeneity. Within this framework, agents collaboratively learn a global policy by aggregating their collective experiences while preserving the privacy of their local trajectories. To better reflect real-world scenarios, we introduce a robust FRL-EH framework by presenting a novel global objective function. This function is specifically designed to optimize a global policy that ensures robust performance across heterogeneous local environments and their plausible perturbations. We propose a tabular FRL algorithm named FedRQ and theoretically prove its asymptotic convergence to an optimal policy for the global objective function. Furthermore, we extend FedRQ to environments with continuous state space through the use of expectile loss, addressing the key challenge of minimizing a value function over a continuous subset of the state space. This advancement facilitates the seamless integration of the principles of FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive empirical evaluations validate the effectiveness and robustness of our FRL algorithms across diverse heterogeneous environments, consistently achieving superior performance over the existing state-of-the-art FRL algorithms.",
      "authors": [
        "Ukjo Hwang",
        "Songnam Hong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:06:38+00:00",
          "link": "https://arxiv.org/abs/2507.14487v1",
          "size": "1592kb",
          "version": "v1"
        }
      ],
      "title": "Federated Reinforcement Learning in Heterogeneous Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14487",
        "HTML": "https://arxiv.org/html/2507.14487",
        "PDF": "https://arxiv.org/pdf/2507.14487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on federated reinforcement learning in heterogeneous environments, with no mention of training data processing for LLMs or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14592",
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance, logistics, agriculture, disaster management, and military operations. Accurate detection and classification of UAV flight states, such as hovering, cruising, ascending, or transitioning, which are essential for safe and effective operations. However, conventional time series classification (TSC) methods often lack robustness and generalization for dynamic UAV environments, while state of the art(SOTA) models like Transformers and LSTM based architectures typically require large datasets and entail high computational costs, especially with high-dimensional data streams. This paper proposes a novel framework that integrates a Transformer-based Generative Adversarial Network (GAN) with Multiple Instance Locally Explainable Learning (MILET) to address these challenges in UAV flight state classification. The Transformer encoder captures long-range temporal dependencies and complex telemetry dynamics, while the GAN module augments limited datasets with realistic synthetic samples. MIL is incorporated to focus attention on the most discriminative input segments, reducing noise and computational overhead. Experimental results show that the proposed method achieves superior accuracy 96.5% on the DroneDetect dataset and 98.6% on the DroneRF dataset that outperforming other SOTA approaches. The framework also demonstrates strong computational efficiency and robust generalization across diverse UAV platforms and flight states, highlighting its potential for real-time deployment in resource constrained environments.",
      "authors": [
        "Haochen Liu",
        "Jia Bi",
        "Xiaomin Wang",
        "Xin Yang and Ling Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:35:45+00:00",
          "link": "https://arxiv.org/abs/2507.14592v1",
          "size": "2578kb",
          "version": "v1"
        }
      ],
      "title": "A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14592",
        "HTML": "https://arxiv.org/html/2507.14592",
        "PDF": "https://arxiv.org/pdf/2507.14592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with UAV signal detection using a Transformer-based GAN for dataset augmentation. It is focused on signal classification specific to UAVs and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14776",
      "abstract": "The rapid adoption of large language models(LLMs) in hardware design has primarily focused on generating functionally correct Verilog code, overlooking critical Power Performance-Area(PPA) metrics essential for industrial-grade designs. To bridge this gap, we propose VeriOpt, a novel framework that leverages role-based prompting and PPA-aware optimization to enable LLMs to produce high-quality, synthesizable Verilog. VeriOpt structures LLM interactions into specialized roles (e.g., Planner, Programmer, Reviewer, Evaluator) to emulate human design workflows, while integrating PPA constraints directly into the prompting pipeline. By combining multi-modal feedback (e.g., synthesis reports, timing diagrams) with PPA aware prompting, VeriOpt achieves PPA-efficient code generation without sacrificing functional correctness. Experimental results demonstrate up to 88% reduction in power, 76% reduction in area and 73% improvement in timing closure compared to baseline LLM-generated RTL, validated using industry standard EDA tools. At the same time achieves 86% success rate in functionality evaluation. Our work advances the state-of-the-art AI-driven hardware design by addressing the critical gap between correctness and quality, paving the way for reliable LLM adoption in production workflows.",
      "authors": [
        "Kimia Tasnia",
        "Alexander Garcia",
        "Tasnuva Farheen",
        "Sazadur Rahman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T00:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.14776v1",
          "size": "8925kb",
          "version": "v1"
        }
      ],
      "title": "VeriOpt: PPA-Aware High-Quality Verilog Generation via Multi-Role LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14776",
        "HTML": "https://arxiv.org/html/2507.14776",
        "PDF": "https://arxiv.org/pdf/2507.14776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces VeriOpt, which uses LLMs for improving Verilog code generation. While it touches on the application of LLMs, the focus is more on code quality and efficiency in hardware design, not directly on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14785",
      "abstract": "The complexity and interconnectivity of entities involved in money laundering demand investigative reasoning over graph-structured data. This paper explores the use of large language models (LLMs) as reasoning engines over localized subgraphs extracted from a financial knowledge graph. We propose a lightweight pipeline that retrieves k-hop neighborhoods around entities of interest, serializes them into structured text, and prompts an LLM via few-shot in-context learning to assess suspiciousness and generate justifications. Using synthetic anti-money laundering (AML) scenarios that reflect common laundering behaviors, we show that LLMs can emulate analyst-style logic, highlight red flags, and provide coherent explanations. While this study is exploratory, it illustrates the potential of LLM-based graph reasoning in AML and lays groundwork for explainable, language-driven financial crime analytics.",
      "authors": [
        "Erfan Pirmorad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:00:21+00:00",
          "link": "https://arxiv.org/abs/2507.14785v1",
          "size": "1150kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14785",
        "HTML": "https://arxiv.org/html/2507.14785",
        "PDF": "https://arxiv.org/pdf/2507.14785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores using LLMs for reasoning over financial graphs in money laundering detection, focusing on in-context learning and reasoning strategies, not on LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15478",
      "abstract": "Ensuring reliable and rule-compliant behavior of autonomous agents in uncertain environments remains a fundamental challenge in modern robotics. Our work shows how neuro-symbolic systems, which integrate probabilistic, symbolic white-box reasoning models with deep learning methods, offer a powerful solution to this challenge. This enables the simultaneous consideration of explicit rules and neural models trained on noisy data, combining the strength of structured reasoning with flexible representations. To this end, we introduce the Constitutional Controller (CoCo), a novel framework designed to enhance the safety and reliability of agents by reasoning over deep probabilistic logic programs representing constraints such as those found in shared traffic spaces. Furthermore, we propose the concept of self-doubt, implemented as a probability density conditioned on doubt features such as travel velocity, employed sensors, or health factors. In a real-world aerial mobility study, we demonstrate CoCo's advantages for intelligent autonomous systems to learn appropriate doubts and navigate complex and uncertain environments safely and compliantly.",
      "authors": [
        "Simon Kohaut and Felix Divo and Navid Hamid and Benedict Flade and Julian Eggert and Devendra Singh Dhami and Kristian Kersting"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:33:31+00:00",
          "link": "https://arxiv.org/abs/2507.15478v1",
          "size": "9488kb",
          "version": "v1"
        }
      ],
      "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15478",
        "HTML": "https://arxiv.org/html/2507.15478",
        "PDF": "https://arxiv.org/pdf/2507.15478"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with improving reliability and rule-compliance in autonomous agents using neuro-symbolic systems, which does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15487",
      "abstract": "Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequency domain information, which is crucial for accurate lesion classification in medical imaging. However, effectively integrating multi-sequence MRI data for robust 3D lesion classification remains a challenge. In this paper, we propose DeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novel framework designed to extract decoupled representations and adaptively fuse spatial and spectral features for lesion classification. DeSamba introduces a Decoupled Representation Learning Module (DRLM) that decouples features from different MRI sequences through self-reconstruction and cross-reconstruction, and a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet, enabling dynamic fusion of spectral and spatial information based on lesion characteristics. We evaluate DeSamba on two clinically relevant 3D datasets. On a six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1 accuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an external validation set (n=372), outperforming all state-of-the-art (SOTA) baselines. On a spondylitis dataset (n=251) involving a challenging binary classification task, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internal and external validation sets, respectively. Ablation studies demonstrate that both DRLM and SAMB significantly contribute to overall performance, with over 10% relative improvement compared to the baseline. Our results highlight the potential of DeSamba as a generalizable and effective solution for 3D lesion classification in multi-sequence medical imaging.",
      "authors": [
        "Dezhen Wang",
        "Sheng Miao",
        "Rongxin Chai",
        "Jiufa Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:42:21+00:00",
          "link": "https://arxiv.org/abs/2507.15487v1",
          "size": "7045kb",
          "version": "v1"
        }
      ],
      "title": "DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15487",
        "HTML": "https://arxiv.org/html/2507.15487",
        "PDF": "https://arxiv.org/pdf/2507.15487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on lesion classification in medical imaging using MRI, proposing a framework for integrating multi-sequence MRI data. There is no discussion on LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15512",
      "abstract": "Test-Time Scaling (TTS) is a promising approach to progressively elicit the model's intelligence during inference. Recently, training-based TTS methods, such as continued reinforcement learning (RL), have further surged in popularity, while training-free TTS methods are gradually fading from prominence. However, the additional computation overhead of training amplifies the burden on test-time scaling. In this paper, we focus on training-free TTS methods for reasoning. We first design Conditional Step-level Self-refinement, a fine-grained sequential scaling method guided by process verification. On top of its effectiveness, we further combine it with other classical parallel scaling methods at the step level, to introduce a novel inference paradigm called Hybrid Test-Time Scaling. Extensive experiments on five instruction-tuned LLMs across different scales (3B-14B) and families demonstrate that hybrid strategy incorporating various training-free TTS methods at a fine granularity has considerable potential for expanding the reasoning performance boundaries of LLMs.",
      "authors": [
        "Kaiyan Chang",
        "Yonghao Shi",
        "Chenglong Wang",
        "Hang Zhou",
        "Chi Hu",
        "Xiaoqian Liu",
        "Yingfeng Luo",
        "Yuan Ge",
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:28:09+00:00",
          "link": "https://arxiv.org/abs/2507.15512v1",
          "size": "212kb",
          "version": "v1"
        }
      ],
      "title": "Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15512",
        "HTML": "https://arxiv.org/html/2507.15512",
        "PDF": "https://arxiv.org/pdf/2507.15512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with inference techniques using Step-level Test-Time Scaling methods for reasoning tasks, not involving LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15540",
      "abstract": "We study the problem of self-supervised procedure learning, which discovers key steps and establishes their order from a set of unlabeled procedural videos. Previous procedure learning methods typically learn frame-to-frame correspondences between videos before determining key steps and their order. However, their performance often suffers from order variations, background/redundant frames, and repeated actions. To overcome these challenges, we propose a self-supervised procedure learning framework, which utilizes a fused Gromov-Wasserstein optimal transport formulation with a structural prior for computing frame-to-frame mapping between videos. However, optimizing exclusively for the above temporal alignment term may lead to degenerate solutions, where all frames are mapped to a small cluster in the embedding space and hence every video is associated with only one key step. To address that limitation, we further integrate a contrastive regularization term, which maps different frames to different points in the embedding space, avoiding the collapse to trivial solutions. Finally, we conduct extensive experiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e., ProceL and CrossTask) benchmarks to demonstrate superior performance by our approach against previous methods, including OPEL which relies on a traditional Kantorovich optimal transport formulation with an optimality prior.",
      "authors": [
        "Syed Ahmed Mahmood",
        "Ali Shah Ali",
        "Umer Ahmed",
        "Fawad Javed Fateh",
        "M. Zeeshan Zia",
        "Quoc-Huy Tran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:09:12+00:00",
          "link": "https://arxiv.org/abs/2507.15540v1",
          "size": "1203kb",
          "version": "v1"
        }
      ],
      "title": "Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15540",
        "HTML": "https://arxiv.org/html/2507.15540",
        "PDF": "https://arxiv.org/pdf/2507.15540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is on self-supervised procedure learning using optimal transport, which is not directly related to any aspect of processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15793",
      "abstract": "Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is increasingly attracting interest in medical imaging due to its effectiveness and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA) is a notable approach based on the assumption that the adaptation inherently occurs in a low-dimensional subspace. While it has shown good performance, its implementation requires a fixed and unalterable rank, which might be challenging to select given the unique complexities and requirements of each medical imaging downstream task. Inspired by advancements in natural image processing, we introduce a novel approach for medical image segmentation that dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank representation of the trainable weight matrices as a singular value decomposition, we introduce an l_1 sparsity regularizer to the loss function, and tackle it with a proximal optimizer. The regularizer could be viewed as a penalty on the decomposition rank. Hence, its minimization enables to find task-adapted ranks automatically. Our method is evaluated in a realistic few-shot fine-tuning setting, where we compare it first to the standard LoRA and then to several other PEFT methods across two distinguishable tasks: base organs and novel organs. Our extensive experiments demonstrate the significant performance improvements driven by our method, highlighting its efficiency and robustness against suboptimal rank initialization. Our code is publicly available: https://github.com/ghassenbaklouti/ARENA",
      "authors": [
        "Ghassen Baklouti",
        "Julio Silva-Rodr\\'iguez",
        "Jose Dolz",
        "Houda Bahig",
        "and Ismail Ben Ayed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.15793v1",
          "size": "59kb",
          "version": "v1"
        }
      ],
      "title": "Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15793",
        "HTML": "https://arxiv.org/html/2507.15793",
        "PDF": "https://arxiv.org/pdf/2507.15793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work centers on parameter-efficient fine-tuning (PEFT) for medical imaging tasks, specifically organ segmentation via LoRA adjustments, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15823",
      "abstract": "Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.",
      "authors": [
        "Anton Abilov",
        "Ke Zhang",
        "Hemank Lamba",
        "Elizabeth M. Olson",
        "Joel R. Tetreault",
        "Alejandro Jaimes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:30:38+00:00",
          "link": "https://arxiv.org/abs/2507.15823v1",
          "size": "146kb",
          "version": "v1"
        }
      ],
      "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15823",
        "HTML": "https://arxiv.org/html/2507.15823",
        "PDF": "https://arxiv.org/pdf/2507.15823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the deployment and maintenance of AI models in humanitarian work, with no focus on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05549",
      "abstract": "This paper introduces Stereo Any Video, a powerful framework for video stereo matching. It can estimate spatially accurate and temporally consistent disparities without relying on auxiliary information such as camera poses or optical flow. The strong capability is driven by rich priors from monocular video depth models, which are integrated with convolutional features to produce stable representations. To further enhance performance, key architectural innovations are introduced: all-to-all-pairs correlation, which constructs smooth and robust matching cost volumes, and temporal convex upsampling, which improves temporal coherence. These components collectively ensure robustness, accuracy, and temporal consistency, setting a new standard in video stereo matching. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple datasets both qualitatively and quantitatively in zero-shot settings, as well as strong generalization to real-world indoor and outdoor scenarios.",
      "authors": [
        "Junpeng Jing",
        "Weixun Luo",
        "Ye Mao",
        "Krystian Mikolajczyk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T16:20:36+00:00",
          "link": "https://arxiv.org/abs/2503.05549v1",
          "size": "14519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:29:20+00:00",
          "link": "https://arxiv.org/abs/2503.05549v2",
          "size": "2111kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T11:11:39+00:00",
          "link": "https://arxiv.org/abs/2503.05549v3",
          "size": "14365kb",
          "version": "v3"
        }
      ],
      "title": "Stereo Any Video: Temporally Consistent Stereo Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05549",
        "HTML": "https://arxiv.org/html/2503.05549",
        "PDF": "https://arxiv.org/pdf/2503.05549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces methods for video stereo matching, focusing on achieving temporal consistency without any relation to LLM training data processing or dataset enhancements."
      },
      "tasks": [
        "Optical Flow Estimation",
        "Stereo Matching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20687",
      "abstract": "The original description of the k-d tree recognized that rebalancing techniques, such as used to build an AVL tree or a red-black tree, are not applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is necessary to find the median of a set of data for each recursive subdivision of that set. The sort or selection used to find the median, and the technique used to partition the set about that median, strongly influence the computational complexity of building a k-d tree. This article describes and contrasts three k-d tree-building algorithms that differ in their technique used to partition the set, and compares the performance of the algorithms. In addition, dual-threaded execution is proposed for one of the three algorithms.",
      "authors": [
        "Russell A. Brown"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T01:01:38+00:00",
          "link": "https://arxiv.org/abs/2506.20687v1",
          "size": "714kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T22:55:07+00:00",
          "link": "https://arxiv.org/abs/2506.20687v2",
          "size": "808kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T22:13:37+00:00",
          "link": "https://arxiv.org/abs/2506.20687v3",
          "size": "794kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T21:32:47+00:00",
          "link": "https://arxiv.org/abs/2506.20687v4",
          "size": "797kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T19:56:40+00:00",
          "link": "https://arxiv.org/abs/2506.20687v5",
          "size": "797kb",
          "version": "v5"
        }
      ],
      "title": "Review of Three Algorithms That Build k-d Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20687",
        "HTML": "https://arxiv.org/html/2506.20687",
        "PDF": "https://arxiv.org/pdf/2506.20687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithms for building k-d trees for data partitioning but does not relate to LLM training data processing. It addresses computational techniques for tree structures rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14482",
      "abstract": "In-depth analysis of competitive debates is essential for participants to develop argumentative skills and refine strategies, and further improve their debating performance. However, manual analysis of unstructured and unlabeled textual records of debating is time-consuming and ineffective, as it is challenging to reconstruct contextual semantics and track logical connections from raw data. To address this, we propose Conch, an interactive visualization system that systematically analyzes both what is debated and how it is debated. In particular, we propose a novel parallel spiral visualization that compactly traces the multidimensional evolution of clash points and participant interactions throughout debate process. In addition, we leverage large language models with well-designed prompts to automatically identify critical debate elements such as clash points, disagreements, viewpoints, and strategies, enabling participants to understand the debate context comprehensively. Finally, through two case studies on real-world debates and a carefully-designed user study, we demonstrate Conch's effectiveness and usability for competitive debate analysis.",
      "authors": [
        "Qianhe Chen",
        "Yong Wang",
        "Yixin Yu",
        "Xiyuan Zhu",
        "Xuerou Yu",
        "Ran Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:42:09+00:00",
          "link": "https://arxiv.org/abs/2507.14482v1",
          "size": "5271kb",
          "version": "v1"
        }
      ],
      "title": "Conch: Competitive Debate Analysis via Visualizing Clash Points and Hierarchical Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14482",
        "HTML": "https://arxiv.org/html/2507.14482",
        "PDF": "https://arxiv.org/pdf/2507.14482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for competitive debate analysis using visualization techniques and large language models, focusing on debate context understanding rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15464",
      "abstract": "Ultrasound imaging is a real-time diagnostic modality that reconstructs acoustic signals into visual representations of internal body structures. A key component in this process is beamforming, with the Delay and Sum (DAS) algorithm being a standard due to its balance between simplicity and effectiveness. However, the computational cost of DAS can be a limiting factor, especially in real-time scenarios where fast frame reconstruction is essential. In this work, we introduce a time-invariant approximation of the DAS algorithm (tiDAS), designed to accelerate the reconstruction process without compromising image quality. By adopting a one-dimensional, row-wise convolutional formulation, tiDAS significantly reduces computational complexity while preserving the core properties of the original model. This approach not only enables faster image reconstruction but also provides a structured foundation for the application of deconvolution methods aimed at enhancing resolution. Synthetic experiments demonstrate that tiDAS achieves a favorable trade-off between speed and accuracy, making it a promising tool for improving the efficiency of real-time ultrasound imaging.",
      "authors": [
        "Chiara Razzetta",
        "Sara Garbarino",
        "Michele Piana",
        "Marco Crocco and Federico Benvenuto"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:17:56+00:00",
          "link": "https://arxiv.org/abs/2507.15464v1",
          "size": "968kb",
          "version": "v1"
        }
      ],
      "title": "tiDAS: a time invariant approximation of the Delay and Sum algorithm for biomedical ultrasound PSF reconstructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15464",
        "HTML": "https://arxiv.org/html/2507.15464",
        "PDF": "https://arxiv.org/pdf/2507.15464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with an approximation algorithm for ultrasound image reconstruction, focusing on computational efficiency in medical imaging, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2205.01533",
      "abstract": "In this letter, we propose reliable covert communications with the aim of minimizing age of information (AoI) in the time-varying channels. We named the time duration that channel state information (CSI) is valid as a new metric, as age of channel variation (AoC). To find reliable covert communication in a fresh manner in dynamic environments, this work considers a new constraint that shows a relation between AoI and AoC. With the aid of the proposed constraint, this paper addresses two main challenges of reliable covert communication with the aim of minimizing AoI: 1) users packets with desirable size; 2) guaranteeing the negligible probability of Willies detection, in time-varying networks. In the simulation results, we compare the performance of the proposed constraint in reliable covert communication with the aim of minimizing AoI with conventional optimization of the requirement of information freshness in covert communications.",
      "authors": [
        "Shima Salar Hosseini",
        "Paeiz Azmi",
        "Nader Mokari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-03T14:34:13+00:00",
          "link": "https://arxiv.org/abs/2205.01533v1",
          "size": "191kb",
          "version": "v1"
        }
      ],
      "title": "Average Age of Information Minimization in Reliable Covert Communication on Time-Varying Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.01533",
        "PDF": "https://arxiv.org/pdf/2205.01533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on covert communication strategies and channel state information, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.13479",
      "abstract": "Given a weighted, undirected graph $G$ cellularly embedded on a topological surface $S$, we describe algorithms to compute the second shortest and third shortest closed walks of $G$ that are neither homotopically trivial in $S$ nor homotopic to the shortest non-trivial closed walk or to each other. Our algorithms run in $O(n^2\\log n)$ time for the second shortest walk and in $O(n^3)$ time for the third shortest walk. We also show how to reduce the running time for the second shortest homotopically non-trivial closed walk to $O(n\\log n)$ when both the genus and the number of boundaries are fixed.\n  Our algorithms rely on a careful analysis of the configurations of the first three shortest homotopically non-trivial curves in $S$. As an intermediate step, we also describe how to compute a shortest essential arc between \\emph{one} pair of vertices or between \\emph{all} pairs of vertices of a given boundary component of $S$ in $O(n^2)$ time or $O(n^3)$ time, respectively.",
      "authors": [
        "Matthijs Ebbens",
        "Francis Lazarus"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Geometric Topology (math.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-18T12:57:19+00:00",
          "link": "https://arxiv.org/abs/2407.13479v1",
          "size": "292kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:00:02+00:00",
          "link": "https://arxiv.org/abs/2407.13479v2",
          "size": "75kb",
          "version": "v2"
        }
      ],
      "title": "Computing the second and third systoles of a combinatorial surface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.13479",
        "HTML": "https://arxiv.org/html/2407.13479",
        "PDF": "https://arxiv.org/pdf/2407.13479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes algorithms for computing shortest closed walks in a weighted, undirected graph on a topological surface, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.17993",
      "abstract": "Question answering represents a core capability of large language models (LLMs). However, when individuals encounter unfamiliar knowledge in texts, they often formulate questions that the text itself cannot answer due to insufficient understanding of the underlying information. Recent studies reveal that while LLMs can detect unanswerable questions, they struggle to assist users in reformulating these questions. Even advanced models like GPT-3.5 demonstrate limited effectiveness in this regard. To address this limitation, we propose DRS: Deep Question Reformulation with Structured Output, a novel zero-shot method aimed at enhancing LLMs ability to assist users in reformulating questions to extract relevant information from new documents. DRS combines the strengths of LLMs with a DFS-based algorithm to iteratively explore potential entity combinations and constrain outputs using predefined entities. This structured approach significantly enhances the reformulation capabilities of LLMs. Comprehensive experimental evaluations demonstrate that DRS improves the reformulation accuracy of GPT-3.5 from 23.03% to 70.42%, while also enhancing the performance of open-source models, such as Gemma2-9B, from 26.35% to 56.75%.",
      "authors": [
        "Zhecheng Li",
        "Yiwei Wang",
        "Bryan Hooi",
        "Yujun Cai",
        "Nanyun Peng",
        "Kai-Wei Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T02:20:44+00:00",
          "link": "https://arxiv.org/abs/2411.17993v1",
          "size": "449kb",
          "version": "v1"
        },
        {
          "date": "2024-12-05T06:53:40+00:00",
          "link": "https://arxiv.org/abs/2411.17993v2",
          "size": "665kb",
          "version": "v2"
        },
        {
          "date": "2024-12-06T04:08:34+00:00",
          "link": "https://arxiv.org/abs/2411.17993v3",
          "size": "665kb",
          "version": "v3"
        },
        {
          "date": "2025-03-25T05:10:39+00:00",
          "link": "https://arxiv.org/abs/2411.17993v4",
          "size": "443kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T02:39:52+00:00",
          "link": "https://arxiv.org/abs/2411.17993v5",
          "size": "444kb",
          "version": "v5"
        }
      ],
      "title": "DRS: Deep Question Reformulation With Structured Output",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17993",
        "HTML": "https://arxiv.org/html/2411.17993",
        "PDF": "https://arxiv.org/pdf/2411.17993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing LLM capabilities in question reformulation through a structured output method. It does not address any aspect of LLM training data processing or involve any data engineering operations related to LLM datasets."
      },
      "tasks": [
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/lizhecheng02/drs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06156",
      "abstract": "Blockchain bridges have become essential infrastructure for enabling interoperability across different blockchain networks, with more than $24B monthly bridge transaction volume. However, their growing adoption has been accompanied by a disproportionate rise in security breaches, making them the single largest source of financial loss in Web3. For cross-chain ecosystems to be robust and sustainable, it is essential to understand and address these vulnerabilities. In this study, we present a comprehensive systematization of blockchain bridge design and security. We define three bridge security priors, formalize the architectural structure of 13 prominent bridges, and identify 23 attack vectors grounded in real-world blockchain exploits. Using this foundation, we evaluate 43 representative attack scenarios and introduce a layered threat model that captures security failures across source chain, off-chain, and destination chain components.\n  Our analysis at the static code and transaction network levels reveals recurring design flaws, particularly in access control, validator trust assumptions, and verification logic, and identifies key patterns in adversarial behavior based on transaction-level traces. To support future development, we propose a decision framework for bridge architecture design, along with defense mechanisms such as layered validation and circuit breakers. This work provides a data-driven foundation for evaluating bridge security and lays the groundwork for standardizing resilient cross-chain infrastructure.",
      "authors": [
        "Poupak Azad",
        "Jiahua Xu",
        "Yebo Feng",
        "Preston Strowbridge",
        "Cuneyt Akcora"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:39:23+00:00",
          "link": "https://arxiv.org/abs/2507.06156v1",
          "size": "1013kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:52:00+00:00",
          "link": "https://arxiv.org/abs/2507.06156v2",
          "size": "1013kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T15:10:06+00:00",
          "link": "https://arxiv.org/abs/2507.06156v3",
          "size": "1013kb",
          "version": "v3"
        }
      ],
      "title": "Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06156",
        "HTML": "https://arxiv.org/html/2507.06156",
        "PDF": "https://arxiv.org/pdf/2507.06156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores blockchain bridge security, vulnerabilities, and design, which does not relate to LLM training data processing tasks like data engineering or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14696",
      "abstract": "Faculty hiring shapes the flow of ideas, resources, and opportunities in academia, influencing not only individual career trajectories but also broader patterns of institutional prestige and scientific progress. While traditional studies have found strong correlations between faculty hiring and attributes such as doctoral department prestige and publication record, they rarely assess whether these associations generalize to individual hiring outcomes, particularly for future candidates outside the original sample. Here, we consider faculty placement as an individual-level prediction task. Our data consist of temporal co-authorship networks with conventional attributes such as doctoral department prestige and bibliometric features. We observe that using the co-authorship network significantly improves predictive accuracy by up to 10% over traditional indicators alone, with the largest gains observed for placements at the most elite (top-10) departments. Our results underscore the role that social networks, professional endorsements, and implicit advocacy play in faculty hiring beyond traditional measures of scholarly productivity and institutional prestige. By introducing a predictive framing of faculty placement and establishing the benefit of considering co-authorship networks, this work provides a new lens for understanding structural biases in academia that could inform targeted interventions aimed at increasing transparency, fairness, and equity in academic hiring practices.",
      "authors": [
        "Samantha Dies",
        "David Liu",
        "Tina Eliassi-Rad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:09:23+00:00",
          "link": "https://arxiv.org/abs/2507.14696v1",
          "size": "459kb",
          "version": "v1"
        }
      ],
      "title": "Forecasting Faculty Placement from Patterns in Co-authorship Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14696",
        "HTML": "https://arxiv.org/html/2507.14696",
        "PDF": "https://arxiv.org/pdf/2507.14696"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on faculty placement predictions based on co-authorship networks and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15194",
      "abstract": "Accurate representation of myocardial infarct geometry is crucial for patient-specific cardiac modeling in MI patients. While Late gadolinium enhancement (LGE) MRI is the clinical gold standard for infarct detection, it requires contrast agents, introducing side effects and patient discomfort. Moreover, infarct reconstruction from LGE often relies on sparsely sampled 2D slices, limiting spatial resolution and accuracy. In this work, we propose a novel framework for automatically reconstructing high-fidelity 3D myocardial infarct geometry from 2D clinically standard cine MRI, eliminating the need for contrast agents. Specifically, we first reconstruct the 4D biventricular mesh from multi-view cine MRIs via an automatic deep shape fitting model, biv-me. Then, we design a infarction reconstruction model, CMotion2Infarct-Net, to explicitly utilize the motion patterns within this dynamic geometry to localize infarct regions. Evaluated on 205 cine MRI scans from 126 MI patients, our method shows reasonable agreement with manual delineation. This study demonstrates the feasibility of contrast-free, cardiac motion-driven 3D infarct reconstruction, paving the way for efficient digital twin of MI.",
      "authors": [
        "Yilin Lyu",
        "Fan Yang",
        "Xiaoyue Liu",
        "Zichen Jiang",
        "Joshua Dillon",
        "Debbie Zhao",
        "Martyn Nash",
        "Charlene Mauger",
        "Alistair Young",
        "Ching-Hui Sia",
        "Mark YY Chan",
        "Lei Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:43:35+00:00",
          "link": "https://arxiv.org/abs/2507.15194v1",
          "size": "721kb",
          "version": "v1"
        }
      ],
      "title": "Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15194",
        "HTML": "https://arxiv.org/html/2507.15194",
        "PDF": "https://arxiv.org/pdf/2507.15194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a framework for reconstructing 3D myocardial infarct geometry from MRI data, focusing on medical imaging and cardiac modeling, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15382",
      "abstract": "Modern traffic generators are essential tools for evaluating the performance of network environments. P4TG is a P4-based traffic generator implemented for Intel Tofino switches that offers high-speed packet generation with fine-grained measurement capabilities. However, P4TG samples time-based metrics such as the round-trip time (RTT) in the data plane and collects them at the controller. This leads to a reduced accuracy. In this paper, we introduce a histogram-based RTT measurement feature for P4TG. It enables accurate analysis at line rate without sampling. Generally, histogram bins are modeled as ranges, and values are matched to a bin. Efficient packet matching in hardware is typically achieved using ternary content addressable memory (TCAM). However, representing range matching rules in TCAM poses a challenge. Therefore, we implemented a range-to-prefix conversion algorithm that models range matching with multiple ternary entries. This paper describes the data plane implementation and runtime configuration of RTT histograms in P4TG. Further, we discuss the efficiency of the ternary decomposition. Our evaluation demonstrates the applicability of the histogram-based RTT analysis by comparing the measured values with a configured theoretical distribution of RTTs.",
      "authors": [
        "Fabian Ihle",
        "Etienne Zink",
        "Michael Menth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:38:11+00:00",
          "link": "https://arxiv.org/abs/2507.15382v1",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "title": "Enhancements to P4TG: Histogram-Based RTT Monitoring in the Data Plane",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15382",
        "HTML": "https://arxiv.org/html/2507.15382",
        "PDF": "https://arxiv.org/pdf/2507.15382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about enhancements to a traffic generator for network environments using a histogram-based RTT measurement. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15636",
      "abstract": "Recent advances in deepfake technology have created increasingly convincing synthetic media that poses significant challenges to information integrity and social trust. While current detection methods show promise, their underlying mechanisms remain poorly understood, and the large sizes of their models make them challenging to deploy in resource-limited environments. This study investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake detection, aiming to identify the key features crucial for recognizing deepfakes. We examine how neural networks can be efficiently pruned while maintaining high detection accuracy. Through extensive experiments with MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and FaceForensics++ datasets, we find that deepfake detection networks contain winning tickets, i.e., subnetworks, that preserve performance even at substantial sparsity levels. Our results indicate that MesoNet retains 56.2% accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000 parameters, which is about 90% of its baseline accuracy (62.6%). The results also show that our proposed LTH-based iterative magnitude pruning approach consistently outperforms one-shot pruning methods. Using Grad-CAM visualization, we analyze how pruned networks maintain their focus on critical facial regions for deepfake detection. Additionally, we demonstrate the transferability of winning tickets across datasets, suggesting potential for efficient, deployable deepfake detection systems.",
      "authors": [
        "Lisan Al Amin",
        "Md. Ismail Hossain",
        "Thanh Thi Nguyen",
        "Tasnim Jahan",
        "Mahbubul Islam",
        "Faisal Quader"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.15636v1",
          "size": "745kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15636",
        "HTML": "https://arxiv.org/html/2507.15636",
        "PDF": "https://arxiv.org/pdf/2507.15636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates deepfake detection through the Lottery Ticket Hypothesis and model pruning. It does not involve any aspects related to LLM training data processing or data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16370",
      "abstract": "Advances in architectural design, data availability, and compute have driven remarkable progress in semantic segmentation. Yet, these models often rely on relaxed Bayesian assumptions, omitting critical uncertainty information needed for robust decision-making. The resulting reliance on point estimates has fueled interest in probabilistic segmentation, but the literature remains fragmented. In response, this review consolidates and contextualizes foundational concepts in uncertainty modeling, including the non-trivial task of distinguishing between epistemic and aleatoric uncertainty and examining their roles across four key downstream segmentation tasks, highlighting Active Learning as particularly promising. By unifying theory, terminology, and applications, we provide a coherent foundation for researchers and identify critical challenges, such as strong assumptions in spatial aggregation, lack of standardized benchmarks, and pitfalls in current uncertainty quantification methods. We identify trends such as the adoption of contemporary generative models, driven by advances in the broader field of generative modeling, with segmentation-specific innovation primarily in the conditioning mechanisms. Moreover, we observe growing interest in distribution- and sampling-free approaches to uncertainty estimation. We further propose directions for advancing uncertainty-aware segmentation in deep learning, including pragmatic strategies for disentangling different sources of uncertainty, novel uncertainty modeling approaches and improved Transformer-based backbones. In this way, we aim to support the development of more reliable, efficient, and interpretable segmentation models that effectively incorporate uncertainty into real-world applications.",
      "authors": [
        "M.M.A. Valiuddin",
        "R.J.G. van Sloun",
        "C.G.A. Viviers",
        "P.H.N. de With",
        "F. van der Sommen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T13:26:09+00:00",
          "link": "https://arxiv.org/abs/2411.16370v1",
          "size": "5446kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T09:34:51+00:00",
          "link": "https://arxiv.org/abs/2411.16370v2",
          "size": "3603kb",
          "version": "v2"
        },
        {
          "date": "2025-03-12T09:51:17+00:00",
          "link": "https://arxiv.org/abs/2411.16370v3",
          "size": "3603kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T13:47:36+00:00",
          "link": "https://arxiv.org/abs/2411.16370v4",
          "size": "3638kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T11:27:39+00:00",
          "link": "https://arxiv.org/abs/2411.16370v5",
          "size": "3664kb",
          "version": "v5"
        },
        {
          "date": "2025-07-21T15:36:24+00:00",
          "link": "https://arxiv.org/abs/2411.16370v6",
          "size": "3664kb",
          "version": "v6"
        }
      ],
      "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16370",
        "PDF": "https://arxiv.org/pdf/2411.16370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Bayesian uncertainty quantification in deep probabilistic image segmentation, which does not relate to LLM training data processing. It primarily addresses advances in uncertainty modeling and segmentation challenges, not data processing for LLMs."
      },
      "tasks": [
        "Active Learning",
        "Bayesian Inference",
        "Benchmarking",
        "Image Segmentation",
        "Semantic Segmentation",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14916",
      "abstract": "The task of automatically coding the International Classification of Diseases (ICD) in the medical field has been well-established and has received much attention. Automatic coding of the ICD in the medical field has been successful in English but faces challenges when dealing with Chinese electronic medical records (EMRs). The first issue lies in the difficulty of extracting disease code-related information from Chinese EMRs, primarily due to the concise writing style and specific internal structure of the EMRs. The second problem is that previous methods have failed to leverage the disease-based multi-axial knowledge and lack of association with the corresponding clinical evidence. This paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge with Evidence verification in ICD coding for Chinese EMRs. Initially, we identify candidate codes for the diagnosis and categorize each of them into knowledge under four coding axes.Subsequently, we retrieve corresponding clinical evidence from the comprehensive content of EMRs and filter credible evidence through a scoring model. Finally, to ensure the validity of the candidate code, we propose an inference module based on the masked language modeling strategy. This module verifies that all the axis knowledge associated with the candidate code is supported by evidence and provides recommendations accordingly. To evaluate the performance of our framework, we conduct experiments using a large-scale Chinese EMR dataset collected from various hospitals. The experimental results demonstrate that MKE-Coder exhibits significant superiority in the task of automatic ICD coding based on Chinese EMRs. In the practical evaluation of our method within simulated real coding scenarios, it has been demonstrated that our approach significantly aids coders in enhancing both their coding accuracy and speed.",
      "authors": [
        "Xinxin You",
        "Xien Liu",
        "Xue Yang",
        "Ziyi Wang",
        "Ji Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T08:08:53+00:00",
          "link": "https://arxiv.org/abs/2502.14916v1",
          "size": "5886kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T04:35:15+00:00",
          "link": "https://arxiv.org/abs/2502.14916v2",
          "size": "4186kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T08:32:32+00:00",
          "link": "https://arxiv.org/abs/2502.14916v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14916",
        "PDF": "https://arxiv.org/pdf/2502.14916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is concerned with ICD coding for Chinese EMRs through evidence verification and knowledge association, using a large-scale electronic medical records dataset. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03625",
      "abstract": "Path loss modeling is a widely used technique for estimating point-to-point losses along a communications link from transmitter (Tx) to receiver (Rx). Accurate path loss predictions can optimize use of the radio frequency spectrum and minimize unwanted interference. Modern path loss modeling often leverages data-driven approaches, using machine learning to train models on drive test measurement datasets. Drive tests primarily represent downlink scenarios, where the Tx is located on a building and the Rx is located on a moving vehicle. Consequently, trained models are frequently reserved for downlink coverage estimation, lacking representation of uplink scenarios. In this paper, we demonstrate that data augmentation can be used to train a path loss model that is generalized to uplink, downlink, and backhaul scenarios, training using only downlink drive test measurements. By adding a small number of synthetic samples representing uplink scenarios to the training set, root mean squared error is reduced by > 8 dB on uplink examples in the test set.",
      "authors": [
        "Ryan G. Dempsey",
        "Jonathan Ethier",
        "Halim Yanikomeroglu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T17:44:14+00:00",
          "link": "https://arxiv.org/abs/2504.03625v1",
          "size": "1554kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:10:23+00:00",
          "link": "https://arxiv.org/abs/2504.03625v2",
          "size": "1564kb",
          "version": "v2"
        }
      ],
      "title": "Reciprocity-Aware Convolutional Neural Networks for Map-Based Path Loss Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03625",
        "HTML": "https://arxiv.org/html/2504.03625",
        "PDF": "https://arxiv.org/pdf/2504.03625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper develops a model for path loss prediction in communication systems using data augmentation. It does not pertain to LLM training data processing."
      },
      "tasks": [
        "Data Augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03582",
      "abstract": "We present SemiOccam, an image recognition network that leverages semi-supervised learning in a highly efficient manner. Existing works often rely on complex training techniques and architectures, requiring hundreds of GPU hours for training, while their generalization ability with extremely limited labeled data remains to be improved. To address these limitations, we construct a hierarchical mixture density classification mechanism by optimizing mutual information between feature representations and target classes, compressing redundant information while retaining crucial discriminative components. Experimental results demonstrate that our method achieves state-of-the-art performance on three commonly used datasets, with accuracy exceeding 95% on two of them using only 4 labeled samples per class, and its simple architecture keeps training time at the minute level. Notably, this paper reveals a long-overlooked data leakage issue in the STL-10 dataset for semi-supervised learning and removes duplicates to ensure reliable experimental results. We release the deduplicated CleanSTL-10 dataset to facilitate fair and reproducible research. Code available at https://github.com/Shu1L0n9/SemiOccam.",
      "authors": [
        "Rui Yann",
        "Tianshuo Zhang",
        "Xianglei Xing"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T05:24:28+00:00",
          "link": "https://arxiv.org/abs/2506.03582v1",
          "size": "2777kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T15:45:08+00:00",
          "link": "https://arxiv.org/abs/2506.03582v2",
          "size": "3096kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T21:11:04+00:00",
          "link": "https://arxiv.org/abs/2506.03582v3",
          "size": "6520kb",
          "version": "v3"
        }
      ],
      "title": "SemiOccam: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03582",
        "HTML": "https://arxiv.org/html/2506.03582",
        "PDF": "https://arxiv.org/pdf/2506.03582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "SemiOccam involves a bit of data processing by deduplicating the STL-10 dataset, but its main focus is on the semi-supervised image recognition network and not on LLM data processing."
      },
      "datasets": [
        {
          "dataset_name": "Shu1L0n9/CleanSTL-10",
          "downloads": "67",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Shu1L0n9/CleanSTL-10"
        }
      ],
      "conference": "vitsgmm-a-robust-semi-supervised-image",
      "conference_url_abs": "https://papers.ssrn.com/abstract=5186712",
      "tasks": [
        "Semi-Supervised Image Classification"
      ],
      "repo_urls": [
        "https://github.com/Shu1L0n9/SemiOccam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14171",
      "abstract": "With the growth of demand on neural network compression methods, the structured pruning methods including importance-based approach are actively studied. The magnitude importance and many correlated modern importance criteria often limit the capacity of pruning decision, since the filters with larger magnitudes are not likely to be pruned if the smaller one didn't, even if it is redundant. In this paper, we propose a novel pruning strategy to challenge this dominating effect of magnitude and provide fair chance to each filter to be pruned, by placing it on projective space. After that, we observe the gradient descent movement whether the filters move toward the origin or not, to measure how the filter is likely to be pruned. This measurement is used to construct PROscore, a novel importance score for IPPRO, a novel importance-based structured pruning with magnitude-indifference. Our evaluation results shows that the proposed importance criteria using the projective space achieves near-lossless pruning by reducing the performance drop in pruning, with promising performance after the finetuning. Our work debunks the ``size-matters'' myth in pruning and expands the frontier of importance-based pruning both theoretically and empirically.",
      "authors": [
        "Jaeheun Jung",
        "Jaehyuk Lee",
        "Yeajin Lee",
        "Donghun Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.14171v1",
          "size": "961kb",
          "version": "v1"
        }
      ],
      "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14171",
        "HTML": "https://arxiv.org/html/2507.14171",
        "PDF": "https://arxiv.org/pdf/2507.14171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers around structured pruning methods for neural network compression, without addressing LLM training data processing tasks or methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14387",
      "abstract": "The escalating threat of cyberattacks on real-time critical infrastructures poses serious risks to public safety, demanding detection methods that effectively capture complex system interdependencies and adapt to evolving attack patterns. Traditional real-time anomaly detection techniques often suffer from excessive false positives due to their statistical sensitivity to high data variance and class imbalance. To address these limitations, recent research has explored modeling causal relationships among system components. However, prior work mainly focuses on offline causal graph-based approaches that require static historical data and fail to generalize to real-time settings. These methods are fundamentally constrained by: (1) their inability to adapt to dynamic shifts in data distribution without retraining, and (2) the risk of catastrophic forgetting when lacking timely supervision in live systems. To overcome these challenges, we propose INCADET, a novel framework for incremental causal graph learning tailored to real-time cyberattack detection. INCADET dynamically captures evolving system behavior by incrementally updating causal graphs across streaming time windows. The framework comprises three modules: 1) Early Symptom Detection: Detects transitions in system status using divergence in edge-weight distributions across sequential causal graphs. 2) Incremental Causal Graph Learning: Leverages experience replay and edge reinforcement to continually refine causal structures while preserving prior knowledge. 3) Causal Graph Classification: Employs Graph Convolutional Networks (GCNs) to classify system status using the learned causal graphs. Extensive experiments on real-world critical infrastructure datasets demonstrate that INCADET achieves superior accuracy, robustness, and adaptability compared to both static causal and deep temporal baselines in evolving attack scenarios.",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Dongjie Wang",
        "Haoyue Bai",
        "and Yanjie Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:27:13+00:00",
          "link": "https://arxiv.org/abs/2507.14387v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14387",
        "HTML": "https://arxiv.org/html/2507.14387",
        "PDF": "https://arxiv.org/pdf/2507.14387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cyberattack detection using causal graph learning, which is unrelated to LLM training data processing. It addresses dynamic system behavior and attack pattern adaptation rather than any aspect of language model data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14698",
      "abstract": "EEG-based emotion recognition plays an important role in developing adaptive brain-computer communication systems, yet faces two fundamental challenges in practical implementations: (1) effective integration of non-stationary spatial-temporal neural patterns, (2) robust adaptation to dynamic emotional intensity variations in real-world scenarios. This paper proposes SST-CL, a novel framework integrating spatial-temporal transformers with curriculum learning. Our method introduces two core components: a spatial encoder that models inter-channel relationships and a temporal encoder that captures multi-scale dependencies through windowed attention mechanisms, enabling simultaneous extraction of spatial correlations and temporal dynamics from EEG signals. Complementing this architecture, an intensity-aware curriculum learning strategy progressively guides training from high-intensity to low-intensity emotional states through dynamic sample scheduling based on a dual difficulty assessment. Comprehensive experiments on three benchmark datasets demonstrate state-of-the-art performance across various emotional intensity levels, with ablation studies confirming the necessity of both architectural components and the curriculum learning mechanism.",
      "authors": [
        "Xuetao Lin (1 and 2)",
        "Tianhao Peng (1 and 2)",
        "Peihong Dai (1 and 2)",
        "Yu Liang (3)",
        "Wenjun Wu (1 and 2) ((1) Beihang University",
        "Beijing",
        "China",
        "(2) SKLCCSE",
        "Beijing",
        "China",
        "(3) Beijing University of Technology",
        "Beijing",
        "China)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:23:38+00:00",
          "link": "https://arxiv.org/abs/2507.14698v1",
          "size": "1961kb",
          "version": "v1"
        }
      ],
      "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14698",
        "HTML": "https://arxiv.org/html/2507.14698",
        "PDF": "https://arxiv.org/pdf/2507.14698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with EEG-based emotion recognition using a spatial-temporal transformer and curriculum learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14893",
      "abstract": "Digital signatures are essential cryptographic tools that provide authentication and integrity in digital communications. However, privacy-sensitive applications, such as e-voting and digital cash, require more restrictive verification models to ensure confidentiality and control. Strong Designated Verifier Signature (SDVS) schemes address this need by enabling the signer to designate a specific verifier, ensuring that only this party can validate the signature. Existing SDVS constructions are primarily based on number-theoretic assumptions and are therefore vulnerable to quantum attacks. Although post-quantum alternatives, particularly those based on lattices, have been proposed, they often entail large key and signature sizes. In this work, we introduce $\\mathsf{CSI\\text{-}SDVS}$, a novel isogeny-based SDVS scheme that offers a compact, quantum-resistant alternative. Our construction builds on the ideal class group action framework of CSIDH and the signature techniques of CSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse Problem (MT-GAIP). $\\mathsf{CSI\\text{-}SDVS}$ achieves strong security guarantees; namely, Strong Unforgeability under Chosen-Message Attacks (SUF-CMA), Non-Transferability (NT), and Privacy of Signer's Identity (PSI), in the random oracle model. Remarkably, both the keys and signatures in $\\mathsf{CSI\\text{-}SDVS}$ are of size $\\mathcal{O}(\\lambda)$, representing a significant improvement over the typical $\\mathcal{O}(\\lambda^2)$ bounds in existing post-quantum SDVS schemes, thereby making it among the most compact PQC-based SDVS schemes and the only post-quantum secure construction based on isogenies.",
      "authors": [
        "Farzin Renan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:15:38+00:00",
          "link": "https://arxiv.org/abs/2507.14893v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14893",
        "HTML": "https://arxiv.org/html/2507.14893",
        "PDF": "https://arxiv.org/pdf/2507.14893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a novel post-quantum cryptographic signature scheme, dealing with cryptography and digital signatures. It does not address any aspect of LLM training data processing, nor does it relate to data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15203",
      "abstract": "Cardiac digital twins (CDTs) provide personalized in-silico cardiac representations and hold great potential for precision medicine in cardiology. However, whole-heart CDT models that simulate the full organ-scale electromechanics of all four heart chambers remain limited. In this work, we propose a weakly supervised learning model to reconstruct 4D (3D+t) heart mesh directly from multi-view 2D cardiac cine MRIs. This is achieved by learning a self-supervised mapping between cine MRIs and 4D cardiac meshes, enabling the generation of personalized heart models that closely correspond to input cine MRIs. The resulting 4D heart meshes can facilitate the automatic extraction of key cardiac variables, including ejection fraction and dynamic chamber volume changes with high temporal resolution. It demonstrates the feasibility of inferring personalized 4D heart models from cardiac MRIs, paving the way for an efficient CDT platform for precision medicine. The code will be publicly released once the manuscript is accepted.",
      "authors": [
        "Xiaoyue Liu",
        "Xicheng Sheng",
        "Xiahai Zhuang",
        "Vicente Grau",
        "Mark YY Chan",
        "Ching-Hui Sia",
        "Lei Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:01:33+00:00",
          "link": "https://arxiv.org/abs/2507.15203v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "Personalized 4D Whole Heart Geometry Reconstruction from Cine MRI for Cardiac Digital Twins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15203",
        "HTML": "https://arxiv.org/html/2507.15203",
        "PDF": "https://arxiv.org/pdf/2507.15203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on cardiac digital twins and the reconstruction of heart geometry from cine MRIs, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15253",
      "abstract": "Multimodal graphs, which integrate unstructured heterogeneous data with structured interconnections, offer substantial real-world utility but remain insufficiently explored in unsupervised learning. In this work, we initiate the study of multimodal graph clustering, aiming to bridge this critical gap. Through empirical analysis, we observe that real-world multimodal graphs often exhibit hybrid neighborhood patterns, combining both homophilic and heterophilic relationships. To address this challenge, we propose a novel framework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which decomposes the original hybrid graph into two complementary views: (1) a homophily-enhanced graph that captures cross-modal class consistency, and (2) heterophily-aware graphs that preserve modality-specific inter-class distinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism that jointly filters these disentangled graphs through a dual-pass strategy, enabling effective multimodal integration while mitigating category confusion. Our self-supervised alignment objectives further guide the learning process without requiring labels. Extensive experiments on both multimodal and multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art performance, highlighting its effectiveness and generalizability across diverse settings. Our code is available at https://github.com/Uncnbb/DMGC.",
      "authors": [
        "Zhaochen Guo",
        "Zhixiang Shen",
        "Xuanting Xie",
        "Liangjian Wen",
        "Zhao Kang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:29:53+00:00",
          "link": "https://arxiv.org/abs/2507.15253v1",
          "size": "2626kb",
          "version": "v1"
        }
      ],
      "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15253",
        "HTML": "https://arxiv.org/html/2507.15253",
        "PDF": "https://arxiv.org/pdf/2507.15253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for multimodal graph clustering, focusing on disentangling homophily and heterophily. It does not address LLM training data processing or dataset creation for LLM-specific applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15286",
      "abstract": "We present a novel evaluation paradigm for AI text detectors that prioritizes real-world and equitable assessment. Current approaches predominantly report conventional metrics like AUROC, overlooking that even modest false positive rates constitute a critical impediment to practical deployment of detection systems. Furthermore, real-world deployment necessitates predetermined threshold configuration, making detector stability (i.e. the maintenance of consistent performance across diverse domains and adversarial scenarios), a critical factor. These aspects have been largely ignored in previous research and benchmarks. Our benchmark, SHIELD, addresses these limitations by integrating both reliability and stability factors into a unified evaluation metric designed for practical assessment. Furthermore, we develop a post-hoc, model-agnostic humanification framework that modifies AI text to more closely resemble human authorship, incorporating a controllable hardness parameter. This hardness-aware approach effectively challenges current SOTA zero-shot detection methods in maintaining both reliability and stability. (Data and code: https://github.com/navid-aub/SHIELD-Benchmark)",
      "authors": [
        "Navid Ayoobi",
        "Sadat Shahriar",
        "Arjun Mukherjee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:37:27+00:00",
          "link": "https://arxiv.org/abs/2507.15286v1",
          "size": "1254kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15286",
        "PDF": "https://arxiv.org/pdf/2507.15286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving AI text detectors with a benchmark called SHIELD and a hardness-aware evaluation, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15343",
      "abstract": "The Transformer architecture has emerged as a landmark advancement within the broad field of artificial intelligence, effectively catalyzing the advent of large language models (LLMs). However, despite its remarkable capabilities and the substantial progress it has facilitated, the Transformer architecture still has some limitations. One such intrinsic limitation is its inability to effectively capture the Chomsky hierarchy, such as regular expressions or deterministic context-free grammars. Drawing inspiration from pushdown automata, which efficiently resolve deterministic context-free grammars using stacks, we propose StackTrans to address the aforementioned issue within LLMs. Unlike previous approaches that modify the attention computation, StackTrans explicitly incorporates hidden state stacks between Transformer layers. This design maintains compatibility with existing frameworks like flash-attention. Specifically, our design features stack operations -- such as pushing and popping hidden states -- that are differentiable and can be learned in an end-to-end manner. Our comprehensive evaluation spans benchmarks for both Chomsky hierarchies and large-scale natural languages. Across these diverse tasks, StackTrans consistently outperforms standard Transformer models and other baselines. We have successfully scaled StackTrans up from 360M to 7B parameters. In particular, our from-scratch pretrained model StackTrans-360M outperforms several larger open-source LLMs with 2-3x more parameters, showcasing its superior efficiency and reasoning capability.",
      "authors": [
        "Kechi Zhang",
        "Ge Li",
        "Jia Li",
        "Huangzhao Zhang",
        "Yihong Dong",
        "Jia Li",
        "Jingjing Xu",
        "Zhi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:58:03+00:00",
          "link": "https://arxiv.org/abs/2507.15343v1",
          "size": "815kb",
          "version": "v1"
        }
      ],
      "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15343",
        "HTML": "https://arxiv.org/html/2507.15343",
        "PDF": "https://arxiv.org/pdf/2507.15343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the StackTrans architecture, focusing on enhancing LLMs' capability to handle specific grammatical structures through a novel model architecture akin to pushdown automata. It does not address any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15606",
      "abstract": "While the proposal of the Tri-plane representation has advanced the development of the 3D-aware image generative models, problems rooted in its inherent structure, such as multi-face artifacts caused by sharing the same features in symmetric regions, limit its ability to generate 360$^\\circ$ view images. In this paper, we propose CylinderPlane, a novel implicit representation based on Cylindrical Coordinate System, to eliminate the feature ambiguity issue and ensure multi-view consistency in 360$^\\circ$. Different from the inevitable feature entanglement in Cartesian coordinate-based Tri-plane representation, the cylindrical coordinate system explicitly separates features at different angles, allowing our cylindrical representation possible to achieve high-quality, artifacts-free 360$^\\circ$ image synthesis. We further introduce the nested cylinder representation that composites multiple cylinders at different scales, thereby enabling the model more adaptable to complex geometry and varying resolutions. The combination of cylinders with different resolutions can effectively capture more critical locations and multi-scale features, greatly facilitates fine detail learning and robustness to different resolutions. Moreover, our representation is agnostic to implicit rendering methods and can be easily integrated into any neural rendering pipeline. Extensive experiments on both synthetic dataset and unstructured in-the-wild images demonstrate that our proposed representation achieves superior performance over previous methods.",
      "authors": [
        "Ru Jia",
        "Xiaozhuang Ma",
        "Jianji Wang",
        "Nanning Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:28:59+00:00",
          "link": "https://arxiv.org/abs/2507.15606v1",
          "size": "909kb",
          "version": "v1"
        }
      ],
      "title": "CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15606",
        "HTML": "https://arxiv.org/html/2507.15606",
        "PDF": "https://arxiv.org/pdf/2507.15606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel representation for 3D-aware image generation and rendering, which does not relate to LLM training data processing, data quality improvement, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11858",
      "abstract": "Large Language Models (LLMs) have demonstrated great potential as evaluators of NLG systems, allowing for high-quality, reference-free, and multi-aspect assessments. However, existing LLM-based metrics suffer from two major drawbacks: reliance on proprietary models to generate training data or perform evaluations, and a lack of fine-grained, explanatory feedback. In this paper, we introduce OpeNLGauge, a fully open-source, reference-free NLG evaluation metric that provides accurate explanations based on error spans. OpeNLGauge is available as a two-stage ensemble of larger open-weight LLMs, or as a small fine-tuned evaluation model, with confirmed generalizability to unseen tasks, domains and aspects. Our extensive meta-evaluation shows that OpeNLGauge achieves competitive correlation with human judgments, outperforming state-of-the-art models on certain tasks while maintaining full reproducibility and providing explanations more than twice as accurate.",
      "authors": [
        "Ivan Kart\\'a\\v{c}",
        "Mateusz Lango",
        "Ond\\v{r}ej Du\\v{s}ek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T20:38:47+00:00",
          "link": "https://arxiv.org/abs/2503.11858v1",
          "size": "9338kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:17:39+00:00",
          "link": "https://arxiv.org/abs/2503.11858v2",
          "size": "404kb",
          "version": "v2"
        }
      ],
      "title": "OpeNLGauge: An Explainable Metric for NLG Evaluation with Open-Weights LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11858",
        "HTML": "https://arxiv.org/html/2503.11858",
        "PDF": "https://arxiv.org/pdf/2503.11858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an evaluation metric for NLG systems and does not focus on training data processing or dataset creation for LLMs, thereby making it irrelevant to LLM training data processing."
      },
      "tasks": [
        "nlg evaluation"
      ],
      "repo_urls": [
        "https://github.com/ivankartac/OpeNLGauge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13163",
      "abstract": "Object detection models are typically applied to standard RGB images processed through Image Signal Processing (ISP) pipelines, which are designed to enhance sensor-captured RAW images for human vision. However, these ISP functions can lead to a loss of critical information that may be essential in optimizing for computer vision tasks, such as object detection. In this work, we introduce Raw Adaptation Module (RAM), a module designed to replace the traditional ISP, with parameters optimized specifically for RAW object detection. Inspired by the parallel processing mechanisms of the human visual system, RAM departs from existing learned ISP methods by applying multiple ISP functions in parallel rather than sequentially, allowing for a more comprehensive capture of image features. These processed representations are then fused in a specialized module, which dynamically integrates and optimizes the information for the target task. This novel approach not only leverages the full potential of RAW sensor data but also enables task-specific pre-processing, resulting in superior object detection performance. Our approach outperforms RGB-based methods and achieves state-of-the-art results across diverse RAW image datasets under varying lighting conditions and dynamic ranges.",
      "authors": [
        "Shani Gamrian",
        "Hila Barel",
        "Feiran Li",
        "Masakazu Yoshimura",
        "Daisuke Iso"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T13:36:49+00:00",
          "link": "https://arxiv.org/abs/2503.13163v1",
          "size": "39041kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T14:20:31+00:00",
          "link": "https://arxiv.org/abs/2503.13163v2",
          "size": "41517kb",
          "version": "v2"
        }
      ],
      "title": "Beyond RGB: Adaptive Parallel Processing for RAW Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13163",
        "HTML": "https://arxiv.org/html/2503.13163",
        "PDF": "https://arxiv.org/pdf/2503.13163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adaptive processing for RAW object detection using the Raw Adaptation Module (RAM), which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14497",
      "abstract": "Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000 pixels, posing significant challenges for multimodal large language model (MLLM) due to long context length and high computational demands. Previous methods typically focus on patch-level analysis or slide-level classification using CLIP-based models with multi-instance learning, but they lack the generative capabilities needed for visual question answering (VQA). More recent MLLM-based approaches address VQA by feeding thousands of patch tokens directly into the language model, which leads to excessive resource consumption. To address these limitations, we propose Token Compression Pathology LLaVA (TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token compression. TCP-LLaVA introduces a set of trainable compression tokens that aggregate visual and textual information through a modality compression module, inspired by the [CLS] token mechanism in BERT. Only the compressed tokens are forwarded to the LLM for answer generation, significantly reducing input length and computational cost. Experiments on ten TCGA tumor subtypes show that TCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing training resource consumption by a substantial margin.",
      "authors": [
        "Weimin Lyu",
        "Qingqiao Hu",
        "Kehan Qi",
        "Zhan Shi",
        "Wentao Huang",
        "Saumya Gupta",
        "Chao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:04:25+00:00",
          "link": "https://arxiv.org/abs/2507.14497v1",
          "size": "3504kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Whole Slide Pathology VQA via Token Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14497",
        "HTML": "https://arxiv.org/html/2507.14497",
        "PDF": "https://arxiv.org/pdf/2507.14497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TCP-LLaVA, which compresses visual and text tokens for whole-slide pathology VQA. While it mentions reducing training resources, it mainly focuses on model architecture improvements rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14527",
      "abstract": "Researchers frequently need to synthesize their own publications into coherent narratives that demonstrate their scholarly contributions. To suit diverse communication contexts, exploring alternative ways to organize one's work while maintaining coherence is particularly challenging, especially in interdisciplinary fields like HCI where individual researchers' publications may span diverse domains and methodologies. In this paper, we present PaperBridge, a human-AI co-exploration system informed by a formative study and content analysis. PaperBridge assists researchers in exploring diverse perspectives for organizing their publications into coherent narratives. At its core is a bi-directional analysis engine powered by large language models, supporting iterative exploration through both top-down user intent (e.g., determining organization structure) and bottom-up refinement on narrative components (e.g., thematic paper groupings). Our user study (N=12) demonstrated PaperBridge's usability and effectiveness in facilitating the exploration of alternative research narratives. Our findings also provided empirical insights into how interactive systems can scaffold academic communication tasks.",
      "authors": [
        "Runhua Zhang",
        "Yang Ouyang",
        "Leixian Shen",
        "Yuying Tang",
        "Xiaojuan Ma",
        "Huamin Qu",
        "Xian Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:04:23+00:00",
          "link": "https://arxiv.org/abs/2507.14527v1",
          "size": "3315kb",
          "version": "v1"
        }
      ],
      "title": "PaperBridge: Crafting Research Narratives through Human-AI Co-Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14527",
        "HTML": "https://arxiv.org/html/2507.14527",
        "PDF": "https://arxiv.org/pdf/2507.14527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PaperBridge's focus on assisting researchers in organizing their publications into narratives does not contribute to LLM training data processing in any clear capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15013",
      "abstract": "In the smart era, psychometric tests are becoming increasingly important for personnel selection, career development, and mental health assessment. Forced-choice tests are common in personality assessments because they require participants to select from closely related options, lowering the risk of response distortion. This study presents a deep learning-based Forced-Choice Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of traditional models and is applicable to the three most common item block types found in forced-choice tests. To account for the unidimensionality of items in forced-choice tests, we create interpretable participant and item parameters. We model the interactions between participant and item features using multilayer neural networks after mining them using nonlinear mapping. In addition, we use the monotonicity assumption to improve the interpretability of the diagnostic results. The FCNCD's effectiveness is validated by experiments on real-world and simulated datasets that show its accuracy, interpretability, and robustness.",
      "authors": [
        "Xiaoyu Li and Jin Wu and Shaoyang Guo and Haoran Shi and Chanjin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:39:36+00:00",
          "link": "https://arxiv.org/abs/2507.15013v1",
          "size": "1588kb",
          "version": "v1"
        }
      ],
      "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15013",
        "HTML": "https://arxiv.org/html/2507.15013",
        "PDF": "https://arxiv.org/pdf/2507.15013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a neural cognitive diagnostic model for personality testing, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15117",
      "abstract": "We propose a modal study of the notion of bisimulation. Our contribution is twofold. First, we extend the basic modal language with a new modality [b], whose intended meaning is universal quantification over all states that are bisimilar to the current one. We show that bisimulations are definable in this object language. Second, we provide a sound and complete axiomatisation of the class of all pairs of Kripke models linked by bisimulations.",
      "authors": [
        "Alfredo Burrieza and Fernando Soler-Toscano and Antonio Yuste-Ginel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:32:14+00:00",
          "link": "https://arxiv.org/abs/2507.15117v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "A meta-modal logic for bisimulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15117",
        "HTML": "https://arxiv.org/html/2507.15117",
        "PDF": "https://arxiv.org/pdf/2507.15117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores a modal logic for bisimulation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15231",
      "abstract": "We generalize the well-known Coupon Collector Problem (CCP) in combinatorics. Our problem is to find the minimum and expected number of draws, with replacement, required to recover $n$ distinctly labeled coupons, with each draw consisting of a random subset of $k$ different coupons and a random ordering of their associated labels. We specify two variations of the problem, Type-I in which the set of labels is known at the start, and Type-II in which the set of labels is unknown at the start. We show that our problem can be viewed as an extension of the separating system problem introduced by R\\'enyi and Katona, provide a full characterization of the minimum, and provide a numerical approach to finding the expectation using a Markov chain model, with special attention given to the case where two coupons are drawn at a time.",
      "authors": [
        "Andrew Tan",
        "Oriel Limor",
        "Daniella Bar-Lev",
        "Ryan Gabrys",
        "Zohar Yakhini",
        "Paul H. Siegel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:24:03+00:00",
          "link": "https://arxiv.org/abs/2507.15231v1",
          "size": "170kb",
          "version": "v1"
        }
      ],
      "title": "The Labeled Coupon Collector Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15231",
        "HTML": "https://arxiv.org/html/2507.15231",
        "PDF": "https://arxiv.org/pdf/2507.15231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a generalization of the Coupon Collector Problem in combinatorics and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15431",
      "abstract": "We offer a theoretical mathematical background to Transformers through Lagrangian optimization across the token space. The Transformer, as a flow map, exists in the tangent fiber for each token along the high-dimensional unit sphere. The circumstance of the hypersphere across the latent data is reasonable due to the trained diagonal matrix equal to the identity, which has various empirical justifications. Thus, under the continuum limit of the dynamics, the latent vectors flow among the tangent bundle. Using these facts, we devise a mathematical framework for the Transformer through calculus of variations. We develop a functional and show that the continuous flow map induced by the Transformer satisfies this functional, therefore the Transformer can be viewed as a natural solver of a calculus of variations problem. We invent new scenarios of when our methods are applicable based on loss optimization with respect to path optimality. We derive the Euler-Lagrange equation for the Transformer. The variant of the Euler-Lagrange equation we present has various appearances in literature, but, to our understanding, oftentimes not foundationally proven or under other specialized cases. Our overarching proof is new: our techniques are classical and the use of the flow map object is original. We provide several other relevant results, primarily ones specific to neural scenarios. In particular, much of our analysis will be attempting to quantify Transformer data in variational contexts under neural approximations. Calculus of variations on manifolds is a well-nourished research area, but for the Transformer specifically, it is uncharted: we lay the foundation for this area through an introduction to the Lagrangian for the Transformer.",
      "authors": [
        "Andrew Gracyk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:43:33+00:00",
          "link": "https://arxiv.org/abs/2507.15431v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "The calculus of variations of the Transformer on the hyperspherical tangent bundle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15431",
        "PDF": "https://arxiv.org/pdf/2507.15431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a theoretical framework for Transformers using calculus of variations, focusing on mathematical optimization rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15717",
      "abstract": "Current benchmarks evaluating large language models (LLMs) in ophthalmology are limited in scope and disproportionately prioritise accuracy. We introduce BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive evaluation benchmark developed through multiple rounds of expert checking by 13 ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset underwent multiple rounds of expert checking. Duplicate and substandard questions were systematically removed. Ten ophthalmologists refined the explanations of each MCQ's correct answer. This was further adjudicated by three senior ophthalmologists. To illustrate BELO's utility, we evaluated six LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro) using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore, BARTScore, METEOR, and AlignScore). In a further evaluation involving human experts, two ophthalmologists qualitatively reviewed 50 randomly selected outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900 high-quality, expert-reviewed questions aggregated from five sources: BCSC (260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public leaderboard has been established to promote transparent evaluation and reporting. Importantly, the BELO dataset will remain a hold-out, evaluation-only benchmark to ensure fair and reproducible comparisons of future models.",
      "authors": [
        "Sahana Srinivasan",
        "Xuguang Ai",
        "Thaddaeus Wai Soon Lo",
        "Aidan Gilson",
        "Minjie Zou",
        "Ke Zou",
        "Hyunjae Kim",
        "Mingjia Yang",
        "Krithi Pushpanathan",
        "Samantha Yew",
        "Wan Ting Loke",
        "Jocelyn Goh",
        "Yibing Chen",
        "Yiming Kong",
        "Emily Yuelei Fu",
        "Michelle Ongyong Hui",
        "Kristen Nwanyanwu",
        "Amisha Dave",
        "Kelvin Zhenghao Li",
        "Chen-Hsin Sun",
        "Mark Chia",
        "Gabriel Dawei Yang",
        "Wendy Meihua Wong",
        "David Ziyou Chen",
        "Dianbo Liu",
        "Maxwell Singer",
        "Fares Antaki",
        "Lucian V Del Priore",
        "Jost Jonas",
        "Ron Adelman",
        "Qingyu Chen",
        "Yih-Chung Tham"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:27:32+00:00",
          "link": "https://arxiv.org/abs/2507.15717v1",
          "size": "1088kb",
          "version": "v1"
        }
      ],
      "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15717",
        "PDF": "https://arxiv.org/pdf/2507.15717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes the creation of the BELO benchmark for evaluating ophthalmology-related knowledge in LLMs, which involves curating a dataset from multiple sources. However, the main focus is on evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20444",
      "abstract": "Continual learning requires to overcome catastrophic forgetting when training a single model on a sequence of tasks. Recent top-performing approaches are prompt-based methods that utilize a set of learnable parameters (i.e., prompts) to encode task knowledge, from which appropriate ones are selected to guide the fixed pre-trained model in generating features tailored to a certain task. However, existing methods rely on predicting prompt identities for prompt selection, where the identity prediction process cannot be optimized with task loss. This limitation leads to sub-optimal prompt selection and inadequate adaptation of pre-trained features for a specific task. Previous efforts have tried to address this by directly generating prompts from input queries instead of selecting from a set of candidates. However, these prompts are continuous, which lack sufficient abstraction for task knowledge representation, making them less effective for continual learning. To address these challenges, we propose VQ-Prompt, a prompt-based continual learning method that incorporates Vector Quantization (VQ) into end-to-end training of a set of discrete prompts. In this way, VQ-Prompt can optimize the prompt selection process with task loss and meanwhile achieve effective abstraction of task knowledge for continual learning. Extensive experiments show that VQ-Prompt outperforms state-of-the-art continual learning methods across a variety of benchmarks under the challenging class-incremental setting. The code is available at \\href{https://github.com/jiaolifengmi/VQ-Prompt}{this https URL}.",
      "authors": [
        "Li Jiao",
        "Qiuxia Lai",
        "Yu Li",
        "Qiang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-27T13:43:53+00:00",
          "link": "https://arxiv.org/abs/2410.20444v1",
          "size": "988kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T07:34:37+00:00",
          "link": "https://arxiv.org/abs/2410.20444v2",
          "size": "988kb",
          "version": "v2"
        }
      ],
      "title": "Vector Quantization Prompting for Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20444",
        "HTML": "https://arxiv.org/html/2410.20444",
        "PDF": "https://arxiv.org/pdf/2410.20444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a continual learning method using vector quantization prompting, focusing on overcoming catastrophic forgetting. It does not discuss LLM training data processing or creation."
      },
      "tasks": [
        "Continual Learning",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/jiaolifengmi/vq-prompt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05770",
      "abstract": "This very preliminary text is related to ``Algorithms on Texts'', also called ``Algorithmic Stringology''. It is an extension of the book ``125 Problems in Text Algorithms'' providing, in the same compact style, more problems with solutions. We refer also to the companions to ``Text algorithms'' available at http://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf and at the web page http://125-problems.univ-mlv.fr, where all 150 problems (including the ones presented here) are briefly announced. The selected problems satisfy three criteria: challenging, having short tricky solutions and solvable with only very basic background in stringology. For the basics in stringology we refer to http://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf.",
      "authors": [
        "Maxime Crochemore",
        "Thierry Lecroq and Wojtek Rytter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:16:50+00:00",
          "link": "https://arxiv.org/abs/2507.05770v1",
          "size": "4743kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:07:26+00:00",
          "link": "https://arxiv.org/abs/2507.05770v2",
          "size": "4743kb",
          "version": "v2"
        }
      ],
      "title": "25 Additional Problems -- Extension to the Book \"125 Problems in Text Algorithms\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05770",
        "PDF": "https://arxiv.org/pdf/2507.05770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides additional problems and solutions related to text algorithms, termed 'Algorithmic Stringology,' without discussing LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12561",
      "abstract": "Architectural smells such as God Class, Cyclic Dependency, and Hub-like Dependency degrade software quality and maintainability. Existing tools detect such smells but rarely suggest how to fix them. This paper explores the use of pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable refactorings based on detected smells. We frame the task as a three-class classification problem and fine-tune both models on over 2 million refactoring instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9% accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our results show that transformer-based models can effectively bridge the gap between smell detection and actionable repair, laying the foundation for future refactoring recommendation systems. We release all code, models, and data under an open license to support reproducibility and further research.",
      "authors": [
        "Samal Nursapa",
        "Anastassiya Samuilova",
        "Alessio Bucaioni",
        "Phuong T. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:19:51+00:00",
          "link": "https://arxiv.org/abs/2507.12561v1",
          "size": "1183kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T19:14:49+00:00",
          "link": "https://arxiv.org/abs/2507.12561v2",
          "size": "1183kb",
          "version": "v2"
        }
      ],
      "title": "ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12561",
        "PDF": "https://arxiv.org/pdf/2507.12561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning transformer models on a dataset of refactoring instances. However, the main focus is on model performance for architectural smells rather than advancing LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14639",
      "abstract": "Kinetic parameters such as the turnover number ($k_{cat}$) and Michaelis constant ($K_{\\mathrm{M}}$) are essential for modelling enzymatic activity but experimental data remains limited in scale and diversity. Previous methods for predicting enzyme kinetics typically use mean-pooled residue embeddings from a single protein language model to represent the protein. We present KinForm, a machine learning framework designed to improve predictive accuracy and generalisation for kinetic parameters by optimising protein feature representations. KinForm combines several residue-level embeddings (Evolutionary Scale Modeling Cambrian, Evolutionary Scale Modeling 2, and ProtT5-XL-UniRef50), taken from empirically selected intermediate transformer layers and applies weighted pooling based on per-residue binding-site probability. To counter the resulting high dimensionality, we apply dimensionality reduction using principal--component analysis (PCA) on concatenated protein features, and rebalance the training data via a similarity-based oversampling strategy. KinForm outperforms baseline methods on two benchmark datasets. Improvements are most pronounced in low sequence similarity bins. We observe improvements from binding-site probability pooling, intermediate-layer selection, PCA, and oversampling of low-identity proteins. We also find that removing sequence overlap between folds provides a more realistic evaluation of generalisation and should be the standard over random splitting when benchmarking kinetic prediction models.",
      "authors": [
        "Saleh Alwer and Ronan Fleming"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:34:57+00:00",
          "link": "https://arxiv.org/abs/2507.14639v1",
          "size": "6943kb",
          "version": "v1"
        }
      ],
      "title": "KinForm: Kinetics Informed Feature Optimised Representation Models for Enzyme $k_{cat}$ and $K_{M}$ Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14639",
        "HTML": "https://arxiv.org/html/2507.14639",
        "PDF": "https://arxiv.org/pdf/2507.14639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents KinForm, a model for predicting enzyme kinetics using protein language model embeddings. It does not relate to LLM training data processing, as it primarily focuses on biochemical data representation and prediction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14879",
      "abstract": "In recent years, the emergence of foundation models for depth prediction has led to remarkable progress, particularly in zero-shot monocular depth estimation. These models generate impressive depth predictions; however, their outputs are often in relative scale rather than metric scale. This limitation poses challenges for direct deployment in real-world applications. To address this, several scale adaptation methods have been proposed to enable foundation models to produce metric depth. However, these methods are typically costly, as they require additional training on new domains and datasets. Moreover, fine-tuning these models often compromises their original generalization capabilities, limiting their adaptability across diverse scenes. In this paper, we introduce a non-learning-based approach that leverages sparse depth measurements to adapt the relative-scale predictions of foundation models into metric-scale depth. Our method requires neither retraining nor fine-tuning, thereby preserving the strong generalization ability of the original foundation models while enabling them to produce metric depth. Experimental results demonstrate the effectiveness of our approach, high-lighting its potential to bridge the gap between relative and metric depth without incurring additional computational costs or sacrificing generalization ability.",
      "authors": [
        "Rizhao Fan and Tianfang Ma and Zhigen Li and Ning An and Jian Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T09:36:57+00:00",
          "link": "https://arxiv.org/abs/2507.14879v1",
          "size": "6831kb",
          "version": "v1"
        }
      ],
      "title": "Region-aware Depth Scale Adaptation with Sparse Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14879",
        "HTML": "https://arxiv.org/html/2507.14879",
        "PDF": "https://arxiv.org/pdf/2507.14879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on depth scale adaptation using sparse measurements for monocular depth estimation, which does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15385",
      "abstract": "The growing integration of renewable energy sources in modern power systems has introduced significant operational challenges due to their intermittent and uncertain outputs. In recent years, mobile energy storage systems (ESSs) have emerged as a popular flexible resource for mitigating these challenges. Compared to stationary ESSs, mobile ESSs offer additional spatial flexibility, enabling cost-effective energy delivery through the transportation network. However, the widespread deployment of mobile ESSs is often hindered by the high investment cost, which has motivated researchers to investigate utilising more readily available alternatives, such as electric vehicles (EVs) as mobile energy storage units instead. Hence, we explore this opportunity with a MIP-based day-ahead electric vehicle joint routing and scheduling problem in this work. However, solving the problem in a practical setting can often be computationally intractable since the existence of binary variables makes it combinatorial challenging. Therefore, we proposed to simplify the problem's solution process for a MIP solver by pruning the solution search space with a transformer-based deep learning (DL) model. This is done by training the model to rapidly predict the optimal binary solutions. In addition, unlike many existing DL approaches that assume fixed problem structures, the proposed model is designed to accommodate problems with EV fleets of any sizes. This flexibility is essential since frequent re-training can introduce significant computational overhead. We evaluated the approach with simulations on the IEEE 33-bus system coupled with the Nguyen-Dupuis transportation network.",
      "authors": [
        "Jun Kang Yap",
        "Vishnu Monn Baskaran",
        "Wen Shan Tan",
        "Ze Yang Ding",
        "Hao Wang",
        "David L. Dowe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:41:05+00:00",
          "link": "https://arxiv.org/abs/2507.15385v1",
          "size": "1186kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-based Deep Learning Model for Joint Routing and Scheduling with Varying Electric Vehicle Numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15385",
        "HTML": "https://arxiv.org/html/2507.15385",
        "PDF": "https://arxiv.org/pdf/2507.15385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores using a transformer-based model for optimizing electric vehicle routing and scheduling. It does not address LLM training data processing operations or methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15550",
      "abstract": "Evaluating the scientific discovery capabilities of large language model based agents, particularly how they cope with varying environmental complexity and utilize prior knowledge, requires specialized benchmarks currently lacking in the landscape. To address this gap, we introduce PhysGym, a novel benchmark suite and simulation platform for rigorously assessing LLM-based scientific reasoning in interactive physics environments. PhysGym's primary contribution lies in its sophisticated control over the level of prior knowledge provided to the agent. This allows researchers to dissect agent performance along axes including the complexity of the problem and the prior knowledge levels. The benchmark comprises a suite of interactive simulations, where agents must actively probe environments, gather data sequentially under constraints and formulate hypotheses about underlying physical laws. PhysGym provides standardized evaluation protocols and metrics for assessing hypothesis accuracy and model fidelity. We demonstrate the benchmark's utility by presenting results from baseline LLMs, showcasing its ability to differentiate capabilities based on varying priors and task complexity.",
      "authors": [
        "Yimeng Chen",
        "Piotr Pi\\c{e}kos",
        "Mateusz Ostaszewski",
        "Firas Laakom",
        "J\\\"urgen Schmidhuber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:28:10+00:00",
          "link": "https://arxiv.org/abs/2507.15550v1",
          "size": "3209kb",
          "version": "v1"
        }
      ],
      "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15550",
        "PDF": "https://arxiv.org/pdf/2507.15550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces PhysGym, a benchmark for evaluating LLMs' scientific reasoning in physics environments. The main focus is on evaluation and testing methodologies, not on the processing or creation of training data for LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15714",
      "abstract": "The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection, introduces an emotion recognition challenge spanning over 28 languages. This competition encourages researchers to explore more advanced approaches to address the challenges posed by the diversity of emotional expressions and background variations. It features two tracks: multi-label classification (Track A) and emotion intensity prediction (Track B), covering six emotion categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we systematically explore the benefits of two contrastive learning approaches: sample-based (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO) contrastive learning. The sample-based contrastive approach trains the model by comparing two samples to generate more reliable predictions. The generation-based contrastive approach trains the model to differentiate between correct and incorrect generations, refining its prediction. All models are fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A and 6th place in Track B for English, while ranking among the top-tier performing systems for other languages.",
      "authors": [
        "Tian Li",
        "Yujian Sun",
        "Huizhi Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:25:47+00:00",
          "link": "https://arxiv.org/abs/2507.15714v1",
          "size": "340kb",
          "version": "v1"
        }
      ],
      "title": "Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15714",
        "HTML": "https://arxiv.org/html/2507.15714",
        "PDF": "https://arxiv.org/pdf/2507.15714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning LLaMa3-Instruct-8B using contrastive learning for emotion perception, but it primarily focuses on model training techniques rather than training data processing aspects. It does not significantly contribute to dataset creation or quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.16660",
      "abstract": "Mobile device control agents can largely enhance user interactions and productivity by automating daily tasks. However, despite growing interest in developing practical agents, the absence of a commonly adopted benchmark in this area makes it challenging to quantify scientific progress. In this work, we introduce B-MoCA: a novel benchmark with interactive environments for evaluating and developing mobile device control agents. To create a realistic benchmark, we develop B-MoCA based on the Android operating system and define 131 common daily tasks. Importantly, we incorporate a randomization feature that changes the configurations of mobile devices, including user interface layouts and language settings, to assess generalization performance. We benchmark diverse agents, including agents employing large language models (LLMs) or multi-modal LLMs as well as agents trained with imitation learning using human expert demonstrations. While these agents demonstrate proficiency in executing straightforward tasks, their poor performance on complex tasks highlights significant opportunities for future research to improve effectiveness. Our source code is publicly available at https://b-moca.github.io.",
      "authors": [
        "Juyong Lee",
        "Taywon Min",
        "Minyong An",
        "Dongyoon Hahm",
        "Haeone Lee",
        "Changyeon Kim",
        "Kimin Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-25T14:56:32+00:00",
          "link": "https://arxiv.org/abs/2404.16660v1",
          "size": "7387kb",
          "version": "v1"
        },
        {
          "date": "2024-10-19T07:07:58+00:00",
          "link": "https://arxiv.org/abs/2404.16660v2",
          "size": "10570kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T02:55:09+00:00",
          "link": "https://arxiv.org/abs/2404.16660v3",
          "size": "12223kb",
          "version": "v3"
        }
      ],
      "title": "Benchmarking Mobile Device Control Agents across Diverse Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16660",
        "PDF": "https://arxiv.org/pdf/2404.16660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Though the paper mentions benchmarking agents using LLMs, the main focus is on developing a benchmark for mobile device control, not directly on LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Imitation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.02217",
      "abstract": "Climate change not only threatens agricultural producers but also strains related public agencies and financial institutions. These important food system actors include government entities tasked with insuring grower livelihoods and supporting response to continued global warming. We examine future risk within the U.S. Corn Belt geographic region for one such crucial institution: the U.S. Federal Crop Insurance Program. Specifically, we predict the impacts of climate-driven crop loss at a policy-salient \"risk unit\" scale. Built through our presented neural network Monte Carlo method, simulations anticipate both more frequent and more severe losses that would result in a costly doubling of the annual probability of maize Yield Protection insurance claims at mid-century. We also provide an open source pipeline and interactive visualization tools to explore these results with configurable statistical treatments. Altogether, we fill an important gap in current understanding for climate adaptation by bridging existing historic yield estimation and climate projection to predict crop loss metrics at policy-relevant granularity.",
      "authors": [
        "A Samuel Pottinger",
        "Lawson Connor",
        "Brookie Guzder-Williams",
        "Maya Weltman-Fahs",
        "Nick Gondek",
        "Timothy Bowles"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-05T03:38:38+00:00",
          "link": "https://arxiv.org/abs/2408.02217v1",
          "size": "343kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T05:25:39+00:00",
          "link": "https://arxiv.org/abs/2408.02217v2",
          "size": "936kb",
          "version": "v2"
        }
      ],
      "title": "Climate-Driven Doubling of U.S. Maize Loss Probability: Interactive Simulation with Neural Network Monte Carlo",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02217",
        "HTML": "https://arxiv.org/html/2408.02217",
        "PDF": "https://arxiv.org/pdf/2408.02217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper predicts climate-driven agricultural impacts using neural network Monte Carlo simulations, unrelated to LLM training data processing."
      },
      "tasks": [
        "Climate Projection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12553",
      "abstract": "Solving the three-dimensional (3D) Bratu equation is highly challenging due to the presence of multiple and sharp solutions. Research on this equation began in the late 1990s, but there are no satisfactory results to date. To address this issue, we introduce a symmetric finite difference method (SFDM) which embeds the symmetry properties of the solutions into a finite difference method (FDM). This SFDM is primarily used to obtain more accurate solutions and bifurcation diagrams for the 3D Bratu equation. Additionally, we propose modifying the Bratu equation by incorporating a new constraint that facilitates the construction of bifurcation diagrams and simplifies handling the turning points. The proposed method, combined with the use of sparse matrix representation, successfully solves the 3D Bratu equation on grids of up to $301^3$ points. The results demonstrate that SFDM outperforms all previously employed methods for the 3D Bratu equation. Furthermore, we provide bifurcation diagrams for the 1D, 2D, 4D, and 5D cases, and accurately identify the first turning points in all dimensions. All simulations indicate that the bifurcation diagrams of the Bratu equation on the cube domains closely resemble the well-established behavior on the ball domains described by Joseph and Lundgren [1]. Furthermore, when SFDM is applied to linear stability analysis, it yields the same largest real eigenvalue as the standard FDM despite having fewer equations and variables in the nonlinear system.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Hadi Susanto",
        "Haralampos Hatzikirou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Optimization and Control (math.OC)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T13:30:44+00:00",
          "link": "https://arxiv.org/abs/2410.12553v1",
          "size": "334kb",
          "version": "v1"
        },
        {
          "date": "2024-10-22T14:33:44+00:00",
          "link": "https://arxiv.org/abs/2410.12553v2",
          "size": "335kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:09:28+00:00",
          "link": "https://arxiv.org/abs/2410.12553v3",
          "size": "323kb",
          "version": "v3"
        }
      ],
      "title": "A finite difference method with symmetry properties for the high-dimensional Bratu equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12553",
        "HTML": "https://arxiv.org/html/2410.12553",
        "PDF": "https://arxiv.org/pdf/2410.12553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a finite difference method for solving the high-dimensional Bratu equation, without addressing any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/luthfishahab/sfdm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12703",
      "abstract": "This paper introduces HEPPO-GAE, an FPGA-based accelerator designed to optimize the Generalized Advantage Estimation (GAE) stage in Proximal Policy Optimization (PPO). Unlike previous approaches that focused on trajectory collection and actor-critic updates, HEPPO-GAE addresses GAE's computational demands with a parallel, pipelined architecture implemented on a single System-on-Chip (SoC). This design allows for the adaptation of various hardware accelerators tailored for different PPO phases. A key innovation is our strategic standardization technique, which combines dynamic reward standardization and block standardization for values, followed by 8-bit uniform quantization. This method stabilizes learning, enhances performance, and manages memory bottlenecks, achieving a 4x reduction in memory usage and a 1.5x increase in cumulative rewards. We propose a solution on a single SoC device with programmable logic and embedded processors, delivering throughput orders of magnitude higher than traditional CPU-GPU systems. Our single-chip solution minimizes communication latency and throughput bottlenecks, significantly boosting PPO training efficiency. Experimental results show a 30% increase in PPO speed and a substantial reduction in memory access time, underscoring HEPPO-GAE's potential for broad applicability in hardware-efficient reinforcement learning algorithms.",
      "authors": [
        "Hazem Taha and Ameer M. S. Abdelhadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T08:18:56+00:00",
          "link": "https://arxiv.org/abs/2501.12703v1",
          "size": "2052kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T04:43:33+00:00",
          "link": "https://arxiv.org/abs/2501.12703v2",
          "size": "925kb",
          "version": "v2"
        }
      ],
      "title": "HEPPO-GAE: Hardware-Efficient Proximal Policy Optimization with Generalized Advantage Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12703",
        "HTML": "https://arxiv.org/html/2501.12703",
        "PDF": "https://arxiv.org/pdf/2501.12703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hardware-efficient reinforcement learning algorithms and computational optimization using FPGA for Proximal Policy Optimization. It does not make any contribution related to LLM training data processing."
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00580",
      "abstract": "Brain foundation models (BFMs) have emerged as a transformative paradigm in computational neuroscience, offering a revolutionary framework for processing diverse neural signals across different brain-related tasks. These models leverage large-scale pre-training techniques, allowing them to generalize effectively across multiple scenarios, tasks, and modalities, thus overcoming the traditional limitations faced by conventional artificial intelligence (AI) approaches in understanding complex brain data. By tapping into the power of pretrained models, BFMs provide a means to process neural data in a more unified manner, enabling advanced analysis and discovery in the field of neuroscience. In this survey, we define BFMs for the first time, providing a clear and concise framework for constructing and utilizing these models in various applications. We also examine the key principles and methodologies for developing these models, shedding light on how they transform the landscape of neural signal processing. This survey presents a comprehensive review of the latest advancements in BFMs, covering the most recent methodological innovations, novel views of application areas, and challenges in the field. Notably, we highlight the future directions and key challenges that need to be addressed to fully realize the potential of BFMs. These challenges include improving the quality of brain data, optimizing model architecture for better generalization, increasing training efficiency, and enhancing the interpretability and robustness of BFMs in real-world applications.",
      "authors": [
        "Xinliang Zhou",
        "Chenyu Liu",
        "Zhisheng Chen",
        "Kun Wang",
        "Yi Ding",
        "Ziyu Jia and Qingsong Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T18:12:50+00:00",
          "link": "https://arxiv.org/abs/2503.00580v1",
          "size": "8418kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T09:40:27+00:00",
          "link": "https://arxiv.org/abs/2503.00580v2",
          "size": "5948kb",
          "version": "v2"
        }
      ],
      "title": "Brain Foundation Models: A Survey on Advancements in Neural Signal Processing and Brain Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00580",
        "HTML": "https://arxiv.org/html/2503.00580",
        "PDF": "https://arxiv.org/pdf/2503.00580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey centers on Brain Foundation Models for neural signal processing. It discusses advancements in neuroscience applications, not related to LLM training data processing."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20748",
      "abstract": "This paper presents a novel symbolic algorithm for the Maximal End Component (MEC) decomposition of a Markov Decision Process (MDP). The key idea behind our algorithm INTERLEAVE is to interleave the computation of Strongly Connected Components (SCCs) with eager elimination of redundant state-action pairs, rather than performing these computations sequentially as done by existing state-of-the-art algorithms. Even though our approach has the same complexity as prior works, an empirical evaluation of INTERLEAVE on the standardized Quantitative Verification Benchmark Set demonstrates that it solves 19 more benchmarks (out of 379) than the closest previous algorithm. On the 149 benchmarks that prior approaches can solve, we demonstrate a 3.81x average speedup in runtime.",
      "authors": [
        "Suguman Bansal and Ramneet Singh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T05:43:55+00:00",
          "link": "https://arxiv.org/abs/2505.20748v1",
          "size": "494kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T20:56:09+00:00",
          "link": "https://arxiv.org/abs/2505.20748v2",
          "size": "494kb",
          "version": "v2"
        }
      ],
      "title": "INTERLEAVE: A Faster Symbolic Algorithm for Maximal End Component Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20748",
        "HTML": "https://arxiv.org/html/2505.20748",
        "PDF": "https://arxiv.org/pdf/2505.20748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a symbolic algorithm for MEC decomposition in MDPs. It does not contribute to training data processing for LLMs or new dataset creation for language models."
      },
      "repo_urls": [
        "https://github.com/Ramneet-Singh/storm-masters-thesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07854",
      "abstract": "Small and Medium-sized Enterprises (SMEs) are vital to the modern economy, yet their credit risk analysis often struggles with scarce data, especially for online lenders lacking direct credit records. This paper introduces a Graph Neural Network (GNN)-based framework, leveraging SME interactions from transaction and social data to map spatial dependencies and predict loan default risks. Tests on real-world datasets from Discover and Ant Credit (23.4M nodes for supply chain analysis, 8.6M for default prediction) show the GNN surpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 for supply chain mining and default prediction, respectively. It also helps regulators model supply chain disruption impacts on banks, accurately forecasting loan defaults from material shortages, and offers Federal Reserve stress testers key data for CCAR risk buffers. This approach provides a scalable, effective tool for assessing SME credit risk.",
      "authors": [
        "Zizhou Zhang",
        "Qinyan Shen",
        "Zhuohuan Hu",
        "Qianying Liu",
        "Huijie Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:33:53+00:00",
          "link": "https://arxiv.org/abs/2507.07854v1",
          "size": "1242kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:25:17+00:00",
          "link": "https://arxiv.org/abs/2507.07854v2",
          "size": "1215kb",
          "version": "v2"
        }
      ],
      "title": "Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07854",
        "PDF": "https://arxiv.org/pdf/2507.07854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework using graph neural networks for credit risk analysis of SMEs. It is not related to data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07872",
      "abstract": "The safety validation of automatic emergency braking system (AEBS) requires accurately distinguishing between false positive (FP) and true positive (TP) system activations. While simulations allow straightforward differentiation by comparing scenarios with and without interventions, analyzing activations from open-loop resimulations - such as those from field operational testing (FOT) - is more complex. This complexity arises from scenario parameter uncertainty and the influence of driver interventions in the recorded data. Human labeling is frequently used to address these challenges, relying on subjective assessments of intervention necessity or situational criticality, potentially introducing biases and limitations. This work proposes a rule-based classification approach leveraging the Prediction Divergence Principle (PDP) to address those issues. Applied to a simplified AEBS, the proposed method reveals key strengths, limitations, and system requirements for effective implementation. The findings suggest that combining this approach with human labeling may enhance the transparency and consistency of classification, thereby improving the overall validation process. While the rule set for classification derived in this work adopts a conservative approach, the paper outlines future directions for refinement and broader applicability. Finally, this work highlights the potential of such methods to complement existing practices, paving the way for more reliable and reproducible AEBS validation frameworks.",
      "authors": [
        "Daniel Betschinske",
        "Steven Peters"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.07872v1",
          "size": "921kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:23:53+00:00",
          "link": "https://arxiv.org/abs/2507.07872v2",
          "size": "921kb",
          "version": "v2"
        }
      ],
      "title": "Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07872",
        "HTML": "https://arxiv.org/html/2507.07872",
        "PDF": "https://arxiv.org/pdf/2507.07872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a classification approach for AEBS validation using prediction divergence. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14843",
      "abstract": "Recent advances in large reasoning models highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing AI's capabilities, particularly in solving complex logical tasks. However, it remains unclear whether RLVR truly expands a model's reasoning boundary or merely amplifies high-reward outputs that the base model already knows for improved precision. This study presents a theoretical and empirical investigation that provides fresh insights into the potential limits of RLVR. First, we offer a new theoretical perspective that RLVR is constrained by the base model's support-unable to sample solutions with zero initial probability-and operates as a conservative reweighting mechanism that may restrict the discovery of entirely original solutions. We also identify an entropy-reward tradeoff: while RLVR reliably enhances precision, it may progressively narrow exploration and potentially overlook correct yet underrepresented solutions. Extensive empirical experiments validate that while RLVR consistently improves pass@1, the shrinkage of empirical support generally outweighs the expansion of empirical support under larger sampling budgets, failing to recover correct answers that were previously accessible to the base model. Interestingly, we also observe that while RLVR sometimes increases token-level entropy, resulting in greater uncertainty at each generation step, answer-level entropy declines, indicating that these seemingly more uncertain paths ultimately converge onto a smaller set of distinct answers. Taken together, these findings reveal potential limits of RLVR in extending reasoning horizons. Breaking this invisible leash may require future algorithmic innovations such as explicit exploration mechanisms or hybrid strategies that seed probability mass into underrepresented solution regions.",
      "authors": [
        "Fang Wu",
        "Weihao Xuan",
        "Ximing Lu",
        "Zaid Harchaoui",
        "Yejin Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:04:08+00:00",
          "link": "https://arxiv.org/abs/2507.14843v1",
          "size": "272kb",
          "version": "v1"
        }
      ],
      "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14843",
        "HTML": "https://arxiv.org/html/2507.14843",
        "PDF": "https://arxiv.org/pdf/2507.14843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Reinforcement Learning with Verifiable Rewards (RLVR) and its limitations in reasoning tasks, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15062",
      "abstract": "Handheld grippers are increasingly used to collect human demonstrations due to their ease of deployment and versatility. However, most existing designs lack tactile sensing, despite the critical role of tactile feedback in precise manipulation. We present a portable, lightweight gripper with integrated tactile sensors that enables synchronized collection of visual and tactile data in diverse, real-world, and in-the-wild settings. Building on this hardware, we propose a cross-modal representation learning framework that integrates visual and tactile signals while preserving their distinct characteristics. The learning procedure allows the emergence of interpretable representations that consistently focus on contacting regions relevant for physical interactions. When used for downstream manipulation tasks, these representations enable more efficient and effective policy learning, supporting precise robotic manipulation based on multimodal feedback. We validate our approach on fine-grained tasks such as test tube insertion and pipette-based fluid transfer, demonstrating improved accuracy and robustness under external disturbances. Our project page is available at https://binghao-huang.github.io/touch_in_the_wild/ .",
      "authors": [
        "Xinyue Zhu",
        "Binghao Huang",
        "Yunzhu Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:53:59+00:00",
          "link": "https://arxiv.org/abs/2507.15062v1",
          "size": "10043kb",
          "version": "v1"
        }
      ],
      "title": "Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15062",
        "HTML": "https://arxiv.org/html/2507.15062",
        "PDF": "https://arxiv.org/pdf/2507.15062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a visuo-tactile gripper for robotic manipulation tasks, not on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15361",
      "abstract": "Medical image segmentation suffers from data scarcity, particularly in polyp detection where annotation requires specialized expertise. We present SynDiff, a framework combining text-guided synthetic data generation with efficient diffusion-based segmentation. Our approach employs latent diffusion models to generate clinically realistic synthetic polyps through text-conditioned inpainting, augmenting limited training data with semantically diverse samples. Unlike traditional diffusion methods requiring iterative denoising, we introduce direct latent estimation enabling single-step inference with T x computational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9% IoU while maintaining real-time capability suitable for clinical deployment. The framework demonstrates that controlled synthetic augmentation improves segmentation robustness without distribution shift. SynDiff bridges the gap between data-hungry deep learning models and clinical constraints, offering an efficient solution for deployment in resourcelimited medical settings.",
      "authors": [
        "Muhammad Aqeel",
        "Maham Nazir",
        "Zanxi Ruan",
        "Francesco Setti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:15:17+00:00",
          "link": "https://arxiv.org/abs/2507.15361v1",
          "size": "4338kb",
          "version": "v1"
        }
      ],
      "title": "Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15361",
        "HTML": "https://arxiv.org/html/2507.15361",
        "PDF": "https://arxiv.org/pdf/2507.15361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces SynDiff, a text-guided data augmentation framework for medical segmentation, it indirectly addresses synthetic data generation, a data processing aspect relevant to LLM pretraining, but the main focus is on biomedical applications."
      },
      "source": "arXiv"
    },
    {
      "id": "1704.01148",
      "abstract": "Why does anything feel like anything at all? This \"hard problem\" of consciousness has haunted philosophy and science for centuries. The Qualia-Singularity Correspondence Theory (QSCT) proposes that conscious experience emerges precisely where quantitative description fails in a specific, structured way. QSCT identifies consciousness with Q-singularities -- moments when a system's dynamics undergo simultaneous collapse (rank-drop) of two mathematical structures: the Fisher-Rao metric (governing external distinguishability) and the Jacobian matrix (governing internal dynamics). At these points, the system becomes simultaneously unmeasurable from outside and causally knotted within, with only its own trajectory surviving. This dual collapse naturally produces consciousness's five hallmarks: privacy, unity, ineffability, subjectivity, and causal efficacy. Such singularities are vanishingly rare outside of highly recurrent, near-critical systems like brains and potentially advanced neural networks -- the very systems known to exhibit, or suspected to be capable of exhibiting, consciousness. We hypothesize that the topological structure around each singularity maps onto differences in experience. QSCT makes testable predictions: specific neural signatures should coincide with reported conscious moments; artificially induced Q-singularities should generate predictable experiences. The theory also explores a conjectural extension suggesting that self-modeling systems may necessarily produce Q-singularities. In short, QSCT proposes that where the quantitative fabric of the world tears, qualitative experience emerges.",
      "authors": [
        "T.R. Lima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2017-04-04T18:32:58+00:00",
          "link": "https://arxiv.org/abs/1704.01148v1",
          "size": "177kb",
          "version": "v1"
        },
        {
          "date": "2017-07-14T04:58:27+00:00",
          "link": "https://arxiv.org/abs/1704.01148v2",
          "size": "176kb",
          "version": "v2"
        },
        {
          "date": "2019-01-05T18:58:53+00:00",
          "link": "https://arxiv.org/abs/1704.01148v3",
          "size": "323kb",
          "version": "v3"
        },
        {
          "date": "2019-08-25T19:57:45+00:00",
          "link": "https://arxiv.org/abs/1704.01148v4",
          "size": "231kb",
          "version": "v4"
        },
        {
          "date": "2023-08-03T02:19:02+00:00",
          "link": "https://arxiv.org/abs/1704.01148v5",
          "size": "587kb",
          "version": "v5"
        },
        {
          "date": "2024-12-10T14:40:14+00:00",
          "link": "https://arxiv.org/abs/1704.01148v6",
          "size": "219kb",
          "version": "v6"
        },
        {
          "date": "2025-07-19T23:43:59+00:00",
          "link": "https://arxiv.org/abs/1704.01148v7",
          "size": "517kb",
          "version": "v7"
        }
      ],
      "title": "The Qualia-Singularity Correspondence Theory (QSCT): A Topological Account of Consciousness",
      "links": {
        "Abstract": "https://arxiv.org/abs/1704.01148",
        "PDF": "https://arxiv.org/pdf/1704.01148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Qualia-Singularity Correspondence Theory which is concerned with consciousness and singularities in dynamical systems. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.02752",
      "abstract": "Airdrops are a popular mechanism used by blockchain protocols to bootstrap communities, reward early adopters, and decentralize token distribution. Despite their widespread adoption, the effectiveness of airdrops in achieving long-term user engagement and ecosystem growth remains poorly understood. In this paper, we present the first comprehensive empirical study of nine major airdrops across Ethereum and Layer-2 ecosystems. Our analysis reveals that a substantial share of tokens--up to 66% in some cases--are rapidly sold, often in recipients' first post-claim transaction. We show that this behavior is largely driven by \"airdrop farmers,\" who strategically optimize eligibility criteria to extract value without contributing meaningfully to the ecosystem. We complement our quantitative findings with a case study of the Arbitrum airdrop, illustrating how short-term activity spikes fail to translate into sustained user involvement. Based on these results, we discuss common design pitfalls--such as Sybil vulnerability, poor incentive alignment, and governance token misuse--and propose actionable guidelines for designing more effective airdrop strategies.",
      "authors": [
        "Johnnatan Messias and Aviv Yaish and Benjamin Livshits"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-05T13:27:15+00:00",
          "link": "https://arxiv.org/abs/2312.02752v1",
          "size": "5079kb",
          "version": "v1"
        },
        {
          "date": "2024-05-24T07:21:06+00:00",
          "link": "https://arxiv.org/abs/2312.02752v2",
          "size": "7022kb",
          "version": "v2"
        },
        {
          "date": "2024-10-17T09:15:29+00:00",
          "link": "https://arxiv.org/abs/2312.02752v3",
          "size": "8434kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T08:18:19+00:00",
          "link": "https://arxiv.org/abs/2312.02752v4",
          "size": "11356kb",
          "version": "v4"
        }
      ],
      "title": "Airdrops: Giving Money Away Is Harder Than It Seems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.02752",
        "HTML": "https://arxiv.org/html/2312.02752",
        "PDF": "https://arxiv.org/pdf/2312.02752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered around blockchain airdrops and their design strategies to achieve desired outcomes, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.21544",
      "abstract": "Intent, typically clearly formulated and planned, functions as a cognitive framework for communication and problem-solving. This paper introduces the concept of Speaking with Intent (SWI) in large language models (LLMs), where the explicitly generated intent encapsulates the model's underlying intention and provides high-level planning to guide subsequent analysis and action. By emulating deliberate and purposeful thoughts in the human mind, SWI is hypothesized to enhance the reasoning capabilities and generation quality of LLMs. Extensive experiments on text summarization, multi-task question answering, and mathematical reasoning benchmarks consistently demonstrate the effectiveness and generalizability of Speaking with Intent over direct generation without explicit intent. Further analysis corroborates the generalizability of SWI under different experimental settings. Moreover, human evaluations verify the coherence, effectiveness, and interpretability of the intent produced by SWI. The promising results in enhancing LLMs with explicit intents pave a new avenue for boosting LLMs' generation and reasoning abilities with cognitive notions.",
      "authors": [
        "Yuwei Yin",
        "EunJeong Hwang",
        "Giuseppe Carenini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T14:34:28+00:00",
          "link": "https://arxiv.org/abs/2503.21544v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T03:53:06+00:00",
          "link": "https://arxiv.org/abs/2503.21544v2",
          "size": "334kb",
          "version": "v2"
        }
      ],
      "title": "SWI: Speaking with Intent in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21544",
        "HTML": "https://arxiv.org/html/2503.21544",
        "PDF": "https://arxiv.org/pdf/2503.21544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Speaking with Intent (SWI) to improve LLM reasoning and generation, but does not discuss any aspect of training data processing."
      },
      "tasks": [
        "Mathematical Reasoning",
        "Question Answering",
        "Text Summarization"
      ],
      "repo_urls": [
        "https://github.com/YuweiYin/SWI"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11558",
      "abstract": "Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with LLM-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.",
      "authors": [
        "Bo-Cheng Chiu",
        "Jen-Jee Chen",
        "Yu-Chee Tseng and Feng-Chi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T08:13:05+00:00",
          "link": "https://arxiv.org/abs/2506.11558v1",
          "size": "3014kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T11:59:30+00:00",
          "link": "https://arxiv.org/abs/2506.11558v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T16:37:00+00:00",
          "link": "https://arxiv.org/abs/2506.11558v3",
          "size": "3013kb",
          "version": "v3"
        }
      ],
      "title": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11558",
        "HTML": "https://arxiv.org/html/2506.11558",
        "PDF": "https://arxiv.org/pdf/2506.11558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions contribution of multiple datasets augmented with LLM-generated QA pairs for video temporal reasoning, indicating a minor connection to training data processing. However, its primary focus is on model architecture and temporal reasoning for video-language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12049",
      "abstract": "VAD is a critical field in machine learning focused on identifying deviations from normal patterns in images, often challenged by the scarcity of anomalous data and the need for unsupervised training. To accelerate research and deployment in this domain, we introduce MoViAD, a comprehensive and highly modular library designed to provide fast and easy access to state-of-the-art VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array of scenarios, including continual, semi-supervised, few-shots, noisy, and many more. In addition, it addresses practical deployment challenges through dedicated Edge and IoT settings, offering optimized models and backbones, along with quantization and compression utilities for efficient on-device execution and distributed inference. MoViAD integrates a selection of backbones, robust evaluation VAD metrics (pixel-level and image-level) and useful profiling tools for efficiency analysis. The library is designed for fast, effortless deployment, enabling machine learning engineers to easily use it for their specific setup with custom models, datasets, and backbones. At the same time, it offers the flexibility and extensibility researchers need to develop and experiment with new methods.",
      "authors": [
        "Manuel Barusco and Francesco Borsatti and Arianna Stropeni and Davide Dalle Pezze and Gian Antonio Susto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T09:10:38+00:00",
          "link": "https://arxiv.org/abs/2507.12049v1",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:17:35+00:00",
          "link": "https://arxiv.org/abs/2507.12049v2",
          "size": "12kb",
          "version": "v2"
        }
      ],
      "title": "MoViAD: A Modular Library for Visual Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12049",
        "HTML": "https://arxiv.org/html/2507.12049",
        "PDF": "https://arxiv.org/pdf/2507.12049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MoViAD, a library for visual anomaly detection, which does not relate to the collection, processing, or creation of datasets for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14213",
      "abstract": "The Big Data revolution has heightened the demand for robust, energy-efficient security hardware capable of withstanding increasingly sophisticated cyber threats. Conventional encryption schemes, reliant on complex algorithms, are resource-intensive and remain vulnerable. To fortify sensitive information, society needs innovative anti-hacking and anti-counterfeiting technologies that exploit new materials and designs. Here, we present a magneto-ionic strategy for hardware-level security based on fully selective voltage-controlled N3- ion migration within pre-defined, initially paramagnetic FeCoN dots. This process generates ferromagnetic sublayers of tuneable thickness, resulting in either deterministic (single-domain or vortex) or probabilistic states (with coexisting magnetic configurations and voltage-adjustable probabilities), each exhibiting stochastic orientation and chirality, thereby providing a rich platform for magnetic fingerprinting. This approach enables self-protected primitives, including true random number generators, physical unclonable functions, and in-memory probabilistic inference. The resulting reconfigurable architecture combines tamper resistance, low energy consumption, and scalability, marking a significant leap toward next-generation hardware security rooted in emergent magnetic phenomena.",
      "authors": [
        "Irena Spasojevic",
        "Federica Celegato",
        "Alessandro Magni",
        "Paola Tiberto",
        "Jordi Sort"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:36:07+00:00",
          "link": "https://arxiv.org/abs/2507.14213v1",
          "size": "40602kb",
          "version": "v1"
        }
      ],
      "title": "Magneto-Ionic Hardware Security Primitives: Embedding Data Protection at the Material Level",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14213",
        "PDF": "https://arxiv.org/pdf/2507.14213"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on hardware security primitives based on magneto-ionic materials, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14249",
      "abstract": "Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions to alleviate urban congestion, with path planning becoming a key focus area. Unlike ground transportation, UAM trajectory planning has to prioritize communication quality for accurate location tracking in constantly changing environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi, requires adaptive planning to respond to real-time passenger requests, especially in ride-sharing scenarios where passenger demands are unpredictable and dynamic. However, conventional trajectory planning strategies based on predefined routes lack the flexibility to meet varied passenger ride demands. To address these challenges, this work first proposes constructing a radio map to evaluate the communication quality of urban airspace. Building on this, we introduce a novel Multi-Source Hybrid Attention Reinforcement Learning (MSHA-RL) framework for the challenge of effectively focusing on passengers and UAM locations, which arises from the significant dimensional disparity between the representations. This model first generates the alignment among diverse data sources with large gap dimensions before employing hybrid attention to balance global and local insights, thereby facilitating responsive, real-time path planning. Extensive experimental results demonstrate that the approach enables communication-compliant trajectory planning, reducing travel time and enhancing operational efficiency while prioritizing passenger safety.",
      "authors": [
        "Yuejiao Xie",
        "Maonan Wang",
        "Di Zhou",
        "Man-On Pun",
        "and Zhu Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T06:09:30+00:00",
          "link": "https://arxiv.org/abs/2507.14249v1",
          "size": "4689kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14249",
        "HTML": "https://arxiv.org/html/2507.14249",
        "PDF": "https://arxiv.org/pdf/2507.14249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on real-time communication-aware ride-sharing route planning using reinforcement learning for urban air mobility, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14739",
      "abstract": "The Controller Area Network (CAN) protocol, essential for automotive embedded systems, lacks inherent security features, making it vulnerable to cyber threats, especially with the rise of autonomous vehicles. Traditional security measures offer limited protection, such as payload encryption and message authentication. This paper presents a novel Intrusion Detection System (IDS) designed for the CAN environment, utilizing Hardware Performance Counters (HPCs) to detect anomalies indicative of cyber attacks. A RISC-V-based CAN receiver is simulated using the gem5 simulator, processing CAN frame payloads with AES-128 encryption as FreeRTOS tasks, which trigger distinct HPC responses. Key HPC features are optimized through data extraction and correlation analysis to enhance classification efficiency. Results indicate that this approach could significantly improve CAN security and address emerging challenges in automotive cybersecurity.",
      "authors": [
        "Franco Oberti",
        "Stefano Di Carlo",
        "Alessandro Savino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:09:52+00:00",
          "link": "https://arxiv.org/abs/2507.14739v1",
          "size": "799kb",
          "version": "v1"
        }
      ],
      "title": "CANDoSA: A Hardware Performance Counter-Based Intrusion Detection System for DoS Attacks on Automotive CAN bus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14739",
        "HTML": "https://arxiv.org/html/2507.14739",
        "PDF": "https://arxiv.org/pdf/2507.14739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an intrusion detection system for automotive CAN bus networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15551",
      "abstract": "Recent progress on large language models (LLMs) has spurred interest in scaling up recommendation systems, yet two practical obstacles remain. First, training and serving cost on industrial Recommenders must respect strict latency bounds and high QPS demands. Second, most human-designed feature-crossing modules in ranking models were inherited from the CPU era and fail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and poor scalability. We introduce RankMixer, a hardware-aware model design tailored towards a unified and scalable feature-interaction architecture. RankMixer retains the transformer's high parallelism while replacing quadratic self-attention with multi-head token mixing module for higher efficiency. Besides, RankMixer maintains both the modeling for distinct feature subspaces and cross-feature-space interactions with Per-token FFNs. We further extend it to one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic routing strategy is adapted to address the inadequacy and imbalance of experts training. Experiments show RankMixer's superior scaling abilities on a trillion-scale production dataset. By replacing previously diverse handcrafted low-MFU modules with RankMixer, we boost the model MFU from 4.5% to 45%, and scale our ranking model parameters by 100x while maintaining roughly the same inference latency. We verify RankMixer's universality with online A/B tests across three core application scenarios (Recommendation, Advertisement and Search). Finally, we launch 1B Dense-Parameters RankMixer for full traffic serving without increasing the serving cost, which improves user active days by 0.2% and total in-app usage duration by 0.5%.",
      "authors": [
        "Jie Zhu",
        "Zhifang Fan",
        "Xiaoxie Zhu",
        "Yuchen Jiang",
        "Hangyu Wang",
        "Xintian Han",
        "Haoran Ding",
        "Xinmin Wang",
        "Wenlin Zhao",
        "Zhen Gong",
        "Huizhi Yang",
        "Zheng Chai",
        "Zhe Chen",
        "Yuchao Zheng",
        "Qiwei Chen",
        "Feng Zhang",
        "Xun Zhou",
        "Peng Xu",
        "Xiao Yang",
        "Di Wu",
        "Zuotao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.15551v1",
          "size": "606kb",
          "version": "v1"
        }
      ],
      "title": "RankMixer: Scaling Up Ranking Models in Industrial Recommenders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15551",
        "HTML": "https://arxiv.org/html/2507.15551",
        "PDF": "https://arxiv.org/pdf/2507.15551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on RankMixer, a scalable ranking model for recommendation systems, dealing with model design and efficiency rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.06691",
      "abstract": "This paper aims to answer a fundamental question in the area of Integrated Sensing and Communications (ISAC): What is the optimal communication-centric ISAC waveform for ranging? Towards that end, we first established a generic framework to analyze the sensing performance of communication-centric ISAC waveforms built upon orthonormal signaling bases and random data symbols. Then, we evaluated their ranging performance by adopting both the periodic and aperiodic auto-correlation functions (P-ACF and A-ACF), and defined the expectation of the integrated sidelobe level (EISL) as a sensing performance metric. On top of that, we proved that among all communication waveforms with cyclic prefix (CP), the orthogonal frequency division multiplexing (OFDM) modulation is the only globally optimal waveform that achieves the lowest ranging sidelobe for quadrature amplitude modulation (QAM) and phase shift keying (PSK) constellations, in terms of both the EISL and the sidelobe level at each individual lag of the P-ACF. As a step forward, we proved that among all communication waveforms without CP, OFDM is a locally optimal waveform for QAM/PSK in the sense that it achieves a local minimum of the EISL of the A-ACF. Finally, we demonstrated by numerical results that under QAM/PSK constellations, there is no other orthogonal communication-centric waveform that achieves a lower ranging sidelobe level than that of the OFDM, in terms of both P-ACF and A-ACF cases.",
      "authors": [
        "Fan Liu",
        "Ying Zhang",
        "Yifeng Xiong",
        "Shuangyang Li",
        "Weijie Yuan",
        "Feifei Gao",
        "Shi Jin",
        "Giuseppe Caire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T09:07:07+00:00",
          "link": "https://arxiv.org/abs/2407.06691v1",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "2024-10-15T12:55:55+00:00",
          "link": "https://arxiv.org/abs/2407.06691v2",
          "size": "104kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T13:00:58+00:00",
          "link": "https://arxiv.org/abs/2407.06691v3",
          "size": "450kb",
          "version": "v3"
        }
      ],
      "title": "CP-OFDM Achieves the Lowest Average Ranging Sidelobe Under QAM/PSK Constellations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06691",
        "HTML": "https://arxiv.org/html/2407.06691",
        "PDF": "https://arxiv.org/pdf/2407.06691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores optimal waveforms for Integrated Sensing and Communications, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.08985",
      "abstract": "Retrieval-Augmented Generation (RAG) systems show remarkable potential as question answering tools in the K-12 Education domain, where knowledge is typically queried within the restricted scope of authoritative textbooks. However, discrepancies between these textbooks and the parametric knowledge inherent in Large Language Models (LLMs) can undermine the effectiveness of RAG systems. To systematically investigate RAG system robustness against such knowledge discrepancies, we introduce KnowShiftQA. This novel question answering dataset simulates these discrepancies by applying deliberate hypothetical knowledge updates to both answers and source documents, reflecting how textbook knowledge can shift. KnowShiftQA comprises 3,005 questions across five subjects, designed with a comprehensive question typology focusing on context utilization and knowledge integration. Our extensive experiments on retrieval and question answering performance reveal that most RAG systems suffer a substantial performance drop when faced with these knowledge discrepancies. Furthermore, questions requiring the integration of contextual (textbook) knowledge with parametric (LLM) knowledge pose a significant challenge to current LLMs.",
      "authors": [
        "Tianshi Zheng",
        "Weihan Li",
        "Jiaxin Bai",
        "Weiqi Wang",
        "Yangqiu Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T06:38:40+00:00",
          "link": "https://arxiv.org/abs/2412.08985v1",
          "size": "452kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T11:22:49+00:00",
          "link": "https://arxiv.org/abs/2412.08985v2",
          "size": "344kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T19:41:20+00:00",
          "link": "https://arxiv.org/abs/2412.08985v3",
          "size": "344kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T16:16:56+00:00",
          "link": "https://arxiv.org/abs/2412.08985v4",
          "size": "342kb",
          "version": "v4"
        }
      ],
      "title": "KnowShiftQA: How Robust are RAG Systems when Textbook Knowledge Shifts in K-12 Education?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08985",
        "HTML": "https://arxiv.org/html/2412.08985",
        "PDF": "https://arxiv.org/pdf/2412.08985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces the KnowShiftQA dataset to study the robustness of RAG systems when textbook knowledge shifts. While it involves dataset creation, its focus is more on evaluating retrieval-augmented systems rather than core LLM training data processing."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18837",
      "abstract": "This paper considers the Helmholtz problem in the exterior of a ball with Dirichlet boundary conditions and radiation conditions imposed at infinity. The differential Helmholtz operator depends on the complex wavenumber with non-negative real part and is formulated for general spatial dimension. We prove wavenumber explicit continuity estimates of the corresponding Dirichlet-to-Neumann (DtN) operator which are valid for all wavenumbers under consideration and do not deteriorate as they tend to zero.\n  The exterior Helmholtz problem can be equivalently reformulated on a bounded domain with DtN boundary conditions on the artificial boundary of a ball. We derive wavenumber independent trace and Friedrichs-type inequalities for the solution space in wavenumber-indexed norms.",
      "authors": [
        "Benedikt Gr\\\"a{\\ss}le",
        "Stefan A. Sauter"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T16:11:03+00:00",
          "link": "https://arxiv.org/abs/2503.18837v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T18:14:29+00:00",
          "link": "https://arxiv.org/abs/2503.18837v2",
          "size": "24kb",
          "version": "v2"
        }
      ],
      "title": "Dirichlet-to-Neumann operator for the Helmholtz problem with general wavenumbers on the $n$-sphere",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18837",
        "HTML": "https://arxiv.org/html/2503.18837",
        "PDF": "https://arxiv.org/pdf/2503.18837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with mathematical analysis of the Helmholtz problem and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12689",
      "abstract": "The rapid growth of scientific literature demands robust tools for automated survey-generation. However, current large language model (LLM)-based methods often lack in-depth analysis, structural coherence, and reliable citations. To address these limitations, we introduce SciSage, a multi-agent framework employing a reflect-when-you-write paradigm. SciSage features a hierarchical Reflector agent that critically evaluates drafts at outline, section, and document levels, collaborating with specialized agents for query interpretation, content retrieval, and refinement. We also release SurveyScope, a rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11 computer science domains, with strict recency and citation-based quality controls. Evaluations demonstrate that SciSage outperforms state-of-the-art baselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document coherence and +32% in citation F1 scores. Human evaluations reveal mixed outcomes (3 wins vs. 7 losses against human-written surveys), but highlight SciSage's strengths in topical breadth and retrieval efficiency. Overall, SciSage offers a promising foundation for research-assistive writing tools.",
      "authors": [
        "Xiaofeng Shi",
        "Qian Kou",
        "Yuduo Li",
        "Ning Tang",
        "Jinxin Xie",
        "Longbin Yu",
        "Songjing Wang",
        "Hua Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T02:23:47+00:00",
          "link": "https://arxiv.org/abs/2506.12689v1",
          "size": "1956kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:49:38+00:00",
          "link": "https://arxiv.org/abs/2506.12689v2",
          "size": "1969kb",
          "version": "v2"
        }
      ],
      "title": "SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12689",
        "PDF": "https://arxiv.org/pdf/2506.12689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multi-agent framework for generating scientific surveys and benchmarks for evaluation, not on LLM training data processing. It does not address data processing for pretraining or fine-tuning LLMs."
      },
      "datasets": [
        {
          "dataset_name": "BAAI/SurveyScope",
          "downloads": "16",
          "likes": "1",
          "link": "https://huggingface.co/datasets/BAAI/SurveyScope"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14299",
      "abstract": "Unmanned aerial vehicles (UAVs) equipped with integrated sensing and communication (ISAC) capabilities are envisioned to play a pivotal role in future wireless networks due to their enhanced flexibility and efficiency. However, jointly optimizing UAV trajectory planning, multi-user communication, and target sensing under stringent resource constraints and time-critical conditions remains a significant challenge. To address this, we propose an Age of Information (AoI)-centric UAV-ISAC system that simultaneously performs target sensing and serves multiple ground users, emphasizing information freshness as the core performance metric. We formulate a long-term average AoI minimization problem that jointly optimizes the UAV's flight trajectory and beamforming. To tackle the high-dimensional, non-convexity of this problem, we develop a deep reinforcement learning (DRL)-based algorithm capable of providing real-time decisions on UAV movement and beamforming for both radar sensing and multi-user communication. Specifically, a Kalman filter is employed for accurate target state prediction, regularized zero-forcing is utilized to mitigate inter-user interference, and the Soft Actor-Critic algorithm is applied for training the DRL agent on continuous actions. The proposed framework adaptively balances the trade-offs between sensing accuracy and communication quality. Extensive simulation results demonstrate that our proposed method consistently achieves lower average AoI compared to baseline approaches.",
      "authors": [
        "Yu Bai",
        "Yifan Zhang",
        "Boxuan Xie",
        "Zheng Chang",
        "Yanru Zhang",
        "Riku Jantti",
        "Zhu Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:17:09+00:00",
          "link": "https://arxiv.org/abs/2507.14299v1",
          "size": "2509kb",
          "version": "v1"
        }
      ],
      "title": "Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14299",
        "HTML": "https://arxiv.org/html/2507.14299",
        "PDF": "https://arxiv.org/pdf/2507.14299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimization in UAV systems and deep reinforcement learning for minimizing information age, focusing on system performance rather than contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15501",
      "abstract": "This work evaluates the potential of large language models (LLMs) to power digital assistants capable of complex action execution. These assistants rely on pre-trained programming knowledge to execute multi-step goals by composing objects and functions defined in assistant libraries into action execution programs. To achieve this, we develop ASPERA, a framework comprising an assistant library simulation and a human-assisted LLM data generation engine. Our engine allows developers to guide LLM generation of high-quality tasks consisting of complex user queries, simulation state and corresponding validation programs, tackling data availability and evaluation robustness challenges. Alongside the framework we release Asper-Bench, an evaluation dataset of 250 challenging tasks generated using ASPERA, which we use to show that program generation grounded in custom assistant libraries is a significant challenge to LLMs compared to dependency-free code generation.",
      "authors": [
        "Alexandru Coca",
        "Mark Gaynor",
        "Zhenxing Zhang",
        "Jianpeng Cheng",
        "Bo-Hsiang Tseng",
        "Pete Boothroyd",
        "H\\'ector Martinez Alonso",
        "Diarmuid \\'O S\\'eaghdha",
        "Anders Johannsen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:07:05+00:00",
          "link": "https://arxiv.org/abs/2507.15501v1",
          "size": "2951kb",
          "version": "v1"
        }
      ],
      "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15501",
        "PDF": "https://arxiv.org/pdf/2507.15501"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces ASPERA, a simulation and data generation engine, that helps in generating high-quality tasks for LLMs, focusing on data generation and quality improvement for evaluating complex action execution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15689",
      "abstract": "While the computation of Craig interpolants for description logics (DLs) with the Craig Interpolation Property (CIP) is well understood, very little is known about the computation and size of interpolants for DLs without CIP or if one aims at interpolating concepts in a weaker DL than the DL of the input ontology and concepts. In this paper, we provide the first elementary algorithms computing (i) ALC-interpolants between ALC-concepts under ALCH-ontologies and (ii) ALC-interpolants between ALCQ-concepts under ALCQ-ontologies. The algorithms are based on recent decision procedures for interpolant existence. We also observe that, in contrast, uniform (possibly depth restricted) interpolants might be of non-elementary size.",
      "authors": [
        "Jean Christoph Jung",
        "J\\k{e}drzej Ko{\\l}odziejski",
        "Frank Wolter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:54:48+00:00",
          "link": "https://arxiv.org/abs/2507.15689v1",
          "size": "150kb",
          "version": "v1"
        }
      ],
      "title": "Computation of Interpolants for Description Logic Concepts in Hard Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15689",
        "HTML": "https://arxiv.org/html/2507.15689",
        "PDF": "https://arxiv.org/pdf/2507.15689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses computation of interpolants for description logic concepts, which is unrelated to LLM training data processing or any related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15715",
      "abstract": "There is growing interest in leveraging LLMs to aid in astronomy and other scientific research, but benchmarks for LLM evaluation in general have not kept pace with the increasingly diverse ways that real people evaluate and use these models. In this study, we seek to improve evaluation procedures by building an understanding of how users evaluate LLMs. We focus on a particular use case: an LLM-powered retrieval-augmented generation bot for engaging with astronomical literature, which we deployed via Slack. Our inductive coding of 368 queries to the bot over four weeks and our follow-up interviews with 11 astronomers reveal how humans evaluated this system, including the types of questions asked and the criteria for judging responses. We synthesize our findings into concrete recommendations for building better benchmarks, which we then employ in constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our work offers ways to improve LLM evaluation and ultimately usability, particularly for use in scientific research.",
      "authors": [
        "Alina Hyk",
        "Kiera McCormick",
        "Mian Zhong",
        "Ioana Ciuc\\u{a}",
        "Sanjib Sharma",
        "John F Wu",
        "J. E. G. Peek",
        "Kartheik G. Iyer",
        "Ziang Xiao",
        "Anjalie Field"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:26:58+00:00",
          "link": "https://arxiv.org/abs/2507.15715v1",
          "size": "1292kb",
          "version": "v1"
        }
      ],
      "title": "From Queries to Criteria: Understanding How Astronomers Evaluate LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15715",
        "HTML": "https://arxiv.org/html/2507.15715",
        "PDF": "https://arxiv.org/pdf/2507.15715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with evaluating LLMs in the context of astronomy research, focusing on user queries and evaluation criteria. It does not discuss any training data processing relevant to pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.07663",
      "abstract": "In variational autoencoders (VAEs), the variational posterior often collapses to the prior, known as posterior collapse, which leads to poor representation learning quality. An adjustable hyperparameter beta has been introduced in VAEs to address this issue. This study sharply evaluates the conditions under which the posterior collapse occurs with respect to beta and dataset size by analyzing a minimal VAE in a high-dimensional limit. Additionally, this setting enables the evaluation of the rate-distortion curve of the VAE. Our results show that, unlike typical regularization parameters, VAEs face \"inevitable posterior collapse\" beyond a certain beta threshold, regardless of dataset size. Moreover, the dataset-size dependence of the derived rate-distortion curve suggests that relatively large datasets are required to achieve a rate-distortion curve with high rates. These findings robustly explain generalization behavior observed in various real datasets with highly non-linear VAEs.",
      "authors": [
        "Yuma Ichikawa and Koji Hukushima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-14T12:27:17+00:00",
          "link": "https://arxiv.org/abs/2309.07663v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T09:12:46+00:00",
          "link": "https://arxiv.org/abs/2309.07663v2",
          "size": "1352kb",
          "version": "v2"
        }
      ],
      "title": "High-dimensional Asymptotics of VAEs: Threshold of Posterior Collapse and Dataset-Size Dependence of Rate-Distortion Curve",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.07663",
        "HTML": "https://arxiv.org/html/2309.07663",
        "PDF": "https://arxiv.org/pdf/2309.07663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes conditions for posterior collapse in VAEs and the dataset-size dependence of the rate-distortion curve, focusing on representation learning and regularization, not on LLM training data processing."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/yuma-ichikawa/vae-replica"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.11567",
      "abstract": "In this paper, we address the problem of reconfiguring Earth observation satellite constellation systems through multiple stages. The Multi-stage Constellation Reconfiguration Problem (MCRP) aims to maximize the total observation rewards obtained by covering a set of targets of interest through the active manipulation of the orbits and relative phasing of constituent satellites. In this paper, we consider deterministic problem settings in which the targets of interest are known a priori. We propose a novel integer linear programming formulation for MCRP, capable of obtaining provably optimal solutions. To overcome computational intractability due to the combinatorial explosion in solving large-scale instances, we introduce two computationally efficient sequential decision-making methods based on the principles of a myopic policy and a rolling horizon procedure. The computational experiments demonstrate that the devised sequential decision-making approaches yield high-quality solutions with improved computational efficiency over the baseline MCRP. Finally, a case study using Hurricane Harvey data showcases the advantages of multi-stage constellation reconfiguration over single-stage and no-reconfiguration scenarios.",
      "authors": [
        "Hang Woon Lee",
        "David O. Williams Rogers",
        "Brycen D. Pearl",
        "Hao Chen",
        "Koki Ho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-21T19:04:33+00:00",
          "link": "https://arxiv.org/abs/2401.11567v1",
          "size": "15778kb",
          "version": "v1"
        },
        {
          "date": "2024-04-30T15:39:50+00:00",
          "link": "https://arxiv.org/abs/2401.11567v2",
          "size": "48186kb",
          "version": "v2"
        },
        {
          "date": "2024-09-04T23:29:30+00:00",
          "link": "https://arxiv.org/abs/2401.11567v3",
          "size": "48186kb",
          "version": "v3"
        }
      ],
      "title": "Deterministic Multistage Constellation Reconfiguration Using Integer Programming and Sequential Decision-Making Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11567",
        "HTML": "https://arxiv.org/html/2401.11567",
        "PDF": "https://arxiv.org/pdf/2401.11567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with reconfiguring satellite constellation systems and does not discuss LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.18239",
      "abstract": "Precise segmentation of papillary thyroid microcarcinoma (PTMC) during ultrasound-guided radiofrequency ablation (RFA) is critical for effective treatment but remains challenging due to acoustic artifacts, small lesion size, and anatomical variability. In this study, we propose DualSwinUnet++, a dual-decoder transformer-based architecture designed to enhance PTMC segmentation by incorporating thyroid gland context. DualSwinUnet++ employs independent linear projection heads for each decoder and a residual information flow mechanism that passes intermediate features from the first (thyroid) decoder to the second (PTMC) decoder via concatenation and transformation. These design choices allow the model to condition tumor prediction explicitly on gland morphology without shared gradient interference. Trained on a clinical ultrasound dataset with 691 annotated RFA images and evaluated against state-of-the-art models, DualSwinUnet++ achieves superior Dice and Jaccard scores while maintaining sub-200ms inference latency. The results demonstrate the model's suitability for near real-time surgical assistance and its effectiveness in improving segmentation accuracy in challenging PTMC cases.",
      "authors": [
        "Maryam Dialameh",
        "Hossein Rajabzadeh",
        "Moslem Sadeghi-Goughari",
        "Jung Suk Sim",
        "Hyock Ju Kwon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T19:33:33+00:00",
          "link": "https://arxiv.org/abs/2410.18239v1",
          "size": "2537kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T03:11:31+00:00",
          "link": "https://arxiv.org/abs/2410.18239v2",
          "size": "3286kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T16:58:02+00:00",
          "link": "https://arxiv.org/abs/2410.18239v3",
          "size": "3286kb",
          "version": "v3"
        }
      ],
      "title": "DualSwinUnet++: An Enhanced Swin-Unet Architecture With Dual Decoders For PTMC Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18239",
        "HTML": "https://arxiv.org/html/2410.18239",
        "PDF": "https://arxiv.org/pdf/2410.18239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this study is on an architecture for medical image segmentation, and it does not contribute to LLM training data processing or related operations."
      },
      "tasks": [
        "Decoder",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04510",
      "abstract": "Large language models (LLMs) have been proposed as powerful tools for detecting software vulnerabilities, where task-specific fine-tuning is typically employed to provide vulnerability-specific knowledge to the LLMs. However, existing fine-tuning techniques often treat source code as plain text, losing the graph-based structural information inherent in code.\n  Graph-enhanced soft prompt tuning addresses this by translating the structural information into contextual cues that the LLM can understand. However, current methods are primarily designed for general graph-related tasks and focus more on adjacency information, they fall short in preserving the rich semantic information (e.g., control/data flow) within code graphs. They also fail to ensure computational efficiency while capturing graph-text interactions in their cross-modal alignment module.\n  This paper presents CGP-Tuning, a new code graph-enhanced, structure-aware soft prompt tuning method for vulnerability detection. CGP-Tuning introduces type-aware embeddings to capture the rich semantic information within code graphs, along with an efficient cross-modal alignment module that achieves linear computational costs while incorporating graph-text interactions. It is evaluated on the latest DiverseVul dataset and three advanced open-source code LLMs, CodeLlama, CodeGemma, and Qwen2.5-Coder. Experimental results show that CGP-Tuning delivers model-agnostic improvements and maintains practical inference speed, surpassing the best graph-enhanced soft prompt tuning baseline by an average of four percentage points and outperforming non-tuned zero-shot prompting by 15 percentage points.",
      "authors": [
        "Ruijun Feng",
        "Hammond Pearce",
        "Pietro Liguori",
        "Yulei Sui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T13:56:17+00:00",
          "link": "https://arxiv.org/abs/2501.04510v1",
          "size": "280kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:31:55+00:00",
          "link": "https://arxiv.org/abs/2501.04510v2",
          "size": "1053kb",
          "version": "v2"
        }
      ],
      "title": "CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04510",
        "HTML": "https://arxiv.org/html/2501.04510",
        "PDF": "https://arxiv.org/pdf/2501.04510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses CGP-Tuning for code vulnerability detection, which involves LLM fine-tuning, but it primarily focuses on enhancing model performance through structure-aware embeddings rather than training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "cross-modal alignment",
        "Vulnerability Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11476",
      "abstract": "Synthetic high-quality multi-step reasoning data can significantly enhance the performance of large language models on various tasks. However, most existing methods rely on rejection sampling, which generates trajectories independently and suffers from inefficiency and imbalanced sampling across problems of varying difficulty. In this work, we introduce FastMCTS, an innovative data synthesis strategy inspired by Monte Carlo Tree Search. FastMCTS provides a more efficient sampling method for multi-step reasoning data, offering step-level evaluation signals and promoting balanced sampling across problems of different difficulty levels. Experiments on both English and Chinese reasoning datasets demonstrate that FastMCTS generates over 30\\% more correct reasoning paths compared to rejection sampling as the number of generated tokens scales up. Furthermore, under comparable synthetic data budgets, models trained on FastMCTS-generated data outperform those trained on rejection sampling data by 3.9\\% across multiple benchmarks. As a lightweight sampling strategy, FastMCTS offers a practical and efficient alternative for synthesizing high-quality reasoning data. Our code will be released soon.",
      "authors": [
        "Peiji Li",
        "Kai Lv",
        "Yunfan Shao",
        "Yichuan Ma",
        "Linyang Li",
        "Xiaoqing Zheng",
        "Xipeng Qiu",
        "Qipeng Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T06:27:57+00:00",
          "link": "https://arxiv.org/abs/2502.11476v1",
          "size": "640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:06:53+00:00",
          "link": "https://arxiv.org/abs/2502.11476v2",
          "size": "642kb",
          "version": "v2"
        }
      ],
      "title": "FastMCTS: A Simple Sampling Strategy for Data Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11476",
        "PDF": "https://arxiv.org/pdf/2502.11476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces FastMCTS, a new data synthesis strategy aimed at generating high-quality multi-step reasoning data. This involves creating datasets for LLM training, thus making a significant contribution to data processing and enhancement for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.19119",
      "abstract": "Purpose: Magnetic resonance imaging (MRI) to visualize anatomical motion is becoming increasingly important when treating cancer patients with radiotherapy. Hybrid MRI-linear accelerator (MRI-linac) systems allow real-time motion management during irradiation. This paper presents a multi-institutional real-time MRI time series dataset from different MRI-linac vendors. The dataset is designed to support developing and evaluating real-time tumor localization (tracking) algorithms for MRI-guided radiotherapy within the TrackRAD2025 challenge (https://trackrad2025.grand-challenge.org/).\n  Acquisition and validation methods: The dataset consists of sagittal 2D cine MRIs in 585 patients from six centers (3 Dutch, 1 German, 1 Australian, and 1 Chinese). Tumors in the thorax, abdomen, and pelvis acquired on two commercially available MRI-linacs (0.35 T and 1.5 T) were included. For 108 cases, irradiation targets or tracking surrogates were manually segmented on each temporal frame. The dataset was randomly split into a public training set of 527 cases (477 unlabeled and 50 labeled) and a private testing set of 58 cases (all labeled).\n  Data Format and Usage Notes: The data is publicly available under the TrackRAD2025 collection: https://doi.org/10.57967/hf/4539. Both the images and segmentations for each patient are available in metadata format.\n  Potential Applications: This novel clinical dataset will enable the development and evaluation of real-time tumor localization algorithms for MRI-guided radiotherapy. By enabling more accurate motion management and adaptive treatment strategies, this dataset has the potential to advance the field of radiotherapy significantly.",
      "authors": [
        "Yiling Wang",
        "Elia Lombardo",
        "Adrian Thummerer",
        "Tom Bl\\\"ocker",
        "Yu Fan",
        "Yue Zhao",
        "Christianna Iris Papadopoulou",
        "Coen Hurkmans",
        "Rob H.N. Tijssen",
        "Pia A.W. G\\\"orts",
        "Shyama U. Tetar",
        "Davide Cusumano",
        "Martijn P.W. Intven",
        "Pim Borman",
        "Marco Riboldi",
        "Denis Dud\\'a\\v{s}",
        "Hilary Byrne",
        "Lorenzo Placidi",
        "Marco Fusella",
        "Michael Jameson",
        "Miguel Palacios",
        "Paul Cobussen",
        "Tobias Finazzi",
        "Cornelis J.A. Haasbeek",
        "Paul Keall",
        "Christopher Kurz",
        "Guillaume Landry and Matteo Maspero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T20:14:42+00:00",
          "link": "https://arxiv.org/abs/2503.19119v1",
          "size": "776kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T19:17:28+00:00",
          "link": "https://arxiv.org/abs/2503.19119v2",
          "size": "695kb",
          "version": "v2"
        }
      ],
      "title": "TrackRAD2025 challenge dataset: Real-time tumor tracking for MRI-guided radiotherapy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19119",
        "PDF": "https://arxiv.org/pdf/2503.19119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dataset for MRI-guided radiotherapy, focusing on tumor tracking in medical imaging, which is unrelated to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "LMUK-RADONC-PHYS-RES/TrackRAD2025",
          "downloads": "1247",
          "likes": "6",
          "link": "https://huggingface.co/datasets/LMUK-RADONC-PHYS-RES/TrackRAD2025"
        }
      ],
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14256",
      "abstract": "Generative AI is gaining increasing attention in software engineering, where testing remains an indispensable reliability mechanism. According to the widely adopted testing pyramid, unit tests constitute the majority of test cases and are often schematic, requiring minimal domain expertise. Automatically generating such tests under the supervision of software engineers can significantly enhance productivity during the development phase of the software lifecycle.\n  This paper investigates the impact of code context and prompting strategies on the quality and adequacy of unit tests generated by various large language models (LLMs) across several families. The results show that including docstrings notably improves code adequacy, while further extending context to the full implementation yields definitely smaller gains. Notably, the chain-of-thought prompting strategy -- applied even to 'reasoning' models -- achieves the best results, with up to 96.3\\% branch coverage, a 57\\% average mutation score, and near-perfect compilation success rate. Among the evaluated models, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation score and branch coverage being still in top in terms of compilation success rate.\n  All the code and resulting test suites are publicly available at https://github.com/peetery/LLM-analysis.",
      "authors": [
        "Jakub Walczak",
        "Piotr Tomalak and Artur Laskowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T11:23:17+00:00",
          "link": "https://arxiv.org/abs/2507.14256v1",
          "size": "3454kb",
          "version": "v1"
        }
      ],
      "title": "Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14256",
        "HTML": "https://arxiv.org/html/2507.14256",
        "PDF": "https://arxiv.org/pdf/2507.14256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating LLMs for automated unit test generation in software engineering without discussing data processing operations, dataset creation, or quality improvement techniques relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14543",
      "abstract": "It has always been a rather tough task to communicate with someone possessing a hearing impairment. One of the most tested ways to establish such a communication is through the use of sign based languages. However, not many people are aware of the smaller intricacies involved with sign language. Sign language recognition using computer vision aims at eliminating the communication barrier between deaf-mute and ordinary people so that they can properly communicate with others. Recently the pandemic has left the whole world shaken up and has transformed the way we communicate. Video meetings have become essential for everyone, even people with a hearing disability. In recent studies, it has been found that people with hearing disabilities prefer to sign over typing during these video calls. In this paper, we are proposing a browser extension that will automatically translate sign language to subtitles for everyone else in the video call. The Large-scale dataset which contains more than 2000 Word-Level ASL videos, which were performed by over 100 signers will be used.",
      "authors": [
        "Sharanya Mukherjee",
        "Md Hishaam Akhtar",
        "Kannadasan R"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:01:59+00:00",
          "link": "https://arxiv.org/abs/2507.14543v1",
          "size": "183kb",
          "version": "v1"
        }
      ],
      "title": "Real Time Captioning of Sign Language Gestures in Video Meetings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14543",
        "HTML": "https://arxiv.org/html/2507.14543",
        "PDF": "https://arxiv.org/pdf/2507.14543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses sign language recognition for video meetings using a large-scale dataset and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14746",
      "abstract": "High-fidelity simulations and physical experiments are essential for engineering analysis and design. However, their high cost often limits their applications in two critical tasks: global sensitivity analysis (GSA) and optimization. This limitation motivates the common use of Gaussian processes (GPs) as proxy regression models to provide uncertainty-aware predictions based on a limited number of high-quality observations. GPs naturally enable efficient sampling strategies that support informed decision-making under uncertainty by extracting information from a subset of possible functions for the model of interest. Despite their popularity in machine learning and statistics communities, sampling from GPs has received little attention in the community of engineering optimization. In this paper, we present the formulation and detailed implementation of two notable sampling methods -- random Fourier features and pathwise conditioning -- for generating posterior samples from GPs. Alternative approaches are briefly described. Importantly, we detail how the generated samples can be applied in GSA, single-objective optimization, and multi-objective optimization. We show successful applications of these sampling methods through a series of numerical examples.",
      "authors": [
        "Bach Do",
        "Nafeezat A. Ajenifuja",
        "Taiwo A. Adebiyi",
        "Ruda Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:36:38+00:00",
          "link": "https://arxiv.org/abs/2507.14746v1",
          "size": "14108kb",
          "version": "v1"
        }
      ],
      "title": "Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14746",
        "HTML": "https://arxiv.org/html/2507.14746",
        "PDF": "https://arxiv.org/pdf/2507.14746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Gaussian Processes and their application in global sensitivity analysis and optimization, without addressing any LLM training data processing tasks such as data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14874",
      "abstract": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine (TM) both interpretable and efficient, while the power of Tsetlin automata enables accuracy comparable to deep learning on an increasing number of datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning interpretable deep clauses from graph-structured input. Moving beyond flat, fixed-length input, the GraphTM gets more versatile, supporting sequences, grids, relations, and multimodality. Through message passing, the GraphTM builds nested deep clauses to recognize sub-graph patterns with exponentially fewer clauses, increasing both interpretability and data utilization. For image classification, GraphTM preserves interpretability and achieves 3.86%-points higher accuracy on CIFAR-10 than a convolutional TM. For tracking action coreference, faced with increasingly challenging tasks, GraphTM outperforms other reinforcement learning methods by up to 20.6%-points. In recommendation systems, it tolerates increasing noise to a greater extent than a Graph Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training 2.5x faster than GCN. The GraphTM's application to these varied fields demonstrates how graph representation learning and deep clauses bring new possibilities for TM learning.",
      "authors": [
        "Ole-Christoffer Granmo and Youmna Abdelwahab and Per-Arne Andersen and Paul F. A. Clarke and Kunal Dumbre and Ylva Gr{\\o}nnins{\\ae}ter and Vojtech Halenka and Runar Helin and Lei Jiao and Ahmed Khalid and Rebekka Omslandseter and Rupsa Saha and Mayur Shende and Xuan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T09:16:31+00:00",
          "link": "https://arxiv.org/abs/2507.14874v1",
          "size": "931kb",
          "version": "v1"
        }
      ],
      "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14874",
        "HTML": "https://arxiv.org/html/2507.14874",
        "PDF": "https://arxiv.org/pdf/2507.14874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces the Graph Tsetlin Machine for improving pattern recognition in graph structures, focusing on interpretability and efficiency rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15113",
      "abstract": "User journeys in e-commerce routinely violate the one-to-one assumption that a clicked item on an advertising platform is the same item later purchased on the merchant's website/app. For a significant number of converting sessions on our platform, users click product A but buy product B -- the Click A, Buy B (CABB) phenomenon. Training recommendation models on raw click-conversion pairs therefore rewards items that merely correlate with purchases, leading to biased learning and sub-optimal conversion rates. We reframe conversion prediction as a multi-task problem with separate heads for Click A Buy A (CABA) and Click A Buy B (CABB). To isolate informative CABB conversions from unrelated CABB conversions, we introduce a taxonomy-aware collaborative filtering weighting scheme where each product is first mapped to a leaf node in a product taxonomy, and a category-to-category similarity matrix is learned from large-scale co-engagement logs. This weighting amplifies pairs that reflect genuine substitutable or complementary relations while down-weighting coincidental cross-category purchases. Offline evaluation on e-commerce sessions reduces normalized entropy by 13.9% versus a last-click attribution baseline. An online A/B test on live traffic shows +0.25% gains in the primary business metric.",
      "authors": [
        "Xiangyu Zeng",
        "Amit Jaspal",
        "Bin Liu",
        "Goutham Panneeru",
        "Kevin Huang",
        "Nicolas Bievre",
        "Mohit Jaggi",
        "Prathap Maniraju and Ankur Jain"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:25:20+00:00",
          "link": "https://arxiv.org/abs/2507.15113v1",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "title": "Click A, Buy B: Rethinking Conversion Attribution in E- Commerce Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15113",
        "PDF": "https://arxiv.org/pdf/2507.15113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses conversion attribution challenges in e-commerce recommendation systems and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.17609",
      "abstract": "Medical imaging is essential in modern radiotherapy, supporting diagnosis, treatment planning, and monitoring. Synthetic imaging, particularly synthetic computed tomography (sCT), is gaining traction in radiotherapy. The SynthRAD2025 dataset and Grand Challenge promote advancements in sCT generation by providing a benchmarking platform for algorithms using cone-beam CT (CBCT) and magnetic resonance imaging (MRI).\n  The dataset includes 2362 cases: 890 MRI-CT and 1472 CBCT-CT pairs from head-and-neck, thoracic, and abdominal cancer patients treated at five European university medical centers (UMC Groningen, UMC Utrecht, Radboud UMC, LMU University Hospital Munich, and University Hospital of Cologne). Data were acquired with diverse scanners and protocols. Pre-processing, including rigid and deformable image registration, ensures high-quality, modality-aligned images. Extensive quality assurance validates image consistency and usability.\n  All imaging data is provided in MetaImage (.mha) format, ensuring compatibility with medical image processing tools. Metadata, including acquisition parameters and registration details, is available in structured CSV files. To maintain dataset integrity, SynthRAD2025 is divided into training (65%), validation (10%), and test (25%) sets. The dataset is accessible at https://doi.org/10.5281/zenodo.14918089 under the SynthRAD2025 collection.\n  This dataset supports benchmarking and the development of synthetic imaging techniques for radiotherapy applications. Use cases include sCT generation for MRI-only and MR-guided photon/proton therapy, CBCT-based dose calculations, and adaptive radiotherapy workflows. By integrating diverse acquisition settings, SynthRAD2025 fosters robust, generalizable image synthesis algorithms, advancing personalized cancer care and adaptive radiotherapy.",
      "authors": [
        "Adrian Thummerer",
        "Erik van der Bijl",
        "Arthur Jr Galapon",
        "Florian Kamp",
        "Mark Savenije",
        "Christina Muijs",
        "Shafak Aluwini",
        "Roel J.H.M. Steenbakkers",
        "Stephanie Beuel",
        "Martijn P.W. Intven",
        "Johannes A. Langendijk",
        "Stefan Both",
        "Stefanie Corradini",
        "Viktor Rogowski",
        "Maarten Terpstra",
        "Niklas Wahl",
        "Christopher Kurz",
        "Guillaume Landry",
        "and Matteo Maspero"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T19:53:09+00:00",
          "link": "https://arxiv.org/abs/2502.17609v1",
          "size": "985kb",
          "version": "v1"
        }
      ],
      "title": "SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for radiotherapy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17609",
        "PDF": "https://arxiv.org/pdf/2502.17609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on synthetic CT data generation for radiotherapy. Although it involves dataset creation, it is specific to medical imaging and does not relate to LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Image Generation",
        "Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.18448",
      "abstract": "Language-driven grasp detection has the potential to revolutionize human-robot interaction by allowing robots to understand and execute grasping tasks based on natural language commands. However, existing approaches face two key challenges. First, they often struggle to interpret complex text instructions or operate ineffectively in densely cluttered environments. Second, most methods require a training or finetuning step to adapt to new domains, limiting their generation in real-world applications. In this paper, we introduce GraspMAS, a new multi-agent system framework for language-driven grasp detection. GraspMAS is designed to reason through ambiguities and improve decision-making in real-world scenarios. Our framework consists of three specialized agents: Planner, responsible for strategizing complex queries; Coder, which generates and executes source code; and Observer, which evaluates the outcomes and provides feedback. Intensive experiments on two large-scale datasets demonstrate that our GraspMAS significantly outperforms existing baselines. Additionally, robot experiments conducted in both simulation and real-world settings further validate the effectiveness of our approach. Our project page is available at https://zquang2202.github.io/GraspMAS",
      "authors": [
        "Quang Nguyen",
        "Tri Le",
        "Huy Nguyen",
        "Thieu Vo",
        "Tung D. Ta",
        "Baoru Huang",
        "Minh N. Vu",
        "Anh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:34:50+00:00",
          "link": "https://arxiv.org/abs/2506.18448v1",
          "size": "3028kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T18:26:00+00:00",
          "link": "https://arxiv.org/abs/2506.18448v2",
          "size": "3024kb",
          "version": "v2"
        }
      ],
      "title": "GraspMAS: Zero-Shot Language-driven Grasp Detection with Multi-Agent System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18448",
        "HTML": "https://arxiv.org/html/2506.18448",
        "PDF": "https://arxiv.org/pdf/2506.18448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for language-driven grasp detection in robotics, which involves natural language commands but does not pertain to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14316",
      "abstract": "In high-stakes, time-critical scenarios-such as emergency evacuation, first responder prioritization, and crisis management -- decision-makers must rapidly choose among spatial targets, such as exits, individuals to assist, or areas to secure. Advances in indoor sensing and artificial intelligence (AI) can support these decisions by visualizing real-time situational data and AI suggestions on 2D maps. However, mentally mapping this information onto real-world spaces imposes significant cognitive load. This load can impair users' ability to appropriately judge AI suggestions, leading to inappropriate reliance (e.g., accepting wrong AI suggestions or rejecting correct ones). Embedded visualizations in Augmented Reality (AR), by directly overlaying information onto physical environments, may reduce this load and foster more deliberate, appropriate reliance on AI. But is this true? In this work, we conducted an empirical study (N = 32) comparing AR see-through (embedded visualization) and 2D Minimap in time-critical, AI-assisted spatial target selection tasks. Contrary to our expectations, users exhibited greater inappropriate reliance on AI in the AR condition. Our analysis further reveals that this is primarily due to over-reliance, with factors specific to embedded visualizations, such as perceptual challenges, visual proximity illusions, and highly realistic visual representations. Nonetheless, embedded visualizations demonstrated notable benefits in spatial reasoning, such as spatial mapping and egocentric spatial imagery. We conclude by discussing the empirical insights, deriving design implications, and outlining important directions for future research on human-AI decision collaboration in AR.",
      "authors": [
        "Xianhao Carton Liu",
        "Difan Jia",
        "Tongyu Nie",
        "Evan Suma Rosenberg",
        "Victoria Interrante",
        "Chen Zhu-Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:40:06+00:00",
          "link": "https://arxiv.org/abs/2507.14316v1",
          "size": "7473kb",
          "version": "v1"
        }
      ],
      "title": "Can AR-Embedded Visualizations Foster Appropriate Reliance on AI in Spatial Decision Making? A Comparative Study of AR See-Through vs. 2D Minimap",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14316",
        "HTML": "https://arxiv.org/html/2507.14316",
        "PDF": "https://arxiv.org/pdf/2507.14316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores AI-assisted decision-making in AR vs. 2D maps and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14473",
      "abstract": "In a recent paper, Caro, Lauri, Mifsud, Yuster, and Zarb ask which parameters $r$ and $c$ admit the existence of an $r$-regular graph such that the neighborhood of each vertex induces exactly $c$ edges. They show that every $r$ with $c$ satisfying $0\\leq c\\leq {r\\choose 2}-5r^{3/2}$ is achievable, but no $r$ with $c$ satisfying ${r\\choose 2}-\\lfloor\\frac{r}{3}\\rfloor\\leq c\\leq {r\\choose 2}-1$ is. We strengthen the bound in their nonexistence result from ${r\\choose 2}-\\lfloor\\frac{r}{3}\\rfloor$ to ${r\\choose 2}-\\lfloor\\frac{r-2}{2}\\rfloor$. Additionally, when the graph is the Cayley graph of an abelian group, we obtain a much more fine-grained characterization of the achievable values of $c$ between $\\binom{r}{2} - 5r^{3/2}$ and $\\binom{r}{2} - \\lfloor\\frac{r-2}{2}\\rfloor$, which we conjecture to be the correct answer for general graphs as well. That result relies on a lemma about approximate subgroups in the \"99% regime,\" quantifying the extent to which nearly-additively-closed subsets of an abelian group must be close to actual subgroups. Finally, we consider a generalization to graphs with multiple types of edges and partially resolve several open questions of Caro et al. about $\\textit{flip}$ colorings of graphs.",
      "authors": [
        "Nathan S. Sheffield and Zoe Xi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:08:04+00:00",
          "link": "https://arxiv.org/abs/2507.14473v1",
          "size": "425kb",
          "version": "v1"
        }
      ],
      "title": "Graphs With the Same Edge Count in Each Neighborhood",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14473",
        "HTML": "https://arxiv.org/html/2507.14473",
        "PDF": "https://arxiv.org/pdf/2507.14473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores graph theory by investigating parameters for regular graphs and edge count in neighborhoods, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14491",
      "abstract": "In many applications, one needs to learn a dynamical system from its solutions sampled at a finite number of time points. The learning problem is often formulated\n  as an optimization problem over a chosen function class. However, in the optimization procedure, it is necessary to employ a numerical scheme to integrate candidate dynamical systems and assess how their solutions fit the data.\n  This paper reveals potentially serious effects of a chosen numerical scheme on the learning outcome. In particular, our analysis demonstrates that a damped oscillatory system may be incorrectly identified as having \"anti-damping\" and exhibiting a reversed oscillation direction, despite adequately fitting the given data points.",
      "authors": [
        "Bing-Ze Lu",
        "Richard Tsai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:23:39+00:00",
          "link": "https://arxiv.org/abs/2507.14491v1",
          "size": "2166kb",
          "version": "v1"
        }
      ],
      "title": "Numerical Artifacts in Learning Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14491",
        "PDF": "https://arxiv.org/pdf/2507.14491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper highlights the effects of numerical schemes in learning dynamical systems. It does not relate to LLM training data processing or data engineering tasks relevant to such models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14549",
      "abstract": "A fundamental challenge in affective cognitive science is to develop models that accurately capture the relationship between external emotional stimuli and human internal experiences. While ANNs have demonstrated remarkable accuracy in facial expression recognition, their ability to model inter-individual differences in human perception remains underexplored. This study investigates the phenomenon of high perceptual variability-where individuals exhibit significant differences in emotion categorization even when viewing the same stimulus. Inspired by the similarity between ANNs and human perception, we hypothesize that facial expression samples that are ambiguous for ANN classifiers also elicit divergent perceptual judgments among human observers. To examine this hypothesis, we introduce a novel perceptual boundary sampling method to generate facial expression stimuli that lie along ANN decision boundaries. These ambiguous samples form the basis of the varEmotion dataset, constructed through large-scale human behavioral experiments. Our analysis reveals that these ANN-confusing stimuli also provoke heightened perceptual uncertainty in human participants, highlighting shared computational principles in emotion perception. Finally, by fine-tuning ANN representations using behavioral data, we achieve alignment between ANN predictions and both group-level and individual-level human perceptual patterns. Our findings establish a systematic link between ANN decision boundaries and human perceptual variability, offering new insights into personalized modeling of emotional interpretation.",
      "authors": [
        "Haotian Deng",
        "Chi Zhang",
        "Chen Wei",
        "Quanying Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:12:13+00:00",
          "link": "https://arxiv.org/abs/2507.14549v1",
          "size": "4992kb",
          "version": "v1"
        }
      ],
      "title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14549",
        "HTML": "https://arxiv.org/html/2507.14549",
        "PDF": "https://arxiv.org/pdf/2507.14549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses ANN-generated image datasets for perceptual variability research, which is not related to LLMs or their training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15303",
      "abstract": "Accurately and comprehensively representing crystal structures is critical for advancing machine learning in large-scale crystal materials simulations, however, effectively capturing and leveraging the intricate geometric and topological characteristics of crystal structures remains a core, long-standing challenge for most existing methods in crystal property prediction. Here, we propose MGT, a multi-view graph transformer framework that synergistically fuses SE3 invariant and SO3 equivariant graph representations, which respectively captures rotation-translation invariance and rotation equivariance in crystal geometries. To strategically incorporate these complementary geometric representations, we employ a lightweight mixture of experts router in MGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on the specific target task. Compared with previous state-of-the-art models, MGT reduces the mean absolute error by up to 21% on crystal property prediction tasks through multi-task self-supervised pretraining. Ablation experiments and interpretable investigations confirm the effectiveness of each technique implemented in our framework. Additionally, in transfer learning scenarios including crystal catalyst adsorption energy and hybrid perovskite bandgap prediction, MGT achieves performance improvements of up to 58% over existing baselines, demonstrating domain-agnostic scalability across diverse application domains. As evidenced by the above series of studies, we believe that MGT can serve as useful model for crystal material property prediction, providing a valuable tool for the discovery of novel materials.",
      "authors": [
        "Liang Zhang",
        "Kong Chen",
        "and Yuen Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:06:26+00:00",
          "link": "https://arxiv.org/abs/2507.15303v1",
          "size": "1789kb",
          "version": "v1"
        }
      ],
      "title": "Universal crystal material property prediction via multi-view geometric fusion in graph transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15303",
        "PDF": "https://arxiv.org/pdf/2507.15303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MGT, a framework for predicting crystal material properties via multi-view geometric fusion in graph transformers. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15844",
      "abstract": "Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to discover natural correspondences between task requirements and computational effort. Extensive experiments demonstrate that HBPO reduces average token usage by up to 60.6% while improving accuracy by 3.14% across four reasoning benchmarks. Unlike existing methods that impose external constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive behavior where models automatically adjust reasoning depth based on problem complexity. Our results suggest that reasoning efficiency and capability are not inherently conflicting, and can be simultaneously optimized through appropriately structured hierarchical training that preserves exploration diversity.",
      "authors": [
        "Shangke Lyu",
        "Linjuan Wu",
        "Yuchen Yan",
        "Xingyu Wu",
        "Hao Li",
        "Yongliang Shen",
        "Peisheng Jiang",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:52:34+00:00",
          "link": "https://arxiv.org/abs/2507.15844v1",
          "size": "1283kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15844",
        "HTML": "https://arxiv.org/html/2507.15844",
        "PDF": "https://arxiv.org/pdf/2507.15844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Hierarchical Budget Policy Optimization for reasoning models, aiming to optimize computational efficiency. It does not address any aspects of LLM training data processing, data quality improvement, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14166",
      "abstract": "Preclinical sleep research remains constrained by labor intensive, manual vigilance state classification and inter rater variability, limiting throughput and reproducibility. This study presents an automated framework developed by Team Neural Prognosticators to classify electroencephalogram (EEG) recordings of small rodents into three critical vigilance states paradoxical sleep (REM), slow wave sleep (SWS), and wakefulness. The system integrates advanced signal processing with machine learning, leveraging engineered features from both time and frequency domains, including spectral power across canonical EEG bands (delta to gamma), temporal dynamics via Maximum-Minimum Distance, and cross-frequency coupling metrics. These features capture distinct neurophysiological signatures such as high frequency desynchronization during wakefulness, delta oscillations in SWS, and REM specific bursts. Validated during the 2024 Big Data Health Science Case Competition (University of South Carolina Big Data Health Science Center, 2024), our XGBoost model achieved 91.5% overall accuracy, 86.8% precision, 81.2% recall, and an F1 score of 83.5%, outperforming all baseline methods. Our approach represents a critical advancement in automated sleep state classification and a valuable tool for accelerating discoveries in sleep science and the development of targeted interventions for chronic sleep disorders. As a publicly available code (BDHSC) resource is set to contribute significantly to advancements.",
      "authors": [
        "Sankalp Jajee",
        "Gaurav Kumar and Homayoun Valafar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:08:57+00:00",
          "link": "https://arxiv.org/abs/2507.14166v1",
          "size": "411kb",
          "version": "v1"
        }
      ],
      "title": "Automated Vigilance State Classification in Rodents Using Machine Learning and Feature Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14166",
        "HTML": "https://arxiv.org/html/2507.14166",
        "PDF": "https://arxiv.org/pdf/2507.14166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents an automated framework for classifying vigilance states in rodents using EEG data, focusing on machine learning for sleep state classification. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14204",
      "abstract": "Recent advancements in Large Language Models (LLMs) have spurred interest in numerous applications requiring robust long-range capabilities, essential for processing extensive input contexts and continuously generating extended outputs. As sequence lengths increase, the number of Key-Value (KV) pairs in LLMs escalates, creating a significant efficiency bottleneck. In this paper, we propose a new KV cache optimization paradigm called LaCache, a training-free method for efficient and accurate generative inference of LLMs. LaCache enables LLMs to simultaneously address both of the critical challenges in long-range modeling: robust long-range capabilities and continuous generation without running out-of-memory (OOM). Specifically, LaCache integrates two key innovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only sequentially (left-to-right within each layer) but also across layers (from shallow to deep), providing an extended span for capturing long-range dependencies under a fixed storage budget, thereby boosting long-range capabilities; and (2) an iterative compaction mechanism that progressively compresses older caches, freeing up space for new tokens within a fixed cache size. This token distance-based dynamic compression enables more effective continuous generation under constrained cache budgets. Experiments across various tasks, benchmarks, and LLM models consistently validate LaCache's effectiveness in enhancing LLMs' long-range capabilities. Our code is available at https://github.com/GATECH-EIC/LaCache.",
      "authors": [
        "Dachuan Shi",
        "Yonggan Fu",
        "Xiangchi Yuan",
        "Zhongzhi Yu",
        "Haoran You",
        "Sixu Li",
        "Xin Dong",
        "Jan Kautz",
        "Pavlo Molchanov",
        "Yingyan (Celine) Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:09:57+00:00",
          "link": "https://arxiv.org/abs/2507.14204v1",
          "size": "3662kb",
          "version": "v1"
        }
      ],
      "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14204",
        "HTML": "https://arxiv.org/html/2507.14204",
        "PDF": "https://arxiv.org/pdf/2507.14204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on LaCache, a KV cache optimization method to improve long-context modeling efficiency in LLMs. It does not relate to training data processing or the creation or improvement of training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14554",
      "abstract": "Software architecture plays a central role in the design, development, and maintenance of software systems. With the rise of cloud computing, microservices, and containers, architectural practices have diversified. Understanding these shifts is vital. This study analyzes software architecture trends across eight leading industry conferences over five years. We investigate the evolution of software architecture by analyzing talks from top practitioner conferences, focusing on the motivations and contexts driving technology adoption. We analyzed 5,677 talks from eight major industry conferences, using large language models and expert validation to extract technologies, their purposes, and usage contexts. We also explored how technologies interrelate and fit within DevOps and deployment pipelines. Among 450 technologies, Kubernetes, Cloud Native, Serverless, and Containers dominate by frequency and centrality. Practitioners present technology mainly related to deployment, communication, AI, and observability. We identify five technology communities covering automation, coordination, cloud AI, monitoring, and cloud-edge. Most technologies span multiple DevOps stages and support hybrid deployment. Our study reveals that a few core technologies, like Kubernetes and Serverless, dominate the contemporary software architecture practice. These are mainly applied in later DevOps stages, with limited focus on early phases like planning and coding. We also show how practitioners frame technologies by purpose and context, reflecting evolving industry priorities. Finally, we observe how only research can provide a more holistic lens on architectural design, quality, and evolution.",
      "authors": [
        "Ruoyu Su",
        "Noman ahmad",
        "Matteo Esposito",
        "Andrea Janes",
        "Davide Taibi",
        "Valentina Lenarduzzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.14554v1",
          "size": "1415kb",
          "version": "v1"
        }
      ],
      "title": "Emerging Trends in Software Architecture from the Practitioners Perspective: A Five Year Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14554",
        "HTML": "https://arxiv.org/html/2507.14554",
        "PDF": "https://arxiv.org/pdf/2507.14554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews trends in software architecture and practices and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14642",
      "abstract": "Story point estimation is an essential part of agile software development. Story points are unitless, project-specific effort estimates that help developers plan their sprints. Traditionally, developers estimate story points collaboratively using planning poker or other manual techniques. While the initial calibrating of the estimates to each project is helpful, once a team has converged on a set of precedents, story point estimation can become tedious and labor-intensive. Machine learning can reduce this burden, but only with enough context from the historical decisions made by the project team. That is, state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate predictions (within-project) when trained on data from the same project. The goal of this work is to streamline story point estimation by evaluating a comparative learning-based framework for calibrating project-specific story point prediction models. Instead of assigning a specific story point value to every backlog item, developers are presented with pairs of items, and indicate which item requires more effort. Using these comparative judgments, a machine learning model is trained to predict the story point estimates. We empirically evaluated our technique using data with 23,313 manual estimates in 16 projects. The model learned from comparative judgments can achieve on average 0.34 Spearman's rank correlation coefficient between its predictions and the ground truth story points. This is similar to, if not better than, the performance of a regression model learned from the ground truth story points. Therefore, the proposed comparative learning approach is more efficient than state-of-the-art regression-based approaches according to the law of comparative judgments - providing comparative judgments yields a lower cognitive burden on humans than providing ratings or categorical labels.",
      "authors": [
        "Monoshiz Mahbub Khan",
        "Xioayin Xi",
        "Andrew Meneely",
        "Zhe Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:36:19+00:00",
          "link": "https://arxiv.org/abs/2507.14642v1",
          "size": "806kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Story Point Estimation With Comparative Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14642",
        "PDF": "https://arxiv.org/pdf/2507.14642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on story point estimation in software development using comparative learning. While it involves data processing within a specific context, it does not contribute to LLM training data activities like dataset generation or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14859",
      "abstract": "The digital twin of humans is a relatively new concept. While many diverse definitions, architectures, and applications exist, a clear picture is missing on what, in fact, makes a human digital twin. Within this context, researchers and industrial use-case owners alike are unaware about the market potential of the - at the moment - rather theoretical construct. In this work, we draw a holistic vision of the human digital twin, and derive the specification of this holistic human digital twin in form of requirements, stakeholders, and users. For each group of users, we define exemplary applications that fall into the six levels of functionality: store, analyze, personalize, predict, control, and optimize. The functionality levels facilitate an abstraction of abilities of the human digital twin. From the manifold applications, we discuss three in detail to showcase the feasibility of the abstraction levels and the analysis of stakeholders and users. Based on the deep discussion, we derive a comprehensive list of requirements on the holistic human digital twin. These considerations shall be used as a guideline for research and industries for the implementation of human digital twins, particularly in context of reusability in multiple target applications.",
      "authors": [
        "Nils Mandischer",
        "Alexander Atanasyan",
        "Ulrich Dahmen",
        "Michael Schluse",
        "J\\\"urgen Rossmann",
        "Lars Mikelsons"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.14859v1",
          "size": "6448kb",
          "version": "v1"
        }
      ],
      "title": "Holistic Specification of the Human Digital Twin: Stakeholders, Users, Functionalities, and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14859",
        "HTML": "https://arxiv.org/html/2507.14859",
        "PDF": "https://arxiv.org/pdf/2507.14859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the concept and specification of human digital twins and does not relate to any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15028",
      "abstract": "Human intelligence requires correctness and robustness, with the former being foundational for the latter. In video understanding, correctness ensures the accurate interpretation of visual content, and robustness maintains consistent performance in challenging conditions. Despite advances in video large language models (video LLMs), existing benchmarks inadequately reflect the gap between these models and human intelligence in maintaining correctness and robustness in video interpretation. We introduce the Video Thinking Test (Video-TT), to assess if video LLMs can interpret real-world videos as effectively as humans. Video-TT reflects genuine gaps in understanding complex visual narratives, and evaluates robustness against natural adversarial questions. Video-TT comprises 1,000 YouTube Shorts videos, each with one open-ended question and four adversarial questions that probe visual and narrative complexity. Our evaluation shows a significant gap between video LLMs and human performance.",
      "authors": [
        "Yuanhan Zhang",
        "Yunice Chew",
        "Yuhao Dong",
        "Aria Leo",
        "Bo Hu",
        "Ziwei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:30:33+00:00",
          "link": "https://arxiv.org/abs/2507.15028v1",
          "size": "3669kb",
          "version": "v1"
        }
      ],
      "title": "Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15028",
        "HTML": "https://arxiv.org/html/2507.15028",
        "PDF": "https://arxiv.org/pdf/2507.15028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a video benchmark, Video Thinking Test, for evaluating video understanding in large language models, focusing on evaluation rather than training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15188",
      "abstract": "Requirements Engineering (RE) is one of the most interaction-intensive phases of software development. This means that RE activities might be especially impacted by stakeholders' national culture. Software development projects increasingly have a very diverse range of stakeholders. To future-proof RE activities, we need to help RE practitioners avoid misunderstandings and conflicts that might arise from not understanding potential Cultural Influences (CIs). Moreover, an awareness of CIs supports diversity and inclusion in the IT profession. Bangladesh has a growing IT sector with some unique socio-cultural characteristics, and has been largely overlooked in this research field. In this study, we aim to investigate how the RE process is adopted in the context of Bangladeshi culture and what cultural influences impact overall RE activities.",
      "authors": [
        "Chowdhury Shahriar Muzammel",
        "Maria Spichkova",
        "James Harland"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:21:51+00:00",
          "link": "https://arxiv.org/abs/2507.15188v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "Cultural Impact on Requirements Engineering Activities: Bangladeshi Practitioners' View",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15188",
        "HTML": "https://arxiv.org/html/2507.15188",
        "PDF": "https://arxiv.org/pdf/2507.15188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates the impact of cultural influences on requirements engineering activities in Bangladesh, with no relation to LLM training data processing or dataset creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.05037",
      "abstract": "Recent advancements in Deep Reinforcement Learning (DRL) and Graph Neural Networks (GNNs) have demonstrated notable promise in the realm of intelligent traffic signal control, facilitating the coordination across multiple intersections. However, the traditional methods rely on standard graph structures often fail to capture the intricate higher-order spatio-temporal correlations inherent in real-world traffic dynamics. Standard graphs cannot fully represent the spatial relationships within road networks, which limits the effectiveness of graph-based approaches. In contrast, directed hypergraphs provide more accurate representation of spatial information to model complex directed relationships among multiple nodes. In this paper, we propose DHLight, a novel multi-agent policy-based framework that synergistically integrates directed hypergraph learning module. This framework introduces a novel dynamic directed hypergraph construction mechanism, which captures complex and evolving spatio-temporal relationships among intersections in road networks. By leveraging the directed hypergraph relational structure, DHLight empowers agents to achieve adaptive decision-making in traffic signal control. The effectiveness of DHLight is validated against state-of-the-art baselines through extensive experiments in various network datasets. We release the code to support the reproducibility of this work at https://github.com/LuckyVoasem/Traffic-Light-control",
      "authors": [
        "Zhen Lei",
        "Zhishu Shen",
        "Kang Wang",
        "Zhenwei Wang",
        "Tiehua Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-08T09:33:26+00:00",
          "link": "https://arxiv.org/abs/2409.05037v1",
          "size": "6048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T02:01:31+00:00",
          "link": "https://arxiv.org/abs/2409.05037v2",
          "size": "2817kb",
          "version": "v2"
        }
      ],
      "title": "DHLight: Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05037",
        "HTML": "https://arxiv.org/html/2409.05037",
        "PDF": "https://arxiv.org/pdf/2409.05037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a novel framework (DHLight) for traffic signal control using hypergraph learning, not on LLM training data processing. It does not discuss data engineering operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.16543",
      "abstract": "This study introduces a LLMs powered multiagent ensemble method to address challenges in hallucination and data labeling, particularly in large-scale EHR datasets. Manual labeling of such datasets requires domain expertise and is labor-intensive, time-consuming, expensive, and error-prone. To overcome this bottleneck, we developed an ensemble LLMs method and demonstrated its effectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG dataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from the clinical notes of EHR. Trading off benefits and cost, we selected a pool of diverse open source LLMs with satisfactory performance. We treat each LLM's prediction as a vote and apply a mechanism of majority voting with minimal winning threshold for ensemble. We implemented an ensemble LLMs application for EHR data labeling tasks. By using the ensemble LLMs and natural language processing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an estimated accuracy of 98.2%. We applied the ensemble LLMs method to identify SDOH from social history sections of 1,405 EHR clinical notes, also achieving competitive performance. Our experiments show that the ensemble LLMs can outperform individual LLM even the best commercial one, and the method reduces hallucination errors. From the research, we found that (1) the ensemble LLMs method significantly reduces the time and effort required for labeling large-scale EHR data, automating the process with high accuracy and quality; (2) the method generalizes well to other text data labeling tasks, as shown by its application to SDOH identification; (3) the ensemble of a group of diverse LLMs can outperform or match the performance of the best individual LLM; and (4) the ensemble method substantially reduces hallucination errors. This approach provides a scalable and efficient solution to data-labeling challenges.",
      "authors": [
        "Jingwei Huang",
        "Kuroush Nezafati",
        "Ismael Villanueva-Miranda",
        "Zifan Gu",
        "Yueshuang Xu",
        "Ann Marie Navar",
        "Tingyi Wanyan",
        "Qin Zhou",
        "Bo Yao",
        "Ruichen Rong",
        "Xiaowei Zhan",
        "Guanghua Xiao",
        "Eric D. Peterson",
        "Donghan M. Yang",
        "Wenqi Shi",
        "Yang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T22:12:00+00:00",
          "link": "https://arxiv.org/abs/2410.16543v1",
          "size": "4134kb",
          "version": "v1"
        },
        {
          "date": "2025-04-25T18:43:19+00:00",
          "link": "https://arxiv.org/abs/2410.16543v2",
          "size": "1755kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T20:53:27+00:00",
          "link": "https://arxiv.org/abs/2410.16543v3",
          "size": "4333kb",
          "version": "v3"
        }
      ],
      "title": "Large Language Models Powered Multiagent Ensemble for Mitigating Hallucination and Efficient Atrial Fibrillation Annotation of ECG Reports",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16543",
        "PDF": "https://arxiv.org/pdf/2410.16543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs for automating data labeling of large-scale datasets, which involves data processing. However, its main focus is on the ensemble method for reducing hallucination and automating labeling, not specifically on LLM training data processing techniques."
      },
      "tasks": [
        "Hallucination"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14214",
      "abstract": "In modern times, people have numerous online accounts, but they rarely read the Terms of Service or Privacy Policy of those sites despite claiming otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that assists users with personalized privacy policy analysis. PoliAnalyzer uses Natural Language Processing (NLP) to extract formal representations of data usage practices from policy texts. In favor of deterministic, logical inference is applied to compare user preferences with the formal privacy policy representation and produce a compliance report. To achieve this, we extend an existing formal Data Terms of Use policy language to model privacy policies as app policies and user preferences as data policies. In our evaluation using our enriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated high accuracy in identifying relevant data usage practices, achieving F1-score of 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can model diverse user data-sharing preferences, derived from prior research as 23 user profiles, and perform compliance analysis against the top 100 most-visited websites. This analysis revealed that, on average, 95.2% of a privacy policy's segments do not conflict with the analyzed user preferences, enabling users to concentrate on understanding the 4.8% (636 / 13205) that violates preferences, significantly reducing cognitive burden. Further, we identified common practices in privacy policies that violate user expectations - such as the sharing of location data with 3rd parties. This paper demonstrates that PoliAnalyzer can support automated personalized privacy policy analysis at scale using off-the-shelf NLP tools. This sheds light on a pathway to help individuals regain control over their data and encourage societal discussions on platform data practices to promote a fairer power dynamic.",
      "authors": [
        "Rui Zhao",
        "Vladyslav Melnychuk",
        "Jun Zhao",
        "Jesse Wright and Nigel Shadbolt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:19:33+00:00",
          "link": "https://arxiv.org/abs/2507.14214v1",
          "size": "3486kb",
          "version": "v1"
        }
      ],
      "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14214",
        "HTML": "https://arxiv.org/html/2507.14214",
        "PDF": "https://arxiv.org/pdf/2507.14214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the automated analysis of privacy policies using NLP tools, which is not related to LLM training data processing for pretraining or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14594",
      "abstract": "Open-source licenses establish the legal foundation for software reuse, yet license variants, including both modified standard licenses and custom-created alternatives, introduce significant compliance complexities. Despite their prevalence and potential impact, these variants are poorly understood in modern software systems, and existing tools do not account for their existence, leading to significant challenges in both effectiveness and efficiency of license analysis. To fill this knowledge gap, we conduct a comprehensive empirical study of license variants in the PyPI ecosystem. Our findings show that textual variations in licenses are common, yet only 2% involve substantive modifications. However, these license variants lead to significant compliance issues, with 10.7% of their downstream dependencies found to be license-incompatible.\n  Inspired by our findings, we introduce LV-Parser, a novel approach for efficient license variant analysis leveraging diff-based techniques and large language models, along with LV-Compat, an automated pipeline for detecting license incompatibilities in software dependency networks. Our evaluation demonstrates that LV-Parser achieves an accuracy of 0.936 while reducing computational costs by 30%, and LV-Compat identifies 5.2 times more incompatible packages than existing methods with a precision of 0.98.\n  This work not only provides the first empirical study into license variants in software packaging ecosystem but also equips developers and organizations with practical tools for navigating the complex landscape of open-source licensing.",
      "authors": [
        "Weiwei Xu",
        "Hengzhi Ye",
        "Kai Gao",
        "Minghui Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:41:33+00:00",
          "link": "https://arxiv.org/abs/2507.14594v1",
          "size": "291kb",
          "version": "v1"
        }
      ],
      "title": "A first look at License Variants in the PyPI Ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14594",
        "HTML": "https://arxiv.org/html/2507.14594",
        "PDF": "https://arxiv.org/pdf/2507.14594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies license variants in software ecosystems and doesn't focus on LLM training data processing. Its main contribution is tools for license analysis, which does not relate to dataset creation or improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14661",
      "abstract": "Semi-supervised domain adaptation (SSDA) aims to achieve high predictive performance in the target domain with limited labeled target data by exploiting abundant source and unlabeled target data. Despite its significance in numerous applications, theory on the effectiveness of SSDA remains largely unexplored, particularly in scenarios involving various types of source-target distributional shifts. In this work, we develop a theoretical framework based on structural causal models (SCMs) which allows us to analyze and quantify the performance of SSDA methods when labeled target data is limited. Within this framework, we introduce three SSDA methods, each having a fine-tuning strategy tailored to a distinct assumption about the source and target relationship. Under each assumption, we demonstrate how extending an unsupervised domain adaptation (UDA) method to SSDA can achieve minimax-optimal target performance with limited target labels. When the relationship between source and target data is only vaguely known -- a common practical concern -- we propose the Multi Adaptive-Start Fine-Tuning (MASFT) algorithm, which fine-tunes UDA models from multiple starting points and selects the best-performing one based on a small hold-out target validation dataset. Combined with model selection guarantees, MASFT achieves near-optimal target predictive performance across a broad range of types of distributional shifts while significantly reducing the need for labeled target data. We empirically validate the effectiveness of our proposed methods through simulations.",
      "authors": [
        "Wooseok Ha",
        "Yuansi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:18:28+00:00",
          "link": "https://arxiv.org/abs/2507.14661v1",
          "size": "295kb",
          "version": "v1"
        }
      ],
      "title": "When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14661",
        "HTML": "https://arxiv.org/html/2507.14661",
        "PDF": "https://arxiv.org/pdf/2507.14661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning strategies in semi-supervised domain adaptation for limited labeled target data but focuses on the theoretical framework and model optimization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14909",
      "abstract": "The Endless Tuning is a design method for a reliable deployment of artificial intelligence based on a double mirroring process, which pursues both the goals of avoiding human replacement and filling the so-called responsibility gap (Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the relational approach urged therein, it was then actualized in a protocol, implemented in three prototypical applications regarding decision-making processes (respectively: loan granting, pneumonia diagnosis, and art style recognition) and tested with such as many domain experts. Step by step illustrating the protocol, giving insights concretely showing a different voice (Gilligan 1993) in the ethics of artificial intelligence, a philosophical account of technical choices (e.g., a reversed and hermeneutic deployment of XAI algorithms) will be provided in the present study together with the results of the experiments, focusing on user experience rather than statistical accuracy. Even thoroughly employing deep learning models, full control was perceived by the interviewees in the decision-making setting, while it appeared that a bridge can be built between accountability and liability in case of damage.",
      "authors": [
        "Elio Grande"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:48:07+00:00",
          "link": "https://arxiv.org/abs/2507.14909v1",
          "size": "4815kb",
          "version": "v1"
        }
      ],
      "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14909",
        "HTML": "https://arxiv.org/html/2507.14909",
        "PDF": "https://arxiv.org/pdf/2507.14909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a design method for AI deployment focusing on avoiding human replacement and filling responsibility gaps. It neither focuses on nor addresses LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15193",
      "abstract": "Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is essential for tumor burden estimation, prognosis, and treatment planning. It may also help infer genetic clusters, reducing reliance on expensive testing. This study systematically evaluates anatomical priors to identify configurations that improve deep learning-based PCC segmentation. We employed the nnU-Net framework to evaluate eleven annotation strategies for accurate 3D segmentation of pheochromocytoma, introducing a set of novel multi-class schemes based on organ-specific anatomical priors. These priors were derived from adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen, kidney, aorta, adrenal gland, and pancreas), and were compared against a broad body-region prior used in previous work. The framework was trained and tested on 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center. Performance was measured using Dice Similarity Coefficient (DSC), Normalized Surface Distance (NSD), and instance-wise F1 score. Among all strategies, the Tumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation accuracy, significantly outperforming the previously used Tumor + Body (TB) annotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84% improvement at an IoU threshold of 0.5), measured on a 70-30 train-test split. The TKA model also showed superior tumor burden quantification (R^2 = 0.968) and strong segmentation across all genetic subtypes. In five-fold cross-validation, TKA consistently outperformed TB across IoU thresholds (0.1 to 0.5), reinforcing its robustness and generalizability. These findings highlight the value of incorporating relevant anatomical context in deep learning models to achieve precise PCC segmentation, supporting clinical assessment and longitudinal monitoring.",
      "authors": [
        "Tanjin Taher Toma",
        "Tejas Sudharshan Mathai",
        "Bikash Santra",
        "Pritam Mukherjee",
        "Jianfei Liu",
        "Wesley Jong",
        "Darwish Alabyad",
        "Vivek Batheja",
        "Abhishek Jha",
        "Mayank Patel",
        "Darko Pucar",
        "Jayadira del Rivero",
        "Karel Pacak",
        "Ronald M. Summers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.15193v1",
          "size": "12853kb",
          "version": "v1"
        }
      ],
      "title": "A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15193",
        "HTML": "https://arxiv.org/html/2507.15193",
        "PDF": "https://arxiv.org/pdf/2507.15193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates anatomical priors for improving segmentation accuracy in medical imaging, specifically for pheochromocytoma in CT scans, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15831",
      "abstract": "In software engineering, numerous studies have focused on the analysis of fine-grained logs, leading to significant innovations in areas such as refactoring, security, and code completion. However, no similar studies have been conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we (1) introduce a toolset for collecting code changes in Jupyter notebooks during development time; (2) use it to collect more than 100 hours of work related to a data analysis task and a machine learning task (carried out by 20 developers with different levels of expertise), resulting in a dataset containing 2,655 cells and 9,207 cell executions; and (3) use this dataset to investigate the dynamic nature of the notebook development process and the changes that take place in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the cells between executions and found that a significant number of these changes were relatively small fixes and code iteration modifications. This suggests that notebooks are used not only as a development and exploration tool but also as a debugging tool. We report a number of other insights and propose potential future research directions on the novel data.",
      "authors": [
        "Sergey Titov",
        "Konstantin Grotov",
        "Cristina Sarasua",
        "Yaroslav Golubev",
        "Dhivyabharathi Ramasamy",
        "Alberto Bacchelli",
        "Abraham Bernstein",
        "Timofey Bryksin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:41:51+00:00",
          "link": "https://arxiv.org/abs/2507.15831v1",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15831",
        "HTML": "https://arxiv.org/html/2507.15831",
        "PDF": "https://arxiv.org/pdf/2507.15831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the analysis and changes within Jupyter notebooks during development, but does not contribute to LLM training data processing or generation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.07409",
      "abstract": "Arunachalam and de Wolf (2018) showed that the sample complexity of quantum batch learning of boolean functions, in the realizable and agnostic settings, has the same form and order as the corresponding classical sample complexities. In this paper, we extend this, ostensibly surprising, message to batch multiclass learning, online boolean learning, and online multiclass learning. For our online learning results, we first consider an adaptive adversary variant of the classical model of Dawid and Tewari (2022). Then, we introduce the first (to the best of our knowledge) model of online learning with quantum examples.",
      "authors": [
        "Preetham Mohan",
        "Ambuj Tewari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Complexity (cs.CC)",
        "Quantum Physics (quant-ph)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-15T00:22:44+00:00",
          "link": "https://arxiv.org/abs/2302.07409v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2023-02-16T18:51:04+00:00",
          "link": "https://arxiv.org/abs/2302.07409v2",
          "size": "33kb",
          "version": "v2"
        },
        {
          "date": "2023-10-10T01:51:40+00:00",
          "link": "https://arxiv.org/abs/2302.07409v3",
          "size": "172kb",
          "version": "v3"
        },
        {
          "date": "2023-12-26T13:08:28+00:00",
          "link": "https://arxiv.org/abs/2302.07409v4",
          "size": "178kb",
          "version": "v4"
        },
        {
          "date": "2025-07-21T16:20:59+00:00",
          "link": "https://arxiv.org/abs/2302.07409v5",
          "size": "182kb",
          "version": "v5"
        }
      ],
      "title": "Quantum Learning Theory Beyond Batch Binary Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.07409",
        "PDF": "https://arxiv.org/pdf/2302.07409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends quantum learning theory into online and multiclass learning, without any focus on LLM training data processing or related operations."
      },
      "tasks": [
        "Binary Classification",
        "Classification",
        "Learning Theory"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.11693",
      "abstract": "Semantic communication (SemCom) is emerging as a key technology for future sixth-generation (6G) systems. Unlike traditional bit-level communication (BitCom), SemCom directly optimizes performance at the semantic level, leading to superior communication efficiency. Nevertheless, the task-oriented nature of SemCom renders it challenging to completely replace BitCom. Consequently, it is desired to consider a semantic-bit coexisting communication system, where a base station (BS) serves SemCom users (sem-users) and BitCom users (bit-users) simultaneously. Such a system faces severe and heterogeneous inter-user interference. In this context, this paper provides a new semantic-bit coexisting communication framework and proposes a spatial beamforming scheme to accommodate both types of users. Specifically, we consider maximizing the semantic rate for semantic users while ensuring the quality-of-service (QoS) requirements for bit-users. Due to the intractability of obtaining the exact closed-form expression of the semantic rate, a data driven method is first applied to attain an approximated expression via data fitting. With the resulting complex transcendental function, majorization minimization (MM) is adopted to convert the original formulated problem into a multiple-ratio problem, which allows fractional programming (FP) to be used to further transform the problem into an inhomogeneous quadratically constrained quadratic programs (QCQP) problem. Solving the problem leads to a semi-closed form solution with undetermined Lagrangian factors that can be updated by a fixed point algorithm. Extensive simulation results demonstrate that the proposed beamforming scheme significantly outperforms conventional beamforming algorithms such as zero-forcing (ZF), maximum ratio transmission (MRT), and weighted minimum mean-square error (WMMSE).",
      "authors": [
        "Maojun Zhang",
        "Guangxu Zhu",
        "Richeng Jin",
        "Xiaoming Chen",
        "Qingjiang Shi",
        "Caijun Zhong",
        "Kaibin Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-18T11:48:02+00:00",
          "link": "https://arxiv.org/abs/2403.11693v1",
          "size": "6153kb",
          "version": "v1"
        },
        {
          "date": "2024-03-22T21:54:33+00:00",
          "link": "https://arxiv.org/abs/2403.11693v2",
          "size": "6153kb",
          "version": "v2"
        },
        {
          "date": "2024-09-21T15:31:25+00:00",
          "link": "https://arxiv.org/abs/2403.11693v3",
          "size": "5958kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T08:45:27+00:00",
          "link": "https://arxiv.org/abs/2403.11693v4",
          "size": "1474kb",
          "version": "v4"
        }
      ],
      "title": "Beamforming Design for Semantic-Bit Coexisting Communication System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11693",
        "HTML": "https://arxiv.org/html/2403.11693",
        "PDF": "https://arxiv.org/pdf/2403.11693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a semantic-bit coexisting communication system using beamforming but does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.01789",
      "abstract": "Software testing remains the most widely used methodology for validating quality of code. However, effectiveness of testing critically depends on the quality of test suites used. Test cases in a test suite consist of two fundamental parts: (1) input values for the code under test, and (2) correct checks for the outputs it produces. These checks are commonly written as assertions, and termed test oracles. The last couple of decades have seen much progress in automated test input generation, e.g., using fuzzing and symbolic execution. However, automating test oracles remains a relatively less explored problem area. Indeed, a test oracle by its nature requires knowledge of expected behavior, which may only be known to the developer and may not not exist in a formal language that supports automated reasoning.\n  Our focus in this paper is automation of test oracles for clients of widely used Java libraries, e.g., java.lang and java.util packages. Our key insight is that Javadocs that provide a rich source of information can enable automated generation of test oracles. Javadocs of the core Java libraries are fairly detailed documents that contain natural language descriptions of not only how the libraries behave but also how the clients must (not) use them. We use large language models as an enabling technology to embody our insight into a framework for test oracle automation, and evaluate it experimentally. Our experiments demonstrate that LLMs can generate oracles for checking normal and exceptional behaviors from Javadocs, with 98.8% of these oracles being compilable and 96.4% accurately reflecting intended properties. Even for the few incorrect oracles, errors are minor and can be easily corrected with the help of additional comment information generated by the LLMs.",
      "authors": [
        "Shan Jiang",
        "Chenguang Zhu",
        "Sarfraz Khurshid"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T04:24:25+00:00",
          "link": "https://arxiv.org/abs/2411.01789v1",
          "size": "630kb",
          "version": "v1"
        },
        {
          "date": "2024-12-14T17:19:41+00:00",
          "link": "https://arxiv.org/abs/2411.01789v2",
          "size": "630kb",
          "version": "v2"
        }
      ],
      "title": "Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01789",
        "HTML": "https://arxiv.org/html/2411.01789",
        "PDF": "https://arxiv.org/pdf/2411.01789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs to automate test oracles for software testing, aligning somewhat with data generation for fine-tuning purposes. However, the main focus is on code testing rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.01481",
      "abstract": "With a view on bilevel and PDE-constrained optimisation, we develop iterative estimates $\\widetilde{F'}(x^k)$ of $F'(x^k)$ for composite functions $F :=J \\circ S$, where $S$ is the solution mapping of the inner optimisation problem or PDE. The idea is to form a single-loop method by interweaving updates of the iterate $x^k$ by an outer optimisation method, with updates of the estimate by single steps of standard optimisation methods and linear system solvers. When the inner methods satisfy simple tracking inequalities, the differential estimates can almost directly be employed in standard convergence proofs for general forward-backward type methods. We adapt those proofs to a general inexact setting in normed spaces, that, besides our differential estimates, also covers mismatched adjoints and unreachable optimality conditions in measure spaces. As a side product of these efforts, we provide improved convergence results for nonconvex Primal-Dual Proximal Splitting (PDPS).",
      "authors": [
        "Neil Dizon",
        "Tuomo Valkonen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T13:30:53+00:00",
          "link": "https://arxiv.org/abs/2412.01481v1",
          "size": "57kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T16:31:58+00:00",
          "link": "https://arxiv.org/abs/2412.01481v2",
          "size": "61kb",
          "version": "v2"
        }
      ],
      "title": "Differential estimates for fast first-order multilevel nonconvex optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01481",
        "PDF": "https://arxiv.org/pdf/2412.01481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimization methods related to PDE-constrained optimization and bilinear optimization problems. It does not involve any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14902",
      "abstract": "Universal multimodal retrieval (UMR), which aims to address complex retrieval tasks where both queries and candidates span diverse modalities, has been significantly advanced by the emergence of MLLMs. While state-of-the-art MLLM-based methods in the literature predominantly adopt contrastive learning principles, they often differ in their specific training recipes. Despite their success, the mechanisms underlying their retrieval capabilities remain largely unexplored, potentially resulting in suboptimal performance and limited generalization ability. To address these issues, we present a comprehensive study aimed at uncovering the key factors that drive effective embedding learning for UMR using MLLMs. We begin by implementing a general MLLM-based embedding learning pipeline, and systematically analyze the primary contributors to high-performing universal retrieval systems. Based on this, we explore various aspects of the details in embedding generation and training strategies, including progressive transition, hard negative mining and re-ranker distillation. Notably, our findings reveal that often-overlooked factors can have a substantial impact on model performance. Building on these discoveries, we introduce a unified framework termed U-MARVEL (\\textbf{U}niversal \\textbf{M}ultimod\\textbf{A}l \\textbf{R}etrie\\textbf{V}al via \\textbf{E}mbedding \\textbf{L}earning), which outperforms state-of-the-art competitors on the M-BEIR benchmark by a large margin in supervised settings, and also exihibits strong zero-shot performance on several tasks such as composed image retrieval and text-to-video retrieval. These results underscore the generalization potential of our framework across various embedding-based retrieval tasks. Code is available at https://github.com/chaxjli/U-MARVEL",
      "authors": [
        "Xiaojie Li",
        "Chu Li",
        "Shi-Zhe Chen",
        "Xi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.14902v1",
          "size": "496kb",
          "version": "v1"
        }
      ],
      "title": "U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14902",
        "HTML": "https://arxiv.org/html/2507.14902",
        "PDF": "https://arxiv.org/pdf/2507.14902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work delves into multimodal retrieval using embedding learning, but its focus is on understanding and improving retrieval systems rather than on data processing or dataset creation for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.18669",
      "abstract": "This paper studies trajectory optimization of an autonomous underwater vehicle (AUV) to track an unknown maneuvering target. Due to the restrictions on sensing capabilities in the underwater scenario, the AUV is limited to collecting only bearing measurements to the target. A framework called GBT is proposed with integration of online learning and planning. First, a Gaussian process learning method is proposed for the AUV to handle unknown target motion, wherein pseudo linear transformation of bearing measurements is introduced to address nonlinearity of bearings. A probabilistic bearing-data-dependent bound on tracking error is then rigorously established. Based on it, optimal desired bearings that can reduce tracking uncertainty are obtained analytically. Finally, the trajectory optimization problem is formulated and transformed into an easily solved one with parametric transformation. Numerical examples and comparison with existing methods verify the feasibility and superior performance of our proposed framework.",
      "authors": [
        "Yingbo Fu",
        "Ziwen Yang",
        "Liang Xu",
        "Yi Guo",
        "Shanying Zhu and Xinnping Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T12:00:37+00:00",
          "link": "https://arxiv.org/abs/2410.18669v1",
          "size": "3148kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T07:02:49+00:00",
          "link": "https://arxiv.org/abs/2410.18669v2",
          "size": "3104kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T13:45:33+00:00",
          "link": "https://arxiv.org/abs/2410.18669v3",
          "size": "5373kb",
          "version": "v3"
        }
      ],
      "title": "Trajectory Optimization for Unknown Maneuvering Target Tracking with Bearing-only Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18669",
        "HTML": "https://arxiv.org/html/2410.18669",
        "PDF": "https://arxiv.org/pdf/2410.18669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on trajectory optimization for an underwater vehicle using bearing-only measurements and does not address any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.15090",
      "abstract": "Modern large language models (LLMs) achieve impressive performance on some tasks, while exhibiting distinctly non-human-like behaviors on others. This raises the question of how well the LLM's learned representations align with human representations. In this work, we introduce a novel approach to study representation alignment: we adopt a method from research on activation steering to identify neurons responsible for specific concepts (e.g., ''cat'') and then analyze the corresponding activation patterns. We find that LLM representations captured this way closely align with human representations inferred from behavioral data, matching inter-human alignment levels. Our approach significantly outperforms the alignment captured by word embeddings, which have been the focus of prior work on human-LLM alignment. Additionally, our approach enables a more granular view of how LLMs represent concepts -- we show that LLMs organize concepts in a way that mirrors human concept organization.",
      "authors": [
        "Masha Fedzechkina",
        "Eleonora Gualdoni",
        "Sinead Williamson",
        "Katherine Metcalf",
        "Skyler Seto",
        "Barry-John Theobald"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T23:08:03+00:00",
          "link": "https://arxiv.org/abs/2502.15090v1",
          "size": "8396kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:48:40+00:00",
          "link": "https://arxiv.org/abs/2502.15090v2",
          "size": "7935kb",
          "version": "v2"
        }
      ],
      "title": "Analyze the Neurons, not the Embeddings: Understanding When and Where LLM Representations Align with Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15090",
        "PDF": "https://arxiv.org/pdf/2502.15090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the alignment of LLM representations with human representations by analyzing neuron activations, rather than working on training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15097",
      "abstract": "Group or cluster structure on explanatory variables in machine learning problems is a very general phenomenon, which has attracted broad interest from practitioners and theoreticians alike. In this work we contribute an approach to sparse learning under such group structure, that does not require prior information on the group identities. Our paradigm is motivated by the Laplacian geometry of an underlying network with a related community structure, and proceeds by directly incorporating this into a penalty that is effectively computed via a heat-flow-based local network dynamics. The proposed penalty interpolates between the lasso and the group lasso penalties, the runtime of the heat-flow dynamics being the interpolating parameter. As such it can automatically default to lasso when the group structure reflected in the Laplacian is weak. In fact, we demonstrate a data-driven procedure to construct such a network based on the available data. Notably, we dispense with computationally intensive pre-processing involving clustering of variables, spectral or otherwise. Our technique is underpinned by rigorous theorems that guarantee its effective performance and provide bounds on its sample complexity. In particular, in a wide range of settings, it provably suffices to run the diffusion for time that is only logarithmic in the problem dimensions. We explore in detail the interfaces of our approach with key statistical physics models in network science, such as the Gaussian Free Field and the Stochastic Block Model. Our work raises the possibility of applying similar diffusion-based techniques to classical learning tasks, exploiting the interplay between geometric, dynamical and stochastic structures underlying the data.",
      "authors": [
        "Subhroshekhar Ghosh and Soumendu Sundar Mukherjee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:32:57+00:00",
          "link": "https://arxiv.org/abs/2507.15097v1",
          "size": "359kb",
          "version": "v1"
        }
      ],
      "title": "Learning under Latent Group Sparsity via Diffusion on Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15097",
        "HTML": "https://arxiv.org/html/2507.15097",
        "PDF": "https://arxiv.org/pdf/2507.15097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses sparse learning and latent group sparsity via diffusion on networks, without focusing on training data processing or datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15355",
      "abstract": "Adjusting visual parameters such as brightness and contrast is common in our everyday experiences. Finding the optimal parameter setting is challenging due to the large search space and the lack of an explicit objective function, leaving users to rely solely on their implicit preferences. Prior work has explored Preferential Bayesian Optimization (PBO) to address this challenge, involving users to iteratively select preferred designs from candidate sets. However, PBO often requires many rounds of preference comparisons, making it more suitable for designers than everyday end-users. We propose Meta-PO, a novel method that integrates PBO with meta-learning to improve sample efficiency. Specifically, Meta-PO infers prior users' preferences and stores them as models, which are leveraged to intelligently suggest design candidates for the new users, enabling faster convergence and more personalized results. An experimental evaluation of our method for appearance design tasks on 2D and 3D content showed that participants achieved satisfactory appearance in 5.86 iterations using Meta-PO when participants shared similar goals with a population (e.g., tuning for a ``warm'' look) and in 8 iterations even generalizes across divergent goals (e.g., from ``vintage'', ``warm'', to ``holiday''). Meta-PO makes personalized visual optimization more applicable to end-users through a generalizable, more efficient optimization conditioned on preferences, with the potential to scale interface personalization more broadly.",
      "authors": [
        "Zhipeng Li",
        "Yi-Chi Liao",
        "Christian Holz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:08:04+00:00",
          "link": "https://arxiv.org/abs/2507.15355v1",
          "size": "11230kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Visual Appearance Optimization by Learning from Prior Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15355",
        "HTML": "https://arxiv.org/html/2507.15355",
        "PDF": "https://arxiv.org/pdf/2507.15355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Meta-PO, a method for optimizing visual appearance based on user preferences. It focuses on visual parameter adjustment and user personalization, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15485",
      "abstract": "Line search is a fundamental part of iterative optimization methods for unconstrained and bound-constrained optimization problems to determine suitable step lengths that provide sufficient improvement in each iteration. Traditional line search methods are based on iterative interval refinement, where valuable information about function value and gradient is discarded in each iteration. We propose a line search method via Bayesian optimization, preserving and utilizing otherwise discarded information to improve step-length choices. Our approach is guaranteed to converge and shows superior performance compared to state-of-the-art methods based on empirical tests on the challenging unconstrained and bound-constrained optimization problems from the CUTEst test set.",
      "authors": [
        "Robin Labryga and Tomislav Prusina and S\\\"oren Laue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:42:12+00:00",
          "link": "https://arxiv.org/abs/2507.15485v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "Information Preserving Line Search via Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15485",
        "PDF": "https://arxiv.org/pdf/2507.15485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves Bayesian optimization for line search in optimization problems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.16370",
      "abstract": "Safe and efficient multi-agent navigation in dynamic environments remains inherently challenging, particularly when real-time decision-making is required on resource-constrained platforms. Ensuring collision-free trajectories while adapting to uncertainties without relying on pre-built maps further complicates real-world deployment. To address these challenges, we propose LSTP-Nav, a lightweight end-to-end policy for multi-agent navigation that enables map-free collision avoidance in complex environments by directly mapping raw LiDAR point clouds to motion commands. At the core of this framework lies LSTP-Net, an efficient network that processes raw LiDAR data using a GRU architecture, enhanced with attention mechanisms to dynamically focus on critical environmental features while minimizing computational overhead. Additionally, a novel HS reward optimizes collision avoidance by incorporating angular velocity, prioritizing obstacles along the predicted heading, and enhancing training stability. To narrow the sim-to-real gap, we develop PhysReplay-Simlab, a physics-realistic multi-agent simulator, employs localized replay to mine near-failure experiences. Relying solely on LiDA, LSTP-Nav achieves efficient zero-shot sim-to-real transfer on a CPU-only robotic platform, enabling robust navigation in dynamic environments while maintaining computation frequencies above 40 Hz. Extensive experiments demonstrate that LSTP-Nav outperforms baselines with a 9.58% higher success rate and a 12.30% lower collision rate, underscoring its practicality and robustness for real-world applications.",
      "authors": [
        "Xingrong Diao",
        "Zhirui Sun",
        "Jianwei Peng",
        "Jiankun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T09:28:05+00:00",
          "link": "https://arxiv.org/abs/2408.16370v1",
          "size": "10497kb",
          "version": "v1"
        },
        {
          "date": "2024-09-04T02:39:53+00:00",
          "link": "https://arxiv.org/abs/2408.16370v2",
          "size": "10099kb",
          "version": "v2"
        },
        {
          "date": "2025-02-24T11:35:07+00:00",
          "link": "https://arxiv.org/abs/2408.16370v3",
          "size": "10092kb",
          "version": "v3"
        },
        {
          "date": "2025-07-11T15:49:24+00:00",
          "link": "https://arxiv.org/abs/2408.16370v4",
          "size": "73394kb",
          "version": "v4"
        },
        {
          "date": "2025-07-18T22:32:58+00:00",
          "link": "https://arxiv.org/abs/2408.16370v5",
          "size": "73394kb",
          "version": "v5"
        }
      ],
      "title": "LSTP-Nav: Lightweight Spatiotemporal Policy for Map-free Multi-agent Navigation with LiDAR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16370",
        "HTML": "https://arxiv.org/html/2408.16370",
        "PDF": "https://arxiv.org/pdf/2408.16370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a multi-agent navigation system using LiDAR and focuses on decision-making in navigation. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.06205",
      "abstract": "High-resolution segmentation is critical for precise disease diagnosis by extracting fine-grained morphological details. Existing hierarchical encoder-decoder frameworks have demonstrated remarkable adaptability across diverse medical segmentation tasks. While beneficial, they usually require the huge computation and memory cost when handling large-size segmentation, which limits their applications in foundation model building and real-world clinical scenarios. To address this limitation, we propose a holistically efficient framework for high-resolution medical image segmentation, called HER-Seg. Specifically, we first devise a computation-efficient image encoder (CE-Encoder) to model long-range dependencies with linear complexity while maintaining sufficient representations. In particular, we introduce the dual-gated linear attention (DLA) mechanism to perform cascaded token filtering, selectively retaining important tokens while ignoring irrelevant ones to enhance attention computation efficiency. Then, we introduce a memory-efficient mask decoder (ME-Decoder) to eliminate the demand for the hierarchical structure by leveraging cross-scale segmentation decoding. Extensive experiments reveal that HER-Seg outperforms state-of-the-arts in high-resolution medical 2D, 3D and video segmentation tasks. In particular, our HER-Seg requires only 0.59GB training GPU memory and 9.39G inference FLOPs per 1024$\\times$1024 image, demonstrating superior memory and computation efficiency. The code is available at https://github.com/xq141839/HER-Seg.",
      "authors": [
        "Qing Xu",
        "Zhenye Lou",
        "Chenxin Li",
        "Yue Li",
        "Xiangjian He",
        "Tesema Fiseha Berhanu",
        "Rong Qu",
        "Wenting Duan",
        "Zhen Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T16:48:57+00:00",
          "link": "https://arxiv.org/abs/2504.06205v1",
          "size": "3627kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:45:54+00:00",
          "link": "https://arxiv.org/abs/2504.06205v2",
          "size": "40373kb",
          "version": "v2"
        }
      ],
      "title": "HER-Seg: Holistically Efficient Segmentation for High-Resolution Medical Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06205",
        "HTML": "https://arxiv.org/html/2504.06205",
        "PDF": "https://arxiv.org/pdf/2504.06205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a framework for high-resolution medical image segmentation. It does not address LLMs or their data processing."
      },
      "tasks": [
        "Decoder",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/xq141839/HRMedSeg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14562",
      "abstract": "This paper investigates the convergence rates of two Euler-type methods for a class of time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients. Building upon existing research, we adapt the backward Euler method to time-changed stochastic differential equations where both coefficients exhibit super-linear growth and introduce an explicit counterpart, the projected Euler method. It is shown that both methods achieve the optimal strong convergence rate of order 1/2 in the mean-square sense for this class of equations. Numerical simulations confirm the theoretical findings",
      "authors": [
        "Yuanling Niu",
        "Shuai Wang",
        "Ying Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.14562v1",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "title": "1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14562",
        "HTML": "https://arxiv.org/html/2507.14562",
        "PDF": "https://arxiv.org/pdf/2507.14562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates convergence rates of Euler-type methods for time-changed stochastic differential equations. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15064",
      "abstract": "Current diffusion models for human image animation often struggle to maintain identity (ID) consistency, especially when the reference image and driving video differ significantly in body size or position. We introduce StableAnimator++, the first ID-preserving video diffusion framework with learnable pose alignment, capable of generating high-quality videos conditioned on a reference image and a pose sequence without any post-processing. Building upon a video diffusion model, StableAnimator++ contains carefully designed modules for both training and inference, striving for identity consistency. In particular, StableAnimator++ first uses learnable layers to predict the similarity transformation matrices between the reference image and the driven poses via injecting guidance from Singular Value Decomposition (SVD). These matrices align the driven poses with the reference image, mitigating misalignment to a great extent. StableAnimator++ then computes image and face embeddings using off-the-shelf encoders, refining the face embeddings via a global content-aware Face Encoder. To further maintain ID, we introduce a distribution-aware ID Adapter that counteracts interference caused by temporal layers while preserving ID via distribution alignment. During the inference stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization integrated into the denoising process, guiding the diffusion trajectory for enhanced facial fidelity. Experiments on benchmarks show the effectiveness of StableAnimator++ both qualitatively and quantitatively.",
      "authors": [
        "Shuyuan Tu",
        "Zhen Xing",
        "Xintong Han",
        "Zhi-Qi Cheng",
        "Qi Dai",
        "Chong Luo",
        "Zuxuan Wu",
        "Yu-Gang Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:59:26+00:00",
          "link": "https://arxiv.org/abs/2507.15064v1",
          "size": "12794kb",
          "version": "v1"
        }
      ],
      "title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15064",
        "HTML": "https://arxiv.org/html/2507.15064",
        "PDF": "https://arxiv.org/pdf/2507.15064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in human image animation through StableAnimator++, focusing on video generation and pose alignment, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15235",
      "abstract": "The Design of Experiments (DOEs) is a fundamental scientific methodology that provides researchers with systematic principles and techniques to enhance the validity, reliability, and efficiency of experimental outcomes. In this study, we explore optimal experimental design within a Bayesian framework, utilizing Bayes' theorem to reformulate the utility expectation--originally expressed as a nested double integral--into an independent double integral form, significantly improving numerical efficiency. To further accelerate the computation of the proposed utility expectation, conditional density estimation is employed to approximate the ratio of two Gaussian random fields, while covariance serves as a selection criterion to identify informative datasets during model fitting and integral evaluation. In scenarios characterized by low simulation efficiency and high costs of raw data acquisition, key challenges such as surrogate modeling, failure probability estimation, and parameter inference are systematically restructured within the Bayesian experimental design framework. The effectiveness of the proposed methodology is validated through both theoretical analysis and practical applications, demonstrating its potential for enhancing experimental efficiency and decision-making under uncertainty.",
      "authors": [
        "Miao Huang and Hongqiao Wang and Kunyu Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T04:41:05+00:00",
          "link": "https://arxiv.org/abs/2507.15235v1",
          "size": "3599kb",
          "version": "v1"
        }
      ],
      "title": "Accelerated Bayesian Optimal Experimental Design via Conditional Density Estimation and Informative Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15235",
        "HTML": "https://arxiv.org/html/2507.15235",
        "PDF": "https://arxiv.org/pdf/2507.15235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on Bayesian experimental design and optimization for improved experimental outcomes, not on LLM training data processing or any data operations relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15281",
      "abstract": "The capabilities of Large Language Models (LLMs) are limited to some extent by pre-training, so some researchers optimize LLMs through post-training. Existing post-training strategies, such as memory-based retrieval or preference optimization, improve user alignment yet fail to enhance the model's domain cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution (DPSE) framework that jointly optimizes user preference adaptation and domain-specific competence. DPSE introduces a Censor module to extract multi-dimensional interaction signals and estimate satisfaction scores, which guide structured data expansion via topic-aware and preference-driven strategies. These expanded datasets support a two-stage fine-tuning pipeline: supervised domain grounding followed by frequency-aware preference optimization. Experiments across general NLP benchmarks and long-term dialogue tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning, Preference Optimization, and Memory-Augmented baselines. Ablation studies validate the contribution of each module. In this way, our framework provides an autonomous path toward continual self-evolution of LLMs.",
      "authors": [
        "Haoran Sun",
        "Zekun Zhang",
        "Shaoning Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:30:39+00:00",
          "link": "https://arxiv.org/abs/2507.15281v1",
          "size": "1096kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Self-Evolution Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15281",
        "HTML": "https://arxiv.org/html/2507.15281",
        "PDF": "https://arxiv.org/pdf/2507.15281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a Dual-Phase Self-Evolution framework involving dataset expansion and fine-tuning strategies. While dataset expansion is mentioned, the primary focus is on model optimization rather than core contributions to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15496",
      "abstract": "Odometry is a critical task for autonomous systems for self-localization and navigation. We propose a novel LiDAR-Visual odometry framework that integrates LiDAR point clouds and images for accurate and robust pose estimation. Our method utilizes a dense-depth map estimated from point clouds and images through depth completion, and incorporates a multi-scale feature extraction network with attention mechanisms, enabling adaptive depth-aware representations. Furthermore, we leverage dense depth information to refine flow estimation and mitigate errors in occlusion-prone regions. Our hierarchical pose refinement module optimizes motion estimation progressively, ensuring robust predictions against dynamic environments and scale ambiguities. Comprehensive experiments on the KITTI odometry benchmark demonstrate that our approach achieves similar or superior accuracy and robustness compared to state-of-the-art visual and LiDAR odometry methods.",
      "authors": [
        "JunYing Huang",
        "Ao Xu",
        "DongSun Yong",
        "KeRen Li",
        "YuanFeng Wang",
        "and Qi Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:58:10+00:00",
          "link": "https://arxiv.org/abs/2507.15496v1",
          "size": "552kb",
          "version": "v1"
        }
      ],
      "title": "Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15496",
        "HTML": "https://arxiv.org/html/2507.15496",
        "PDF": "https://arxiv.org/pdf/2507.15496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a LiDAR-Visual odometry framework for pose estimation in autonomous systems. It does not make any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2011.09177",
      "abstract": "Business process modelling languages typically enable the representation of business process models by employing (graphical) symbols. These symbols can vary depending upon the verbosity of the language, the modelling paradigm, the focus of the language, and so on. To make explicit the different constructs and rules employed by a specific language, as well as bridge the gap across different languages, meta-models have been proposed in literature. These meta-models are a crucial source of knowledge on what state-of-the-art literature considers relevant to describe business processes. The goal of this work is to provide an extensive systematic literature review (SLR) of business process meta-models. This SLR aims at answering research questions concerning: (i) the kind of meta-models proposed in literature; (ii) the recurring constructs they contain; (iii) their purposes; and (iv) their evaluations.",
      "authors": [
        "Greta Adamo",
        "Chiara Ghidini",
        "Chiara Di Francescomarino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2020-11-18T09:54:51+00:00",
          "link": "https://arxiv.org/abs/2011.09177v1",
          "size": "711kb",
          "version": "v1"
        }
      ],
      "title": "What is a Process Model Composed of? A Systematic Literature Review of Meta-Models in BPM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2011.09177",
        "PDF": "https://arxiv.org/pdf/2011.09177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a systematic literature review of meta-models in business process management, which is not related to LLM training data processing or any data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10297",
      "abstract": "This paper presents a numerical investigation of acoustic wave propagation in an obstacle with periodically time-modulated material parameters. We focus on the numerical construction of Floquet$-$Bloch solutions, which are quasi-periodic kernel elements of the hyperbolic operator appearing on the left-hand side of the acoustic wave equation. Using the temporal Fourier expansion yields a system of coupled harmonics, which can be truncated. Rewriting this system then provides different (generally nonlinear) eigenvalue formulations for discretized Floquet$-$Bloch solutions. Deriving energy estimates and the necessary conditions for Riesz$-$Schauder theory show basic properties of the occurring Floquet exponents. To derive fully discrete schemes, we employ a general Galerkin space discretization. Under assumptions on the relation of the temporal Fourier truncation and the Galerkin space discretization, we prove that the approximated Floquet exponents exhibit the same limitations as their continuous counterparts. Moreover, the approximated modes are shown to satisfy the defining properties of Floquet$-$Bloch solutions, with a defect that tends to zero as the number of harmonics approaches infinity. Numerical experiments demonstrate the effectiveness of the proposed approach and illustrate the theoretical findings.",
      "authors": [
        "J\\\"org Nick",
        "Ralf Hiptmair and Habib Ammari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T08:51:16+00:00",
          "link": "https://arxiv.org/abs/2410.10297v1",
          "size": "2430kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:14:05+00:00",
          "link": "https://arxiv.org/abs/2410.10297v2",
          "size": "1085kb",
          "version": "v2"
        }
      ],
      "title": "Floquet$-$Bloch analysis of wave propagation with time-periodic coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10297",
        "HTML": "https://arxiv.org/html/2410.10297",
        "PDF": "https://arxiv.org/pdf/2410.10297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around numerical analysis of wave propagation using Floquet-Bloch theory and does not involve any aspect of LLM training data processing or techniques related to data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.23768",
      "abstract": "Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic capabilities, achieving impressive performance in various tasks such as image recognition and object localization. However, their effectiveness in fine-grained tasks remains an open question. In everyday scenarios, individuals encountering design materials, such as magazines, typography tutorials, research papers, or branding content, may wish to identify aesthetically pleasing fonts used in the text. Given their multimodal capabilities and free accessibility, many VLMs are often considered potential tools for font recognition. This raises a fundamental question: Do VLMs truly possess the capability to recognize fonts? To investigate this, we introduce the Font Recognition Benchmark (FRB), a compact and well-structured dataset comprising 15 commonly used fonts. FRB includes two versions: (i) an easy version, where 10 sentences are rendered in different fonts, and (ii) a hard version, where each text sample consists of the names of the 15 fonts themselves, introducing a stroop effect that challenges model perception. Through extensive evaluation of various VLMs on font recognition tasks, we arrive at the following key findings: (i) Current VLMs exhibit limited font recognition capabilities, with many state-of-the-art models failing to achieve satisfactory performance and being easily affected by the stroop effect introduced by textual information. (ii) Few-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits in improving font recognition accuracy across different VLMs. (iii) Attention analysis sheds light on the inherent limitations of VLMs in capturing semantic features.",
      "authors": [
        "Zhecheng Li",
        "Guoxian Song",
        "Yujun Cai",
        "Zhen Xiong",
        "Junsong Yuan",
        "Yiwei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T06:33:21+00:00",
          "link": "https://arxiv.org/abs/2503.23768v1",
          "size": "29534kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T02:51:42+00:00",
          "link": "https://arxiv.org/abs/2503.23768v2",
          "size": "31749kb",
          "version": "v2"
        }
      ],
      "title": "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23768",
        "HTML": "https://arxiv.org/html/2503.23768",
        "PDF": "https://arxiv.org/pdf/2503.23768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Font Recognition Benchmark (FRB) and evaluates vision-language models on font recognition tasks, which is not related to LLM training data processing."
      },
      "tasks": [
        "Few-Shot Learning",
        "Font Recognition",
        "Object Localization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14202",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse applications, yet they pose significant security risks that threaten their safe deployment in critical domains. Current security alignment methodologies predominantly rely on Process Reward Models (PRMs) to evaluate intermediate reasoning steps, introducing substantial computational overhead and scalability constraints. This paper presents a novel PRM-free security alignment framework that leverages automated red teaming and adversarial training to achieve robust security guarantees while maintaining computational efficiency. Our approach systematically identifies vulnerabilities through sophisticated attack strategies including genetic algorithm optimization, multi-agent simulation, and advanced prompt mutation techniques. The framework enhances model robustness via targeted adversarial training with curriculum learning and adaptive regularization mechanisms. Comprehensive experimental evaluation across five state-of-the-art LLMs demonstrates that our method achieves superior security alignment performance compared to PRM-based approaches while reducing computational costs by 61\\%. The framework incorporates transparent reporting and continuous audit mechanisms that enable iterative security improvement and regulatory compliance. Our contributions advance the field of efficient LLM security alignment by democratizing access to robust security measures for resource-constrained organizations and providing a scalable foundation for addressing evolving adversarial threats.",
      "authors": [
        "Pengfei Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:41:12+00:00",
          "link": "https://arxiv.org/abs/2507.14202v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14202",
        "HTML": "https://arxiv.org/html/2507.14202",
        "PDF": "https://arxiv.org/pdf/2507.14202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers around enhancing security alignment of LLMs without using training data PRMs by utilizing red teaming and adversarial training. It does not deal with training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14683",
      "abstract": "Large language models have recently evolved from fluent text generation to advanced reasoning across diverse domains, giving rise to reasoning language models. Among these domains, mathematical reasoning serves as a representative benchmark as it requires precise multi-step logic and abstract reasoning, which can be generalized to other tasks. While closed-source RLMs such as GPT-o3 demonstrate impressive reasoning capabilities, their proprietary nature limits transparency and reproducibility. Although many open-source projects aim to close this gap, most of them lack sufficient openness by omitting critical resources such as datasets and detailed training configurations, which hinders reproducibility. To contribute toward greater transparency in RLM development, we introduce the MiroMind-M1 series, a set of fully open-source RLMs built on the Qwen-2.5 backbone that match or exceed the performance of existing open-source RLMs. Specifically, our models are trained in two stages: SFT on a carefully curated corpus of 719K math-reasoning problems with verified CoT trajectories, followed by RLVR on 62K challenging and verifiable problems. To enhance the robustness and efficiency of the RLVR process, we introduce Context-Aware Multi-Stage Policy Optimization, an algorithm that integrates length-progressive training with an adaptive repetition penalty to encourage context-aware RL training. Our model achieves state-of-the-art or competitive performance and superior token efficiency among Qwen-2.5-based open-source 7B and 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate reproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B, MiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K, MiroMind-M1-RL-62K); and all training and evaluation configurations. We hope these resources will support further research and foster community advancement.",
      "authors": [
        "Xingxuan Li",
        "Yao Xiao",
        "Dianwen Ng",
        "Hai Ye",
        "Yue Deng",
        "Xiang Lin",
        "Bin Wang",
        "Zhanfeng Mo",
        "Chong Zhang",
        "Yueyi Zhang",
        "Zonglin Yang",
        "Ruilin Li",
        "Lei Lei",
        "Shihao Xu",
        "Han Zhao",
        "Weiling Chen",
        "Feng Ji",
        "Lidong Bing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:21:23+00:00",
          "link": "https://arxiv.org/abs/2507.14683v1",
          "size": "1583kb",
          "version": "v1"
        }
      ],
      "title": "MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14683",
        "HTML": "https://arxiv.org/html/2507.14683",
        "PDF": "https://arxiv.org/pdf/2507.14683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This study involves the creation and public release of datasets specifically designed for mathematical reasoning tasks and discusses training processes, significantly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14794",
      "abstract": "Metasurface (MTS) comprises an array of metaatoms, each reflecting and inducing a phase shift into the incident wireless signal. We seek the optimal combination of phase shifts across all the meta-atoms to maximize the channel strength from transmitter to receiver. Unlike many existing works that heavily rely on channel state information (CSI), this paper proposes a statistical approach to the phase shift optimization in the absence of CSI, namely blind configuration or zero-order optimization. The main idea is to extract the key features of the wireless environment from the received signal strength (RSS) data via conditional sample mean, with provable performance. Furthermore, as a windfall profit, we show that the proposed blind configuration method has a nontrivial connection to phase retrieval which can be utilized for active sensing. In a nutshell, by configuring a pair of MTSs blindly without channel estimation, we not only enhance the channel strength to facilitate wireless communication, but also enable receiver to localize transmitter. All we need is the RSS data that can be readily measured at receiver. Our algorithm is verified in prototype systems in the 2.6 GHz spectral band. As shown in field tests, the proposed algorithm outperforms the benchmarks (e.g., MUSIC) in the active sensing task, and in the meanwhile raises the signal-to-noise ratio (SNR) significantly by about 10 dB.",
      "authors": [
        "Wenhai Lai",
        "Kaiming Shen",
        "Zhi-Quan Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:53:12+00:00",
          "link": "https://arxiv.org/abs/2507.14794v1",
          "size": "10295kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Communications and Sensing Simultaneously by Zero-Order Optimization of MTS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14794",
        "HTML": "https://arxiv.org/html/2507.14794",
        "PDF": "https://arxiv.org/pdf/2507.14794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores optimization techniques for enhancing wireless communications and sensing with a metasurface system. It is not related to LLM training data processing or any relevant data processing methods or techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14904",
      "abstract": "3D visual grounding allows an embodied agent to understand visual information in real-world 3D environments based on human instructions, which is crucial for embodied intelligence. Existing 3D visual grounding methods typically rely on separate encoders for different modalities (e.g., RGB images, text, and 3D point clouds), resulting in large and complex models that are inefficient to train. While some approaches use pre-trained 2D multi-modal models like CLIP for 3D tasks, they still struggle with aligning point cloud data to 2D encoders. As a result, these methods continue to depend on 3D encoders for feature extraction, further increasing model complexity and training inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal network to process all three modalities (RGB images, text, and point clouds), significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal model with adapter-based fine-tuning, this framework effectively adapts to the tri-modal setting, improving both adaptability and performance across modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module is designed to fuse geometric multi-scale features from point clouds and images. We then integrate textual features for final modality fusion and introduce a multi-modal decoder to facilitate deep cross-modal understanding. Together, our method achieves unified feature extraction and fusion across the three modalities, enabling an end-to-end 3D visual grounding model. Compared to the baseline, our method reduces the number of trainable parameters by approximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection task and a 6.25\\% improvement in the 3D visual grounding task.",
      "authors": [
        "Fan Li",
        "Zanyi Wang",
        "Zeyi Huang",
        "Guang Dai",
        "Jingdong Wang",
        "Mengmeng Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:28:06+00:00",
          "link": "https://arxiv.org/abs/2507.14904v1",
          "size": "750kb",
          "version": "v1"
        }
      ],
      "title": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14904",
        "HTML": "https://arxiv.org/html/2507.14904",
        "PDF": "https://arxiv.org/pdf/2507.14904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for 3D visual grounding using CLIP-based models. It focuses on modality integration for 3D visual tasks, not on language model training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10602",
      "abstract": "We investigate the properties of positive definite and positive semi-definite symmetric matrices within the framework of symmetrized tropical algebra, an extension of tropical algebra adapted to ordered valued fields.\n  We focus on the eigenvalues and eigenvectors of these matrices. We\n  prove that the eigenvalues of a positive (semi)-definite matrix in the tropical symmetrized setting coincide with its diagonal entries. Then, we show that the images by the valuation of the eigenvalues of a positive definite matrix over a valued nonarchimedean ordered field coincide with the eigenvalues of an associated matrix in the symmetrized tropical algebra. Moreover, under a genericity condition, we characterize the images of the eigenvectors under the map keeping track both of the nonarchimedean valuation and sign, showing that they coincide with tropical eigenvectors in the symmetrized algebra. These results offer new insights into the spectral theory of matrices over tropical semirings, and provide combinatorial formul\\ae\\ for log-limits of eigenvalues and eigenvectors of parametric families of real positive definite matrices.",
      "authors": [
        "Marianne Akian",
        "Stephane Gaubert",
        "Dariush Kiani",
        "Hanieh Tavakolipour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Numerical Analysis (cs.NA)",
        "Combinatorics (math.CO)",
        "Numerical Analysis (math.NA)",
        "Spectral Theory (math.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T23:07:37+00:00",
          "link": "https://arxiv.org/abs/2412.10602v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T19:26:16+00:00",
          "link": "https://arxiv.org/abs/2412.10602v2",
          "size": "62kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T18:04:23+00:00",
          "link": "https://arxiv.org/abs/2412.10602v3",
          "size": "85kb",
          "version": "v3"
        }
      ],
      "title": "Spectral Properties of Positive Definite Matrices over Symmetrized Tropical Algebras and Valued Ordered fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10602",
        "PDF": "https://arxiv.org/pdf/2412.10602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the spectral properties of matrices over tropical algebras and does not discuss any aspects of data processing for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.08898",
      "abstract": "We consider learning outcomes in games with carryover effects between rounds: when outcomes in the present round affect the game in the future. An important example of such systems is routers in networking, as they use simple learning algorithms to find the best way to deliver packets to their desired destination. This simple, myopic, and distributed decision process makes large queuing systems easy to operate, but at the same time, the system needs more capacity than would be required if all traffic were centrally coordinated. Gaitonde and Tardos (EC 2020 and JACM 2023) initiated the study of such systems, modeling them as an infinitely repeated game in which routers compete for servers and the system maintains a state (the number of packets held at each queue) that results from outcomes of previous rounds. However, their model assumes that servers have no buffers at all, so routers have to resend all packets that were not served successfully, which makes their system model unrealistic. They show that in their model, even with hugely increased server capacity relative to what is needed in the centrally coordinated case, ensuring that the system is stable requires the use of timestamps and priority for older packets.\n  We consider a system with two important changes, which make the model more realistic and allow for much higher traffic rates: first, we add a very small buffer to each server, allowing the server to hold on to a single packet to be served later (if it fails to serve it immediately), and second, we do not require timestamps or priority to older packets. Using theoretical analysis and simulations, we show that when queues are learning, a small constant-factor increase in server capacity, compared to what would be needed if centrally coordinating, suffices to keep the system stable, even if servers select randomly among packets arriving simultaneously.",
      "authors": [
        "Ariana Abel",
        "Yoav Kolumbus",
        "Jeronimo Martin Duque",
        "Cristian Palma Foster",
        "Eva Tardos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T02:23:23+00:00",
          "link": "https://arxiv.org/abs/2502.08898v1",
          "size": "1521kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T02:59:48+00:00",
          "link": "https://arxiv.org/abs/2502.08898v2",
          "size": "1520kb",
          "version": "v2"
        }
      ],
      "title": "Learning in Strategic Queuing Systems with Small Buffers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08898",
        "HTML": "https://arxiv.org/html/2502.08898",
        "PDF": "https://arxiv.org/pdf/2502.08898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on learning outcomes in networking systems modeled as carryover effect games. It does not address LLM training data processing, so it does not make contributions relevant to this task."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14227",
      "abstract": "In this study, we address the gradient-based domain generalization problem, where predictors aim for consistent gradient directions across different domains. Existing methods have two main challenges. First, minimization of gradient empirical distance or gradient inner products (GIP) leads to gradient fluctuations among domains, thereby hindering straightforward learning. Second, the direct application of gradient learning to the joint loss function can incur high computation overheads due to second-order derivative approximation. To tackle these challenges, we propose a new Pareto Optimality Gradient Matching (POGM) method. In contrast to existing methods that add gradient matching as regularization, we leverage gradient trajectories as collected data and apply independent training at the meta-learner. In the meta-update, we maximize GIP while limiting the learned gradient from deviating too far from the empirical risk minimization gradient trajectory. By doing so, the aggregate gradient can incorporate knowledge from all domains without suffering gradient fluctuation towards any particular domain. Experimental evaluations on datasets from DomainBed demonstrate competitive results yielded by POGM against other baselines while achieving computational efficiency.",
      "authors": [
        "Khoi Do",
        "Duong Nguyen",
        "Nam-Khanh Le",
        "Quoc-Viet Pham",
        "Binh-Son Hua",
        "Won-Joo Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.14227v1",
          "size": "279kb",
          "version": "v1"
        }
      ],
      "title": "Domain Generalization via Pareto Optimal Gradient Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14227",
        "HTML": "https://arxiv.org/html/2507.14227",
        "PDF": "https://arxiv.org/pdf/2507.14227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for domain generalization using Pareto Optimal Gradient Matching, which is about gradient-based optimization techniques, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14559",
      "abstract": "The remarkable success of pretrain-then-finetune paradigm has led to a proliferation of available pre-trained models for vision tasks. This surge presents a significant challenge in efficiently choosing the most suitable pre-trained models for downstream tasks. The critical aspect of this challenge lies in effectively predicting the model transferability by considering the underlying fine-tuning dynamics. Existing methods often model fine-tuning dynamics in feature space with linear transformations, which do not precisely align with the fine-tuning objective and fail to grasp the essential nonlinearity from optimization. To this end, we present LEAD, a finetuning-aligned approach based on the network output of logits. LEAD proposes a theoretical framework to model the optimization process and derives an ordinary differential equation (ODE) to depict the nonlinear evolution toward the final logit state. Additionally, we design a class-aware decomposition method to consider the varying evolution dynamics across classes and further ensure practical applicability. Integrating the closely aligned optimization objective and nonlinear modeling capabilities derived from the differential equation, our method offers a concise solution to effectively bridge the optimization gap in a single step, bypassing the lengthy fine-tuning process. The comprehensive experiments on 24 supervised and self-supervised pre-trained models across 10 downstream datasets demonstrate impressive performances and showcase its broad adaptability even in low-data scenarios.",
      "authors": [
        "Zixuan Hu",
        "Xiaotong Li",
        "Shixiang Tang",
        "Jun Liu",
        "Yichun Hu",
        "Ling-Yu Duan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:45:17+00:00",
          "link": "https://arxiv.org/abs/2507.14559v1",
          "size": "3429kb",
          "version": "v1"
        }
      ],
      "title": "LEAD: Exploring Logit Space Evolution for Model Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14559",
        "HTML": "https://arxiv.org/html/2507.14559",
        "PDF": "https://arxiv.org/pdf/2507.14559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on model selection and predicting model transferability by modeling optimization dynamics in the logit space, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14811",
      "abstract": "Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or training data. However, existing PTQ methods for diffusion models often rely on architecture-specific heuristics that limit their generalizability and hinder integration with industrial deployment pipelines. To address these limitations, we propose SegQuant, a unified quantization framework that adaptively combines complementary techniques to enhance cross-model versatility. SegQuant consists of a segment-aware, graph-based quantization strategy (SegLinear) that captures structural semantics and spatial heterogeneity, along with a dual-scale quantization scheme (DualScale) that preserves polarity-asymmetric activations, which is crucial for maintaining visual fidelity in generated outputs. SegQuant is broadly applicable beyond Transformer-based diffusion models, achieving strong performance while ensuring seamless compatibility with mainstream deployment tools.",
      "authors": [
        "Jiaji Zhang",
        "Ruichao Sun",
        "Hailiang Zhao",
        "Jiaju Wu",
        "Peng Chen",
        "Hao Li",
        "Xinkui Zhao",
        "Kingsum Chow",
        "Gang Xiong",
        "Lin Ye",
        "Shuiguang Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:00:53+00:00",
          "link": "https://arxiv.org/abs/2507.14811v1",
          "size": "38338kb",
          "version": "v1"
        }
      ],
      "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14811",
        "HTML": "https://arxiv.org/html/2507.14811",
        "PDF": "https://arxiv.org/pdf/2507.14811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a quantization framework for diffusion models to reduce computational costs, focusing on model efficiency in resource-constrained environments. It does not involve LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14971",
      "abstract": "It is shown that quadrature formulas in many different applications can be derived from rational approximation of the Cauchy transform of a weight function. Since rational approximation is now a routine technology, this provides an easy new method to derive all kinds of quadrature formulas as well as fundamental insight into the mathematics of quadrature. Intervals or curves of quadrature nodes correspond to near-optimal branch cuts of the Cauchy transform.",
      "authors": [
        "Andrew Horning and Lloyd N. Trefethen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T14:03:29+00:00",
          "link": "https://arxiv.org/abs/2507.14971v1",
          "size": "1756kb",
          "version": "v1"
        }
      ],
      "title": "Quadrature formulas from rational approximations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14971",
        "HTML": "https://arxiv.org/html/2507.14971",
        "PDF": "https://arxiv.org/pdf/2507.14971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quadrature formulas derived from rational approximation, which is unrelated to LLM training data processing, as it involves mathematical tools rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15089",
      "abstract": "Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial Vehicle (UAV) navigation, enabling robust localization across diverse environments. Despite significant advancements, aerial vPR faces unique challenges due to the limited availability of large-scale, high-altitude datasets, which limits model generalization, along with the inherent rotational ambiguity in UAV imagery. To address these challenges, we introduce LASED, a large-scale aerial dataset with approximately one million images, systematically sampled from 170,000 unique locations throughout Estonia over a decade, offering extensive geographic and temporal diversity. Its structured design ensures clear place separation significantly enhancing model training for aerial scenarios. Furthermore, we propose the integration of steerable Convolutional Neural Networks (CNNs) to explicitly handle rotational variance, leveraging their inherent rotational equivariance to produce robust, orientation-invariant feature representations. Our extensive benchmarking demonstrates that models trained on LASED achieve significantly higher recall compared to those trained on smaller, less diverse datasets, highlighting the benefits of extensive geographic coverage and temporal diversity. Moreover, steerable CNNs effectively address rotational ambiguity inherent in aerial imagery, consistently outperforming conventional convolutional architectures, achieving on average 12\\% recall improvement over the best-performing non-steerable network. By combining structured, large-scale datasets with rotation-equivariant neural networks, our approach significantly enhances model robustness and generalization for aerial vPR.",
      "authors": [
        "Ioannis Tsampikos Papapetros",
        "Ioannis Kansizoglou",
        "Antonios Gasteratos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:02:15+00:00",
          "link": "https://arxiv.org/abs/2507.15089v1",
          "size": "7857kb",
          "version": "v1"
        }
      ],
      "title": "Visual Place Recognition for Large-Scale UAV Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15089",
        "HTML": "https://arxiv.org/html/2507.15089",
        "PDF": "https://arxiv.org/pdf/2507.15089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work introduces a new dataset for UAV applications focusing on visual place recognition, not LLM training data. Its relevance lies in UAV navigation, not in language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15581",
      "abstract": "Using multiple-choice questions (MCQs) has become a standard for assessing LLM capabilities efficiently. A variety of metrics can be employed for this task. However, previous research has not conducted a thorough assessment of them. At the same time, MCQ evaluation suffers from answer fluctuation: models produce different results given slight changes in prompts. We suggest a metric assessment protocol in which evaluation methodologies are analyzed through their connection with fluctuation rates, as well as original performance. Our results show that there is a strong link between existing metrics and the answer changing, even when computed without any additional prompt variants. A novel metric, worst accuracy, demonstrates the highest association on the protocol.",
      "authors": [
        "Ekaterina Goliakova",
        "Xavier Renard",
        "Marie-Jeanne Lesot",
        "Thibault Laugel",
        "Christophe Marsala",
        "Marcin Detyniecki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:01:46+00:00",
          "link": "https://arxiv.org/abs/2507.15581v1",
          "size": "2550kb",
          "version": "v1"
        }
      ],
      "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15581",
        "PDF": "https://arxiv.org/pdf/2507.15581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the metric assessment protocol in the context of answer fluctuation in MCQs tasks for LLMs but does not focus on training data processing or dataset operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.00061",
      "abstract": "Automated fact-checking is a key strategy to overcome the spread of COVID-19 misinformation on the internet. These systems typically leverage deep learning approaches through Natural Language Inference (NLI) to verify the truthfulness of information based on supporting evidence. However, one challenge that arises in deep learning is performance stagnation due to a lack of knowledge during training. This study proposes using a Knowledge Graph (KG) as external knowledge to enhance NLI performance for automated COVID-19 fact-checking in the Indonesian language. The proposed model architecture comprises three modules: a fact module, an NLI module, and a classifier module. The fact module processes information from the KG, while the NLI module handles semantic relationships between the given premise and hypothesis. The representation vectors from both modules are concatenated and fed into the classifier module to produce the final result. The model was trained using the generated Indonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia. Our study demonstrates that incorporating KGs can significantly improve NLI performance in fact-checking, achieving the best accuracy of 0.8616. This suggests that KGs are a valuable component for enhancing NLI performance in automated fact-checking.",
      "authors": [
        "Arief Purnama Muharram and Ayu Purwarianti"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T14:27:47+00:00",
          "link": "https://arxiv.org/abs/2409.00061v1",
          "size": "762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T15:04:28+00:00",
          "link": "https://arxiv.org/abs/2409.00061v2",
          "size": "803kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00061",
        "PDF": "https://arxiv.org/pdf/2409.00061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing natural language inference for fact-checking by adding a knowledge graph but focuses on improving model performance rather than directly addressing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14403",
      "abstract": "Neural processing units (NPUs) are gaining prominence in power-sensitive devices like client devices, with AI PCs being defined by their inclusion of these specialized processors. Running AI workloads efficiently on these devices requires libraries of optimized kernels. Creating efficient kernels demands expertise in domain-specific C++ with vector intrinsics and in-depth knowledge of the target architecture. Unlike GPU programming, which has had years to mature, NPU programming is new, with smaller and more fragmented developer communities across hardware platforms. This fragmentation poses a challenge when utilizing LLMs to assist in writing NPU kernels, as domain-specific optimized code examples are underrepresented in LLM pre-training data.\n  In this paper we introduce NPUEval -- a benchmark for writing and evaluating NPU kernels, consisting of 102 common operators for machine learning workloads. We evaluate LLM generated code on actual hardware based on both functional correctness and vectorization efficiency using open source compiler tools targeting the AMD NPU. We evaluate a range of state-of-the-art LLMs with a mix of proprietary and open-weight models. Latest reasoning models like DeepSeek R1, show promising results achieving out-of-the-box 50%+ vectorization on select kernels. However, the average score across the entire dataset remains roughly 10% even with compiler feedback and vectorized kernel examples -- showing that this is a challenging dataset even for frontier models. The dataset and evaluation code will be released with a permissive open source license, providing an essential benchmark for advancing research in code generation and NPU kernel optimization.",
      "authors": [
        "Sarunas Kalade and Graham Schelle"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T23:21:52+00:00",
          "link": "https://arxiv.org/abs/2507.14403v1",
          "size": "1809kb",
          "version": "v1"
        }
      ],
      "title": "NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14403",
        "HTML": "https://arxiv.org/html/2507.14403",
        "PDF": "https://arxiv.org/pdf/2507.14403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes NPUEval, a benchmark for NPU kernel optimization using LLMs, focusing on code generation and evaluation. Though dataset creation is mentioned, it relates to benchmarking rather than direct contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14601",
      "abstract": "The implementation of simple, inexpensive, and mass-production-oriented solutions for smart electromagnetic environments (SEMEs) is dealt with by introducing the concept of \"one-time programmable\" electromagnetic skins (OTP-EMSs). The simultaneous achievement of modular fabrication, (one-time) configurable reflection properties, passive-static operation, and zero maintenance is yielded by integrating expendable components at the atomic level of EMSs. Towards this end, an OTP meta-atom structure is properly defined and optimized to build EMSs featuring the desired scenario-dependent EM wave manipulation functionalities. In order to illustrate the features as well as to point out the potentialities of OTP-EMSs, a representative set of analytical, numerical, and experimental results is reported by considering different apertures, illuminations, and EM wave manipulation requirements.",
      "authors": [
        "Giacomo Oliveri",
        "Francesco Zardi",
        "Aaron Angel Salas Sancez",
        "Andrea Massa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:54:12+00:00",
          "link": "https://arxiv.org/abs/2507.14601v1",
          "size": "5425kb",
          "version": "v1"
        }
      ],
      "title": "One-Time Programmable Passive Electromagnetic Skins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14601",
        "HTML": "https://arxiv.org/html/2507.14601",
        "PDF": "https://arxiv.org/pdf/2507.14601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the implementation of one-time programmable electromagnetic skins for smart environments and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14744",
      "abstract": "Automated machine learning systems efficiently streamline model selection but often focus on a single best-performing model, overlooking explanation uncertainty, an essential concern in human centered explainable AI. To address this, we propose a novel framework that incorporates model multiplicity into explanation generation by aggregating partial dependence profiles (PDP) from a set of near optimal models, known as the Rashomon set. The resulting Rashomon PDP captures interpretive variability and highlights areas of disagreement, providing users with a richer, uncertainty aware view of feature effects. To evaluate its usefulness, we introduce two quantitative metrics, the coverage rate and the mean width of confidence intervals, to evaluate the consistency between the standard PDP and the proposed Rashomon PDP. Experiments on 35 regression datasets from the OpenML CTR23 benchmark suite show that in most cases, the Rashomon PDP covers less than 70% of the best model's PDP, underscoring the limitations of single model explanations. Our findings suggest that Rashomon PDP improves the reliability and trustworthiness of model interpretations by adding additional information that would otherwise be neglected. This is particularly useful in high stakes domains where transparency and confidence are critical.",
      "authors": [
        "Mustafa Cavus",
        "Jan N. van Rijn",
        "Przemys{\\l}aw Biecek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T20:30:52+00:00",
          "link": "https://arxiv.org/abs/2507.14744v1",
          "size": "577kb",
          "version": "v1"
        }
      ],
      "title": "Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14744",
        "HTML": "https://arxiv.org/html/2507.14744",
        "PDF": "https://arxiv.org/pdf/2507.14744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for explanation generation in AutoML, focusing on modeling and interpretability rather than on LLM training data processing tasks such as dataset creation or filtering improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15434",
      "abstract": "We are concerned with the problem of scheduling $n$ jobs onto $m$ identical machines. Each machine has to be in operation for a prescribed time, and the objective is to minimize the total machine working time. Precisely, let $c_i$ be the prescribed time for machine $i$, where $i\\in[m]$, and $p_j$ be the processing time for job $j$, where $j\\in[n]$. The problem asks for a schedule $\\sigma\\colon\\, J\\to M$ such that $\\sum_{i=1}^m\\max\\{c_i, \\sum_{j\\in\\sigma^{-1}(i)}p_j\\}$ is minimized, where $J$ and $M$ denote the sets of jobs and machines, respectively. We show that First Fit Decreasing (FFD) leads to a $1.5$-approximation, and this problem admits a polynomial-time approximation scheme (PTAS). The idea is further applied to mixed-criticality system scheduling to yield improved approximation results.",
      "authors": [
        "Yi-Ting Hsieh",
        "Mong-Jen Kao",
        "Jhong-Yun Liu",
        "Hung-Lung Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:45:05+00:00",
          "link": "https://arxiv.org/abs/2507.15434v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Job Scheduling under Base and Additional Fees, with Applications to Mixed-Criticality Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15434",
        "HTML": "https://arxiv.org/html/2507.15434",
        "PDF": "https://arxiv.org/pdf/2507.15434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on job scheduling problems and their applications in mixed-criticality systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15652",
      "abstract": "Multimodal Large Language Models (MLLMs) have made significant strides by combining visual recognition and language understanding to generate content that is both coherent and contextually accurate. However, MLLMs continue to struggle with object hallucinations, where models produce seemingly plausible but factually incorrect outputs, including objects that do not exist in the image. Recent work has revealed that the prior knowledge in MLLMs significantly suppresses visual information in deep layers, causing hallucinatory outputs. However, how these priors suppress visual information at the intermediate layer stage in MLLMs remains unclear. We observe that visual factual knowledge and the differences between intermediate-layer prior/original probability distributions show similar evolutionary trends in intermediate layers. Motivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a simple, training-free method that dynamically selects intermediate layers with the most significant visual factual information. By contrasting the output distributions of the selected layer derived from the original input and pure-text input, EVA extracts visual factual knowledge and proportionally incorporates it into the final layer to correct the output logits. Importantly, EVA is model-agnostic, seamlessly integrates with various classic decoding strategies, and is applicable across different MLLMs. We validate EVA on widely-used benchmarks, and the results show that it significantly reduces hallucination rates compared to baseline methods, underscoring its effectiveness in mitigating hallucinations.",
      "authors": [
        "Haoran Zhou",
        "Zihan Zhang",
        "Hao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:15:34+00:00",
          "link": "https://arxiv.org/abs/2507.15652v1",
          "size": "1781kb",
          "version": "v1"
        }
      ],
      "title": "Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15652",
        "HTML": "https://arxiv.org/html/2507.15652",
        "PDF": "https://arxiv.org/pdf/2507.15652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses the issue of hallucinations in multimodal LLMs using a method that selects layers with significant visual information. While it relates to improving the output of LLMs, its focus is not on training data processing but on inference techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12202",
      "abstract": "Many current state-of-the-art models for sequential recommendations are based on transformer architectures. Interpretation and explanation of such black box models is an important research question, as a better understanding of their internals can help understand, influence, and control their behavior, which is very important in a variety of real-world applications. Recently sparse autoencoders (SAE) have been shown to be a promising unsupervised approach for extracting interpretable features from language models. These autoencoders learn to reconstruct hidden states of the transformer's internal layers from sparse linear combinations of directions in their activation space.\n  This paper is focused on the application of SAE to the sequential recommendation domain. We show that this approach can be successfully applied to the transformer trained on a sequential recommendation task: learned directions turn out to be more interpretable and monosemantic than the original hidden state dimensions. Moreover, we demonstrate that the features learned by SAE can be used to effectively and flexibly control the model's behavior, providing end-users with a straightforward method to adjust their recommendations to different custom scenarios and contexts.",
      "authors": [
        "Anton Klenitskiy",
        "Konstantin Polev",
        "Daria Denisova",
        "Alexey Vasilev",
        "Dmitry Simakov",
        "Gleb Gusev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:57:43+00:00",
          "link": "https://arxiv.org/abs/2507.12202v1",
          "size": "3020kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12202",
        "HTML": "https://arxiv.org/html/2507.12202",
        "PDF": "https://arxiv.org/pdf/2507.12202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using sparse autoencoders for interpretability in sequential recommendation models and does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14321",
      "abstract": "We consider the Cops and Robbers game played on finite simple graphs. In a graph $G$, the number of cops required to capture a robber in the Cops and Robbers game is denoted by $c(G)$. For all graphs $G$, $c(G) \\leq \\alpha(G) \\leq \\theta(G)$ where $\\alpha(G)$ and $\\theta(G)$ are the independence number and clique cover number respectively. In 2022 Turcotte asked if $c(G) < \\alpha(G)$ for all graphs with $\\alpha(G) \\geq 3$. Recently, Char, Maniya, and Pradhan proved this is false, at least when $\\alpha = 3$,by demonstrating the compliment of the Shrikhande graph has cop number and independence number $3$. We prove, using random graphs, the stronger result that for all $k\\geq 1$ there exists a graph $G$ such that $c(G) = \\alpha(G) = \\theta(G) = k$. Next, we consider the structure of graphs with $c(G) = \\theta(G) \\geq 3$. We prove, using structural arguments, that any graphs $G$ which satisfies $c(G) = \\theta(G) = k \\geq 3$ contain induced cycles of all lengths $3\\leq t \\leq k+1$. This implies all perfect graphs $G$ with $\\alpha(G)\\geq 4$ have $c(G) < \\alpha(G)$. Additionally,we discuss if typical triangle-free and $C_4$-free graphs will have $c(G) < \\alpha(G)$.",
      "authors": [
        "Alexander Clow and Imed Zaguia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:50:02+00:00",
          "link": "https://arxiv.org/abs/2507.14321v1",
          "size": "20kb",
          "version": "v1"
        }
      ],
      "title": "Cops and Robbers, Clique Covers, and Induced Cycles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14321",
        "HTML": "https://arxiv.org/html/2507.14321",
        "PDF": "https://arxiv.org/pdf/2507.14321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Cops and Robbers game and graph theory, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14655",
      "abstract": "In this article we propose an extension to the typed natural deduction calculus TNDPQ to model verification of counterfactual fairness in probabilistic classifiers. This is obtained formulating specific structural conditions for causal labels and checking that evaluation is robust under their variation.",
      "authors": [
        "Leonardo Ceragioli and Giuseppe Primiero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:05:40+00:00",
          "link": "https://arxiv.org/abs/2507.14655v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "A Proof System with Causal Labels (Part II): checking Counterfactual Fairness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14655",
        "HTML": "https://arxiv.org/html/2507.14655",
        "PDF": "https://arxiv.org/pdf/2507.14655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a proof system for counterfactual fairness in probabilistic classifiers, an area unrelated to LLM training data processing or dataset preparation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15409",
      "abstract": "Partial differential equations (PDEs) play a central role in describing many physical phenomena. Various scientific and engineering applications demand a versatile and differentiable PDE solver that can quickly generate solutions with adequate accuracy, and limitations of the traditional solvers and specialized neural operators motivate the development of foundation models for solving PDEs. This paper introduces PDEformer-2, a versatile foundation model for two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1 model, PDEformer-2 receives the PDE form as network input via computational graph representation, which has the flexibility to encode most common PDEs. The mesh-free predicted solutions can be directly queried at arbitrary spatio-temporal coordinates. A large (40TB) diverse dataset is employed to pretrain the current model, making it capable of simultaneously addressing PDEs with different symbolic forms, domain shapes, boundary conditions, number of variables, and time-dependency. Accurate zero-shot prediction is allowed for PDEs that resemble the pretraining ones. When adapted to new unseen PDEs, PDEformer-2 demonstrates faster learning than many specialized models, and has smaller errors given limited (less than 100) samples. Additionally, PDEformer-2 can be employed in the inverse problems thanks to its fast and differentiable nature and produces reasonable results in our experiments to recover coefficient scalars and fields of a PDE.",
      "authors": [
        "Zhanhong Ye",
        "Zining Liu",
        "Bingyang Wu",
        "Hongjie Jiang",
        "Leheng Chen",
        "Minyan Zhang",
        "Xiang Huang",
        "Qinghe Meng. Jingyuan Zou",
        "Hongsheng Liu",
        "Bin Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:08:48+00:00",
          "link": "https://arxiv.org/abs/2507.15409v1",
          "size": "28432kb",
          "version": "v1"
        }
      ],
      "title": "PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15409",
        "HTML": "https://arxiv.org/html/2507.15409",
        "PDF": "https://arxiv.org/pdf/2507.15409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper details a foundation model for solving PDEs and discusses its application and training, focusing solely on PDEs and unrelated to language model data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15542",
      "abstract": "Zero-shot human-object interaction (HOI) detection remains a challenging task, particularly in generalizing to unseen actions. Existing methods address this challenge by tapping Vision-Language Models (VLMs) to access knowledge beyond the training data. However, they either struggle to distinguish actions involving the same object or demonstrate limited generalization to unseen classes. In this paper, we introduce HOLa (Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation), a novel approach that both enhances generalization to unseen classes and improves action distinction. In training, HOLa decomposes VLM text features for given HOI classes via low-rank factorization, producing class-shared basis features and adaptable weights. These features and weights form a compact HOI representation that preserves shared information across classes, enhancing generalization to unseen classes. Subsequently, we refine action distinction by adapting weights for each HOI class and introducing human-object tokens to enrich visual interaction representations. To further distinguish unseen actions, we guide the weight adaptation with LLM-derived action regularization. Experimental results show that our method sets a new state-of-the-art across zero-shot HOI settings on HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting. Our code is available at https://github.com/ChelsieLei/HOLa.",
      "authors": [
        "Qinqian Lei",
        "Bo Wang",
        "Robby T. Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:15:27+00:00",
          "link": "https://arxiv.org/abs/2507.15542v1",
          "size": "4614kb",
          "version": "v1"
        }
      ],
      "title": "HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15542",
        "HTML": "https://arxiv.org/html/2507.15542",
        "PDF": "https://arxiv.org/pdf/2507.15542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses zero-shot human-object interaction detection using vision-language models and does not discuss training data processing for large language models or dataset creation with relevance to LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15770",
      "abstract": "With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments validate EAMI in complex online-to-offline (O2O) service system and the Stanford AI Town experiment, with ablation studies confirming its effectiveness, generalizability, and efficiency. This framework provides a novel paradigm for abnormal emergence and causal analysis in service ecosystems. The code is available at https://anonymous.4open.science/r/EAMI-B085.",
      "authors": [
        "Yifan Shen",
        "Zihan Zhao",
        "Xiao Xue",
        "Yuwei Guo",
        "Qun Ma",
        "Deyu Zhou",
        "Ming Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.15770v1",
          "size": "3159kb",
          "version": "v1"
        }
      ],
      "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15770",
        "HTML": "https://arxiv.org/html/2507.15770",
        "PDF": "https://arxiv.org/pdf/2507.15770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for analyzing abnormal emergence in service ecosystems using LLMs for intention mining but does not address any aspect of LLM training data processing such as data collection, generation, or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04020",
      "abstract": "Understanding the spatial dynamics of cars within urban systems is essential for optimizing infrastructure management and resource allocation. Recent empirical approaches for analyzing traffic patterns have gained traction due to their applicability to city-scale policy development. However, conventional methodologies often rely on fragmented grid-based techniques, which may overlook critical interdependencies among spatial elements and temporal continuity. These limitations can compromise analytical effectiveness in complex urban environments. To address these challenges, we propose PriorMotion, a data integration framework designed to systematically uncover movement patterns through driving dynamics analysis. Our approach combines multi-scale empirical observations with customized analytical tools to capture evolving spatial-temporal trends in urban traffic. Comprehensive evaluations demonstrate that PriorMotion significantly enhances analytical outcomes, including increased accuracy in traffic pattern analysis, improved adaptability to heterogeneous data environments, and reduced long-term projection errors. Validation confirms its effectiveness for urban infrastructure management applications requiring precise characterization of complex spatial-temporal interactions.",
      "authors": [
        "Kangan Qian and Jinyu Miao and Xinyu Jiao and Ziang Luo and Zheng Fu and Yining Shi and Yunlong Wang and Kun Jiang and Diange Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Performance (cs.PF)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T09:56:24+00:00",
          "link": "https://arxiv.org/abs/2412.04020v1",
          "size": "2872kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T13:44:04+00:00",
          "link": "https://arxiv.org/abs/2412.04020v2",
          "size": "14253kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T06:21:15+00:00",
          "link": "https://arxiv.org/abs/2412.04020v3",
          "size": "2562kb",
          "version": "v3"
        }
      ],
      "title": "How Cars Move: Analyzing Driving Dynamics for Safer Urban Traffic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04020",
        "HTML": "https://arxiv.org/html/2412.04020",
        "PDF": "https://arxiv.org/pdf/2412.04020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a data integration framework for analyzing urban traffic dynamics, which is unrelated to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Autonomous Navigation",
        "motion prediction",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08947",
      "abstract": "We present the first systematic approach to static and dynamic taint analysis for Graph APIs focusing on broken access control. The approach comprises the following. We taint nodes in the Graph API if they represent data requiring specific privileges in order to be retrieved or manipulated, and identify API calls which are related to sources and sinks. Then, we statically analyze whether tainted information flow between API source and sink calls occurs. To this end, we model the API calls using graph transformation rules. We subsequently use critical pair analysis to automatically analyze potential dependencies between rules representing source calls and rules representing sink calls. We distinguish direct from indirect tainted information flow and argue under which conditions the CPA is able to detect not only direct, but also indirect tainted flow. The static taint analysis (i) identifies flows that need to be further reviewed, since tainted nodes may be created by an API call and used or manipulated by another API call later without having the necessary privileges, and (ii) can be used to systematically design dynamic security tests for broken access control. The dynamic taint analysis checks if potential broken access control risks detected during the static taint analysis really occur. We apply the approach to a part of the GitHub GraphQL API. The application illustrates that our analysis supports the detection of two types of broken access control systematically: the case where users of the API may not be able to access or manipulate information, although they should be able to do so; and the case where users (or attackers) of the API may be able to access/manipulate information that they should not.",
      "authors": [
        "Leen Lambers",
        "Lucas Sakizloglou",
        "Taisiya Khakharova",
        "Fernando Orejas"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Logic in Computer Science (cs.LO)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T16:49:32+00:00",
          "link": "https://arxiv.org/abs/2501.08947v1",
          "size": "1653kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T16:01:09+00:00",
          "link": "https://arxiv.org/abs/2501.08947v2",
          "size": "1764kb",
          "version": "v2"
        }
      ],
      "title": "Taint Analysis for Graph APIs Focusing on Broken Access Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08947",
        "HTML": "https://arxiv.org/html/2501.08947",
        "PDF": "https://arxiv.org/pdf/2501.08947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses static and dynamic taint analysis for Graph APIs, focusing on access control issues, and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10638",
      "abstract": "Classifier-free guidance has become a staple for conditional generation with denoising diffusion models. However, a comprehensive understanding of classifier-free guidance is still missing. In this work, we carry out an empirical study to provide a fresh perspective on classifier-free guidance. Concretely, instead of solely focusing on classifier-free guidance, we trace back to the root, i.e., classifier guidance, pinpoint the key assumption for the derivation, and conduct a systematic study to understand the role of the classifier. We find that both classifier guidance and classifier-free guidance achieve conditional generation by pushing the denoising diffusion trajectories away from decision boundaries, i.e., areas where conditional information is usually entangled and is hard to learn. Based on this classifier-centric understanding, we propose a generic postprocessing step built upon flow-matching to shrink the gap between the learned distribution for a pre-trained denoising diffusion model and the real data distribution, majorly around the decision boundaries. Experiments on various datasets verify the effectiveness of the proposed approach.",
      "authors": [
        "Xiaoming Zhao",
        "Alexander G. Schwing"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2503.10638v1",
          "size": "34217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T23:15:53+00:00",
          "link": "https://arxiv.org/abs/2503.10638v2",
          "size": "71988kb",
          "version": "v2"
        }
      ],
      "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10638",
        "HTML": "https://arxiv.org/html/2503.10638",
        "PDF": "https://arxiv.org/pdf/2503.10638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on classifier guidance and classifier-free guidance in denoising diffusion models, primarily exploring conditional generation rather than training data processing for LLMs."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.19037",
      "abstract": "Masked diffusion language models (MDLMs) promise fast, non-autoregressive text generation, yet existing samplers, which pick tokens to unmask based on model confidence, ignore interactions when unmasking multiple positions in parallel and effectively reduce to slow, autoregressive behavior. We propose the Dilated Unmasking Scheduler (DUS), an inference-only, planner-model-free method that partitions sequence positions into non-adjacent dilated groups and unmasked them in parallel so as to minimize an upper bound on joint entropy gain at each denoising step. By explicitly trading off the number of network calls against generation quality, DUS recovers most of the performance lost under traditional parallel unmasking strategies. Across math (GSM8K, MATH500), code (HumanEval, MBPP) and general-knowledge benchmarks (BBH, MMLU-Pro), DUS outperforms confidence-based planners, without modifying the underlying denoiser, and reveals the true speed-quality frontier of MDLMs.",
      "authors": [
        "Omer Luxembourg",
        "Haim Permuter",
        "Eliya Nachmani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:49:23+00:00",
          "link": "https://arxiv.org/abs/2506.19037v1",
          "size": "556kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T19:07:54+00:00",
          "link": "https://arxiv.org/abs/2506.19037v2",
          "size": "1134kb",
          "version": "v2"
        }
      ],
      "title": "Plan for Speed: Dilated Scheduling for Masked Diffusion Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19037",
        "HTML": "https://arxiv.org/html/2506.19037",
        "PDF": "https://arxiv.org/pdf/2506.19037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving the speed and quality of text generation using masked diffusion language models by proposing a new scheduling method. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12465",
      "abstract": "3D modeling is moving from virtual to physical. Existing 3D generation primarily emphasizes geometries and textures while neglecting physical-grounded modeling. Consequently, despite the rapid development of 3D generative models, the synthesized 3D assets often overlook rich and important physical properties, hampering their real-world application in physical domains like simulation and embodied AI. As an initial attempt to address this challenge, we propose \\textbf{PhysX-3D}, an end-to-end paradigm for physical-grounded 3D asset generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we present PhysXNet - the first physics-grounded 3D dataset systematically annotated across five foundational dimensions: absolute scale, material, affordance, kinematics, and function description. In particular, we devise a scalable human-in-the-loop annotation pipeline based on vision-language models, which enables efficient creation of physics-first assets from raw 3D assets.2) Furthermore, we propose \\textbf{PhysXGen}, a feed-forward framework for physics-grounded image-to-3D asset generation, injecting physical knowledge into the pre-trained 3D structural space. Specifically, PhysXGen employs a dual-branch architecture to explicitly model the latent correlations between 3D structures and physical properties, thereby producing 3D assets with plausible physical predictions while preserving the native geometry quality. Extensive experiments validate the superior performance and promising generalization capability of our framework. All the code, data, and models will be released to facilitate future research in generative physical AI.",
      "authors": [
        "Ziang Cao",
        "Zhaoxi Chen",
        "Liang Pan",
        "Ziwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.12465v1",
          "size": "3895kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:11:34+00:00",
          "link": "https://arxiv.org/abs/2507.12465v2",
          "size": "3895kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T07:57:36+00:00",
          "link": "https://arxiv.org/abs/2507.12465v3",
          "size": "3895kb",
          "version": "v3"
        }
      ],
      "title": "PhysX-3D: Physical-Grounded 3D Asset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12465",
        "HTML": "https://arxiv.org/html/2507.12465",
        "PDF": "https://arxiv.org/pdf/2507.12465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces PhysX-3D for 3D asset generation with a focus on physical properties. It involves a new dataset for physics-grounded 3D data but is not relevant to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "Caoza/PhysX-3D",
          "downloads": "2052",
          "likes": "11",
          "link": "https://huggingface.co/datasets/Caoza/PhysX-3D"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14183",
      "abstract": "In mid-2025, Iran experienced a novel, stealthy Internet shutdown that preserved global routing presence while isolating domestic users through deep packet inspection, aggressive throttling, and selective protocol blocking. This paper analyzes active network measurements such as DNS poisoning, HTTP injection, TLS interception, and protocol whitelisting, traced to a centralized border gateway. We quantify an approximate 707 percent rise in VPN demand and describe the multi-layered censorship infrastructure, highlighting implications for circumvention and digital rights monitoring.",
      "authors": [
        "Arash Aryapour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T16:30:07+00:00",
          "link": "https://arxiv.org/abs/2507.14183v1",
          "size": "111kb",
          "version": "v1"
        }
      ],
      "title": "Iran's Stealth Internet Blackout: A New Model of Censorship",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14183",
        "HTML": "https://arxiv.org/html/2507.14183",
        "PDF": "https://arxiv.org/pdf/2507.14183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes Internet censorship in Iran and does not pertain to any aspect of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15085",
      "abstract": "Text image is a unique and crucial information medium that integrates visual aesthetics and linguistic semantics in modern e-society. Due to their subtlety and complexity, the generation of text images represents a challenging and evolving frontier in the image generation field. The recent surge of specialized image generators (\\emph{e.g.}, Flux-series) and unified generative models (\\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a natural question: can they master the intricacies of text image generation and editing? Motivated by this, we assess current state-of-the-art generative models' capabilities in terms of text image generation and editing. We incorporate various typical optical character recognition (OCR) tasks into our evaluation and broaden the concept of text-based generation tasks into OCR generative tasks. We select 33 representative tasks and categorize them into five categories: document, handwritten text, scene text, artistic text, and complex \\& layout-rich text. For comprehensive evaluation, we examine six models across both closed-source and open-source domains, using tailored, high-quality image inputs and prompts. Through this evaluation, we draw crucial observations and identify the weaknesses of current generative models for OCR tasks. We argue that photorealistic text image generation and editing should be internalized as foundational skills into general-domain generative models, rather than being delegated to specialized solutions, and we hope this empirical analysis can provide valuable insights for the community to achieve this goal. This evaluation is online and will be continuously updated at our GitHub repository.",
      "authors": [
        "Peirong Zhang",
        "Haowei Xu",
        "Jiaxin Zhang",
        "Guitao Xu",
        "Xuhan Zheng",
        "Zhenhua Yang",
        "Junle Liu",
        "Yuyi Zhang",
        "Lianwen Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:43:09+00:00",
          "link": "https://arxiv.org/abs/2507.15085v1",
          "size": "36829kb",
          "version": "v1"
        }
      ],
      "title": "Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15085",
        "HTML": "https://arxiv.org/html/2507.15085",
        "PDF": "https://arxiv.org/pdf/2507.15085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the evaluation of generative models for text image generation and editing tasks, specifically related to OCR and photorealistic text imagery, without addressing LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15162",
      "abstract": "Machine learning-based decision models are increasingly being used to make decisions that significantly impact people's lives, but their opaque nature leaves end users without a clear understanding of why a decision was made. Counterfactual Explanations (CFEs) have grown in popularity as a means of offering actionable guidance by identifying the minimum changes in feature values required to flip a model's prediction to something more desirable. Unfortunately, most prior research in CFEs relies on artificial evaluation metrics, such as proximity, which may overlook end-user preferences and constraints, e.g., the user's perception of effort needed to make certain feature changes may differ from that of the model designer. To address this research gap, this paper makes three novel contributions. First, we conduct a pilot study with 20 crowd-workers on Amazon MTurk to experimentally validate the alignment of existing CF evaluation metrics with real-world user preferences. Results show that user-preferred CFEs matched those based on proximity in only 63.81% of cases, highlighting the limited applicability of these metrics in real-world settings. Second, inspired by the need to design a user-informed evaluation metric for CFEs, we conduct a more detailed two-day user study with 41 participants facing realistic credit application scenarios to find experimental support for or against three intuitive hypotheses that may explain how end users evaluate CFEs. Third, based on the findings of this second study, we propose the AWP model, a novel user-centric, two-stage model that describes one possible mechanism by which users evaluate and select CFEs. Our results show that AWP predicts user-preferred CFEs with 84.37% accuracy. Our study provides the first human-centered validation for personalized cost models in CFE generation and highlights the need for adaptive, user-centered evaluation metrics.",
      "authors": [
        "Firdaus Ahmed Choudhury",
        "Ethan Leicht",
        "Jude Ethan Bislig",
        "Hangzhi Guo",
        "Amulya Yadav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:58:29+00:00",
          "link": "https://arxiv.org/abs/2507.15162v1",
          "size": "2677kb",
          "version": "v1"
        }
      ],
      "title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15162",
        "HTML": "https://arxiv.org/html/2507.15162",
        "PDF": "https://arxiv.org/pdf/2507.15162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines counterfactual explanations and user-centric evaluation metrics in decision models, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15198",
      "abstract": "This paper addresses the challenges of high computational cost and slow inference in deploying large language models. It proposes a distillation strategy guided by multiple teacher models. The method constructs several teacher models and integrates their output probability distributions and intermediate semantic features. This guides the student model to learn from multiple sources of knowledge. As a result, the student model gains stronger language understanding and generation ability while maintaining a small parameter size. To achieve this, the paper introduces a weighted output fusion mechanism, a feature alignment loss function, and an entropy-driven dynamic teacher weighting strategy. These components improve the quality and stability of knowledge transfer during distillation. Under multi-teacher guidance, the student model captures semantic information more effectively and demonstrates strong performance across multiple evaluation metrics. In particular, the method shows high consistency in expression, generalization ability, and task adaptability in tasks such as language modeling, text generation, and multi-task learning. The experiments compare the proposed method with several widely adopted distillation approaches. The results further confirm its overall advantages in perplexity, distillation loss, and generation quality. This study provides a feasible technical path for the efficient compression of large-scale language models. It also demonstrates the effectiveness of multi-teacher collaborative mechanisms in complex language modeling tasks.",
      "authors": [
        "Xiandong Meng",
        "Yan Wu",
        "Yexin Tian",
        "Xin Hu",
        "Tianze Kang",
        "Junliang Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:55:33+00:00",
          "link": "https://arxiv.org/abs/2507.15198v1",
          "size": "844kb",
          "version": "v1"
        }
      ],
      "title": "Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15198",
        "PDF": "https://arxiv.org/pdf/2507.15198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a distillation strategy for language model deployment, focusing on computational cost and multi-teacher models. It does not deal with training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15603",
      "abstract": "Spiking Neural Networks (SNNs) are increasingly favored for deployment on resource-constrained edge devices due to their energy-efficient and event-driven processing capabilities. However, training SNNs remains challenging because of the computational intensity of traditional backpropagation algorithms adapted for spike-based systems. In this paper, we propose a novel software-hardware co-design that introduces a hardware-friendly training algorithm, Spiking Direct Feedback Alignment (SDFA) and implement it on a Resistive Random Access Memory (RRAM)-based In-Memory Computing (IMC) architecture, referred to as PipeSDFA, to accelerate SNN training. Software-wise, the computational complexity of SNN training is reduced by the SDFA through the elimination of sequential error propagation. Hardware-wise, a three-level pipelined dataflow is designed based on IMC architecture to parallelize the training process. Experimental results demonstrate that the PipeSDFA training accelerator incurs less than 2% accuracy loss on five datasets compared to baselines, while achieving 1.1X~10.5X and 1.37X~2.1X reductions in training time and energy consumption, respectively compared to PipeLayer.",
      "authors": [
        "Haoxiong Ren",
        "Yangu He",
        "Kwunhang Wong",
        "Rui Bao",
        "Ning Lin",
        "Zhongrui Wang",
        "Dashan Shang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:26:02+00:00",
          "link": "https://arxiv.org/abs/2507.15603v1",
          "size": "4772kb",
          "version": "v1"
        }
      ],
      "title": "When Pipelined In-Memory Accelerators Meet Spiking Direct Feedback Alignment: A Co-Design for Neuromorphic Edge Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15603",
        "HTML": "https://arxiv.org/html/2507.15603",
        "PDF": "https://arxiv.org/pdf/2507.15603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on a hardware-software co-design for accelerating Spiking Neural Networks (SNNs) on edge devices, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.00758",
      "abstract": "Although recent generative image compression methods have demonstrated impressive potential in optimizing the rate-distortion-perception trade-off, they still face the critical challenge of flexible rate adaption to diverse compression necessities and scenarios. To overcome this challenge, this paper proposes a Controllable Generative Image Compression framework, termed Control-GIC, the first capable of fine-grained bitrate adaption across a broad spectrum while ensuring high-fidelity and generality compression. Control-GIC is grounded in a VQGAN framework that encodes an image as a sequence of variable-length codes (i.e. VQ-indices), which can be losslessly compressed and exhibits a direct positive correlation with the bitrates. Drawing inspiration from the classical coding principle, we correlate the information density of local image patches with their granular representations. Hence, we can flexibly determine a proper allocation of granularity for the patches to achieve dynamic adjustment for VQ-indices, resulting in desirable compression rates. We further develop a probabilistic conditional decoder capable of retrieving historic encoded multi-granularity representations according to transmitted codes, and then reconstruct hierarchical granular features in the formalization of conditional probability, enabling more informative aggregation to improve reconstruction realism. Our experiments show that Control-GIC allows highly flexible and controllable bitrate adaption where the results demonstrate its superior performance over recent state-of-the-art methods. Code is available at https://github.com/lianqi1008/Control-GIC.",
      "authors": [
        "Anqi Li",
        "Feng Li",
        "Yuxi Liu",
        "Runmin Cong",
        "Yao Zhao",
        "Huihui Bai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-02T14:22:09+00:00",
          "link": "https://arxiv.org/abs/2406.00758v1",
          "size": "2643kb",
          "version": "v1"
        },
        {
          "date": "2024-06-05T17:05:55+00:00",
          "link": "https://arxiv.org/abs/2406.00758v2",
          "size": "2643kb",
          "version": "v2"
        },
        {
          "date": "2024-12-04T09:36:56+00:00",
          "link": "https://arxiv.org/abs/2406.00758v3",
          "size": "45083kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T07:25:30+00:00",
          "link": "https://arxiv.org/abs/2406.00758v4",
          "size": "33178kb",
          "version": "v4"
        }
      ],
      "title": "Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00758",
        "PDF": "https://arxiv.org/pdf/2406.00758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on generative image compression techniques and not on LLM training data processing. It deals with improving compression methods rather than data collection or quality improvement for language models."
      },
      "tasks": [
        "All",
        "Image Compression"
      ],
      "repo_urls": [
        "https://github.com/lianqi1008/Control-GIC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06944",
      "abstract": "Neural dependency parsing has achieved remarkable performance for low resource morphologically rich languages. It has also been well-studied that morphologically rich languages exhibit relatively free word order. This prompts a fundamental investigation: Is there a way to enhance dependency parsing performance, making the model robust to word order variations utilizing the relatively free word order nature of morphologically rich languages? In this work, we examine the robustness of graph-based parsing architectures on 7 relatively free word order languages. We focus on scrutinizing essential modifications such as data augmentation and the removal of position encoding required to adapt these architectures accordingly. To this end, we propose a contrastive self-supervised learning method to make the model robust to word order variations. Furthermore, our proposed modification demonstrates a substantial average gain of 3.03/2.95 points in 7 relatively free word order languages, as measured by the UAS/LAS Score metric when compared to the best performing baseline.",
      "authors": [
        "Pretam Ray",
        "Jivnesh Sandhan",
        "Amrith Krishna",
        "Pawan Goyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T14:38:49+00:00",
          "link": "https://arxiv.org/abs/2410.06944v1",
          "size": "8367kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T13:43:51+00:00",
          "link": "https://arxiv.org/abs/2410.06944v2",
          "size": "8348kb",
          "version": "v2"
        }
      ],
      "title": "CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06944",
        "HTML": "https://arxiv.org/html/2410.06944",
        "PDF": "https://arxiv.org/pdf/2410.06944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing dependency parsing for morphologically rich languages using contrastive self-supervised learning. It does not address LLM training data processing or make any contributions related to training data operations for LLMs."
      },
      "tasks": [
        "Data Augmentation",
        "Dependency Parsing",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14177",
      "abstract": "This paper aims to understand the training solution, which is obtained by the back-propagation algorithm, of two-layer neural networks whose hidden layer is composed of the units with smooth activation functions, including the usual sigmoid type most commonly used before the advent of ReLUs. The mechanism contains four main principles: construction of Taylor series expansions, strict partial order of knots, smooth-spline implementation and smooth-continuity restriction. The universal approximation for arbitrary input dimensionality is proved and experimental verification is given, through which the mystery of ``black box'' of the solution space is largely revealed. The new proofs employed also enrich approximation theory.",
      "authors": [
        "Changcun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T01:55:07+00:00",
          "link": "https://arxiv.org/abs/2507.14177v1",
          "size": "156kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14177",
        "HTML": "https://arxiv.org/html/2507.14177",
        "PDF": "https://arxiv.org/pdf/2507.14177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores the training solutions for two-layer neural networks with smooth activation functions, focusing on approximation theory and not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14719",
      "abstract": "As large language models (LLMs) become increasingly integrated into real-world applications, scalable and rigorous safety evaluation is essential. This paper introduces Aymara AI, a programmatic platform for generating and administering customized, policy-grounded safety evaluations. Aymara AI transforms natural-language safety policies into adversarial prompts and scores model responses using an AI-based rater validated against human judgments. We demonstrate its capabilities through the Aymara LLM Risk and Responsibility Matrix, which evaluates 20 commercially available LLMs across 10 real-world safety domains. Results reveal wide performance disparities, with mean safety scores ranging from 86.2% to 52.4%. While models performed well in well-established safety domains such as Misinformation (mean = 95.7%), they consistently failed in more complex or underspecified domains, notably Privacy & Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety scores differed significantly across both models and domains (p < .05). These findings underscore the inconsistent and context-dependent nature of LLM safety and highlight the need for scalable, customizable tools like Aymara AI to support responsible AI development and oversight.",
      "authors": [
        "Juan Manuel Contreras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:49:16+00:00",
          "link": "https://arxiv.org/abs/2507.14719v1",
          "size": "1020kb",
          "version": "v1"
        }
      ],
      "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14719",
        "HTML": "https://arxiv.org/html/2507.14719",
        "PDF": "https://arxiv.org/pdf/2507.14719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on safety evaluations of LLMs, using a platform to assess model performance across various safety domains. It does not address training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14912",
      "abstract": "The global ageing population necessitates new and emerging strategies for caring for older adults. In this article, we explore the potential for transformation in elderly care through Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs). We discuss the proactive and autonomous decision-making facilitated by Agentic AI in elderly care. Personalized tracking of health, cognitive care, and environmental management, all aimed at enhancing independence and high-level living for older adults, represents important areas of application. With a potential for significant transformation of elderly care, Agentic AI also raises profound concerns about data privacy and security, decision independence, and access. We share key insights to emphasize the need for ethical safeguards, privacy protections, and transparent decision-making. Our goal in this article is to provide a balanced discussion of both the potential and the challenges associated with Agentic AI, and to provide insights into its responsible use in elderly care, to bring Agentic AI into harmony with the requirements and vulnerabilities specific to the elderly. Finally, we identify the priorities for the academic research communities, to achieve human-centered advancements and integration of Agentic AI in elderly care. To the best of our knowledge, this is no existing study that reviews the role of Agentic AI in elderly care. Hence, we address the literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in elderly care. We also provide a companion interactive dashboard at https://hazratali.github.io/agenticai/.",
      "authors": [
        "Ruhul Amin Khalil",
        "Kashif Ahmad",
        "and Hazrat Ali"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:53:01+00:00",
          "link": "https://arxiv.org/abs/2507.14912v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14912",
        "HTML": "https://arxiv.org/html/2507.14912",
        "PDF": "https://arxiv.org/pdf/2507.14912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the application of Agentic AI in elderly care, exploring ethical and application aspects. It does not discuss any processes related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14962",
      "abstract": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain observed symptoms and manifestations. It has many applications, such as diagnosis and planning in artificial intelligence and database updates. In propositional abduction, we focus on specifying knowledge by a propositional formula. The computational complexity of tasks in propositional abduction has been systematically characterized - even with detailed classifications for Boolean fragments. Unsurprisingly, the most insightful reasoning problems (counting and enumeration) are computationally highly challenging. Therefore, we consider reasoning between decisions and counting, allowing us to understand explanations better while maintaining favorable complexity. We introduce facets to propositional abductions, which are literals that occur in some explanation (relevant) but not all explanations (dispensable). Reasoning with facets provides a more fine-grained understanding of variability in explanations (heterogeneous). In addition, we consider the distance between two explanations, enabling a better understanding of heterogeneity/homogeneity. We comprehensively analyze facets of propositional abduction in various settings, including an almost complete characterization in Post's framework.",
      "authors": [
        "Johannes Schmidt and Mohamed Maizia and Victor Lagerkvist and Johannes K. Fichte"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Complexity (cs.CC)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T13:50:26+00:00",
          "link": "https://arxiv.org/abs/2507.14962v1",
          "size": "751kb",
          "version": "v1"
        }
      ],
      "title": "Complexity of Faceted Explanations in Propositional Abduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14962",
        "HTML": "https://arxiv.org/html/2507.14962",
        "PDF": "https://arxiv.org/pdf/2507.14962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses propositional abduction and the complexity of reasoning with facets in AI, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15078",
      "abstract": "Diffusion models have shown great promise in medical image denoising and reconstruction, but their application to Positron Emission Tomography (PET) imaging remains limited by tracer-specific contrast variability and high computational demands. In this work, we proposed an anatomical prior-guided PET image reconstruction method based on diffusion models, inspired by the deep diffusion image prior (DDIP) framework. The proposed method alternated between diffusion sampling and model fine-tuning guided by the PET sinogram, enabling the reconstruction of high-quality images from various PET tracers using a score function pretrained on a dataset of another tracer. To improve computational efficiency, the half-quadratic splitting (HQS) algorithm was adopted to decouple network optimization from iterative PET reconstruction. The proposed method was evaluated using one simulation and two clinical datasets. For the simulation study, a model pretrained on [$^{18}$F]FDG data was tested on amyloid-negative PET data to assess out-of-distribution (OOD) performance. For the clinical-data validation, ten low-dose [$^{18}$F]FDG datasets and one [$^{18}$F]Florbetapir dataset were tested on a model pretrained on data from another tracer. Experiment results show that the proposed PET reconstruction method can generalize robustly across tracer distributions and scanner types, providing an efficient and versatile reconstruction framework for low-dose PET imaging.",
      "authors": [
        "Fumio Hashimoto and Kuang Gong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:25:29+00:00",
          "link": "https://arxiv.org/abs/2507.15078v1",
          "size": "800kb",
          "version": "v1"
        }
      ],
      "title": "PET Image Reconstruction Using Deep Diffusion Image Prior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15078",
        "HTML": "https://arxiv.org/html/2507.15078",
        "PDF": "https://arxiv.org/pdf/2507.15078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using diffusion models for PET image reconstruction, unrelated to LLM training data processing. It involves medical image processing, not any form of data processing for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15275",
      "abstract": "Building high-quality data resources is crucial for advancing artificial intelligence research and applications in specific domains, particularly in the Chinese medical domain. Existing Chinese medical datasets are limited in size and narrow in domain coverage, falling short of the diverse corpora required for effective pre-training. Moreover, most datasets are designed solely for LLM fine-tuning and do not support pre-training and reinforcement learning from human feedback (RLHF). In this paper, we propose a Chinese medical dataset named ChiMed 2.0, which extends our previous work ChiMed, and covers data collected from Chinese medical online platforms and generated by LLMs. ChiMed 2.0 contains 204.4M Chinese characters covering both traditional Chinese medicine classics and modern general medical data, where there are 164.8K documents for pre-training, 351.6K question-answering pairs for supervised fine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the effectiveness of our approach for training a Chinese medical LLM, we conduct further pre-training, SFT, and RLHF experiments on representative general domain LLMs and evaluate their performance on medical benchmark datasets. The results show performance gains across different model scales, validating the dataset's effectiveness and applicability.",
      "authors": [
        "Yuanhe Tian",
        "Junjie Liu",
        "Zhizhou Kou",
        "Yuxiang Li",
        "Yan Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:23:16+00:00",
          "link": "https://arxiv.org/abs/2507.15275v1",
          "size": "1087kb",
          "version": "v1"
        }
      ],
      "title": "ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15275",
        "HTML": "https://arxiv.org/html/2507.15275",
        "PDF": "https://arxiv.org/pdf/2507.15275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces ChiMed 2.0, a Chinese medical dataset designed for LLM pre-training, SFT, and RLHF. It involves data collection and generation, making significant contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15507",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models, such as language models (LMs), to follow complex human preferences. In RLHF for LMs, we first train an LM using supervised fine-tuning, sample pairs of responses, obtain human feedback, and use the resulting data to train a reward model (RM). RL methods are then used to train the LM to maximize the reward given by the RM. As training progresses, the responses generated by the LM no longer resemble the responses seen by the RM during training, leading to the RM becoming inaccurate. The score given by the RM keeps increasing, but the learned behavior no longer matches the human preferences. This issue is known as overoptimization. We investigate overoptimization from the point of view of distribution shift and show that the shift results in an inconsistent estimate of the RM parameters, leading to an inconsistent estimate of the policy gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which iteratively off-policy corrects the RM using importance weighting, without requiring new labels or samples. This results in a more accurate RM, which empirically leads to an improved final policy. We validate our approach in experiments with summarization and chatbot datasets and show that it performs significantly better than standard RLHF methods and baselines. Our implementation is available at https://github.com/JohannesAck/OffPolicyCorrectedRewardModeling",
      "authors": [
        "Johannes Ackermann and Takashi Ishida and Masashi Sugiyama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:19:04+00:00",
          "link": "https://arxiv.org/abs/2507.15507v1",
          "size": "282kb",
          "version": "v1"
        }
      ],
      "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15507",
        "PDF": "https://arxiv.org/pdf/2507.15507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses Off-Policy Corrected Reward Modeling in the context of Reinforcement Learning from Human Feedback (RLHF) which involves feedback data processing. However, its main focus is more on RL optimization than on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15743",
      "abstract": "Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchronously. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) of text consultations with asynchronous oversight, we compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across 60 scenarios, g-AMIE outperformed both groups in performing high-quality intake, summarizing cases, and proposing diagnoses and management plans for the overseeing PCP to review. This resulted in higher quality composite decisions. PCP oversight of g-AMIE was also more time-efficient than standalone PCP consultations in prior work. While our study does not replicate existing clinical practices and likely underestimates clinicians' capabilities, our results demonstrate the promise of asynchronous oversight as a feasible paradigm for diagnostic AI systems to operate under expert human oversight for enhancing real-world care.",
      "authors": [
        "Elahe Vedadi",
        "David Barrett",
        "Natalie Harris",
        "Ellery Wulczyn",
        "Shashir Reddy",
        "Roma Ruparel",
        "Mike Schaekermann",
        "Tim Strother",
        "Ryutaro Tanno",
        "Yash Sharma",
        "Jihyeon Lee",
        "C\\'ian Hughes",
        "Dylan Slack",
        "Anil Palepu",
        "Jan Freyberg",
        "Khaled Saab",
        "Valentin Li\\'evin",
        "Wei-Hung Weng",
        "Tao Tu",
        "Yun Liu",
        "Nenad Tomasev",
        "Kavita Kulkarni",
        "S. Sara Mahdavi",
        "Kelvin Guu",
        "Jo\\\"elle Barral",
        "Dale R. Webster",
        "James Manyika",
        "Avinatan Hassidim",
        "Katherine Chou",
        "Yossi Matias",
        "Pushmeet Kohli",
        "Adam Rodman",
        "Vivek Natarajan",
        "Alan Karthikesalingam",
        "David Stutz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:54:36+00:00",
          "link": "https://arxiv.org/abs/2507.15743v1",
          "size": "4531kb",
          "version": "v1"
        }
      ],
      "title": "Towards physician-centered oversight of conversational diagnostic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15743",
        "HTML": "https://arxiv.org/html/2507.15743",
        "PDF": "https://arxiv.org/pdf/2507.15743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for physician-centered oversight of conversational diagnostic AI, which is unrelated to LLM training data processing or data improvement methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15781",
      "abstract": "The design of control systems for the spatial self-organization of mobile agents is an open challenge across several engineering domains, including swarm robotics and synthetic biology. Here, we propose a bio-inspired leader-follower solution, which is aware of energy constraints of mobile agents and is apt to deal with large swarms. Akin to many natural systems, control objectives are formulated for the entire collective, and leaders and followers are allowed to plastically switch their role in time. We frame a density control problem, modeling the agents' population via a system of nonlinear partial differential equations. This approach allows for a compact description that inherently avoids the curse of dimensionality and improves analytical tractability. We derive analytical guarantees for the existence of desired steady-state solutions and their local stability for one-dimensional and higher-dimensional problems. We numerically validate our control methodology, offering support to the effectiveness, robustness, and versatility of our proposed bio-inspired control strategy.",
      "authors": [
        "Gian Carlo Maffettone",
        "Alain Boldini",
        "Mario di Bernardo",
        "Maurizio Porfiri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.15781v1",
          "size": "714kb",
          "version": "v1"
        }
      ],
      "title": "Density control of multi-agent swarms via bio-inspired leader-follower plasticity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15781",
        "HTML": "https://arxiv.org/html/2507.15781",
        "PDF": "https://arxiv.org/pdf/2507.15781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses bio-inspired control systems for spatial self-organization of mobile agents, a topic within swarm robotics and synthetic biology, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13764",
      "abstract": "Rice is one of the most widely cultivated crops globally and has been developed into numerous varieties. The quality of rice during cultivation is primarily determined by its cultivar and characteristics. Traditionally, rice classification and quality assessment rely on manual visual inspection, a process that is both time-consuming and prone to errors. However, with advancements in machine vision technology, automating rice classification and quality evaluation based on its cultivar and characteristics has become increasingly feasible, enhancing both accuracy and efficiency. This study proposes a real-time evaluation mechanism for comprehensive rice grain assessment, integrating a one-stage object detection approach, a deep convolutional neural network, and traditional machine learning techniques. The proposed framework enables rice variety identification, grain completeness grading, and grain chalkiness evaluation. The rice grain dataset used in this study comprises approximately 20,000 images from six widely cultivated rice varieties in China. Experimental results demonstrate that the proposed mechanism achieves a mean average precision (mAP) of 99.14% in the object detection task and an accuracy of 97.89% in the classification task. Furthermore, the framework attains an average accuracy of 97.56% in grain completeness grading within the same rice variety, contributing to an effective quality evaluation system.",
      "authors": [
        "Wanke Xia",
        "Ruoxin Peng",
        "Haoqi Chu",
        "Xinlei Zhu",
        "Zhiyu Yang",
        "Lili Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T14:24:25+00:00",
          "link": "https://arxiv.org/abs/2502.13764v1",
          "size": "667kb",
          "version": "v1"
        },
        {
          "date": "2025-02-23T07:06:03+00:00",
          "link": "https://arxiv.org/abs/2502.13764v2",
          "size": "667kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T05:16:33+00:00",
          "link": "https://arxiv.org/abs/2502.13764v3",
          "size": "673kb",
          "version": "v3"
        }
      ],
      "title": "An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13764",
        "PDF": "https://arxiv.org/pdf/2502.13764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on automating rice classification and quality evaluation using machine vision techniques. It does not address any aspect of LLM training data processing or dataset related to natural language processing."
      },
      "tasks": [
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10010",
      "abstract": "Uncertainties influencing the dynamical systems pose a significant challenge in estimating the achievable performance of a controller aiming to control such uncertain systems. When the uncertainties are of stochastic nature, obtaining hard guarantees for the robustness of a controller aiming to hedge against the uncertainty is not possible. This issue set the platform for the development of probabilistic robust control approaches. In this work, we utilise the gap metric between the known nominal model and the unknown perturbed model of the uncertain system as a tool to gauge the robustness of a controller and formulate the gap as a random variable in the setting with stochastic uncertainties. The main results of this paper include giving a probabilistic bound on the gap exceeding a known threshold, followed by bounds on the expected gap value and probabilistic robust stability and performance guarantees in terms of the gap metric. We also provide a probabilistic controller performance certification under gap uncertainty and probabilistic guarantee on the achievable $\\mathcal{H}_{\\infty}$ robustness. Numerical simulations are provided to demonstrate the proposed approach.",
      "authors": [
        "Venkatraman Renganathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:43:54+00:00",
          "link": "https://arxiv.org/abs/2507.10010v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:46:00+00:00",
          "link": "https://arxiv.org/abs/2507.10010v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "Probabilistic Robustness in the Gap Metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10010",
        "HTML": "https://arxiv.org/html/2507.10010",
        "PDF": "https://arxiv.org/pdf/2507.10010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on probabilistic robustness in control systems, utilizing the gap metric. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14188",
      "abstract": "In 2023, satellite and mobile networks crossed a historic threshold: standard smartphones, using unmodified 3GPP protocols, connected directly to low Earth orbit (LEO) satellites. This first wave of direct-to-device (D2D) demonstrations validated the physical feasibility of satellite-based mobile access. However, these systems remain fallback-grade--rural-only, bandwidth-limited, and fully dependent on Earth-based mobile cores for identity, session, and policy control. This paper asks a more ambitious question: Can a complete mobile network, including radio access, core functions, traffic routing, and content delivery, operate entirely from orbit? And can it deliver sustained, urban-grade service in the world's densest cities? We present the first end-to-end system architecture for a fully orbital telco, integrating electronically steered phased arrays with 1000-beam capacity, space-based deployment of 5G core functions (UPF, AMF), and inter-satellite laser mesh backhaul. We analyze spectral efficiency, beam capacity, and link budgets under dense urban conditions, accounting for path loss, Doppler, and multipath. Simulations show that rooftop and line-of-sight users can sustain 64-QAM throughput, while street-level access is feasible with relay or assisted beam modes. The paper outlines the remaining constraints, power, thermal dissipation, compute radiation hardening, and regulatory models, and demonstrates that these are engineering bottlenecks, not physical limits. Finally, we propose a staged 15-year roadmap from today's fallback D2D systems to autonomous orbital overlays delivering 50-100 Mbps to handhelds in megacities, with zero reliance on terrestrial infrastructure.",
      "authors": [
        "Sebastian Barros Elgueta"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T22:37:02+00:00",
          "link": "https://arxiv.org/abs/2507.14188v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "From Cell Towers to Satellites: A 2040 Blueprint for Urban-Grade Direct-to-Device Mobile Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14188",
        "HTML": "https://arxiv.org/html/2507.14188",
        "PDF": "https://arxiv.org/pdf/2507.14188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the system architecture for satellite-based mobile networks, which does not relate to LLM training data processing or any direct contributions to data operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14396",
      "abstract": "Effective communication is a critical factor in successful software engineering collaboration. However, communication gaps remain a persistent challenge, often leading to misunderstandings, inefficiencies, and defects. This research investigates the technical factors contributing to such misunderstandings and explores the measurable benefits of establishing shared vocabulary systems within software documentation and codebases. Using a Design Science Research (DSR) framework, the study was structured into three iterative phases: problem identification, method development, and empirical validation. The problem identification phase involved thematic analysis of communication data and semi-structured interviews, revealing key factors such as ambiguous messaging, misalignment in documentation, inconsistent code review feedback, and API integration miscommunication. Grounded Theory principles were employed to design a structured methodology for collaborative vocabulary development. Empirical validation through controlled experiments demonstrated that while initial adoption introduced overhead, the shared vocabulary system significantly improved information density, documentation clarity, and collaboration efficiency over time. Findings offer actionable insights for improving communication practices in software engineering, while also identifying limitations and directions for future research.",
      "authors": [
        "Carey Lai Zheng Hui",
        "Johnson Britto Jessia Esther Leena",
        "Kumuthini Subramanian",
        "Zhao Chenyu",
        "Shubham Rajeshkumar Jariwala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:58:16+00:00",
          "link": "https://arxiv.org/abs/2507.14396v1",
          "size": "1088kb",
          "version": "v1"
        }
      ],
      "title": "Developing Shared Vocabulary System For Collaborative Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14396",
        "PDF": "https://arxiv.org/pdf/2507.14396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research looks into communication in software engineering via shared vocabulary systems. It explores improving collaboration efficiency but does not involve any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14903",
      "abstract": "Autonomous driving demands reliable and efficient solutions to closely related problems such as decision-making and motion planning. In this work, decision-making refers specifically to highway lane selection, while motion planning involves generating control commands (such as speed and steering) to reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs), achieving both flexible and safe lane selection alongside precise trajectory execution remains a significant challenge. This paper proposes a framework called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly integrates decision-making and motion planning using a Mixture of Experts (MoE) inspired architecture combined with multi-policy reinforcement learning. By coordinating multiple specialized sub-networks through a gating mechanism, the method decomposes the complex driving task into modular components. Each sub-network focuses on a specific aspect of driving, improving efficiency by activating only the most relevant modules during inference. This design also enhances safety through modular specialization. CDGMP improves the adaptability and robustness of CAVs across diverse traffic scenarios, offering a scalable solution to real-world autonomy challenges. The architectural principles behind CDGMP, especially the use of MoE, also provide a strong foundation for other high-dimensional decision and control tasks. Simulation results (available at https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane selection and motion planning.",
      "authors": [
        "Pan Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.14903v1",
          "size": "764kb",
          "version": "v1"
        }
      ],
      "title": "CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14903",
        "PDF": "https://arxiv.org/pdf/2507.14903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for decision-making and motion planning in autonomous vehicles using reinforcement learning and a Mixture of Experts model. It is unrelated to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15058",
      "abstract": "A fundamental problem in cybersecurity and computer science is determining whether a program is free of bugs and vulnerabilities. Fuzzing, a popular approach to discovering vulnerabilities in programs, has several advantages over alternative strategies, although it has investment costs in the form of initial setup and continuous maintenance. The choice of fuzzing is further complicated when only a binary library is available, such as the case of closed-source and proprietary software. In response, we introduce LibLMFuzz, a framework that reduces costs associated with fuzzing closed-source libraries by pairing an agentic Large Language Model (LLM) with a lightweight tool-chain (disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan fuzz strategies, generate drivers, and iteratively self-repair build or runtime errors. Tested on four widely-used Linux libraries, LibLMFuzz produced syntactically correct drivers for all 558 fuzz-able API functions, achieving 100% API coverage with no human intervention. Across the 1601 synthesized drivers, 75.52% were nominally correct on first execution. The results show that LLM-augmented middleware holds promise in reducing the costs of fuzzing black box components and provides a foundation for future research efforts. Future opportunities exist for research in branch coverage.",
      "authors": [
        "Ian Hardgrove",
        "John D. Hastings"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:38:51+00:00",
          "link": "https://arxiv.org/abs/2507.15058v1",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "title": "LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15058",
        "HTML": "https://arxiv.org/html/2507.15058",
        "PDF": "https://arxiv.org/pdf/2507.15058"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces LibLMFuzz, a framework leveraging LLMs for fuzz target generation in cybersecurity, involving data analysis and strategy planning. It touches on data processing through LLMs but the main focus is not on training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15146",
      "abstract": "The design of medical systems for remote, resource-limited environments faces persistent challenges due to poor interoperability, lack of offline support, and dependency on costly infrastructure. Many existing digital health solutions neglect these constraints, limiting their effectiveness for frontline health workers in underserved regions. This paper presents a portable, edge-enabled Electronic Health Record platform optimized for offline-first operation, secure patient data management, and modular diagnostic integration. Running on small-form factor embedded devices, it provides AES-256 encrypted local storage with optional cloud synchronization for interoperability. As a use case, we integrated a non-invasive anemia screening module leveraging fingernail pallor analysis. Trained on 250 patient cases (27\\% anemia prevalence) with KDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL and MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To optimize performance, a YOLOv8n-based nail bed detector was quantized to INT8, reducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5 at 0.995. The system emphasizes low-cost deployment, modularity, and data privacy compliance (HIPAA/GDPR), addressing critical barriers to digital health adoption in disconnected settings. Our work demonstrates a scalable approach to enhance portable health information systems and support frontline healthcare in underserved regions.",
      "authors": [
        "Sebastian A. Cruz Romero",
        "Misael J. Mercado Hernandez",
        "Samir Y. Ali Rivera",
        "Jorge A. Santiago Fernandez",
        "Wilfredo E. Lugo Beauchamp"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T22:46:42+00:00",
          "link": "https://arxiv.org/abs/2507.15146v1",
          "size": "5360kb",
          "version": "v1"
        }
      ],
      "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15146",
        "HTML": "https://arxiv.org/html/2507.15146",
        "PDF": "https://arxiv.org/pdf/2507.15146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work describes a portable health record system and addresses data privacy and offline operation, but it is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15706",
      "abstract": "Receivers in standard signaling game models struggle with learning compositional information. Even when the signalers send compositional messages, the receivers do not interpret them compositionally. When information from one message component is lost or forgotten, the information from other components is also erased. In this paper I construct signaling game models in which genuine compositional understanding evolves. I present two new models: a minimalist receiver who only learns from the atomic messages of a signal, and a generalist receiver who learns from all of the available information. These models are in many ways simpler than previous alternatives, and allow the receivers to learn from the atomic components of messages.",
      "authors": [
        "David Peter Wallis Freeborn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:14:40+00:00",
          "link": "https://arxiv.org/abs/2507.15706v1",
          "size": "521kb",
          "version": "v1"
        }
      ],
      "title": "Compositional Understanding in Signaling Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15706",
        "HTML": "https://arxiv.org/html/2507.15706",
        "PDF": "https://arxiv.org/pdf/2507.15706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with compositional understanding in signaling games, focusing on message interpretation models, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01431",
      "abstract": "Camouflaged object segmentation presents unique challenges compared to traditional segmentation tasks, primarily due to the high similarity in patterns and colors between camouflaged objects and their backgrounds. Effective solutions to this problem have significant implications in critical areas such as pest control, defect detection, and lesion segmentation in medical imaging. Prior research has predominantly emphasized supervised or unsupervised pre-training methods, leaving zero-shot approaches significantly underdeveloped. Existing zero-shot techniques commonly utilize the Segment Anything Model (SAM) in automatic mode or rely on vision-language models to generate cues for segmentation; however, their performances remain unsatisfactory, due to the similarity of the camouflaged object and the background. This work studies how to avoid training by integrating large pre-trained models like SAM-2 and Owl-v2 with temporal information into a modular pipeline. Evaluated on the MoCA-Mask dataset, our approach achieves outstanding performance improvements, significantly outperforming existing zero-shot methods by raising the F-measure ($F_\\beta^w$) from 0.296 to 0.628. Our approach also surpasses supervised methods, increasing the F-measure from 0.476 to 0.628. Additionally, evaluation on the MoCA-Filter dataset demonstrates an increase in the success rate from 0.628 to 0.697 when compared with FlowSAM, a supervised transfer method. A thorough ablation study further validates the individual contributions of each component. Besides our main contributions, we also highlight inconsistencies in previous work regarding metrics and settings. Code can be found in https://github.com/weathon/vcos.",
      "authors": [
        "Wenqi Guo",
        "Mohamed Shehata",
        "Shan Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T06:24:54+00:00",
          "link": "https://arxiv.org/abs/2505.01431v1",
          "size": "13388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T23:46:11+00:00",
          "link": "https://arxiv.org/abs/2505.01431v2",
          "size": "6767kb",
          "version": "v2"
        }
      ],
      "title": "ZS-VCOS: Zero-Shot Video Camouflaged Object Segmentation By Optical Flow and Open Vocabulary Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01431",
        "HTML": "https://arxiv.org/html/2505.01431",
        "PDF": "https://arxiv.org/pdf/2505.01431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on ameliorating camouflaged object segmentation via zero-shot learning, primarily in the context of vision tasks, not the processing of training data for LLMs."
      },
      "tasks": [
        "Camouflaged Object Segmentation",
        "Defect Detection",
        "Lesion Segmentation",
        "Optical Flow Estimation",
        "Segmentation",
        "Semantic Segmentation",
        "Unsupervised Pre-training"
      ],
      "repo_urls": [
        "https://github.com/weathon/vcos"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14393",
      "abstract": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward in language model capabilities, aiming to tackle increasingly sophisticated tasks with unprecedented efficiency and accuracy. However, despite their impressive performance, recent studies have highlighted how current reasoning models frequently fail to generalize to novel, unseen problems, often resorting to memorized solutions rather than genuine inferential reasoning. Such behavior underscores a critical limitation in modern LRMs, i.e., their tendency toward overfitting, which in turn results in poor generalization in problem-solving capabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our multi-agent system framework, Nexus, equipped with a novel automated workflow synthesis mechanism. Given a user's prompt and a small set of representative examples, the Architect autonomously generates a tailored reasoning workflow by selecting suitable strategies, tool integrations, and adversarial techniques for a specific problem class. Furthermore, the Architect includes an iterative prompt refinement mechanism that fine-tunes agents' system prompts to maximize performance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf, non-reasoning model on a custom dataset of challenging logical questions and compare its performance against state-of-the-art LRMs. Results show that Nexus Architect consistently outperforms existing solutions, achieving up to a 66% increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against Claude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.",
      "authors": [
        "Humza Sami",
        "Mubashir ul Islam",
        "Pierre-Emmanuel Gaillardon",
        "Valerio Tenace"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:46:27+00:00",
          "link": "https://arxiv.org/abs/2507.14393v1",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14393",
        "HTML": "https://arxiv.org/html/2507.14393",
        "PDF": "https://arxiv.org/pdf/2507.14393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a reasoning model framework that enhances multi-agent reasoning capabilities. It does not address LLM training data processing, focusing instead on improving inferential reasoning and workflow synthesis in reasoning models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14760",
      "abstract": "Deep learning models often hallucinate, producing realistic artifacts that are not truly present in the sample. This can have dire consequences for scientific and medical inverse problems, such as MRI and microscopy denoising, where accuracy is more important than perceptual quality. Uncertainty quantification techniques, such as conformal prediction, can pinpoint outliers and provide guarantees for image regression tasks, improving reliability. However, existing methods utilize a linear constant scaling factor to calibrate uncertainty bounds, resulting in larger, less informative bounds. We propose QUTCC, a quantile uncertainty training and calibration technique that enables nonlinear, non-uniform scaling of quantile predictions to enable tighter uncertainty estimates. Using a U-Net architecture with a quantile embedding, QUTCC enables the prediction of the full conditional distribution of quantiles for the imaging task. During calibration, QUTCC generates uncertainty bounds by iteratively querying the network for upper and lower quantiles, progressively refining the bounds to obtain a tighter interval that captures the desired coverage. We evaluate our method on several denoising tasks as well as compressive MRI reconstruction. Our method successfully pinpoints hallucinations in image estimates and consistently achieves tighter uncertainty intervals than prior methods while maintaining the same statistical coverage.",
      "authors": [
        "Cassandra Tong Ye",
        "Shamus Li",
        "Tyler King",
        "Kristina Monakhova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T21:44:14+00:00",
          "link": "https://arxiv.org/abs/2507.14760v1",
          "size": "1482kb",
          "version": "v1"
        }
      ],
      "title": "QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14760",
        "HTML": "https://arxiv.org/html/2507.14760",
        "PDF": "https://arxiv.org/pdf/2507.14760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research concerns uncertainty quantification in imaging inverse problems, distinct from LLM training data processing tasks or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15079",
      "abstract": "Quantifying the uncertainty of forecasting models is essential to assess and mitigate the risks associated with data-driven decisions, especially in volatile domains such as electricity markets. Machine learning methods can provide highly accurate electricity price forecasts, critical for informing the decisions of market participants. However, these models often lack uncertainty estimates, which limits the ability of decision makers to avoid unnecessary risks. In this paper, we propose a novel method for generating probabilistic forecasts from ensembles of point forecasts, called Isotonic Quantile Regression Averaging (iQRA). Building on the established framework of Quantile Regression Averaging (QRA), we introduce stochastic order constraints to improve forecast accuracy, reliability, and computational costs. In an extensive forecasting study of the German day-ahead electricity market, we show that iQRA consistently outperforms state-of-the-art postprocessing methods in terms of both reliability and sharpness. It produces well-calibrated prediction intervals across multiple confidence levels, providing superior reliability to all benchmark methods, particularly coverage-based conformal prediction. In addition, isotonic regularization decreases the complexity of the quantile regression problem and offers a hyperparameter-free approach to variable selection.",
      "authors": [
        "Arkadiusz Lipiecki and Bartosz Uniejewski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:28:39+00:00",
          "link": "https://arxiv.org/abs/2507.15079v1",
          "size": "644kb",
          "version": "v1"
        }
      ],
      "title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15079",
        "HTML": "https://arxiv.org/html/2507.15079",
        "PDF": "https://arxiv.org/pdf/2507.15079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for uncertainty quantification in electricity price forecasts. It does not address any aspects of LLM training data processing or contribute to training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15351",
      "abstract": "On-demand ride-sharing platforms face the fundamental challenge of dynamically bundling passengers with diverse origins and destinations and matching them with vehicles in real time, all under significant uncertainty. Recently, MARL has emerged as a promising solution for this problem, leveraging decentralized learning to address the curse of dimensionality caused by the large number of agents in the ride-hailing market and the resulting expansive state and action spaces. However, conventional MARL-based ride-sharing approaches heavily rely on the accurate estimation of Q-values or V-values, which becomes problematic in large-scale, highly uncertain environments. Specifically, most of these approaches adopt an independent paradigm, exacerbating this issue, as each agent treats others as part of the environment, leading to unstable training and substantial estimation bias in value functions. To address these challenges, we propose two novel alternative methods that bypass value function estimation. First, we adapt GRPO to ride-sharing, replacing the PPO baseline with the group average reward to eliminate critic estimation errors and reduce training bias. Second, inspired by GRPO's full utilization of group reward information, we customize the PPO framework for ride-sharing platforms and show that, under a homogeneous fleet, the optimal policy can be trained using only one-step rewards - a method we term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior performance across most scenarios, efficiently optimizing pickup times and the number of served orders using simple MLP networks.",
      "authors": [
        "Zijian Zhao",
        "Sen Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:04:31+00:00",
          "link": "https://arxiv.org/abs/2507.15351v1",
          "size": "1153kb",
          "version": "v1"
        }
      ],
      "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15351",
        "HTML": "https://arxiv.org/html/2507.15351",
        "PDF": "https://arxiv.org/pdf/2507.15351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multi-agent reinforcement learning for ride-sharing platforms using a novel policy optimization method. It does not pertain to LLM training data processing or related data tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15658",
      "abstract": "We study the problem of collective tree exploration in which a team of $k$ mobile agents must collectively visit all nodes of an unknown tree in as few moves as possible. The agents all start from the root and discover adjacent edges as they progress in the tree. Communication is distributed in the sense that agents share information by reading and writing on whiteboards located at all nodes. Movements are asynchronous, in the sense that the speeds of all agents are controlled by an adversary at all times. All previous competitive guarantees for collective tree exploration are either distributed but synchronous, or asynchronous but centralized. In contrast, we present a distributed asynchronous algorithm that explores any tree of $n$ nodes and depth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear in $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e., with a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is asymptotically optimal (i.e., $1$-competitive) from the perspective of average-case complexity. We then present a new general lower bound on the competitive ratio of asynchronous collective tree exploration, in $\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and centralized settings, and improves upon the previous lower bound in $\\Omega(\\log k)$.",
      "authors": [
        "Romain Cosson",
        "Laurent Massouli\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:21:13+00:00",
          "link": "https://arxiv.org/abs/2507.15658v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15658",
        "HTML": "https://arxiv.org/html/2507.15658",
        "PDF": "https://arxiv.org/pdf/2507.15658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the problem of collective tree exploration by mobile agents and does not make any contribution to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15736",
      "abstract": "Recent advancements in Large Language Models (LLMs) have revealed their impressive ability to perform multi-step, logic-driven reasoning across complex domains, positioning them as powerful tools and collaborators in scientific discovery while challenging the long-held view that inspiration-driven ideation is uniquely human. However, the lack of a dedicated benchmark that evaluates LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings poses a critical barrier to fully understanding their strengths and limitations. To address this gap, we introduce IDRBench -- a pioneering benchmark featuring an expert annotated dataset and a suite of tasks tailored to evaluate LLMs' capabilities in proposing valuable research ideas from different scientific domains for interdisciplinary research. This benchmark aims to provide a systematic framework for assessing LLM performance in complex, cross-domain scientific research. Our dataset consists of scientific publications sourced from the ArXiv platform covering six distinct disciplines, and is annotated by domain experts with diverse academic backgrounds. To ensure high-quality annotations, we emphasize clearly defined dimensions that characterize authentic interdisciplinary research. The design of evaluation tasks in IDRBench follows a progressive, real-world perspective, reflecting the natural stages of interdisciplinary research development, including 1) IDR Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation. Using IDRBench, we construct baselines across 10 LLMs and observe that despite fostering some level of IDR awareness, LLMs still struggle to produce quality IDR ideas. These findings could not only spark new research directions, but also help to develop next-generation LLMs that excel in interdisciplinary research.",
      "authors": [
        "Yuanhao Shen",
        "Daniel Xavier de Sousa",
        "Ricardo Mar\\c{c}al",
        "Ali Asad",
        "Hongyu Guo",
        "Xiaodan Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:43:05+00:00",
          "link": "https://arxiv.org/abs/2507.15736v1",
          "size": "6657kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Large Language Models' Ability on Interdisciplinary Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15736",
        "HTML": "https://arxiv.org/html/2507.15736",
        "PDF": "https://arxiv.org/pdf/2507.15736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark called IDRBench and discusses its dataset, the focus is on assessing LLMs' interdisciplinary research capabilities rather than directly on data processing techniques for LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15822",
      "abstract": "Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills?\n  To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.",
      "authors": [
        "Li Huang",
        "Ilgiz Mustafin",
        "Marco Piccioni",
        "Alessandro Schena",
        "Reto Weber",
        "Bertrand Meyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:30:16+00:00",
          "link": "https://arxiv.org/abs/2507.15822v1",
          "size": "839kb",
          "version": "v1"
        }
      ],
      "title": "Do AI models help produce verified bug fixes?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15822",
        "HTML": "https://arxiv.org/html/2507.15822",
        "PDF": "https://arxiv.org/pdf/2507.15822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the use of LLMs in automatic program repair (APR) rather than any aspect of training data processing for LLMs, making it irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.05064",
      "abstract": "In this paper, we propose a structure-guided Gauss-Newton (SgGN) method for solving least squares problems using a shallow ReLU neural network. The method effectively takes advantage of both the least squares structure and the neural network structure of the objective function. By categorizing the weights and biases of the hidden and output layers of the network as nonlinear and linear parameters, respectively, the method iterates back and forth between the nonlinear and linear parameters. The nonlinear parameters are updated by a damped Gauss-Newton method and the linear ones are updated by a linear solver. Moreover, at the Gauss-Newton step, a special form of the Gauss-Newton matrix is derived for the shallow ReLU neural network and is used for efficient iterations. It is shown that the corresponding mass and Gauss-Newton matrices in the respective linear and nonlinear steps are symmetric and positive definite under reasonable assumptions. Thus, the SgGN method naturally produces an effective search direction without the need of additional techniques like shifting in the Levenberg-Marquardt method to achieve invertibility of the Gauss-Newton matrix. The convergence and accuracy of the method are demonstrated numerically for several challenging function approximation problems, especially those with discontinuities or sharp transition layers that pose significant challenges for commonly used training algorithms in machine learning.",
      "authors": [
        "Zhiqiang Cai",
        "Tong Ding",
        "Min Liu",
        "Xinyu Liu",
        "Jianlin Xia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-07T20:24:44+00:00",
          "link": "https://arxiv.org/abs/2404.05064v1",
          "size": "4599kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T21:33:40+00:00",
          "link": "https://arxiv.org/abs/2404.05064v2",
          "size": "4759kb",
          "version": "v2"
        }
      ],
      "title": "A Structure-Guided Gauss-Newton Method for Shallow ReLU Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.05064",
        "HTML": "https://arxiv.org/html/2404.05064",
        "PDF": "https://arxiv.org/pdf/2404.05064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the Gauss-Newton method for solving least squares problems in neural networks, with no relevance to LLM training data processing or data operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.21385",
      "abstract": "Reconstructing and understanding dynamic visual information (video) from brain EEG recordings is challenging due to the non-stationary nature of EEG signals, their low signal-to-noise ratio (SNR), and the limited availability of EEG-Video stimulus datasets. Most recent studies have focused on reconstructing static images from EEG recordings. In this work, we propose a framework to reconstruct dynamic visual stimuli from EEG data and conduct an in-depth study of the information encoded in EEG signals. Our approach first trains a feature extraction network using a triplet-based contrastive learning strategy within an EEG-video generation framework. The extracted EEG features are then used for video synthesis with a modified StyleGAN-ADA, which incorporates temporal information as conditioning. Additionally, we analyze how different brain regions contribute to processing dynamic visual stimuli. Through several empirical studies, we evaluate the effectiveness of our framework and investigate how much dynamic visual information can be inferred from EEG signals. The inferences we derive through our extensive studies would be of immense value to future research on extracting visual dynamics from EEG.",
      "authors": [
        "Prajwal Singh",
        "Anupam Sharma",
        "Pankaj Pandey",
        "Krishna Miyapuram and Shanmuganathan Raman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T16:12:43+00:00",
          "link": "https://arxiv.org/abs/2505.21385v1",
          "size": "12352kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:06:53+00:00",
          "link": "https://arxiv.org/abs/2505.21385v2",
          "size": "29263kb",
          "version": "v2"
        }
      ],
      "title": "EEGVid: Dynamic Vision from EEG Brain Recordings, How much does EEG know?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21385",
        "HTML": "https://arxiv.org/html/2505.21385",
        "PDF": "https://arxiv.org/pdf/2505.21385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reconstructing dynamic visual stimuli from EEG data using a framework involving video synthesis and EEG feature extraction. It does not address LLM training data processing or data operations related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14842",
      "abstract": "Poor security of Internet routing enables adversaries to divert user data through unintended infrastructures (hijack). Of particular concern -- and the focus of this paper -- are cases where attackers reroute domestic traffic through foreign countries, exposing it to surveillance, bypassing legal privacy protections, and posing national security threats. Efforts to detect and mitigate such attacks have focused primarily on the control plane while data-plane signals remain largely overlooked. In particular, change in propagation delay caused by rerouting offers a promising signal: the change is unavoidable and the increased propagation delay is directly observable from the affected networks. In this paper, we explore the practicality of using delay variations for hijack detection, addressing two key questions: (1) What coverage can this provide, given its heavy dependence on the geolocations of the sender, receiver, and adversary? and (2) Can an always-on latency-based detection system be deployed without disrupting normal network operations? We observe that for 86% of victim-attacker country pairs in the world, mid-attack delays exceed pre-attack delays by at least 25% in real deployments, making delay-based hijack detection promising. To demonstrate practicality, we design HiDe, which reliably detects delay surges from long-distance hijacks at line rate. We measure HiDe's accuracy and false-positive rate on real-world data and validate it with ethically conducted hijacks.",
      "authors": [
        "Satadal Sengupta",
        "Hyojoon Kim",
        "Daniel Jubas",
        "Maria Apostolaki",
        "Jennifer Rexford"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:00:24+00:00",
          "link": "https://arxiv.org/abs/2507.14842v1",
          "size": "4001kb",
          "version": "v1"
        }
      ],
      "title": "Data-Plane Telemetry to Mitigate Long-Distance BGP Hijacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14842",
        "HTML": "https://arxiv.org/html/2507.14842",
        "PDF": "https://arxiv.org/pdf/2507.14842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mitigating long-distance BGP hijacks using data-plane telemetry and delay variations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15313",
      "abstract": "Sturmian words form a family of one-sided infinite words over a binary alphabet that are obtained as a discretization of a line with an irrational slope starting from the origin. A finite version of this class of words called Christoffel words has been extensively studied for their interesting properties. It is a class of words that has a geometric and an algebraic definition, making it an intriguing topic of study for many mathematicians. Recently, a generalization of Christoffel words for an alphabet with 3 letters or more, called epichristoffel words, using episturmian morphisms has been studied, and many of the properties of Christoffel words have been shown to carry over to epichristoffel words; however, many properties are not shared by them as well. In this paper, we introduce the notion of an epichristoffel tree, which proves to be a useful tool in determining a subclass of epichristoffel words that share an important property of Christoffel words, which is the ability to factorize an epichristoffel word as a product of smaller epichristoffel words. We also use the epichristoffel tree to present some interesting results that help to better understand epichristoffel words.",
      "authors": [
        "Abhishek Krishnamoorthy (Madras Christian College)",
        "Robinson Thamburaj (Madras Christian College)",
        "Durairaj Gnanaraj Thomas (Madras Christian College)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:14:47+00:00",
          "link": "https://arxiv.org/abs/2507.15313v1",
          "size": "217kb",
          "version": "v1"
        }
      ],
      "title": "On a Generalization of the Christoffel Tree: Epichristoffel Trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15313",
        "PDF": "https://arxiv.org/pdf/2507.15313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces the concept of epichristoffel trees and words, with a focus on combinatorial properties, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15597",
      "abstract": "We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained on large-scale human videos. Existing VLAs struggle with complex manipulation tasks requiring high dexterity and generalize poorly to novel scenarios and tasks, primarily due to their reliance on synthetic data with significant sim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To address this data bottleneck, we propose leveraging human hands as a foundation manipulator, capitalizing on the rich dexterity and scalability present in web data. Our approach centers on physical instruction tuning, a novel training paradigm that combines large-scale VLA pretraining from human videos, physical space alignment for 3D reasoning, and post-training adaptation for robotic tasks. Additionally, we introduce a part-level motion tokenization method which achieves millimeter-level reconstruction accuracy to model precise hand trajectories for action learning. To support our proposed paradigm, we further develop a comprehensive data curation pipeline that integrates heterogeneous sources -- including motion capture, VR, and RGB-only videos -- into a large-scale dataset with millions of motion-based instructional instances. We empirically show the excellence of Being-H0 in hand motion generation and instruction following, and it also scales well with model and data sizes. Importantly, we observe the expected gains of Being-H0 in real-world robotic manipulation as physical instruction tuning is applied. More details are available at https://beingbeyond.github.io/Being-H0.",
      "authors": [
        "Hao Luo",
        "Yicheng Feng",
        "Wanpeng Zhang",
        "Sipeng Zheng",
        "Ye Wang",
        "Haoqi Yuan",
        "Jiazheng Liu",
        "Chaoyi Xu",
        "Qin Jin",
        "Zongqing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:19:09+00:00",
          "link": "https://arxiv.org/abs/2507.15597v1",
          "size": "8779kb",
          "version": "v1"
        }
      ],
      "title": "Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15597",
        "HTML": "https://arxiv.org/html/2507.15597",
        "PDF": "https://arxiv.org/pdf/2507.15597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents Being-H0, which involves data curation from heterogeneous sources for model pretraining, but its main focus is on VLA model development and robotic tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15734",
      "abstract": "Human machine interaction is a huge source of inspiration in today's media art and digital design, as machines and humans merge together more and more. Its place in art reflects its growing applications in industry, such as robotics. However, those interactions often remains too technical and machine-driven for people to really engage into. On the artistic side, new technologies are often not explored in their full potential and lag a bit behind, so that state-of-the-art research does not make its way up to museums and exhibitions. Machines should support people's imagination and poetry in a seamless interface to their body or soul. We propose an artistic sound installation featuring neuromorphic body sensing to support a direct yet non intrusive interaction with the visitor with the purpose of creating sound scapes together with the machine. We design a neuromorphic multihead human pose estimation neural sensor that shapes sound scapes and visual output with fine body movement control. In particular, the feature extractor is a spiking neural network tailored for a dedicated neuromorphic chip. The visitor, immersed in a sound atmosphere and a neurally processed representation of themselves that they control, experience the dialogue with a machine that thinks neurally, similarly to them.",
      "authors": [
        "Jules Lecomte (1)",
        "Konrad Zinner (2)",
        "Michael Neumeier (1) and Axel von Arnim (1) ((1) Fortiss GmbH",
        "Munich",
        "Germany",
        "(2) Hochschule f\\\"ur Musik und Theater Munich",
        "Germany)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T15:42:11+00:00",
          "link": "https://arxiv.org/abs/2507.15734v1",
          "size": "5937kb",
          "version": "v1"
        }
      ],
      "title": "TONUS: Neuromorphic human pose estimation for artistic sound co-creation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15734",
        "HTML": "https://arxiv.org/html/2507.15734",
        "PDF": "https://arxiv.org/pdf/2507.15734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neuromorphic human pose estimation for artistic sound co-creation, which involves human-machine interaction but does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15857",
      "abstract": "Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings-where training involves repeated passes over limited data-and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We interpret this advantage as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of token orderings and prediction tasks, unlike AR's fixed left-to-right factorization. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to outperform AR. These results suggest that when data, not compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm. Our code is available at: https://diffusion-scaling.github.io.",
      "authors": [
        "Mihir Prabhudesai",
        "Menging Wu",
        "Amir Zadeh",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2507.15857v1",
          "size": "5123kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15857",
        "HTML": "https://arxiv.org/html/2507.15857",
        "PDF": "https://arxiv.org/pdf/2507.15857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper studies diffusion models in data-constrained settings, which involves considerations about data efficiency and data use. However, it primarily explores modeling benefits over autoregressive approaches, not direct contributions to LLM data processing techniques or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.02244",
      "abstract": "The advancement of machine learning algorithms in medical image analysis requires the expansion of training datasets. A popular and cost-effective approach is automated annotation extraction from free-text medical reports, primarily due to the high costs associated with expert clinicians annotating medical images, such as chest X-rays. However, it has been shown that the resulting datasets are susceptible to biases and shortcuts. Another strategy to increase the size of a dataset is crowdsourcing, a widely adopted practice in general computer vision with some success in medical image analysis. In a similar vein to crowdsourcing, we enhance two publicly available chest X-ray datasets by incorporating non-expert annotations. However, instead of using diagnostic labels, we annotate shortcuts in the form of tubes. We collect 3.5k chest drain annotations for NIH-CXR14, and 1k annotations for four different tube types in PadChest, and create the Non-Expert Annotations of Tubes in X-rays (NEATX) dataset. We train a chest drain detector with the non-expert annotations that generalizes well to expert labels. Moreover, we compare our annotations to those provided by experts and show \"moderate\" to \"almost perfect\" agreement. Finally, we present a pathology agreement study to raise awareness about the quality of ground truth annotations. We make our dataset available on Zenodo at https://zenodo.org/records/14944064 and our code available at https://github.com/purrlab/chestxr-label-reliability.",
      "authors": [
        "Veronika Cheplygina",
        "Cathrine Damgaard",
        "Trine Naja Eriksen",
        "Dovile Juodelyte",
        "Amelia Jim\\'enez-S\\'anchez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-05T13:52:43+00:00",
          "link": "https://arxiv.org/abs/2309.02244v1",
          "size": "1218kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T13:04:45+00:00",
          "link": "https://arxiv.org/abs/2309.02244v2",
          "size": "819kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T09:08:16+00:00",
          "link": "https://arxiv.org/abs/2309.02244v3",
          "size": "818kb",
          "version": "v3"
        }
      ],
      "title": "Augmenting Chest X-ray Datasets with Non-Expert Annotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.02244",
        "HTML": "https://arxiv.org/html/2309.02244",
        "PDF": "https://arxiv.org/pdf/2309.02244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses augmenting chest X-ray datasets with non-expert annotations and creating the NEATX dataset. While this involves data processing, it is specific to medical imaging and not directly related to LLM training data processing."
      },
      "tasks": [
        "Diagnostic",
        "Medical Image Analysis"
      ],
      "repo_urls": [
        "https://github.com/purrlab/chestxr-label-reliability",
        "https://github.com/volesen/slicing-through-bias",
        "https://github.com/nina-weng/fastdime_med"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05170",
      "abstract": "Deep learning has shown strong potential in cancer classification from whole-slide images (WSIs), but the need for extensive expert annotations often limits its success. Annotation-free approaches, such as multiple instance learning (MIL) and self-supervised learning (SSL), have emerged as promising alternatives to traditional annotation-based methods. However, conventional SSL methods typically rely on synthetic data augmentations, which may fail to capture the spatial structure critical to histopathology. In this work, we propose a spatial context-driven positive pair sampling strategy that enhances SSL by leveraging the morphological coherence of spatially adjacent patches within WSIs. Our method is modular and compatible with established joint embedding SSL frameworks, including Barlow Twins, BYOL, VICReg, and DINOv2. We evaluate its effectiveness on both slide-level classification using MIL and patch-level linear probing. Experiments across four datasets demonstrate consistent performance improvements, with accuracy gains of 5\\% to 10\\% compared to standard augmentation-based sampling. These findings highlight the value of spatial context in improving representation learning for computational pathology and provide a biologically meaningful enhancement for pretraining models in annotation-limited settings. The code is available at https://anonymous.4open.science/r/contextual-pairs-E72F/.",
      "authors": [
        "Willmer Rafell Quinones Robles",
        "Sakonporn Noree",
        "Young Sin Ko",
        "Bryan Wong",
        "Jongwoo Kim",
        "Mun Yong Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T06:31:19+00:00",
          "link": "https://arxiv.org/abs/2503.05170v1",
          "size": "4139kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T05:36:36+00:00",
          "link": "https://arxiv.org/abs/2503.05170v2",
          "size": "3633kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging Spatial Context for Positive Pair Sampling in Histopathology Image Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05170",
        "HTML": "https://arxiv.org/html/2503.05170",
        "PDF": "https://arxiv.org/pdf/2503.05170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new strategy for positive pair sampling in histopathology image representation learning, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13296",
      "abstract": "Deep neural networks (DNNs) deliver outstanding performance, but their complexity often prohibits deployment in resource-constrained settings. Comprehensive structured pruning frameworks based on parameter dependency analysis reduce model size with specific regard to computational performance. When applying them to Multi-Component Neural Architectures (MCNAs), they risk network integrity by removing large parameter groups. We introduce a component-aware pruning strategy, extending dependency graphs to isolate individual components and inter-component flows. This creates smaller, targeted pruning groups that conserve functional integrity. Demonstrated effectively on a control task, our approach achieves greater sparsity and reduced performance degradation, opening a path for optimizing complex, multi-component DNNs efficiently.",
      "authors": [
        "Ganesh Sundaram",
        "Jonas Ulmen",
        "and Daniel G\\\"orges"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T19:12:49+00:00",
          "link": "https://arxiv.org/abs/2504.13296v1",
          "size": "274kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:37:33+00:00",
          "link": "https://arxiv.org/abs/2504.13296v2",
          "size": "169kb",
          "version": "v2"
        }
      ],
      "title": "Enhanced Pruning Strategy for Multi-Component Neural Architectures Using Component-Aware Graph Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13296",
        "HTML": "https://arxiv.org/html/2504.13296",
        "PDF": "https://arxiv.org/pdf/2504.13296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on an enhanced pruning strategy for neural architectures to optimize deployment, which is unrelated to LLM training data processing. It addresses model complexity and performance, not details of data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14234",
      "abstract": "Long-term wildlife tracking is crucial for biodiversity monitoring, but energy limitations pose challenges, especially for animal tags, where replacing batteries is impractical and stressful for the animal due to the need to locate, possibly sedate, and handle it. Energy harvesting offers a sustainable alternative, yet most existing systems rely on a single energy source and infrastructure-limited communication technologies. This paper presents an energy-neutral system that combines solar and kinetic energy harvesting to enable the tracking and monitoring of wild animals. Harvesting from multiple sources increases the total available energy. Uniquely, the kinetic harvester also serves as a motion proxy by sampling harvested current, enabling activity monitoring without dedicated sensors. Our approach also ensures compatibility with existing cellular infrastructure, using Narrowband Internet of Things (NB-IoT). We present a simulation framework that models energy harvesting, storage, and consumption at the component level. An energy-aware scheduler coordinates task execution based on real-time energy availability. We evaluate performance under realistically varying conditions, comparing task frequencies and capacitor sizes. Results show that our approach maintains energy-neutral operation while significantly increasing data yield and reliability compared to single-source systems, with the ability to consistently sample GPS location data and kinetic harvesting data every two minutes while transmitting these results over NB-IoT every hour. These findings demonstrate the potential for maintenance-free, environmentally friendly tracking in remote habitats, enabling more effective and scalable wildlife monitoring.",
      "authors": [
        "Samer Nasser",
        "Henrique Duarte Moura",
        "Dragan Subotic",
        "Ritesh Kumar Singh",
        "Maarten Weyn",
        "Jeroen Famaey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:08:34+00:00",
          "link": "https://arxiv.org/abs/2507.14234v1",
          "size": "2729kb",
          "version": "v1"
        }
      ],
      "title": "Feasibility of Energy Neutral Wildlife Tracking using Multi-Source Energy Harvesting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14234",
        "PDF": "https://arxiv.org/pdf/2507.14234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a wildlife tracking system using energy harvesting but does not relate to any data processing operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14271",
      "abstract": "The MiDeSeC dataset is created through H&E stained invasive breast carcinoma, no special type (NST) slides of 25 different patients captured at 40x magnification from the Department of Medical Pathology at Ankara University. The slides have been scanned by 3D Histech Panoramic p250 Flash-3 scanner and Olympus BX50 microscope. As several possible mitosis shapes exist, it is crucial to have a large dataset to cover all the cases. Accordingly, a total of 50 regions is selected from glass slides for 25 patients, each of regions with a size of 1024*1024 pixels. There are more than 500 mitoses in total in these 50 regions. Two-thirds of the regions are reserved for training, the other third for testing.",
      "authors": [
        "Refik Samet",
        "Nooshin Nemati",
        "Emrah Hancer",
        "Serpil Sak",
        "Bilge Ayca Kirmizi",
        "Zeynep Yildirim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:19:05+00:00",
          "link": "https://arxiv.org/abs/2507.14271v1",
          "size": "287kb",
          "version": "v1"
        }
      ],
      "title": "MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14271",
        "PDF": "https://arxiv.org/pdf/2507.14271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about the creation of a dataset for mitosis detection and segmentation in breast cancer images, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14728",
      "abstract": "This study introduces and addresses the critical challenge of traffic load estimation in cell switching within vertical heterogeneous networks. The effectiveness of cell switching is significantly limited by the lack of accurate traffic load data for small base stations (SBSs) in sleep mode, making many load-dependent energy-saving approaches impractical, as they assume perfect knowledge of traffic loads, an assumption that is unrealistic when SBSs are inactive. In other words, when SBSs are in sleep mode, their traffic loads cannot be directly known and can only be estimated, inevitably with corresponding errors. Rather than proposing a new switching algorithm, we focus on eliminating this foundational barrier by exploring effective prediction techniques. A novel vertical heterogeneous network model is considered, integrating a high-altitude platform station (HAPS) as a super macro base station (SMBS). We investigate both spatial and temporal load estimation approaches, including three spatial interpolation schemes, random neighboring selection, distance based selection, and multi level clustering (MLC), alongside a temporal deep learning method based on long short-term memory (LSTM) networks. Using a real world dataset for empirical validation, our results show that both spatial and temporal methods significantly improve estimation accuracy, with the MLC and LSTM approaches demonstrating particularly strong performance.",
      "authors": [
        "Maryam Salamatmoghadasi",
        "Metin Ozturk",
        "Halim Yanikomeroglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:27:57+00:00",
          "link": "https://arxiv.org/abs/2507.14728v1",
          "size": "1805kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Sustainability in HAPS-Assisted 6G Networks: Load Estimation Aware Cell Switching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14728",
        "HTML": "https://arxiv.org/html/2507.14728",
        "PDF": "https://arxiv.org/pdf/2507.14728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses traffic load estimation in network configurations, not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15112",
      "abstract": "Machine unlearning seeks to remove unwanted information from trained models, initially at the individual-sample level, but increasingly at the level of entire sub-populations. In many deployments, models must delete whole topical domains to satisfy privacy, legal, or quality requirements, e.g., removing several users' posts under GDPR or copyrighted web content. Existing unlearning tools remain largely sample-oriented, and straightforward point deletion often leaves enough residual signal for downstream learners to recover the unwanted domain. We introduce distributional unlearning, a data-centric, model-agnostic framework that asks: Given examples from an unwanted distribution and a retained distribution, what is the smallest set of points whose removal makes the edited dataset far from the unwanted domain yet close to the retained one? Using Kullback-Leibler divergence to quantify removal and preservation, we derive the exact Pareto frontier in the Gaussian case and prove that any model retrained on the edited data incurs log-loss shifts bounded by the divergence thresholds. We propose a simple distance-based selection rule satisfying these constraints with a quadratic reduction in deletion budget compared to random removal. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam, and CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on retained performance.",
      "authors": [
        "Youssef Allouah",
        "Rachid Guerraoui",
        "Sanmi Koyejo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:21:23+00:00",
          "link": "https://arxiv.org/abs/2507.15112v1",
          "size": "2092kb",
          "version": "v1"
        }
      ],
      "title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15112",
        "HTML": "https://arxiv.org/html/2507.15112",
        "PDF": "https://arxiv.org/pdf/2507.15112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on machine unlearning for forgetting unwanted distributions, primarily dealing with privacy and legal compliance rather than improving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15362",
      "abstract": "Besides the center of inertia (COI) frequency dynamics addressed in Part I, the spatial frequency variation in power systems with grid-following (GFL) converters is also crucial. Part II revisits the effect of GFLs on frequency spatial variation. Leveraging the interfacing state variables and equivalent frequency defined in Part I, an extended frequency divider (FD) formula is proposed. The linearized mapping relationship between network node frequency and synchronous generator (SG) rotor frequency, as well as GFL equivalent frequency, is modeled. The superposition contribution from GFLs is determined by the electrical distance between the generator and the frequency observation node, as well as the system power flow conditions. Additionally, the frequency mapping for branch currents, which is overlooked in previous research, is addressed. Simulation results validate the accuracy of the proposed extended FD formula. They quantitatively demonstrate that the superposition contribution of GFLs to node frequency is relatively weak and that the superposition coefficient is time-varying. The branch frequency superposition reveals a complex and distinctly different pattern.",
      "authors": [
        "Jiahao Liu",
        "Cheng Wang",
        "Tianshu Bi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:15:38+00:00",
          "link": "https://arxiv.org/abs/2507.15362v1",
          "size": "5830kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting the Effect of Grid-Following Converter on Frequency Dynamics -- Part II: Spatial Variation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15362",
        "HTML": "https://arxiv.org/html/2507.15362",
        "PDF": "https://arxiv.org/pdf/2507.15362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Similar to Part I, this paper discusses grid-following converters in power systems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15797",
      "abstract": "We introduce a novel deterministic quantum search algorithm that provides a practical alternative to conventional probabilistic search approaches. Our scheme eliminates the inherent uncertainty of quantum search without relying on arbitrary phase rotations, a key limitation of other deterministic methods. The algorithm achieves certainty by recursively expanding the base oracle so that it marks all states prefixed by the same two bits as the target, encompassing exactly one-quarter of the search space. This enables a step-by-step reduction of the superposition until the target state can be measured with certainty. The algorithm achieves deterministic success with a query complexity of $O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$, falling between Grover's $O(\\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively on two-qubit nearest-neighbour diffusion operators, avoiding global diffusion entirely. We show that, despite the increased query complexity, this design reduces the total number of two-qubit gates required for diffusion by more than an order of magnitude for search spaces up to at least 18 qubits, with even greater advantages on hardware with limited qubit connectivity. The scheme's inherent determinism, reliance on simple nearest-neighbour, low-depth operations, and scalable recursive structure make it well-suited for hardware implementation. Additionally, we show that the algorithm naturally supports partial database search, enabling deterministic identification of selected target bits without requiring a full search, further broadening its applicability.",
      "authors": [
        "John Burke and Ciaran McGoldrick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.15797v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Deterministic Quantum Search via Recursive Oracle Expansion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15797",
        "HTML": "https://arxiv.org/html/2507.15797",
        "PDF": "https://arxiv.org/pdf/2507.15797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a quantum search algorithm and does not discuss any aspects of LLM training data processing, focusing instead on search optimization and computational efficiency."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.16148",
      "abstract": "Prompt-based language models like GPT4 and LLaMa have been used for a wide variety of use cases such as simulating agents, searching for information, or for content analysis. For all of these applications and others, political biases in these models can affect their performance. Several researchers have attempted to study political bias in language models using evaluation suites based on surveys, such as the Political Compass Test (PCT), often finding a particular leaning favored by these models. However, there is some variation in the exact prompting techniques, leading to diverging findings, and most research relies on constrained-answer settings to extract model responses. Moreover, the Political Compass Test is not a scientifically valid survey instrument. In this work, we contribute a political bias measured informed by political science theory, building on survey design principles to test a wide variety of input prompts, while taking into account prompt sensitivity. We then prompt 11 different open and commercial models, differentiating between instruction-tuned and non-instruction-tuned models, and automatically classify their political stances from 88,110 responses. Leveraging this dataset, we compute political bias profiles across different prompt variations and find that while PCT exaggerates bias in certain models like GPT3.5, measures of political bias are often unstable, but generally more left-leaning for instruction-tuned models. Code and data are available on: https://github.com/MaFa211/theory_grounded_pol_bias",
      "authors": [
        "Mats Faulborn",
        "Indira Sen",
        "Max Pellert",
        "Andreas Spitz",
        "and David Garcia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T13:51:06+00:00",
          "link": "https://arxiv.org/abs/2503.16148v1",
          "size": "610kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T19:32:30+00:00",
          "link": "https://arxiv.org/abs/2503.16148v2",
          "size": "166kb",
          "version": "v2"
        }
      ],
      "title": "Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16148",
        "HTML": "https://arxiv.org/html/2503.16148",
        "PDF": "https://arxiv.org/pdf/2503.16148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on measuring political bias in language models and does not discuss training data processing methodologies or data engineering operations related to LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.13982",
      "abstract": "Effectively utilizing multi-sensory data is important for robots to generalize across diverse tasks. However, the heterogeneous nature of these modalities makes fusion challenging. Existing methods propose strategies to obtain comprehensively fused features but often ignore the fact that each modality requires different levels of attention at different manipulation stages. To address this, we propose a force-guided attention fusion module that adaptively adjusts the weights of visual and tactile features without human labeling. We also introduce a self-supervised future force prediction auxiliary task to reinforce the tactile modality, improve data imbalance, and encourage proper adjustment. Our method achieves an average success rate of 93% across three fine-grained, contactrich tasks in real-world experiments. Further analysis shows that our policy appropriately adjusts attention to each modality at different manipulation stages. The videos can be viewed at https://adaptac-dex.github.io/.",
      "authors": [
        "Jinzhou Li",
        "Tianhao Wu",
        "Jiyao Zhang",
        "Zeyuan Chen",
        "Haotian Jin",
        "Mingdong Wu",
        "Yujun Shen",
        "Yaodong Yang",
        "Hao Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T06:29:20+00:00",
          "link": "https://arxiv.org/abs/2505.13982v1",
          "size": "4146kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:10:44+00:00",
          "link": "https://arxiv.org/abs/2505.13982v2",
          "size": "3689kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13982",
        "HTML": "https://arxiv.org/html/2505.13982",
        "PDF": "https://arxiv.org/pdf/2505.13982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on adaptive visuo-tactile fusion for dexterous manipulation, which pertains to robotics and sensor data fusion, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12403",
      "abstract": "Limited infrastructure, scarce educational resources, and unreliable internet access often hinder physics and photonics education in underdeveloped regions. These barriers create deep inequities in Science, Technology, Engineering, and Mathematics (STEM) education. This article explores how Small Language Models (SLMs)-compact, AI-powered tools that can run offline on low-power devices, offering a scalable solution. By acting as virtual tutors, enabling native-language instruction, and supporting interactive learning, SLMs can help address the shortage of trained educators and laboratory access. By narrowing the digital divide through targeted investment in AI technologies, SLMs present a scalable and inclusive solution to advance STEM education and foster scientific empowerment in marginalized communities.",
      "authors": [
        "Asghar Ghorbani",
        "Hanieh Fattahi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics Education (physics.ed-ph)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T08:41:05+00:00",
          "link": "https://arxiv.org/abs/2506.12403v1",
          "size": "4785kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:03:53+00:00",
          "link": "https://arxiv.org/abs/2506.12403v2",
          "size": "4147kb",
          "version": "v2"
        }
      ],
      "title": "Bridging the Digital Divide: Small Language Models as a Pathway for Physics and Photonics Education in Underdeveloped Regions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12403",
        "HTML": "https://arxiv.org/html/2506.12403",
        "PDF": "https://arxiv.org/pdf/2506.12403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Small Language Models as educational tools in underdeveloped regions. It doesn't address training data processing or contribute technically to data processes for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14242",
      "abstract": "While Artificial Intelligence (AI) is not a new field, recent developments, especially with the release of generative tools like ChatGPT, have brought it to the forefront of the minds of industry workers and academic folk alike. There is currently much talk about AI and its ability to reshape many everyday processes as we know them through automation. It also allows users to expand their ideas by suggesting things they may not have thought of on their own and provides easier access to information. However, not all of the changes this technology will bring or has brought so far are positive; this is why it is extremely important for all modern people to recognize and understand the risks before using these tools and allowing them to cause harm. This work takes a position on better understanding many equity concerns and the spread of misinformation that result from new AI, in this case, specifically ChatGPT and deepfakes, and encouraging collaboration with law enforcement, developers, and users to reduce harm. Considering many academic sources, it warns against these issues, analyzing their cause and impact in fields including healthcare, education, science, academia, retail, and finance. Lastly, we propose a set of future-facing guidelines and policy considerations to solve these issues while still enabling innovation in these fields, this responsibility falling upon users, developers, and government entities.",
      "authors": [
        "Prerana Khatiwada",
        "Grace Donaher",
        "Jasymyn Navarro",
        "Lokesh Bhatta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T21:19:47+00:00",
          "link": "https://arxiv.org/abs/2507.14242v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Culling Misinformation from Gen AI: Toward Ethical Curation and Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14242",
        "HTML": "https://arxiv.org/html/2507.14242",
        "PDF": "https://arxiv.org/pdf/2507.14242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses equity concerns and misinformation in generative AI, focusing on ethical implications and policy considerations rather than technical contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14440",
      "abstract": "This paper is concerned with an inverse moving point source problem in electromagnetics. The aim is to reconstruct the moving orbit from the tangential components of magnetic fields taken at a finite number of observation points. The distance function between each observation point and the moving point source is computed by solving a nonlinear ordinary differential equation with an initial value. This ODE system only involves the measurement data from the tangential trace of the magnetic field at observation points. As a consequence, the dynamical measurement data recorded at four non-coplanar points are sufficient to reconstruct the orbit function. A Lipschitz stability is established for the inverse problem, and numerical experiments are reported to demonstrate the effectiveness of the proposed method. Numerical examples have shown that the reconstructed error depends linearly on the noise level and that the wave speed is a critical factor affecting the relative error.",
      "authors": [
        "Minghui Li",
        "Guanghui Hu",
        "and Yue Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:33:17+00:00",
          "link": "https://arxiv.org/abs/2507.14440v1",
          "size": "2754kb",
          "version": "v1"
        }
      ],
      "title": "An inverse moving point source problem in electromagnetics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14440",
        "HTML": "https://arxiv.org/html/2507.14440",
        "PDF": "https://arxiv.org/pdf/2507.14440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a problem in electromagnetics related to reconstructing the orbit of a moving point source from observation data. It does not pertain to LLM training data processing or any relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14470",
      "abstract": "Reserve prices are widely used in practice. The problem of designing revenue-optimal auctions based on reserve price has drawn much attention in the auction design community. Although they have been extensively studied, most developments rely on the significant assumption that the target audience of the sale is directly reachable by the auctioneer, while a large portion of bidders in the economic network unaware of the sale are omitted. This work follows the diffusion auction design, which aims to extend the target audience of optimal auction theory to all entities in economic networks. We investigate the design of simple and provably near-optimal network auctions via reserve price. Using Bayesian approximation analysis, we provide a simple and explicit form of the reserve price function tailored to the most representative network auction. We aim to balance setting a sufficiently high reserve price to induce high revenue in a successful sale, and attracting more buyers from the network to increase the probability of a successful sale. This reserve price function preserves incentive compatibility for network auctions, allowing the seller to extract additional revenue beyond that achieved by the Myerson optimal auction. Specifically, if the seller has $\\rho$ direct neighbours in a network of size $n$, this reserve price guarantees a $1-{1 \\over \\rho}$ approximation to the theoretical upper bound, i.e., the maximum possible revenue from any network of size $n$. This result holds for any size and any structure of the networked market.",
      "authors": [
        "Yifan Huang",
        "Dong Hao",
        "Zhiyi Fan",
        "Yuhang Guo",
        "Bin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:04:09+00:00",
          "link": "https://arxiv.org/abs/2507.14470v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "Approximate Revenue Maximization for Diffusion Auctions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14470",
        "HTML": "https://arxiv.org/html/2507.14470",
        "PDF": "https://arxiv.org/pdf/2507.14470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses diffusion auctions and revenue maximization in economic networks, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14485",
      "abstract": "Completing the whole 3D structure based on an incomplete point cloud is a challenging task, particularly when the residual point cloud lacks typical structural characteristics. Recent methods based on cross-modal learning attempt to introduce instance images to aid the structure feature learning. However, they still focus on each particular input class, limiting their generation abilities. In this work, we propose a novel retrieval-augmented point cloud completion framework. The core idea is to incorporate cross-modal retrieval into completion task to learn structural prior information from similar reference samples. Specifically, we design a Structural Shared Feature Encoder (SSFE) to jointly extract cross-modal features and reconstruct reference features as priors. Benefiting from a dual-channel control gate in the encoder, relevant structural features in the reference sample are enhanced and irrelevant information interference is suppressed. In addition, we propose a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical feature fusion mechanism to integrate reference prior information with input features from global to local. Through extensive evaluations on multiple datasets and real-world scenes, our method shows its effectiveness in generating fine-grained point clouds, as well as its generalization capability in handling sparse data and unseen categories.",
      "authors": [
        "Hongye Hou and Liu Zhan and Yang Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:57:41+00:00",
          "link": "https://arxiv.org/abs/2507.14485v1",
          "size": "4977kb",
          "version": "v1"
        }
      ],
      "title": "Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14485",
        "HTML": "https://arxiv.org/html/2507.14485",
        "PDF": "https://arxiv.org/pdf/2507.14485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a retrieval-augmented approach for 3D point cloud completion, which focuses on cross-modal learning and structural feature extraction, not applicable to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15444",
      "abstract": "Autonomous quadrotor flight in confined spaces such as pipes and tunnels presents significant challenges due to unsteady, self-induced aerodynamic disturbances. Very recent advances have enabled flight in such conditions, but they either rely on constant motion through the pipe to mitigate airflow recirculation effects or suffer from limited stability during hovering. In this work, we present the first closed-loop control system for quadrotors for hovering in narrow pipes that leverages real-time flow field measurements. We develop a low-latency, event-based smoke velocimetry method that estimates local airflow at high temporal resolution. This flow information is used by a disturbance estimator based on a recurrent convolutional neural network, which infers force and torque disturbances in real time. The estimated disturbances are integrated into a learning-based controller trained via reinforcement learning. The flow-feedback control proves particularly effective during lateral translation maneuvers in the pipe cross-section. There, the real-time disturbance information enables the controller to effectively counteract transient aerodynamic effects, thereby preventing collisions with the pipe wall. To the best of our knowledge, this work represents the first demonstration of an aerial robot with closed-loop control informed by real-time flow field measurements. This opens new directions for research on flight in aerodynamically complex environments. In addition, our work also sheds light on the characteristic flow structures that emerge during flight in narrow, circular pipes, providing new insights at the intersection of robotics and fluid dynamics.",
      "authors": [
        "Leonard Bauersfeld and Davide Scaramuzza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:53:42+00:00",
          "link": "https://arxiv.org/abs/2507.15444v1",
          "size": "2173kb",
          "version": "v1"
        }
      ],
      "title": "Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15444",
        "HTML": "https://arxiv.org/html/2507.15444",
        "PDF": "https://arxiv.org/pdf/2507.15444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on autonomous quadrotor flight control using real-time flow field measurements, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.09693",
      "abstract": "The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed approaches show great promise in achieving symbiotic unions of neural and symbolic methods. However, a unifying framework is needed to organize common NeSy modeling patterns and develop general learning approaches. In this paper, we introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying mathematical framework for discriminative and generative NeSy modeling. Importantly, NeSy-EBMs allow the derivation of general expressions for gradients of prominent learning losses, and we introduce a suite of four learning approaches that leverage methods from multiple domains, including bilevel and stochastic policy optimization. Finally, we ground the NeSy-EBM framework with Neural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library designed for scalability and expressivity, facilitating the real-world application of NeSy systems. Through extensive empirical analysis across multiple datasets, we demonstrate the practical advantages of NeSy-EBMs in various tasks, including image classification, graph node labeling, autonomous vehicle situation awareness, and question answering.",
      "authors": [
        "Charles Dickens",
        "Connor Pryor",
        "Changyu Gao",
        "Alon Albalak",
        "Eriq Augustine",
        "William Wang",
        "Stephen Wright",
        "and Lise Getoor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-12T21:26:21+00:00",
          "link": "https://arxiv.org/abs/2407.09693v1",
          "size": "4086kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:37:41+00:00",
          "link": "https://arxiv.org/abs/2407.09693v2",
          "size": "2215kb",
          "version": "v2"
        }
      ],
      "title": "A Mathematical Framework and a Suite of Learning Techniques for Neural-Symbolic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09693",
        "PDF": "https://arxiv.org/pdf/2407.09693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on Neural-Symbolic systems and does not cover LLM training data processing concerning data collection, quality improvement, or dataset creation."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/linqs/dickens-arxiv24"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06268",
      "abstract": "Power system networks are often modeled as homogeneous graphs, which limits the ability of graph neural network (GNN) to capture individual generator features at the same nodes. By introducing the proposed virtual node-splitting strategy, generator-level attributes like costs, limits, and ramp rates can be fully captured by GNN models, improving GNN's learning capacity and prediction accuracy. Optimal power flow (OPF) problem is used for real-time grid operations. Limited timeframe motivates studies to create size-reduced OPF (ROPF) models to relieve the computational complexity. In this paper, with virtual node-splitting, a novel two-stage adaptive hierarchical GNN is developed to (i) predict critical lines that would be congested, and then (ii) predict base generators that would operate at the maximum capacity. This will substantially reduce the constraints and variables needed for OPF, creating the proposed ROPFLG model with reduced monitor lines and reduced generator-specific variables and constraints. Two ROPF models, ROPFL and ROPFG, with just reduced lines or generators respectively, are also implemented as additional benchmark models. Case studies show that the proposed ROPFLG consistently outperforms the benchmark full OPF (FOPF) and the other two ROPF methods, achieving significant computational time savings while reliably finding optimal solutions.",
      "authors": [
        "Thuan Pham",
        "Xingpeng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T19:46:28+00:00",
          "link": "https://arxiv.org/abs/2411.06268v1",
          "size": "435kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T04:57:08+00:00",
          "link": "https://arxiv.org/abs/2411.06268v2",
          "size": "402kb",
          "version": "v2"
        }
      ],
      "title": "Constraints and Variables Reduction for Optimal Power Flow Using Hierarchical Graph Neural Networks with Virtual Node-Splitting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06268",
        "PDF": "https://arxiv.org/pdf/2411.06268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying graph neural networks to optimize power flow in electrical networks, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14552",
      "abstract": "Ontology evaluation through functional requirements, such as testing via competency question (CQ) verification, is a well-established yet costly, labour-intensive, and error-prone endeavour, even for ontology engineering experts. In this work, we introduce OE-Assist, a novel framework designed to assist ontology evaluation through automated and semi-automated CQ verification. By presenting and leveraging a dataset of 1,393 CQs paired with corresponding ontologies and ontology stories, our contributions present, to our knowledge, the first systematic investigation into large language model (LLM)-assisted ontology evaluation, and include: (i) evaluating the effectiveness of a LLM-based approach for automatically performing CQ verification against a manually created gold standard, and (ii) developing and assessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e, by providing suggestions. We found that automated LLM-based evaluation with o1-preview and o3-mini perform at a similar level to the average user's performance.",
      "authors": [
        "Anna Sofia Lippolis",
        "Mohammad Javad Saeedizade",
        "Robin Keskis\\\"arkk\\\"a",
        "Aldo Gangemi",
        "Eva Blomqvist",
        "Andrea Giovanni Nuzzolese"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T09:13:51+00:00",
          "link": "https://arxiv.org/abs/2507.14552v1",
          "size": "1485kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models Assisting Ontology Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14552",
        "HTML": "https://arxiv.org/html/2507.14552",
        "PDF": "https://arxiv.org/pdf/2507.14552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves LLMs in the context of ontology evaluation, its main focus is on automated CQ verification, not on LLM training data processing. It includes some dataset creation for evaluation purposes, hence the 'partial' relevance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14713",
      "abstract": "As drones increasingly deliver packages in neighborhoods, concerns about collisions arise. One solution is to share flight paths within a specific zip code, but this compromises business privacy by revealing delivery routes. For example, it could disclose which stores send packages to certain addresses. To avoid exposing path information, we propose using homomorphic encryption-based comparison to compute path intersections. This allows drones to identify potential collisions without revealing path and destination details, allowing them to adjust altitude to avoid crashes. We implemented and tested our approach on resource-limited virtual machines to mimic the computational power of drones. Our results demonstrate that our method is significantly faster and requires less network communication compared to a garbled circuit-based approach. We also provide a security analysis of the approach against potential attacks.",
      "authors": [
        "Allan Luedeman",
        "Nicholas Baum",
        "Andrew Quijano",
        "Kemal Akkaya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:16:02+00:00",
          "link": "https://arxiv.org/abs/2507.14713v1",
          "size": "193kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Drone Navigation Through Homomorphic Encryption for Collision Avoidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14713",
        "HTML": "https://arxiv.org/html/2507.14713",
        "PDF": "https://arxiv.org/pdf/2507.14713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses privacy-preserving drone navigation using homomorphic encryption, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15158",
      "abstract": "As artificial intelligence continues to push into real-time, edge-based and resource-constrained environments, there is an urgent need for novel, hardware-efficient computational models. In this study, we present and validate a neuromorphic computing architecture based on resonant-tunnelling diodes (RTDs), which exhibit the nonlinear characteristics ideal for physical reservoir computing (RC). We theoretically formulate and numerically implement an RTD-based RC system and demonstrate its effectiveness on two image recognition benchmarks: handwritten digit classification and object recognition using the Fruit~360 dataset. Our results show that this circuit-level architecture delivers promising performance while adhering to the principles of next-generation RC -- eliminating random connectivity in favour of a deterministic nonlinear transformation of input signals.",
      "authors": [
        "A. H. Abbas",
        "Hend Abdel-Ghani",
        "and Ivan S. Maksymov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:50:32+00:00",
          "link": "https://arxiv.org/abs/2507.15158v1",
          "size": "2521kb",
          "version": "v1"
        }
      ],
      "title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15158",
        "HTML": "https://arxiv.org/html/2507.15158",
        "PDF": "https://arxiv.org/pdf/2507.15158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research concerns a neuromorphic computing architecture for image recognition, without any mention of data processing techniques or applications related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15616",
      "abstract": "Spin glasses are fundamental probability distributions at the core of statistical physics, the theory of average-case computational complexity, and modern high-dimensional statistical inference. In the mean-field setting, we design deterministic quasipolynomial-time algorithms for estimating the partition function to arbitrarily high accuracy for nearly all inverse temperatures in the second moment regime. In particular, for the Sherrington--Kirkpatrick model, our algorithms succeed for almost the entire replica-symmetric phase. To achieve this, we study the locations of the zeros of the partition function. Notably, our methods are conceptually simple, and apply equally well to the spherical case and the case of Ising spins.",
      "authors": [
        "Ferenc Bencs",
        "Kuikui Liu",
        "Guus Regts"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Discrete Mathematics (cs.DM)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:41:07+00:00",
          "link": "https://arxiv.org/abs/2507.15616v1",
          "size": "684kb",
          "version": "v1"
        }
      ],
      "title": "On zeros and algorithms for disordered systems: mean-field spin glasses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15616",
        "PDF": "https://arxiv.org/pdf/2507.15616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered on algorithms for estimating the partition function in statistical physics models like spin glasses. It does not relate to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15816",
      "abstract": "Federated learning (FL) is one of the popular distributed machine learning (ML) solutions but incurs significant communication and computation costs at edge devices. Federated split learning (FSL) can train sub-models in parallel and reduce the computational burden of edge devices by splitting the model architecture. However, it still requires a high communication overhead due to transmitting the smashed data and gradients between clients and the server in every global round. Furthermore, the server must maintain separate partial models for every client, leading to a significant storage requirement. To address these challenges, this paper proposes a novel communication and storage efficient federated split learning method, termed CSE-FSL, which utilizes an auxiliary network to locally update the weights of the clients while keeping a single model at the server, hence avoiding frequent transmissions of gradients from the server and greatly reducing the storage requirement of the server. Additionally, a new model update method of transmitting the smashed data in selected epochs can reduce the amount of smashed data sent from the clients. We provide a theoretical analysis of CSE-FSL, rigorously guaranteeing its convergence under non-convex loss functions. The extensive experimental results further indicate that CSE-FSL achieves a significant communication reduction over existing FSL solutions using real-world FL tasks.",
      "authors": [
        "Yujia Mu",
        "Cong Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:21:16+00:00",
          "link": "https://arxiv.org/abs/2507.15816v1",
          "size": "2500kb",
          "version": "v1"
        }
      ],
      "title": "Federated Split Learning with Improved Communication and Storage Efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15816",
        "HTML": "https://arxiv.org/html/2507.15816",
        "PDF": "https://arxiv.org/pdf/2507.15816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes improvements in federated split learning to enhance communication and storage efficiency. It does not discuss LLM training data processing but focuses on the technicalities of federated learning architectures."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19993",
      "abstract": "This paper presents a novel data-driven approach for approximating the $\\varepsilon$-Nash equilibrium in continuous-time linear quadratic Gaussian (LQG) games, where multiple agents interact with each other through their dynamics and infinite horizon discounted costs. The core of our method involves solving two algebraic Riccati equations (AREs) and an ordinary differential equation (ODE) using state and input samples collected from agents, eliminating the need for a priori knowledge of their dynamical models. The standard ARE is addressed through an integral reinforcement learning (IRL) technique, while the nonsymmetric ARE and the ODE are resolved by identifying the drift coefficients of the agents' dynamics under general conditions. Moreover, by imposing specific conditions on models, we extend the IRL-based approach to approximately solve the nonsymmetric ARE. Numerical examples are given to demonstrate the effectiveness of the proposed algorithms.",
      "authors": [
        "Zhenhui Xu",
        "Jiayu Chen",
        "Bing-Chang Wang",
        "Tielong Shen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T11:20:02+00:00",
          "link": "https://arxiv.org/abs/2502.19993v1",
          "size": "5788kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T13:52:10+00:00",
          "link": "https://arxiv.org/abs/2502.19993v2",
          "size": "2258kb",
          "version": "v2"
        }
      ],
      "title": "Data-Driven Mean Field Equilibrium Computation in Large-Population LQG Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19993",
        "HTML": "https://arxiv.org/html/2502.19993",
        "PDF": "https://arxiv.org/pdf/2502.19993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on data-driven approaches to compute mean field equilibrium in LQG games, which is unrelated to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.14159",
      "abstract": "Percolation theory serves as a cornerstone for studying phase transitions and critical phenomena, with broad implications in statistical physics, materials science, and complex networks. However, most machine learning frameworks for percolation analysis have focused on two-dimensional systems, oversimplifying the spatial correlations and morphological complexity of real-world three-dimensional materials. To bridge this gap and improve label efficiency and scalability in 3D systems, we propose a Siamese Neural Network (SNN) that leverages features of the largest cluster as discriminative input. Our method achieves high predictive accuracy for both site and bond percolation thresholds and critical exponents in three dimensions, with sub-1% error margins using significantly fewer labeled samples than traditional approaches. This work establishes a robust and data-efficient framework for modeling high-dimensional critical phenomena, with potential applications in materials discovery and complex network analysis.",
      "authors": [
        "Shanshan Wang",
        "Dian Xu",
        "Jianmin Shen",
        "Feng Gao",
        "Wei Li",
        "Weibing Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T09:51:26+00:00",
          "link": "https://arxiv.org/abs/2507.14159v1",
          "size": "21511kb",
          "version": "v1"
        }
      ],
      "title": "Siamese Neural Network for Label-Efficient Critical Phenomena Prediction in 3D Percolation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14159",
        "HTML": "https://arxiv.org/html/2507.14159",
        "PDF": "https://arxiv.org/pdf/2507.14159"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a Siamese Neural Network for predicting percolation thresholds in 3D models, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14266",
      "abstract": "Over the past decade, higher education has evolved through three distinct paradigms: the emergence of Massive Open Online Courses (MOOCs), the integration of Smart Teaching technologies into classrooms, and the rise of AI-enhanced learning. Each paradigm is intended to address specific challenges in traditional education: MOOCs enable ubiquitous access to learning resources; Smart Teaching supports real-time interaction with data-driven insights; and generative AI offers personalized feedback and on-demand content generation. However, these paradigms are often implemented in isolation due to their disparate technological origins and policy-driven adoption. This paper examines the origins, strengths, and limitations of each paradigm, and advocates a unified pedagogical perspective that synthesizes their complementary affordances. We propose a three-layer instructional framework that combines the scalability of MOOCs, the responsiveness of Smart Teaching, and the adaptivity of AI. To demonstrate its feasibility, we present a curriculum design for a project-based course. The findings highlight the framework's potential to enhance learner engagement, support instructors, and enable personalized yet scalable learning.",
      "authors": [
        "Bo Yuan",
        "Jiazi Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T14:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.14266v1",
          "size": "675kb",
          "version": "v1"
        }
      ],
      "title": "Bridging MOOCs, Smart Teaching, and AI: A Decade of Evolution Toward a Unified Pedagogy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14266",
        "PDF": "https://arxiv.org/pdf/2507.14266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores educational paradigms over the past decade, focusing on MOOCs, Smart Teaching, and AI-enhanced learning, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14675",
      "abstract": "Despite significant progress in multimodal large language models (MLLMs), their performance on complex, multi-page document comprehension remains inadequate, largely due to the lack of high-quality, document-level datasets. While current retrieval-augmented generation (RAG) methods offer partial solutions, they suffer from issues, such as fragmented retrieval contexts, multi-stage error accumulation, and extra time costs of retrieval. In this work, we present a high-quality document-level dataset, Doc-750K, designed to support in-depth understanding of multimodal documents. This dataset includes diverse document structures, extensive cross-page dependencies, and real question-answer pairs derived from the original documents. Building on the dataset, we develop a native multimodal model, Docopilot, which can accurately handle document-level dependencies without relying on RAG. Experiments demonstrate that Docopilot achieves superior coherence, accuracy, and efficiency in document understanding tasks and multi-turn interactions, setting a new baseline for document-level multimodal understanding. Data, code, and models are released at https://github.com/OpenGVLab/Docopilot",
      "authors": [
        "Yuchen Duan",
        "Zhe Chen",
        "Yusong Hu",
        "Weiyun Wang",
        "Shenglong Ye",
        "Botian Shi",
        "Lewei Lu",
        "Qibin Hou",
        "Tong Lu",
        "Hongsheng Li",
        "Jifeng Dai",
        "Wenhai Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:03:34+00:00",
          "link": "https://arxiv.org/abs/2507.14675v1",
          "size": "5359kb",
          "version": "v1"
        }
      ],
      "title": "Docopilot: Improving Multimodal Models for Document-Level Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14675",
        "HTML": "https://arxiv.org/html/2507.14675",
        "PDF": "https://arxiv.org/pdf/2507.14675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents the high-quality Doc-750K dataset for document-level understanding, enhancing multimodal large language models. It involves the creation of a new dataset, contributing directly to LLM training data processing with improvements in data quality and modeling approaches."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15428",
      "abstract": "Egomotion videos are first-person recordings where the view changes continuously due to the agent's movement. As they serve as the primary visual input for embodied AI agents, making egomotion video reasoning more efficient is therefore essential for real-world deployment. Recent advances in vision-language models have enabled strong multimodal reasoning capabilities, but their computational cost remains prohibitive for long, redundant video inputs. Existing token pruning methods, typically designed for third-person videos, fail to leverage the spatiotemporal continuity and motion constraints inherent in egomotion settings. To address this, we propose EgoPrune, a training-free token pruning method tailored for egomotion video reasoning. EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR for temporally efficient sampling; Perspective-Aware Redundancy Filtering (PARF), which aligns visual tokens using perspective transformations and removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token selector that jointly considers visual-text relevance and intra-frame diversity. Experiments on two egomotion video benchmarks show that EgoPrune consistently outperforms prior training-free methods across various pruning ratios while significantly reducing FLOPs, memory usage, and latency. Moreover, we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB edge device, demonstrating its real-world efficiency and suitability for on-device egomotion video reasoning.",
      "authors": [
        "Jiaao Li",
        "Kaiyuan Li",
        "Chen Gao",
        "Yong Li",
        "Xinlei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:27:45+00:00",
          "link": "https://arxiv.org/abs/2507.15428v1",
          "size": "11232kb",
          "version": "v1"
        }
      ],
      "title": "EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15428",
        "HTML": "https://arxiv.org/html/2507.15428",
        "PDF": "https://arxiv.org/pdf/2507.15428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses token pruning for egomotion video reasoning in embodied agents using existing vision-language models. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15449",
      "abstract": "We consider the multivariate scheme Pesto, which was introduced by Calderini, Caminata, and Villa. In this scheme, the public polynomials are obtained by applying a CCZ transformation to a set of quadratic secret polynomials. As a consequence, the public key consists of polynomials of degree 4. In this work, we show that the public degree 4 polynomial system can be efficiently reduced to a system of quadratic polynomials. This seems to suggest that the CCZ transformation may not offer a significant increase in security, contrary to what was initially believed.",
      "authors": [
        "Alessio Caminata",
        "Elisa Gorla",
        "Madison Mabe",
        "Martina Vigorito",
        "Irene Villa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:01:42+00:00",
          "link": "https://arxiv.org/abs/2507.15449v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Cryptanalysis of a multivariate CCZ scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15449",
        "HTML": "https://arxiv.org/html/2507.15449",
        "PDF": "https://arxiv.org/pdf/2507.15449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cryptanalysis of a multivariate scheme and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.04895",
      "abstract": "For which unary predicates $P_1, \\ldots, P_m$ is the MSO theory of the structure $\\langle \\mathbb{N}; <, P_1, \\ldots, P_m \\rangle$ decidable? We survey the state of the art, leading us to investigate combinatorial properties of almost-periodic, morphic, and toric words. In doing so, we show that if each $P_i$ can be generated by a toric dynamical system of a certain kind, then the attendant MSO theory is decidable.",
      "authors": [
        "Val\\'erie Berth\\'e",
        "Toghrul Karimov",
        "Jo\\\"el Ouaknine",
        "Mihir Vahanwala",
        "James Worrell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-08T18:55:33+00:00",
          "link": "https://arxiv.org/abs/2311.04895v1",
          "size": "529kb",
          "version": "v1"
        },
        {
          "date": "2023-12-15T09:12:53+00:00",
          "link": "https://arxiv.org/abs/2311.04895v2",
          "size": "357kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T15:06:48+00:00",
          "link": "https://arxiv.org/abs/2311.04895v3",
          "size": "359kb",
          "version": "v3"
        }
      ],
      "title": "The Monadic Theory of Toric Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.04895",
        "HTML": "https://arxiv.org/html/2311.04895",
        "PDF": "https://arxiv.org/pdf/2311.04895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the combinatorial properties of toric words and their decidability in logical structures. It does not have any relevance to LLM training data processing as it does not involve data engineering operations or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07901",
      "abstract": "Traffic light detection under adverse weather conditions remains largely unexplored in ADAS systems, with existing approaches relying on complex deep learning methods that introduce significant computational overheads during training and deployment. This paper proposes Fourier Domain Adaptation (FDA), which requires only training data modifications without architectural changes, enabling effective adaptation to rainy and foggy conditions. FDA minimizes the domain gap between source and target domains, creating a dataset for reliable performance under adverse weather.\n  The source domain merged LISA and S2TLD datasets, processed to address class imbalance. Established methods simulated rainy and foggy scenarios to form the target domain. Semi-Supervised Learning (SSL) techniques were explored to leverage data more effectively, addressing the shortage of comprehensive datasets and poor performance of state-of-the-art models under hostile weather.\n  Experimental results show FDA-augmented models outperform baseline models across mAP50, mAP50-95, Precision, and Recall metrics. YOLOv8 achieved a 12.25% average increase across all metrics. Average improvements of 7.69% in Precision, 19.91% in Recall, 15.85% in mAP50, and 23.81% in mAP50-95 were observed across all models, demonstrating FDA's effectiveness in mitigating adverse weather impact. These improvements enable real-world applications requiring reliable performance in challenging environmental conditions.",
      "authors": [
        "Ishaan Gakhar",
        "Aryesh Guha",
        "Aryaman Gupta",
        "Amit Agarwal",
        "Ujjwal Verma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T16:15:25+00:00",
          "link": "https://arxiv.org/abs/2411.07901v1",
          "size": "4916kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T16:51:22+00:00",
          "link": "https://arxiv.org/abs/2411.07901v2",
          "size": "4916kb",
          "version": "v2"
        }
      ],
      "title": "Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07901",
        "PDF": "https://arxiv.org/pdf/2411.07901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on traffic light detection under adverse weather using Fourier Domain Adaptation. It does not discuss any element of LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15265",
      "abstract": "Gradient-based methods are a prototypical family of explainability techniques, especially for image-based models. Nonetheless, they have several shortcomings in that they (1) require white-box access to models, (2) are vulnerable to adversarial attacks, and (3) produce attributions that lie off the image manifold, leading to explanations that are not actually faithful to the model and do not align well with human perception. To overcome these challenges, we introduce Derivative-Free Diffusion Manifold-Constrainted Gradients (FreeMCG), a novel method that serves as an improved basis for explainability of a given neural network than the traditional gradient. Specifically, by leveraging ensemble Kalman filters and diffusion models, we derive a derivative-free approximation of the model's gradient projected onto the data manifold, requiring access only to the model's outputs. We demonstrate the effectiveness of FreeMCG by applying it to both counterfactual generation and feature attribution, which have traditionally been treated as distinct tasks. Through comprehensive evaluation on both tasks, counterfactual explanation and feature attribution, we show that our method yields state-of-the-art results while preserving the essential properties expected of XAI tools.",
      "authors": [
        "Won Jun Kim",
        "Hyungjin Chung",
        "Jaemin Kim",
        "Sangmin Lee",
        "Byeongsu Sim",
        "Jong Chul Ye"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T11:15:14+00:00",
          "link": "https://arxiv.org/abs/2411.15265v1",
          "size": "7569kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T12:56:10+00:00",
          "link": "https://arxiv.org/abs/2411.15265v2",
          "size": "4861kb",
          "version": "v2"
        }
      ],
      "title": "Derivative-Free Diffusion Manifold-Constrained Gradient for Unified XAI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15265",
        "HTML": "https://arxiv.org/html/2411.15265",
        "PDF": "https://arxiv.org/pdf/2411.15265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a derivative-free method for neural network explainability, which does not address LLM training data processing or related data engineering operations."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Kim_Derivative-Free_Diffusion_Manifold-Constrained_Gradient_for_Unified_XAI_CVPR_2025_paper.html",
      "tasks": [
        "counterfactual",
        "Counterfactual Explanation"
      ],
      "repo_urls": [
        "https://github.com/openxaiproject/pnpxai"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01250",
      "abstract": "Character diversity in competitive games, while enriching gameplay, often introduces balance challenges that can negatively impact player experience and strategic depth. Traditional balance assessments rely on aggregate metrics like win rates and pick rates, which offer limited insight into the intricate dynamics of team-based games and nuanced character roles. This paper proposes a novel clustering-based methodology to analyze character balance, leveraging in-game data from Valorant to account for team composition influences and reveal latent character roles. By applying hierarchical agglomerative clustering with Jensen-Shannon Divergence to professional match data from the Valorant Champions Tour 2022, our approach identifies distinct clusters of agents exhibiting similar co-occurrence patterns within team compositions. This method not only complements existing quantitative metrics but also provides a more holistic and interpretable perspective on character synergies and potential imbalances, offering game developers a valuable tool for informed and context-aware balance adjustments.",
      "authors": [
        "Haokun Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T11:20:21+00:00",
          "link": "https://arxiv.org/abs/2502.01250v1",
          "size": "45kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:42:05+00:00",
          "link": "https://arxiv.org/abs/2502.01250v2",
          "size": "801kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Win Rates: A Clustering-Based Approach to Character Balance Analysis in Team-Based Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01250",
        "HTML": "https://arxiv.org/html/2502.01250",
        "PDF": "https://arxiv.org/pdf/2502.01250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses character balance analysis in team-based games using clustering methods, with no mention of or relevance to LLM training data processing, dataset creation, or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13682",
      "abstract": "Thermal imaging can greatly enhance the application of intelligent unmanned aerial vehicles (UAV) in challenging environments. However, the inherent low resolution of thermal sensors leads to insufficient details and blurred boundaries. Super-resolution (SR) offers a promising solution to address this issue, while most existing SR methods are designed for fixed-scale SR. They are computationally expensive and inflexible in practical applications. To address above issues, this work proposes a novel any-scale thermal SR method (AnyTSR) for UAV within a single model. Specifically, a new image encoder is proposed to explicitly assign specific feature code to enable more accurate and flexible representation. Additionally, by effectively embedding coordinate offset information into the local feature ensemble, an innovative any-scale upsampler is proposed to better understand spatial relationships and reduce artifacts. Moreover, a novel dataset (UAV-TSR), covering both land and water scenes, is constructed for thermal SR tasks. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art methods across all scaling factors as well as generates more accurate and detailed high-resolution images. The code is located at https://github.com/vision4robotics/AnyTSR.",
      "authors": [
        "Mengyuan Li",
        "Changhong Fu",
        "Ziyu Lu",
        "Zijie Zhang",
        "Haobo Zuo",
        "Liangliang Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T13:23:25+00:00",
          "link": "https://arxiv.org/abs/2504.13682v1",
          "size": "2311kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:16:12+00:00",
          "link": "https://arxiv.org/abs/2504.13682v2",
          "size": "1255kb",
          "version": "v2"
        }
      ],
      "title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13682",
        "HTML": "https://arxiv.org/html/2504.13682",
        "PDF": "https://arxiv.org/pdf/2504.13682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on thermal super-resolution methods and UAV applications with a novel dataset, but it does not address LLM training data processing or related operations."
      },
      "tasks": [
        "Super-Resolution"
      ],
      "repo_urls": [
        "https://github.com/vision4robotics/anytsr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10019",
      "abstract": "This paper addresses the problem of estimating the containment and similarity between two sets using only random samples from each set, without relying on sketches of full sets. The study introduces a binomial model for predicting the overlap between samples, demonstrating that it is both accurate and practical when sample sizes are small compared to the original sets. The paper compares this model to previous approaches and shows that it provides better estimates under the considered conditions. It also analyzes the statistical properties of the estimator, including error bounds and sample size requirements needed to achieve a desired level of accuracy and confidence. The framework is extended to estimate set similarity, and the paper provides guidance for applying these methods in large scale data systems where only partial or sampled data is available.",
      "authors": [
        "Pranav Joshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Databases (cs.DB)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.10019v1",
          "size": "506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:08:24+00:00",
          "link": "https://arxiv.org/abs/2507.10019v2",
          "size": "545kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T11:14:22+00:00",
          "link": "https://arxiv.org/abs/2507.10019v3",
          "size": "693kb",
          "version": "v3"
        }
      ],
      "title": "Sampling-Based Estimation of Jaccard Containment and Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10019",
        "HTML": "https://arxiv.org/html/2507.10019",
        "PDF": "https://arxiv.org/pdf/2507.10019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses estimation of set containment and similarity using sampling methods. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14723",
      "abstract": "We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile agents in a 1-interval-connected ring network having $n$ nodes and with $l$ agents where $3 \\le l \\le \\lfloor \\frac{n}{k}\\rfloor$, without the assumption of chirality (a common sense of direction for the agents). This generalizes the classical dispersion problem by requiring that agents maintain a minimum distance of $k$ hops from each other, with the special case $k=1$ corresponding to the standard dispersion.\n  The contribution in this work is threefold. Our first contribution is a novel method that enables agents to simulate chirality using only local information, vision and bounded memory. This technique demonstrates that chirality is not a fundamental requirement for coordination in this model.\n  Building on this, our second contribution partially resolves an open question posed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1- interval connected ring, synchronous agents, no chirality). We prove that D-$k$-D, and thus dispersion is solvable from any arbitrary configuration under these assumptions (excluding vertex permutation dynamism)for any size of the ring network which was earlier limited to only odd sized ring or to a ring of size four.\n  Finally, we present an algorithm for D-$k$-D in this setting that works in $O(ln)$ rounds, completing the constructive side of our result.\n  Altogether, our findings significantly extend the theoretical understanding of mobile agent coordination in dynamic networks and clarify the role of chirality in distributed computation.",
      "authors": [
        "Brati Mondal",
        "Pritam Goswami",
        "Buddhadeb Sau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:51:52+00:00",
          "link": "https://arxiv.org/abs/2507.14723v1",
          "size": "582kb",
          "version": "v1"
        }
      ],
      "title": "Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14723",
        "HTML": "https://arxiv.org/html/2507.14723",
        "PDF": "https://arxiv.org/pdf/2507.14723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study addresses a problem in distributed systems regarding mobile agents in networked environments and does not contribute to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14787",
      "abstract": "Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous wavelength bands, making it a powerful tool in biology, agriculture, and environmental monitoring. However, interpreting Vision Transformers (ViTs) in this setting remains largely unexplored due to two key challenges: (1) existing saliency methods struggle to capture meaningful spectral cues, often collapsing attention onto the class token, and (2) full-spectrum ViTs are computationally prohibitive for interpretability, given the high-dimensional nature of HSI data. We present FOCUS, the first framework that enables reliable and efficient spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core components: class-specific spectral prompts that guide attention toward semantically meaningful wavelength groups, and a learnable [SINK] token trained with an attraction loss to absorb noisy or redundant attention. Together, these designs make it possible to generate stable and interpretable 3D saliency maps and spectral importance curves in a single forward pass, without any gradient backpropagation or backbone modification. FOCUS improves band-level IoU by 15 percent, reduces attention collapse by over 40 percent, and produces saliency results that align closely with expert annotations. With less than 1 percent parameter overhead, our method makes high-resolution ViT interpretability practical for real-world hyperspectral applications, bridging a long-standing gap between black-box modeling and trustworthy HSI decision-making.",
      "authors": [
        "Xi Xiao",
        "Aristeidis Tsaris",
        "Anika Tabassum",
        "John Lagergren",
        "Larry M. York",
        "Tianyang Wang",
        "Xiao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:08:23+00:00",
          "link": "https://arxiv.org/abs/2507.14787v1",
          "size": "1426kb",
          "version": "v1"
        }
      ],
      "title": "FOCUS: Fused Observation of Channels for Unveiling Spectra",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14787",
        "HTML": "https://arxiv.org/html/2507.14787",
        "PDF": "https://arxiv.org/pdf/2507.14787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents FOCUS, a framework for interpreting Vision Transformers in hyperspectral imaging, without any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15259",
      "abstract": "This letter develops a novel physics-informed neural ordinary differential equations-based framework to emulate the proprietary dynamics of the inverters -- essential for improved accuracy in grid dynamic simulations. In current industry practice, the original equipment manufacturers (OEMs) often do not disclose the exact internal controls and parameters of the inverters, posing significant challenges in performing accurate dynamic simulations and other relevant studies, such as gain tunings for stability analysis and controls. To address this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM) that integrates system physics with neural learning layers to capture the unmodeled behaviors of proprietary units. The proposed method is validated using a grid-forming inverter (GFM) case study, demonstrating improved dynamic simulation accuracy over approaches that rely solely on data-driven learning without physics-based guidance.",
      "authors": [
        "Kyung-Bin Kwon",
        "Sayak Mukherjee",
        "Ramij R. Hossain",
        "Marcelo Elizondo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:48:31+00:00",
          "link": "https://arxiv.org/abs/2507.15259v1",
          "size": "1219kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15259",
        "HTML": "https://arxiv.org/html/2507.15259",
        "PDF": "https://arxiv.org/pdf/2507.15259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a physics-informed neural ODE framework for grid dynamic simulations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15500",
      "abstract": "The sustainability of the global academic ecosystem relies on researcher demographics and gender balance, yet assessing these dynamics in a timely manner for policy is challenging. Here, we propose a researcher population pyramids framework for tracking global demographic and gender trajectories using publication data. This framework provides a timely snapshot of historical and present demographics and gender balance, revealing three contrasting research systems: Emerging systems (e.g., Arab countries) exhibit high researcher inflows with widening gender gaps in cumulative productivity; Mature systems (e.g., the United States) show modest inflows with narrowing gender gaps; and Rigid systems (e.g., Japan) lag in both. Furthermore, by simulating future scenarios, the framework makes potential trajectories visible. If 2023 demographic patterns persist, Arab countries' systems could resemble mature or even rigid ones by 2050. Our framework provides a robust diagnostic tool for policymakers worldwide to foster sustainable talent pipelines and gender equality in academia.",
      "authors": [
        "Kazuki Nakajima",
        "Takayuki Mizuno"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:05:02+00:00",
          "link": "https://arxiv.org/abs/2507.15500v1",
          "size": "994kb",
          "version": "v1"
        }
      ],
      "title": "Researcher Population Pyramids for Tracking Global Demographic and Gender Trajectories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15500",
        "HTML": "https://arxiv.org/html/2507.15500",
        "PDF": "https://arxiv.org/pdf/2507.15500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a framework for tracking researcher demographics and gender trajectories using publication data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15509",
      "abstract": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based on reinforcement learning fine-tuning has received widespread attention from the community. Previous R1-Style methods mainly focus on mathematical reasoning and code intelligence. It is of great research significance to verify their advantages on more general multimodal data. Chart is an important multimodal data type with rich information, which brings important research challenges in complex reasoning. In this work, we introduce Chart-R1, a chart-domain vision-language model with reinforcement learning fine-tuning to enable complex chart reasoning. To support Chart-R1, we first propose a novel programmatic data synthesis technology to generate high-quality step-by-step chart reasoning data covering single- and multi-subcharts, which makes up for the lack of reasoning data in the chart domain. Then we develop a two-stage training strategy: Chart-COT with step-by-step chain-of-thought supervision, and Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims to decompose complex chart reasoning tasks into fine-grained, understandable subtasks through step-by-step supervision, which lays a good foundation for improving the reasoning level of reinforcement learning. Chart-RFT utilize the typical group relative policy optimization strategy, in which a relatively soft reward is adopted for numerical response to emphasize the numerical sensitivity in the chart domain. We conduct extensive experiments on open-source benchmarks and self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental results show that Chart-R1 has significant advantages compared to chart-domain methods, even comparable to open/closed source large-scale models (\\emph{e.g., GPT-4o, Claude-3.5}).",
      "authors": [
        "Lei Chen",
        "Xuanle Zhao",
        "Zhixiong Zeng",
        "Jing Huang",
        "Yufeng Zhong",
        "Lin Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:22:17+00:00",
          "link": "https://arxiv.org/abs/2507.15509v1",
          "size": "1185kb",
          "version": "v1"
        }
      ],
      "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15509",
        "HTML": "https://arxiv.org/html/2507.15509",
        "PDF": "https://arxiv.org/pdf/2507.15509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Chart-R1, focusing on chart reasoning using reinforcement learning. It mentions programmatic data synthesis for training, touching upon data generation, but focuses primarily on reasoning models rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20913",
      "abstract": "In our prior work, we investigated the minimum fuel consumption of a hybrid electric vehicle (HEV) under a state-of-charge (SOC) balance constraint, assuming perfect SOC measurements and accurate reference speed profiles. The constrained optimal fuel consumption (COFC) problem was addressed using a constrained reinforcement learning (CRL) framework. However, in real-world scenarios, SOC readings are often corrupted by sensor noise, and reference speeds may deviate from actual driving conditions. To account for these imperfections, this study reformulates the COFC problem by explicitly incorporating observational noise in both SOC and reference speed. We adopt a robust CRL approach, where the noise is modeled as a uniform distribution, and employ a structured training procedure to ensure stability. The proposed method is evaluated through simulations on the Toyota Prius hybrid system (THS), using both the New European Driving Cycle (NEDC) and the Worldwide Harmonized Light Vehicles Test Cycle (WLTC). Results show that fuel consumption and SOC constraint satisfaction remain robust across varying noise levels. Furthermore, the analysis reveals that observational noise in SOC and speed can impact fuel consumption to different extents. To the best of our knowledge, this is the first study to explicitly examine how observational noise -- commonly encountered in dynamometer testing and predictive energy control (PEC) applications -- affects constrained optimal fuel consumption in HEVs.",
      "authors": [
        "Shuchang Yan and Haoran Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T10:45:42+00:00",
          "link": "https://arxiv.org/abs/2410.20913v1",
          "size": "7516kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:09:35+00:00",
          "link": "https://arxiv.org/abs/2410.20913v2",
          "size": "1830kb",
          "version": "v2"
        }
      ],
      "title": "Constrained Optimal Fuel Consumption of HEVs under Observational Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20913",
        "HTML": "https://arxiv.org/html/2410.20913",
        "PDF": "https://arxiv.org/pdf/2410.20913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates optimal fuel consumption in hybrid vehicles under observational noise. It does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.02180",
      "abstract": "Capability evaluations are required to understand and regulate AI systems that may be deployed or further developed. Therefore, it is important that evaluations provide an accurate estimation of an AI system's capabilities. However, in numerous cases, previously latent capabilities have been elicited from models, sometimes long after initial release. Accordingly, substantial efforts have been made to develop methods for eliciting latent capabilities from models. In this paper, we evaluate the effectiveness of capability elicitation techniques by intentionally training model organisms -- language models with hidden capabilities that are revealed by a password. We introduce a novel method for training model organisms, based on circuit-breaking, which is more robust to elicitation techniques than standard password-locked models. We focus on elicitation techniques based on prompting and activation steering, and compare these to fine-tuning methods. Prompting techniques can elicit the actual capability of both password-locked and circuit-broken model organisms in the MCQA setting, while steering fails to do so. For a code-generation task, only fine-tuning can elicit the hidden capabilities of our novel model organism. Additionally, our results suggest that combining techniques improves elicitation. Still, if possible, fine-tuning should be the method of choice to improve the trustworthiness of capability evaluations.",
      "authors": [
        "Felix Hofst\\\"atter and Teun van der Weij and Jayden Teoh and Rada Djoneva and Henning Bartsch and Francis Rhys Ward"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T09:54:24+00:00",
          "link": "https://arxiv.org/abs/2502.02180v1",
          "size": "6491kb",
          "version": "v1"
        },
        {
          "date": "2025-02-24T18:51:21+00:00",
          "link": "https://arxiv.org/abs/2502.02180v2",
          "size": "7813kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T19:01:58+00:00",
          "link": "https://arxiv.org/abs/2502.02180v3",
          "size": "1715kb",
          "version": "v3"
        }
      ],
      "title": "The Elicitation Game: Evaluating Capability Elicitation Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02180",
        "HTML": "https://arxiv.org/html/2502.02180",
        "PDF": "https://arxiv.org/pdf/2502.02180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates capability elicitation techniques for language models and discusses methods like fine-tuning, yet its primary focus is on evaluating latent capabilities rather than directly contributing to data processing or dataset creation."
      },
      "tasks": [
        "Code Generation"
      ],
      "repo_urls": [
        "https://github.com/Felhof/sandbagging-elicitation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08366",
      "abstract": "We propose a new problem, In-2-4D, for generative 4D (i.e., 3D + motion) inbetweening from a minimalistic input setting: two single-view images capturing an object in two distinct motion states. Given two images representing the start and end states of an object in motion, our goal is to generate and reconstruct the motion in 4D. We utilize a video interpolation model to predict the motion, but large frame-to-frame motions can lead to ambiguous interpretations. To overcome this, we employ a hierarchical approach to identify keyframes that are visually close to the input states and show significant motion, then generate smooth fragments between them. For each fragment, we construct the 3D representation of the keyframe using Gaussian Splatting. The temporal frames within the fragment guide the motion, enabling their transformation into dynamic Gaussians through a deformation field. To improve temporal consistency and refine 3D motion, we expand the self-attention of multi-view diffusion across timesteps and apply rigid transformation regularization. Finally, we merge the independently generated 3D motion segments by interpolating boundary deformation fields and optimizing them to align with the guiding video, ensuring smooth and flicker-free transitions. Through extensive qualitative and quantitiave experiments as well as a user study, we show the effectiveness of our method and its components. The project page is available at https://in-2-4d.github.io/",
      "authors": [
        "Sauradip Nag",
        "Daniel Cohen-Or",
        "Hao Zhang",
        "Ali Mahdavi-Amiri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T09:01:09+00:00",
          "link": "https://arxiv.org/abs/2504.08366v1",
          "size": "37302kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:49:56+00:00",
          "link": "https://arxiv.org/abs/2504.08366v2",
          "size": "36488kb",
          "version": "v2"
        }
      ],
      "title": "In-2-4D: Inbetweening from Two Single-View Images to 4D Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08366",
        "HTML": "https://arxiv.org/html/2504.08366",
        "PDF": "https://arxiv.org/pdf/2504.08366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses 4D generation from images, focusing on video interpolation and motion reconstruction, lacking any mention of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.17768",
      "abstract": "While recent advances in image editing have enabled impressive visual synthesis capabilities, current methods remain constrained by explicit textual instructions and limited editing operations, lacking deep comprehension of implicit user intentions and contextual reasoning. In this work, we introduce a new image editing paradigm: reasoning-guided generative editing, which synthesizes images based on complex, multi-faceted textual queries accepting world knowledge and intention inference. To facilitate this task, we first construct a comprehensive dataset featuring over 1,000 image-instruction-edit triples that incorporate rich reasoning contexts and real-world knowledge. We then propose R-Genie: a reasoning-guided generative image editor, which synergizes the generation power of diffusion models with advanced reasoning capabilities of multimodal large language models. R-Genie incorporates a reasoning-attention mechanism to bridge linguistic understanding with visual synthesis, enabling it to handle intricate editing requests involving abstract user intentions and contextual reasoning relations. Extensive experimental results validate that R-Genie can equip diffusion models with advanced reasoning-based editing capabilities, unlocking new potentials for intelligent image synthesis.",
      "authors": [
        "Dong Zhang",
        "Lingfeng He",
        "Rui Yan",
        "Fei Shen",
        "Jinhui Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T11:41:26+00:00",
          "link": "https://arxiv.org/abs/2505.17768v1",
          "size": "38903kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T01:08:18+00:00",
          "link": "https://arxiv.org/abs/2505.17768v2",
          "size": "38903kb",
          "version": "v2"
        }
      ],
      "title": "R-Genie: Reasoning-Guided Generative Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17768",
        "HTML": "https://arxiv.org/html/2505.17768",
        "PDF": "https://arxiv.org/pdf/2505.17768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reasoning-guided generative image editing and the development of a new paradigm for image synthesis. It does not address LLM training data processing, as it primarily deals with image editing and multimodal models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15104",
      "abstract": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize analog design automation through data-driven approaches. In particular, researchers are increasingly fascinated by harnessing the power of generative AI to automate the discovery of novel analog circuit topologies. Unlocking the full potential of generative AI in these data-driven discoveries requires access to large and diverse datasets.Yet, there is a significant barrier in the analog domain--Analog circuit design is inherently proprietary, involving not only confidential circuit structures but also the underlying commercial semiconductor processes. As a result, current generative AI research is largely confined to individual researchers who construct small, narrowly focused private datasets. This fragmentation severely limits collaborative innovation and impedes progress across the research community. To address these challenges, we propose AnalogFed. AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. To make this vision practical, we introduce a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers. Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines--while maintaining strict data privacy. Specifically, the generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.",
      "authors": [
        "Qiufeng Li",
        "Shu Hong",
        "Jian Gao",
        "Xuan Zhang",
        "Tian Lan",
        "and Weidong Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T19:57:07+00:00",
          "link": "https://arxiv.org/abs/2507.15104v1",
          "size": "689kb",
          "version": "v1"
        }
      ],
      "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15104",
        "HTML": "https://arxiv.org/html/2507.15104",
        "PDF": "https://arxiv.org/pdf/2507.15104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces AnalogFed for collaborative topology discovery in analog circuit design using federated learning. While it discusses data handling and generative models, it is outside the scope of LLM pretraining or fine-tuning data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15114",
      "abstract": "This position paper argues that annotation disagreement in Natural Language Inference (NLI) is not mere noise but often reflects meaningful interpretive variation, especially when triggered by ambiguity in the premise or hypothesis. While underspecified guidelines and annotator behavior can contribute to variation, content-based ambiguity offers a process-independent signal of divergent human perspectives. We call for a shift toward ambiguity-aware NLI by systematically identifying ambiguous input pairs and classifying ambiguity types. To support this, we present a unified framework that integrates existing taxonomies and illustrate key ambiguity subtypes through concrete examples. These examples reveal how ambiguity shapes annotator decisions and motivate the need for targeted detection methods that better align models with human interpretation. A key limitation is the lack of datasets annotated for ambiguity and subtypes. We propose addressing this gap through new annotated resources and unsupervised approaches to ambiguity detection -- paving the way for more robust, explainable, and human-aligned NLI systems.",
      "authors": [
        "Chathuri Jayaweera",
        "Bonnie Dorr"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:27:35+00:00",
          "link": "https://arxiv.org/abs/2507.15114v1",
          "size": "181kb",
          "version": "v1"
        }
      ],
      "title": "From Disagreement to Understanding: The Case for Ambiguity Detection in NLI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15114",
        "PDF": "https://arxiv.org/pdf/2507.15114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper argues for ambiguity detection in annotation for Natural Language Inference (NLI) and does not pertain to LLM training data processing techniques or methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15530",
      "abstract": "Bayesian probabilistic programming languages (BPPLs) let users denote statistical models as code while the interpreter infers the posterior distribution. The semantics of BPPLs are usually mathematically complex and unable to reason about desirable properties such as expected values and independence of random variables. To reason about these properties in a non-Bayesian setting, probabilistic separation logics such as PSL and Lilac interpret separating conjunction as probabilistic independence of random variables. However, no existing separation logic can handle Bayesian updating, which is the key distinguishing feature of BPPLs.\n  To close this gap, we introduce Bayesian separation logic (BaSL), a probabilistic separation logic that gives semantics to BPPL. We prove an internal version of Bayes' theorem using a result in measure theory known as the Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model probabilistic programming concepts such as Bayesian updating, unnormalised distribution, conditional distribution, soft constraint, conjugate prior and improper prior while maintaining modularity via the frame rule. The model of BaSL is based on a novel instantiation of Kripke resource monoid via $\\sigma$-finite measure spaces over the Hilbert cube, and the semantics of Hoare triple is compatible with an existing denotational semantics of BPPL based on the category of $s$-finite kernels. Using BaSL, we then prove properties of statistical models such as the expected value of Bayesian coin flip, correlation of random variables in the collider Bayesian network, and the posterior distributions of the burglar alarm model, a parameter estimation algorithm, and the Gaussian mixture model.",
      "authors": [
        "Shing Hin Ho",
        "Nicolas Wu and Azalea Raad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:56:11+00:00",
          "link": "https://arxiv.org/abs/2507.15530v1",
          "size": "123kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Separation Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15530",
        "PDF": "https://arxiv.org/pdf/2507.15530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses Bayesian separation logic and its application in probabilistic programming languages. It does not involve any processing of LLM training data or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15807",
      "abstract": "Multimodal Large Language Models (MLLMs), built on powerful language backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new tasks from a few multimodal demonstrations consisting of images, questions, and answers. Despite showing noticeable improvement on standard vision-language datasets, current MLLMs struggle to leverage visual information in the demonstrations. Specifically, they tend to neglect visual cues and over-rely on textual patterns, leading to mere text imitation rather than genuine multimodal adaptation. This behavior makes MICL still unimodal and largely restricts its practical utility. More importantly, this limitation is often concealed by the improved performance on tasks that do not require understanding the visual context. As a result, how to effectively enhance MICL ability and reliably evaluate the MICL performance remains underexplored. To address these issues, we first introduce Dynamic Attention Reallocation (DARA), an efficient fine-tuning strategy that encourages models to attend to the visual context by rebalancing attention across visual and textual tokens. In addition, we present TrueMICL, an MICL-dedicated dataset with both support and test sets that explicitly requires the integration of multimodal information-particularly visual content-for correct task completion. Extensive experiments demonstrate the effectiveness of our holistic solution, showcasing substantial improvements in the true multimodal in-context learning capabilities. Code and datasets are available at https://chenxshuo.github.io/true-micl-colm .",
      "authors": [
        "Shuo Chen",
        "Jianzhe Liu",
        "Zhen Han",
        "Yan Xia",
        "Daniel Cremers",
        "Philip Torr",
        "Volker Tresp",
        "Jindong Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:08:18+00:00",
          "link": "https://arxiv.org/abs/2507.15807v1",
          "size": "1401kb",
          "version": "v1"
        }
      ],
      "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15807",
        "HTML": "https://arxiv.org/html/2507.15807",
        "PDF": "https://arxiv.org/pdf/2507.15807"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper presents a strategy for enhancing multimodal in-context learning in MLLMs, mentioning dataset creation for evaluation. However, the core focus is on model adaptation techniques, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15852",
      "abstract": "Video Object Segmentation (VOS) is a core task in computer vision, requiring models to track and segment target objects across video frames. Despite notable advances with recent efforts, current techniques still lag behind human capabilities in handling drastic visual variations, occlusions, and complex scene changes. This limitation arises from their reliance on appearance matching, neglecting the human-like conceptual understanding of objects that enables robust identification across temporal dynamics. Motivated by this gap, we propose Segment Concept (SeC), a concept-driven segmentation framework that shifts from conventional feature matching to the progressive construction and utilization of high-level, object-centric representations. SeC employs Large Vision-Language Models (LVLMs) to integrate visual cues across diverse frames, constructing robust conceptual priors. During inference, SeC forms a comprehensive semantic representation of the target based on processed frames, realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively balances LVLM-based semantic reasoning with enhanced feature matching, dynamically adjusting computational efforts based on scene complexity. To rigorously assess VOS methods in scenarios demanding high-level conceptual reasoning and robust semantic understanding, we introduce the Semantic Complex Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160 manually annotated multi-scenario videos designed to challenge models with substantial appearance variations and dynamic scene transformations. In particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS, establishing a new state-of-the-art in concept-aware video object segmentation.",
      "authors": [
        "Zhixiong Zhang",
        "Shuangrui Ding",
        "Xiaoyi Dong",
        "Songxin He",
        "Jianfan Lin",
        "Junsong Tang",
        "Yuhang Zang",
        "Yuhang Cao",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.15852v1",
          "size": "6049kb",
          "version": "v1"
        }
      ],
      "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15852",
        "HTML": "https://arxiv.org/html/2507.15852",
        "PDF": "https://arxiv.org/pdf/2507.15852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is centered on video object segmentation and the construction of conceptual representations for better object tracking, which falls under computer vision and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00926",
      "abstract": "Computing matchings in general graphs plays a central role in graph algorithms. However, despite the recent interest in differentially private graph algorithms, there has been limited work on private matchings. Moreover, almost all existing work focuses on estimating the size of the maximum matching, whereas in many applications, the matching itself is the object of interest. There is currently only a single work on private algorithms for computing matching solutions by [HHRRW STOC'14]. Moreover, their work focuses on allocation problems and hence is limited to bipartite graphs.\n  Motivated by the importance of computing matchings in sensitive graph data, we initiate the study of differentially private algorithms for computing maximal and maximum matchings in general graphs. We provide a number of algorithms and lower bounds for this problem in different models and settings. We first prove a lower bound showing that computing explicit solutions necessarily incurs large error, even if we try to obtain privacy by allowing ourselves to output non-edges. We then consider implicit solutions, where at the end of the computation there is an ($\\varepsilon$-differentially private) billboard and each node can determine its matched edge(s) based on what is written on this publicly visible billboard. For this solution concept, we provide tight upper and lower (bicriteria) bounds, where the degree bound is violated by a logarithmic factor (which we show is necessary). We further show that our algorithm can be made distributed in the local edge DP (LEDP) model, and can even be done in a logarithmic number of rounds if we further relax the degree bounds by logarithmic factors. Our edge-DP matching algorithms give rise to new matching algorithms in the node-DP setting by combining our edge-DP algorithms with a novel use of arboricity sparsifiers. [...]",
      "authors": [
        "Michael Dinitz",
        "George Z. Li",
        "Quanquan C. Liu",
        "Felix Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-01T18:52:05+00:00",
          "link": "https://arxiv.org/abs/2501.00926v1",
          "size": "111kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T02:05:47+00:00",
          "link": "https://arxiv.org/abs/2501.00926v2",
          "size": "113kb",
          "version": "v2"
        }
      ],
      "title": "Differentially Private Matchings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00926",
        "PDF": "https://arxiv.org/pdf/2501.00926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses differentially private algorithms for computing matchings in graph data, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09510",
      "abstract": "Target Speaker Extraction (TSE) uses a reference cue to extract the target speech from a mixture. In TSE systems relying on audio cues, the speaker embedding from the enrolled speech is crucial to performance. However, these embeddings may suffer from speaker identity confusion. Unlike previous studies that focus on improving speaker embedding extraction, we improve TSE performance from the perspective of speaker consistency. In this paper, we propose a speaker consistency-aware target speaker extraction method that incorporates a centroid-based speaker consistency loss. This approach enhances TSE performance by ensuring speaker consistency between the enrolled and extracted speech. In addition, we integrate conditional loss suppression into the training process. The experimental results validate the effectiveness of our proposed methods in advancing the TSE performance. A speech demo is available online:https://sc-tse.netlify.app/",
      "authors": [
        "Shu Wu",
        "Anbin Qi",
        "Yanzhang Xie and Xiang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:35:13+00:00",
          "link": "https://arxiv.org/abs/2507.09510v1",
          "size": "109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T16:40:33+00:00",
          "link": "https://arxiv.org/abs/2507.09510v2",
          "size": "109kb",
          "version": "v2"
        }
      ],
      "title": "SC-TSE: Speaker Consistency-Aware Target Speaker Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09510",
        "HTML": "https://arxiv.org/html/2507.09510",
        "PDF": "https://arxiv.org/pdf/2507.09510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with target speaker extraction (TSE) improvements focused on speaker consistency, without relating to any aspects of data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14332",
      "abstract": "Accurate prediction of critical heat flux (CHF) is an essential component of safety analysis in pressurized and boiling water reactors. To support reliable prediction of this quantity, several empirical correlations and lookup tables have been constructed from physical experiments over the past several decades. With the onset of accessible machine learning (ML) frameworks, multiple initiatives have been established with the goal of predicting CHF more accurately than these traditional methods. While purely data-driven surrogate modeling has been extensively investigated, these approaches lack interpretability, lack resilience to data scarcity, and have been developed mostly using data from tube experiments. As a result, bias-correction hybrid approaches have become increasingly popular, which correct initial \"low-fidelity\" estimates provided by deterministic base models by using ML-predicted residuals. This body of work has mostly considered round tube geometries; annular geometry-specific ML models have not yet been deployed in thermal hydraulic codes. This study developed, deployed, and validated four ML models to predict CHF in annular geometries using the CTF subchannel code. Three empirical correlation models, Biasi, Bowring, and Katto, were used as base models for comparison. The ML models were trained and tested using 577 experimental annulus data points from four datasets: Becker, Beus, Janssen, and Mortimore. Baseline CHF predictions were obtained from the empirical correlations, with mean relative errors above 26%. The ML-driven models achieved mean relative errors below 3.5%, with no more than one point exceeding the 10% error envelope. In all cases, the hybrid ML models significantly outperformed their empirical counterparts.",
      "authors": [
        "Aidan Furlong",
        "Xingang Zhao",
        "Robert Salko",
        "Xu Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:19:38+00:00",
          "link": "https://arxiv.org/abs/2507.14332v1",
          "size": "1562kb",
          "version": "v1"
        }
      ],
      "title": "Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14332",
        "HTML": "https://arxiv.org/html/2507.14332",
        "PDF": "https://arxiv.org/pdf/2507.14332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about using ML models for predicting critical heat flux in engineering contexts. It does not relate to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14335",
      "abstract": "Language models have become increasingly powerful tools for formal mathematical reasoning. However, most existing approaches rely exclusively on either large general-purpose models or smaller specialized models, each with distinct limitations, while training specialized large models still requires significant computational resources. This paper introduces ProofCompass, a novel hybrid methodology that achieves remarkable computational efficiency by strategically guiding existing specialized prover methods, such as DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without requiring additional model training. The LLM provides natural language proof strategies and analyzes failed attempts to select intermediate lemmas, enabling effective problem decomposition. On the miniF2F benchmark, ProofCompass demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\% \\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$). Our synergistic approach paves the way for simultaneously improving computational efficiency and accuracy in formal theorem proving.",
      "authors": [
        "Nicolas Wischermann",
        "Claudio Mayrink Verdun",
        "Gabriel Poesia",
        "Francesco Noseda"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.14335v1",
          "size": "277kb",
          "version": "v1"
        }
      ],
      "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14335",
        "PDF": "https://arxiv.org/pdf/2507.14335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes ProofCompass, a methodology for improving theorem proving efficiency using LLMs. It focuses on model efficiency rather than training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14716",
      "abstract": "Reconstructing a method's change history efficiently and accurately is critical for many software engineering tasks, including maintenance, refactoring, and comprehension. Despite the availability of method history generation tools such as CodeShovel and CodeTracker, existing evaluations of their effectiveness are limited by inaccuracies in the ground truth oracles used. In this study, we systematically construct two new oracles -- the corrected CodeShovel oracle and a newly developed HistoryFinder oracle -- by combining automated analysis with expert-guided manual validation. We also introduce HistoryFinder, a new method history generation tool designed to improve not only the accuracy and completeness of method change histories but also to offer competitive runtime performance. Through extensive evaluation across 400 methods from 40 open-source repositories, we show that HistoryFinder consistently outperforms CodeShovel, CodeTracker, IntelliJ, and Git-based baselines in terms of precision, recall, and F1 score. Moreover, HistoryFinder achieves competitive runtime performance, offering the lowest mean and median execution times among all the research-based tools.\n  While Git-based tools exhibit the fastest runtimes, this efficiency comes at the cost of significantly lower precision and recall -- leaving HistoryFinder as the best overall choice when both accuracy and efficiency are important. To facilitate adoption, we provide a web interface, CLI, and Java library for flexible usage.",
      "authors": [
        "Shahidul Islam",
        "Ashik Aowal",
        "Md Sharif Uddin",
        "Shaiful Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T18:37:42+00:00",
          "link": "https://arxiv.org/abs/2507.14716v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "HistoryFinder: Advancing Method-Level Source Code History Generation with Accurate Oracles and Enhanced Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14716",
        "HTML": "https://arxiv.org/html/2507.14716",
        "PDF": "https://arxiv.org/pdf/2507.14716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on method-level source code history generation in software engineering, specifically on improving oracles and algorithms for history reconstruction, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15063",
      "abstract": "This paper explores the applications of quantum annealing (QA) and classical simulated annealing (SA) to a suite of combinatorial optimization problems in machine learning, namely feature selection, instance selection, and clustering. We formulate each task as a Quadratic Unconstrained Binary Optimization (QUBO) problem and implement both quantum and classical solvers to compare their effectiveness. For feature selection, we propose several QUBO configurations that balance feature importance and redundancy, showing that quantum annealing (QA) produces solutions that are computationally more efficient. In instance selection, we propose a few novel heuristics for instance-level importance measures that extend existing methods. For clustering, we embed a classical-to-quantum pipeline, using classical clustering followed by QUBO-based medoid refinement, and demonstrate consistent improvements in cluster compactness and retrieval metrics. Our results suggest that QA can be a competitive and efficient tool for discrete machine learning optimization, even within the constraints of current quantum hardware.",
      "authors": [
        "Chloe Pomeroy",
        "Aleksandar Pramov",
        "Karishma Thakrar",
        "Lakshmi Yendapalli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:59:14+00:00",
          "link": "https://arxiv.org/abs/2507.15063v1",
          "size": "7041kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Annealing for Machine Learning: Applications in Feature Selection, Instance Selection, and Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15063",
        "HTML": "https://arxiv.org/html/2507.15063",
        "PDF": "https://arxiv.org/pdf/2507.15063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses quantum annealing applications in machine learning for tasks like feature selection and clustering, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15292",
      "abstract": "Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at https://szupc.github.io/EndoControlMag/.",
      "authors": [
        "An Wanga",
        "Rulin Zhou",
        "Mengya Xu",
        "Yiru Ye",
        "Longfei Gou",
        "Yiting Chang",
        "Hao Chen",
        "Chwee Ming Lim",
        "Jiankun Wang",
        "Hongliang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.15292v1",
          "size": "1683kb",
          "version": "v1"
        }
      ],
      "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15292",
        "HTML": "https://arxiv.org/html/2507.15292",
        "PDF": "https://arxiv.org/pdf/2507.15292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on endoscopic motion magnification techniques in surgical environments without addressing any aspect of LLM training data processing or handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15297",
      "abstract": "Fingerprint matching under diverse capture conditions remains a fundamental challenge in biometric recognition. To achieve robust and accurate performance in such scenarios, we propose DMD, a minutiae-anchored local dense representation which captures both fine-grained ridge textures and discriminative minutiae features in a spatially structured manner. Specifically, descriptors are extracted from local patches centered and oriented on each detected minutia, forming a three-dimensional tensor, where two dimensions represent spatial locations on the fingerprint plane and the third encodes semantic features. This representation explicitly captures abstract features of local image patches, enabling a multi-level, fine-grained description that aggregates information from multiple minutiae and their surrounding ridge structures. Furthermore, thanks to its strong spatial correspondence with the patch image, DMD allows for the use of foreground segmentation masks to identify valid descriptor regions. During matching, comparisons are then restricted to overlapping foreground areas, improving efficiency and robustness. Extensive experiments on rolled, plain, parital, contactless, and latent fingerprint datasets demonstrate the effectiveness and generalizability of the proposed method. It achieves state-of-the-art accuracy across multiple benchmarks while maintaining high computational efficiency, showing strong potential for large-scale fingerprint recognition. Corresponding code is available at https://github.com/Yu-Yy/DMD.",
      "authors": [
        "Zhiyu Pan",
        "Xiongjun Guan",
        "Yongjie Duan",
        "Jianjiang Feng",
        "Jie Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:55:54+00:00",
          "link": "https://arxiv.org/abs/2507.15297v1",
          "size": "6173kb",
          "version": "v1"
        }
      ],
      "title": "Minutiae-Anchored Local Dense Representation for Fingerprint Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15297",
        "HTML": "https://arxiv.org/html/2507.15297",
        "PDF": "https://arxiv.org/pdf/2507.15297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses fingerprint matching techniques through minutiae-based representations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15377",
      "abstract": "Nowadays, equivalence problems are widely used in cryptography, most notably to establish cryptosystems such as digital signatures, with MEDS, LESS, PERK as the most recent ones. However, in the context of matrix codes, only the code equivalence problem has been studied, while the subcode equivalence is well-defined in the Hamming metric. In this work, we introduce two new problems: the Matrix Subcode Equivalence Problem and the Matrix Code Permuted Kernel Problem, to which we apply the MPCitH paradigm to build a signature scheme. These new problems, closely related to the Matrix Code Equivalence problem, ask to find an isometry given a code $C$ and a subcode $D$. Furthermore, we prove that the Matrix Subcode Equivalence problem reduces to the Hamming Subcode Equivalence problem, which is known to be NP-Complete, thus introducing the matrix code version of the Permuted Kernel Problem. We also adapt the combinatorial and algebraic algorithms for the Matrix Code Equivalence problem to the subcode case, and we analyze their complexities. We find with this analysis that the algorithms perform much worse than in the code equivalence case, which is the same as what happens in the Hamming metric. Finally, our analysis of the attacks allows us to take parameters much smaller than in the Matrix Code Equivalence case. Coupled with the effectiveness of \\textit{Threshold-Computation-in-the-Head} or \\textit{VOLE-in-the-Head}, we obtain a signature size of $\\approx$ 4 800 Bytes, with a public key of $\\approx$ 275 Bytes. We thus obtain a reasonable signature size, which brings diversity in the landscape of post-quantum signature schemes, by relying on a new hard problem. In particular, this new signature scheme performs better than SPHINCS+, with a smaller size of public key + signature. Our signature compares also well with other signature schemes: compared to MEDS, the signature is smaller, and we reduced the size of the sum of signature and public key by a factor close to 5. We also obtain a signature size that is almost half the size of the CROSS signature scheme.",
      "authors": [
        "Magali Bardet (CA - LITIS)",
        "Charles Brion (CA - LITIS)",
        "Philippe Gaborit (XLIM-MATHIS)",
        "Mercedes Haiech (XLIM-MATHIS)",
        "Romaric Neveu (XLIM-MATHIS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:33:24+00:00",
          "link": "https://arxiv.org/abs/2507.15377v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "The Matrix Subcode Equivalence problem and its application to signature with MPC-in-the-Head",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15377",
        "PDF": "https://arxiv.org/pdf/2507.15377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around cryptography, specifically matrix subcode equivalence problems and signature schemes, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15618",
      "abstract": "We present an adapter-based approach for tactical conditioning of StarCraft II AI agents. Current agents, while powerful, lack the ability to adapt their strategies based on high-level tactical directives. Our method freezes a pre-trained policy network (DI-Star) and attaches lightweight adapter modules to each action head, conditioned on a tactical tensor that encodes strategic preferences. By training these adapters with KL divergence constraints, we ensure the policy maintains core competencies while exhibiting tactical variations. Experimental results show our approach successfully modulates agent behavior across tactical dimensions including aggression, expansion patterns, and technology preferences, while maintaining competitive performance. Our method enables flexible tactical control with minimal computational overhead, offering practical strategy customization for complex real-time strategy games.",
      "authors": [
        "Weiyu Ma",
        "Jiwen Jiang",
        "Haobo Fu",
        "Haifeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:42:06+00:00",
          "link": "https://arxiv.org/abs/2507.15618v1",
          "size": "5520kb",
          "version": "v1"
        }
      ],
      "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15618",
        "HTML": "https://arxiv.org/html/2507.15618",
        "PDF": "https://arxiv.org/pdf/2507.15618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for tactical adaptation in StarCraft II AI agents using an adapter-based approach. This work does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "1804.02422",
      "abstract": "Predictive process monitoring has recently gained traction in academia and is maturing also in companies. However, with the growing body of research, it might be daunting for companies to navigate in this domain in order to find, provided certain data, what can be predicted and what methods to use. The main objective of this paper is developing a value-driven framework for classifying existing work on predictive process monitoring. This objective is achieved by systematically identifying, categorizing, and analyzing existing approaches for predictive process monitoring. The review is then used to develop a value-driven framework that can support organizations to navigate in the predictive process monitoring field and help them to find value and exploit the opportunities enabled by these analysis techniques.",
      "authors": [
        "Chiara Di Francescomarino and Chiara Ghidini and Fabrizio Maria Maggi and Fredrik Milani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2018-04-06T18:45:54+00:00",
          "link": "https://arxiv.org/abs/1804.02422v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Process Monitoring Methods: Which One Suits Me Best?",
      "links": {
        "Abstract": "https://arxiv.org/abs/1804.02422",
        "PDF": "https://arxiv.org/pdf/1804.02422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses predictive process monitoring methods and aims to develop a framework for classifying these methods. It does not address any aspect of data processing for LLM training."
      },
      "tasks": [
        "Navigate",
        "Predictive Process Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19457",
      "abstract": "Recent advances in dexterous grasping synthesis have demonstrated significant progress in producing reasonable and plausible grasps for many task purposes. But it remains challenging to generalize to unseen object categories and diverse task instructions. In this paper, we propose G-DexGrasp, a retrieval-augmented generation approach that can produce high-quality dexterous hand configurations for unseen object categories and language-based task instructions. The key is to retrieve generalizable grasping priors, including the fine-grained contact part and the affordance-related distribution of relevant grasping instances, for the following synthesis pipeline. Specifically, the fine-grained contact part and affordance act as generalizable guidance to infer reasonable grasping configurations for unseen objects with a generative model, while the relevant grasping distribution plays as regularization to guarantee the plausibility of synthesized grasps during the subsequent refinement optimization. Our comparison experiments validate the effectiveness of our key designs for generalization and demonstrate the remarkable performance against the existing approaches. Project page: https://g-dexgrasp.github.io/",
      "authors": [
        "Juntao Jian",
        "Xiuping Liu",
        "Zixuan Chen",
        "Manyi Li",
        "Jian Liu",
        "Ruizhen Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T08:46:50+00:00",
          "link": "https://arxiv.org/abs/2503.19457v1",
          "size": "3374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:32:50+00:00",
          "link": "https://arxiv.org/abs/2503.19457v2",
          "size": "6475kb",
          "version": "v2"
        }
      ],
      "title": "G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19457",
        "HTML": "https://arxiv.org/html/2503.19457",
        "PDF": "https://arxiv.org/pdf/2503.19457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores grasp synthesis for robotics, incorporating generative models for hand configurations, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09993",
      "abstract": "Camera-based object detection systems play a vital role in autonomous driving, yet they remain vulnerable to adversarial threats in real-world environments. Existing 2D and 3D physical attacks, due to their focus on texture optimization, often struggle to balance physical realism and attack robustness. In this work, we propose 3D Gaussian-based Adversarial Attack (3DGAA), a novel adversarial object generation framework that leverages the full 14-dimensional parameterization of 3D Gaussian Splatting (3DGS) to jointly optimize geometry and appearance in physically realizable ways. Unlike prior works that rely on patches or texture optimization, 3DGAA jointly perturbs both geometric attributes (shape, scale, rotation) and appearance attributes (color, opacity) to produce physically realistic and transferable adversarial objects. We further introduce a physical filtering module that filters outliers to preserve geometric fidelity, and a physical augmentation module that simulates complex physical scenarios to enhance attack generalization under real-world conditions. We evaluate 3DGAA on both virtual benchmarks and physical-world setups using miniature vehicle models. Experimental results show that 3DGAA achieves to reduce the detection mAP from 87.21\\% to 7.38\\%, significantly outperforming existing 3D physical attacks. Moreover, our method maintains high transferability across different physical conditions, demonstrating a new state-of-the-art in physically realizable adversarial attacks.",
      "authors": [
        "Yixun Zhang",
        "Lizhi Wang",
        "Junjun Zhao",
        "Wending Zhao",
        "Feng Zhou",
        "Yonghao Dang",
        "and Jianqin Yin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:27:52+00:00",
          "link": "https://arxiv.org/abs/2507.09993v1",
          "size": "8767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T11:48:13+00:00",
          "link": "https://arxiv.org/abs/2507.09993v2",
          "size": "3718kb",
          "version": "v2"
        }
      ],
      "title": "3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09993",
        "HTML": "https://arxiv.org/html/2507.09993",
        "PDF": "https://arxiv.org/pdf/2507.09993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a 3D adversarial attack framework for autonomous driving systems. It primarily focuses on adversarial attack methodology rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14315",
      "abstract": "Generalized Category Discovery (GCD) aims to classify unlabeled data from both known and unknown categories by leveraging knowledge from labeled known categories. While existing methods have made notable progress, they often overlook a hidden stumbling block in GCD: distracted attention. Specifically, when processing unlabeled data, models tend to focus not only on key objects in the image but also on task-irrelevant background regions, leading to suboptimal feature extraction. To remove this stumbling block, we propose Attention Focusing (AF), an adaptive mechanism designed to sharpen the model's focus by pruning non-informative tokens. AF consists of two simple yet effective components: Token Importance Measurement (TIME) and Token Adaptive Pruning (TAP), working in a cascade. TIME quantifies token importance across multiple scales, while TAP prunes non-informative tokens by utilizing the multi-scale importance scores provided by TIME. AF is a lightweight, plug-and-play module that integrates seamlessly into existing GCD methods with minimal computational overhead. When incorporated into one prominent GCD method, SimGCD, AF achieves up to 15.4% performance improvement over the baseline with minimal computational overhead. The implementation code is provided in https://github.com/Afleve/AFGCD.",
      "authors": [
        "Qiyu Xu",
        "Zhanxuan Hu",
        "Yu Duan",
        "Ercheng Pei",
        "Yonghang Tai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:39:16+00:00",
          "link": "https://arxiv.org/abs/2507.14315v1",
          "size": "1618kb",
          "version": "v1"
        }
      ],
      "title": "A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14315",
        "HTML": "https://arxiv.org/html/2507.14315",
        "PDF": "https://arxiv.org/pdf/2507.14315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses improving attention mechanisms in category discovery models, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14412",
      "abstract": "Socially assistive robots (SARs) have shown great potential for supplementing well-being support. However, prior studies have found that existing dialogue pipelines for SARs remain limited in real-time latency, back-channeling, and personalized speech dialogue. Toward addressing these limitations, we propose using integrated end-to-end speech-language models (SLMs) with SARs. This work 1) evaluated the usability of an SLM-enabled SAR dialogue system through a small user study, and 2) identified remaining limitations through study user feedback to inform future improvements. We conducted a small within-participant user study with university students (N = 11) whose results showed that participants perceived an SLM-enabled SAR system as capable of providing empathetic feedback, natural turn-taking, back-channeling, and adaptive responses. We also found that participants reported the robot's nonverbal behaviors as lacking variability and synchronization with conversation, and the SLM's verbal feedback as generic and repetitive. These findings highlighted the need for real-time robot movement synchronized with conversation, improved prompting or fine-tuning to generate outputs better aligned with mental health practices, and more expressive, adaptive vocal generation.",
      "authors": [
        "Mengxue Fu",
        "Zhonghao Shi",
        "Minyu Huang",
        "Siqi Liu",
        "Mina Kian",
        "Yirui Song",
        "and Maja J. Matari\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T23:36:06+00:00",
          "link": "https://arxiv.org/abs/2507.14412v1",
          "size": "1720kb",
          "version": "v1"
        }
      ],
      "title": "Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14412",
        "HTML": "https://arxiv.org/html/2507.14412",
        "PDF": "https://arxiv.org/pdf/2507.14412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on integrating speech-language models into robot systems for user interaction, without addressing aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14500",
      "abstract": "This paper introduces a robust framework for motion segmentation and egomotion estimation using event-based normal flow, tailored specifically for neuromorphic vision sensors. In contrast to traditional methods that rely heavily on optical flow or explicit depth estimation, our approach exploits the sparse, high-temporal-resolution event data and incorporates geometric constraints between normal flow, scene structure, and inertial measurements. The proposed optimization-based pipeline iteratively performs event over-segmentation, isolates independently moving objects via residual analysis, and refines segmentations using hierarchical clustering informed by motion similarity and temporal consistency. Experimental results on the EVIMO2v2 dataset validate that our method achieves accurate segmentation and translational motion estimation without requiring full optical flow computation. This approach demonstrates significant advantages at object boundaries and offers considerable potential for scalable, real-time robotic and navigation applications.",
      "authors": [
        "Zhiyuan Hua",
        "Dehao Yuan",
        "Cornelia Ferm\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T06:11:09+00:00",
          "link": "https://arxiv.org/abs/2507.14500v1",
          "size": "9077kb",
          "version": "v1"
        }
      ],
      "title": "Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14500",
        "HTML": "https://arxiv.org/html/2507.14500",
        "PDF": "https://arxiv.org/pdf/2507.14500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for motion segmentation and egomotion estimation using event-based sensors, without addressing any LLM training data processing, data engineering operations, or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14704",
      "abstract": "Historically, the design of antenna arrays has evolved separately from Shannon theory. Shannon theory adopts a probabilistic approach in the design of communication systems, while antenna design approaches have relied on the deterministic Maxwell theory alone. In this paper, we investigate an information-theoretic analysis approach which we apply to evaluate the design of a dual-band, dual-polarized multiple-input multiple-output (MIMO) array on a cellphone. To this end, we use ANSYS HFSS, a commercial electromagnetic (EM) simulation software suitable for the numerical optimization of antenna systems. HFSS is used to obtain an accurate model of the cellphone MIMO antenna array and HFSS SBR+ is utilized to obtain channel matrices for a large number of users. Taking advantage of linear and optimal processing at the cellphone, we estimate the outage probability curves. The curves are then used to determine the diversity gain in a moderate signal-to-noise ratio (SNR) regime and the multiplexing gain at a high SNR regime. This approach is then compared with the method of estimating the diversity gain from the envelope correlation coefficients or the beam-coupling matrix showing substantial differences in the two methodologies.",
      "authors": [
        "Volodymyr Shyianov",
        "Bamelak Tadele",
        "Vladimir I.Okhmatovski",
        "and Amine Mezghani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T17:50:56+00:00",
          "link": "https://arxiv.org/abs/2507.14704v1",
          "size": "945kb",
          "version": "v1"
        }
      ],
      "title": "Information Theoretic Analysis of a Dual-Band MIMO Cellphone Antenna with ANSYS HFSS SBR+",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14704",
        "HTML": "https://arxiv.org/html/2507.14704",
        "PDF": "https://arxiv.org/pdf/2507.14704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the design and analysis of a dual-band MIMO cellphone antenna using an information-theoretic approach. It does not discuss LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14774",
      "abstract": "Reactive, semi-permeable interfaces play important roles in key biological processes such as targeted drug delivery, lipid metabolism, and signal transduction. These systems involve coupled surface reactions, transmembrane transport, and interfacial deformation, often triggered by local biochemical signals. The strong mechanochemical couplings complicate the modeling of such interfacial dynamics. We propose a thermodynamically consistent continuum framework that integrates bulk fluid motion, interfacial dynamics, surface chemistry, and selective solute exchange, derived via an energy variation approach to ensure mass conservation and energy dissipation. To efficiently solve the resulting coupled system, we develop a finite element scheme within an Arbitrary Lagrangian-Eulerian (ALE) framework, incorporating the Barrett-Garcke-Nurnberg (BGN) strategy to maintain mesh regularity and preserve conservation laws. Numerical experiments verify the convergence and conservation properties of the scheme and demonstrate its ability in capturing complex interfacial dynamics. Two biologically inspired examples showcase the model's versatility: cholesterol efflux via the ABCG1 pathway, involving multistage interfacial reactions and HDL uptake; and a self-propelled droplet system with reaction-activated permeability, mimicking drug release in pathological environments. This work provides a unified computational platform for studying strongly coupled biochemical and mechanical interactions at interfaces, offering new insights into reactive transport processes in both biological and industrial contexts.",
      "authors": [
        "Weidong Shi",
        "Shixin Xu",
        "Zhen Zhang and Quan Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T00:11:12+00:00",
          "link": "https://arxiv.org/abs/2507.14774v1",
          "size": "4039kb",
          "version": "v1"
        }
      ],
      "title": "Thermodynamically Consistent Modeling and Stable ALE Approximations of Reactive Semi-Permeable Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14774",
        "HTML": "https://arxiv.org/html/2507.14774",
        "PDF": "https://arxiv.org/pdf/2507.14774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with thermodynamically consistent modeling of reactive interfaces, which is not relevant to LLM training data processing or data engineering tasks related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15315",
      "abstract": "We introduce and study the repetitive variants of the deterministic and the nondeterministic finite automaton with translucent words (DFAwtw and NFAwtw). On seeing the right sentinel, a repetitive NFAwtw need not halt immediately, accepting or rejecting, but it may change into another state and continue with its computation. We establish that a repetitive DFAwtw already accepts a language that is not even semi-linear, which shows that the property of being repetitive increases the expressive capacity of the DFAwtw and the NFAwtw considerably.",
      "authors": [
        "Franti\\v{s}ek Mr\\'az (Charles University in Prague)",
        "Friedrich Otto (Universit\\\"atKassel)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:15:15+00:00",
          "link": "https://arxiv.org/abs/2507.15315v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "On Repetitive Finite Automata with Translucent Words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15315",
        "PDF": "https://arxiv.org/pdf/2507.15315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the study of repetitive finite automata with translucent words, discussing their expressive capacity. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03919",
      "abstract": "This paper offers a direct data-driven approach for learning robust control barrier certificates (R-CBCs) and robust safety controllers (R-SCs) for discrete-time input-affine polynomial systems with unknown dynamics under unknown-but-bounded disturbances. The proposed method relies on data from input-state observations collected over a finite-time horizon while satisfying a specific rank condition to ensure the system is persistently excited. Our data-driven scheme enables the synthesis of R-CBCs and R-SCs directly from observed data, bypassing the need for explicit modeling of the system's dynamics and thus ensuring robust system safety against disturbances within an infinite time horizon. Our proposed approach is formulated as a sum-of-squares (SOS) optimization problem, providing a structured design framework. Two case studies showcase our method's capability to provide robust safety guarantees for unknown input-affine polynomial systems under bounded disturbances, demonstrating its practical effectiveness.",
      "authors": [
        "Omid Akbarzadeh",
        "MohammadHossein Ashoori",
        "Abolfazl Lavaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T06:45:29+00:00",
          "link": "https://arxiv.org/abs/2412.03919v1",
          "size": "2355kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T16:21:28+00:00",
          "link": "https://arxiv.org/abs/2412.03919v2",
          "size": "3234kb",
          "version": "v2"
        }
      ],
      "title": "Learning Robust Safety Controllers for Uncertain Input-Affine Polynomial Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03919",
        "PDF": "https://arxiv.org/pdf/2412.03919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses learning robust safety controllers for uncertain polynomial systems using a data-driven approach. It does not contribute to LLM training data processing or any related operations for pretraining or fine-tuning language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.07677",
      "abstract": "Diffusion models have shown impressive results in generating high-quality conditional samples using guidance techniques such as Classifier-Free Guidance (CFG). However, existing methods often require additional training or neural function evaluations (NFEs), making them incompatible with guidance-distilled models. Also, they rely on heuristic approaches that need identifying target layers. In this work, we propose a novel and efficient method, termed PLADIS, which boosts pre-trained models (U-Net/Transformer) by leveraging sparse attention. Specifically, we extrapolate query-key correlations using softmax and its sparse counterpart in the cross-attention layer during inference, without requiring extra training or NFEs. By leveraging the noise robustness of sparse attention, our PLADIS unleashes the latent potential of text-to-image diffusion models, enabling them to excel in areas where they once struggled with newfound effectiveness. It integrates seamlessly with guidance techniques, including guidance-distilled models. Extensive experiments show notable improvements in text alignment and human preference, offering a highly efficient and universally applicable solution. See Our project page : https://cubeyoung.github.io/pladis-proejct/",
      "authors": [
        "Kwanyoung Kim",
        "Byeongsu Sim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T07:23:19+00:00",
          "link": "https://arxiv.org/abs/2503.07677v1",
          "size": "12613kb",
          "version": "v1"
        },
        {
          "date": "2025-03-16T14:10:37+00:00",
          "link": "https://arxiv.org/abs/2503.07677v2",
          "size": "12613kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T12:43:22+00:00",
          "link": "https://arxiv.org/abs/2503.07677v3",
          "size": "14315kb",
          "version": "v3"
        }
      ],
      "title": "PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07677",
        "HTML": "https://arxiv.org/html/2503.07677",
        "PDF": "https://arxiv.org/pdf/2503.07677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for improving diffusion models through sparse attention during inference time. It does not discuss any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00444",
      "abstract": "Analog circuit design consists of the pre-layout and layout phases. Among them, the pre-layout phase directly decides the final circuit performance, but heavily depends on experienced engineers to do manual design according to specific application scenarios. To overcome these challenges and automate the analog circuit pre-layout design phase, we introduce DiffCkt: a diffusion model-based hybrid neural network framework for the automatic transistor-level generation of analog circuits, which can directly generate corresponding circuit structures and device parameters tailored to specific performance requirements. To more accurately quantify the efficiency of circuits generated by DiffCkt, we introduce the Circuit Generation Efficiency Index (CGEI), which is determined by both the figure of merit (FOM) of a single generated circuit and the time consumed. Compared with relative research, DiffCkt has improved CGEI by a factor of $2.21 \\sim 8365\\times$, reaching a state-of-the-art (SOTA) level. In conclusion, this work shows that the diffusion model has the remarkable ability to learn and generate analog circuit structures and device parameters, providing a revolutionary method for automating the pre-layout design of analog circuits. The circuit dataset will be open source, its preview version is available at https://github.com/CjLiu-NJU/DiffCkt.",
      "authors": [
        "Chengjie Liu",
        "Jiajia Li",
        "Yabing Feng",
        "Wenhao Huang",
        "Weiyu Chen",
        "Yuan Du",
        "Jun Yang",
        "and Li Du"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T05:54:31+00:00",
          "link": "https://arxiv.org/abs/2507.00444v1",
          "size": "1492kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T03:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.00444v2",
          "size": "1492kb",
          "version": "v2"
        }
      ],
      "title": "DiffCkt: A Diffusion Model-Based Hybrid Neural Network Framework for Automatic Transistor-Level Generation of Analog Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00444",
        "HTML": "https://arxiv.org/html/2507.00444",
        "PDF": "https://arxiv.org/pdf/2507.00444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on automating the design of analog circuits using a neural network framework, and though it mentions creating a dataset, it is specific to analog circuit generation, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14199",
      "abstract": "Semantic communication represents a promising technique towards reducing communication costs, especially when dealing with image segmentation, but it still lacks a balance between computational efficiency and bandwidth requirements while maintaining high image segmentation accuracy, particularly in resource-limited environments and changing channel conditions. On the other hand, the more complex and larger semantic image segmentation models become, the more stressed the devices are when processing data. This paper proposes a novel approach to implementing semantic communication based on splitting the semantic image segmentation process between a resource constrained transmitter and the receiver. This allows saving bandwidth by reducing the transmitted data while maintaining the accuracy of the semantic image segmentation. Additionally, it reduces the computational requirements at the resource constrained transmitter compared to doing all the semantic image segmentation in the transmitter. The proposed approach is evaluated by means of simulation-based experiments in terms of different metrics such as computational resource usage, required bit rate and segmentation accuracy. The results when comparing the proposal with the full semantic image segmentation in the transmitter show that up to 72% of the bit rate was reduced in the transmission process. In addition, the computational load of the transmitter is reduced by more than 19%. This reflects the interest of this technique for its application in communication systems, particularly in the upcoming 6G systems.",
      "authors": [
        "Ebrahim Abu-Helalah",
        "Jordi Serra",
        "Jordi Perez-Romero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:55:02+00:00",
          "link": "https://arxiv.org/abs/2507.14199v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "On Splitting Lightweight Semantic Image Segmentation for Wireless Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14199",
        "HTML": "https://arxiv.org/html/2507.14199",
        "PDF": "https://arxiv.org/pdf/2507.14199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research concerns semantic image segmentation and wireless communications, which do not pertain to LLM training data processing or relevant datasets specifically for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14468",
      "abstract": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery and disease understanding, yet their completion and reasoning are challenging. Knowledge Embedding (KE) methods capture global semantics but struggle with dynamic structural integration, while Graph Neural Networks (GNNs) excel locally but often lack semantic understanding. Even ensemble approaches, including those leveraging language models, often fail to achieve a deep, adaptive, and synergistic co-evolution between semantic comprehension and structural learning. Addressing this critical gap in fostering continuous, reciprocal refinement between these two aspects in complex biomedical KGs is paramount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply synergistic semantic and structural learning. BioGraphFusion establishes a global semantic foundation via tensor decomposition, guiding an LSTM-driven mechanism to dynamically refine relation embeddings during graph propagation. This fosters adaptive interplay between semantic understanding and structural learning, further enhanced by query-guided subgraph construction and a hybrid scoring mechanism. Experiments across three key biomedical tasks demonstrate BioGraphFusion's superior performance over state-of-the-art KE, GNN, and ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1) highlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely available for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics online.",
      "authors": [
        "Yitong Lin",
        "Jiaying He",
        "Jiahe Chen",
        "Xinnan Zhu",
        "Jianwei Zheng",
        "Tao Bo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T04:03:42+00:00",
          "link": "https://arxiv.org/abs/2507.14468v1",
          "size": "1454kb",
          "version": "v1"
        }
      ],
      "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14468",
        "HTML": "https://arxiv.org/html/2507.14468",
        "PDF": "https://arxiv.org/pdf/2507.14468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces BioGraphFusion for knowledge graph embedding in biomedical tasks, and does not address the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14614",
      "abstract": "A major locus of musicological activity-increasingly in the digital domain-is the cataloguing of sources, which requires large-scale and long-lasting research collaborations. Yet, the databases aiming at covering and representing musical repertoires are never quite complete, and scholars must contend with the question: how much are we still missing? This question structurally resembles the 'unseen species' problem in ecology, where the true number of species must be estimated from limited observations. In this case study, we apply for the first time the common Chao1 estimator to music, specifically to Gregorian chant. We find that, overall, upper bounds for repertoire coverage of the major chant genres range between 50 and 80 %. As expected, we find that Mass Propers are covered better than the Divine Office, though not overwhelmingly so. However, the accumulation curve suggests that those bounds are not tight: a stable ~5% of chants in sources indexed between 1993 and 2020 was new, so diminishing returns in terms of repertoire diversity are not yet to be expected. Our study demonstrates that these questions can be addressed empirically to inform musicological data-gathering, showing the potential of unseen species models in musicology.",
      "authors": [
        "Jan Haji\\v{c} jr.",
        "Fabian Moss"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:25:08+00:00",
          "link": "https://arxiv.org/abs/2507.14614v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Knowing when to stop: insights from ecology for building catalogues, collections, and corpora",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14614",
        "HTML": "https://arxiv.org/html/2507.14614",
        "PDF": "https://arxiv.org/pdf/2507.14614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses cataloguing and diversity estimation in musicology datasets, using ecological methods. This is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14887",
      "abstract": "Although large language models (LLMs) excel in text comprehension and generation, their performance on the Emotion-Cause Pair Extraction (ECPE) task, which requires reasoning ability, is often underperform smaller language model. The main reason is the lack of auxiliary knowledge, which limits LLMs' ability to effectively perceive emotions and reason causes. To address this issue, we propose a novel \\textbf{M}ulti-source h\\textbf{E}terogeneous \\textbf{K}nowledge \\textbf{i}njection me\\textbf{T}hod, MEKiT, which integrates heterogeneous internal emotional knowledge and external causal knowledge. Specifically, for these two distinct aspects and structures of knowledge, we apply the approaches of incorporating instruction templates and mixing data for instruction-tuning, which respectively facilitate LLMs in more comprehensively identifying emotion and accurately reasoning causes. Experimental results demonstrate that MEKiT provides a more effective and adaptable solution for the ECPE task, exhibiting an absolute performance advantage over compared baselines and dramatically improving the performance of LLMs on the ECPE task.",
      "authors": [
        "Shiyi Mu and Yongkang Liu and Shi Feng and Xiaocui Yang and Daling Wang and Yifei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T10:11:21+00:00",
          "link": "https://arxiv.org/abs/2507.14887v1",
          "size": "683kb",
          "version": "v1"
        }
      ],
      "title": "MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14887",
        "HTML": "https://arxiv.org/html/2507.14887",
        "PDF": "https://arxiv.org/pdf/2507.14887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes MEKiT, which uses instruction tuning involving data mixing for emotion-cause pair extraction. While it uses instruction-tuning, its focus is on task-specific performance enhancement rather than core LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15031",
      "abstract": "This paper develops a framework for synthesizing safety controllers for discrete-time stochastic linear control systems (dt-SLS) operating under communication imperfections. The control unit is remote and communicates with the sensor and actuator through an imperfect wireless network. We consider a constant delay in the sensor-to-controller channel (uplink), and data loss in both sensor-to-controller and controller-to-actuator (downlink) channels. In our proposed scheme, data loss in each channel is modeled as an independent Bernoulli-distributed random process. To systematically handle the uplink delay, we first introduce an augmented discrete-time stochastic linear system (dt-ASLS) by concatenating all states and control inputs that sufficiently represent the state-input evolution of the original dt-SLS under the delay and packet loss constraints. We then leverage control barrier certificates (CBCs) for dt-ASLS to synthesize a controller that guarantees dt-SLS safety in a stochastic sense, ensuring that all trajectories of dt-SLS remain within safe regions with a quantified probabilistic bound. Our approach translates safety constraints into matrix inequalities, leading to an optimization problem that eventually quantifies the probability of satisfying the safety specification in the presence of communication imperfections. We validate our results on an RLC circuit subject to both constant delay and probabilistic data loss.",
      "authors": [
        "Omid Akbarzadeh",
        "Mohammad H. Mamduhi",
        "Abolfazl Lavaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:32:51+00:00",
          "link": "https://arxiv.org/abs/2507.15031v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Safety Controller Synthesis for Stochastic Networked Systems under Communication Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15031",
        "HTML": "https://arxiv.org/html/2507.15031",
        "PDF": "https://arxiv.org/pdf/2507.15031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for safety controller synthesis in stochastic network systems, unrelated to any aspect of LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15256",
      "abstract": "The rapid proliferation and growth of artificial intelligence (AI) has led to the development of federated learning (FL). FL allows wireless devices (WDs) to cooperatively learn by sharing only local model parameters, without needing to share the entire dataset. However, the emergence of large AI models has made existing FL approaches inefficient, due to the significant communication overhead required. In this paper, we propose a novel over-the-air federated distillation (FD) framework by synergizing the strength of FL and knowledge distillation to avoid the heavy local model transmission. Instead of sharing the model parameters, only the WDs' model outputs, referred to as knowledge, are shared and aggregated over-the-air by exploiting the superposition property of the multiple-access channel. We shall study the transceiver design in over-the-air FD, aiming to maximize the learning convergence rate while meeting the power constraints of the transceivers. The main challenge lies in the intractability of the learning performance analysis, as well as the non-convex nature and the optimization spanning the whole FD training period. To tackle this problem, we first derive an analytical expression of the convergence rate in over-the-air FD. Then, the closed-form optimal solutions of the WDs' transmit power and the estimator for over-the-air aggregation are obtained given the receiver combining strategy. Accordingly, we put forth an efficient approach to find the optimal receiver beamforming vector via semidefinite relaxation. We further prove that there is no optimality gap between the original and relaxed problem for the receiver beamforming design. Numerical results will show that the proposed over-the-air FD approach achieves a significant reduction in communication overhead, with only a minor compromise in testing accuracy compared to conventional FL benchmarks.",
      "authors": [
        "Zihao Hu (1)",
        "Jia Yan (2)",
        "Ying-Jun Angela Zhang (1)",
        "Jun Zhang (3)",
        "Khaled B. Letaief (3) ((1) The Chinese University of Hong Kong",
        "(2) The Hong Kong University of Science and Technology (Guangzhou)",
        "(3) The Hong Kong University of Science and Technology)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T05:37:08+00:00",
          "link": "https://arxiv.org/abs/2507.15256v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Transceiver Design in Over-the-Air Federated Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15256",
        "HTML": "https://arxiv.org/html/2507.15256",
        "PDF": "https://arxiv.org/pdf/2507.15256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses federated learning and transceiver design for over-the-air federated distillation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15299",
      "abstract": "This paper provides an overview and critique of the risk based model of artificial intelligence (AI) governance that has become a popular approach to AI regulation across multiple jurisdictions. The 'AI Policy Landscape in Europe, North America and Australia' section summarises the existing AI policy efforts across these jurisdictions, with a focus of the EU AI Act and the Australian Department of Industry, Science and Regulation's (DISR) safe and responsible AI consultation. The 'Analysis' section of this paper proposes several criticisms of the risk based approach to AI governance, arguing that the construction and calculation of risks that they use reproduces existing inequalities. Drawing on the work of Julia Black, it argues that risk and harm should be distinguished clearly and that the notion of risk is problematic as its inherent normativity reproduces dominant and harmful narratives about whose interests matter, and risk categorizations should be subject to deep scrutiny. This paper concludes with the suggestion that existing risk governance scholarship can provide valuable insights toward the improvement of the risk based AI governance, and that the use of multiple regulatory implements and responsive risk regulation should be considered in the continuing development of the model.",
      "authors": [
        "Veve Fry"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.15299v1",
          "size": "387kb",
          "version": "v1"
        }
      ],
      "title": "An Overview of the Risk-based Model of AI Governance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15299",
        "PDF": "https://arxiv.org/pdf/2507.15299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI governance and policy, specifically focusing on the risk-based model of AI regulation. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15541",
      "abstract": "Surgical scene understanding is crucial for computer-assisted intervention systems, requiring visual comprehension of surgical scenes that involves diverse elements such as surgical tools, anatomical structures, and their interactions. To effectively represent the complex information in surgical scenes, graph-based approaches have been explored to structurally model surgical entities and their relationships. Previous surgical scene graph studies have demonstrated the feasibility of representing surgical scenes using graphs. However, certain aspects of surgical scenes-such as diverse combinations of tool-action-target and the identity of the hand operating the tool-remain underexplored in graph-based representations, despite their importance. To incorporate these aspects into graph representations, we propose Endoscapes-SG201 dataset, which includes annotations for tool-action-target combinations and hand identity. We also introduce SSG-Com, a graph-based method designed to learn and represent these critical elements. Through experiments on downstream tasks such as critical view of safety assessment and action triplet recognition, we demonstrated the importance of integrating these essential scene graph components, highlighting their significant contribution to surgical scene understanding. The code and dataset are available at https://github.com/ailab-kyunghee/SSG-Com",
      "authors": [
        "Jongmin Shin",
        "Enki Cho",
        "Ka Yong Kim",
        "Jung Yong Kim",
        "Seong Tae Kim",
        "and Namkee Oh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:10:42+00:00",
          "link": "https://arxiv.org/abs/2507.15541v1",
          "size": "5719kb",
          "version": "v1"
        }
      ],
      "title": "Towards Holistic Surgical Scene Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15541",
        "HTML": "https://arxiv.org/html/2507.15541",
        "PDF": "https://arxiv.org/pdf/2507.15541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on surgical scene understanding using graph-based representation for surgical tools and actions. It does not involve training data processing for LLMs but rather a dataset specific to surgical scene comprehension."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.10559",
      "abstract": "This report investigates the history and impact of Generative Models and Connected and Automated Vehicles (CAVs), two groundbreaking forces pushing progress in technology and transportation. By focusing on the application of generative models within the context of CAVs, the study aims to unravel how this integration could enhance predictive modeling, simulation accuracy, and decision-making processes in autonomous vehicles. This thesis discusses the benefits and challenges of integrating generative models and CAV technology in transportation. It aims to highlight the progress made, the remaining obstacles, and the potential for advancements in safety and innovation.",
      "authors": [
        "Bo Shu",
        "Yiting Zhang",
        "Dong Shu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-14T06:51:26+00:00",
          "link": "https://arxiv.org/abs/2403.10559v1",
          "size": "713kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T20:14:08+00:00",
          "link": "https://arxiv.org/abs/2403.10559v2",
          "size": "150kb",
          "version": "v2"
        }
      ],
      "title": "Generative Models and Connected and Automated Vehicles: A Survey in Exploring the Intersection of Transportation and AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.10559",
        "HTML": "https://arxiv.org/html/2403.10559",
        "PDF": "https://arxiv.org/pdf/2403.10559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys the intersection of generative models and connected automated vehicles, with no focus on LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.14198",
      "abstract": "A context-free problem of Fair Division is a function W from a profile of n types to a freely transferable amount of surplus W(x) they must share in the common property regime. A pair of tight guarantees assigns to each type an upper and a lower bound on its share under any profile of types of the other agents, and these bounds cannot be improved. The choice of a particular pair of such guarantees when the types and W have an economic interpretation vindicates ony some familiar fair sharing rules, and suggests many new ones. Our examples include the allocation of an indivisible good or bad, the classic model of a commons where types enter additively in the function W, and sharing the cost of a capacity or of the transportation costs to a location on a line.",
      "authors": [
        "Anna Bogomolnaia and Herv\\'e Moulin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T11:03:51+00:00",
          "link": "https://arxiv.org/abs/2406.14198v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2024-11-18T11:11:29+00:00",
          "link": "https://arxiv.org/abs/2406.14198v2",
          "size": "41kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T12:38:44+00:00",
          "link": "https://arxiv.org/abs/2406.14198v3",
          "size": "45kb",
          "version": "v3"
        }
      ],
      "title": "Guaranteed shares of benefits and costs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14198",
        "PDF": "https://arxiv.org/pdf/2406.14198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses fair division of benefits and costs in economic scenarios, with examples in property regime and resource allocation. It does not relate to LLM training data processing or dataset preparation for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.17723",
      "abstract": "Volatile memristors have recently gained popularity as promising devices for neuromorphic circuits, capable of mimicking the leaky function of neurons and offering advantages over capacitor-based circuits in terms of power dissipation and area. Additionally, volatile memristors are useful as selector devices and for hardware security circuits such as physical unclonable functions. To facilitate the design and simulation of circuits, a compact behavioral model is essential. This paper proposes V-VTEAM, a compact, simple, general, and flexible behavioral model for volatile memristors, inspired by the VTEAM nonvolatile memristor model and developed in MATLAB. The validity of the model is demonstrated by fitting it to an ion drift/diffusion-based Ag/SiOx/C/W volatile memristor, achieving a relative root mean error square of 4.5%.",
      "authors": [
        "Tanay Patni",
        "Rishona Daniels and Shahar Kvatinsky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T10:52:04+00:00",
          "link": "https://arxiv.org/abs/2409.17723v1",
          "size": "499kb",
          "version": "v1"
        }
      ],
      "title": "VVTEAM: A Compact Behavioral Model for Volatile Memristors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17723",
        "PDF": "https://arxiv.org/pdf/2409.17723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a behavioral model for volatile memristors in neuromorphic circuits, unrelated to any aspect of LLM training data processing."
      },
      "tasks": [
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.17845",
      "abstract": "Anatomical landmark detection in medical images is essential for various clinical and research applications, including disease diagnosis and surgical planning. However, manual landmark annotation is time-consuming and requires significant expertise. Existing deep learning (DL) methods often require large amounts of well-annotated data, which are costly to acquire. In this paper, we introduce CABLD, a novel self-supervised DL framework for 3D brain landmark detection in unlabeled scans with varying contrasts by using only a single reference example. To achieve this, we employed an inter-subject landmark consistency loss with an image registration loss while introducing a 3D convolution-based contrast augmentation strategy to promote model generalization to new contrasts. Additionally, we utilize an adaptive mixed loss function to schedule the contributions of different sub-tasks for optimal outcomes. We demonstrate the proposed method with the intricate task of MRI-based 3D brain landmark detection. With comprehensive experiments on four diverse clinical and public datasets, including both T1w and T2w MRI scans at different MRI field strengths, we demonstrate that CABLD outperforms the state-of-the-art methods in terms of mean radial errors (MREs) and success detection rates (SDRs). Our framework provides a robust and accurate solution for anatomical landmark detection, reducing the need for extensively annotated datasets and generalizing well across different imaging contrasts. Our code is publicly available at https://github.com/HealthX-Lab/CABLD.",
      "authors": [
        "Soorena Salari",
        "Arash Harirpoush",
        "Hassan Rivaz",
        "Yiming Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T19:56:29+00:00",
          "link": "https://arxiv.org/abs/2411.17845v1",
          "size": "37390kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T21:21:44+00:00",
          "link": "https://arxiv.org/abs/2411.17845v2",
          "size": "32053kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T21:14:22+00:00",
          "link": "https://arxiv.org/abs/2411.17845v3",
          "size": "29397kb",
          "version": "v3"
        }
      ],
      "title": "CABLD: Contrast-Agnostic Brain Landmark Detection with Consistency-Based Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17845",
        "HTML": "https://arxiv.org/html/2411.17845",
        "PDF": "https://arxiv.org/pdf/2411.17845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a self-supervised framework for brain landmark detection in medical imaging. It emphasizes deep learning methods in medical image processing, not relevant to LLM training data processing."
      },
      "tasks": [
        "Anatomical Landmark Detection",
        "Brain landmark detection",
        "Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09279",
      "abstract": "While theoretical computer science primarily works with discrete models of computation, like the Turing machine and the wordRAM, there are many scenarios in which introducing real computation models is more adequate. We want to compare real models of computation with discrete models of computation. We do this by means of oracle separation results.\n  We define the notion of a real Turing machine as an extension of the (binary) Turing machine by adding a real tape. Using those machines, we define and study the real polynomial hierarchy RPH. We are interested in RPH as the first level of the hierarchy corresponds to the well-known complexity class ER. It is known that $NP \\subseteq ER \\subseteq PSPACE$ and furthermore $PH \\subseteq RPH \\subseteq PSPACE$. We are interested to know if any of those inclusions are tight. In the absence of unconditional separations of complexity classes, we turn to oracle separation. We develop a technique that allows us to transform oracle separation results from the binary world to the real world. As applications, we show there are oracles such that:\n  - $RPH^O$ proper subset of $PSPACE^O$,\n  - $\\Sigma_{k+1}^O$ not contained in $\\Sigma_kR^O$, for all $k\\geq 0$,\n  - $\\Sigma_kR^O$ proper subset of $\\Sigma_{k+1}R^O$, for all $k\\geq 0$,\n  - $BQP^O$ not contained in $RPH^O$.\n  Our results indicate that ER is strictly contained in PSPACE and that there is a separation between the different levels of the real polynomial hierarchy. We also bound the power of real computations by showing that NP-hard problems are unlikely to be solvable using polynomial time on a realRAM. Furthermore, our oracle separations indicate that polynomial-time quantum computing cannot be simulated on an efficient real Turing machine.",
      "authors": [
        "Thekla Hamm",
        "Lucas Meijer",
        "Tillmann Miltzow and Subhasree Patro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T12:50:08+00:00",
          "link": "https://arxiv.org/abs/2502.09279v1",
          "size": "328kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:26:25+00:00",
          "link": "https://arxiv.org/abs/2502.09279v2",
          "size": "237kb",
          "version": "v2"
        }
      ],
      "title": "Oracle Separations for RPH",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09279",
        "HTML": "https://arxiv.org/html/2502.09279",
        "PDF": "https://arxiv.org/pdf/2502.09279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses oracle separations in theoretical computer science and real computation models. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.09459",
      "abstract": "Concept Bottleneck Models (CBMs) aim to enhance interpretability by structuring predictions around human-understandable concepts. However, unintended information leakage, where predictive signals bypass the concept bottleneck, compromises their transparency. This paper introduces an information-theoretic measure to quantify leakage in CBMs, capturing the extent to which concept embeddings encode additional, unintended information beyond the specified concepts. We validate the measure through controlled synthetic experiments, demonstrating its effectiveness in detecting leakage trends across various configurations. Our findings highlight that feature and concept dimensionality significantly influence leakage, and that classifier choice impacts measurement stability, with XGBoost emerging as the most reliable estimator. Additionally, preliminary investigations indicate that the measure exhibits the anticipated behavior when applied to soft joint CBMs, suggesting its reliability in leakage quantification beyond fully synthetic settings. While this study rigorously evaluates the measure in controlled synthetic experiments, future work can extend its application to real-world datasets.",
      "authors": [
        "Mikael Makonnen",
        "Moritz Vandenhirtz",
        "Sonia Laguna",
        "Julia E Vogt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T07:09:55+00:00",
          "link": "https://arxiv.org/abs/2504.09459v1",
          "size": "1778kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T11:18:24+00:00",
          "link": "https://arxiv.org/abs/2504.09459v2",
          "size": "1778kb",
          "version": "v2"
        }
      ],
      "title": "Measuring Leakage in Concept-Based Methods: An Information Theoretic Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09459",
        "HTML": "https://arxiv.org/html/2504.09459",
        "PDF": "https://arxiv.org/pdf/2504.09459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an information-theoretic approach to measure leakage in Concept Bottleneck Models, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14295",
      "abstract": "Multi-turn problem solving is critical yet challenging for Large Reasoning Models (LRMs) to reflect on their reasoning and revise from feedback. Existing Reinforcement Learning (RL) methods train large reasoning models on a single-turn paradigm with verifiable rewards. However, we observe that models trained with existing RL paradigms often lose their ability to solve problems across multiple turns and struggle to revise answers based on contextual feedback, leading to repetitive responses. We ask: can LRMs learn to reflect their answers in a multi-turn context? In this work, we find that training models with multi-turn RL using only unary feedback (e.g., \"Let's try again\") after wrong answers can improve both single-turn performance and multi-turn reasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement learning, which uses minimal yet common unary user feedback during iterative problem solving. It can be easily applied to existing single-turn RL training setups. Experimental results show that RL training with UFO keeps single-turn performance and improves multi-turn reasoning accuracy by up to 14%, enabling language models to better react to feedback in multi-turn problem solving. To further minimize the number of turns needed for a correct answer while encouraging diverse reasoning when mistakes occur, we design reward structures that guide models to produce careful and deliberate answers in each turn. Code: https://github.com/lichengliu03/unary-feedback",
      "authors": [
        "Licheng Liu",
        "Zihan Wang",
        "Linjie Li",
        "Chenwei Xu",
        "Yiping Lu",
        "Han Liu",
        "Avirup Sil",
        "Manling Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:07:38+00:00",
          "link": "https://arxiv.org/abs/2507.14295v1",
          "size": "1584kb",
          "version": "v1"
        }
      ],
      "title": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14295",
        "PDF": "https://arxiv.org/pdf/2507.14295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on improving LRMs with reinforcement learning for multi-turn reasoning and feedback processing, not directly on data processing for LLMs, but it does touch on data aspects in training through feedback, thus making a partial contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15176",
      "abstract": "We study the algorithmic robustness of general finite Markov chains in terms of their stationary distributions to general, adversarial corruptions of the transition matrix. We show that for Markov chains admitting a spectral gap, variants of the \\emph{PageRank} chain are robust in the sense that, given an \\emph{arbitrary} corruption of the edges emanating from an $\\epsilon$-measure of the nodes, the PageRank distribution of the corrupted chain will be $\\mathsf{poly}(\\varepsilon)$ close in total variation to the original distribution under mild conditions on the restart distribution. Our work thus shows that PageRank serves as a simple regularizer against broad, realistic corruptions with algorithmic guarantees that are dimension-free and scale gracefully in terms of necessary and natural parameters.",
      "authors": [
        "Jason Gaitonde",
        "Elchanan Mossel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T01:48:12+00:00",
          "link": "https://arxiv.org/abs/2507.15176v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "On Algorithmic Robustness of Corrupted Markov Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15176",
        "HTML": "https://arxiv.org/html/2507.15176",
        "PDF": "https://arxiv.org/pdf/2507.15176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the algorithmic robustness of Markov chains and their stationary distributions under adversarial corruptions, which does not relate to LLM training data processing activities such as data collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15404",
      "abstract": "Extracting a quad mesh from a grid preserving map is straightforward in theory, but typical inputs are not exactly grid preserving maps. Previous works can manage minor deviations from grid preserving maps, but without a clear specification of what is acceptable. This work clarifies how typical inputs differ from a grid preserving map, and shows how the differences with a grid preserving map can be reflected by a sequence of operations acting on a discrete structure. It opens research opportunities for the design of a robust quad extraction algorithm.",
      "authors": [
        "Nicolas Ray (PIXEL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:06:11+00:00",
          "link": "https://arxiv.org/abs/2507.15404v1",
          "size": "8626kb",
          "version": "v1"
        }
      ],
      "title": "On Quad Mesh Extraction From Messy Grid Preserving Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15404",
        "PDF": "https://arxiv.org/pdf/2507.15404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The content is about quad mesh extraction from grid preserving maps, which is outside the domain of LLM training data processing, making it irrelevant."
      },
      "source": "arXiv"
    },
    {
      "id": "1909.12738",
      "abstract": "Recent advances in the field of Business Process Management have brought about several suites able to model complex data objects along with the traditional control flow perspective. Nonetheless, when it comes to formal verification there is still the lack of effective verification tools on imperative data-aware process models and executions: the data perspective is often abstracted away and verification tools are often missing. In this paper we provide a concrete framework for formal verification of reachability properties on imperative data-aware business processes. We start with an expressive, yet empirically tractable class of data-aware process models, an extension of Workflow Nets, and we provide a rigorous mapping between the semantics of such models and that of three important paradigms for reasoning about dynamic systems: Action Languages, Classical Planning, and Model Checking. Then we perform a comprehensive assessment of the performance of three popular tools supporting the above paradigms in solving reachability problems for imperative data-aware business processes, which paves the way for a theoretically well founded and practically viable exploitation of formal verification techniques on data-aware business processes.",
      "authors": [
        "Riccardo De Masellis and Chiara Di Francescomarino and Chiara Ghidini and Sergio Tessaris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-27T15:15:55+00:00",
          "link": "https://arxiv.org/abs/1909.12738v1",
          "size": "1525kb",
          "version": "v1"
        },
        {
          "date": "2020-09-03T15:07:02+00:00",
          "link": "https://arxiv.org/abs/1909.12738v2",
          "size": "1533kb",
          "version": "v2"
        }
      ],
      "title": "Solving reachability problems on data-aware workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.12738",
        "PDF": "https://arxiv.org/pdf/1909.12738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for verifying reachability in data-aware workflows. It does not involve training data processing for LLMs."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01334",
      "abstract": "The burgeoning volume of multi-modal data necessitates advanced retrieval paradigms beyond unimodal and cross-modal approaches. Composed Multi-modal Retrieval (CMR) emerges as a pivotal next-generation technology, enabling users to query images or videos by integrating a reference visual input with textual modifications, thereby achieving unprecedented flexibility and precision. This paper provides a comprehensive survey of CMR, covering its fundamental challenges, technical advancements, and applications. CMR is categorized into supervised, zero-shot, and semi-supervised learning paradigms. We discuss key research directions, including data construction, model architecture, and loss optimization in supervised CMR, as well as transformation frameworks and linear integration in zero-shot CMR, and semi-supervised CMR that leverages generated pseudo-triplets while addressing data noise/uncertainty. Additionally, we extensively survey the diverse application landscape of CMR, highlighting its transformative potential in e-commerce, social media, search engines, public security, etc. Seven high impact application scenarios are explored in detail with benchmark data sets and performance analysis. Finally, we further provide new potential research directions with the hope of inspiring exploration in other yet-to-be-explored fields. A curated list of works is available at: https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval",
      "authors": [
        "Kun Zhang",
        "Jingyu Li",
        "Zhe Li",
        "Jingjing Zhang",
        "Fan Li",
        "Yandong Liu",
        "Rui Yan",
        "Zihang Jiang",
        "Nan Chen",
        "Lei Zhang",
        "Yongdong Zhang",
        "Zhendong Mao",
        "and S.Kevin Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T09:18:43+00:00",
          "link": "https://arxiv.org/abs/2503.01334v1",
          "size": "165kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T17:16:52+00:00",
          "link": "https://arxiv.org/abs/2503.01334v2",
          "size": "9495kb",
          "version": "v2"
        }
      ],
      "title": "Composed Multi-modal Retrieval: A Survey of Approaches and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01334",
        "HTML": "https://arxiv.org/html/2503.01334",
        "PDF": "https://arxiv.org/pdf/2503.01334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper surveys multi-modal retrieval and mentions data construction, the primary focus is not on LLM training data processing, but rather on retrieval systems and their applications."
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Data Augmentation",
        "Image Retrieval",
        "Person Retrieval",
        "Retrieval",
        "Video Retrieval"
      ],
      "repo_urls": [
        "https://github.com/kkzhang95/awesome-composed-multi-modal-retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19557",
      "abstract": "Text-to-motion generative models span a wide range of 3D human actions but struggle with nuanced stylistic attributes such as a \"Chicken\" style. Due to the scarcity of style-specific data, existing approaches pull the generative prior towards a reference style, which often results in out-of-distribution low quality generations. In this work, we introduce LoRA-MDM, a lightweight framework for motion stylization that generalizes to complex actions while maintaining editability. Our key insight is that adapting the generative prior to include the style, while preserving its overall distribution, is more effective than modifying each individual motion during generation. Building on this idea, LoRA-MDM learns to adapt the prior to include the reference style using only a few samples. The style can then be used in the context of different textual prompts for generation. The low-rank adaptation shifts the motion manifold in a semantically meaningful way, enabling realistic style infusion even for actions not present in the reference samples. Moreover, preserving the distribution structure enables advanced operations such as style blending and motion editing. We compare LoRA-MDM to state-of-the-art stylized motion generation methods and demonstrate a favorable balance between text fidelity and style consistency.",
      "authors": [
        "Haim Sawdayee",
        "Chuan Guo",
        "Guy Tevet",
        "Bing Zhou",
        "Jian Wang",
        "Amit H. Bermano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T11:23:34+00:00",
          "link": "https://arxiv.org/abs/2503.19557v1",
          "size": "3926kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:06:45+00:00",
          "link": "https://arxiv.org/abs/2503.19557v2",
          "size": "3377kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T08:43:30+00:00",
          "link": "https://arxiv.org/abs/2503.19557v3",
          "size": "2810kb",
          "version": "v3"
        }
      ],
      "title": "Dance Like a Chicken: Low-Rank Stylization for Human Motion Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19557",
        "HTML": "https://arxiv.org/html/2503.19557",
        "PDF": "https://arxiv.org/pdf/2503.19557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a framework for motion stylization within human motion diffusion models, unrelated to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19073",
      "abstract": "To facilitate robust and trustworthy deployment of large language models (LLMs), it is essential to quantify the reliability of their generations through uncertainty estimation. While recent efforts have made significant advancements by leveraging the internal logic and linguistic features of LLMs to estimate uncertainty scores, our empirical analysis highlights the pitfalls of these methods to strike a harmonized estimation between indication, balance, and calibration, which hinders their broader capability for accurate uncertainty estimation. To address this challenge, we propose CUE (Corrector for Uncertainty Estimation): A straightforward yet effective method that employs a lightweight model trained on data aligned with the target LLM's performance to adjust uncertainty scores. Comprehensive experiments across diverse models and tasks demonstrate its effectiveness, which achieves consistent improvements of up to 60% over existing methods.",
      "authors": [
        "Rui Li",
        "Jing Long",
        "Muge Qi",
        "Heming Xia",
        "Lei Sha",
        "Peiyi Wang",
        "Zhifang Sui"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-25T10:17:57+00:00",
          "link": "https://arxiv.org/abs/2505.19073v1",
          "size": "489kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T15:35:43+00:00",
          "link": "https://arxiv.org/abs/2505.19073v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "Towards Harmonized Uncertainty Estimation for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19073",
        "HTML": "https://arxiv.org/html/2505.19073",
        "PDF": "https://arxiv.org/pdf/2505.19073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses uncertainty estimation in large language models, specifically proposing a method named CUE to improve uncertainty scores. It does not involve any training data processing operations for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09795",
      "abstract": "Recent advancements in Vision-Language Models like CLIP have enabled zero-shot OOD detection by leveraging both image and textual label information. Among these, negative label-based methods such as NegLabel and CSP have shown promising results by utilizing a lexicon of words to define negative labels for distinguishing OOD samples. However, these methods suffer from detecting in-distribution samples as OOD due to negative labels that are subcategories of in-distribution labels or proper nouns. They also face limitations in handling images that match multiple in-distribution and negative labels. We propose NegRefine, a novel negative label refinement framework for zero-shot OOD detection. By introducing a filtering mechanism to exclude subcategory labels and proper nouns from the negative label set and incorporating a multi-matching-aware scoring function that dynamically adjusts the contributions of multiple labels matching an image, NegRefine ensures a more robust separation between in-distribution and OOD samples. We evaluate NegRefine on large-scale benchmarks, including ImageNet-1K. The code is available at https://github.com/ah-ansari/NegRefine.",
      "authors": [
        "Amirhossein Ansari",
        "Ke Wang",
        "Pulei Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:15:30+00:00",
          "link": "https://arxiv.org/abs/2507.09795v1",
          "size": "782kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.09795v2",
          "size": "782kb",
          "version": "v2"
        }
      ],
      "title": "NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09795",
        "HTML": "https://arxiv.org/html/2507.09795",
        "PDF": "https://arxiv.org/pdf/2507.09795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents a framework for zero-shot OOD detection in Vision-Language Models, focusing on negative label refinement, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11688",
      "abstract": "Contemporary large models often exhibit behaviors suggesting the presence of low-level primitives that compose into modules with richer functionality, but these fundamental building blocks remain poorly understood. We investigate this compositional structure in linear layers by asking: can we identify/synthesize linear transformations from a minimal set of geometric primitives? Using Clifford algebra, we show that linear layers can be expressed as compositions of bivectors -- geometric objects encoding oriented planes -- and introduce a differentiable algorithm that decomposes them into products of rotors. This construction uses only O(log^2 d) parameters, versus O(d^2) required by dense matrices. Applied to the key, query, and value projections in LLM attention layers, our rotor-based layers match the performance of strong baselines such as block-Hadamard and low-rank approximations. Our findings provide an algebraic perspective on how these geometric primitives can compose into higher-level functions within deep models.",
      "authors": [
        "Travis Pence",
        "Daisuke Yamada",
        "Vikas Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:46:00+00:00",
          "link": "https://arxiv.org/abs/2507.11688v1",
          "size": "80kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:19:28+00:00",
          "link": "https://arxiv.org/abs/2507.11688v2",
          "size": "80kb",
          "version": "v2"
        }
      ],
      "title": "Composing Linear Layers from Irreducibles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11688",
        "HTML": "https://arxiv.org/html/2507.11688",
        "PDF": "https://arxiv.org/pdf/2507.11688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates the compositional structure in linear layers of neural networks using geometric primitives. It addresses model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14680",
      "abstract": "Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel tissue analysis across various pathological tasks. While recent advancements in multi-modal large language models (MLLMs) allow multi-task WSI analysis through natural language, they often underperform compared to task-specific models. Collaborative multi-agent systems have emerged as a promising solution to balance versatility and accuracy in healthcare, yet their potential remains underexplored in pathology-specific domains. To address these issues, we propose WSI-Agents, a novel collaborative multi-agent system for multi-modal WSI analysis. WSI-Agents integrates specialized functional agents with robust task allocation and verification mechanisms to enhance both task-specific accuracy and multi-task versatility through three components: (1) a task allocation module assigning tasks to expert agents using a model zoo of patch and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through internal consistency checks and external validation using pathology knowledge bases and domain-specific models, and (3) a summary module synthesizing the final summary with visual interpretation maps. Extensive experiments on multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs and medical agent frameworks across diverse tasks.",
      "authors": [
        "Xinheng Lyu",
        "Yuci Liang",
        "Wenting Chen",
        "Meidan Ding",
        "Jiaqi Yang",
        "Guolin Huang",
        "Daokun Zhang",
        "Xiangjian He",
        "and Linlin Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:11:03+00:00",
          "link": "https://arxiv.org/abs/2507.14680v1",
          "size": "6402kb",
          "version": "v1"
        }
      ],
      "title": "WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14680",
        "HTML": "https://arxiv.org/html/2507.14680",
        "PDF": "https://arxiv.org/pdf/2507.14680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a multi-agent system for whole slide image analysis in pathology. Its focus is on improving medical image analysis capabilities, not on LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15061",
      "abstract": "The advent of Large Language Model (LLM)-powered agents has revolutionized artificial intelligence by enabling solutions to complex, open-ended tasks through web-based information-seeking (IS) capabilities. The scarcity of high-quality training data has limited the development of IS agents. Existing approaches typically adopt an information-driven paradigm that first collects web data and then generates questions based on the retrieval. However, this may lead to inconsistency between information structure and reasoning structure, question and answer. To mitigate, we propose a formalization-driven IS data synthesis framework WebShaper to construct a dataset. WebShaper systematically formalizes IS tasks through set theory. Central to the formalization is the concept of Knowledge Projections (KP), which enables precise control over reasoning structure by KP operation compositions. During synthesis, we begin by creating seed tasks, then use a multi-step expansion process. At each step, an agentic Expander expands the current formal question more complex with retrieval and validation tools based on our formalization. We train our model on the synthesized dataset. Experiment results demonstrate that WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks.",
      "authors": [
        "Zhengwei Tao",
        "Jialong Wu",
        "Wenbiao Yin",
        "Junkai Zhang",
        "Baixuan Li",
        "Haiyang Shen",
        "Kuan Li",
        "Liwen Zhang",
        "Xinyu Wang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T17:53:37+00:00",
          "link": "https://arxiv.org/abs/2507.15061v1",
          "size": "2166kb",
          "version": "v1"
        }
      ],
      "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15061",
        "PDF": "https://arxiv.org/pdf/2507.15061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces WebShaper, a formalization-driven IS data synthesis framework to construct datasets for IS tasks, directly contributing to LLM training data processing by generating new, high-quality datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15173",
      "abstract": "We study the problem of learning the structure and parameters of the Ising model, a fundamental model of high-dimensional data, when observing the evolution of an associated Markov chain. A recent line of work has studied the natural problem of learning when observing an evolution of the well-known Glauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018, Gaitonde, Mossel STOC 2024], which provides an arguably more realistic generative model than the classical i.i.d. setting. However, this prior work crucially assumes that all site update attempts are observed, \\emph{even when this attempt does not change the configuration}: this strong observation model is seemingly essential for these approaches. While perhaps possible in restrictive contexts, this precludes applicability to most realistic settings where we can observe \\emph{only} the stochastic evolution itself, a minimal and natural assumption for any process we might hope to learn from. However, designing algorithms that succeed in this more realistic setting has remained an open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018, Gaitonde, Moitra, Mossel, STOC 2025].\n  In this work, we give the first algorithms that efficiently learn the Ising model in this much more natural observation model that only observes when the configuration changes. For Ising models with maximum degree $d$, our algorithm recovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log n$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time, which qualitatively matches the state-of-the-art even in the i.i.d. setting in a much weaker observation model. Our analysis holds more generally for a broader class of reversible, single-site Markov chains that also includes the popular Metropolis chain by leveraging more robust properties of reversible Markov chains.",
      "authors": [
        "Jason Gaitonde",
        "Ankur Moitra",
        "Elchanan Mossel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T01:26:57+00:00",
          "link": "https://arxiv.org/abs/2507.15173v1",
          "size": "66kb",
          "version": "v1"
        }
      ],
      "title": "Better Models and Algorithms for Learning Ising Models from Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15173",
        "HTML": "https://arxiv.org/html/2507.15173",
        "PDF": "https://arxiv.org/pdf/2507.15173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on learning Ising models from dynamics, which involves algorithms for high-dimensional data learning but is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15285",
      "abstract": "Recent advances in biometric systems have significantly improved the detection and prevention of fraudulent activities. However, as detection methods improve, attack techniques become increasingly sophisticated. Attacks on face recognition systems can be broadly divided into physical and digital approaches. Traditionally, deep learning models have been the primary defence against such attacks. While these models perform exceptionally well in scenarios for which they have been trained, they often struggle to adapt to different types of attacks or varying environmental conditions. These subsystems require substantial amounts of training data to achieve reliable performance, yet biometric data collection faces significant challenges, including privacy concerns and the logistical difficulties of capturing diverse attack scenarios under controlled conditions. This work investigates the application of Vision Language Models (VLM) and proposes an in-context learning framework for detecting physical presentation attacks and digital morphing attacks in biometric systems. Focusing on open-source models, the first systematic framework for the quantitative evaluation of VLMs in security-critical scenarios through in-context learning techniques is established. The experimental evaluation conducted on freely available databases demonstrates that the proposed subsystem achieves competitive performance for physical and digital attack detection, outperforming some of the traditional CNNs without resource-intensive training. The experimental results validate the proposed framework as a promising tool for improving generalisation in attack detection.",
      "authors": [
        "Lazaro Janier Gonzalez-Soler",
        "Maciej Salwowski and Christoph Busch"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:35:46+00:00",
          "link": "https://arxiv.org/abs/2507.15285v1",
          "size": "1483kb",
          "version": "v1"
        }
      ],
      "title": "In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15285",
        "HTML": "https://arxiv.org/html/2507.15285",
        "PDF": "https://arxiv.org/pdf/2507.15285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using Vision Language Models for detecting attacks in face recognition systems, with no direct contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15773",
      "abstract": "We present Supernova, a 650M-parameter decoder-only transformer that demonstrates how careful architectural design and tokenization innovation can achieve the performance of larger models while maintaining computational efficiency. Our architecture combines Rotary Positional Embeddings (RoPE), Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for computational efficiency, and SwiGLU activation functions. A critical innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which achieves state-of-the-art compression performance. Through detailed analysis, we show that Supernova achieves 90% of the performance of 1B-parameter models while using 53% fewer parameters and requiring only 100B training tokens--an order of magnitude less than competing models. Our findings challenge the prevailing scaling paradigm, demonstrating that architectural efficiency and tokenization quality can compensate for reduced parameter counts.",
      "authors": [
        "Andrei-Valentin Tanase",
        "Elena Pelican"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:27:48+00:00",
          "link": "https://arxiv.org/abs/2507.15773v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Supernova: Achieving More with Less in Transformer Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15773",
        "HTML": "https://arxiv.org/html/2507.15773",
        "PDF": "https://arxiv.org/pdf/2507.15773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper primarily focuses on architectural design and efficiency of transformer models, it mentions a custom tokenizer, which relates to data processing but is not the main contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12721",
      "abstract": "The MinRank problem is a simple linear algebra problem: given matrices with coefficients in a field, find a non trivial linear combination of the matrices that has a small rank.  There are several algebraic modeling of the problem. The main ones are: the Kipnis-Shamir modeling, the Minors modeling and the Support-Minors modeling. The Minors modeling has been studied by Faug{\\`e}re et al. in 2010, where the authors provide an analysis of the complexity of computing a Gr{\\\"o}bner basis of the modeling, through the computation of the exact Hilbert Series for a generic instance. For the Support-Minors modeling, the first terms of the Hilbert Series are given by Bardet et al. in 2020 based on an heuristic and experimental work.  In this work, we provide a formula and a proof for the complete Hilbert Series of the Support Minors modeling for generic instances. This is done by adapting well known results on determinantal ideals to an ideal generated by a particular subset of the set of all minors of a matrix of variables. We then show that this ideal is generated by",
      "authors": [
        "Magali Bardet (CA - LITIS)",
        "Alban Gilard (CA - LITIS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T10:38:06+00:00",
          "link": "https://arxiv.org/abs/2502.12721v1",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:13:58+00:00",
          "link": "https://arxiv.org/abs/2502.12721v2",
          "size": "31kb",
          "version": "v2"
        }
      ],
      "title": "Computation of the Hilbert Series for the Support-Minors Modeling of the MinRank Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12721",
        "PDF": "https://arxiv.org/pdf/2502.12721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computing the Hilbert Series for algebraic modeling in the context of the MinRank problem, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.21284",
      "abstract": "Traditional approaches to learning fair machine learning models often require rebuilding models from scratch, typically without considering potentially existing models. In a context where models need to be retrained frequently, this can lead to inconsistent model updates, as well as redundant and costly validation testing. To address this limitation, we introduce the notion of controlled model debiasing, a novel supervised learning task relying on two desiderata: that the differences between the new fair model and the existing one should be (i) minimal and (ii) interpretable. After providing theoretical guarantees to this new problem, we introduce a novel algorithm for algorithmic fairness, COMMOD, that is both model-agnostic and does not require the sensitive attribute at test time. In addition, our algorithm is explicitly designed to enforce minimal and interpretable changes between biased and debiased predictions in a binary classification task, a property that, while highly desirable in high-stakes applications, is rarely prioritized as an explicit objective in fairness literature. Our approach combines a concept-based architecture and adversarial learning and we demonstrate through empirical results that it achieves comparable performance to state-of-the-art debiasing methods while performing minimal and interpretable prediction changes.",
      "authors": [
        "Federico Di Gennaro and Thibault Laugel and Vincent Grari and Marcin Detyniecki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T18:03:55+00:00",
          "link": "https://arxiv.org/abs/2502.21284v1",
          "size": "835kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T11:56:52+00:00",
          "link": "https://arxiv.org/abs/2502.21284v2",
          "size": "199kb",
          "version": "v2"
        }
      ],
      "title": "Controlled Model Debiasing through Minimal and Interpretable Updates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.21284",
        "HTML": "https://arxiv.org/html/2502.21284",
        "PDF": "https://arxiv.org/pdf/2502.21284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model debiasing techniques through minimal updates in model predictions. It does not involve any data processing operations related to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.10968",
      "abstract": "Large Language Models (LLMs) have shown notable potential in code generation for optimization algorithms, unlocking exciting new opportunities. This paper examines how LLMs, rather than creating algorithms from scratch, can improve existing ones without the need for specialized expertise. To explore this potential, we selected 10 baseline optimization algorithms from various domains (metaheuristics, reinforcement learning, deterministic, and exact methods) to solve the classic Travelling Salesman Problem. The results show that our simple methodology often results in LLM-generated algorithm variants that improve over the baseline algorithms in terms of solution quality, reduction in computational time, and simplification of code complexity, all without requiring specialized optimization knowledge or advanced algorithmic implementation skills.",
      "authors": [
        "Camilo Chac\\'on Sartori",
        "Christian Blum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T00:26:00+00:00",
          "link": "https://arxiv.org/abs/2503.10968v1",
          "size": "1640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T21:55:15+00:00",
          "link": "https://arxiv.org/abs/2503.10968v2",
          "size": "1662kb",
          "version": "v2"
        }
      ],
      "title": "Combinatorial Optimization for All: Using LLMs to Aid Non-Experts in Improving Optimization Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10968",
        "PDF": "https://arxiv.org/pdf/2503.10968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using LLMs to enhance optimization algorithms rather than addressing any aspect of LLM training data processing for pretraining or fine-tuning."
      },
      "tasks": [
        "All",
        "Code Generation",
        "Combinatorial Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09681",
      "abstract": "High-resolution elevation estimations are essential to understand catchment and hillslope hydrology, study urban morphology and dynamics, and monitor the growth, decline, and mortality of terrestrial ecosystems. Various deep learning approaches (e.g., super-resolution techniques, monocular depth estimation) have been developed to create high-resolution Digital Elevation Models (DEMs). However, super-resolution techniques are limited by the upscaling factor, and monocular depth estimation lacks global elevation context, making its conversion to a seamless DEM restricted. The recently introduced technique of prompt-based monocular depth estimation has opened new opportunities to extract estimates of absolute elevation in a global context. We present here a framework for the estimation of high-resolution DEMs as a new paradigm for absolute global elevation mapping. It is exemplified using low-resolution Shuttle Radar Topography Mission (SRTM) elevation data as prompts and high-resolution RGB imagery from the National Agriculture Imagery Program (NAIP). The approach fine-tunes a vision transformer encoder with LiDAR-derived DEMs and employs a versatile prompting strategy, enabling tasks such as DEM estimation, void filling, and updating. Our framework achieves a 100x resolution gain (from 30-m to 30-cm), surpassing prior methods by an order of magnitude. Evaluations across three diverse U.S. landscapes show robust generalization, capturing urban structures and fine-scale terrain features with < 5 m MAE relative to LiDAR, improving over SRTM by up to 18%. Hydrological analysis confirms suitability for hazard and environmental studies. We demonstrate scalability by applying the framework to large regions in the U.S. and Israel. All code and pretrained models are publicly available at: https://osherr1996.github.io/prompt2dem_propage/.",
      "authors": [
        "Osher Rafaeli",
        "Tal Svoray and Ariel Nahlieli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:38:22+00:00",
          "link": "https://arxiv.org/abs/2507.09681v1",
          "size": "41601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:29:28+00:00",
          "link": "https://arxiv.org/abs/2507.09681v2",
          "size": "39770kb",
          "version": "v2"
        }
      ],
      "title": "Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09681",
        "HTML": "https://arxiv.org/html/2507.09681",
        "PDF": "https://arxiv.org/pdf/2507.09681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for generating high-resolution Digital Elevation Models (DEMs) using deep learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14140",
      "abstract": "Model-based seismic inversion is a key technique in reservoir characterization, but traditional methods face significant limitations, such as relying on 1D average stationary wavelets and assuming an unrealistic lateral resolution. To address these challenges, we propose a Geophysics-Informed Neural Network (GINN) that integrates deep learning with seismic modeling. This novel approach employs a Deep Convolutional Neural Network (DCNN) to simultaneously estimate Point Spread Functions (PSFs) and acoustic impedance (IP). PSFs are divided into zero-phase and residual components to ensure geophysical consistency and to capture fine details. We used synthetic data from the SEAM Phase I Earth Model to train the GINN for 100 epochs (approximately 20 minutes) using a 2D UNet architecture. The network's inputs include positional features and a low-frequency impedance (LF-IP) model. A self-supervised loss function combining Mean Squared Error (MSE) and Structural Similarity Index Measure (SSIM) was employed to ensure accurate results. The GINN demonstrated its ability to generate high-resolution IP and realistic PSFs, aligning with expected geological features. Unlike traditional 1D wavelets, the GINN produces PSFs with limited lateral resolution, reducing noise and improving accuracy. Future work will aim to refine the training process and validate the methodology with real seismic data.",
      "authors": [
        "Marcus Saraiva",
        "Ana Muller",
        "Alexandre Maul"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T18:10:11+00:00",
          "link": "https://arxiv.org/abs/2507.14140v1",
          "size": "333kb",
          "version": "v1"
        }
      ],
      "title": "Geophysics-informed neural network for model-based seismic inversion using surrogate point spread functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14140",
        "PDF": "https://arxiv.org/pdf/2507.14140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on seismic inversion and geophysics-informed neural networks, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14193",
      "abstract": "Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for \"open-source\" models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper models the strategic interactions among the creator of a general-purpose model (the generalist) and the entity that fine-tunes the general-purpose model to a specialized domain or task (the specialist), in response to regulatory requirements on model openness. We present a stylized model of the regulator's choice of an open-source definition to evaluate which AI openness standards will establish appropriate economic incentives for developers. Our results characterize market equilibria -- specifically, upstream model release decisions and downstream fine-tuning efforts -- under various openness regulations and present a range of effective regulatory penalties and open-source thresholds. Overall, we find the model's baseline performance determines when increasing the regulatory penalty vs. the open-source threshold will significantly alter the generalist's release strategy. Our model provides a theoretical foundation for AI governance decisions around openness and enables evaluation and refinement of practical open-source policies.",
      "authors": [
        "Tori Qiu and Benjamin Laufer and Jon Kleinberg and Hoda Heidari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:08:31+00:00",
          "link": "https://arxiv.org/abs/2507.14193v1",
          "size": "1933kb",
          "version": "v1"
        }
      ],
      "title": "A Formal Model of the Economic Impacts of AI Openness Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14193",
        "PDF": "https://arxiv.org/pdf/2507.14193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper models economic impacts of AI openness regulation, focusing on regulatory frameworks and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15617",
      "abstract": "Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated epidemiological outputs, including fully AI-generated papers, we demonstrate that recently developed agentic systems can now design and execute epidemiological analysis, albeit to varied quality (see https://github.com/edlowther/automated-epidemiology). Epidemiologists have new opportunities to empirically test and benchmark AI systems; realising the potential of AI will require two-way engagement between epidemiologists and engineers.",
      "authors": [
        "David Bann",
        "Ed Lowther",
        "Liam Wright",
        "Yevgeniya Kovalchuk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:41:52+00:00",
          "link": "https://arxiv.org/abs/2507.15617v1",
          "size": "4176kb",
          "version": "v1"
        }
      ],
      "title": "Why can't Epidemiology be automated (yet)?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15617",
        "PDF": "https://arxiv.org/pdf/2507.15617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the automation of epidemiological research using AI, with no focus on LLM training data processing or improvements directly applicable to such processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.20435",
      "abstract": "Convergence rate analysis for general state-space Markov chains is fundamentally important in areas such as Markov chain Monte Carlo and algorithmic analysis (for computing explicit convergence bounds). This problem, however, is notoriously difficult because traditional analytical methods often do not generate practically useful convergence bounds for realistic Markov chains. We propose the Deep Contractive Drift Calculator (DCDC), the first general-purpose sample-based algorithm for bounding the convergence of Markov chains to stationarity in Wasserstein distance. The DCDC has two components. First, inspired by the new convergence analysis framework in Qu, Blanchet and Glynn (2023), we introduce the Contractive Drift Equation (CDE), the solution of which leads to an explicit convergence bound. Second, we develop an efficient neural-network-based CDE solver. Equipped with these two components, DCDC solves the CDE and converts the solution into a convergence bound. We analyze the sample complexity of the algorithm and further demonstrate the effectiveness of the DCDC by generating convergence bounds for realistic Markov chains arising from stochastic processing networks as well as constant step-size stochastic optimization.",
      "authors": [
        "Yanlin Qu",
        "Jose Blanchet",
        "Peter Glynn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-30T19:26:51+00:00",
          "link": "https://arxiv.org/abs/2405.20435v1",
          "size": "1563kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T13:25:48+00:00",
          "link": "https://arxiv.org/abs/2405.20435v2",
          "size": "1563kb",
          "version": "v2"
        }
      ],
      "title": "Deep Learning for Computing Convergence Rates of Markov Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.20435",
        "HTML": "https://arxiv.org/html/2405.20435",
        "PDF": "https://arxiv.org/pdf/2405.20435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses convergence rate analysis for Markov chains using deep learning, aiming to produce convergence bounds. It does not involve any aspect of data processing in the context of LLM training data."
      },
      "tasks": [
        "Deep Learning",
        "Efficient Neural Network",
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16002",
      "abstract": "We describe KVLink, an approach for efficient key-value (KV) cache reuse in large language models (LLMs). In many LLM applications, different inputs can share overlapping context, such as the same retrieved document appearing in multiple queries. However, the LLMs still need to encode the entire context for each query, leading to redundant computation. In this paper, we investigate a new strategy to eliminate such inefficiency, where the KV cache of each document is precomputed independently. During inference, the KV caches of retrieved documents are concatenated, allowing the model to reuse cached representations instead of recomputing them. To mitigate the performance degradation when using KV caches computed independently for each document, KVLink introduces two key techniques: adjusting positional embeddings of the KV cache at inference to match the global position after concatenation, and using trainable special tokens to restore self-attention across independently encoded documents. Experiments across 7 datasets demonstrate that KVLink improves question answering accuracy by an average of 4% over state-of-the-art methods. Furthermore, by leveraging precomputed KV caches, our approach reduces time-to-first-token by up to 96% compared to standard LLM inference, making it a scalable and efficient solution for context reuse. Additionally, KVLink can be combined with KV cache compression to further save cache loading and storage overhead while outperforming the baselines.",
      "authors": [
        "Jingbo Yang",
        "Bairu Hou",
        "Wei Wei",
        "Yujia Bao",
        "Shiyu Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T23:34:29+00:00",
          "link": "https://arxiv.org/abs/2502.16002v1",
          "size": "572kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T20:42:08+00:00",
          "link": "https://arxiv.org/abs/2502.16002v2",
          "size": "492kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T07:41:03+00:00",
          "link": "https://arxiv.org/abs/2502.16002v3",
          "size": "359kb",
          "version": "v3"
        }
      ],
      "title": "KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16002",
        "HTML": "https://arxiv.org/html/2502.16002",
        "PDF": "https://arxiv.org/pdf/2502.16002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "KVLink is aimed at improving LLM efficiency through efficient cache reuse during inference, not training data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/UCSB-NLP-Chang/KVLink"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02701",
      "abstract": "We analyze the extent to which internal representations of language models (LMs) identify and distinguish mentions of named entities, focusing on the many-to-many correspondence between entities and their mentions. We first formulate two problems of entity mentions -- ambiguity and variability -- and propose a framework analogous to clustering quality metrics. Specifically, we quantify through cluster analysis of LM internal representations the extent to which mentions of the same entity cluster together and mentions of different entities remain separated. Our experiments examine five Transformer-based autoregressive models, showing that they effectively identify and distinguish entities with metrics analogous to precision and recall ranging from 0.66 to 0.9. Further analysis reveals that entity-related information is compactly represented in a low-dimensional linear subspace at early LM layers. Additionally, we clarify how the characteristics of entity representations influence word prediction performance. These findings are interpreted through the lens of isomorphism between LM representations and entity-centric knowledge structures in the real world, providing insights into how LMs internally organize and use entity information.",
      "authors": [
        "Masaki Sakata",
        "Benjamin Heinzerling",
        "Sho Yokoi",
        "Takumi Ito",
        "Kentaro Inui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T09:55:21+00:00",
          "link": "https://arxiv.org/abs/2506.02701v1",
          "size": "5783kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T03:15:30+00:00",
          "link": "https://arxiv.org/abs/2506.02701v2",
          "size": "5783kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T01:17:55+00:00",
          "link": "https://arxiv.org/abs/2506.02701v3",
          "size": "5783kb",
          "version": "v3"
        },
        {
          "date": "2025-07-20T11:22:13+00:00",
          "link": "https://arxiv.org/abs/2506.02701v4",
          "size": "5783kb",
          "version": "v4"
        }
      ],
      "title": "On Entity Identification in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02701",
        "HTML": "https://arxiv.org/html/2506.02701",
        "PDF": "https://arxiv.org/pdf/2506.02701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes entity identification within language models, which involves model internals but does not contribute directly to training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10827",
      "abstract": "The SENCOTEN language, spoken on the Saanich peninsula of southern Vancouver Island, is in the midst of vigorous language revitalization efforts to turn the tide of language loss as a result of colonial language policies. To support these on-the-ground efforts, the community is turning to digital technology. Automatic Speech Recognition (ASR) technology holds great promise for accelerating language documentation and the creation of educational resources. However, developing ASR systems for SENCOTEN is challenging due to limited data and significant vocabulary variation from its polysynthetic structure and stress-driven metathesis. To address these challenges, we propose an ASR-driven documentation pipeline that leverages augmented speech data from a text-to-speech (TTS) system and cross-lingual transfer learning with Speech Foundation Models (SFMs). An n-gram language model is also incorporated via shallow fusion or n-best restoring to maximize the use of available data. Experiments on the SENCOTEN dataset show a word error rate (WER) of 19.34% and a character error rate (CER) of 5.09% on the test set with a 57.02% out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the potential of our ASR-driven pipeline to support SENCOTEN language documentation.",
      "authors": [
        "Mengzhe Geng",
        "Patrick Littell",
        "Aidan Pine",
        "PEN\\'A\\'C",
        "Marc Tessier",
        "Roland Kuhn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:44:35+00:00",
          "link": "https://arxiv.org/abs/2507.10827v1",
          "size": "9287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T14:35:26+00:00",
          "link": "https://arxiv.org/abs/2507.10827v2",
          "size": "9287kb",
          "version": "v2"
        }
      ],
      "title": "Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10827",
        "HTML": "https://arxiv.org/html/2507.10827",
        "PDF": "https://arxiv.org/pdf/2507.10827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on supporting language documentation for SENCOTEN using an ASR-driven pipeline and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14237",
      "abstract": "This paper explores the outcome of training state-ofthe-art dereverberation models with supervision settings ranging from weakly-supervised to fully unsupervised, relying solely on reverberant signals and an acoustic model for training. Most of the existing deep learning approaches typically require paired dry and reverberant data, which are difficult to obtain in practice. We develop instead a sequential learning strategy motivated by a bayesian formulation of the dereverberation problem, wherein acoustic parameters and dry signals are estimated from reverberant inputs using deep neural networks, guided by a reverberation matching loss. Our most data-efficient variant requires only 100 reverberation-parameter-labelled samples to outperform an unsupervised baseline, demonstrating the effectiveness and practicality of the proposed method in low-resource scenarios.",
      "authors": [
        "Louis Bahrman (IDS",
        "S2A)",
        "Mathieu Fontaine (IDS",
        "S2A)",
        "Ga\\\"el Richard (IDS",
        "S2A)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:26:18+00:00",
          "link": "https://arxiv.org/abs/2507.14237v1",
          "size": "1128kb",
          "version": "v1"
        }
      ],
      "title": "U-DREAM: Unsupervised Dereverberation guided by a Reverberation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14237",
        "PDF": "https://arxiv.org/pdf/2507.14237"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses unsupervised dereverberation models guided by a reverberation model, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14259",
      "abstract": "We study how eigenvectors of random regular graphs behave when projected onto fixed directions. For a random $d$-regular graph with $N$ vertices, where the degree $d$ grows slowly with $N$, we prove that these projections follow approximately normal distributions. Our main result establishes a Berry-Esseen bound showing convergence to the Gaussian with error $O(\\sqrt{d} \\cdot N^{-1/6+\\varepsilon})$ for degrees $d \\leq N^{1/4}$. This bound significantly improves upon previous results that had error terms scaling as $d^3$, and we prove our $\\sqrt{d}$ scaling is optimal by establishing a matching lower bound. Our proof combines three techniques: (1) refined concentration inequalities that exploit the specific variance structure of regular graphs, (2) a vector-based analysis of the resolvent that avoids iterative procedures, and (3) a framework combining Stein's method with graph-theoretic tools to control higher-order fluctuations. These results provide sharp constants for eigenvector universality in the transition from sparse to moderately dense graphs.",
      "authors": [
        "Leonhard Nagel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Discrete Mathematics (cs.DM)",
        "Mathematical Physics (math-ph)",
        "Combinatorics (math.CO)",
        "Mathematical Physics (math.MP)",
        "Spectral Theory (math.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T12:45:57+00:00",
          "link": "https://arxiv.org/abs/2507.14259v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Sharp Square Root Bounds for Edge Eigenvector Universality in Sparse Random Regular Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14259",
        "HTML": "https://arxiv.org/html/2507.14259",
        "PDF": "https://arxiv.org/pdf/2507.14259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the behavior of eigenvectors in random regular graphs, focusing on mathematical bounds and convergence, with no connection to LLM training data processing or related data techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14272",
      "abstract": "The NuSeC dataset is created by selecting 4 images with the size of 1024*1024 pixels from the slides of each patient among 25 patients. Therefore, there are a total of 100 images in the NuSeC dataset. To carry out a consistent comparative analysis between the methods that will be developed using the NuSeC dataset by the researchers in the future, we divide the NuSeC dataset 75% as the training set and 25% as the testing set. In detail, an image is randomly selected from 4 images of each patient among 25 patients to build the testing set, and then the remaining images are reserved for the training set. While the training set includes 75 images with around 30000 nuclei structures, the testing set includes 25 images with around 6000 nuclei structures.",
      "authors": [
        "Refik Samet",
        "Nooshin Nemati",
        "Emrah Hancer",
        "Serpil Sak",
        "Bilge Ayca Kirmizi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T16:23:07+00:00",
          "link": "https://arxiv.org/abs/2507.14272v1",
          "size": "374kb",
          "version": "v1"
        }
      ],
      "title": "NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14272",
        "PDF": "https://arxiv.org/pdf/2507.14272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the NuSeC dataset for nuclei segmentation in breast cancer images, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14882",
      "abstract": "Deep neural networks (DNNs) offer significant versatility and performance benefits, but their widespread adoption is often hindered by high model complexity and computational demands. Model compression techniques such as pruning have emerged as promising solutions to these challenges. However, it remains critical to ensure that application-specific performance characteristics are preserved during compression. In structured pruning, where groups of structurally coherent elements are removed, conventional importance metrics frequently fail to maintain these essential performance attributes. In this work, we propose an enhanced importance metric framework that not only reduces model size but also explicitly accounts for application-specific performance constraints. We employ multiple strategies to determine the optimal pruning magnitude for each group, ensuring a balance between compression and task performance. Our approach is evaluated on an autoencoder tasked with reconstructing MNIST images. Experimental results demonstrate that the proposed method effectively preserves task-relevant performance, maintaining the model's usability even after substantial pruning, by satisfying the required application-specific criteria.",
      "authors": [
        "Ganesh Sundaram",
        "Jonas Ulmen",
        "Amjad Haider",
        "Daniel G\\\"orges"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T09:50:04+00:00",
          "link": "https://arxiv.org/abs/2507.14882v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14882",
        "HTML": "https://arxiv.org/html/2507.14882",
        "PDF": "https://arxiv.org/pdf/2507.14882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses structured pruning of deep neural networks to reduce model size while preserving application-specific performance. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15130",
      "abstract": "Visual Planning for Assistance (VPA) aims to predict a sequence of user actions required to achieve a specified goal based on a video showing the user's progress. Although recent advances in multimodal large language models (MLLMs) have shown promising results in video understanding, long-horizon visual planning remains a challenging problem. We identify two challenges in training large MLLMs for video-based planning tasks: (1) scarcity of procedural annotations, limiting the model's ability to learn procedural task dynamics effectively, and (2) inefficiency of next-token prediction objective to explicitly capture the structured action space for visual planning when compared to free-form, natural language. To tackle data scarcity, we introduce Auxiliary Task Augmentation. We design and train our model on auxiliary tasks relevant to long-horizon video-based planning (e.g., goal prediction) to augment the model's planning ability. To more explicitly model the structured action space unique to visual planning tasks, we leverage Multi-token Prediction, extending traditional next-token prediction by using multiple heads to predict multiple future tokens during training. Our approach, VideoPlan, achieves state-of-the-art VPA performance on the COIN and CrossTask datasets, surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3 future actions. We further extend our method to the challenging Ego4D Long-term Action Anticipation task, and show that it is on par with the state-of-the-art approaches despite not using specialized egocentric features. Code will be made available.",
      "authors": [
        "Ce Zhang",
        "Yale Song",
        "Ruta Desai",
        "Michael Louis Iuzzolino",
        "Joseph Tighe",
        "Gedas Bertasius",
        "Satwik Kottur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T21:39:05+00:00",
          "link": "https://arxiv.org/abs/2507.15130v1",
          "size": "6134kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15130",
        "HTML": "https://arxiv.org/html/2507.15130",
        "PDF": "https://arxiv.org/pdf/2507.15130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Auxiliary Task Augmentation to tackle data scarcity in training models for visual planning, briefly touching on data augmentation which is relevant to training data processing, but the main focus is on model performance and task design."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15163",
      "abstract": "Evolving security vulnerabilities and shifting operational conditions require frequent updates to network security policies. These updates include adjustments to incident response procedures and modifications to access controls, among others. Reinforcement learning methods have been proposed for automating such policy adaptations, but most of the methods in the research literature lack performance guarantees and adapt slowly to changes. In this paper, we address these limitations and present a method for computing security policies that is scalable, offers theoretical guarantees, and adapts quickly to changes. It assumes a model or simulator of the system and comprises three components: belief estimation through particle filtering, offline policy computation through aggregation, and online policy adaptation through rollout. Central to our method is a new feature-based aggregation technique, which improves scalability and flexibility. We analyze the approximation error of aggregation and show that rollout efficiently adapts policies to changes under certain conditions. Simulations and testbed results demonstrate that our method outperforms state-of-the-art methods on several benchmarks, including CAGE-2.",
      "authors": [
        "Kim Hammar",
        "Yuchao Li",
        "Tansu Alpcan",
        "Emil C. Lupu",
        "Dimitri Bertsekas"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T00:26:53+00:00",
          "link": "https://arxiv.org/abs/2507.15163v1",
          "size": "621kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Network Security Policies via Belief Aggregation and Rollout",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15163",
        "PDF": "https://arxiv.org/pdf/2507.15163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on adaptive network security policies using reinforcement learning, without addressing LLM training data processing concerns or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15225",
      "abstract": "General-purpose Large Language Models (LLMs) have achieved remarkable success in intelligence, performing comparably to human experts on complex reasoning tasks such as coding and mathematical reasoning. However, generating formal proofs in specialized languages like Lean 4 remains a significant challenge for these models, limiting their application in complex theorem proving and automated verification. Current approaches typically require specializing models through fine-tuning on dedicated formal corpora, incurring high costs for data collection and training. In this work, we introduce \\textbf{Delta Prover}, an agent-based framework that orchestrates the interaction between a general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages the reflection and reasoning capabilities of general-purpose LLMs to interactively construct formal proofs in Lean 4, circumventing the need for model specialization. At its core, the agent integrates two novel, interdependent components: an algorithmic framework for reflective decomposition and iterative proof repair, and a custom Domain-Specific Language (DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta Prover achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test benchmark, surpassing all existing approaches, including those requiring model specialization.} Furthermore, Delta Prover exhibits a significantly stronger test-time scaling law compared to standard Best-of-N proof strategies. Crucially, our findings demonstrate that general-purpose LLMs, when guided by an effective agentic structure, possess substantial untapped theorem-proving capabilities. This presents a computationally efficient alternative to specialized models for robust automated reasoning in formal environments.",
      "authors": [
        "Yichi Zhou",
        "Jianqiu Zhao",
        "Yongxin Zhang",
        "Bohan Wang",
        "Siran Wang",
        "Luoxin Chen",
        "Jiahui Wang",
        "Haowei Chen",
        "Allan Jie",
        "Xinbo Zhang",
        "Haocheng Wang",
        "Luong Trung",
        "Rong Ye",
        "Phan Nhat Hoang",
        "Huishuai Zhang",
        "Peng Sun",
        "Hang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:56:35+00:00",
          "link": "https://arxiv.org/abs/2507.15225v1",
          "size": "16651kb",
          "version": "v1"
        }
      ],
      "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15225",
        "HTML": "https://arxiv.org/html/2507.15225",
        "PDF": "https://arxiv.org/pdf/2507.15225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Delta Prover, an agent framework for formal math problem-solving, rather than focusing on LLM training data processing directly. While it mentions fine-tuning, its main contribution lies in interactive theorem proving."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15386",
      "abstract": "Gridization, the process of partitioning space into grids where users share similar channel characteristics, serves as a fundamental prerequisite for efficient large-scale network optimization. However, existing methods like Geographical or Beam Space Gridization (GSG or BSG) are limited by reliance on unavailable location data or the flawed assumption that similar signal strengths imply similar channel properties. We propose Channel Space Gridization (CSG), a pioneering framework that unifies channel estimation and gridization for the first time. Formulated as a joint optimization problem, CSG uses only beam-level reference signal received power (RSRP) to estimate Channel Angle Power Spectra (CAPS) and partition samples into grids with homogeneous channel characteristics. To perform CSG, we develop the CSG Autoencoder (CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse codebook quantizer, and a physics-informed decoder based on the Localized Statistical Channel Model. On recognizing the limitations of naive training scheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous (PIDA) training scheme for CSG-AE, ensuring stable and effective training by systematically addressing the common pitfalls of the naive training paradigm. Evaluations reveal that CSG-AE excels in CAPS estimation accuracy and clustering quality on synthetic data. On real-world datasets, it reduces Active Mean Absolute Error (MAE) by 30\\% and Overall MAE by 65\\% on RSRP prediction accuracy compared to salient baselines using the same data, while improving channel consistency, cluster sizes balance, and active ratio, advancing the development of gridization for large-scale network optimization.",
      "authors": [
        "Juntao Wang",
        "Feng Yin",
        "Tian Ding",
        "Tsung-Hui Chang",
        "Zhi-Quan Luo",
        "Qi Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:43:34+00:00",
          "link": "https://arxiv.org/abs/2507.15386v1",
          "size": "6018kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Gridize: Segment Physical World by Wireless Communication Channel",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15386",
        "HTML": "https://arxiv.org/html/2507.15386",
        "PDF": "https://arxiv.org/pdf/2507.15386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for gridizing space using wireless communication channels, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15663",
      "abstract": "Background: Text-to-image generation models are widely used across numerous domains. Among these models, Stable Diffusion (SD) - an open-source text-to-image generation model - has become the most popular, producing over 12 billion images annually. However, the widespread use of these models raises concerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the environment, we introduce SustainDiffusion, a search-based approach designed to enhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters and prompt structures that can reduce gender and ethnic bias in generated images while also lowering the energy consumption required for image generation. Importantly, SustainDiffusion maintains image quality comparable to that of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion, testing it against six different baselines using 56 different prompts. Our results demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%, ethnic bias by 59%, and energy consumption (calculated as the sum of CPU and GPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are consistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social and environmental sustainability of text-to-image generation models is possible without fine-tuning or changing the model's architecture.",
      "authors": [
        "Giordano d'Aloisio",
        "Tosin Fadahunsi",
        "Jay Choy",
        "Rebecca Moussa",
        "Federica Sarro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:24:31+00:00",
          "link": "https://arxiv.org/abs/2507.15663v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15663",
        "HTML": "https://arxiv.org/html/2507.15663",
        "PDF": "https://arxiv.org/pdf/2507.15663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing the social and environmental sustainability of Stable Diffusion models, which relates to text-to-image generation, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15824",
      "abstract": "Recent progress in text-to-video (T2V) generation has enabled the synthesis of visually compelling and temporally coherent videos from natural language. However, these models often fall short in basic physical commonsense, producing outputs that violate intuitive expectations around causality, object behavior, and tool use. Addressing this gap, we present PhysVidBench, a benchmark designed to evaluate the physical reasoning capabilities of T2V systems. The benchmark includes 383 carefully curated prompts, emphasizing tool use, material properties, and procedural interactions, and domains where physical plausibility is crucial. For each prompt, we generate videos using diverse state-of-the-art models and adopt a three-stage evaluation pipeline: (1) formulate grounded physics questions from the prompt, (2) caption the generated video with a vision-language model, and (3) task a language model to answer several physics-involved questions using only the caption. This indirect strategy circumvents common hallucination issues in direct video-based evaluation. By highlighting affordances and tool-mediated actions, areas overlooked in current T2V evaluations, PhysVidBench provides a structured, interpretable framework for assessing physical commonsense in generative video models.",
      "authors": [
        "Enes Sanli",
        "Baris Sarper Tezcan",
        "Aykut Erdem",
        "Erkut Erdem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:30:46+00:00",
          "link": "https://arxiv.org/abs/2507.15824v1",
          "size": "34608kb",
          "version": "v1"
        }
      ],
      "title": "Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15824",
        "PDF": "https://arxiv.org/pdf/2507.15824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although it presents a benchmark for video generation models, the paper does not address LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03040",
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in various NLP tasks, yet they still face significant challenges in reasoning and arithmetic. Temporal reasoning, a critical component of natural language understanding, has raised increasing research attention. However, comprehensive testing of Allen's interval relations (e.g., before, after, during) -- a fundamental framework for temporal relationships -- remains underexplored. To fill this gap, we present ChronoSense, a new benchmark for evaluating LLMs' temporal understanding. It includes 16 tasks, focusing on identifying the Allen relation between two temporal events and temporal arithmetic, using both abstract events and real-world data from Wikidata. We assess the performance of seven recent LLMs using this benchmark and the results indicate that models handle Allen relations, even symmetrical ones, quite differently. Moreover, the findings suggest that the models may rely on memorization to answer time-related questions. Overall, the models' low performance highlights the need for improved temporal understanding in LLMs and ChronoSense offers a robust framework for future research in this area. Our dataset and the source code are available at https://github.com/duyguislakoglu/chronosense.",
      "authors": [
        "Duygu Sezen Islakoglu",
        "Jan-Christoph Kalo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T14:27:41+00:00",
          "link": "https://arxiv.org/abs/2501.03040v1",
          "size": "268kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:01:59+00:00",
          "link": "https://arxiv.org/abs/2501.03040v2",
          "size": "269kb",
          "version": "v2"
        }
      ],
      "title": "ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03040",
        "HTML": "https://arxiv.org/html/2501.03040",
        "PDF": "https://arxiv.org/pdf/2501.03040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "ChronoSense presents a new dataset and benchmark for evaluating temporal understanding in LLMs, making a significant contribution to LLM training data processing by providing novel test data to improve model evaluation."
      },
      "tasks": [
        "Memorization",
        "Natural Language Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01909",
      "abstract": "Can transformers learn to perform algorithmic tasks reliably across previously unseen input/output domains? While pre-trained language models show solid accuracy on benchmarks incorporating algorithmic reasoning, assessing the reliability of these results necessitates an ability to distinguish genuine algorithmic understanding from memorization. In this paper, we propose AttentionSpan, an algorithmic benchmark comprising five tasks of infinite input domains where we can disentangle and trace the correct, robust algorithm necessary for the task. This allows us to assess (i) models' ability to extrapolate to unseen types of inputs, including new lengths, value ranges or input domains, but also (ii)to assess the robustness of their learned mechanisms. By analyzing attention maps and performing targeted interventions, we show that attention mechanism directly causes failures in extrapolation. We make the implementation of all our tasks and interpretability methods publicly available at https://github.com/michalspiegel/AttentionSpan .",
      "authors": [
        "Michal Spiegel",
        "Michal \\v{S}tef\\'anik",
        "Marek Kadl\\v{c}\\'ik",
        "Josef Kucha\\v{r}"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T22:50:38+00:00",
          "link": "https://arxiv.org/abs/2503.01909v1",
          "size": "7080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:17:34+00:00",
          "link": "https://arxiv.org/abs/2503.01909v2",
          "size": "7163kb",
          "version": "v2"
        }
      ],
      "title": "Attend or Perish: Benchmarking Attention in Algorithmic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01909",
        "HTML": "https://arxiv.org/html/2503.01909",
        "PDF": "https://arxiv.org/pdf/2503.01909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with evaluating transformers on algorithmic tasks via the AttentionSpan benchmark, concentrating on model assessment rather than any aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00704",
      "abstract": "Generating realistic and controllable weather effects in videos is valuable for many applications. Physics-based weather simulation requires precise reconstructions that are hard to scale to in-the-wild videos, while current video editing often lacks realism and control. In this work, we introduce WeatherWeaver, a video diffusion model that synthesizes diverse weather effects -- including rain, snow, fog, and clouds -- directly into any input video without the need for 3D modeling. Our model provides precise control over weather effect intensity and supports blending various weather types, ensuring both realism and adaptability. To overcome the scarcity of paired training data, we propose a novel data strategy combining synthetic videos, generative image editing, and auto-labeled real-world videos. Extensive evaluations show that our method outperforms state-of-the-art methods in weather simulation and removal, providing high-quality, physically plausible, and scene-identity-preserving results over various real-world videos.",
      "authors": [
        "Chih-Hao Lin",
        "Zian Wang",
        "Ruofan Liang",
        "Yuxuan Zhang",
        "Sanja Fidler",
        "Shenlong Wang",
        "Zan Gojcic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2505.00704v1",
          "size": "40717kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T19:07:12+00:00",
          "link": "https://arxiv.org/abs/2505.00704v2",
          "size": "43879kb",
          "version": "v2"
        }
      ],
      "title": "Controllable Weather Synthesis and Removal with Video Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00704",
        "HTML": "https://arxiv.org/html/2505.00704",
        "PDF": "https://arxiv.org/pdf/2505.00704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses techniques for generating synthetic data (weather effects in videos), it primarily targets video processing and diffusion models rather than LLM training data processing or dataset creation for language models."
      },
      "tasks": [
        "Video Editing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11347",
      "abstract": "Deep neural networks often learn and rely on spurious correlations, i.e., superficial associations between non-causal features and the targets. For instance, an image classifier may identify camels based on the desert backgrounds. While it can yield high overall accuracy during training, it degrades generalization on more diverse scenarios where such correlations do not hold. This problem poses significant challenges for out-of-distribution robustness and trustworthiness. Existing methods typically mitigate this issue by using external group annotations or auxiliary deterministic models to learn unbiased representations. However, such information is costly to obtain, and deterministic models may fail to capture the full spectrum of biases learned by the models. To address these limitations, we propose Evidential Alignment, a novel framework that leverages uncertainty quantification to understand the behavior of the biased models without requiring group annotations. By quantifying the evidence of model prediction with second-order risk minimization and calibrating the biased models with the proposed evidential calibration technique, Evidential Alignment identifies and suppresses spurious correlations while preserving core features. We theoretically justify the effectiveness of our method as capable of learning the patterns of biased models and debiasing the model without requiring any spurious correlation annotations. Empirical results demonstrate that our method significantly improves group robustness across diverse architectures and data modalities, providing a scalable and principled solution to spurious correlations.",
      "authors": [
        "Wenqian Ye",
        "Guangtao Zheng",
        "Aidong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T22:47:21+00:00",
          "link": "https://arxiv.org/abs/2506.11347v1",
          "size": "4289kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T16:55:20+00:00",
          "link": "https://arxiv.org/abs/2506.11347v2",
          "size": "4289kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T00:54:08+00:00",
          "link": "https://arxiv.org/abs/2506.11347v3",
          "size": "3426kb",
          "version": "v3"
        }
      ],
      "title": "Improving Group Robustness on Spurious Correlation via Evidential Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11347",
        "HTML": "https://arxiv.org/html/2506.11347",
        "PDF": "https://arxiv.org/pdf/2506.11347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method called Evidential Alignment to improve group robustness against spurious correlations in neural networks. It does not pertain to LLM training data processing or data-related operations."
      },
      "tasks": [
        "Uncertainty Quantification"
      ],
      "repo_urls": [
        "https://github.com/wenqian-ye/evidential_alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14925",
      "abstract": "In multi-behavior recommendation scenarios, analyzing users' diverse behaviors, such as click, purchase, and rating, enables a more comprehensive understanding of their interests, facilitating personalized and accurate recommendations. A fundamental assumption of multi-behavior recommendation methods is the existence of shared user preferences across behaviors, representing users' intrinsic interests. Based on this assumption, existing approaches aim to integrate information from various behaviors to enrich user representations. However, they often overlook the presence of both commonalities and individualities in users' multi-behavior preferences. These individualities reflect distinct aspects of preferences captured by different behaviors, where certain auxiliary behaviors may introduce noise, hindering the prediction of the target behavior. To address this issue, we propose a user invariant preference learning for multi-behavior recommendation (UIPL for short), aiming to capture users' intrinsic interests (referred to as invariant preferences) from multi-behavior interactions to mitigate the introduction of noise. Specifically, UIPL leverages the paradigm of invariant risk minimization to learn invariant preferences. To implement this, we employ a variational autoencoder (VAE) to extract users' invariant preferences, replacing the standard reconstruction loss with an invariant risk minimization constraint. Additionally, we construct distinct environments by combining multi-behavior data to enhance robustness in learning these preferences. Finally, the learned invariant preferences are used to provide recommendations for the target behavior. Extensive experiments on four real-world datasets demonstrate that UIPL significantly outperforms current state-of-the-art methods.",
      "authors": [
        "Mingshi Yan",
        "Zhiyong Cheng",
        "Fan Liu",
        "Yingda Lyu",
        "Yahong Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:47:36+00:00",
          "link": "https://arxiv.org/abs/2507.14925v1",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "title": "User Invariant Preference Learning for Multi-Behavior Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14925",
        "HTML": "https://arxiv.org/html/2507.14925",
        "PDF": "https://arxiv.org/pdf/2507.14925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves preference learning for multi-behavior recommendation systems, which is unrelated to LLM training data processing, focusing instead on user preference modeling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15150",
      "abstract": "Event-based sensors offer high temporal resolution and low latency by generating sparse, asynchronous data. However, converting this irregular data into dense tensors for use in standard neural networks diminishes these inherent advantages, motivating research into graph representations. While such methods preserve sparsity and support asynchronous inference, their performance on downstream tasks remains limited due to suboptimal modeling of spatiotemporal dynamics. In this work, we propose a novel spatiotemporal multigraph representation to better capture spatial structure and temporal changes. Our approach constructs two decoupled graphs: a spatial graph leveraging B-spline basis functions to model global structure, and a temporal graph utilizing motion vector-based attention for local dynamic changes. This design enables the use of efficient 2D kernels in place of computationally expensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM datasets for event-based object detection, achieving over a 6% improvement in detection accuracy compared to previous graph-based works, with a 5x speedup, reduced parameter count, and no increase in computational cost. These results highlight the effectiveness of structured graph modeling for asynchronous vision. Project page: eventbasedvision.github.io/eGSMV.",
      "authors": [
        "Aayush Atul Verma",
        "Arpitsinh Vaghela",
        "Bharatesh Chakravarthi",
        "Kaustav Chanda",
        "Yezhou Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T23:02:23+00:00",
          "link": "https://arxiv.org/abs/2507.15150v1",
          "size": "1151kb",
          "version": "v1"
        }
      ],
      "title": "Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15150",
        "HTML": "https://arxiv.org/html/2507.15150",
        "PDF": "https://arxiv.org/pdf/2507.15150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on event-based graph representation for object detection using asynchronous data. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15557",
      "abstract": "Despite recent progress in large language models (LLMs), evaluation of text generation tasks such as text style transfer (TST) remains a significant challenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025) revealed a substantial gap between automatic metrics and human judgments. Moreover, most prior work focuses exclusively on English, leaving multilingual TST evaluation largely unexplored. In this paper, we perform the first comprehensive multilingual study on evaluation of text detoxification system across nine languages: English, Spanish, German, Chinese, Arabic, Hindi, Ukrainian, Russian, Amharic. Drawing inspiration from the machine translation, we assess the effectiveness of modern neural-based evaluation models alongside prompting-based LLM-as-a-judge approaches. Our findings provide a practical recipe for designing more reliable multilingual TST evaluation pipeline in the text detoxification case.",
      "authors": [
        "Vitaly Protasov",
        "Nikolay Babakov",
        "Daryna Dementieva",
        "Alexander Panchenko"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:38:07+00:00",
          "link": "https://arxiv.org/abs/2507.15557v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15557",
        "PDF": "https://arxiv.org/pdf/2507.15557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with multilingual evaluation of text style transfer systems, focusing on evaluation metrics rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15595",
      "abstract": "Medical image segmentation is crucial for many healthcare tasks, including disease diagnosis and treatment planning. One key area is the segmentation of skin lesions, which is vital for diagnosing skin cancer and monitoring patients. In this context, this paper introduces SegDT, a new segmentation model based on diffusion transformer (DiT). SegDT is designed to work on low-cost hardware and incorporates Rectified Flow, which improves the generation quality at reduced inference steps and maintains the flexibility of standard diffusion models. Our method is evaluated on three benchmarking datasets and compared against several existing works, achieving state-of-the-art results while maintaining fast inference speeds. This makes the proposed model appealing for real-world medical applications. This work advances the performance and capabilities of deep learning models in medical image analysis, enabling faster, more accurate diagnostic tools for healthcare professionals. The code is made publicly available at \\href{https://github.com/Bekhouche/SegDT}{GitHub}.",
      "authors": [
        "Salah Eddine Bekhouche",
        "Gaby Maroun",
        "Fadi Dornaika",
        "Abdenour Hadid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.15595v1",
          "size": "393kb",
          "version": "v1"
        }
      ],
      "title": "SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15595",
        "HTML": "https://arxiv.org/html/2507.15595",
        "PDF": "https://arxiv.org/pdf/2507.15595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new segmentation model for medical imaging and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.13697",
      "abstract": "Ordinal Classification (OC) addresses those classification tasks where the labels exhibit a natural order. Unlike nominal classification, which treats all classes as mutually exclusive and unordered, OC takes the ordinal relationship into account, producing more accurate and relevant results. This is particularly critical in applications where the magnitude of classification errors has significant consequences. Despite this, OC problems are often tackled using nominal methods, leading to suboptimal solutions. Although decision trees are among the most popular classification approaches, ordinal tree-based approaches have received less attention when compared to other classifiers. This work provides a comprehensive survey of ordinal splitting criteria, standardising the notations used in the literature to enhance clarity and consistency. Three ordinal splitting criteria, Ordinal Gini (OGini), Weighted Information Gain (WIG), and Ranking Impurity (RI), are compared to the nominal counterparts of the first two (Gini and information gain), by incorporating them into a decision tree classifier. An extensive repository considering $45$ publicly available OC datasets is presented, supporting the first experimental comparison of ordinal and nominal splitting criteria using well-known OC evaluation metrics. The results have been statistically analysed, highlighting that OGini stands out as the best ordinal splitting criterion to date, reducing the mean absolute error achieved by Gini by more than 3.02%. To promote reproducibility, all source code developed, a detailed guide for reproducing the results, the 45 OC datasets, and the individual results for all the evaluated methodologies are provided.",
      "authors": [
        "Rafael Ayll\\'on-Gavil\\'an",
        "Francisco Jos\\'e Mart\\'inez-Estudillo",
        "David Guijo-Rubio",
        "C\\'esar Herv\\'as-Mart\\'inez",
        "Pedro Antonio Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T10:41:44+00:00",
          "link": "https://arxiv.org/abs/2412.13697v1",
          "size": "2570kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T18:53:15+00:00",
          "link": "https://arxiv.org/abs/2412.13697v2",
          "size": "375kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T17:19:05+00:00",
          "link": "https://arxiv.org/abs/2412.13697v3",
          "size": "203kb",
          "version": "v3"
        }
      ],
      "title": "Splitting criteria for ordinal decision trees: an experimental study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13697",
        "HTML": "https://arxiv.org/html/2412.13697",
        "PDF": "https://arxiv.org/pdf/2412.13697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about decision tree splitting criteria for ordinal classifications, and while it involves data classification, it does not relate to LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Ordinal Classification"
      ],
      "repo_urls": [
        "https://github.com/ayrna/decision-trees-from-scratch"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02184",
      "abstract": "Many autonomous robots aimed at source-seeking are studied, and their controls designed, using unicycle modeling and formulation. This is true not only for model-based controllers, but also for model-free, real-time control methods such as extremum seeking control (ESC). In this paper, we propose a unicycle-based ESC design applicable to differential wheeled robots that: (1) is very simple design, based on one simple control-affine law, and without state integrators; (2) attenuates oscillations known to persist in ESC designs (i.e., fully stop at the source); and (3) operates in a model-free, real-time setting, tolerating environmental/sensor noise. We provide simulation and real-world robotic experimental results for fixed and moving light source seeking by a differential wheeled robot using our proposed design. Results indicate clear advantages of our proposed design when compared to the literature, including attenuation of undesired oscillations, improved convergence speed, and better handling of noise.",
      "authors": [
        "Ahmed A. Elgohary",
        "Sameh A. Eisa",
        "and Shivam Bajpai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-04T04:35:05+00:00",
          "link": "https://arxiv.org/abs/2501.02184v1",
          "size": "2433kb",
          "version": "v1"
        },
        {
          "date": "2025-01-11T12:35:16+00:00",
          "link": "https://arxiv.org/abs/2501.02184v2",
          "size": "2434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T15:58:40+00:00",
          "link": "https://arxiv.org/abs/2501.02184v3",
          "size": "1178kb",
          "version": "v3"
        }
      ],
      "title": "Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02184",
        "PDF": "https://arxiv.org/pdf/2501.02184"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses control design for differential wheeled robots and does not relate to LLM training data processing or contribute to high-quality data construction for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15393",
      "abstract": "Phishing emails are a critical component of the cybercrime kill chain due to their wide reach and low cost. Their ever-evolving nature renders traditional rule-based and feature-engineered detectors ineffective in the ongoing arms race between attackers and defenders. The rise of large language models (LLMs) further exacerbates the threat, enabling attackers to craft highly convincing phishing emails at minimal cost.\n  This work demonstrates that LLMs can generate psychologically persuasive phishing emails tailored to victim profiles, successfully bypassing nearly all commercial and academic detectors. To defend against such threats, we propose PiMRef, the first reference-based phishing email detector that leverages knowledge-based invariants. Our core insight is that persuasive phishing emails often contain disprovable identity claims, which contradict real-world facts. PiMRef reframes phishing detection as an identity fact-checking task. Given an email, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the legitimacy of the sender's domain against a predefined knowledge base, and (iii) detects call-to-action prompts that push user engagement. Contradictory claims are flagged as phishing indicators and serve as human-understandable explanations.\n  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector, PiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks like Nazario and PhishPot. In a real-world evaluation of 10,183 emails across five university accounts over three years, PiMRef achieved 92.1% precision, 87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art in both effectiveness and efficiency.",
      "authors": [
        "Ruofan Liu",
        "Yun Lin",
        "Silas Yeo Shuen Yu",
        "Xiwen Teoh",
        "Zhenkai Liang",
        "Jin Song Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:53:41+00:00",
          "link": "https://arxiv.org/abs/2507.15393v1",
          "size": "4254kb",
          "version": "v1"
        }
      ],
      "title": "PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15393",
        "HTML": "https://arxiv.org/html/2507.15393",
        "PDF": "https://arxiv.org/pdf/2507.15393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses detecting phishing emails and does not involve LLM training data processing techniques or principles."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08136",
      "abstract": "3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing scenes from unposed images. However, optimization-based 3DGS methods struggle with sparse views due to limited prior knowledge. Meanwhile, feed-forward Gaussian approaches are constrained by input formats, making it challenging to incorporate more input views. To address these challenges, we propose RegGS, a 3D Gaussian registration-based framework for reconstructing unposed sparse views. RegGS aligns local 3D Gaussians generated by a feed-forward network into a globally consistent 3D Gaussian representation. Technically, we implement an entropy-regularized Sinkhorn algorithm to efficiently solve the optimal transport Mixture 2-Wasserstein $(\\text{MW}_2)$ distance, which serves as an alignment metric for Gaussian mixture models (GMMs) in $\\mathrm{Sim}(3)$ space. Furthermore, we design a joint 3DGS registration module that integrates the $\\text{MW}_2$ distance, photometric consistency, and depth geometry. This enables a coarse-to-fine registration process while accurately estimating camera poses and aligning the scene. Experiments on the RE10K and ACID datasets demonstrate that RegGS effectively registers local Gaussians with high fidelity, achieving precise pose estimation and high-quality novel-view synthesis. Project page: https://3dagentworld.github.io/reggs/.",
      "authors": [
        "Chong Cheng",
        "Yu Hu",
        "Sicheng Yu",
        "Beizhen Zhao",
        "Zijian Wang",
        "Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T19:56:08+00:00",
          "link": "https://arxiv.org/abs/2507.08136v1",
          "size": "4562kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T19:26:14+00:00",
          "link": "https://arxiv.org/abs/2507.08136v2",
          "size": "4562kb",
          "version": "v2"
        }
      ],
      "title": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08136",
        "HTML": "https://arxiv.org/html/2507.08136",
        "PDF": "https://arxiv.org/pdf/2507.08136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses 3D scene reconstruction from unposed images using Gaussian Splatting and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14355",
      "abstract": "Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a promising approach for scalable personality assessment from open-ended language. However, inferring personality traits remains challenging, and earlier work often relied on synthetic data or social media text lacking psychometric validity. We introduce a real-world benchmark of 555 semi-structured interviews with BFI-10 self-report scores for evaluating LLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini, Meta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item prediction and both zero-shot and chain-of-thought prompting for Big Five trait inference. All models showed high test-retest reliability, but construct validity was limited: correlations with ground-truth scores were weak (max Pearson's $r = 0.27$), interrater agreement was low (Cohen's $\\kappa < 0.10$), and predictions were biased toward moderate or high trait levels. Chain-of-thought prompting and longer input context modestly improved distributional alignment, but not trait-level accuracy. These results underscore limitations in current LLM-based personality inference and highlight the need for evidence-based development for psychological applications.",
      "authors": [
        "Jianfeng Zhu",
        "Ruoming Jin",
        "and Karin G. Coifman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T20:22:47+00:00",
          "link": "https://arxiv.org/abs/2507.14355v1",
          "size": "1431kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Infer Personality from Real World Conversations?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14355",
        "PDF": "https://arxiv.org/pdf/2507.14355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores LLMs' ability to infer personality traits using real-world data, touching slightly on data for specific testing purposes, but it is more focused on application and evaluation rather than on LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14454",
      "abstract": "3D Gaussian splatting video (3DGS) streaming has recently emerged as a research hotspot in both academia and industry, owing to its impressive ability to deliver immersive 3D video experiences. However, research in this area is still in its early stages, and several fundamental challenges, such as tiling, quality assessment, and bitrate adaptation, require further investigation. In this paper, we tackle these challenges by proposing a comprehensive set of solutions. Specifically, we propose an adaptive 3DGS tiling technique guided by saliency analysis, which integrates both spatial and temporal features. Each tile is encoded into versions possessing dedicated deformation fields and multiple quality levels for adaptive selection. We also introduce a novel quality assessment framework for 3DGS video that jointly evaluates spatial-domain degradation in 3DGS representations during streaming and the quality of the resulting 2D rendered images. Additionally, we develop a meta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS video streaming, achieving optimal performance across varying network conditions. Extensive experiments demonstrate that our proposed approaches significantly outperform state-of-the-art methods.",
      "authors": [
        "Han Gong",
        "Qiyue Li",
        "Jie Li",
        "Zhi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:00:36+00:00",
          "link": "https://arxiv.org/abs/2507.14454v1",
          "size": "18097kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14454",
        "HTML": "https://arxiv.org/html/2507.14454",
        "PDF": "https://arxiv.org/pdf/2507.14454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with 3D video streaming techniques, including tiling and bitrate adaptation, and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14669",
      "abstract": "Two graphs $G_1,G_2$ are distinguished by the Weisfeiler--Leman isomorphism test if and only if there is a tree $T$ that has a different number of homomorphisms to $G_1$ and to $G_2$. There are two known proofs of this fact -- a logical proof by Dvorak and a linear-algebraic proof by Dell, Grohe, and Rattan. We give another simple proof, based on ordering WL-labels and asymptotic arguments.",
      "authors": [
        "Alexander Kozachinskiy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:40:28+00:00",
          "link": "https://arxiv.org/abs/2507.14669v1",
          "size": "4kb",
          "version": "v1"
        }
      ],
      "title": "Dvorak-Dell-Grohe-Rattan theorem via an asymptotic argument",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14669",
        "HTML": "https://arxiv.org/html/2507.14669",
        "PDF": "https://arxiv.org/pdf/2507.14669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a proof related to the Weisfeiler--Leman isomorphism test, which is purely theoretical and has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06273",
      "abstract": "We explore a novel zero-shot Audio-Visual Speech Recognition (AVSR) framework, dubbed Zero-AVSR, which enables speech recognition in target languages without requiring any audio-visual speech data in those languages. Specifically, we introduce the Audio-Visual Speech Romanizer (AV-Romanizer), which learns language-agnostic speech representations by predicting Roman text. Then, by leveraging the strong multilingual modeling capabilities of Large Language Models (LLMs), we propose converting the predicted Roman text into language-specific graphemes, forming the proposed Cascaded Zero-AVSR. Taking it a step further, we explore a unified Zero-AVSR approach by directly integrating the audio-visual speech representations encoded by the AV-Romanizer into the LLM. This is achieved through finetuning the adapter and the LLM using our proposed multi-task learning scheme. To capture the wide spectrum of phonetic and linguistic diversity, we also introduce a Multilingual Audio-Visual Romanized Corpus (MARC) consisting of 2,916 hours of audio-visual speech data across 82 languages, along with transcriptions in both language-specific graphemes and Roman text. Extensive analysis and experiments confirm that the proposed Zero-AVSR framework has the potential to expand language support beyond the languages seen during the training of the AV-Romanizer.",
      "authors": [
        "Jeong Hun Yeo",
        "Minsu Kim",
        "Chae Won Kim",
        "Stavros Petridis",
        "Yong Man Ro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T16:40:13+00:00",
          "link": "https://arxiv.org/abs/2503.06273v1",
          "size": "539kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T06:53:55+00:00",
          "link": "https://arxiv.org/abs/2503.06273v2",
          "size": "751kb",
          "version": "v2"
        }
      ],
      "title": "Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LLMs by Learning Language-Agnostic Speech Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06273",
        "HTML": "https://arxiv.org/html/2503.06273",
        "PDF": "https://arxiv.org/pdf/2503.06273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework for zero-shot audio-visual speech recognition and introduces a multilingual corpus used for training. Although it involves creating a dataset, the main focus is on AVSR system development, not directly on LLM training data processing."
      },
      "tasks": [
        "Audio-Visual Speech Recognition",
        "Multi-Task Learning",
        "speech-recognition",
        "Speech Recognition",
        "Visual Speech Recognition"
      ],
      "repo_urls": [
        "https://github.com/JeongHun0716/zero-avsr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14494",
      "abstract": "We contribute an in-depth analysis of the workflows and tensions arising from generative AI (genAI) use in biomedical visualization (BioMedVis). Although genAI affords facile production of aesthetic visuals for biological and medical content, the architecture of these tools fundamentally limits the accuracy and trustworthiness of the depicted information, from imaginary (or fanciful) molecules to alien anatomy. Through 17 interviews with a diverse group of practitioners and researchers, we qualitatively analyze the concerns and values driving genAI (dis)use for the visual representation of spatially-oriented biomedical data. We find that BioMedVis experts, both in roles as developers and designers, use genAI tools at different stages of their daily workflows and hold attitudes ranging from enthusiastic adopters to skeptical avoiders of genAI. In contrasting the current use and perspectives on genAI observed in our study with predictions towards genAI in the visualization pipeline from prior work, our refocus the discussion of genAI's effects on projects in visualization in the here and now with its respective opportunities and pitfalls for future visualization research. At a time when public trust in science is in jeopardy, we are reminded to first do no harm, not just in biomedical visualization but in science communication more broadly. Our observations reaffirm the necessity of human intervention for empathetic design and assessment of accurate scientific visuals.",
      "authors": [
        "Roxanne Ziman",
        "Shehryar Saharan",
        "Ga\\\"el McGill",
        "Laura Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:42:23+00:00",
          "link": "https://arxiv.org/abs/2507.14494v1",
          "size": "3293kb",
          "version": "v1"
        }
      ],
      "title": "\"It looks sexy but it's wrong.\" Tensions in creativity and accuracy using genAI for biomedical visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14494",
        "HTML": "https://arxiv.org/html/2507.14494",
        "PDF": "https://arxiv.org/pdf/2507.14494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an analysis of generative AI in biomedical visualization, emphasizing the trade-off between creativity and accuracy. It does not address LLM training data processing or relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14736",
      "abstract": "Trainable activation functions, whose parameters are optimized alongside network weights, offer increased expressivity compared to fixed activation functions. Specifically, trainable activation functions defined as ratios of polynomials (rational functions) have been proposed to enhance plasticity in reinforcement learning. However, their impact on training stability remains unclear. In this work, we study trainable rational activations in both reinforcement and continual learning settings. We find that while their flexibility enhances adaptability, it can also introduce instability, leading to overestimation in RL and feature collapse in longer continual learning scenarios. Our main result is demonstrating a trade-off between expressivity and plasticity in rational activations. To address this, we propose a constrained variant that structurally limits excessive output scaling while preserving adaptability. Experiments across MetaWorld and DeepMind Control Suite (DMC) environments show that our approach improves training stability and performance. In continual learning benchmarks, including MNIST with reshuffled labels and Split CIFAR-100, we reveal how different constraints affect the balance between expressivity and long-term retention. While preliminary experiments in discrete action domains (e.g., Atari) did not show similar instability, this suggests that the trade-off is particularly relevant for continuous control. Together, our findings provide actionable design principles for robust and adaptable trainable activations in dynamic, non-stationary environments. Code available at: https://github.com/special114/rl_rational_plasticity.",
      "authors": [
        "Rafa{\\l} Surdej",
        "Micha{\\l} Bortkiewicz",
        "Alex Lewandowski",
        "Mateusz Ostaszewski",
        "Clare Lyle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:53:08+00:00",
          "link": "https://arxiv.org/abs/2507.14736v1",
          "size": "10520kb",
          "version": "v1"
        }
      ],
      "title": "Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14736",
        "HTML": "https://arxiv.org/html/2507.14736",
        "PDF": "https://arxiv.org/pdf/2507.14736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on trainable activation functions in reinforcement learning and their stability. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14823",
      "abstract": "Large vision-language models (LVLMs) have made significant progress in chart understanding. However, financial charts, characterized by complex temporal structures and domain-specific terminology, remain notably underexplored. We introduce FinChart-Bench, the first benchmark specifically focused on real-world financial charts. FinChart-Bench comprises 1,200 financial chart images collected from 2015 to 2024, each annotated with True/False (TF), Multiple Choice (MC), and Question Answering (QA) questions, totaling 7,016 questions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs on FinChart-Bench. Our evaluation reveals critical insights: (1) the performance gap between open-source and closed-source models is narrowing, (2) performance degradation occurs in upgraded models within families, (3) many models struggle with instruction following, (4) both advanced models show significant limitations in spatial reasoning abilities, and (5) current LVLMs are not reliable enough to serve as automated evaluators. These findings highlight important limitations in current LVLM capabilities for financial chart understanding. The FinChart-Bench dataset is available at https://huggingface.co/datasets/Tizzzzy/FinChart-Bench.",
      "authors": [
        "Dong Shu",
        "Haoyang Yuan",
        "Yuchen Wang",
        "Yanguang Liu",
        "Huopu Zhang",
        "Haiyan Zhao",
        "Mengnan Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T05:00:42+00:00",
          "link": "https://arxiv.org/abs/2507.14823v1",
          "size": "6975kb",
          "version": "v1"
        }
      ],
      "title": "FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14823",
        "HTML": "https://arxiv.org/html/2507.14823",
        "PDF": "https://arxiv.org/pdf/2507.14823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating vision-language models for financial chart comprehension and introduces the FinChart-Bench dataset specifically for this purpose. It does not address LLM training data processing or data preparation for text pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15401",
      "abstract": "Facial expression recognition (FER) is a challenging task due to pervasive occlusion and dataset biases. Especially when facial information is partially occluded, existing FER models struggle to extract effective facial features, leading to inaccurate classifications. In response, we present ORSANet, which introduces the following three key contributions: First, we introduce auxiliary multi-modal semantic guidance to disambiguate facial occlusion and learn high-level semantic knowledge, which is two-fold: 1) we introduce semantic segmentation maps as dense semantics prior to generate semantics-enhanced facial representations; 2) we introduce facial landmarks as sparse geometric prior to mitigate intrinsic noises in FER, such as identity and gender biases. Second, to facilitate the effective incorporation of these two multi-modal priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively fuse the landmark feature and semantics-enhanced representations within different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes, further enhancing the model's ability to distinguish similar expressions. We further construct the first occlusion-oriented FER dataset to facilitate specialized robustness analysis on various real-world occlusion conditions, dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER demonstrate that our proposed ORSANet achieves SOTA recognition performance. Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.",
      "authors": [
        "Huiyu Zhai",
        "Xingxing Yang",
        "Yalan Ye",
        "Chenyang Li",
        "Bin Fan",
        "Changze Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T09:04:29+00:00",
          "link": "https://arxiv.org/abs/2507.15401v1",
          "size": "1925kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15401",
        "HTML": "https://arxiv.org/html/2507.15401",
        "PDF": "https://arxiv.org/pdf/2507.15401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses facial expression recognition with techniques to handle occlusion, focusing on multi-modal guidance and adversarial loss. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15526",
      "abstract": "Mixed Reality (MR) head mounted displays (HMDs) offer a promising alternative to traditional Flight Simulator Training Device (FSTD) displays, providing immersion, realism and cost efficiency. However, these technologies require management of human factors; cybersickness, visual fatigue and ergonomic strain. If left unmitigated, these effects can hinder pilot performance and training outcomes. For safety critical fields like aviation, addressing human factors challenges is crucial for MR's training potential. This survey systematically reviews the current literature identifying key human factors challenges in MR HMD use in pilot training and examines strategies to mitigate these barriers. Drawing on existing industry standards set by a leading aviation authority, the review adopts a regulatory perspective to explore hardware, software, ergonomic, physiological and psychological interventions improving pilot comfort, safety and training effectiveness in an MR FSTD. Additionally, it evaluates which of these interventions are most appropriate and viable for MR pilot training under existing aviation training regulations, ensuring that technical requirements and pilot wellbeing remain balanced. The findings yield significant insights for the human dimensions of aviation simulation training, highlighting how regulatory considerations shape the practicality of mitigation measures. These insights inform emerging MR aviation training guidelines and best practices, supporting MR's readiness to enhance aviation training.",
      "authors": [
        "Antonio Perez",
        "Avinash Singh",
        "Jonathan Mitchell",
        "Philip Swadling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:51:30+00:00",
          "link": "https://arxiv.org/abs/2507.15526v1",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "title": "Strategies to Manage Human Factors in Mixed Reality Pilot Training: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15526",
        "HTML": "https://arxiv.org/html/2507.15526",
        "PDF": "https://arxiv.org/pdf/2507.15526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys human factors in mixed reality pilot training, a topic unrelated to LLM training data processing or any form of data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15590",
      "abstract": "Since the 60s, musicology has been increasingly impacted by computational tools in various ways, from systematic analysis approaches to modeling of creativity. This article presents a comprehensive assessment of the current state of Computational Musicology tools based on survey data collected from practitioners in the field. We gathered information on tool usage patterns, common analytical tasks, user satisfaction levels, data characteristics, and prioritized features across four distinct domains: symbolic music, music-related imagery, audio, and text. Our findings reveal significant gaps between current tooling capabilities and user needs, highlighting some limitations of these tools across all domains. This assessment contributes to the ongoing dialogue between tool developers and music scholars, aiming to enhance the effectiveness and accessibility of computational methods in musicological research.",
      "authors": [
        "Jorge Junior Morgado Vega",
        "Sachin Sharma and Federico Simonetta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T13:13:31+00:00",
          "link": "https://arxiv.org/abs/2507.15590v1",
          "size": "3008kb",
          "version": "v1"
        }
      ],
      "title": "Drafting the Landscape of Computational Musicology Tools: a Survey-Based Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15590",
        "HTML": "https://arxiv.org/html/2507.15590",
        "PDF": "https://arxiv.org/pdf/2507.15590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses computational tools in musicology, focusing on their effectiveness and user needs. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06838",
      "abstract": "Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. While existing research has proposed multiple detection tools, the automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of AC lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence.\n  Leveraging recent advancements in large language models (LLMs), we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX. The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality. To this end, ACFIX involves both offline and online phases. First, during the offline phase, ACFIX mines a taxonomy of common Role-based Access Control (RBAC) practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 pairs mined. Second, during the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch. This patch will then undergo a validity and effectiveness check. To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them. This represents a significant improvement compared to the baseline GPT-4, which achieved only 52.54%.",
      "authors": [
        "Lyuye Zhang and Kaixuan Li and Kairan Sun and Daoyuan Wu and Ye Liu and Haoye Tian and Yang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T15:59:59+00:00",
          "link": "https://arxiv.org/abs/2403.06838v1",
          "size": "5331kb",
          "version": "v1"
        },
        {
          "date": "2024-03-18T13:37:56+00:00",
          "link": "https://arxiv.org/abs/2403.06838v2",
          "size": "5336kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T05:24:59+00:00",
          "link": "https://arxiv.org/abs/2403.06838v3",
          "size": "3320kb",
          "version": "v3"
        }
      ],
      "title": "ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06838",
        "PDF": "https://arxiv.org/pdf/2403.06838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on using LLMs to repair access control vulnerabilities in smart contracts, primarily focusing on security and repair mechanisms rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.00460",
      "abstract": "Current data-driven approaches for X-ray prohibited items detection remain under-explored, particularly in the design of effective data augmentations. Existing natural image augmentations for reflected light imaging neglect the data characteristics of X-ray security images. Moreover, prior X-ray augmentation methods have predominantly focused on foreground prohibited items, overlooking informative background cues. In this paper, we propose Background Mixup (BGM), a background-based augmentation technique tailored for X-ray security imaging domain. Unlike conventional methods, BGM is founded on an in-depth analysis of physical properties including: 1) X-ray Transmission Imagery: Transmitted X-ray pixels represent composite information from multiple materials along the imaging path. 2) Material-based Pseudo-coloring: Pseudo-coloring in X-ray images correlates directly with material properties, aiding in material distinction. Building upon the above insights, BGM mixes background patches across regions on both 1) texture structure and 2) material variation, to benefit models from complicated background cues. This enhances the model's capability to handle domain-specific challenges such as occlusion-induced discriminative imbalance. Importantly, BGM is orthogonal and fully compatible with existing foreground-focused augmentation techniques, enabling joint use to further enhance detection performance. Extensive experiments on multiple X-ray security benchmarks show that BGM consistently surpasses strong baselines, without additional annotations or significant training overhead. This work pioneers the exploration of background-aware augmentation in X-ray prohibited items detection and provides a lightweight, plug-and-play solution with broad applicability.",
      "authors": [
        "Weizhe Liu",
        "Renshuai Tao",
        "Hongguang Zhu",
        "Yunda Sun",
        "Yao Zhao",
        "Yunchao Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-30T12:26:55+00:00",
          "link": "https://arxiv.org/abs/2412.00460v1",
          "size": "1015kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:44:06+00:00",
          "link": "https://arxiv.org/abs/2412.00460v2",
          "size": "1604kb",
          "version": "v2"
        }
      ],
      "title": "BGM: Background Mixup for X-ray Prohibited Items Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00460",
        "HTML": "https://arxiv.org/html/2412.00460",
        "PDF": "https://arxiv.org/pdf/2412.00460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on data augmentation techniques for X-ray prohibited items detection, specifically via a method called Background Mixup. It doesn't address LLM training data processing or any related data operations for language model pretraining or fine-tuning."
      },
      "tasks": [
        "Data Augmentation",
        "Image Augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.09442",
      "abstract": "Textual-based prompt learning methods primarily employ multiple learnable soft prompts and hard class tokens in a cascading manner as text inputs, aiming to align image and text (category) spaces for downstream tasks. However, current training is restricted to aligning images with predefined known categories and cannot be associated with unknown categories. In this work, we propose utilizing universal attributes as a bridge to enhance the alignment between images and unknown categories. Specifically, we introduce an Attribute-anchored Textual Prompt learning method for vision-language models, named ATPrompt. This approach expands the learning space of soft prompts from the original one-dimensional category level into the multi-dimensional attribute level by incorporating multiple attribute tokens into the learnable soft prompts. Through this modification, we transform the text prompt from a category-centric form to an attribute-category hybrid form. Additionally, we introduce a straightforward differentiable attribute search method to identify representative and suitable attributes for downstream tasks. As an easy-to-use plug-in technique, ATPrompt can seamlessly replace the existing basic prompt format in textual-based methods, providing general improvements at a negligible computational cost. Extensive experiments across 11 datasets validate the effectiveness of our method. Code is publicly available at https://github.com/zhengli97/ATPrompt.",
      "authors": [
        "Zheng Li",
        "Yibing Song",
        "Ming-Ming Cheng",
        "Xiang Li",
        "Jian Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T16:57:20+00:00",
          "link": "https://arxiv.org/abs/2412.09442v1",
          "size": "2168kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:54:19+00:00",
          "link": "https://arxiv.org/abs/2412.09442v2",
          "size": "2037kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T07:36:17+00:00",
          "link": "https://arxiv.org/abs/2412.09442v3",
          "size": "2037kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T16:14:11+00:00",
          "link": "https://arxiv.org/abs/2412.09442v4",
          "size": "2037kb",
          "version": "v4"
        }
      ],
      "title": "Advancing Textual Prompt Learning with Anchored Attributes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09442",
        "HTML": "https://arxiv.org/html/2412.09442",
        "PDF": "https://arxiv.org/pdf/2412.09442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing prompt learning for vision-language models by introducing attribute-anchored textual prompts. It does not involve any data collection, processing, or manipulation for LLMs, which is required for an LLM training data processing contribution."
      },
      "tasks": [
        "Attribute",
        "Large Language Model",
        "Prompt Learning"
      ],
      "repo_urls": [
        "https://github.com/zhengli97/promptkd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04950",
      "abstract": "Deep neural network (DNN) based perception models are indispensable in the development of autonomous vehicles (AVs). However, their reliance on large-scale, high-quality data is broadly recognized as a burdensome necessity due to the substantial cost of data acquisition and labeling. Further, the issue is not a one-time concern, as AVs might need a new dataset if they are to be deployed to another region (real-target domain) that the in-hand dataset within the real-source domain cannot incorporate. To mitigate this burden, we propose leveraging synthetic environments as an auxiliary domain where the characteristics of real domains are reproduced. This approach could enable indirect experience about the real-target domain in a time- and cost-effective manner. As a practical demonstration of our methodology, nuScenes and South Korea are employed to represent real-source and real-target domains, respectively. That means we construct digital twins for several regions of South Korea, and the data-acquisition framework of nuScenes is reproduced. Blending the aforementioned components within a simulator allows us to obtain a synthetic-fusion domain in which we forge our novel driving dataset, MORDA: Mixture Of Real-domain characteristics for synthetic-data-assisted Domain Adaptation. To verify the value of synthetic features that MORDA provides in learning about driving environments of South Korea, 2D/3D detectors are trained solely on a combination of nuScenes and MORDA. Afterward, their performance is evaluated on the unforeseen real-world dataset (AI-Hub) collected in South Korea. Our experiments present that MORDA can significantly improve mean Average Precision (mAP) on AI-Hub dataset while that on nuScenes is retained or slightly enhanced.",
      "authors": [
        "Hojun Lim",
        "Heecheol Yoo",
        "Jinwoo Lee",
        "Seungmin Jeon",
        "Hyeongseok Jeon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T03:58:02+00:00",
          "link": "https://arxiv.org/abs/2501.04950v1",
          "size": "4044kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T04:40:14+00:00",
          "link": "https://arxiv.org/abs/2501.04950v2",
          "size": "4030kb",
          "version": "v2"
        },
        {
          "date": "2025-07-21T07:29:18+00:00",
          "link": "https://arxiv.org/abs/2501.04950v3",
          "size": "4030kb",
          "version": "v3"
        }
      ],
      "title": "MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04950",
        "HTML": "https://arxiv.org/html/2501.04950",
        "PDF": "https://arxiv.org/pdf/2501.04950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces MORDA, a synthetic dataset for domain adaptation in autonomous vehicles, addressing synthetic dataset creation to improve data quality for machine learning, aligning it with LLM training data processing contributions."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02247",
      "abstract": "Object Goal Navigation-requiring an agent to locate a specific object in an unseen environment-remains a core challenge in embodied AI. Although recent progress in Vision-Language Model (VLM)-based agents has demonstrated promising perception and decision-making abilities through prompting, none has yet established a fully modular world model design that reduces risky and costly interactions with the environment by predicting the future state of the world. We introduce WMNav, a novel World Model-based Navigation framework powered by Vision-Language Models (VLMs). It predicts possible outcomes of decisions and builds memories to provide feedback to the policy module. To retain the predicted state of the environment, WMNav proposes the online maintained Curiosity Value Map as part of the world model memory to provide dynamic configuration for navigation policy. By decomposing according to a human-like thinking process, WMNav effectively alleviates the impact of model hallucination by making decisions based on the feedback difference between the world model plan and observation. To further boost efficiency, we implement a two-stage action proposer strategy: broad exploration followed by precise localization. Extensive evaluation on HM3D and MP3D validates WMNav surpasses existing zero-shot benchmarks in both success rate and exploration efficiency (absolute improvement: +3.2% SR and +3.2% SPL on HM3D, +13.5% SR and +1.1% SPL on MP3D). Project page: https://b0b8k1ng.github.io/WMNav/.",
      "authors": [
        "Dujun Nie",
        "Xianda Guo",
        "Yiqun Duan",
        "Ruijun Zhang",
        "Long Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T03:51:36+00:00",
          "link": "https://arxiv.org/abs/2503.02247v1",
          "size": "2427kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T13:23:05+00:00",
          "link": "https://arxiv.org/abs/2503.02247v2",
          "size": "2428kb",
          "version": "v2"
        },
        {
          "date": "2025-04-26T03:02:46+00:00",
          "link": "https://arxiv.org/abs/2503.02247v3",
          "size": "2428kb",
          "version": "v3"
        },
        {
          "date": "2025-04-26T03:10:06+00:00",
          "link": "https://arxiv.org/abs/2503.02247v4",
          "size": "2428kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T03:44:28+00:00",
          "link": "https://arxiv.org/abs/2503.02247v5",
          "size": "2431kb",
          "version": "v5"
        }
      ],
      "title": "WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02247",
        "HTML": "https://arxiv.org/html/2503.02247",
        "PDF": "https://arxiv.org/pdf/2503.02247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on navigation frameworks in embodied AI, integrating vision-language models into a world model for navigation but not on LLM training data processing."
      },
      "tasks": [
        "Hallucination"
      ],
      "repo_urls": [
        "https://github.com/B0B8K1ng/WMNavigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10217",
      "abstract": "Recent diffusion models achieve personalization by learning specific subjects, allowing learned attributes to be integrated into generated images. However, personalized human image generation remains challenging due to the need for precise and consistent attribute preservation (e.g., identity, clothing details). Existing subject-driven image generation methods often require either (1) inference-time fine-tuning with few images for each new subject or (2) large-scale dataset training for generalization. Both approaches are computationally expensive and impractical for real-time applications. To address these limitations, we present Wardrobe Polyptych LoRA, a novel part-level controllable model for personalized human image generation. By training only LoRA layers, our method removes the computational burden at inference while ensuring high-fidelity synthesis of unseen subjects. Our key idea is to condition the generation on the subject's wardrobe and leverage spatial references to reduce information loss, thereby improving fidelity and consistency. Additionally, we introduce a selective subject region loss, which encourages the model to disregard some of reference images during training. Our loss ensures that generated images better align with text prompts while maintaining subject integrity. Notably, our Wardrobe Polyptych LoRA requires no additional parameters at the inference stage and performs generation using a single model trained on a few training samples. We construct a new dataset and benchmark tailored for personalized human image generation. Extensive experiments show that our approach significantly outperforms existing techniques in fidelity and consistency, enabling realistic and identity-preserving full-body synthesis.",
      "authors": [
        "Jeongho Kim",
        "Sunghyun Park",
        "Hyoungwoo Park",
        "Sungrack Yun",
        "Jaegul Choo",
        "Seokeon Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:34:25+00:00",
          "link": "https://arxiv.org/abs/2507.10217v1",
          "size": "11658kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:49:59+00:00",
          "link": "https://arxiv.org/abs/2507.10217v2",
          "size": "11658kb",
          "version": "v2"
        }
      ],
      "title": "From Wardrobe to Canvas: Wardrobe Polyptych LoRA for Part-level Controllable Human Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10217",
        "HTML": "https://arxiv.org/html/2507.10217",
        "PDF": "https://arxiv.org/pdf/2507.10217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel model for personalized human image generation through Wardrobe Polyptych LoRA and the creation of a new dataset for this purpose. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14586",
      "abstract": "Large Language Models (LLMs) are increasingly applied in the fields of mechanical engineering and materials science. As models that establish connections through the interface of language, LLMs can be applied for step-wise reasoning through the Processing-Structure-Property-Performance chain of material science and engineering. Current LLMs are built for adequately representing a dataset, which is the most part of the accessible internet. However, the internet mostly contains non-scientific content. If LLMs should be applied for engineering purposes, it is valuable to investigate models for their intrinsic knowledge -- here: the capacity to generate correct information about materials. In the current work, for the example of the Periodic Table of Elements, we highlight the role of vocabulary and tokenization for the uniqueness of material fingerprints, and the LLMs' capabilities of generating factually correct output of different state-of-the-art open models. This leads to a material knowledge benchmark for an informed choice, for which steps in the PSPP chain LLMs are applicable, and where specialized models are required.",
      "authors": [
        "Adrian Ehrenhofer and Thomas Wallmersperger and Gianaurelio Cuniberti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:02:08+00:00",
          "link": "https://arxiv.org/abs/2507.14586v1",
          "size": "816kb",
          "version": "v1"
        }
      ],
      "title": "What do Large Language Models know about materials?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14586",
        "HTML": "https://arxiv.org/html/2507.14586",
        "PDF": "https://arxiv.org/pdf/2507.14586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies LLMs' knowledge about materials and their tokenization impact, without addressing any aspect of data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14766",
      "abstract": "In intensive care units (ICUs), patients with complex clinical conditions require vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a vital diagnostic tool, providing insights into clinical trajectories, but their irregular acquisition limits their utility. Existing tools for CXR interpretation are constrained by cross-sectional analysis, failing to capture temporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal framework that integrates temporally sparse CXR imaging and radiology reports with high-frequency clinical data, such as vital signs, laboratory values, and respiratory flow sheets, to predict the trajectory of CXR findings in critically ill patients. CXR-TFT leverages latent embeddings from a vision encoder that are temporally aligned with hourly clinical data through interpolation. A transformer model is then trained to predict CXR embeddings at each hour, conditioned on previous embeddings and clinical measurements. In a retrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy in forecasting abnormal CXR findings up to 12 hours before they became radiographically evident. This predictive capability in clinical data holds significant potential for enhancing the management of time-sensitive conditions like acute respiratory distress syndrome, where early intervention is crucial and diagnoses are often delayed. By providing distinctive temporal resolution in prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights that can directly improve clinical outcomes.",
      "authors": [
        "Mehak Arora",
        "Ayman Ali",
        "Kaiyuan Wu",
        "Carolyn Davis",
        "Takashi Shimazui",
        "Mahmoud Alwakeel",
        "Victor Moas",
        "Philip Yang",
        "Annette Esper",
        "Rishikesan Kamaleswaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T22:42:26+00:00",
          "link": "https://arxiv.org/abs/2507.14766v1",
          "size": "1958kb",
          "version": "v1"
        }
      ],
      "title": "CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14766",
        "HTML": "https://arxiv.org/html/2507.14766",
        "PDF": "https://arxiv.org/pdf/2507.14766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a multi-modal framework for predicting clinical trajectories using Chest X-rays and clinical data. It focuses on medical diagnostics and prediction rather than on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15072",
      "abstract": "Industrial warehouses are congested with moving forklifts, shelves and personnel, making robot teleoperation particularly risky and demanding for blind and low-vision (BLV) operators. Although accessible teleoperation plays a key role in inclusive workforce participation, systematic research on its use in industrial environments is limited, and few existing studies barely address multimodal guidance designed for BLV users. We present a novel multimodal guidance simulator that enables BLV users to control a mobile robot through a high-fidelity warehouse environment while simultaneously receiving synchronized visual, auditory, and haptic feedback. The system combines a navigation mesh with regular re-planning so routes remain accurate avoiding collisions as forklifts and human avatars move around the warehouse. Users with low vision are guided with a visible path line towards destination; navigational voice cues with clockwise directions announce upcoming turns, and finally proximity-based haptic feedback notifies the users of static and moving obstacles in the path. This real-time, closed-loop system offers a repeatable testbed and algorithmic reference for accessible teleoperation research. The simulator's design principles can be easily adapted to real robots due to the alignment of its navigation, speech, and haptic modules with commercial hardware, supporting rapid feasibility studies and deployment of inclusive telerobotic tools in actual warehouses.",
      "authors": [
        "Maisha Maimuna",
        "Minhaz Bin Farukee",
        "Sama Nikanfar",
        "Mahfuza Siddiqua",
        "Ayon Roy and Fillia Makedon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:14:55+00:00",
          "link": "https://arxiv.org/abs/2507.15072v1",
          "size": "12018kb",
          "version": "v1"
        }
      ],
      "title": "NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15072",
        "HTML": "https://arxiv.org/html/2507.15072",
        "PDF": "https://arxiv.org/pdf/2507.15072"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a telerobotic simulation system for navigation by visually impaired users, emphasizing multimodal feedback. It does not involve LLM training data processing, nor does it pertain to dataset creation or data operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15186",
      "abstract": "As modeling and visualization applications proliferate, there arises a need to simplify large polygonal models at interactive rates. Unfortunately existing polygon mesh simplification algorithms are not well suited for this task because they are either too slow (requiring the simplified model to be pre-computed) or produce models that are too poor in quality. These shortcomings become particularly acute when models are extremely large. We present an algorithm suitable for simplification of large models at interactive speeds. The algorithm is fast and can guarantee displayable results within a given time limit. Results also have good quality. Inspired by splitting algorithms from vector quantization literature, we simplify models in reverse, beginning with an extremely coarse approximation and refining it. Approximations of surface curvature guide the simplification process. Previously produced simplifications can be further refined by using them as input to the algorithm.",
      "authors": [
        "Dmitry Brodsky and Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T02:12:53+00:00",
          "link": "https://arxiv.org/abs/2507.15186v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "Model Simplification through refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15186",
        "PDF": "https://arxiv.org/pdf/2507.15186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an algorithm for simplifying large polygonal models at interactive speeds, which does not associate with any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15502",
      "abstract": "Postoperative follow-up plays a crucial role in monitoring recovery and identifying complications. However, traditional approaches, typically involving bedside interviews and manual documentation, are time-consuming and labor-intensive. Although existing digital solutions, such as web questionnaires and intelligent automated calls, can alleviate the workload of nurses to a certain extent, they either deliver an inflexible scripted interaction or face private information leakage issues. To address these limitations, this paper introduces FollowUpBot, an LLM-powered edge-deployed robot for postoperative care and monitoring. It allows dynamic planning of optimal routes and uses edge-deployed LLMs to conduct adaptive and face-to-face conversations with patients through multiple interaction modes, ensuring data privacy. Moreover, FollowUpBot is capable of automatically generating structured postoperative follow-up reports for healthcare institutions by analyzing patient interactions during follow-up. Experimental results demonstrate that our robot achieves high coverage and satisfaction in follow-up interactions, as well as high report generation accuracy across diverse field types. The demonstration video is available at https://www.youtube.com/watch?v=_uFgDO7NoK0.",
      "authors": [
        "Chen Chen",
        "Jianing Yin",
        "Jiannong Cao",
        "Zhiyuan Wen",
        "Mingjin Zhang",
        "Weixun Gao",
        "Xiang Wang",
        "Haihua Shu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:07:49+00:00",
          "link": "https://arxiv.org/abs/2507.15502v1",
          "size": "1222kb",
          "version": "v1"
        }
      ],
      "title": "FollowUpBot: An LLM-Based Conversational Robot for Automatic Postoperative Follow-up",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15502",
        "HTML": "https://arxiv.org/html/2507.15502",
        "PDF": "https://arxiv.org/pdf/2507.15502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses FollowUpBot, a conversational robot for postoperative follow-up, which focuses on patient care applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15518",
      "abstract": "Creating an immersive and interactive theatrical experience is a long-term goal in the field of interactive narrative. The emergence of large language model (LLM) is providing a new path to achieve this goal. However, existing LLM-based drama generation methods often result in AI agents that lack initiative and cannot interact with the physical environment. Furthermore, these methods typically require detailed user input to drive the drama. These limitations reduce the interactivity and immersion of online real-time performance. To address the above challenges, we propose HAMLET, a multi-agent framework focused on drama creation and online performance. Given a simple topic, the framework generates a narrative blueprint, guiding the subsequent improvisational performance. During the online performance, each actor is given an autonomous mind. This means that actors can make independent decisions based on their own background, goals, and emotional state. In addition to conversations with other actors, their decisions can also change the state of scene props through actions such as opening a letter or picking up a weapon. The change is then broadcast to other related actors, updating what they know and care about, which in turn influences their next action. To evaluate the quality of drama performance, we designed an evaluation method to assess three primary aspects, including character performance, narrative quality, and interaction experience. The experimental evaluation shows that HAMLET can create expressive and coherent theatrical experiences. Our code, dataset and models are available at https://github.com/HAMLET-2025/HAMLET.",
      "authors": [
        "Sizhou Chen",
        "Shufan Jiang",
        "Chi Zhang",
        "Xiao-Lei Zhang",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T11:36:39+00:00",
          "link": "https://arxiv.org/abs/2507.15518v1",
          "size": "4404kb",
          "version": "v1"
        }
      ],
      "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15518",
        "HTML": "https://arxiv.org/html/2507.15518",
        "PDF": "https://arxiv.org/pdf/2507.15518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves LLMs, its main focus is on creating a multi-agent framework for interactive theatrical experiences. It does not specifically address LLM training data processing, although it may involve generating narrative data for fine-tuning models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14775",
      "abstract": "The inherent vulnerability of wireless communication necessitates strategies to enhance its security, particularly in the face of jamming attacks. This paper uses the collaborations of multiple sensing nodes (SNs) in the wireless network to present a cooperative anti-jamming approach (CAJ) designed to neutralize the impact of jamming attacks. We propose an eigenvector (EV) method to estimate the direction of the channel vector from pilot symbols. Through our analysis, we demonstrate that with an adequate number of pilot symbols, the performance of the proposed EV method is comparable to the scenario where the perfect channel state information (CSI) is utilized. Both analytical formulas and simulations illustrate the excellent performance of the proposed EV-CAJ under strong jamming signals. Considering severe jamming, the proposed EV-CAJ method exhibits only a 0.7 dB degradation compared to the case without jamming especially when the number of SNs is significantly larger than the number of jamming nodes (JNs). Moreover, the extension of the proposed method can handle multiple jammers at the expense of degrees of freedom (DoF). We also investigate the method's ability to remain robust in fast-fading channels with different coherence times. Our proposed approach demonstrates good resilience, particularly when the ratio of the channel's coherence time to the time frame is small. This is especially important in the case of mobile jammers with large Doppler shifts.",
      "authors": [
        "Amir Mehrabian",
        "Georges Kaddoum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T00:28:36+00:00",
          "link": "https://arxiv.org/abs/2507.14775v1",
          "size": "1226kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Resilience Against Jamming Attacks: A Cooperative Anti-Jamming Method Using Direction Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14775",
        "HTML": "https://arxiv.org/html/2507.14775",
        "PDF": "https://arxiv.org/pdf/2507.14775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus of this paper is on a cooperative method for enhancing resilience against jamming attacks in wireless communications, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14784",
      "abstract": "Video Question Answering (VideoQA) requires identifying sparse critical moments in long videos and reasoning about their causal relationships to answer semantically complex questions. While recent advances in multimodal learning have improved alignment and fusion, current approaches remain limited by two prevalent but fundamentally flawed strategies: (1) task-agnostic sampling indiscriminately processes all frames, overwhelming key events with irrelevant content; and (2) heuristic retrieval captures superficial patterns but misses causal-temporal structures needed for complex reasoning. To address these challenges, we introduce LeAdQA, an innovative approach that bridges these gaps through synergizing causal-aware query refinement with fine-grained visual grounding. Our method first leverages LLMs to reformulate question-option pairs, resolving causal ambiguities and sharpening temporal focus. These refined queries subsequently direct a temporal grounding model to precisely retrieve the most salient segments, complemented by an adaptive fusion mechanism dynamically integrating the evidence to maximize relevance. The integrated visual-textual cues are then processed by an MLLM to generate accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and NExT-GQA demonstrate that our method's precise visual grounding substantially enhances the understanding of video-question relationships, achieving state-of-the-art (SOTA) performance on complex reasoning tasks while maintaining computational efficiency.",
      "authors": [
        "Xinxin Dong",
        "Baoyun Peng",
        "Haokai Ma",
        "Yufei Wang",
        "Zixuan Dong",
        "Fei Hu",
        "Xiaodong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T01:57:00+00:00",
          "link": "https://arxiv.org/abs/2507.14784v1",
          "size": "2753kb",
          "version": "v1"
        }
      ],
      "title": "LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14784",
        "HTML": "https://arxiv.org/html/2507.14784",
        "PDF": "https://arxiv.org/pdf/2507.14784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "LeAdQA involves using LLMs for improving video question answering through query refinement and temporal grounding, with minor focus on data processing as it uses existing data for video QA enhancement rather than creating or processing new training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15569",
      "abstract": "In recent years, the introduction of Multi-modal Large Language Models (MLLMs) into video understanding tasks has become increasingly prevalent. However, how to effectively integrate temporal information remains a critical research focus. Traditional approaches treat spatial and temporal information separately. Due to issues like motion blur, it is challenging to accurately represent the spatial information of rapidly moving objects. This can lead to temporally important regions being underemphasized during spatial feature extraction, which in turn hinders accurate spatio-temporal interaction and video understanding. To address this limitation, we propose an innovative video representation method called Dynamic-Image (DynImg). Specifically, we introduce a set of non-key frames as temporal prompts to highlight the spatial areas containing fast-moving objects. During the process of visual feature extraction, these prompts guide the model to pay additional attention to the fine-grained spatial features corresponding to these regions. Moreover, to maintain the correct sequence for DynImg, we employ a corresponding 4D video Rotary Position Embedding. This retains both the temporal and spatial adjacency of DynImg, helping MLLM understand the spatio-temporal order within this combined format. Experimental evaluations reveal that DynImg surpasses the state-of-the-art methods by approximately 2% across multiple video understanding benchmarks, proving the effectiveness of our temporal prompts in enhancing video comprehension.",
      "authors": [
        "Xiaoyi Bao",
        "Chenwei Xie",
        "Hao Tang",
        "Tingyu Weng",
        "Xiaofeng Wang",
        "Yun Zheng and Xingang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T12:50:49+00:00",
          "link": "https://arxiv.org/abs/2507.15569v1",
          "size": "9947kb",
          "version": "v1"
        }
      ],
      "title": "DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15569",
        "HTML": "https://arxiv.org/html/2507.15569",
        "PDF": "https://arxiv.org/pdf/2507.15569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a video representation method for multi-modal video understanding, focusing on spatio-temporal interactions, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15818",
      "abstract": "We study the problem of semantic private information retrieval (Sem-PIR) with $T$ colluding servers (Sem-TPIR), i.e., servers that collectively share user queries. In Sem-TPIR, the message sizes are different, and message retrieval probabilities by any user are not uniform. This is a generalization of the classical PIR problem where the message sizes are equal and message retrieval probabilities are identical. The earlier work on Sem-PIR considered the case of no collusions, i.e., the collusion parameter of $T=1$. In this paper, we consider the general problem for arbitrary $T < N$. We find an upper bound on the retrieval rate and design a scheme that achieves this rate, i.e., we derive the exact capacity of Sem-TPIR.",
      "authors": [
        "Mohamed Nomeir",
        "Alptug Aytekin",
        "Sennur Ulukus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:24:40+00:00",
          "link": "https://arxiv.org/abs/2507.15818v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "The Capacity of Semantic Private Information Retrieval with Colluding Servers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15818",
        "HTML": "https://arxiv.org/html/2507.15818",
        "PDF": "https://arxiv.org/pdf/2507.15818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines semantic private information retrieval with colluding servers, which is a concern of data privacy in communications systems. It does not address the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00306",
      "abstract": "J-PARSE is a method for smooth first-order inverse kinematic control of a serial manipulator near kinematic singularities. The commanded end-effector velocity is interpreted component-wise, according to the available mobility in each dimension of the task space. First, a substitute \"Safety\" Jacobian matrix is created, keeping the aspect ratio of the manipulability ellipsoid above a threshold value. The desired motion is then projected onto non-singular and singular directions, and the latter projection scaled down by a factor informed by the threshold value. A right-inverse of the non-singular Safety Jacobian is applied to the modified command. In the absence of joint limits and collisions, this ensures smooth transition into and out of low-rank poses, guaranteeing asymptotic stability for target poses within the workspace, and stability for those outside. Velocity control with J-PARSE is benchmarked against the Least-Squares and Damped Least-Squares inversions of the Jacobian, and shows high accuracy in reaching and leaving singular target poses. By expanding the available workspace of manipulators, the method finds applications in servoing, teleoperation, and learning. Videos and code are available at https://jparse-manip.github.io/.",
      "authors": [
        "Shivani Guptasarma",
        "Matthew Strong",
        "Honghao Zhen and Monroe Kennedy III"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T04:58:50+00:00",
          "link": "https://arxiv.org/abs/2505.00306v1",
          "size": "14572kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T16:08:39+00:00",
          "link": "https://arxiv.org/abs/2505.00306v2",
          "size": "32264kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T22:46:57+00:00",
          "link": "https://arxiv.org/abs/2505.00306v3",
          "size": "12206kb",
          "version": "v3"
        }
      ],
      "title": "J-PARSE: Jacobian-based Projection Algorithm for Resolving Singularities Effectively in Inverse Kinematic Control of Serial Manipulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00306",
        "HTML": "https://arxiv.org/html/2505.00306",
        "PDF": "https://arxiv.org/pdf/2505.00306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a method for inverse kinematic control of serial manipulators, which is unrelated to LLM training data processing, focusing instead on robotics and control systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09410",
      "abstract": "Camera traps have long been used by wildlife researchers to monitor and study animal behavior, population dynamics, habitat use, and species diversity in a non-invasive and efficient manner. While data collection from the field has increased with new tools and capabilities, methods to develop, process, and manage the data, especially the adoption of ML/AI tools, remain challenging. These challenges include the sheer volume of data generated, the need for accurate labeling and annotation, variability in environmental conditions affecting data quality, and the integration of ML/AI tools into existing workflows that often require domain-specific customization and computational resources. This paper provides a guide to a low-resource pipeline to process camera trap data on-premise, incorporating ML/AI capabilities tailored for small research groups with limited resources and computational expertise. By focusing on practical solutions, the pipeline offers accessible approaches for data transmission, inference, and evaluation, enabling researchers to discover meaningful insights from their ever-increasing camera trap datasets.",
      "authors": [
        "Bernie Boscoe",
        "Shawn Johnson",
        "Andrea Osbon",
        "Chandler Campbell",
        "Karen Mager"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T22:02:55+00:00",
          "link": "https://arxiv.org/abs/2507.09410v1",
          "size": "20217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T19:29:25+00:00",
          "link": "https://arxiv.org/abs/2507.09410v2",
          "size": "20217kb",
          "version": "v2"
        }
      ],
      "title": "GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09410",
        "HTML": "https://arxiv.org/html/2507.09410",
        "PDF": "https://arxiv.org/pdf/2507.09410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a pipeline for processing camera trap data in environmental science, incorporating ML/AI tools tailored for wildlife research, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11061",
      "abstract": "Recent advances in 3D neural representations and instance-level editing models have enabled the efficient creation of high-quality 3D content. However, achieving precise local 3D edits remains challenging, especially for Gaussian Splatting, due to inconsistent multi-view 2D part segmentations and inherently ambiguous nature of Score Distillation Sampling (SDS) loss. To address these limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that enables precise and drastic part-level modifications. First, we introduce a robust 3D mask generation module with our 3D-Geometry Aware Label Prediction (3D-GALP), which uses spherical harmonics (SH) coefficients to model view-dependent label variations and soft-label property, yielding accurate and consistent part segmentations across viewpoints. Second, we propose a regularized SDS loss that combines the standard SDS loss with additional regularizers. In particular, an L1 anchor loss is introduced via our Scheduled Latent Mixing and Part (SLaMP) editing method, which generates high-quality part-edited 2D images and confines modifications only to the target region while preserving contextual coherence. Additional regularizers, such as Gaussian prior removal, further improve flexibility by allowing changes beyond the existing context, and robust 3D masking prevents unintended edits. Experimental results demonstrate that our RoMaP achieves state-of-the-art local 3D editing on both reconstructed and generated Gaussian scenes and objects qualitatively and quantitatively, making it possible for more robust and flexible part-level 3D Gaussian editing. Code is available at https://janeyeon.github.io/romap.",
      "authors": [
        "Hayeon Kim",
        "Ji Ha Jang and Se Young Chun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.11061v1",
          "size": "32579kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T10:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.11061v2",
          "size": "32580kb",
          "version": "v2"
        }
      ],
      "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11061",
        "HTML": "https://arxiv.org/html/2507.11061",
        "PDF": "https://arxiv.org/pdf/2507.11061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D Gaussian editing with a specific method for local 3D modifications. It deals with graphics and computational geometry, not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14161",
      "abstract": "This study integrates causal inference, graph analysis, temporal complexity measures, and machine learning to examine whether individual symptom trajectories can reveal meaningful diagnostic patterns. Testing on a longitudinal dataset of N=45 individuals affected by General Anxiety Disorder (GAD) and/or Major Depressive Disorder (MDD) derived from Fisher et al. 2017, we propose a novel pipeline for the analysis of the temporal dynamics of psychopathological symptoms. First, we employ the PCMCI+ algorithm with nonparametric independence test to determine the causal network of nonlinear dependencies between symptoms in individuals with different mental disorders. We found that the PCMCI+ effectively highlights the individual peculiarities of each symptom network, which could be leveraged towards personalized therapies. At the same time, aggregating the networks by diagnosis sheds light to disorder-specific causal mechanisms, in agreement with previous psychopathological literature. Then, we enrich the dataset by computing complexity-based measures (e.g. entropy, fractal dimension, recurrence) from the symptom time series, and feed it to a suitably selected machine learning algorithm to aid the diagnosis of each individual. The new dataset yields 91% accuracy in the classification of the symptom dynamics, proving to be an effective diagnostic support tool. Overall, these findings highlight how integrating causal modeling and temporal complexity can enhance diagnostic differentiation, offering a principled, data-driven foundation for both personalized assessment in clinical psychology and structural advances in psychological research.",
      "authors": [
        "Eleonora Vitanza",
        "Pietro DeLellis",
        "Chiara Mocenni",
        "Manuel Ruiz Marin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T16:38:37+00:00",
          "link": "https://arxiv.org/abs/2507.14161v1",
          "size": "6444kb",
          "version": "v1"
        }
      ],
      "title": "Complex Dynamics in Psychological Data: Mapping Individual Symptom Trajectories to Group-Level Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14161",
        "HTML": "https://arxiv.org/html/2507.14161",
        "PDF": "https://arxiv.org/pdf/2507.14161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates psychological data using causal inference and machine learning to analyze symptom trajectories, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15289",
      "abstract": "The energy-based vector hysteresis model of Francois-Lavet et al. establishes an implicit relation between magnetic fields and fluxes via internal magnetic polarizations which are determined by convex but non-smooth minimization problems. The systematic solution of these problems for every material point is a key ingredient for the efficient implementation of the model into standard magnetic field solvers. We propose to approximate the non-smooth terms via regularization which allows to employ standard Newton methods for the evaluation of the local material models while being in control of the error in this approximation. We further derive the inverse of the regularized hysteresis operator which amounts to a regularized version of the inverse hysteresis model. The magnetic polarizations in this model are again determined by local minimization problems which here are coupled across the different pinning forces. An efficient algorithm for solving the Newton systems is proposed which allows evaluation of the inverse hysteresis operator at the same cost as the forward model. Numerical tests on standard benchmark problems are presented for illustration of our results.",
      "authors": [
        "Herbert Egger",
        "Felix Engertsberger",
        "Andreas Schafelner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:40:08+00:00",
          "link": "https://arxiv.org/abs/2507.15289v1",
          "size": "117kb",
          "version": "v1"
        }
      ],
      "title": "Efficient evaluation of forward and inverse energy-based magnetic hysteresis operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15289",
        "HTML": "https://arxiv.org/html/2507.15289",
        "PDF": "https://arxiv.org/pdf/2507.15289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with energy-based magnetic hysteresis operators in the context of magnetic field solvers, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15802",
      "abstract": "In recent decades, hypergraphs and their analysis through Topological Data Analysis (TDA) have emerged as powerful tools for understanding complex data structures. Various methods have been developed to construct hypergraphs -- referred to as simplicial complexes in the TDA framework -- over datasets, enabling the formation of edges between more than two vertices. This paper addresses the challenge of constructing hypergraphs from collections of multivariate time series. While prior work has focused on the case of a single multivariate time series, we extend this framework to handle collections of such time series. Our approach generalizes the method proposed in Chretien and al. by leveraging the properties of signature transforms to introduce controlled randomness, thereby enhancing the robustness of the construction process. We validate our method on synthetic datasets and present promising results.",
      "authors": [
        "R\\'emi Vaucher and Paul Minchella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:02:36+00:00",
          "link": "https://arxiv.org/abs/2507.15802v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "Hypergraphs on high dimensional time series sets using signature transform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15802",
        "HTML": "https://arxiv.org/html/2507.15802",
        "PDF": "https://arxiv.org/pdf/2507.15802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research concerns hypergraphs and time series data, extending methods for constructing hypergraphs from multivariate time series. It does not relate to language models or data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.04860",
      "abstract": "Process extraction from text is an important task of process discovery, for which various approaches have been developed in recent years. However, in contrast to other information extraction tasks, there is a lack of gold-standard corpora of business process descriptions that are carefully annotated with all the entities and relationships of interest. Due to this, it is currently hard to compare the results obtained by extraction approaches in an objective manner, whereas the lack of annotated texts also prevents the application of data-driven information extraction methodologies, typical of the natural language processing field. Therefore, to bridge this gap, we present the PET dataset, a first corpus of business process descriptions annotated with activities, gateways, actors, and flow information. We present our new resource, including a variety of baselines to benchmark the difficulty and challenges of business process extraction from text. PET can be accessed via huggingface.co/datasets/patriziobellan/PET",
      "authors": [
        "Patrizio Bellan",
        "Han van der Aa",
        "Mauro Dragoni",
        "Chiara Ghidini",
        "Simone Paolo Ponzetto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-09T16:33:59+00:00",
          "link": "https://arxiv.org/abs/2203.04860v1",
          "size": "1282kb",
          "version": "v1"
        },
        {
          "date": "2022-06-13T13:19:25+00:00",
          "link": "https://arxiv.org/abs/2203.04860v2",
          "size": "1508kb",
          "version": "v2"
        }
      ],
      "title": "PET: An Annotated Dataset for Process Extraction from Natural Language Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.04860",
        "PDF": "https://arxiv.org/pdf/2203.04860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents PET, a dataset for process extraction from text. While it involves the creation of an annotated dataset, the focus is on business process extraction rather than specifically on LLM training data processing for pretraining or fine-tuning."
      },
      "datasets": [
        {
          "dataset_name": "patriziobellan/PET",
          "downloads": "213",
          "likes": "20",
          "link": "https://huggingface.co/datasets/patriziobellan/PET"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.21517",
      "abstract": "Video Snapshot Compressive Imaging (SCI) aims to use a low-speed 2D camera to capture high-speed scene as snapshot compressed measurements, followed by a reconstruction algorithm to reconstruct the high-speed video frames. State-of-the-art (SOTA) deep learning-based algorithms have achieved impressive performance, yet with heavy computational workload. Network quantization is a promising way to reduce computational cost. However, a direct low-bit quantization will bring large performance drop. To address this challenge, in this paper, we propose a simple low-bit quantization framework (dubbed Q-SCI) for the end-to-end deep learning-based video SCI reconstruction methods which usually consist of a feature extraction, feature enhancement, and video reconstruction module. Specifically, we first design a high-quality feature extraction module and a precise video reconstruction module to extract and propagate high-quality features in the low-bit quantized model. In addition, to alleviate the information distortion of the Transformer branch in the quantized feature enhancement module, we introduce a shift operation on the query and key distributions to further bridge the performance gap. Comprehensive experimental results manifest that our Q-SCI framework can achieve superior performance, e.g., 4-bit quantized EfficientSCI-S derived by our Q-SCI framework can theoretically accelerate the real-valued EfficientSCI-S by 7.8X with only 2.3% performance gap on the simulation testing datasets. Code is available at https://github.com/mcao92/QuantizedSCI.",
      "authors": [
        "Miao Cao",
        "Lishun Wang",
        "Huan Wang",
        "Xin Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-31T10:38:11+00:00",
          "link": "https://arxiv.org/abs/2407.21517v1",
          "size": "6008kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T08:06:48+00:00",
          "link": "https://arxiv.org/abs/2407.21517v2",
          "size": "5795kb",
          "version": "v2"
        }
      ],
      "title": "A Simple Low-bit Quantization Framework for Video Snapshot Compressive Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.21517",
        "HTML": "https://arxiv.org/html/2407.21517",
        "PDF": "https://arxiv.org/pdf/2407.21517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a low-bit quantization framework for video snapshot compressive imaging, which does not relate to training data processing for LLMs."
      },
      "tasks": [
        "Quantization",
        "Video Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/mcao92/quantizedsci"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11299",
      "abstract": "This paper reports the first brain-inspired large language model (BriLLM). This is a non-Transformer, non-GPT, non-traditional machine learning input-output controlled generative language model. The model is based on the Signal Fully-connected flowing (SiFu) definition on the directed graph in terms of the neural network, and has the interpretability of all nodes on the graph of the whole model, instead of the traditional machine learning model that only has limited interpretability at the input and output ends. In the language model scenario, the token is defined as a node in the graph. A randomly shaped or user-defined signal flow flows between nodes on the principle of \"least resistance\" along paths. The next token or node to be predicted or generated is the target of the signal flow. As a language model, BriLLM theoretically supports infinitely long $n$-gram models when the model size is independent of the input and predicted length of the model. The model's working signal flow provides the possibility of recall activation and innate multi-modal support similar to the cognitive patterns of the human brain. At present, we released the first BriLLM version in Chinese, with 4000 tokens, 32-dimensional node width, 16-token long sequence prediction ability, and language model prediction performance comparable to GPT-1. More computing power will help us explore the infinite possibilities depicted above.",
      "authors": [
        "Hai Zhao and Hongqiu Wu and Dongjie Yang and Anni Zou and Jiale Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T11:08:30+00:00",
          "link": "https://arxiv.org/abs/2503.11299v1",
          "size": "3371kb",
          "version": "v1"
        },
        {
          "date": "2025-04-07T11:09:39+00:00",
          "link": "https://arxiv.org/abs/2503.11299v2",
          "size": "3371kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T15:02:30+00:00",
          "link": "https://arxiv.org/abs/2503.11299v3",
          "size": "3371kb",
          "version": "v3"
        },
        {
          "date": "2025-05-25T04:34:29+00:00",
          "link": "https://arxiv.org/abs/2503.11299v4",
          "size": "3579kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T11:11:05+00:00",
          "link": "https://arxiv.org/abs/2503.11299v5",
          "size": "550kb",
          "version": "v5"
        }
      ],
      "title": "BriLLM: Brain-inspired Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11299",
        "PDF": "https://arxiv.org/pdf/2503.11299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a brain-inspired language model (BriLLM), focusing on model architecture and generative capabilities, without mentioning contributions to training data processing for LLMs."
      },
      "models": [
        {
          "model_path": "BriLLM/BriLLM0.5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BriLLM/BriLLM0.5"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05759",
      "abstract": "In low-light environments, the performance of computer vision algorithms often deteriorates significantly, adversely affecting key vision tasks such as segmentation, detection, and classification. With the rapid advancement of deep learning, its application to low-light image processing has attracted widespread attention and seen significant progress in recent years. However, there remains a lack of comprehensive surveys that systematically examine how recent deep-learning-based low-light image enhancement methods function and evaluate their effectiveness in enhancing downstream vision tasks. To address this gap, this review provides detailed elaboration on how various recent approaches (from 2020) operate and their enhancement mechanisms, supplemented with clear illustrations. It also investigates the impact of different enhancement techniques on subsequent vision tasks, critically analyzing their strengths and limitations. Our review found that image enhancement improved the performance of downstream vision tasks to varying degrees. Although supervised methods often produced images with high perceptual quality, they typically produced modest improvements in vision tasks. In contrast, zero-shot learning, despite achieving lower scores in image quality metrics, showed consistently boosted performance across various vision tasks. These suggest a disconnect between image quality metrics and those evaluating vision task performance. Additionally, unsupervised domain adaptation techniques demonstrated significant gains in segmentation tasks, highlighting their potential in practical low-light scenarios where labelled data is scarce. Observed limitations of existing studies are analyzed, and directions for future research are proposed. This review serves as a useful reference for determining low-light image enhancement techniques and optimizing vision task performance in low-light conditions.",
      "authors": [
        "Fangxue Liu and Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T03:39:23+00:00",
          "link": "https://arxiv.org/abs/2505.05759v1",
          "size": "2013kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T02:31:12+00:00",
          "link": "https://arxiv.org/abs/2505.05759v2",
          "size": "2878kb",
          "version": "v2"
        }
      ],
      "title": "A review of advancements in low-light image enhancement using deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05759",
        "PDF": "https://arxiv.org/pdf/2505.05759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This review paper discusses deep learning techniques for low-light image enhancement and their impact on computer vision tasks, which do not relate to LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Image Enhancement",
        "Low-Light Image Enhancement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12982",
      "abstract": "It is well known that evolutionary algorithms can benefit from dynamic choices of the key parameters that control their behavior, to adjust their search strategy to the different stages of the optimization process. A prominent example where dynamic parameter choices have shown a provable super-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing the OneMax function. While optimal parameter control policies result in linear expected running times, this is not possible with static parameter choices. This result has spurred a lot of interest in parameter control policies. However, many works, in particular theoretical running time analyses, focus on controlling one single parameter. Deriving policies for controlling multiple parameters remains very challenging. In this work we reconsider the problem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We decouple its four main parameters and investigate how well state-of-the-art deep reinforcement learning techniques can approximate good control policies. We show that although making deep reinforcement learning learn effectively is a challenging task, once it works, it is very powerful and is able to find policies that outperform all previously known control policies on the same benchmark. Based on the results found through reinforcement learning, we derive a simple control policy that consistently outperforms the default theory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest existing control policy on this benchmark, by $13\\%$, for all tested problem sizes up to $40{,}000$.",
      "authors": [
        "Tai Nguyen",
        "Phong Le",
        "Carola Doerr",
        "Nguyen Dang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T11:18:41+00:00",
          "link": "https://arxiv.org/abs/2505.12982v1",
          "size": "239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:18:09+00:00",
          "link": "https://arxiv.org/abs/2505.12982v2",
          "size": "241kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T19:56:29+00:00",
          "link": "https://arxiv.org/abs/2505.12982v3",
          "size": "242kb",
          "version": "v3"
        }
      ],
      "title": "Multi-parameter Control for the $(1+(\\lambda,\\lambda))$-GA on OneMax via Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12982",
        "HTML": "https://arxiv.org/html/2505.12982",
        "PDF": "https://arxiv.org/pdf/2505.12982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an optimization approach for evolutionary algorithms using deep reinforcement learning, unrelated to LLM training data processing operations such as data collection or dataset creation for LLMs."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Evolutionary Algorithms",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14647",
      "abstract": "We introduce our submission to the AudioMOS Challenge (AMC) 2025 Track 3: mean opinion score (MOS) prediction for speech with multiple sampling frequencies (SFs). Our submitted model integrates an SF-independent (SFI) convolutional layer into a self-supervised learning (SSL) model to achieve SFI speech feature extraction for MOS prediction. We present some strategies to improve the MOS prediction performance of our model: distilling knowledge from a pretrained non-SFI-SSL model and pretraining with a large-scale MOS dataset. Our submission to the AMC 2025 Track 3 ranked the first in one evaluation metric and the fourth in the final ranking. We also report the results of our ablation study to investigate essential factors of our model.",
      "authors": [
        "Go Nishikawa",
        "Wataru Nakata",
        "Yuki Saito",
        "Kanami Imamura",
        "Hiroshi Saruwatari",
        "Tomohiko Nakamura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T14:41:51+00:00",
          "link": "https://arxiv.org/abs/2507.14647v1",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Sampling-Frequency Naturalness MOS Prediction Using Self-Supervised Learning Model with Sampling-Frequency-Independent Layer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14647",
        "HTML": "https://arxiv.org/html/2507.14647",
        "PDF": "https://arxiv.org/pdf/2507.14647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on MOS prediction for speech using self-supervised learning, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15690",
      "abstract": "Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in reconstructing high-quality novel views, as it often overfits to the widely-varying high-frequency (HF) details of the sparse training views. While frequency regularization can be a promising approach, its typical reliance on Fourier transforms causes difficult parameter tuning and biases towards detrimental HF learning. We propose DWTGS, a framework that rethinks frequency regularization by leveraging wavelet-space losses that provide additional spatial supervision. Specifically, we supervise only the low-frequency (LF) LL subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband in a self-supervised manner. Experiments across benchmarks show that DWTGS consistently outperforms Fourier-based counterparts, as this LF-centric strategy improves generalization and reduces HF hallucinations.",
      "authors": [
        "Hung Nguyen and Runfa Li and An Le and Truong Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:56:46+00:00",
          "link": "https://arxiv.org/abs/2507.15690v1",
          "size": "14662kb",
          "version": "v1"
        }
      ],
      "title": "DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15690",
        "HTML": "https://arxiv.org/html/2507.15690",
        "PDF": "https://arxiv.org/pdf/2507.15690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for frequency regularization in 3D Gaussian Splatting, targeting improvements in 3D view reconstruction, not related to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14385",
      "abstract": "The manufacturing industry is under growing pressure to enhance sustainability while preserving economic competitiveness. As a result, manufacturers have been trying to determine how to integrate onsite renewable energy and real-time electricity pricing into manufacturing schedules without compromising profitability. To address this challenge, we propose a bi-level model predictive control framework that jointly optimizes product prices and production scheduling with explicit consideration of renewable energy availability. The higher level determines the product price to maximize revenue and renewable energy usage. The lower level controls production scheduling in runtime to minimize operational costs and respond to the product demand. Price elasticity is incorporated to model market response, allowing the system to increase demand by lowering the product price during high renewable energy generation. Results from a lithium-ion battery pack manufacturing system case study demonstrate that our approach enables manufacturers to reduce grid energy costs while increasing profit.",
      "authors": [
        "Hongliang Li",
        "Herschel C. Pangborn",
        "Ilya Kovalenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:17:42+00:00",
          "link": "https://arxiv.org/abs/2507.14385v1",
          "size": "2034kb",
          "version": "v1"
        }
      ],
      "title": "Bi-level Model Predictive Control for Energy-aware Integrated Product Pricing and Production Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14385",
        "HTML": "https://arxiv.org/html/2507.14385",
        "PDF": "https://arxiv.org/pdf/2507.14385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on optimizing product pricing and production scheduling for energy-aware manufacturing, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14492",
      "abstract": "Many critical decision-making tasks are now delegated to machine-learned models, and it is imperative that their decisions are trustworthy and reliable, and their outputs are consistent across similar inputs. We identify a new source of unreliable behaviors-called glitches-which may significantly impair the reliability of AI models having steep decision boundaries. Roughly speaking, glitches are small neighborhoods in the input space where the model's output abruptly oscillates with respect to small changes in the input. We provide a formal definition of glitches, and use well-known models and datasets from the literature to demonstrate that they have widespread existence and argue they usually indicate potential model inconsistencies in the neighborhood of where they are found. We proceed to the algorithmic search of glitches for widely used gradient-boosted decision tree (GBDT) models. We prove that the problem of detecting glitches is NP-complete for tree ensembles, already for trees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP encoding of the problem, and its effectiveness and computational feasibility are demonstrated on a set of widely used GBDT benchmarks taken from the literature.",
      "authors": [
        "Satyankar Chandra",
        "Ashutosh Gupta",
        "Kaushik Mallik",
        "Krishna Shankaranarayanan",
        "Namrita Varshney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T05:33:57+00:00",
          "link": "https://arxiv.org/abs/2507.14492v1",
          "size": "1143kb",
          "version": "v1"
        }
      ],
      "title": "Glitches in Decision Tree Ensemble Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14492",
        "PDF": "https://arxiv.org/pdf/2507.14492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on glitches in decision tree ensemble models and does not cover any aspects of LLM training data processing or associated data operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "1909.04374",
      "abstract": "Cache persistence analysis is an important part of worst-case execution time (WCET) analysis. It has been extensively studied in the past twenty years. Despite these efforts, all existing persistence analyses are approximative in the sense that they are not guaranteed to find all persistent memory blocks.\n  In this paper, we close this gap by introducing the first exact persistence analysis for caches with least-recently-used (LRU) replacement. To this end, we first introduce an exact abstraction that exploits monotonicity properties of LRU to significantly reduce the information the analysis needs to maintain for exact persistence classifications. We show how to efficiently implement this abstraction using zero-suppressed binary decision diagrams (ZDDs) and introduce novel techniques to deal with uncertainty that arises during the analysis of data caches.\n  The experimental evaluation demonstrates that the new exact analysis is competitive with state-of-the-art inexact analyses in terms of both memory consumption and analysis run time, which is somewhat surprising as we show that persistence analysis is NP-complete. We also observe that while prior analyses are not exact in theory they come close to being exact in practice.",
      "authors": [
        "Gregory Stock",
        "Sebastian Hahn",
        "Jan Reineke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-10T09:49:57+00:00",
          "link": "https://arxiv.org/abs/1909.04374v1",
          "size": "1436kb",
          "version": "v1"
        }
      ],
      "title": "Cache Persistence Analysis: Finally Exact",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.04374",
        "PDF": "https://arxiv.org/pdf/1909.04374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to cache persistence analysis and worst-case execution time analysis. It is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.12897",
      "abstract": "A vast amount of instruction tuning data is crucial for the impressive performance of Large Multimodal Models (LMMs), but the associated computational costs and data collection demands during supervised fine-tuning make it impractical for most researchers. Federated learning (FL) has the potential to leverage all distributed data and training resources to reduce the overhead of joint training. However, most existing methods assume a fixed number of tasks, while in real-world scenarios, clients continuously encounter new knowledge and often struggle to retain old tasks due to memory constraints. In this work, we introduce the Federated Continual Instruction Tuning (FCIT) benchmark to model this real-world challenge. Our benchmark includes two realistic scenarios, encompassing four different settings and twelve carefully curated instruction tuning datasets. To address the challenges posed by FCIT, we propose dynamic knowledge organization to effectively integrate updates from different tasks during training and subspace selective activation to allocate task-specific output during inference. Extensive experimental results demonstrate that our proposed method significantly enhances model performance across varying levels of data heterogeneity and catastrophic forgetting. Code and dataset are released at https://github.com/Ghy0501/FCIT.",
      "authors": [
        "Haiyang Guo",
        "Fanhu Zeng",
        "Fei Zhu",
        "Wenzhuo Liu",
        "Da-Han Wang",
        "Jian Xu",
        "Xu-Yao Zhang",
        "Cheng-Lin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T07:58:06+00:00",
          "link": "https://arxiv.org/abs/2503.12897v1",
          "size": "2064kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:46:38+00:00",
          "link": "https://arxiv.org/abs/2503.12897v2",
          "size": "2050kb",
          "version": "v2"
        }
      ],
      "title": "Federated Continual Instruction Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12897",
        "HTML": "https://arxiv.org/html/2503.12897",
        "PDF": "https://arxiv.org/pdf/2503.12897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the FCIT benchmark for federated continual instruction tuning, providing a dataset and addressing data heterogeneity challenges in instruction tuning. It contributes directly to data processing for fine-tuning LLMs."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.07212",
      "abstract": "State-sponsored influence operations (SIOs) have become a pervasive and complex challenge in the digital age, particularly on social media platforms where information spreads rapidly and with minimal oversight. These operations are strategically employed by nation-state actors to manipulate public opinion, exacerbate social divisions, and project geopolitical narratives, often through the dissemination of misleading or inflammatory content. Despite increasing awareness of their existence, the specific linguistic and emotional strategies employed by these campaigns remain underexplored. This study addresses this gap by conducting a comprehensive analysis of sentiment, emotional valence, and abusive language across 2 million tweets attributed to influence operations linked to China, Iran, and Russia, using Twitter's publicly released dataset of state-affiliated accounts. We identify distinct affective and rhetorical patterns that characterize each nation's digital propaganda. Russian campaigns predominantly deploy negative sentiment and toxic language to intensify polarization and destabilize discourse. In contrast, Iranian operations blend antagonistic and supportive tones to simultaneously incite conflict and foster ideological alignment. Chinese activities emphasize positive sentiment and emotionally neutral rhetoric to promote favorable narratives and subtly influence global perceptions. These findings reveal how state actors tailor their information warfare tactics to achieve specific geopolitical objectives through differentiated content strategies.",
      "authors": [
        "Ashfaq Ali Shafin and Khandaker Mamun Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T03:43:48+00:00",
          "link": "https://arxiv.org/abs/2505.07212v1",
          "size": "1544kb",
          "version": "v1"
        },
        {
          "date": "2025-05-31T19:50:15+00:00",
          "link": "https://arxiv.org/abs/2505.07212v2",
          "size": "864kb",
          "version": "v2"
        },
        {
          "date": "2025-07-18T18:48:30+00:00",
          "link": "https://arxiv.org/abs/2505.07212v3",
          "size": "864kb",
          "version": "v3"
        }
      ],
      "title": "The Language of Influence: Sentiment, Emotion, and Hate Speech in State Sponsored Influence Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07212",
        "HTML": "https://arxiv.org/html/2505.07212",
        "PDF": "https://arxiv.org/pdf/2505.07212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes sentiment and emotional strategies in state-sponsored influence operations and does not contribute to any facet of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.16091",
      "abstract": "Pretrained latent diffusion models have shown strong potential for lossy image compression, owing to their powerful generative priors. Most existing diffusion-based methods reconstruct images by iteratively denoising from random noise, guided by compressed latent representations. While these approaches have achieved high reconstruction quality, their multi-step sampling process incurs substantial computational overhead. Moreover, they typically require training separate models for different compression bit-rates, leading to significant training and storage costs. To address these challenges, we propose a one-step diffusion codec across multiple bit-rates. termed OSCAR. Specifically, our method views compressed latents as noisy variants of the original latents, where the level of distortion depends on the bit-rate. This perspective allows them to be modeled as intermediate states along a diffusion trajectory. By establishing a mapping from the compression bit-rate to a pseudo diffusion timestep, we condition a single generative model to support reconstructions at multiple bit-rates. Meanwhile, we argue that the compressed latents retain rich structural information, thereby making one-step denoising feasible. Thus, OSCAR replaces iterative sampling with a single denoising pass, significantly improving inference efficiency. Extensive experiments demonstrate that OSCAR achieves superior performance in both quantitative and visual quality metrics. The code and models will be released at https://github.com/jp-guo/OSCAR.",
      "authors": [
        "Jinpei Guo",
        "Yifei Ji",
        "Zheng Chen",
        "Kai Liu",
        "Min Liu",
        "Wang Rao",
        "Wenbo Li",
        "Yong Guo",
        "and Yulun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T00:14:12+00:00",
          "link": "https://arxiv.org/abs/2505.16091v1",
          "size": "18502kb",
          "version": "v1"
        },
        {
          "date": "2025-05-24T12:28:19+00:00",
          "link": "https://arxiv.org/abs/2505.16091v2",
          "size": "18502kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T20:58:12+00:00",
          "link": "https://arxiv.org/abs/2505.16091v3",
          "size": "14187kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T18:07:00+00:00",
          "link": "https://arxiv.org/abs/2505.16091v4",
          "size": "14187kb",
          "version": "v4"
        }
      ],
      "title": "OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16091",
        "HTML": "https://arxiv.org/html/2505.16091",
        "PDF": "https://arxiv.org/pdf/2505.16091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with image compression using pretrained latent diffusion models, focusing on codec efficiency and not on any aspect of LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Image Compression"
      ],
      "repo_urls": [
        "https://github.com/jp-guo/oscar"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03034",
      "abstract": "The (generative) artificial intelligence (AI) era has profoundly reshaped the meaning and value of data. No longer confined to static content, data now permeates every stage of the AI lifecycle from the training samples that shape model parameters to the prompts and outputs that drive real-world model deployment. This shift renders traditional notions of data protection insufficient, while the boundaries of what needs safeguarding remain poorly defined. Failing to safeguard data in AI systems can inflict societal and individual, underscoring the urgent need to clearly delineate the scope of and rigorously enforce data protection. In this perspective, we propose a four-level taxonomy, including non-usability, privacy preservation, traceability, and deletability, that captures the diverse protection needs arising in modern (generative) AI models and systems. Our framework offers a structured understanding of the trade-offs between data utility and control, spanning the entire AI pipeline, including training datasets, model weights, system prompts, and AI-generated content. We analyze representative technical approaches at each level and reveal regulatory blind spots that leave critical assets exposed. By offering a structured lens to align future AI technologies and governance with trustworthy data practices, we underscore the urgency of rethinking data protection for modern AI techniques and provide timely guidance for developers, researchers, and regulators alike.",
      "authors": [
        "Yiming Li",
        "Shuo Shao",
        "Yu He",
        "Junfeng Guo",
        "Tianwei Zhang",
        "Zhan Qin",
        "Pin-Yu Chen",
        "Michael Backes",
        "Philip Torr",
        "Dacheng Tao",
        "Kui Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:45:51+00:00",
          "link": "https://arxiv.org/abs/2507.03034v1",
          "size": "1387kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T06:52:55+00:00",
          "link": "https://arxiv.org/abs/2507.03034v2",
          "size": "1413kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T05:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.03034v3",
          "size": "1413kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03034",
        "HTML": "https://arxiv.org/html/2507.03034",
        "PDF": "https://arxiv.org/pdf/2507.03034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper surveys data protection issues within AI systems, addressing challenges in data contexts such as training datasets. However, its main contribution is not in training data processing techniques but rather in data protection frameworks, decisions, and governance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07485",
      "abstract": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.",
      "authors": [
        "Wooseong Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.07485v1",
          "size": "1089kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T06:05:16+00:00",
          "link": "https://arxiv.org/abs/2507.07485v2",
          "size": "1088kb",
          "version": "v2"
        }
      ],
      "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07485",
        "HTML": "https://arxiv.org/html/2507.07485",
        "PDF": "https://arxiv.org/pdf/2507.07485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses token-space manipulation for improving multi-task learning in transformer models. It does not discuss training data processing related to pretraining or fine-tuning of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09560",
      "abstract": "3D hand pose estimation has garnered great attention in recent years due to its critical applications in human-computer interaction, virtual reality, and related fields. The accurate estimation of hand joints is essential for high-quality hand pose estimation. However, existing methods neglect the importance of Distal Phalanx Tip (TIP) and Wrist in predicting hand joints overall and often fail to account for the phenomenon of error accumulation for distal joints in gesture estimation, which can cause certain joints to incur larger errors, resulting in misalignments and artifacts in the pose estimation and degrading the overall reconstruction quality. To address this challenge, we propose a novel segmented architecture for enhanced hand pose estimation (EHPE). We perform local extraction of TIP and wrist, thus alleviating the effect of error accumulation on TIP prediction and further reduce the predictive errors for all joints on this basis. EHPE consists of two key stages: In the TIP and Wrist Joints Extraction stage (TW-stage), the positions of the TIP and wrist joints are estimated to provide an initial accurate joint configuration; In the Prior Guided Joints Estimation stage (PG-stage), a dual-branch interaction network is employed to refine the positions of the remaining joints. Extensive experiments on two widely used benchmarks demonstrate that EHPE achieves state-of-the-arts performance. Code is available at https://github.com/SereinNout/EHPE.",
      "authors": [
        "Bolun Zheng",
        "Xinjie Liu",
        "Qianyu Zhang",
        "Canjin Wang",
        "Fangni Chen",
        "Mingen Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:09:23+00:00",
          "link": "https://arxiv.org/abs/2507.09560v1",
          "size": "1295kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T15:21:24+00:00",
          "link": "https://arxiv.org/abs/2507.09560v2",
          "size": "1296kb",
          "version": "v2"
        }
      ],
      "title": "EHPE: A Segmented Architecture for Enhanced Hand Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09560",
        "HTML": "https://arxiv.org/html/2507.09560",
        "PDF": "https://arxiv.org/pdf/2507.09560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses 3D hand pose estimation enhancements, which include a novel architecture for joint prediction, not involving any processes related to LLM training or data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14344",
      "abstract": "Language models are commonly fine-tuned via reinforcement learning to alter their behavior or elicit new capabilities. Datasets used for these purposes, and particularly human preference datasets, are often noisy. The relatively small size post-training datasets, combined with parameter-efficient fine-tuning methods, enable the use of influence functions approximations to detect and prune training examples that are harmful to performance on a validation set. In this work, we adapt the TL;DR dataset for reward model training to demonstrate how conjugate-gradient approximated influence functions can be used to filter datasets. In our experiments, influence function filtering yields a small retraining accuracy uplift of 1.5% after removing 10% of training examples. We also show that gradient similarity outperforms influence functions for detecting helpful training examples. This suggests that local curvature is important for detecting harmful training examples, but less so for identifying helpful examples.",
      "authors": [
        "Daniel Fein",
        "Gabriela Aranguiz-Dias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:43:36+00:00",
          "link": "https://arxiv.org/abs/2507.14344v1",
          "size": "2023kb",
          "version": "v1"
        }
      ],
      "title": "Influence Functions for Preference Dataset Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14344",
        "HTML": "https://arxiv.org/html/2507.14344",
        "PDF": "https://arxiv.org/pdf/2507.14344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper addresses the use of influence functions to prune noisy datasets for fine-tuning language models, significantly contributing to the improvement of training data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14459",
      "abstract": "The dissemination of visualizations is primarily in the form of raster images, which often results in the loss of critical information such as source code, interactive features, and metadata. While previous methods have proposed embedding metadata into images to facilitate Visualization Image Data Retrieval (VIDR), most existing methods lack practicability since they are fragile to common image tampering during online distribution such as cropping and editing. To address this issue, we propose VisGuard, a tamper-resistant VIDR framework that reliably embeds metadata link into visualization images. The embedded data link remains recoverable even after substantial tampering upon images. We propose several techniques to enhance robustness, including repetitive data tiling, invertible information broadcasting, and an anchor-based scheme for crop localization. VisGuard enables various applications, including interactive chart reconstruction, tampering detection, and copyright protection. We conduct comprehensive experiments on VisGuard's superior performance in data retrieval accuracy, embedding capacity, and security against tampering and steganalysis, demonstrating VisGuard's competence in facilitating and safeguarding visualization dissemination and information conveyance.",
      "authors": [
        "Huayuan Ye",
        "Juntong Chen",
        "Shenzhuo Zhang",
        "Yipeng Zhang",
        "Changbo Wang",
        "Chenhui Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T03:09:30+00:00",
          "link": "https://arxiv.org/abs/2507.14459v1",
          "size": "26167kb",
          "version": "v1"
        }
      ],
      "title": "VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14459",
        "HTML": "https://arxiv.org/html/2507.14459",
        "PDF": "https://arxiv.org/pdf/2507.14459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for secure visualization dissemination through tamper-resistant data retrieval, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14783",
      "abstract": "The advancement of general-purpose artificial intelligence relies on large language models (LLMs) that excel across a wide range of tasks, from structured reasoning to creative generation. However, post-training methods like Supervised Fine-Tuning (SFT) often struggle with generalization, favoring memorization over transferable learning. In this work, we introduce Omni-Think, a unified reinforcement learning (RL) framework that enhances LLM performance across diverse tasks by combining rule-based verifiable rewards with generative preference signals via LLM-as-a-Judge evaluations. Our approach enables consistent optimization across task types and scales RL-based training to subjective domains. We further investigate training strategies, demonstrating that a curriculum-based progression that orders tasks from structured to open-ended improves performance and reduces forgetting. Experimental results across four domains reveal that curriculum learning improves performance by 5.2\\% over joint training and 9.1\\% over model merging. These results highlight the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs.",
      "authors": [
        "Derek Li and Jiaming Zhou",
        "Amirreza Kazemi",
        "Qianyi Sun",
        "Abbas Ghaddar",
        "Mohammad Ali Alomrani",
        "Liheng Ma",
        "Yu Luo",
        "Dong Li",
        "Feng Wen",
        "Jianye Hao",
        "Mark Coates",
        "Yingxue Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T01:50:16+00:00",
          "link": "https://arxiv.org/abs/2507.14783v1",
          "size": "839kb",
          "version": "v1"
        }
      ],
      "title": "Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14783",
        "HTML": "https://arxiv.org/html/2507.14783",
        "PDF": "https://arxiv.org/pdf/2507.14783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Omni-Think, a reinforcement learning framework for LLMs, focusing on task generalization and curriculum learning rather than data processing techniques. It briefly touches on task-aware sampling, which is tangentially related to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15000",
      "abstract": "Document dewarping is crucial for many applications. However, existing learning-based methods primarily rely on supervised regression with annotated data without leveraging the inherent geometric properties in physical documents to the dewarping process. Our key insight is that a well-dewarped document is characterized by transforming distorted feature lines into axis-aligned ones. This property aligns with the inherent axis-aligned nature of the discrete grid geometry in planar documents. In the training phase, we propose an axis-aligned geometric constraint to enhance document dewarping. In the inference phase, we propose an axis alignment preprocessing strategy to reduce the dewarping difficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned Distortion (AAD), that not only incorporates geometric meaning and aligns with human visual perception but also demonstrates greater robustness. As a result, our method achieves SOTA results on multiple existing benchmarks and achieves 18.2%~34.5% improvements on the AAD metric.",
      "authors": [
        "Chaoyun Wang",
        "I-Chao Shen",
        "Takeo Igarashi",
        "Nanning Zheng",
        "Caigui Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T15:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.15000v1",
          "size": "30046kb",
          "version": "v1"
        }
      ],
      "title": "Axis-Aligned Document Dewarping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15000",
        "HTML": "https://arxiv.org/html/2507.15000",
        "PDF": "https://arxiv.org/pdf/2507.15000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses document dewarping by introducing geometric constraints and evaluation metrics, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15124",
      "abstract": "The rise of social networking platforms has amplified privacy threats as users increasingly share sensitive information across profiles, content, and social connections. We present a Comprehensive Privacy Risk Scoring (CPRS) framework that quantifies privacy risk by integrating user attributes, social graph structures, and user-generated content. Our framework computes risk scores across these dimensions using sensitivity, visibility, structural similarity, and entity-level analysis, then aggregates them into a unified risk score. We validate CPRS on two real-world datasets: the SNAP Facebook Ego Network (4,039 users) and the Koo microblogging dataset (1M posts, 1M comments). The average CPRS is 0.478 with equal weighting, rising to 0.501 in graph-sensitive scenarios. Component-wise, graph-based risks (mean 0.52) surpass content (0.48) and profile attributes (0.45). High-risk attributes include email, date of birth, and mobile number. Our user study with 100 participants shows 85% rated the dashboard as clear and actionable, confirming CPRS's practical utility. This work enables personalized privacy risk insights and contributes a holistic, scalable methodology for privacy management. Future directions include incorporating temporal dynamics and multimodal content for broader applicability.",
      "authors": [
        "Md Jahangir Alam",
        "Ismail Hossain",
        "Sai Puppala",
        "Sajedul Talukder"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T21:18:50+00:00",
          "link": "https://arxiv.org/abs/2507.15124v1",
          "size": "305kb",
          "version": "v1"
        }
      ],
      "title": "Comprehensive Privacy Risk Assessment in Social Networks Using User Attributes Social Graphs and Text Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15124",
        "HTML": "https://arxiv.org/html/2507.15124",
        "PDF": "https://arxiv.org/pdf/2507.15124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a privacy risk assessment framework for social networks, focusing on user attributes and social graph analysis. It does not involve LLM training data processing techniques or dataset management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15833",
      "abstract": "Human vision is a highly active process driven by gaze, which directs attention and fixation to task-relevant regions and dramatically reduces visual processing. In contrast, robot learning systems typically rely on passive, uniform processing of raw camera images. In this work, we explore how incorporating human-like active gaze into robotic policies can enhance both efficiency and performance. We build on recent advances in foveated image processing and apply them to an Active Vision robot system that emulates both human head movement and eye tracking. Extending prior work on the AV-ALOHA robot simulation platform, we introduce a framework for simultaneously collecting eye-tracking data and robot demonstrations from a human operator as well as a simulation benchmark and dataset for training robot policies that incorporate human gaze. Given the widespread use of Vision Transformers (ViTs) in robot learning, we integrate gaze information into ViTs using a foveated patch tokenization scheme inspired by recent work in image segmentation. Compared to uniform patch tokenization, this significantly reduces the number of tokens-and thus computation-without sacrificing visual fidelity near regions of interest. We also explore two approaches to gaze imitation and prediction from human data. The first is a two-stage model that predicts gaze to guide foveation and action; the second integrates gaze into the action space, allowing the policy to jointly predict gaze and actions end-to-end. Our results show that our method for foveated robot vision not only drastically reduces computational overhead, but also improves performance for high precision tasks and robustness to unseen distractors. Together, these findings suggest that human-inspired visual processing offers a useful inductive bias for robotic vision systems. https://ian-chuang.github.io/gaze-av-aloha/",
      "authors": [
        "Ian Chuang",
        "Andrew Lee",
        "Dechen Gao",
        "Jinyu Zou",
        "Iman Soltani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:44:10+00:00",
          "link": "https://arxiv.org/abs/2507.15833v1",
          "size": "2502kb",
          "version": "v1"
        }
      ],
      "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15833",
        "HTML": "https://arxiv.org/html/2507.15833",
        "PDF": "https://arxiv.org/pdf/2507.15833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on enhancing robot learning through human-like gaze and visual processing, but it does not relate to LLM training data processing or the creation of datasets for such models."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.15562",
      "abstract": "Domain adaptation is especially important for robotics applications, where target domain training data is usually scarce and annotations are costly to obtain. We present a method for self-supervised domain adaptation for the scenario where annotated source domain data (e.g. from synthetic generation) is available, but the target domain data is completely unannotated. Our method targets the semantic segmentation task and leverages a segmentation foundation model (Segment Anything Model) to obtain segment information on unannotated data. We take inspiration from recent advances in unsupervised local feature learning and propose an invariance-variance loss over the detected segments for regularizing feature representations in the target domain. Crucially, this loss structure and network architecture can handle overlapping segments and oversegmentation as produced by Segment Anything. We demonstrate the advantage of our method on the challenging YCB-Video and HomebrewedDB datasets and show that it outperforms prior work and, on YCB-Video, even a network trained with real annotations. Additionally, we provide insight through model ablations and show applicability to a custom robotic application.",
      "authors": [
        "Mayara E. Bonani",
        "Max Schwarz",
        "Sven Behnke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-27T10:37:36+00:00",
          "link": "https://arxiv.org/abs/2309.15562v1",
          "size": "1401kb",
          "version": "v1"
        },
        {
          "date": "2024-02-14T11:13:33+00:00",
          "link": "https://arxiv.org/abs/2309.15562v2",
          "size": "2245kb",
          "version": "v2"
        },
        {
          "date": "2024-05-10T15:07:54+00:00",
          "link": "https://arxiv.org/abs/2309.15562v3",
          "size": "2245kb",
          "version": "v3"
        },
        {
          "date": "2025-07-21T08:42:10+00:00",
          "link": "https://arxiv.org/abs/2309.15562v4",
          "size": "2042kb",
          "version": "v4"
        }
      ],
      "title": "Learning from SAM: Harnessing a Foundation Model for Sim2Real Adaptation by Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.15562",
        "HTML": "https://arxiv.org/html/2309.15562",
        "PDF": "https://arxiv.org/pdf/2309.15562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on domain adaptation and semantic segmentation tasks using a foundation model. It does not discuss LLM training data processing but rather model architecture and adaptation strategies, making it irrelevant to LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14211",
      "abstract": "Predictive Quality of Service (PQoS) makes it possible to anticipate QoS changes, e.g., in wireless networks, and trigger appropriate countermeasures to avoid performance degradation. Hence, PQoS is extremely useful for automotive applications such as teleoperated driving, which poses strict constraints in terms of latency and reliability. A promising tool for PQoS is given by Reinforcement Learning (RL), a methodology that enables the design of decision-making strategies for stochastic optimization. In this manuscript, we present PRATA, a new simulation framework to enable PRedictive QoS based on AI for Teleoperated driving Applications. PRATA consists of a modular pipeline that includes (i) an end-to-end protocol stack to simulate the 5G Radio Access Network (RAN), (ii) a tool for generating automotive data, and (iii) an Artificial Intelligence (AI) unit to optimize PQoS decisions. To prove its utility, we use PRATA to design an RL unit, named RAN-AI, to optimize the segmentation level of teleoperated driving data in the event of resource saturation or channel degradation. Hence, we show that the RAN-AI entity efficiently balances the trade-off between QoS and Quality of Experience (QoE) that characterize teleoperated driving applications, almost doubling the system performance compared to baseline approaches. In addition, by varying the learning settings of the RAN-AI entity, we investigate the impact of the state space and the relative cost of acquiring network data that are necessary for the implementation of RL.",
      "authors": [
        "Federico Mason",
        "Tommaso Zugno",
        "Matteo Drago",
        "Marco Giordani",
        "Mate Boban",
        "and Michele Zorzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:36:25+00:00",
          "link": "https://arxiv.org/abs/2507.14211v1",
          "size": "1364kb",
          "version": "v1"
        }
      ],
      "title": "PRATA: A Framework to Enable Predictive QoS in Vehicular Networks via Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14211",
        "HTML": "https://arxiv.org/html/2507.14211",
        "PDF": "https://arxiv.org/pdf/2507.14211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for predictive QoS in vehicular networks, focusing on AI and reinforcement learning for network optimization, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14324",
      "abstract": "Identity verification is the process of confirming an individual's claimed identity, which is essential in sectors like finance, healthcare, and online services to ensure security and prevent fraud. However, current password/PIN-based identity solutions are susceptible to phishing or skimming attacks, where malicious intermediaries attempt to steal credentials using fake identification portals. Alikhani et al. [Nature, 2021] began exploring identity verification through graph coloring-based relativistic zero-knowledge proofs (RZKPs), a key cryptographic primitive that enables a prover to demonstrate knowledge of secret credentials to a verifier without disclosing any information about the secret. Our work advances this field and addresses unresolved issues: From an engineering perspective, we relax further the relativistic constraints from 60m to 30m, and significantly enhance the stability and scalability of the experimental demonstration of the 2-prover graph coloring-based RZKP protocol for near-term use cases. At the same time, for long-term security against entangled malicious provers, we propose a modified protocol with comparable computation and communication costs, we establish an upper bound on the soundness parameter for this modified protocol. On the other hand, we extend the two-prover, two-verifier setup to a three-prover configuration, demonstrating the security of such relativistic protocols against entangled malicious provers.",
      "authors": [
        "Yao Ma",
        "Wen Yu Kon",
        "Jefferson Chu",
        "Kevin Han Yong Loh",
        "Kaushik Chakraborty and Charles Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T18:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.14324v1",
          "size": "6497kb",
          "version": "v1"
        }
      ],
      "title": "Quantum-Safe Identity Verification using Relativistic Zero-Knowledge Proof Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14324",
        "PDF": "https://arxiv.org/pdf/2507.14324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on quantum-safe identity verification using zero-knowledge proof systems, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14590",
      "abstract": "Numerous domain-specific machine learning tasks struggle with data scarcity and class imbalance. This paper systematically explores data augmentation methods for NLP, particularly through large language models like GPT. The purpose of this paper is to examine and evaluate whether traditional methods such as paraphrasing and backtranslation can leverage a new generation of models to achieve comparable performance to purely generative methods. Methods aimed at solving the problem of data scarcity and utilizing ChatGPT were chosen, as well as an exemplary dataset. We conducted a series of experiments comparing four different approaches to data augmentation in multiple experimental setups. We then evaluated the results both in terms of the quality of generated data and its impact on classification performance. The key findings indicate that backtranslation and paraphrasing can yield comparable or even better results than zero and a few-shot generation of examples.",
      "authors": [
        "{\\L}ukasz Radli\\'nski",
        "Mateusz Gu\\'sciora",
        "Jan Koco\\'n"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:23:20+00:00",
          "link": "https://arxiv.org/abs/2507.14590v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14590",
        "PDF": "https://arxiv.org/pdf/2507.14590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores data augmentation methods, such as backtranslation and paraphrasing, using LLMs for emotion classification, which relates to data processing but only indirectly connected to LLM training data processing itself. Its main focus is on evaluating competitive performance with augmented data, not creating or improving datasets specifically for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14920",
      "abstract": "Time series data are prevalent across various domains and often encompass large datasets containing multiple time-dependent features in each sample. Exploring time-varying data is critical for data science practitioners aiming to understand dynamic behaviors and discover periodic patterns and trends. However, the analysis of such data often requires sophisticated procedures and tools. Information visualization is a communication channel that leverages human perceptual abilities to transform abstract data into visual representations. Visualization techniques have been successfully applied in the context of time series to enhance interpretability by graphically representing the temporal evolution of data. The challenge for information visualization developers lies in integrating a wide range of analytical tools into rich visualization systems that can summarize complex datasets while clearly describing the impacts of the temporal component. Such systems enable data scientists to turn raw data into understandable and potentially useful knowledge. This review examines techniques and approaches designed for handling time series data, guiding users through knowledge discovery processes based on visual analysis. We also provide readers with theoretical insights and design guidelines for considering when developing comprehensive information visualization approaches for time series, with a particular focus on time series with multiple features. As a result, we highlight the challenges and future research directions to address open questions in the visualization of time-dependent data.",
      "authors": [
        "Evandro S. Ortigossa",
        "F\\'abio F. Dias",
        "Diego C. Nascimento",
        "Luis Gustavo Nonato"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:28:47+00:00",
          "link": "https://arxiv.org/abs/2507.14920v1",
          "size": "3532kb",
          "version": "v1"
        }
      ],
      "title": "Time Series Information Visualization -- A Review of Approaches and Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14920",
        "HTML": "https://arxiv.org/html/2507.14920",
        "PDF": "https://arxiv.org/pdf/2507.14920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The review focuses on information visualization techniques for time series data, which is not applicable to LLM training data processing or the creation of datasets for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15762",
      "abstract": "In this work we consider generic coalescing of eigenvalues of smooth complex valued matrix functions depending on 2 parameters. We call generic cuspidal points the parameter values where eigenvalues coalesce and we discuss the relation between cuspidal points and the closely related exceptional points studied in the literature. By considering loops in parameter space enclosing the cuspidal points, we rigorously prove when there is a phase accumulation for the eigenvectors and further detail how, by looking at the periodicity of the eigenvalues along the loop, and/or by looking at the aforementioned phase accumulation, one may be able to localize generic cuspidal points.",
      "authors": [
        "Luca Dieci",
        "Alessandro Pugliese"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:19:21+00:00",
          "link": "https://arxiv.org/abs/2507.15762v1",
          "size": "3535kb",
          "version": "v1"
        }
      ],
      "title": "Generic cuspidal points and their localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15762",
        "HTML": "https://arxiv.org/html/2507.15762",
        "PDF": "https://arxiv.org/pdf/2507.15762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on mathematical concepts like eigenvalues and cuspidal points, with no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.14077",
      "abstract": "Retrosynthesis poses a key challenge in biopharmaceuticals, aiding chemists in finding appropriate reactant molecules for given product molecules. With reactants and products represented as 2D graphs, retrosynthesis constitutes a conditional graph-to-graph (G2G) generative task. Inspired by advancements in discrete diffusion models for graph generation, we aim to design a diffusion-based method to address this problem. However, integrating a diffusion-based G2G framework while retaining essential chemical reaction template information presents a notable challenge. Our key innovation involves a multi-stage diffusion process. We decompose the retrosynthesis procedure to first sample external groups from the dummy distribution given products, then generate external bonds to connect products and generated groups. Interestingly, this generation process mirrors the reverse of the widely adapted semi-template retrosynthesis workflow, \\emph{i.e.} from reaction center identification to synthon completion. Based on these designs, we introduce Retrosynthesis Diffusion (RetroDiff), a novel diffusion-based method for the retrosynthesis task. Experimental results demonstrate that RetroDiff surpasses all semi-template methods in accuracy, and outperforms template-based and template-free methods in large-scale scenarios and molecular validity, respectively. Code: https://github.com/Alsace08/RetroDiff.",
      "authors": [
        "Yiming Wang",
        "Yuxuan Song",
        "Yiqun Wang",
        "Minkai Xu",
        "Rui Wang",
        "Hao Zhou",
        "Wei-Ying Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-23T16:08:52+00:00",
          "link": "https://arxiv.org/abs/2311.14077v1",
          "size": "1032kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T02:14:31+00:00",
          "link": "https://arxiv.org/abs/2311.14077v2",
          "size": "1399kb",
          "version": "v2"
        }
      ],
      "title": "RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.14077",
        "HTML": "https://arxiv.org/html/2311.14077",
        "PDF": "https://arxiv.org/pdf/2311.14077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a retrosynthesis task in biopharmaceuticals using diffusion-based methods for graph-to-graph tasks, unrelated to data processing or dataset creation for LLMs."
      },
      "tasks": [
        "Graph Generation",
        "Retrosynthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.20435",
      "abstract": "NASA's forthcoming Lunar Gateway space station, which will be uncrewed most of the time, will need to operate with an unprecedented level of autonomy. Enhancing autonomy on the Gateway presents several unique challenges, one of which is to equip the Canadarm3, the Gateway's external robotic system, with the capability to perform worksite monitoring. Monitoring will involve using the arm's inspection cameras to detect any anomalies within the operating environment, a task complicated by the widely-varying lighting conditions in space. In this paper, we introduce the visual anomaly detection and localization task for space applications and establish a benchmark with our novel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit). We develop a complete data generation pipeline to create ALLO, which we use to evaluate the performance of state-of-the-art visual anomaly detection algorithms. Given the low tolerance for risk during space operations and the lack of relevant data, we emphasize the need for novel, robust, and accurate anomaly detection methods to handle the challenging visual conditions found in lunar orbit and beyond.",
      "authors": [
        "Selina Leveugle",
        "Chang Won Lee",
        "Svetlana Stolpner",
        "Chris Langley",
        "Paul Grouchy",
        "Steven Waslander",
        "Jonathan Kelly"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T15:53:46+00:00",
          "link": "https://arxiv.org/abs/2409.20435v1",
          "size": "4742kb",
          "version": "v1"
        },
        {
          "date": "2024-11-14T22:27:15+00:00",
          "link": "https://arxiv.org/abs/2409.20435v2",
          "size": "4742kb",
          "version": "v2"
        },
        {
          "date": "2025-07-19T17:51:48+00:00",
          "link": "https://arxiv.org/abs/2409.20435v3",
          "size": "4742kb",
          "version": "v3"
        }
      ],
      "title": "ALLO: A Photorealistic Dataset and Data Generation Pipeline for Anomaly Detection During Robotic Proximity Operations in Lunar Orbit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.20435",
        "HTML": "https://arxiv.org/html/2409.20435",
        "PDF": "https://arxiv.org/pdf/2409.20435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the ALLO dataset and presents a complete data generation pipeline for anomaly detection in lunar orbit, which directly contributes to the creation of new datasets, relevant to training data processing."
      },
      "repo_urls": [
        "https://github.com/utiasSTARS/ALLO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01474",
      "abstract": "Interactive navigation is crucial in scenarios where proactively interacting with objects can yield shorter paths, thus significantly improving traversal efficiency. Existing methods primarily focus on using the robot body to relocate large obstacles (which could be comparable to the size of a robot). However, they prove ineffective in narrow or constrained spaces where the robot's dimensions restrict its manipulation capabilities. This paper introduces a novel interactive navigation framework for legged manipulators, featuring an active arm-pushing mechanism that enables the robot to reposition movable obstacles in space-constrained environments. To this end, we develop a reinforcement learning-based arm-pushing controller with a two-stage reward strategy for large-object manipulation. Specifically, this strategy first directs the manipulator to a designated pushing zone to achieve a kinematically feasible contact configuration. Then, the end effector is guided to maintain its position at appropriate contact points for stable object displacement while preventing toppling. The simulations validate the robustness of the arm-pushing controller, showing that the two-stage reward strategy improves policy convergence and long-term performance. Real-world experiments further demonstrate the effectiveness of the proposed navigation framework, which achieves shorter paths and reduced traversal time. The open-source project can be found at https://github.com/Zhihaibi/Interactive-Navigation-for-legged-manipulator.git.",
      "authors": [
        "Zhihai Bi",
        "Kai Chen",
        "Chunxin Zheng",
        "Yulin Li",
        "Haoang Li",
        "and Jun Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T12:29:48+00:00",
          "link": "https://arxiv.org/abs/2503.01474v1",
          "size": "3659kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T14:00:54+00:00",
          "link": "https://arxiv.org/abs/2503.01474v2",
          "size": "3643kb",
          "version": "v2"
        }
      ],
      "title": "Interactive Navigation for Legged Manipulators with Learned Arm-Pushing Controller",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01474",
        "HTML": "https://arxiv.org/html/2503.01474",
        "PDF": "https://arxiv.org/pdf/2503.01474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a navigation framework for legged manipulators, focusing on robotic control strategies and obstacle interaction, unrelated to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/zhihaibi/interactive-navigation-for-legged-manipulator"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14372",
      "abstract": "The introduction of large language models has brought rapid progress on Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise solution. In this paper, we present insights from building an internal chatbot that enables LinkedIn's product managers, engineers, and operations teams to self-serve data insights from a large, dynamic data lake. Our approach features three components. First, we construct a knowledge graph that captures up-to-date semantics by indexing database metadata, historical query logs, wikis, and code. We apply clustering to identify relevant tables for each team or product area. Second, we build a Text-to-SQL agent that retrieves and ranks context from the knowledge graph, writes a query, and automatically corrects hallucinations and syntax errors. Third, we build an interactive chatbot that supports various user intents, from data discovery to query writing to debugging, and displays responses in rich UI elements to encourage follow-up chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of its responses are correct or close to correct on an internal benchmark set. Through ablation studies, we identify the most important knowledge graph and modeling components, offering a practical path for developing enterprise Text-to-SQL solutions.",
      "authors": [
        "Albert Chen",
        "Manas Bundele",
        "Gaurav Ahlawat",
        "Patrick Stetz",
        "Zhitao Wang",
        "Qiang Fei",
        "Donghoon Jung",
        "Audrey Chu",
        "Bharadwaj Jayaraman",
        "Ayushi Panth",
        "Yatin Arora",
        "Sourav Jain",
        "Renjith Varma",
        "Alexey Ilin",
        "Iuliia Melnychuk",
        "Chelsea Chueh",
        "Joyan Sil and Xiaofeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T21:39:17+00:00",
          "link": "https://arxiv.org/abs/2507.14372v1",
          "size": "4187kb",
          "version": "v1"
        }
      ],
      "title": "Text-to-SQL for Enterprise Data Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14372",
        "HTML": "https://arxiv.org/html/2507.14372",
        "PDF": "https://arxiv.org/pdf/2507.14372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes building a Text-to-SQL system that leverages a knowledge graph for enterprise data analytics. While it uses LLM for query construction and error correction, the main focus is not on LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14727",
      "abstract": "Quadrupedal animals employ diverse galloping strategies to optimize speed, stability, and energy efficiency. However, the biomechanical mechanisms that enable adaptive gait transitions during high-speed locomotion under load remain poorly understood. In this study, we present new empirical and modeling insights into the biomechanics of load-pulling quadrupeds, using sprint sled dogs as a model system. High-speed video and force recordings reveal that sled dogs often switch between rotary and transverse galloping gaits within just a few strides and without any observable changes in speed, stride duration, or terrain, providing clear evidence of locomotor multistability during high-speed load-pulling. To investigate the mechanical basis of these transitions, a physics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid dynamics and prescribed footfall sequences to reproduce the asymmetric galloping patterns observed in racing sled dogs. Through trajectory optimization, we replicate experimentally observed gait sequences and identify swing-leg stiffness modulation as a key control mechanism for inducing transitions. This work provides a much-needed biomechanical perspective on high-speed animal draft and establishes a modeling framework for studying locomotion in pulling quadrupeds, with implications for both biological understanding and the design of adaptive legged systems.",
      "authors": [
        "Jiayu Ding",
        "Benjamin Seleb",
        "Saad Bhamla",
        "Zhenyu Gan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:22:08+00:00",
          "link": "https://arxiv.org/abs/2507.14727v1",
          "size": "6045kb",
          "version": "v1"
        }
      ],
      "title": "Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14727",
        "HTML": "https://arxiv.org/html/2507.14727",
        "PDF": "https://arxiv.org/pdf/2507.14727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is focused on the biomechanics of quadrupeds and their gait transitions, with no discussion of LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14733",
      "abstract": "This work considers uplink asynchronous massive machine-type communications, where a large number of low-power and low-cost devices asynchronously transmit short packets to an access point equipped with multiple receive antennas. If orthogonal preambles are employed, massive collisions will occur due to the limited number of orthogonal preambles given the preamble sequence length. To address this problem, we propose a delay-calibrated joint user activity detection, channel estimation, and data detection algorithm, and investigate the benefits of oversampling in estimating continuous-valued time delays at the receiver. The proposed algorithm is based on the expectation-maximization method, which alternately estimates the delays and detects active users and their channels and data by noting that the collided users have different delays. Under the Bayesian inference framework, we develop a computationally efficient iterative algorithm using the approximate message passing principle to resolve the joint user activity detection, channel estimation, and data detection problem. Numerical results demonstrate the effectiveness of the proposed algorithm in terms of the normalized mean-squared errors of channel and data symbols, and the probability of misdetection.",
      "authors": [
        "Z. Shao",
        "X. Yuan and R. de Lamare"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:48:41+00:00",
          "link": "https://arxiv.org/abs/2507.14733v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "Study of Delay-Calibrated Joint User Activity Detection, Channel Estimation and Data Detection for Asynchronous mMTC Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14733",
        "HTML": "https://arxiv.org/html/2507.14733",
        "PDF": "https://arxiv.org/pdf/2507.14733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on user activity detection, channel estimation, and data detection in asynchronous mMTC systems, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14444",
      "abstract": "As a paradigm for sequential decision making in unknown environments, reinforcement learning (RL) has received a flurry of attention in recent years. However, the explosion of model complexity in emerging applications and the presence of nonconvexity exacerbate the challenge of achieving efficient RL in sample-starved situations, where data collection is expensive, time-consuming, or even high-stakes (e.g., in clinical trials, autonomous systems, and online advertising). How to understand and enhance the sample and computational efficacies of RL algorithms is thus of great interest. In this tutorial, we aim to introduce several important algorithmic and theoretical developments in RL, highlighting the connections between new ideas and classical topics. Employing Markov Decision Processes as the central mathematical model, we cover several distinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL, robust RL, and RL with human feedback), and present several mainstream RL approaches (i.e., model-based approach, value-based approach, and policy optimization). Our discussions gravitate around the issues of sample complexity, computational efficiency, as well as algorithm-dependent and information-theoretic lower bounds from a non-asymptotic viewpoint.",
      "authors": [
        "Yuejie Chi",
        "Yuxin Chen",
        "Yuting Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T02:42:41+00:00",
          "link": "https://arxiv.org/abs/2507.14444v1",
          "size": "126kb",
          "version": "v1"
        }
      ],
      "title": "Statistical and Algorithmic Foundations of Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14444",
        "HTML": "https://arxiv.org/html/2507.14444",
        "PDF": "https://arxiv.org/pdf/2507.14444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a tutorial on reinforcement learning, highlighting algorithmic and theoretical developments without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14588",
      "abstract": "Secure federated learning enables collaborative model training across decentralized users while preserving data privacy. A key component is secure aggregation, which keeps individual updates hidden from both the server and users, while also defending against Byzantine users who corrupt the aggregation. To this end, Jinhyun So et al. recently developed a Byzantine-resilient secure aggregation scheme using a secret-sharing strategy over finite-field arithmetic. However, such an approach can suffer from numerical errors and overflows when applied to real-valued model updates, motivating the need for secure aggregation methods that operate directly over the real domain. We propose FORTA, a Byzantine-resilient secure aggregation framework that operates entirely in the real domain. FORTA leverages Discrete Fourier Transform (DFT) codes for privacy and employs Krum-based outlier detection for robustness. While DFT decoder is error-free under infinite precision, finite precision introduces numerical perturbations that can distort distance estimates and allow malicious updates to evade detection. To address this, FORTA refines Krum using feedback from DFT decoder, improving the selection of trustworthy updates. Theoretical analysis and experiments show that our modification of Krum offers improved robustness and more accurate aggregation than standard Krum.",
      "authors": [
        "Usayd Shahul and J. Harshan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T12:17:24+00:00",
          "link": "https://arxiv.org/abs/2507.14588v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14588",
        "PDF": "https://arxiv.org/pdf/2507.14588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on Byzantine-resilient secure aggregation for federated learning, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14615",
      "abstract": "Large Language Models(LLMs) hold promise for improving healthcare access in low-resource settings, but their effectiveness in African primary care remains underexplored. We present a methodology for creating a benchmark dataset and evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our approach uses retrieval augmented generation (RAG) to ground clinical questions in Kenya's national guidelines, ensuring alignment with local standards. These guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic clinical scenarios, multiple-choice questions, and rationale based answers in English and Swahili. Kenyan physicians co-created and refined the dataset, and a blinded expert review process ensured clinical accuracy, clarity, and cultural appropriateness. The resulting Alama Health QA dataset includes thousands of regulator-aligned question answer pairs across common outpatient conditions. Beyond accuracy, we introduce evaluation metrics that test clinical reasoning, safety, and adaptability such as rare case detection (Needle in the Haystack), stepwise logic (Decision Points), and contextual adaptability. Initial results reveal significant performance gaps when LLMs are applied to localized scenarios, consistent with findings that LLM accuracy is lower on African medical content than on US-based benchmarks. This work offers a replicable model for guideline-driven, dynamic benchmarking to support safe AI deployment in African health systems.",
      "authors": [
        "Fred Mutisya (1,2)",
        "Shikoh Gitau (1)",
        "Christine Syovata (2)",
        "Diana Oigara (2)",
        "Ibrahim Matende (2)",
        "Muna Aden (2)",
        "Munira Ali (2)",
        "Ryan Nyotu (2)",
        "Diana Marion (2)",
        "Job Nyangena (2)",
        "Nasubo Ongoma (1)",
        "Keith Mbae (1)",
        "Elizabeth Wamicha (1)",
        "Eric Mibuari (1)",
        "Jean Philbert Nsengemana (3)",
        "Talkmore Chidede (4) ((1) Qhala",
        "Nairobi",
        "Kenya",
        "(2) Kenya Medical Association",
        "Nairobi",
        "Kenya",
        "(3) Africa CDC",
        "(4) AfCFTA)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:25:26+00:00",
          "link": "https://arxiv.org/abs/2507.14615v1",
          "size": "2479kb",
          "version": "v1"
        }
      ],
      "title": "Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14615",
        "PDF": "https://arxiv.org/pdf/2507.14615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents the creation of the Alama Health QA dataset, which entails a dataset creation process relevant to training data processing. However, its primary focus is on benchmarking for clinical testing, rather than a technical contribution to LLM data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14793",
      "abstract": "Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth transformations can be viewed as continuous symmetries of the environment that we inhabit, defining equivalence relations between stimuli over time. In machine learning, neural network architectures that respect symmetries of their data are called equivariant and have provable benefits in terms of generalization ability and sample efficiency. To date, however, equivariance has been considered only for static transformations and feed-forward networks, limiting its applicability to sequence models, such as recurrent neural networks (RNNs), and corresponding time-parameterized sequence transformations. In this work, we extend equivariant network theory to this regime of `flows' -- one-parameter Lie subgroups capturing natural transformations over time, such as visual motion. We begin by showing that standard RNNs are generally not flow equivariant: their hidden states fail to transform in a geometrically structured manner for moving stimuli. We then show how flow equivariance can be introduced, and demonstrate that these models significantly outperform their non-equivariant counterparts in terms of training speed, length generalization, and velocity generalization, on both next step prediction and sequence classification. We present this work as a first step towards building sequence models that respect the time-parameterized symmetries which govern the world around us.",
      "authors": [
        "T. Anderson Keller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:52:21+00:00",
          "link": "https://arxiv.org/abs/2507.14793v1",
          "size": "4574kb",
          "version": "v1"
        }
      ],
      "title": "Flow Equivariant Recurrent Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14793",
        "HTML": "https://arxiv.org/html/2507.14793",
        "PDF": "https://arxiv.org/pdf/2507.14793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on introducing flow equivariance to RNNs for improved sequence modeling. It does not discuss any aspects of data processing relevant to LLM training, such as dataset creation or quality enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14809",
      "abstract": "Predicting future motion trajectories is a critical capability across domains such as robotics, autonomous systems, and human activity forecasting, enabling safer and more intelligent decision-making. This paper proposes a novel, efficient, and lightweight approach for robot action prediction, offering significantly reduced computational cost and inference latency compared to conventional video prediction models. Importantly, it pioneers the adaptation of the InstructPix2Pix model for forecasting future visual frames in robotic tasks, extending its utility beyond static image editing. We implement a deep learning-based visual prediction framework that forecasts what a robot will observe 100 frames (10 seconds) into the future, given a current image and a textual instruction. We repurpose and fine-tune the InstructPix2Pix model to accept both visual and textual inputs, enabling multimodal future frame prediction. Experiments on the RoboTWin dataset (generated based on real-world scenarios) demonstrate that our method achieves superior SSIM and PSNR compared to state-of-the-art baselines in robot action prediction tasks. Unlike conventional video prediction models that require multiple input frames, heavy computation, and slow inference latency, our approach only needs a single image and a text prompt as input. This lightweight design enables faster inference, reduced GPU demands, and flexible multimodal control, particularly valuable for applications like robotics and sports motion trajectory analytics, where motion trajectory precision is prioritized over visual fidelity.",
      "authors": [
        "Zesen Zhong",
        "Duomin Zhang",
        "and Yijia Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:57:18+00:00",
          "link": "https://arxiv.org/abs/2507.14809v1",
          "size": "1342kb",
          "version": "v1"
        }
      ],
      "title": "Light Future: Multimodal Action Frame Prediction via InstructPix2Pix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14809",
        "HTML": "https://arxiv.org/html/2507.14809",
        "PDF": "https://arxiv.org/pdf/2507.14809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for predicting future motion trajectories in robotics using a visual prediction model. It discusses multimodal action frame prediction and fine-tuning of models but does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14841",
      "abstract": "In recent years, 3D generation has made great strides in both academia and industry. However, generating 3D scenes from a single RGB image remains a significant challenge, as current approaches often struggle to ensure both object generation quality and scene coherence in multi-object scenarios. To overcome these limitations, we propose a novel three-stage framework for 3D scene generation with explicit geometric representations and high-quality textural details via single image-guided model generation and spatial layout optimization. Our method begins with an image instance segmentation and inpainting phase, which recovers missing details of occluded objects in the input images, thereby achieving complete generation of foreground 3D assets. Subsequently, our approach captures the spatial geometry of reference image by constructing pseudo-stereo viewpoint for camera parameter estimation and scene depth inference, while employing a model selection strategy to ensure optimal alignment between the 3D assets generated in the previous step and the input. Finally, through model parameterization and minimization of the Chamfer distance between point clouds in 3D and 2D space, our approach optimizes layout parameters to produce an explicit 3D scene representation that maintains precise alignment with input guidance image. Extensive experiments on multi-object scene image sets have demonstrated that our approach not only outperforms state-of-the-art methods in terms of geometric accuracy and texture fidelity of individual generated 3D models, but also has significant advantages in scene layout synthesis.",
      "authors": [
        "Xiang Tang",
        "Ruotong Li",
        "Xiaopeng Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T06:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.14841v1",
          "size": "19449kb",
          "version": "v1"
        }
      ],
      "title": "Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14841",
        "HTML": "https://arxiv.org/html/2507.14841",
        "PDF": "https://arxiv.org/pdf/2507.14841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on 3D scene generation with geometric and textural consistency, using single image-guided generation and layout optimization. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14946",
      "abstract": "Patent examiners and inventors face significant pressure to verify the originality and non-obviousness of inventions, and the intricate nature of patent data intensifies the challenges of patent retrieval. Therefore, there is a pressing need to devise cutting-edge retrieval strategies that can reliably achieve the desired recall. This study introduces FullRecall, a novel patent retrieval approach that effectively manages the complexity of patent data while maintaining the reliability of relevance matching and maximising recall. It leverages IPC-guided knowledge to generate informative phrases, which are processed to extract key information in the form of noun phrases characterising the query patent under observation. From these, the top k keyphrases are selected to construct a query for retrieving a focused subset of the dataset. This initial retrieval step achieves complete recall, successfully capturing all relevant documents. To further refine the results, a ranking scheme is applied to the retrieved subset, reducing its size while maintaining 100% recall. This multi-phase process demonstrates an effective strategy for balancing precision and recall in patent retrieval tasks. Comprehensive experiments were conducted, and the results were compared with baseline studies, namely HRR2 [1] and ReQ-ReC [2]. The proposed approach yielded superior results, achieving 100% recall in all five test cases. However, HRR2[1] recall values across the five test cases were 10%, 25%, 33.3%, 0%, and 14.29%, while ReQ-ReC [2] showed 50% for the first test case, 25% for the second test case, and 0% for the third, fourth, and fifth test cases. The 100% recall ensures that no relevant prior art is overlooked, thereby strengthening the patent pre-filing and examination processes, hence reducing potential legal risks.",
      "authors": [
        "Amna Ali",
        "Liyanage C. De Silva",
        "Pg Emeroylariffion Abas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T12:52:58+00:00",
          "link": "https://arxiv.org/abs/2507.14946v1",
          "size": "2228kb",
          "version": "v1"
        }
      ],
      "title": "FullRecall: A Semantic Search-Based Ranking Approach for Maximizing Recall in Patent Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14946",
        "PDF": "https://arxiv.org/pdf/2507.14946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with patent retrieval and introduces a novel approach for maximizing recall. It does not relate to LLM training data processing in terms of dataset collection or processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15214",
      "abstract": "The temporal dynamics of speech, encompassing variations in rhythm, intonation, and speaking rate, contain important and unique information about speaker identity. This paper proposes a new method for representing speaker characteristics by extracting context-dependent duration embeddings from speech temporal dynamics. We develop novel attack models using these representations and analyze the potential vulnerabilities in speaker verification and voice anonymization systems.The experimental results show that the developed attack models provide a significant improvement in speaker verification performance for both original and anonymized data in comparison with simpler representations of speech temporal dynamics reported in the literature.",
      "authors": [
        "Natalia Tomashenko",
        "Emmanuel Vincent",
        "Marc Tommasi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T03:28:56+00:00",
          "link": "https://arxiv.org/abs/2507.15214v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Context-dependent Duration Features for Voice Anonymization Attack Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15214",
        "HTML": "https://arxiv.org/html/2507.15214",
        "PDF": "https://arxiv.org/pdf/2507.15214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses voice anonymization attack systems through representation of speech dynamics. It does not relate to any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.15618",
      "abstract": "Squamous cell carcinoma (SCC) is the most common cancer subtype, with an increasing incidence and a significant impact on cancer-related mortality. SCC grading using whole slide images is inherently challenging due to the lack of a reliable protocol and substantial tissue heterogeneity. We propose RACR-MIL, the first weakly-supervised SCC grading approach achieving robust generalization across multiple anatomies (skin, head and neck, lung). RACR-MIL is an attention-based multiple-instance learning framework that enhances grade-relevant contextual representation learning and addresses tumor heterogeneity through two key innovations: (1) a hybrid WSI graph that captures both local tissue context and non-local phenotypical dependencies between tumor regions, and (2) a rank-ordering constraint in the attention mechanism that consistently prioritizes higher-grade tumor regions, aligning with pathologists diagnostic process. Our model achieves state-of-the-art performance across multiple SCC datasets, achieving 3-9% higher grading accuracy, resilience to class imbalance, and up to 16% improved tumor localization. In a pilot study, pathologists reported that RACR-MIL improved grading efficiency in 60% of cases, underscoring its potential as a clinically viable cancer diagnosis and grading assistant.",
      "authors": [
        "Anirudh Choudhary",
        "Mosbah Aouad",
        "Krishnakant Saboo",
        "Angelina Hwang",
        "Jacob Kechter",
        "Blake Bordeaux",
        "Puneet Bhullar",
        "David DiCaudo",
        "Steven Nelson",
        "Nneka Comfere",
        "Emma Johnson",
        "Olayemi Sokumbi",
        "Jason Sluzevich",
        "Leah Swanson",
        "Dennis Murphree",
        "Aaron Mangold",
        "Ravishankar Iyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-29T20:25:49+00:00",
          "link": "https://arxiv.org/abs/2308.15618v1",
          "size": "24772kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T21:50:45+00:00",
          "link": "https://arxiv.org/abs/2308.15618v2",
          "size": "20086kb",
          "version": "v2"
        }
      ],
      "title": "RACR-MIL: Rank-aware contextual reasoning for weakly supervised grading of squamous cell carcinoma using whole slide images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.15618",
        "PDF": "https://arxiv.org/pdf/2308.15618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for grading squamous cell carcinoma using whole slide images. It addresses medical imaging and cancer diagnosis but does not contribute to LLM training data processing operations or datasets."
      },
      "tasks": [
        "Graph Attention",
        "Multiple Instance Learning",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.15219",
      "abstract": "Self-attention and transformers have been widely used in deep learning. Recent efforts have been devoted to incorporating transformer blocks into different neural architectures, including those with convolutions, leading to various visual transformers for computer vision tasks. In this paper, we propose a novel and compact transformer block, Transformer with Learnable Token Merging (LTM), or LTM-Transformer. LTM-Transformer performs token merging in a learnable scheme. LTM-Transformer is compatible with many popular and compact transformer networks, and it reduces the FLOPs and the inference time of the visual transformers while maintaining or even improving the prediction accuracy. In the experiments, we replace all the transformer blocks in popular visual transformers, including MobileViT, EfficientViT, ViT, and Swin, with LTM-Transformer blocks, leading to LTM-Transformer networks with different backbones. The LTM-Transformer is motivated by reduction of Information Bottleneck, and a novel and separable variational upper bound for the IB loss is derived. The architecture of the mask module in our LTM blocks, which generates the token merging mask, is designed to reduce the derived upper bound for the IB loss. Extensive results on computer vision tasks evidence that LTM-Transformer renders compact and efficient visual transformers with comparable or much better prediction accuracy than the original visual transformers. The code of the LTM-Transformer is available at https://github.com/Statistical-Deep-Learning/LTM}",
      "authors": [
        "Yancheng Wang",
        "Yingzhen Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-21T17:09:19+00:00",
          "link": "https://arxiv.org/abs/2407.15219v1",
          "size": "21150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T05:09:39+00:00",
          "link": "https://arxiv.org/abs/2407.15219v2",
          "size": "1220kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Visual Transformer by Learnable Token Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15219",
        "HTML": "https://arxiv.org/html/2407.15219",
        "PDF": "https://arxiv.org/pdf/2407.15219"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel transformer block for visual transformers to improve prediction accuracy and inference time. It focuses on model architecture rather than LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/statistical-deep-learning/ltm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.19334",
      "abstract": "The vast storage capacity and computational power of cloud servers have led to the widespread outsourcing of machine learning inference services. While offering significant operational benefits, this practice also introduces privacy risks, such as the exposure of proprietary models and sensitive user data. In this paper, we present OnePath, a framework for secure and efficient decision tree inference in cloud environments. Unlike existing methods that traverse all internal nodes of a decision tree, our traversal protocol processes only the nodes on the prediction path, significantly improving inference efficiency while preserving privacy. To further optimize privacy and performance, OnePath is the first to employ functional encryption for evaluating decision tree nodes. Notably, our protocol enables both model providers and users to remain offline during the inference phase, offering a crucial advantage for practical deployment. We provide formal security analysis to demonstrate that OnePath provides comprehensive privacy protections during the model inference process. Extensive experimental results show that our approach processes query data in microseconds, highlighting its efficiency. OnePath offers a practical solution that strikes a balance between security and performance, making it a promising option for a wide range of cloud-based decision tree inference applications.",
      "authors": [
        "Shuai Yuan",
        "Hongwei Li",
        "Xinyuan Qian",
        "Guowen Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-28T12:35:32+00:00",
          "link": "https://arxiv.org/abs/2409.19334v1",
          "size": "3532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T03:51:45+00:00",
          "link": "https://arxiv.org/abs/2409.19334v2",
          "size": "3188kb",
          "version": "v2"
        }
      ],
      "title": "OnePath: Efficient and Privacy-Preserving Decision Tree Inference in the Cloud",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.19334",
        "HTML": "https://arxiv.org/html/2409.19334",
        "PDF": "https://arxiv.org/pdf/2409.19334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy and efficiency improvements for decision tree inference in cloud environments, which does not involve LLM pretraining, fine-tuning, or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20289",
      "abstract": "We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dynamically explore, select, and combine tools from a diverse library based on empirical performance. Existing methods for tool-augmented reasoning either rely on training-free prompting or large-scale fine-tuning; both lack active tool exploration and typically assume limited tool diversity, and fine-tuning methods additionally demand extensive human supervision. In contrast, VisTA leverages end-to-end reinforcement learning to iteratively refine sophisticated, query-specific tool selection strategies, using task outcomes as feedback signals. Through Group Relative Policy Optimization (GRPO), our framework enables an agent to autonomously discover effective tool-selection pathways without requiring explicit reasoning supervision. Experiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate that VisTA achieves substantial performance gains over training-free baselines, especially on out-of-distribution examples. These results highlight VisTA's ability to enhance generalization, adaptively utilize diverse tools, and pave the way for flexible, experience-driven visual reasoning systems.",
      "authors": [
        "Zeyi Huang",
        "Yuyang Ji",
        "Anirudh Sundara Rajan",
        "Zefan Cai",
        "Wen Xiao",
        "Haohan Wang",
        "Junjie Hu",
        "Yong Jae Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T17:59:17+00:00",
          "link": "https://arxiv.org/abs/2505.20289v1",
          "size": "1318kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T05:24:59+00:00",
          "link": "https://arxiv.org/abs/2505.20289v2",
          "size": "1318kb",
          "version": "v2"
        }
      ],
      "title": "VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20289",
        "HTML": "https://arxiv.org/html/2505.20289",
        "PDF": "https://arxiv.org/pdf/2505.20289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a reinforcement learning framework for visual tool selection. Its focus is on tool exploration and selection strategies, not on LLM training data processing or dataset operations."
      },
      "tasks": [
        "Diversity",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14386",
      "abstract": "We propose a neural network model, which, with appropriate assignment of the stability of its equilibrium points (EPs), achieves Hopfield-like associative memory. The oscillator Ising machine (OIM) is an ideal candidates for such a model, as all its $0/\\pi$ binary EPs are structurally stable with their dynamic stability tunable by the coupling weights. Traditional Hopfield-based models store the desired patterns by designing the coupling weights between neurons. The design of coupling weights should simultaneously take into account both the existence and the dynamic stability of the EPs for the storage of the desired patterns. For OIMs, since all $0/\\pi$ binary EPs are structurally stable, the design of the coupling weights needs only to focus on assigning appropriate stability for the $0/\\pi$ binary EPs according to the desired patterns. In this paper, we establish a connection between the stability and the Hamiltonian energy of EPs for OIMs, and, based on this connection, provide a Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the coupling weights of OIMs for assigning appropriate stability to their EPs. Finally, numerical experiments are performed to validate the effectiveness of the proposed method.",
      "authors": [
        "Yi Cheng and Zongli Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T22:23:05+00:00",
          "link": "https://arxiv.org/abs/2507.14386v1",
          "size": "5101kb",
          "version": "v1"
        }
      ],
      "title": "Training oscillator Ising machines to assign the dynamic stability of their equilibrium points",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14386",
        "HTML": "https://arxiv.org/html/2507.14386",
        "PDF": "https://arxiv.org/pdf/2507.14386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model related to neural networks and stability of equilibrium points, not specifically addressing data processing for LLM training such as data engineering or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14668",
      "abstract": "Deep learning models have been widely adopted for False Data Injection Attack (FDIA) detection in smart grids due to their ability to capture unstructured and sparse features. However, the increasing system scale and data dimensionality introduce significant computational and memory burdens, particularly in large-scale industrial datasets, limiting detection efficiency. To address these issues, this paper proposes Rec-AD, a computationally efficient framework that integrates Tensor Train decomposition with the Deep Learning Recommendation Model (DLRM). Rec-AD enhances training and inference efficiency through embedding compression, optimized data access via index reordering, and a pipeline training mechanism that reduces memory communication overhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing FDIA detection systems without code modifications. Experimental results show that Rec-AD significantly improves computational throughput and real-time detection performance, narrowing the attack window and increasing attacker cost. These advancements strengthen edge computing capabilities and scalability, providing robust technical support for smart grid security.",
      "authors": [
        "Yunfeng Li",
        "Junhong Liu",
        "Zhaohui Yang",
        "Guofu Liao",
        "Chuyun Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:38:56+00:00",
          "link": "https://arxiv.org/abs/2507.14668v1",
          "size": "2650kb",
          "version": "v1"
        }
      ],
      "title": "Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14668",
        "HTML": "https://arxiv.org/html/2507.14668",
        "PDF": "https://arxiv.org/pdf/2507.14668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing computational efficiency for FDIA detection in smart grids and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14693",
      "abstract": "Suicidal ideation detection is critical for real-time suicide prevention, yet its progress faces two under-explored challenges: limited language coverage and unreliable annotation practices. Most available datasets are in English, but even among these, high-quality, human-annotated data remains scarce. As a result, many studies rely on available pre-labeled datasets without examining their annotation process or label reliability. The lack of datasets in other languages further limits the global realization of suicide prevention via artificial intelligence (AI). In this study, we address one of these gaps by constructing a novel Turkish suicidal ideation corpus derived from social media posts and introducing a resource-efficient annotation framework involving three human annotators and two large language models (LLMs). We then address the remaining gaps by performing a bidirectional evaluation of label reliability and model consistency across this dataset and three popular English suicidal ideation detection datasets, using transfer learning through eight pre-trained sentiment and emotion classifiers. These transformers help assess annotation consistency and benchmark model performance against manually labeled data. Our findings underscore the need for more rigorous, language-inclusive approaches to annotation and evaluation in mental health natural language processing (NLP) while demonstrating the questionable performance of popular models with zero-shot transfer learning. We advocate for transparency in model training and dataset construction in mental health NLP, prioritizing data and model reliability.",
      "authors": [
        "Amina Dzafic",
        "Merve Kavut",
        "Ulya Bayram"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T16:54:36+00:00",
          "link": "https://arxiv.org/abs/2507.14693v1",
          "size": "7729kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14693",
        "HTML": "https://arxiv.org/html/2507.14693",
        "PDF": "https://arxiv.org/pdf/2507.14693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves constructing a Turkish dataset and discussing annotation frameworks, which touches on data processing but mainly focuses on improving model evaluation and annotation practices within mental health NLP, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14847",
      "abstract": "Electronic Health Records (EHR) contain valuable clinical information for predicting patient outcomes and guiding healthcare decisions. However, effectively modeling Electronic Health Records (EHRs) requires addressing data heterogeneity and complex temporal patterns. Standard approaches often struggle with irregular time intervals between clinical events. We propose TALE-EHR, a Transformer-based framework featuring a novel time-aware attention mechanism that explicitly models continuous temporal gaps to capture fine-grained sequence dynamics. To complement this temporal modeling with robust semantics, TALE-EHR leverages embeddings derived from standardized code descriptions using a pre-trained Large Language Model (LLM), providing a strong foundation for understanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset demonstrate that our approach outperforms state-of-the-art baselines on tasks such as disease progression forecasting. TALE-EHR underscores the benefit of integrating explicit, continuous temporal modeling with strong semantic representations provides a powerful solution for advancing EHR analysis.",
      "authors": [
        "Junhan Yu",
        "Zhunyi Feng",
        "Junwei Lu",
        "Tianxi Cai",
        "Doudou Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T07:32:41+00:00",
          "link": "https://arxiv.org/abs/2507.14847v1",
          "size": "5679kb",
          "version": "v1"
        }
      ],
      "title": "Time-Aware Attention for Enhanced Electronic Health Records Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14847",
        "HTML": "https://arxiv.org/html/2507.14847",
        "PDF": "https://arxiv.org/pdf/2507.14847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a time-aware attention mechanism for EHR modeling, leveraging LLM-derived embeddings. It does not contribute to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14939",
      "abstract": "The Kolmogorov-Petrovsky-Piskunov (Fisher-KPP) equation is a classical reaction-diffusion equation with broad applications such as biology, chemistry and physics. In this paper, an alternative second-order scheme is proposed by employing a shifted BDF2 method to approximate the two-dimensional (modified) Fisher-KPP equation. We both consider an uniform and a nonuniform time steps of such the scheme. The stability of the uniform discretization scheme is proved. Numerical experiments demonstrate that our uniform and non-uniform schemes are robust and accurate.",
      "authors": [
        "Lei Ge",
        "Yong-Liang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T12:23:35+00:00",
          "link": "https://arxiv.org/abs/2507.14939v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "A second-order generalized BDF method for the two-dimensional (modified) Fisher-Kolmogorov-Petrovsky-Piskunov equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14939",
        "HTML": "https://arxiv.org/html/2507.14939",
        "PDF": "https://arxiv.org/pdf/2507.14939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses numerical methods for solving a modified reaction-diffusion equation, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15642",
      "abstract": "Hypoxia-activated prodrugs offer a promising strategy for targeting oxygen-deficient regions in solid tumors, which are often resistant to conventional therapies. However, modeling their behavior is challenging because of the complex interplay between oxygen availability, drug activation, and cell survival. In this work, we develop a multiscale and mixed-dimensional model that couples spatially resolved drug and oxygen transport with pharmacokinetics and pharmacodynamics to simulate the cellular response. The model integrates blood flow, oxygen diffusion and consumption, drug delivery, and metabolism. To reduce computational cost, we mitigate the global nonlinearity through a one-way coupling of the multiscale and mixed/dimensional models with a reduced 0D model for the drug metabolism. The global sensitivity analysis is then used to identify key parameters influencing drug activation and therapeutic outcome. This approach enables efficient simulation and supports the design of optimized hypoxia-targeted therapies.",
      "authors": [
        "Alessandro Coclite",
        "Riccardo Montanelli Eccher",
        "Luca Possenti",
        "Piermario Vitullo",
        "Paolo Zunino"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T14:03:49+00:00",
          "link": "https://arxiv.org/abs/2507.15642v1",
          "size": "2553kb",
          "version": "v1"
        }
      ],
      "title": "Mathematical modeling and sensitivity analysis of hypoxia-activated drugs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15642",
        "PDF": "https://arxiv.org/pdf/2507.15642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on modeling and sensitivity analysis of hypoxia-activated drugs in the medical field, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15778",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective post-training method for improving the reasoning abilities of Large Language Models (LLMs), mainly by shaping higher-order behaviors such as reflection and planning. However, previous RLVR algorithms often apply uniform training signals to all tokens, without considering the different roles of low-entropy knowledge-related tokens and high-entropy reasoning-related tokens. Some recent methods try to separate these token types by gradient masking or asynchronous updates, but these approaches may break semantic dependencies in the model output and hinder effective learning. In this work, we propose Archer, an entropy-aware RLVR approach with dual-token constraints and synchronous updates. Specifically, our method applies weaker KL regularization and higher clipping thresholds to reasoning tokens to encourage exploration, while using stronger constraints on knowledge tokens to maintain factual knowledge. Experimental results on several mathematical reasoning and code generation benchmarks show that our approach significantly outperforms previous RLVR methods, reaching or exceeding state-of-the-art performance among models of comparable size. The code is available at https://github.com/wizard-III/ArcherCodeR.",
      "authors": [
        "Jiakang Wang",
        "Runze Liu",
        "Fuzheng Zhang",
        "Xiu Li",
        "Guorui Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:34:01+00:00",
          "link": "https://arxiv.org/abs/2507.15778v1",
          "size": "1467kb",
          "version": "v1"
        }
      ],
      "title": "Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15778",
        "HTML": "https://arxiv.org/html/2507.15778",
        "PDF": "https://arxiv.org/pdf/2507.15778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus of the paper is on RLVR and improving reasoning in LLMs, it does involve post-training modifications which could indirectly affect data usage efficiency. However, it does not make a direct contribution to data processing operations such as collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23516",
      "abstract": "Federated learning (FL) often suffers from performance degradation due to key challenges such as data heterogeneity and communication constraints. To address these limitations, we present a novel FL framework called FedWSQ, which integrates weight standardization (WS) and the proposed distribution-aware non-uniform quantization (DANUQ). WS enhances FL performance by filtering out biased components in local updates during training, thereby improving the robustness of the model against data heterogeneity and unstable client participation. In addition, DANUQ minimizes quantization errors by leveraging the statistical properties of local model updates. As a result, FedWSQ significantly reduces communication overhead while maintaining superior model accuracy. Extensive experiments on FL benchmark datasets demonstrate that FedWSQ consistently outperforms existing FL methods across various challenging FL settings, including extreme data heterogeneity and ultra-low-bit communication scenarios.",
      "authors": [
        "Seung-Wook Kim",
        "Seongyeol Kim",
        "Jiah Kim",
        "Seowon Ji",
        "Se-Ho Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:46:25+00:00",
          "link": "https://arxiv.org/abs/2506.23516v1",
          "size": "1575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T07:23:25+00:00",
          "link": "https://arxiv.org/abs/2506.23516v2",
          "size": "1576kb",
          "version": "v2"
        }
      ],
      "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23516",
        "HTML": "https://arxiv.org/html/2506.23516",
        "PDF": "https://arxiv.org/pdf/2506.23516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on federated learning with weight standardization and quantization techniques, which do not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11683",
      "abstract": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for modeling spatial and temporal data dependencies. However, their applications have been limited primarily to small-scale datasets because of memory constraints. While distributed training offers a solution, current frameworks lack support for spatiotemporal models and overlook the properties of spatiotemporal data. Informed by a scaling study on a large-scale workload, we present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch Geometric Temporal that integrates distributed data parallel training and two novel strategies: index-batching and distributed-index-batching. Our index techniques exploit spatiotemporal structure to construct snapshots dynamically at runtime, significantly reducing memory overhead, while distributed-index-batching extends this approach by enabling scalable processing across multiple GPUs. Our techniques enable the first-ever training of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing peak memory usage by up to 89% and achieving up to a 11.78x speedup over standard DDP with 128 GPUs.",
      "authors": [
        "Seth Ockerman",
        "Amal Gueroudji",
        "Tanwi Mallick",
        "Yixuan He",
        "Line Pouchard",
        "Robert Ross",
        "Shivaram Venkataraman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:38:16+00:00",
          "link": "https://arxiv.org/abs/2507.11683v1",
          "size": "333kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:40:27+00:00",
          "link": "https://arxiv.org/abs/2507.11683v2",
          "size": "323kb",
          "version": "v2"
        }
      ],
      "title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11683",
        "HTML": "https://arxiv.org/html/2507.11683",
        "PDF": "https://arxiv.org/pdf/2507.11683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves graph neural networks and their training efficiency through distributed computing techniques. It does not concern LLM training data processing, making it irrelevant to the task objective."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14222",
      "abstract": "The Interpretable Generalization (IG) mechanism recently published in IEEE Transactions on Information Forensics and Security delivers state-of-the-art, evidence-based intrusion detection by discovering coherent normal and attack patterns through exhaustive intersect-and-subset operations-yet its cubic-time complexity and large intermediate bitsets render full-scale datasets impractical on CPUs. We present IG-GPU, a PyTorch re-architecture that offloads all pairwise intersections and subset evaluations to commodity GPUs. Implemented on a single NVIDIA RTX 4070 Ti, in the 15k-record NSL-KDD dataset, IG-GPU shows a 116-fold speed-up over the multi-core CPU implementation of IG. In the full size of NSL-KDD (148k-record), given small training data (e.g., 10%-90% train-test split), IG-GPU runs in 18 minutes with Recall 0.957, Precision 0.973, and AUC 0.961, whereas IG required down-sampling to 15k-records to avoid memory exhaustion and obtained Recall 0.935, Precision 0.942, and AUC 0.940. The results confirm that IG-GPU is robust across scales and could provide millisecond-level per-flow inference once patterns are learned. IG-GPU thus bridges the gap between rigorous interpretability and real-time cyber-defense, offering a portable foundation for future work on hardware-aware scheduling, multi-GPU sharding, and dataset-specific sparsity optimizations.",
      "authors": [
        "Shu-Ting Huang",
        "Wen-Cheng Chung",
        "Hao-Ting Pai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T12:38:19+00:00",
          "link": "https://arxiv.org/abs/2507.14222v1",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "title": "GPU-Accelerated Interpretable Generalization for Rapid Cyberattack Detection and Forensics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14222",
        "HTML": "https://arxiv.org/html/2507.14222",
        "PDF": "https://arxiv.org/pdf/2507.14222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a GPU-accelerated mechanism for cyberattack detection, which does not relate to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14731",
      "abstract": "Existing navigation methods are primarily designed for specific robot embodiments, limiting their generalizability across diverse robot platforms. In this paper, we introduce X-Nav, a novel framework for end-to-end cross-embodiment navigation where a single unified policy can be deployed across various embodiments for both wheeled and quadrupedal robots. X-Nav consists of two learning stages: 1) multiple expert policies are trained using deep reinforcement learning with privileged observations on a wide range of randomly generated robot embodiments; and 2) a single general policy is distilled from the expert policies via navigation action chunking with transformer (Nav-ACT). The general policy directly maps visual and proprioceptive observations to low-level control commands, enabling generalization to novel robot embodiments. Simulated experiments demonstrated that X-Nav achieved zero-shot transfer to both unseen embodiments and photorealistic environments. A scalability study showed that the performance of X-Nav improves when trained with an increasing number of randomly generated embodiments. An ablation study confirmed the design choices of X-Nav. Furthermore, real-world experiments were conducted to validate the generalizability of X-Nav in real-world environments.",
      "authors": [
        "Haitong Wang",
        "Aaron Hao Tan",
        "Angus Fung",
        "Goldie Nejat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T19:40:53+00:00",
          "link": "https://arxiv.org/abs/2507.14731v1",
          "size": "8401kb",
          "version": "v1"
        }
      ],
      "title": "X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14731",
        "PDF": "https://arxiv.org/pdf/2507.14731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a navigation framework for robots, involving cross-embodiment learning rather than any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14790",
      "abstract": "In convolutional neural networks (CNNs), downsampling operations are crucial to model performance. Although traditional downsampling methods (such as maximum pooling and cross-row convolution) perform well in feature aggregation, receptive field expansion, and computational reduction, they may lead to the loss of key spatial information in semantic segmentation tasks, thereby affecting the pixel-by-pixel prediction accuracy.To this end, this study proposes a downsampling method based on information complementarity - Hybrid Pooling Downsampling (HPD). The core is to replace the traditional method with MinMaxPooling, and effectively retain the light and dark contrast and detail features of the image by extracting the maximum value information of the local area.Experiment on various CNN architectures on the ACDC and Synapse datasets show that HPD outperforms traditional methods in segmentation performance, and increases the DSC coefficient by 0.5% on average. The results show that the HPD module provides an efficient solution for semantic segmentation tasks.",
      "authors": [
        "Wenbo Yue",
        "Chang Li",
        "Guoping Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T02:30:34+00:00",
          "link": "https://arxiv.org/abs/2507.14790v1",
          "size": "609kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14790",
        "PDF": "https://arxiv.org/pdf/2507.14790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel downsampling strategy for medical image segmentation in CNNs, which is unrelated to LLM training data processing, focusing instead on improving CNN performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15294",
      "abstract": "Audio-visual Target Speaker Extraction (AV-TSE) aims to isolate a target speaker's voice from multi-speaker environments by leveraging visual cues as guidance. However, the performance of AV-TSE systems heavily relies on the quality of these visual cues. In extreme scenarios where visual cues are missing or severely degraded, the system may fail to accurately extract the target speaker. In contrast, humans can maintain attention on a target speaker even in the absence of explicit auxiliary information. Motivated by such human cognitive ability, we propose a novel framework called MeMo, which incorporates two adaptive memory banks to store attention-related information. MeMo is specifically designed for real-time scenarios: once initial attention is established, the system maintains attentional momentum over time, even when visual cues become unavailable. We conduct comprehensive experiments to verify the effectiveness of MeMo. Experimental results demonstrate that our proposed framework achieves SI-SNR improvements of at least 2 dB over the corresponding baseline.",
      "authors": [
        "Junjie Li",
        "Wenxuan Wu",
        "Shuai Wang",
        "Zexu Pan",
        "Kong Aik Lee",
        "Helen Meng",
        "Haizhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:49:12+00:00",
          "link": "https://arxiv.org/abs/2507.15294v1",
          "size": "926kb",
          "version": "v1"
        }
      ],
      "title": "MeMo: Attentional Momentum for Real-time Audio-visual Speaker Extraction under Impaired Visual Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15294",
        "HTML": "https://arxiv.org/html/2507.15294",
        "PDF": "https://arxiv.org/pdf/2507.15294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on audio-visual speaker extraction using memory mechanisms, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15396",
      "abstract": "Hearing loss simulation models are essential for hearing aid deployment. However, existing models have high computational complexity and latency, which limits real-time applications and lack direct integration with speech processing systems. To address these issues, we propose Neuro-MSBG, a lightweight end-to-end model with a personalized audiogram encoder for effective time-frequency modeling. Experiments show that Neuro-MSBG supports parallel inference and retains the intelligibility and perceptual quality of the original MSBG, with a Spearman's rank correlation coefficient (SRCC) of 0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for Perceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation runtime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second input), further demonstrating its efficiency and practicality.",
      "authors": [
        "Hui-Guan Yuan",
        "Ryandhimas E. Zezario",
        "Shafique Ahmed",
        "Hsin-Min Wang",
        "Kai-Lung Hua",
        "Yu Tsao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:58:31+00:00",
          "link": "https://arxiv.org/abs/2507.15396v1",
          "size": "2139kb",
          "version": "v1"
        }
      ],
      "title": "Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15396",
        "HTML": "https://arxiv.org/html/2507.15396",
        "PDF": "https://arxiv.org/pdf/2507.15396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a neural model for simulating hearing loss, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15454",
      "abstract": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and real-time novel view synthesis, yet its lack of semantic understanding limits object-level perception. In this work, we propose ObjectGS, an object-aware framework that unifies 3D scene reconstruction with semantic understanding. Instead of treating the scene as a unified whole, ObjectGS models individual objects as local anchors that generate neural Gaussians and share object IDs, enabling precise object-level reconstruction. During training, we dynamically grow or prune these anchors and optimize their features, while a one-hot ID encoding with a classification loss enforces clear semantic constraints. We show through extensive experiments that ObjectGS not only outperforms state-of-the-art methods on open-vocabulary and panoptic segmentation tasks, but also integrates seamlessly with applications like mesh extraction and scene editing. Project page: https://ruijiezhu94.github.io/ObjectGS_page",
      "authors": [
        "Ruijie Zhu",
        "Mulin Yu",
        "Linning Xu",
        "Lihan Jiang",
        "Yixuan Li",
        "Tianzhu Zhang",
        "Jiangmiao Pang",
        "Bo Dai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T10:06:23+00:00",
          "link": "https://arxiv.org/abs/2507.15454v1",
          "size": "45484kb",
          "version": "v1"
        }
      ],
      "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15454",
        "HTML": "https://arxiv.org/html/2507.15454",
        "PDF": "https://arxiv.org/pdf/2507.15454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with 3D scene reconstruction and semantic understanding, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.03262",
      "abstract": "Visual anomaly detection aims to identify anomalous regions in images through unsupervised learning paradigms, with increasing application demand and value in fields such as industrial inspection and medical lesion detection. Despite significant progress in recent years, there is a lack of comprehensive benchmarks to adequately evaluate the performance of various mainstream methods across different datasets under the practical multi-class setting. The absence of standardized experimental setups can lead to potential biases in training epochs, resolution, and metric results, resulting in erroneous conclusions. This paper addresses this issue by proposing a comprehensive visual anomaly detection benchmark, ADer, which is a modular framework that is highly extensible for new methods. The benchmark includes multiple datasets from industrial and medical domains, implementing fifteen state-of-the-art methods and nine comprehensive metrics. Additionally, we have proposed the GPU-assisted ADEval package to address the slow evaluation problem of metrics like time-consuming mAU-PRO on large-scale data, significantly reducing evaluation time by more than 1000-fold. Through extensive experimental results, we objectively reveal the strengths and weaknesses of different methods and provide insights into the challenges and future directions of multi-class visual anomaly detection. We hope that ADer will become a valuable resource for researchers and practitioners in the field, promoting the development of more robust and generalizable anomaly detection systems. Full codes are open-sourced at https://github.com/zhangzjn/ader.",
      "authors": [
        "Jiangning Zhang",
        "Haoyang He",
        "Zhenye Gan",
        "Qingdong He",
        "Yuxuan Cai",
        "Zhucun Xue",
        "Yabiao Wang",
        "Chengjie Wang",
        "Lei Xie",
        "Yong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-05T13:40:07+00:00",
          "link": "https://arxiv.org/abs/2406.03262v1",
          "size": "1214kb",
          "version": "v1"
        },
        {
          "date": "2024-06-06T07:20:10+00:00",
          "link": "https://arxiv.org/abs/2406.03262v2",
          "size": "1208kb",
          "version": "v2"
        },
        {
          "date": "2024-09-30T13:19:43+00:00",
          "link": "https://arxiv.org/abs/2406.03262v3",
          "size": "7208kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T06:17:54+00:00",
          "link": "https://arxiv.org/abs/2406.03262v4",
          "size": "7078kb",
          "version": "v4"
        },
        {
          "date": "2025-07-20T10:32:09+00:00",
          "link": "https://arxiv.org/abs/2406.03262v5",
          "size": "1010kb",
          "version": "v5"
        }
      ],
      "title": "A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03262",
        "HTML": "https://arxiv.org/html/2406.03262",
        "PDF": "https://arxiv.org/pdf/2406.03262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a benchmarking library for visual anomaly detection methods. It addresses evaluation and benchmarking of visual data methods, without contributing to LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection",
        "Benchmarking",
        "Lesion Detection",
        "Multi-class Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/zhangzjn/ader"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.06013",
      "abstract": "By the seminal paper of Claude Shannon \\cite{Shannon48}, the computation of the capacity of a discrete memoryless channel has been considered as one of the most important and fundamental problems in Information Theory. Nearly 50 years ago, Arimoto and Blahut independently proposed identical algorithms to solve this problem in their seminal papers \\cite{Arimoto1972AnAF, Blahut1972ComputationOC}. The Arimoto-Blahut algorithm was proven to converge to the capacity of the channel as $t \\to \\infty$, with a convergence rate upper bounded by $O\\left(\\log(m)/t\\right)$, where $m$ is the size of the input distribution. Under the assumption that a unique optimal solution is in the interior of the input probability simplex, the convergence becomes inverse exponential after an iteration $t^0$ \\cite{Arimoto1972AnAF}. More recently, it was demonstrated in \\cite{Nakagawa2020AnalysisOT} that in certain specific cases, the convergence rate is at worst case inverse linear. In this paper, we revisit this fundamental algorithm analyzing its rate of convergence focusing on the approximation of the capacity. Our main result shows that the convergence rate to an $\\varepsilon$-optimal solution, for any sufficiently small constant $\\varepsilon > 0$, is inverse exponential $O\\left(\\log(m)/c^t\\right)$, for some constant $c > 1$. Given this, we derive new and complementary results for the computation of capacity, particularly in cases where an exact solution is sought.",
      "authors": [
        "Michail Fasoulakis",
        "Konstantinos Varsos",
        "and Apostolos Traganitis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T15:05:53+00:00",
          "link": "https://arxiv.org/abs/2407.06013v1",
          "size": "314kb",
          "version": "v1"
        },
        {
          "date": "2024-08-28T08:27:11+00:00",
          "link": "https://arxiv.org/abs/2407.06013v2",
          "size": "314kb",
          "version": "v2"
        },
        {
          "date": "2024-09-11T07:06:54+00:00",
          "link": "https://arxiv.org/abs/2407.06013v3",
          "size": "314kb",
          "version": "v3"
        },
        {
          "date": "2025-04-24T15:43:26+00:00",
          "link": "https://arxiv.org/abs/2407.06013v4",
          "size": "315kb",
          "version": "v4"
        },
        {
          "date": "2025-05-04T13:47:03+00:00",
          "link": "https://arxiv.org/abs/2407.06013v5",
          "size": "315kb",
          "version": "v5"
        },
        {
          "date": "2025-07-20T19:13:20+00:00",
          "link": "https://arxiv.org/abs/2407.06013v6",
          "size": "317kb",
          "version": "v6"
        }
      ],
      "title": "Revisit the Arimoto-Blahut algorithm: New Analysis with Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06013",
        "HTML": "https://arxiv.org/html/2407.06013",
        "PDF": "https://arxiv.org/pdf/2407.06013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the convergence analysis of the Arimoto-Blahut algorithm in Information Theory, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.04777",
      "abstract": "Community structure is a key feature omnipresent in real-world network data. Plethora of methods have been proposed to reveal subsets of densely interconnected nodes using criteria such as the modularity index. These approaches have been successful for undirected graphs, but directed edge information has not yet been dealt with in a satisfactory way. Here, we revisit the concept of directed communities as a mapping between sending and receiving communities. This translates into a new definition that we term bimodularity. Using convex relaxation, bimodularity can be optimized with the singular value decomposition of the directed modularity matrix. Subsequently, we propose an edge-based clustering approach to reveal the directed communities including their mappings. The feasibility of the new framework is illustrated on a synthetic model and further applied to the neuronal wiring diagram of the \\textit{C. elegans}, for which it yields meaningful feedforward loops of the head and body motion systems. This framework sets the ground for the understanding and detection of community structures in directed networks.",
      "authors": [
        "Alexandre Cionca",
        "Chun Hei Michael Chan",
        "Dimitri Van De Ville"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T09:28:13+00:00",
          "link": "https://arxiv.org/abs/2502.04777v1",
          "size": "9827kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:51:40+00:00",
          "link": "https://arxiv.org/abs/2502.04777v2",
          "size": "5223kb",
          "version": "v2"
        }
      ],
      "title": "Community detection for directed networks revisited using bimodularity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04777",
        "HTML": "https://arxiv.org/html/2502.04777",
        "PDF": "https://arxiv.org/pdf/2502.04777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses bimodularity for community detection in directed networks, focusing on network data rather than LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/miplabch/bimodularity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17814",
      "abstract": "People's daily lives involve numerous periodic behaviors, such as eating and traveling. Local-life platforms cater to these recurring needs by providing essential services tied to daily routines. Therefore, users' periodic intentions are reflected in their interactions with the platforms. There are two main challenges in modeling users' periodic behaviors in the local-life service recommendation systems: 1) the diverse demands of users exhibit varying periodicities, which are difficult to distinguish as they are mixed in the behavior sequences; 2) the periodic behaviors of users are subject to dynamic changes due to factors such as holidays and promotional events. Existing methods struggle to distinguish the periodicities of diverse demands and overlook the importance of dynamically capturing changes in users' periodic behaviors. To this end, we employ a Frequency-Aware Multi-View Interest Modeling framework (FIM). Specifically, we propose a multi-view search strategy that decomposes users' demands from different perspectives to separate their various periodic intentions. This allows the model to comprehensively extract their periodic features than category-searched-only methods. Moreover, we propose a frequency-domain perception and evolution module. This module uses the Fourier Transform to convert users' temporal behaviors into the frequency domain, enabling the model to dynamically perceive their periodic features. Extensive offline experiments demonstrate that FIM achieves significant improvements on public and industrial datasets, showing its capability to effectively model users' periodic intentions. Furthermore, the model has been deployed on the Kuaishou local-life service platform. Through online A/B experiments, the transaction volume has been significantly improved.",
      "authors": [
        "Guoquan Wang",
        "Qiang Luo",
        "Weisong Hu",
        "Pengfei Yao",
        "Wencong Zeng",
        "Guorui Zhou",
        "and Kun Gai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T02:05:31+00:00",
          "link": "https://arxiv.org/abs/2504.17814v1",
          "size": "2260kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T07:51:20+00:00",
          "link": "https://arxiv.org/abs/2504.17814v2",
          "size": "2260kb",
          "version": "v2"
        },
        {
          "date": "2025-07-20T12:15:35+00:00",
          "link": "https://arxiv.org/abs/2504.17814v3",
          "size": "1250kb",
          "version": "v3"
        }
      ],
      "title": "FIM: Frequency-Aware Multi-View Interest Modeling for Local-Life Service Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17814",
        "HTML": "https://arxiv.org/html/2504.17814",
        "PDF": "https://arxiv.org/pdf/2504.17814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on recommendation systems via multi-view interest modeling, not on LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14218",
      "abstract": "Artificial intelligence functions not as an epistemic leveller, but as an accelerant of cognitive stratification, entrenching and formalising informational castes within liberal-democratic societies. Synthesising formal epistemology, political theory, algorithmic architecture, and economic incentive structures, the argument traces how contemporary AI systems selectively amplify the reasoning capacity of individuals equipped with recursive abstraction, symbolic logic, and adversarial interrogation, whilst simultaneously pacifying the cognitively untrained through engagement-optimised interfaces. Fluency replaces rigour, immediacy displaces reflection, and procedural reasoning is eclipsed by reactive suggestion. The result is a technocratic realignment of power: no longer grounded in material capital alone, but in the capacity to navigate, deconstruct, and manipulate systems of epistemic production. Information ceases to be a commons; it becomes the substrate through which consent is manufactured and autonomy subdued. Deliberative democracy collapses not through censorship, but through the erosion of interpretive agency. The proposed response is not technocratic regulation, nor universal access, but the reconstruction of rational autonomy as a civic mandate, codified in education, protected by epistemic rights, and structurally embedded within open cognitive infrastructure.",
      "authors": [
        "Craig S Wright"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:46:45+00:00",
          "link": "https://arxiv.org/abs/2507.14218v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Cognitive Castes: Artificial Intelligence, Epistemic Stratification, and the Dissolution of Democratic Discourse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14218",
        "HTML": "https://arxiv.org/html/2507.14218",
        "PDF": "https://arxiv.org/pdf/2507.14218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the societal impact of AI on democratic discourse and epistemic stratification, without addressing LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15119",
      "abstract": "Time series forecasting (TSF) is a central problem in time series analysis. However, as the number of channels in time series datasets scales to the thousands or more, a scenario we define as High-Dimensional Time Series Forecasting (HDTSF), it introduces significant new modeling challenges that are often not the primary focus of traditional TSF research. HDTSF is challenging because the channel correlation often forms complex and hierarchical patterns. Existing TSF models either ignore these interactions or fail to scale as dimensionality grows. To address this issue, we propose U-Cast, a channel-dependent forecasting architecture that learns latent hierarchical channel structures with an innovative query-based attention. To disentangle highly correlated channel representation, U-Cast adds a full-rank regularization during training. We also release Time-HD, a benchmark of large, diverse, high-dimensional datasets. Our theory shows that exploiting cross-channel information lowers forecasting risk, and experiments on Time-HD demonstrate that U-Cast surpasses strong baselines in both accuracy and efficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF research.",
      "authors": [
        "Juntong Ni",
        "Shiyu Wang",
        "Zewen Liu",
        "Xiaoming Shi",
        "Xinyue Zhong",
        "Zhou Ye",
        "Wei Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T20:47:32+00:00",
          "link": "https://arxiv.org/abs/2507.15119v1",
          "size": "3560kb",
          "version": "v1"
        }
      ],
      "title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15119",
        "HTML": "https://arxiv.org/html/2507.15119",
        "PDF": "https://arxiv.org/pdf/2507.15119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses time series forecasting and introduces the U-Cast architecture and Time-HD dataset for this purpose. It does not pertain to LLM training data processing as it focuses on time series data rather than language model data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15347",
      "abstract": "This work explores entropy analysis as a tool for probing information distribution within Transformer-based architectures. By quantifying token-level uncertainty and examining entropy patterns across different stages of processing, we aim to investigate how information is managed and transformed within these models. As a case study, we apply the methodology to a GPT-based large language model, illustrating its potential to reveal insights into model behavior and internal representations. This approach may offer insights into model behavior and contribute to the development of interpretability and evaluation frameworks for transformer-based models",
      "authors": [
        "Amedeo Buonanno",
        "Alessandro Rivetti",
        "Francesco A. N. Palmieri",
        "Giovanni Di Gennaro",
        "Gianmarco Romano"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:01:22+00:00",
          "link": "https://arxiv.org/abs/2507.15347v1",
          "size": "1681kb",
          "version": "v1"
        }
      ],
      "title": "Probing Information Distribution in Transformer Architectures through Entropy Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15347",
        "HTML": "https://arxiv.org/html/2507.15347",
        "PDF": "https://arxiv.org/pdf/2507.15347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper employs entropy analysis to study information distribution within Transformer architectures. It focuses on model behavior and interpretability, and does not involve data processing operations for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14824",
      "abstract": "Foundation models have emerged as a powerful approach for processing electronic health records (EHRs), offering flexibility to handle diverse medical data modalities. In this study, we present a comprehensive benchmark that evaluates the performance, fairness, and interpretability of foundation models, both as unimodal encoders and as multimodal learners, using the publicly available MIMIC-IV database. To support consistent and reproducible evaluation, we developed a standardized data processing pipeline that harmonizes heterogeneous clinical records into an analysis-ready format. We systematically compared eight foundation models, encompassing both unimodal and multimodal models, as well as domain-specific and general-purpose variants. Our findings demonstrate that incorporating multiple data modalities leads to consistent improvements in predictive performance without introducing additional bias. Through this benchmark, we aim to support the development of effective and trustworthy multimodal artificial intelligence (AI) systems for real-world clinical applications. Our code is available at https://github.com/nliulab/MIMIC-Multimodal.",
      "authors": [
        "Kunyu Yu",
        "Rui Yang",
        "Jingchi Liao",
        "Siqi Li",
        "Huitao Li",
        "Irene Li",
        "Yifan Peng",
        "Rishikesan Kamaleswaran",
        "Nan Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T05:08:28+00:00",
          "link": "https://arxiv.org/abs/2507.14824v1",
          "size": "11951kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14824",
        "HTML": "https://arxiv.org/html/2507.14824",
        "PDF": "https://arxiv.org/pdf/2507.14824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates foundation models' performance using multimodal electronic health records from the MIMIC-IV database. It focuses on benchmarking model performance rather than processing training data for LLMs or text data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15267",
      "abstract": "Currently, short video platforms have become the primary place for individuals to share experiences and obtain information. To better meet users' needs for acquiring information while browsing short videos, some apps have introduced a search entry at the bottom of videos, accompanied with recommended relevant queries. This scenario is known as query recommendation in video-related search, where core task is item-to-query (I2Q) recommendation. As this scenario has only emerged in recent years, there is a notable scarcity of academic research and publicly available datasets in this domain. To address this gap, we systematically examine the challenges associated with this scenario for the first time. Subsequently, we release a large-scale dataset derived from real-world data pertaining to the query recommendation in video-\\textit{\\textbf{r}}elated \\textit{\\textbf{s}}earch on the \\textit{\\textbf{Kuai}}shou app (\\textbf{KuaiRS}). Presently, existing methods rely on embeddings to calculate similarity for matching short videos with queries, lacking deep interaction between the semantic content and the query. In this paper, we introduce a novel LLM-based framework named \\textbf{GREAT}, which \\textit{\\textbf{g}}uides que\\textit{\\textbf{r}}y g\\textit{\\textbf{e}}ner\\textit{\\textbf{a}}tion with a \\textit{\\textbf{t}}rie to address I2Q recommendation in related search. Specifically, we initially gather high-quality queries with high exposure and click-through rate to construct a query-based trie. During training, we enhance the LLM's capability to generate high-quality queries using the query-based trie. In the inference phase, the query-based trie serves as a guide for the token generation. Finally, we further refine the relevance and literal quality between items and queries via a post-processing module. Extensive offline and online experiments demonstrate the effectiveness of our proposed method.",
      "authors": [
        "Ninglu Shao",
        "Jinshan Wang",
        "Chenxu Wang",
        "Qingbiao Li",
        "Xiaoxue Zang",
        "Han Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:10:30+00:00",
          "link": "https://arxiv.org/abs/2507.15267v1",
          "size": "962kb",
          "version": "v1"
        }
      ],
      "title": "GREAT: Guiding Query Generation with a Trie for Recommending Related Search about Video at Kuaishou",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15267",
        "HTML": "https://arxiv.org/html/2507.15267",
        "PDF": "https://arxiv.org/pdf/2507.15267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework for query recommendation using LLMs and involves creating a dataset for query generation. However, the focus is primarily on improving search recommendations, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15367",
      "abstract": "Reconfigurable intelligent surfaces (RISs) are an emerging technology for improving spectral efficiency and reducing power consumption in future wireless systems. This paper investigates the joint design of the transmit precoding matrices and the RIS phase shift vector in a multi-user RIS-aided multiple-input multiple-output (MIMO) communication system. We formulate a max-min optimization problem to maximize the minimum achievable rate while considering transmit power and reradiation mask constraints. The achievable rate is simplified using the Arimoto-Blahut algorithm, and the problem is broken into quadratic programs with quadratic constraints (QPQC) sub-problems using an alternating optimization approach. To improve efficiency, we develop a model-based neural network optimization that utilizes the one-hot encoding for the angles of incidence and reflection. We address practical RIS limitations by using a greedy search algorithm to solve the optimization problem for discrete phase shifts. Simulation results demonstrate that the proposed methods effectively shape the multi-beam radiation pattern towards desired directions while satisfying reradiation mask constraints. The neural network design reduces the execution time, and the discrete phase shift scheme performs well with a small reduction of the beamforming gain by using only four phase shift levels.",
      "authors": [
        "Shumin Wang",
        "Hajar El Hassani",
        "Marco Di Renzo",
        "and Marios Poulakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T08:18:23+00:00",
          "link": "https://arxiv.org/abs/2507.15367v1",
          "size": "21241kb",
          "version": "v1"
        }
      ],
      "title": "Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15367",
        "PDF": "https://arxiv.org/pdf/2507.15367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study concentrates on the optimization and design of MIMO communication systems with RIS technology, which has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1703.06125",
      "abstract": "Process discovery techniques return process models that are either formal (precisely describing the possible behaviors) or informal (merely a \"picture\" not allowing for any form of formal reasoning). Formal models are able to classify traces (i.e., sequences of events) as fitting or non-fitting. Most process mining approaches described in the literature produce such models. This is in stark contrast with the over 25 available commercial process mining tools that only discover informal process models that remain deliberately vague on the precise set of possible traces. There are two main reasons why vendors resort to such models: scalability and simplicity. In this paper, we propose to combine the best of both worlds: discovering hybrid process models that have formal and informal elements. As a proof of concept we present a discovery technique based on hybrid Petri nets. These models allow for formal reasoning, but also reveal information that cannot be captured in mainstream formal models. A novel discovery algorithm returning hybrid Petri nets has been implemented in ProM and has been applied to several real-life event logs. The results clearly demonstrate the advantages of remaining \"vague\" when there is not enough \"evidence\" in the data or standard modeling constructs do not \"fit\". Moreover, the approach is scalable enough to be incorporated in industrial-strength process mining tools.",
      "authors": [
        "Wil M.P. van der Aalst",
        "Riccardo De Masellis",
        "Chiara Di Francescomarino",
        "Chiara Ghidini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2017-03-17T17:38:30+00:00",
          "link": "https://arxiv.org/abs/1703.06125v1",
          "size": "886kb",
          "version": "v1"
        },
        {
          "date": "2017-03-21T10:49:12+00:00",
          "link": "https://arxiv.org/abs/1703.06125v2",
          "size": "799kb",
          "version": "v2"
        },
        {
          "date": "2017-05-23T23:49:59+00:00",
          "link": "https://arxiv.org/abs/1703.06125v3",
          "size": "2302kb",
          "version": "v3"
        }
      ],
      "title": "Learning Hybrid Process Models From Events: Process Discovery Without Faking Confidence",
      "links": {
        "Abstract": "https://arxiv.org/abs/1703.06125",
        "PDF": "https://arxiv.org/pdf/1703.06125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses process discovery techniques using hybrid process models in the context of event logs, which is not relevant to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12948",
      "abstract": "We investigate the potential of an attention-based neural network architecture, the Senseiver, for sparse sensing in tsunami forecasting. Specifically, we focus on the Tsunami Data Assimilation Method, which generates forecasts from tsunameter networks. Our model is used to reconstruct high-resolution tsunami wavefields from extremely sparse observations, including cases where the tsunami epicenters are not represented in the training set. Furthermore, we demonstrate that our approach significantly outperforms the Linear Interpolation with Huygens-Fresnel Principle in generating dense observation networks, achieving markedly improved accuracy.",
      "authors": [
        "Edward McDugald",
        "Arvind Mohan",
        "Darren Engwirda",
        "Agnese Marcato",
        "and Javier Santos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T00:42:40+00:00",
          "link": "https://arxiv.org/abs/2411.12948v1",
          "size": "7340kb",
          "version": "v1"
        },
        {
          "date": "2024-11-23T18:43:27+00:00",
          "link": "https://arxiv.org/abs/2411.12948v2",
          "size": "7340kb",
          "version": "v2"
        },
        {
          "date": "2025-02-17T01:11:23+00:00",
          "link": "https://arxiv.org/abs/2411.12948v3",
          "size": "3916kb",
          "version": "v3"
        },
        {
          "date": "2025-05-23T06:48:36+00:00",
          "link": "https://arxiv.org/abs/2411.12948v4",
          "size": "22199kb",
          "version": "v4"
        },
        {
          "date": "2025-07-19T19:33:22+00:00",
          "link": "https://arxiv.org/abs/2411.12948v5",
          "size": "22334kb",
          "version": "v5"
        }
      ],
      "title": "Attention-Based Reconstruction of Full-Field Tsunami Waves from Sparse Tsunameter Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12948",
        "HTML": "https://arxiv.org/html/2411.12948",
        "PDF": "https://arxiv.org/pdf/2411.12948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores tsunami wave reconstruction using an attention-based neural network, which does not address any aspect of LLM training data processing or data engineering operations for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03022",
      "abstract": "Prior work on in-context copying has shown the existence of induction heads, which attend to and promote individual tokens during copying. In this work we discover a new type of induction head: concept-level induction heads, which copy entire lexical units instead of individual tokens. Concept induction heads learn to attend to the ends of multi-token words throughout training, working in parallel with token-level induction heads to copy meaningful text. We show that these heads are responsible for semantic tasks like word-level translation, whereas token induction heads are vital for tasks that can only be done verbatim (like copying nonsense tokens). These two \"routes\" operate independently: we show that ablation of token induction heads causes models to paraphrase where they would otherwise copy verbatim. By patching concept induction head outputs, we find that they contain language-independent word representations that mediate natural language translation, suggesting that LLMs represent abstract word meanings independent of language or form.",
      "authors": [
        "Sheridan Feucht",
        "Eric Todd",
        "Byron Wallace",
        "David Bau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T20:40:31+00:00",
          "link": "https://arxiv.org/abs/2504.03022v1",
          "size": "15923kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T18:59:21+00:00",
          "link": "https://arxiv.org/abs/2504.03022v2",
          "size": "17581kb",
          "version": "v2"
        }
      ],
      "title": "The Dual-Route Model of Induction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03022",
        "HTML": "https://arxiv.org/html/2504.03022",
        "PDF": "https://arxiv.org/pdf/2504.03022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores induction heads in LLMs, focusing on copying lexical units and translation tasks, which does not contribute to LLM training data processing."
      },
      "tasks": [
        "In-Context Learning",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00847",
      "abstract": "With the growing penetration of electric trucks, freight transportation is transitioning toward a mixed system comprising both fuel-powered and electric trucks. Enhancing truck platoon formation in such a heterogeneous environment presents new challenges. This paper investigates the hub-based platoon coordination problem in a mixed truck fleet, where the focus is to optimize the trucks' waiting times, charging amounts for electric trucks, and platoon leader assignments. The objective is to maximize the overall platoon revenue of the fleet while accounting for the associated waiting and charging costs. We formulate the problem as a mixed-integer linear program and present a dynamic programming approach to compute its sub-optimal solution efficiently. The proposed method operates in polynomial time, ensuring scalable computational efficiency. Simulation studies involving 1,000 trucks traveling between two hubs in Sweden demonstrate the effectiveness and scalability of the proposed approach.",
      "authors": [
        "Ying Wang",
        "Ting Bai",
        "Andreas A. Malikopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T20:18:07+00:00",
          "link": "https://arxiv.org/abs/2505.00847v1",
          "size": "1924kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T09:06:32+00:00",
          "link": "https://arxiv.org/abs/2505.00847v2",
          "size": "1636kb",
          "version": "v2"
        }
      ],
      "title": "Platoon Coordination and Leader Selection in Mixed Transportation Systems via Dynamic Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00847",
        "HTML": "https://arxiv.org/html/2505.00847",
        "PDF": "https://arxiv.org/pdf/2505.00847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing truck platoon coordination in transportation systems, which does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.03233",
      "abstract": "Embodied foundation models are gaining increasing attention for their zero-shot generalization, scalability, and adaptability to new tasks through few-shot post-training. However, existing models rely heavily on real-world data, which is costly and labor-intensive to collect. Synthetic data offers a cost-effective alternative, yet its potential remains largely underexplored. To bridge this gap, we explore the feasibility of training Vision-Language-Action models entirely with large-scale synthetic action data. We curate SynGrasp-1B, a billion-frame robotic grasping dataset generated in simulation with photorealistic rendering and extensive domain randomization. Building on this, we present GraspVLA, a VLA model pretrained on large-scale synthetic action data as a foundational model for grasping tasks. GraspVLA integrates autoregressive perception tasks and flow-matching-based action generation into a unified Chain-of-Thought process, enabling joint training on synthetic action data and Internet semantics data. This design helps mitigate sim-to-real gaps and facilitates the transfer of learned actions to a broader range of Internet-covered objects, achieving open-vocabulary generalization in grasping. Extensive evaluations across real-world and simulation benchmarks demonstrate GraspVLA's advanced zero-shot generalizability and few-shot adaptability to specific human preferences. We will release SynGrasp-1B dataset and pre-trained weights to benefit the community.",
      "authors": [
        "Shengliang Deng",
        "Mi Yan",
        "Songlin Wei",
        "Haixin Ma",
        "Yuxin Yang",
        "Jiayi Chen",
        "Zhiqi Zhang",
        "Taoyu Yang",
        "Xuheng Zhang",
        "Heming Cui",
        "Zhizheng Zhang",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T06:59:28+00:00",
          "link": "https://arxiv.org/abs/2505.03233v1",
          "size": "16605kb",
          "version": "v1"
        },
        {
          "date": "2025-07-19T03:33:23+00:00",
          "link": "https://arxiv.org/abs/2505.03233v2",
          "size": "8282kb",
          "version": "v2"
        }
      ],
      "title": "GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03233",
        "HTML": "https://arxiv.org/html/2505.03233",
        "PDF": "https://arxiv.org/pdf/2505.03233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses the use of synthetic data for training Vision-Language-Action models, which is relevant to data processing, its primary focus is on grasping tasks and robotic applications, not LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23298",
      "abstract": "Multimodal large language models (MLLMs) have enormous potential to perform few-shot in-context learning in the context of medical image analysis. However, safe deployment of these models into real-world clinical practice requires an in-depth analysis of the accuracies of their predictions, and their associated calibration errors, particularly across different demographic subgroups. In this work, we present the first investigation into the calibration biases and demographic unfairness of MLLMs' predictions and confidence scores in few-shot in-context learning for medical image classification. We introduce CALIN, an inference-time calibration method designed to mitigate the associated biases. Specifically, CALIN estimates the amount of calibration needed, represented by calibration matrices, using a bi-level procedure: progressing from the population level to the subgroup level prior to inference. It then applies this estimation to calibrate the predicted confidence scores during inference. Experimental results on three medical imaging datasets: PAPILA for fundus image classification, HAM10000 for skin cancer classification, and MIMIC-CXR for chest X-ray classification demonstrate CALIN's effectiveness at ensuring fair confidence calibration in its prediction, while improving its overall prediction accuracies and exhibiting minimum fairness-utility trade-off. Our codebase can be found at https://github.com/xingbpshen/medical-calibration-fairness-mllm.",
      "authors": [
        "Xing Shen",
        "Justin Szeto",
        "Mingyang Li",
        "Hengguan Huang",
        "Tal Arbel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:37:17+00:00",
          "link": "https://arxiv.org/abs/2506.23298v1",
          "size": "1033kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T01:57:28+00:00",
          "link": "https://arxiv.org/abs/2506.23298v2",
          "size": "1033kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T18:00:33+00:00",
          "link": "https://arxiv.org/abs/2506.23298v3",
          "size": "1033kb",
          "version": "v3"
        }
      ],
      "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23298",
        "HTML": "https://arxiv.org/html/2506.23298",
        "PDF": "https://arxiv.org/pdf/2506.23298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses calibration biases and demographic fairness in MLLM few-shot learning for medical image classification, focusing on model inference rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09194",
      "abstract": "The hitting set problem is a fundamental problem in computer science and mathematics. Given a family of sets over a universe of elements, a minimal hitting set is a subset-minimal collection of elements that intersects each set in the family. Enumerating all minimal hitting sets is crucial in various real-world applications.\n  In this paper, we address the full enumeration of all minimal hitting sets for a given family of sets. We formulate the problem using Answer Set Programming (ASP) and leverage existing ASP solvers for efficient enumeration. We propose an ASP-based tool, MinHit-ASP, and our empirical evaluation shows that it effectively enumerates minimal hitting sets across benchmarks from diverse problem domains.",
      "authors": [
        "Mohimenul Kabir",
        "Kuldeep S Meel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T08:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.09194v1",
          "size": "388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T04:36:52+00:00",
          "link": "https://arxiv.org/abs/2507.09194v2",
          "size": "389kb",
          "version": "v2"
        }
      ],
      "title": "A Simple and Effective ASP-Based Tool for Enumerating Minimal Hitting Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09194",
        "HTML": "https://arxiv.org/html/2507.09194",
        "PDF": "https://arxiv.org/pdf/2507.09194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses enumerating minimal hitting sets using an ASP-based tool. It does not relate to LLM training data processing in any capacity, focusing instead on a mathematical problem with computer science applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14341",
      "abstract": "We introduce MENO (''Matrix Exponential-based Neural Operator''), a hybrid surrogate modeling framework for efficiently solving stiff systems of ordinary differential equations (ODEs) that exhibit a sparse nonlinear structure. In such systems, only a few variables contribute nonlinearly to the dynamics, while the majority influence the equations linearly. MENO exploits this property by decomposing the system into two components: the low-dimensional nonlinear part is modeled using conventional neural operators, while the linear time-varying subsystem is integrated using a novel neural matrix exponential formulation. This approach combines the exact solution of linear time-invariant systems with learnable, time-dependent graph-based corrections applied to the linear operators. Unlike black-box or soft-constrained physics-informed (PI) models, MENO embeds the governing equations directly into its architecture, ensuring physical consistency (e.g., steady states), improved robustness, and more efficient training. We validate MENO on three complex thermochemical systems: the POLLU atmospheric chemistry model, an oxygen mixture in thermochemical nonequilibrium, and a collisional-radiative argon plasma in one- and two-dimensional shock-tube simulations. MENO achieves relative errors below 2% in trained zero-dimensional settings and maintains good accuracy in extrapolatory multidimensional regimes. It also delivers substantial computational speedups, achieving up to 4 800$\\times$ on GPU and 185$\\times$ on CPU compared to standard implicit ODE solvers. Although intrusive by design, MENO's physics-based architecture enables superior generalization and reliability, offering a scalable path for real-time simulation of stiff reactive systems.",
      "authors": [
        "Ivan Zanardi",
        "Simone Venturi",
        "Marco Panesi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:41:52+00:00",
          "link": "https://arxiv.org/abs/2507.14341v1",
          "size": "31507kb",
          "version": "v1"
        }
      ],
      "title": "MENO: Hybrid Matrix Exponential-based Neural Operator for Stiff ODEs. Application to Thermochemical Kinetics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14341",
        "PDF": "https://arxiv.org/pdf/2507.14341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a hybrid neural operator framework for solving stiff ODEs, specifically applied to thermochemical kinetics. This does not involve LLM training data processing or dataset improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14432",
      "abstract": "The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the quality of volumetric video representation. Meanwhile, in contrast to conventional volumetric video, 3DGS video poses significant challenges for streaming due to its substantially larger data volume and the heightened complexity involved in compression and transmission. To address these issues, we introduce an innovative framework for 3DGS volumetric video streaming. Specifically, we design a 3DGS video construction method based on the Gaussian deformation field. By employing hybrid saliency tiling and differentiated quality modeling of 3DGS video, we achieve efficient data compression and adaptation to bandwidth fluctuations while ensuring high transmission quality. Then we build a complete 3DGS video streaming system and validate the transmission performance. Through experimental evaluation, our method demonstrated superiority over existing approaches in various aspects, including video quality, compression effectiveness, and transmission rate.",
      "authors": [
        "Han Gong",
        "Qiyue Li",
        "Zhi Liu",
        "Hao Zhou",
        "Peng Yuan Zhou",
        "Zhu Li",
        "Jie Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T01:45:24+00:00",
          "link": "https://arxiv.org/abs/2507.14432v1",
          "size": "26470kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive 3D Gaussian Splatting Video Streaming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14432",
        "HTML": "https://arxiv.org/html/2507.14432",
        "PDF": "https://arxiv.org/pdf/2507.14432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing volumetric video streaming with 3D Gaussian splatting rather than LLM training data processing. It addresses data compression and transmission issues specific to video data, not LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15339",
      "abstract": "Modern moderation systems increasingly support multiple languages, but often fail to address localisation and low-resource variants - creating safety gaps in real-world deployments. Small models offer a potential alternative to large LLMs, yet still demand considerable data and compute. We present LionGuard 2, a lightweight, multilingual moderation classifier tailored to the Singapore context, supporting English, Chinese, Malay, and partial Tamil. Built on pre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2 outperforms several commercial and open-source systems across 17 benchmarks, including both Singapore-specific and public English datasets. The system is actively deployed within the Singapore Government, demonstrating practical efficacy at scale. Our findings show that high-quality local data and robust multilingual embeddings can achieve strong moderation performance, without fine-tuning large models. We release our model weights and part of our training data to support future work on LLM safety.",
      "authors": [
        "Leanne Tan",
        "Gabriel Chua",
        "Ziyu Ge",
        "Roy Ka-Wei Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:50:48+00:00",
          "link": "https://arxiv.org/abs/2507.15339v1",
          "size": "1539kb",
          "version": "v1"
        }
      ],
      "title": "LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15339",
        "HTML": "https://arxiv.org/html/2507.15339",
        "PDF": "https://arxiv.org/pdf/2507.15339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a multilingual moderation system that utilizes high-quality local data and multilingual embeddings. However, it mainly targets moderation capabilities rather than directly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15832",
      "abstract": "To address the limitations of medium- and long-term four-dimensional (4D) trajectory prediction models, this paper proposes a hybrid CNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy improved snake-herd optimization (SO) algorithm. The model applies the Adaboost algorithm to divide multiple weak learners, and each submodel utilizes CNN to extract spatial features, LSTM to capture temporal features, and attention mechanism to capture global features comprehensively. The strong learner model, combined with multiple sub-models, then optimizes the hyperparameters of the prediction model through the natural selection behavior pattern simulated by SO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the comparison experiments and ablation studies of multiple optimizers are carried out, and a comprehensive test and evaluation analysis is carried out. The results show that SO-CLA-adaboost outperforms traditional optimizers such as particle swarm, whale, and gray wolf in handling large-scale high-dimensional trajectory data. In addition, introducing the full-strategy collaborative improvement SO algorithm improves the model's prediction accuracy by 39.89%.",
      "authors": [
        "Shiyang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T17:44:06+00:00",
          "link": "https://arxiv.org/abs/2507.15832v1",
          "size": "3813kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15832",
        "PDF": "https://arxiv.org/pdf/2507.15832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hybrid model for trajectory prediction and optimization, which is unrelated to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10729",
      "abstract": "Local Polynomial Regression (LPR) is a widely used nonparametric method for modeling complex relationships due to its flexibility and simplicity. It estimates a regression function by fitting low-degree polynomials to localized subsets of the data, weighted by proximity. However, traditional LPR is sensitive to outliers and high-leverage points, which can significantly affect estimation accuracy. This paper revisits the kernel function used to compute regression weights and proposes a novel framework that incorporates both predictor and response variables in the weighting mechanism. The focus of this work is a conditional density kernel that robustly estimates weights by mitigating the influence of outliers through localized density estimation. A related joint density kernel is also discussed in an appendix. The proposed method is implemented in Python and is publicly available at https://github.com/yaniv-shulman/rsklpr, demonstrating competitive performance in synthetic benchmark experiments. Compared to standard LPR, the proposed approach consistently improves robustness and accuracy, especially in heteroscedastic and noisy environments, without requiring multiple iterations. This advancement provides a promising extension to traditional LPR, opening new possibilities for robust regression applications.",
      "authors": [
        "Yaniv Shulman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T11:21:26+00:00",
          "link": "https://arxiv.org/abs/2501.10729v1",
          "size": "553kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:25:40+00:00",
          "link": "https://arxiv.org/abs/2501.10729v2",
          "size": "541kb",
          "version": "v2"
        }
      ],
      "title": "Robust Local Polynomial Regression with Similarity Kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10729",
        "HTML": "https://arxiv.org/html/2501.10729",
        "PDF": "https://arxiv.org/pdf/2501.10729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a robust method for Local Polynomial Regression, with no connection to LLM training data processing."
      },
      "tasks": [
        "Density Estimation",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/yaniv-shulman/rsklpr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16115",
      "abstract": "The discretization of reduced one-dimensional hyperbolic models of blood flow using the Lax-Friedrichs method is discussed. Employing the well-established central scheme in this domain significantly simplifies the implementation of specific boundary and coupling conditions in vascular networks accounting e.g. for a periodic heart beat, vascular occlusions, stented vessel segments and bifurcations. In particular, the coupling of system extensions modeling patient specific geometries and therapies can be realized without information on the eigenstructure of the models. For the derivation of the scheme and the coupling conditions a relaxation of the model is considered and its discrete relaxation limit evaluated. Moreover, a second order MUSCL-type extensions of the scheme is introduced. Numerical experiments in uncoupled and coupled cases that verify the consistency and convergence of the approach are presented.",
      "authors": [
        "Anika Beckers and Niklas Kolbe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T15:06:08+00:00",
          "link": "https://arxiv.org/abs/2501.16115v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "The Lax-Friedrichs method in one-dimensional hemodynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16115",
        "HTML": "https://arxiv.org/html/2501.16115",
        "PDF": "https://arxiv.org/pdf/2501.16115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the application of the Lax-Friedrichs method to blood flow modeling, focusing on numerical experiments in hemodynamics. It does not address LLM training data processing or contribute to related data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01229",
      "abstract": "Traditionally, query optimizers rely on cost models to choose the best execution plan from several candidates, making precise cost estimates critical for efficient query execution. In recent years, cost models based on machine learning have been proposed to overcome the weaknesses of traditional cost models. While these models have been shown to provide better prediction accuracy, only limited efforts have been made to investigate how well Learned Cost Models (LCMs) actually perform in query optimization and how they affect overall query performance. In this paper, we address this by a systematic study evaluating LCMs on three of the core query optimization tasks: join ordering, access path selection, and physical operator selection. In our study, we compare seven state-of-the-art LCMs to a traditional cost model and, surprisingly, find that the traditional model often still outperforms LCMs in these tasks. We conclude by highlighting major takeaways and recommendations to guide future research toward making LCMs more effective for query optimization.",
      "authors": [
        "Roman Heinrich",
        "Manisha Luthra",
        "Johannes Wehrstein",
        "Harald Kornmayer",
        "Carsten Binnig"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T10:37:05+00:00",
          "link": "https://arxiv.org/abs/2502.01229v1",
          "size": "1052kb",
          "version": "v1"
        }
      ],
      "title": "How Good are Learned Cost Models, Really? Insights from Query Optimization Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01229",
        "HTML": "https://arxiv.org/html/2502.01229",
        "PDF": "https://arxiv.org/pdf/2502.01229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating learned cost models in query optimization, which is unrelated to LLM training data processing, as it does not address data collection, generation, or enhancement for LLMs."
      },
      "repo_urls": [
        "https://github.com/datamanagementlab/lcm-eval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09676",
      "abstract": "Research into the development of special-purpose computing architectures designed to solve quadratic unconstrained binary optimization (QUBO) problems has flourished in recent years. It has been demonstrated in the literature that such special-purpose solvers can outperform traditional CMOS architectures by orders of magnitude with respect to timing metrics on synthetic problems. However, they face challenges with constrained problems such as the quadratic assignment problem (QAP), where mapping to binary formulations such as QUBO introduces overhead and limits parallelism. In-memory computing (IMC) devices, such as memristor-based analog Ising machines, offer significant speedups and efficiency gains over traditional CPU-based solvers, particularly for solving combinatorial optimization problems. In this work, we present a novel local search heuristic designed for IMC hardware to tackle the QAP. Our approach enables massive parallelism that allows for computing of full neighbourhoods simultaneously to make update decisions. We ensure binary solutions remain feasible by selecting local moves that lead to neighbouring feasible solutions, leveraging feasible-space search heuristics and the underlying structure of a given problem. Our approach is compatible with both digital computers and analog hardware. We demonstrate its effectiveness in CPU implementations by comparing it with state-of-the-art heuristics for solving the QAP.",
      "authors": [
        "Haesol Im",
        "Chan-Woo Yang",
        "Moslem Noori",
        "Dmitrii Dobrynin",
        "Elisabetta Valiante",
        "Giacomo Pedretti",
        "Arne Heittmann",
        "Thomas Van Vaerenbergh",
        "Masoud Mohseni",
        "John Paul Strachan",
        "Dmitri Strukov",
        "Ray Beausoleil",
        "and Ignacio Rozada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T17:57:27+00:00",
          "link": "https://arxiv.org/abs/2503.09676v1",
          "size": "2842kb",
          "version": "v1"
        },
        {
          "date": "2025-07-18T22:06:22+00:00",
          "link": "https://arxiv.org/abs/2503.09676v2",
          "size": "841kb",
          "version": "v2"
        }
      ],
      "title": "Hardware-Compatible Single-Shot Feasible-Space Heuristics for Solving the Quadratic Assignment Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09676",
        "HTML": "https://arxiv.org/html/2503.09676",
        "PDF": "https://arxiv.org/pdf/2503.09676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an approach for solving the quadratic assignment problem using in-memory computing devices and hardware-compatible heuristics, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14333",
      "abstract": "The work presents an inverse-designed optical cavity that can direct light from two sources such that if the sources were to represent any number in the range [-1,1] with magnitude encoded through the power emitted by the source and sign by switching the direction of source current, the photocurrent generated at the two output ports is proportional to the product of the two numbers. Let us say that the two sources encode x and y, which are two numbers $\\in$ [-1,1]. Multiplication is reduced to the form $(x+y)^2 - (x-y)^2 = 4xy \\propto xy$. The addition and subtraction operations of the numbers are supported by constructive and destructive interference, respectively. The work shows that replacing the DDOT dot product engine of the Lightening Transformer with the optical cavity proposed to calculate the dot product can lead to a reduction in the area occupied by the photonic core by 88 \\%, can reduce the power consumption by lasers by around 23.43 \\%, and bring down energy consumption while training DeiT models by 0.88 \\%. The cavities can generate photocurrents of the form $1.057 xy + 0.249$ with $R^2=0.88,$ thus showing a relationship of direct proportionality between the target product $xy$ and the output of the cavity in response to stimuli encoding $x$ and $y$.",
      "authors": [
        "Anannya Mathur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-18T19:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.14333v1",
          "size": "2974kb",
          "version": "v1"
        }
      ],
      "title": "Inverse-Designed Dot Product Engine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14333",
        "HTML": "https://arxiv.org/html/2507.14333",
        "PDF": "https://arxiv.org/pdf/2507.14333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optical cavities for computational purposes, specifically for multiplication operations, and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14612",
      "abstract": "Next point of interest (POI) recommendation primarily predicts future activities based on users' past check-in data and current status, providing significant value to users and service providers. We observed that the popular check-in times for different POI categories vary. For example, coffee shops are crowded in the afternoon because people like to have coffee to refresh after meals, while bars are busy late at night. However, existing methods rarely explore the relationship between POI categories and time, which may result in the model being unable to fully learn users' tendencies to visit certain POI categories at different times. Additionally, existing methods for modeling time information often convert it into time embeddings or calculate the time interval and incorporate it into the model, making it difficult to capture the continuity of time. Finally, during POI prediction, various weighting information is often ignored, such as the popularity of each POI, the transition relationships between POIs, and the distances between POIs, leading to suboptimal performance. To address these issues, this paper proposes a novel next POI recommendation framework called Graph Disentangler with POI Weighted Module (GDPW). This framework aims to jointly consider POI category information and multiple POI weighting factors. Specifically, the proposed GDPW learns category and time representations through the Global Category Graph and the Global Category-Time Graph. Then, we disentangle category and time information through contrastive learning. After prediction, the final POI recommendation for users is obtained by weighting the prediction results based on the transition weights and distance relationships between POIs. We conducted experiments on two real-world datasets, and the results demonstrate that the proposed GDPW outperforms other existing models, improving performance by 3% to 11%.",
      "authors": [
        "Pei-Xuan Li",
        "Wei-Yun Liang",
        "Fandel Lin",
        "Hsun-Ping Hsieh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T13:16:44+00:00",
          "link": "https://arxiv.org/abs/2507.14612v1",
          "size": "982kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14612",
        "HTML": "https://arxiv.org/html/2507.14612",
        "PDF": "https://arxiv.org/pdf/2507.14612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for POI recommendation using graph disentanglement, unrelated to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15074",
      "abstract": "The emerging reconfigurable antenna (RA) array technology promises capacity enhancement through dynamic antenna positioning. Traditional approaches enforce half-wavelength or greater spacing among RA elements to avoid mutual coupling, limiting the solution space. Additionally, achieving sufficient spatial channel sampling requires numerous discrete RA positions (ports), while high-frequency scenarios with hybrid processing demand many physical RAs to maintain array gains. This leads to exponential growth in the solution space. We propose two techniques to address the former challenge: (1) surrounding a limited number of active RAs with passive ones terminated to tunable analog loads to \\textit{exploit} mutual coupling and increase array gain, and (2) employing tunable loads on each RA in an all-active design to \\textit{eliminate} mutual coupling in the analog domain. Both methods enable arbitrary RA spacing, unlocking the full solution space. Regarding the latter challenge, we develop greedy and meta-heuristic port selection algorithms, alongside low-complexity heuristic variants, that efficiently handle over $10^{20}$ array configurations, and optimize the loading values to maximize the sum-rate in a multiple-input single-output broadcast channel under transmission power constraints, assuming a heuristic linear precoder. Furthermore, we analyze performance degradation from quantized loads and propose corresponding robust designs. Numerical simulations reveal significant performance gains over benchmarks and provide valuable insights.",
      "authors": [
        "Elio Faddoul",
        "Konstantinos Ntougias",
        "Ioannis Krikidis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:17:54+00:00",
          "link": "https://arxiv.org/abs/2507.15074v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Reconfigurable Antenna Arrays With Tunable Loads: Expanding Solution Space via Coupling Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15074",
        "HTML": "https://arxiv.org/html/2507.15074",
        "PDF": "https://arxiv.org/pdf/2507.15074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on reconfigurable antenna arrays and their optimization, which does not relate to LLM training data processing or involve operations like data generation or filtering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.06211",
      "abstract": "Mixture-of-experts (MoEs) have been adopted for reducing inference costs by sparsely activating experts in Large language models (LLMs). Despite this reduction, the massive number of experts in MoEs still makes them expensive to serve. In this paper, we study how to address this, by pruning MoEs. Among pruning methodologies, unstructured pruning has been known to achieve the highest performance for a given pruning ratio, compared to structured pruning, since the latter imposes constraints on the sparsification structure. This is intuitive, as the solution space of unstructured pruning subsumes that of structured pruning. However, our counterintuitive finding reveals that expert pruning, a form of structured pruning, can actually precede unstructured pruning to outperform unstructured-only pruning. As existing expert pruning, requiring $O(\\frac{k^n}{\\sqrt{n}})$ forward passes for $n$ experts, cannot scale for recent MoEs, we propose a scalable alternative with $O(1)$ complexity, yet outperforming the more expensive methods. The key idea is leveraging a latent structure between experts, based on behavior similarity, such that the greedy decision of whether to prune closely captures the joint pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized MoE with 128 experts, our method needs only one H100 and two hours to achieve nearly no loss in performance with 40% sparsity, even in generative tasks such as GSM8K, where state-of-the-art unstructured pruning fails to. The code will be made publicly available.",
      "authors": [
        "Jaeseong Lee",
        "seung-won hwang",
        "Aurick Qiao",
        "Daniel F Campos",
        "Zhewei Yao",
        "Yuxiong He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T04:34:42+00:00",
          "link": "https://arxiv.org/abs/2409.06211v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T09:16:12+00:00",
          "link": "https://arxiv.org/abs/2409.06211v2",
          "size": "372kb",
          "version": "v2"
        }
      ],
      "title": "STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06211",
        "HTML": "https://arxiv.org/html/2409.06211",
        "PDF": "https://arxiv.org/pdf/2409.06211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with pruning methodologies for MoEs in LLMs but does not address training data processing aspects like data collection, filtering, or dataset creation for LLMs."
      },
      "tasks": [
        "GSM8K",
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.12406",
      "abstract": "The Sinc convolution is an approximate formula for indefinite convolutions proposed by Stenger. The formula was derived based on the Sinc indefinite integration formula combined with the single-exponential transformation. Although its efficiency has been confirmed in various fields, several theoretical issues remain unresolved. The first contribution of this study is to resolve those issues by refining the underlying theory of the Sinc convolution. This contribution includes an essential resolution of Stenger's conjecture. The second contribution of this study is to improve the convergence rate by replacing the single-exponential transformation with the double-exponential transformation. Theoretical analysis and numerical experiments confirm that the modified formula achieves superior convergence compared to Stenger's original formula.",
      "authors": [
        "Tomoaki Okayama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:52:02+00:00",
          "link": "https://arxiv.org/abs/2507.12406v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2025-07-21T17:00:55+00:00",
          "link": "https://arxiv.org/abs/2507.12406v2",
          "size": "43kb",
          "version": "v2"
        }
      ],
      "title": "Refinement of the theory and convergence of the Sinc convolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12406",
        "PDF": "https://arxiv.org/pdf/2507.12406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with theoretical advancements in the convergence of the Sinc convolution, which is unrelated to LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14228",
      "abstract": "We propose a multiple chirp rate index modulation (MCR-IM) system based on Zadoff-Chu (ZC) sequences that overcomes the problems of low transmission rate and large-scale access in classical LoRa networks. We demonstrate the extremely low cross-correlation of MCR-IM signals across different spread factors, showing that the proposed MCR-IM system also inherits the characteristics of ZC sequences modulation. Moreover, we derive an approximate closed-form expression for the bit-error rate (BER) of the proposed MCR-IM system over Nakagami-m fading channels. Simulation results confirm the accuracy of the derived closed-form expression and demonstrate that the MCR-IM system achieves higher levels of spectral efficiency (SE) compared to existing systems. In this context, assigning multiple chirp rates to each user results in a reduction in the number of parallel channels. To mitigate this issue, we propose a peak detection based successive interference cancellation (PD-SIC) algorithm to accommodate more users. Compared to orthogonal scatter chirp spreading spectrum system that names OrthoRa, the MCR-IM system with PD-SIC algorithm achieves lower BER levels. For a similar number of collision signals, the throughput of the MCR-IM system is enhanced by 16% to 21%. Owing to these advantages, the proposed MCR-IM is well suited for large-scale, high-rate LoRa network applications.",
      "authors": [
        "Xiaobin Zhu",
        "Minling Zhang",
        "Guofa Cai",
        "Jiguang He",
        "Georges Kaddoum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:27:26+00:00",
          "link": "https://arxiv.org/abs/2507.14228v1",
          "size": "1303kb",
          "version": "v1"
        }
      ],
      "title": "Design of A New Multiple-Chirp-Rate Index Modulation for LoRa Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14228",
        "HTML": "https://arxiv.org/html/2507.14228",
        "PDF": "https://arxiv.org/pdf/2507.14228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new modulation system for LoRa networks and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14528",
      "abstract": "In causal inference, whether through randomized controlled trials or observational studies, access to both treated and control units is essential for estimating the effect of a treatment on an outcome of interest. When treatment assignment is random, the average treatment effect (ATE) can be estimated directly by comparing outcomes between groups. In non-randomized settings, various techniques are employed to adjust for confounding and approximate the counterfactual scenario to recover an unbiased ATE. A common challenge, especially in observational studies, is the absence of units clearly labeled as controls-that is, units known not to have received the treatment. To address this, we propose positive-unlabeled (PU) learning as a framework for identifying, with high confidence, control units from a pool of unlabeled ones, using only the available treated (positive) units. We evaluate this approach using both simulated and real-world data. We construct a causal graph with diverse relationships and use it to generate synthetic data under various scenarios, assessing how reliably the method recovers control groups that allow estimates of true ATE. We also apply our approach to real-world data on optimal sowing and fertilizer treatments in sustainable agriculture. Our findings show that PU learning can successfully identify control (negative) units from unlabeled data based only on treated units and, through the resulting control group, estimate an ATE that closely approximates the true value. This work has important implications for observational causal inference, especially in fields where randomized experiments are difficult or costly. In domains such as earth, environmental, and agricultural sciences, it enables a plethora of quasi-experiments by leveraging available earth observation and climate data, particularly when treated units are available but control units are lacking.",
      "authors": [
        "Ilias Tsoumas",
        "Dimitrios Bormpoudakis",
        "Vasileios Sitokonstantinou",
        "Athanasios Askitopoulos",
        "Andreas Kalogeras",
        "Charalampos Kontoes",
        "Ioannis Athanasiadis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T08:06:08+00:00",
          "link": "https://arxiv.org/abs/2507.14528v1",
          "size": "3969kb",
          "version": "v1"
        }
      ],
      "title": "Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14528",
        "HTML": "https://arxiv.org/html/2507.14528",
        "PDF": "https://arxiv.org/pdf/2507.14528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel approach using positive-unlabeled learning for identifying control groups in causal inference studies, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14818",
      "abstract": "Mobile games are becoming a vital medium for social interaction, offering a platform that transcends geographical boundaries. An increasing number of visually impaired individuals are engaging in mobile gaming to connect, collaborate, compete, and build friendships. In China, visually impaired communities face significant social challenges in offline settings, making mobile games a crucial avenue for socialization. However, the design of mobile games and their mapping to real-world environments significantly shape their social gaming experiences. This study explores how visually impaired players in China navigate socialization and integrate into gaming communities. Through interviews with 30 visually impaired players, we found that while mobile games fulfill many of their social needs, technological barriers and insufficient accessibility features, and internal community divisions present significant challenges to their participation. This research sheds light on their social experiences and offers insights for designing more inclusive and accessible mobile games.",
      "authors": [
        "Zihe Ran",
        "Xiyu Li",
        "Qing Xiao",
        "Yanyun Wang",
        "Franklin Mingzhe Li",
        "Zhicong Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:30:05+00:00",
          "link": "https://arxiv.org/abs/2507.14818v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Understanding How Visually Impaired Players Socialize in Mobile Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14818",
        "HTML": "https://arxiv.org/html/2507.14818",
        "PDF": "https://arxiv.org/pdf/2507.14818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores social interactions of visually impaired players in mobile games. The paper does not make any contribution to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15022",
      "abstract": "Among the promising approaches to enforce safety in control systems, learning Control Barrier Functions (CBFs) from expert demonstrations has emerged as an effective strategy. However, a critical challenge remains: verifying that the learned CBFs truly enforce safety across the entire state space. This is especially difficult when CBF is represented using neural networks (NCBFs). Several existing verification techniques attempt to address this problem including SMT-based solvers, mixed-integer programming (MIP), and interval or bound-propagation methods but these approaches often introduce loose, conservative bounds. To overcome these limitations, in this work we use CPED-NCBFs a split-conformal prediction based verification strategy to verify the learned NCBF from the expert demonstrations. We further validate our method on point mass systems and unicycle models to demonstrate the effectiveness of the proposed theory.",
      "authors": [
        "Sumeadh MS",
        "Kevin Dsouza",
        "Ravi Prakash"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T16:06:31+00:00",
          "link": "https://arxiv.org/abs/2507.15022v1",
          "size": "1918kb",
          "version": "v1"
        }
      ],
      "title": "CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15022",
        "HTML": "https://arxiv.org/html/2507.15022",
        "PDF": "https://arxiv.org/pdf/2507.15022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses verification strategies for learning Control Barrier Functions within control systems and is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15788",
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated emergent capabilities in complex reasoning, largely spurred by rule-based Reinforcement Learning (RL) techniques applied during the post-training. This has raised the question of whether similar methods can instill more nuanced, human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This paper investigates whether small-scale LLMs can acquire a robust and generalizable ToM capability through RL with verifiable rewards (RLVR). We conduct a systematic evaluation by training models on various combinations of prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for generalization on held-out datasets (e.g., OpenToM). Our findings indicate that small LLMs struggle to develop a generic ToM capability. While performance on in-distribution tasks improves, this capability fails to transfer to unseen ToM tasks with different characteristics. Furthermore, we demonstrate that prolonged RL training leads to models ``hacking'' the statistical patterns of the training datasets, resulting in significant performance gains on in-domain data but no change, or degradation of performance on out-of-distribution tasks. This suggests the learned behavior is a form of narrow overfitting rather than the acquisition of a true, abstract ToM capability.",
      "authors": [
        "Sneheel Sarangi and Hanan Salam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T16:47:59+00:00",
          "link": "https://arxiv.org/abs/2507.15788v1",
          "size": "9730kb",
          "version": "v1"
        }
      ],
      "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15788",
        "HTML": "https://arxiv.org/html/2507.15788",
        "PDF": "https://arxiv.org/pdf/2507.15788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on whether small LLMs can learn a Theory of Mind through reinforcement learning rather than on any direct training data processing methods or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.17163",
      "abstract": "Automatic evaluation of retrieval augmented generation (RAG) systems relies on fine-grained dimensions like faithfulness and relevance, as judged by expert human annotators. Meta-evaluation benchmarks support the development of automatic evaluators that correlate well with human judgement. However, existing benchmarks predominantly focus on English or use translated data, which fails to capture cultural nuances. A native approach provides a better representation of the end user experience.\n  In this work, we develop a Multilingual End-to-end Meta-Evaluation RAG benchmark (MEMERAG). Our benchmark builds on the popular MIRACL dataset, using native-language questions and generating responses with diverse large language models (LLMs), which are then assessed by expert annotators for faithfulness and relevance. We describe our annotation process and show that it achieves high inter-annotator agreement. We then analyse the performance of the answer-generating LLMs across languages as per the human evaluators. Finally we apply the dataset to our main use-case which is to benchmark multilingual automatic evaluators (LLM-as-a-judge). We show that our benchmark can reliably identify improvements offered by advanced prompting techniques and LLMs. Our dataset is available at https://github.com/amazon-science/MEMERAG",
      "authors": [
        "Mar\\'ia Andrea Cruz Bland\\'on",
        "Jayasimha Talur",
        "Bruno Charron",
        "Dong Liu",
        "Saab Mansour",
        "Marcello Federico"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T13:58:42+00:00",
          "link": "https://arxiv.org/abs/2502.17163v1",
          "size": "2432kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T12:39:53+00:00",
          "link": "https://arxiv.org/abs/2502.17163v2",
          "size": "2432kb",
          "version": "v2"
        },
        {
          "date": "2025-04-29T07:28:04+00:00",
          "link": "https://arxiv.org/abs/2502.17163v3",
          "size": "2434kb",
          "version": "v3"
        },
        {
          "date": "2025-07-19T07:01:23+00:00",
          "link": "https://arxiv.org/abs/2502.17163v4",
          "size": "1284kb",
          "version": "v4"
        }
      ],
      "title": "MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17163",
        "HTML": "https://arxiv.org/html/2502.17163",
        "PDF": "https://arxiv.org/pdf/2502.17163"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a multilingual benchmark for evaluating Retrieval Augmented Generation (RAG) systems. It involves dataset development for evaluation purposes, but the primary focus is not on LLM training data processing operations like filtering or dataset creation for training."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/amazon-science/memerag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.14664",
      "abstract": "Pre-training data shapes a language model's quality, but raw web text is noisy and demands careful cleaning. Existing large-scale corpora rely on English-centric or language-agnostic pipelines whose heuristics do not capture Thai script or cultural nuances, leaving risky material such as gambling content untreated. Prior Thai-specific efforts customize pipelines or build new ones, yet seldom release their data or document design choices, hindering reproducibility and raising the question of how to construct a transparent, high-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai corpus built through a Thai-adapted Dolma pipeline that includes custom rule-based language ID, revised C4/Gopher quality filters, and Thai-trained content filters, plus curated non-web sources such as Wikipedia, Royal Gazette texts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic ablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M documents while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION model continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and Llama-3.1 by about four points on Thai benchmarks. We release the full pipeline code, cleaning manifests, corpus snapshot, and all checkpoints, providing a fully reproducible foundation for future Thai and regional LLM research.",
      "authors": [
        "Wannaphong Phatthiyaphaibun",
        "Can Udomcharoenchaikit",
        "Pakpoom Singkorapoom",
        "Kunat Pipatanakul",
        "Ekapol Chuangsuwanich",
        "Peerat Limkonchotiwat",
        "Sarana Nutanong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-19T15:28:58+00:00",
          "link": "https://arxiv.org/abs/2507.14664v1",
          "size": "2522kb",
          "version": "v1"
        }
      ],
      "title": "Mangosteen: An Open Thai Corpus for Language Model Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14664",
        "HTML": "https://arxiv.org/html/2507.14664",
        "PDF": "https://arxiv.org/pdf/2507.14664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents Mangosteen, a Thai corpus for language model pretraining, detailing its creation with a specialized Thai-adapted pipeline, aimed at improving data quality and transparency, making a core contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14914",
      "abstract": "Floorplanning determines the shapes and locations of modules on a chip canvas and plays a critical role in optimizing the chip's Power, Performance, and Area (PPA) metrics. However, existing floorplanning approaches often fail to integrate with subsequent physical design stages, leading to suboptimal in-module component placement and excessive inter-module feedthrough. To tackle this challenge, we propose Flora, a three-stage feedthrough and placement aware rectilinear floorplanner. In the first stage, Flora employs wiremask and position mask techniques to achieve coarse-grained optimization of HPWL and feedthrough. In the second stage, under the constraint of a fixed outline, Flora achieves a zero-whitespace layout by locally resizing module shapes, thereby performing fine-grained optimization of feedthrough and improving component placement. In the third stage, Flora utilizes a fast tree search-based method to efficiently place components-including macros and standard cells-within each module, subsequently adjusting module boundaries based on the placement results to enable cross-stage optimization. Experimental results show that Flora outperforms recent state-of-the-art floorplanning approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin, 29.15% in FTmod, and a 14% improvement in component placement performance.",
      "authors": [
        "Zhexuan Xu",
        "Jie Wang",
        "Siyuan Xu",
        "Zijie Geng",
        "Mingxuan Yuan and Feng Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:00:18+00:00",
          "link": "https://arxiv.org/abs/2507.14914v1",
          "size": "511kb",
          "version": "v1"
        }
      ],
      "title": "One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14914",
        "HTML": "https://arxiv.org/html/2507.14914",
        "PDF": "https://arxiv.org/pdf/2507.14914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on floorplanning for chip design optimization. It does not address LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14921",
      "abstract": "Generalizable 3D Gaussian Splatting reconstruction showcases advanced Image-to-3D content creation but requires substantial computational resources and large datasets, posing challenges to training models from scratch. Current methods usually entangle the prediction of 3D Gaussian geometry and appearance, which rely heavily on data-driven priors and result in slow regression speeds. To address this, we propose \\method, a disentangled framework for efficient 3D Gaussian prediction. Our method extracts features from local image pairs using a stereo vision backbone and fuses them via global attention blocks. Dedicated point and Gaussian prediction heads generate multi-view point-maps for geometry and Gaussian features for appearance, combined as GS-maps to represent the 3DGS object. A refinement network enhances these GS-maps for high-quality reconstruction. Unlike existing methods that depend on camera parameters, our approach achieves pose-free 3D reconstruction, improving robustness and practicality. By reducing resource demands while maintaining high-quality outputs, \\method provides an efficient, scalable solution for real-world 3D content generation.",
      "authors": [
        "Xiufeng Huang",
        "Ka Chun Cheung",
        "Runmin Cong",
        "Simon See",
        "Renjie Wan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T11:33:13+00:00",
          "link": "https://arxiv.org/abs/2507.14921v1",
          "size": "1643kb",
          "version": "v1"
        }
      ],
      "title": "Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14921",
        "HTML": "https://arxiv.org/html/2507.14921",
        "PDF": "https://arxiv.org/pdf/2507.14921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on advancements in 3D Gaussian Splatting and stereo vision for image-to-3D content creation, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15082",
      "abstract": "We introduce a novel extension to robust control theory that explicitly addresses uncertainty in the value function's gradient, a form of uncertainty endemic to applications like reinforcement learning where value functions are approximated. We formulate a zero-sum dynamic game where an adversary perturbs both system dynamics and the value function gradient, leading to a new, highly nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness by proving a comparison principle for its viscosity solutions under a uniform ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a key insight: we prove that the classical quadratic value function assumption fails for any non-zero gradient uncertainty, fundamentally altering the problem structure. A formal perturbation analysis characterizes the non-polynomial correction to the value function and the resulting nonlinearity of the optimal control law, which we validate with numerical studies. Finally, we bridge theory to practice by proposing a novel Gradient-Uncertainty-Robust Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating its effectiveness in stabilizing training. This work provides a new direction for robust control, holding significant implications for fields where function approximation is common, including reinforcement learning and computational finance.",
      "authors": [
        "Qian Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T18:37:30+00:00",
          "link": "https://arxiv.org/abs/2507.15082v1",
          "size": "458kb",
          "version": "v1"
        }
      ],
      "title": "Robust Control with Gradient Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15082",
        "HTML": "https://arxiv.org/html/2507.15082",
        "PDF": "https://arxiv.org/pdf/2507.15082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an extension to robust control theory dealing with gradient uncertainty in value functions, applicable to reinforcement learning. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15274",
      "abstract": "Closed-loop neural stimulation provides novel therapies for neurological diseases such as Parkinson's disease (PD), but it is not yet clear whether artificial intelligence (AI) techniques can tailor closed-loop stimulation to individual patients or identify new therapies. Progress requires us to address a number of translational issues, including sample efficiency, training time, and minimizing loop latency such that stimulation may be shaped in response to changing brain activity. We propose temporal basis function models (TBFMs) to address these difficulties, and explore this approach in the context of excitatory optogenetic stimulation. We demonstrate the ability of TBF models to provide a single-trial, spatiotemporal forward prediction of the effect of optogenetic stimulation on local field potentials (LFPs) measured in two non-human primates. We further use simulations to demonstrate the use of TBF models for closed-loop stimulation, driving neural activity towards target patterns. The simplicity of TBF models allow them to be sample efficient, rapid to train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the model on 40 sessions of previously published excitatory optogenetic stimulation data. For each session, the model required 15-20min of data collection to successfully model the remainder of the session. It achieved a prediction accuracy comparable to a baseline nonlinear dynamical systems model that requires hours to train, and superior accuracy to a linear state-space model. In our simulations, it also successfully allowed a closed-loop stimulator to control a neural circuit. Our approach begins to bridge the translational gap between complex AI-based approaches to modeling dynamical systems and the vision of using such forward prediction models to develop novel, clinically useful closed-loop stimulation protocols.",
      "authors": [
        "Matthew J. Bryan",
        "Felix Schwock",
        "Azadeh Yazdan-Shahmorad",
        "Rajesh P N Rao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T06:21:58+00:00",
          "link": "https://arxiv.org/abs/2507.15274v1",
          "size": "15242kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Basis Function Models for Closed-Loop Neural Stimulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15274",
        "HTML": "https://arxiv.org/html/2507.15274",
        "PDF": "https://arxiv.org/pdf/2507.15274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research pertains to closed-loop neural stimulation and does not relate to any aspect of LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15338",
      "abstract": "This paper investigates how to achieve both low-power operations of sensor nodes and accurate state estimation using Kalman filter for internet of things (IoT) monitoring employing wireless sensor networks under radio resource constraint. We consider two policies used by the base station to collect observations from the sensor nodes: (i) an oblivious policy, based on statistics of the observations, and (ii) a decentralized policy, based on autonomous decision of each sensor based on its instantaneous observation. This work introduces a wake-up receiver and wake-up signaling to both policies to improve the energy efficiency of the sensor nodes. The decentralized policy designed with random access prioritizes transmissions of instantaneous observations that are highly likely to contribute to the improvement of state estimation. Our numerical results show that the decentralized policy improves the accuracy of the estimation in comparison to the oblivious policy under the constraint on the radio resource and consumed energy when the correlation between the processes observed by the sensor nodes is low. We also clarify the degree of correlation in which the superiority of two policies changes.",
      "authors": [
        "Takaho Shimokasa",
        "Hiroyuki Yomo",
        "Federico Chiariotti",
        "Junya Shiraishi",
        "Petar Popovski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:50:20+00:00",
          "link": "https://arxiv.org/abs/2507.15338v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Low-Power and Accurate IoT Monitoring Under Radio Resource Constraint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15338",
        "HTML": "https://arxiv.org/html/2507.15338",
        "PDF": "https://arxiv.org/pdf/2507.15338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on IoT sensor networks and low-power operations using Kalman filtering for state estimation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09025",
      "abstract": "We propose Lizard, a linearization framework that transforms pretrained Transformer-based Large Language Models (LLMs) into flexible, subquadratic architectures for infinite-context generation. Transformer-based LLMs face significant memory and computational bottlenecks as context lengths increase, due to the quadratic complexity of softmax attention and the growing key-value (KV) cache. Lizard addresses these limitations by introducing a subquadratic attention mechanism that closely approximates softmax attention while preserving the output quality. Unlike previous linearization methods, which are often limited by fixed model structures and therefore exclude gating mechanisms, Lizard incorporates a gating module inspired by recent state-of-the-art linear models. This enables adaptive memory control, supports constant-memory inference, offers strong length generalization, and allows more flexible model design. Lizard combines gated linear attention for global context compression with sliding window attention enhanced by meta memory, forming a hybrid mechanism that captures both long-range dependencies and fine-grained local interactions. Moreover, we introduce a hardware-aware algorithm that accelerates the training speed of our models. Extensive experiments show that Lizard achieves near-lossless recovery of the teacher model's performance across standard language modeling tasks, while significantly outperforming previous linearization methods. On the 5-shot MMLU benchmark, Lizard improves over prior models by 18 points and shows significant improvements on associative recall tasks.",
      "authors": [
        "Chien Van Nguyen",
        "Ruiyi Zhang",
        "Hanieh Deilamsalehy",
        "Puneet Mathur",
        "Viet Dac Lai",
        "Haoliang Wang",
        "Jayakumar Subramanian",
        "Ryan A. Rossi",
        "Trung Bui",
        "Nikos Vlassis",
        "Franck Dernoncourt",
        "Thien Huu Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T21:19:18+00:00",
          "link": "https://arxiv.org/abs/2507.09025v1",
          "size": "369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-20T03:49:03+00:00",
          "link": "https://arxiv.org/abs/2507.09025v2",
          "size": "369kb",
          "version": "v2"
        }
      ],
      "title": "Lizard: An Efficient Linearization Framework for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09025",
        "HTML": "https://arxiv.org/html/2507.09025",
        "PDF": "https://arxiv.org/pdf/2507.09025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Lizard offers a linearization framework for LLM architectures to tackle memory issues but does not concern LLM training data processing. It focuses on model architecture modification, not dataset creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14207",
      "abstract": "The integration of Large Language Models (LLMs) in K--12 education offers both transformative opportunities and emerging risks. This study explores how students may Trojanize prompts to elicit unsafe or unintended outputs from LLMs, bypassing established content moderation systems with safety guardrils. Through a systematic experiment involving simulated K--12 queries and multi-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This paper presents our experimental design, detailed findings, and a prototype tool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized educational prompts. These insights aim to inform both AI safety researchers and educational technologists on the safe deployment of LLMs for educators.",
      "authors": [
        "Richard M. Charles",
        "James H. Curry and Richard B. Charles"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:23:19+00:00",
          "link": "https://arxiv.org/abs/2507.14207v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14207",
        "HTML": "https://arxiv.org/html/2507.14207",
        "PDF": "https://arxiv.org/pdf/2507.14207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on detecting and mitigating trojanized prompts in educational contexts, which is more about AI safety and prompt security rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14797",
      "abstract": "Diffusion models (DMs) have achieved state-of-the-art generative performance but suffer from high sampling latency due to their sequential denoising nature. Existing solver-based acceleration methods often face image quality degradation under a low-latency budget. In this paper, we propose the Ensemble Parallel Direction solver (dubbed as \\ours), a novel ODE solver that mitigates truncation errors by incorporating multiple parallel gradient evaluations in each ODE step. Importantly, since the additional gradient computations are independent, they can be fully parallelized, preserving low-latency sampling.\n  Our method optimizes a small set of learnable parameters in a distillation fashion, ensuring minimal training overhead.\n  In addition, our method can serve as a plugin to improve existing ODE samplers. Extensive experiments on various image synthesis benchmarks demonstrate the effectiveness of our \\ours~in achieving high-quality and low-latency sampling. For example, at the same latency level of 5 NFE, EPD achieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26 on LSUN Bedroom, surpassing existing learning-based solvers by a significant margin. Codes are available in https://github.com/BeierZhu/EPD.",
      "authors": [
        "Beier Zhu",
        "Ruoyu Wang",
        "Tong Zhao",
        "Hanwang Zhang",
        "Chi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T03:08:06+00:00",
          "link": "https://arxiv.org/abs/2507.14797v1",
          "size": "2890kb",
          "version": "v1"
        }
      ],
      "title": "Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14797",
        "HTML": "https://arxiv.org/html/2507.14797",
        "PDF": "https://arxiv.org/pdf/2507.14797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a new ODE solver for diffusion models to improve sampling efficiency. It does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14819",
      "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in transforming text descriptions or tables to data visualizations via instruction-tuning methods. However, it is not straightforward to apply these methods directly for a more real-world use case of visualizing data from long documents based on user-given intents, as opposed to the user pre-selecting the relevant content manually. We introduce the task of intent-based chart generation from documents: given a user-specified intent and document(s), the goal is to generate a chart adhering to the intent and grounded on the document(s) in a zero-shot setting. We propose an unsupervised, two-staged framework in which an LLM first extracts relevant information from the document(s) by decomposing the intent and iteratively validates and refines this data. Next, a heuristic-guided module selects an appropriate chart type before final code generation. To assess the data accuracy of the generated charts, we propose an attribution-based metric that uses a structured textual representation of charts, instead of relying on visual decoding metrics that often fail to capture the chart data effectively. To validate our approach, we curate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from two domains, finance and scientific, in contrast to the existing datasets that are largely limited to parallel text descriptions/ tables and their corresponding charts. We compare our approach with baselines using single-shot chart generation using LLMs and query-based retrieval methods; our method outperforms by upto $9$ points and $17$ points in terms of chart data accuracy and chart type respectively over the best baselines.",
      "authors": [
        "Akriti Jain",
        "Pritika Ramu",
        "Aparna Garimella",
        "Apoorv Saxena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T04:34:59+00:00",
          "link": "https://arxiv.org/abs/2507.14819v1",
          "size": "2259kb",
          "version": "v1"
        }
      ],
      "title": "Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14819",
        "HTML": "https://arxiv.org/html/2507.14819",
        "PDF": "https://arxiv.org/pdf/2507.14819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Doc2Chart for zero-shot chart generation using LLMs, and curates a dataset of intent-document-chart tuples. However, the primary focus is on chart generation, not directly on LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.14881",
      "abstract": "This paper presents an adaptive symplectic integrator, SQQ-PTQ, developed on the basis of the fixed-step symplectic integrator SQQ. To mitigate the Runge phenomenon, SQQ-PTQ employs Chebyshev interpolation for approximating the action, enhancing both the precision and stability of the interpolation. In addition, to reduce the computational cost of evaluating interpolation functions, SQQ-PTQ introduces a projection method that improves the efficiency of these computations. A key feature of SQQ-PTQ is its use of the time transformation to implement an adaptive time step. To address the challenge of computing complicated Jacobian matrices attributed to the time transformation, SQQ-PTQ adopts a quasi-Newton method based on Broyden's method. This strategy accelerates the solution of nonlinear equations, thereby improving the overall computational performance. The effectiveness and robustness of SQQ-PTQ are demonstrated via three numerical experiments. In particular, SQQ-PTQ demonstrates adaptability in handling close-encounter problems. Moreover, during long-term integrations, SQQ-PTQ maintains the energy conservation, further confirming its advantages as a symplectic algorithm.",
      "authors": [
        "Keqi Ye",
        "Zizhe Cai",
        "Mingji Wang",
        "Kun Yang",
        "and Xiaodong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Astrophysics of Galaxies (astro-ph.GA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-20T09:49:41+00:00",
          "link": "https://arxiv.org/abs/2507.14881v1",
          "size": "2489kb",
          "version": "v1"
        }
      ],
      "title": "An adaptive symplectic integrator for gravitational dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.14881",
        "HTML": "https://arxiv.org/html/2507.14881",
        "PDF": "https://arxiv.org/pdf/2507.14881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the development of an adaptive symplectic integrator for gravitational dynamics, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.15336",
      "abstract": "Database systems have recently advocated for embedding machine learning (ML) capabilities, offering declarative model queries over large, managed model repositories, thereby circumventing the huge computational overhead of traditional ML-based algorithms in automated neural network model selection. Pioneering database studies aim to organize existing benchmark repositories as model bases (MB), querying them for the model records with the highest performance estimation metrics for given tasks. However, this static model selection practice overlooks the fine-grained, evolving relational dependencies between diverse task queries and model architecture variations, resulting in suboptimal matches and failing to further refine the model effectively. To fill the model refinement gap in database research, we propose M-DESIGN, a curated model knowledge base (MKB) pipeline for mastering neural network refinement by adaptively weaving prior insights about model architecture modification. First, we propose a knowledge weaving engine that reframes model refinement as an adaptive query problem over task metadata. Given a user's task query, M-DESIGN quickly matches and iteratively refines candidate models by leveraging a graph-relational knowledge schema that explicitly encodes data properties, architecture variations, and pairwise performance deltas as joinable relations. This schema supports fine-grained relational analytics over architecture tweaks and drives a predictive query planner that can detect and adapt to out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics tasks, where our model knowledge base enriches existing benchmarks with structured metadata covering 3 graph tasks and 22 graph datasets, contributing data records of 67,760 graph models. Empirical results demonstrate that M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited budgets.",
      "authors": [
        "Jialiang Wang",
        "Hanmo Liu",
        "Shimin Di",
        "Zhili Wang",
        "Jiachuan Wang",
        "Lei Chen",
        "Xiaofang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-21T07:49:19+00:00",
          "link": "https://arxiv.org/abs/2507.15336v1",
          "size": "1126kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.15336",
        "HTML": "https://arxiv.org/html/2507.15336",
        "PDF": "https://arxiv.org/pdf/2507.15336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural network model refinement through a knowledge weaving engine but does not address data processing for LLM training. The focus is on model architecture modification rather than training data operations."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Physics and Society (physics.soc-ph)",
    "Multimedia (cs.MM)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Popular Physics (physics.pop-ph)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Classical Analysis and ODEs (math.CA)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Symplectic Geometry (math.SG)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Accelerator Physics (physics.acc-ph)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Statistical Finance (q-fin.ST)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Representation Theory (math.RT)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Astrophysics of Galaxies (astro-ph.GA)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Mathematical Physics (math.MP)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Classical Physics (physics.class-ph)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Number Theory (math.NT)",
    "Computation (stat.CO)",
    "Spectral Theory (math.SP)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
    "Machine Learning (stat.ML)",
    "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Information Theory (cs.IT)",
    "Physics Education (physics.ed-ph)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Group Theory (math.GR)",
    "Functional Analysis (math.FA)",
    "Numerical Analysis (cs.NA)",
    "Multiagent Systems (cs.MA)",
    "Statistics Theory (math.ST)",
    "Pattern Formation and Solitons (nlin.PS)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Computational Physics (physics.comp-ph)",
    "Geometric Topology (math.GT)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Nuclear Theory (nucl-th)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Rings and Algebras (math.RA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Dynamical Systems (math.DS)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to the performance of large language models (LLMs). You are a computer science expert specializing in LLM training data processing. Your task is to analyze a set of arXiv papers and determine their relevance to **LLM training data processing**.\n\n### **Task Objective**\n\nFor each paper, assess whether it makes a technical contribution to **LLM training data processing**.\n\n1. First, the paper must relate to data processing for **pretraining or fine-tuning**, including stages such as LLM pretraining, instruction fine-tuning, supervised fine-tuning (SFT), or alignment fine-tuning.\n2. Second, the paper must involve **training data processing** operations, such as:\n\n   * Data engineering operations, including data collection, data generation, deduplication, filtering, etc.;\n   * Techniques or methods that significantly improve data quality;\n   * Creation or generation of new datasets.\n\n### Answer: **Relevance Classification**\n\n**`core`**: The paper makes a direct contribution to LLM training data processing. Examples include: creation, generation, or synthesis of new datasets; building higher-quality datasets from existing ones; novel data processing techniques; or any data engineering operations that substantially improve data quality.\n\n**`partial`**: The paper briefly discusses training data processing, but the main focus lies elsewhere\u2014such as model architecture, task design, evaluation, or prompt engineering\u2014rather than training data processing.\n\n**`irrelevant`**: The paper does not address any aspect of LLM training data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<Paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1\u20132 sentence explanation of your classification, citing key content from the abstract or methodology section.\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```\n[\n    {\n        \"id\": \"2411.12372\",\n        \"title\": \"RedPajama: an Open Dataset for Training Large Language Models\",\n        \"abstract\": \"Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and metadata for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce's XGen and AI2's OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.\"\n    },\n    {\n        \"id\": \"2306.01116\",\n        \"title\": \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\",\n        \"abstract\": \"Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.\"\n    }\n]\n```\n\noutput:\n\n```\n{\n  \"result\": [\n    {\n      \"id\": \"2411.12372\",\n      \"answer\": \"core\",\n      \"reason\": \"This paper releases RedPajama-V1 and V2 datasets, comprising over 100 trillion tokens, and introduces quality signals for filtering. It involves data collection, deduplication, filtering, and quality assessment, making a significant contribution to LLM training data processing.\"\n    },\n    {\n      \"id\": \"2306.01116\",\n      \"answer\": \"core\",\n      \"reason\": \"The paper presents the RefinedWeb dataset, which uses only deduplicated and filtered web data to train LLMs. It challenges the conventional reliance on mixed curated corpora and publicly releases both the dataset and models, representing a core contribution to high-quality data construction.\"\n    }\n  ]\n}\n\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 1353,
    "partial": 158,
    "core": 39
  },
  "arxiv_update_date": "2025-07-21",
  "updated_at": "2025-07-22 11:00:35"
}