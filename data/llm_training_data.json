{
  "data": [
    {
      "id": "2507.12468",
      "abstract": "Digital Twins (DTs) are virtual representations of physical systems synchronized in real time through Internet of Things (IoT) sensors and computational models. In industrial applications, DTs enable predictive maintenance, fault diagnosis, and process optimization. This paper explores the mathematical foundations of DTs, hybrid modeling techniques, including Physics Informed Neural Networks (PINNs), and their implementation in industrial scenarios. We present key applications, computational tools, and future research directions.",
      "authors": [
        "Ali Mohammad-Djafari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Computer Science (cs.OH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T12:32:18+00:00",
          "link": "https://arxiv.org/abs/2507.12468v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Digital Twins in Industrial Applications: Concepts, Mathematical Modeling, and Use Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12468",
        "HTML": "https://arxiv.org/html/2507.12468v1",
        "PDF": "https://arxiv.org/pdf/2507.12468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Digital Twins, mathematical modeling, and industrial applications, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12469",
      "abstract": "This paper explores the computational complexity of diffusion-based language modeling. We prove a dichotomy based on the quality of the score-matching network in a diffusion model. In one direction, a network that exactly computes the score function of some initial distribution can only perform language modeling within the $\\mathsf{TC}^0$ complexity class, reflecting limitations tied to rapid convergence. In the other direction, we show that if there is no requirement for the network to match any score function, then diffusion modeling can simulate any Turing machine in a certain sense. This dichotomy provides a theoretical lens on the capabilities and limitations of diffusion models, particularly concerning tasks requiring sequential computation. We conjecture extensions of our theoretical results, including for the case where the diffusion model is not perfect, but merely good. We also discuss the wider context and practical implications, and hypothesize that a machine learning architecture that can interpolate between sequential and parallel modes of operation would be superior to both Transformers and diffusion models.",
      "authors": [
        "Yuxi Liu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T22:35:53+00:00",
          "link": "https://arxiv.org/abs/2507.12469v1",
          "size": "331kb",
          "version": "v1"
        }
      ],
      "title": "Perfect diffusion is $\\mathsf{TC}^0$ -- Bad diffusion is Turing-complete",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12469",
        "HTML": "https://arxiv.org/html/2507.12469v1",
        "PDF": "https://arxiv.org/pdf/2507.12469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the computational complexity of diffusion-based language modeling, but it does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12470",
      "abstract": "Efficiently solving NP-complete problems-such as protein structure prediction, cryptographic decryption, and vulnerability detection-remains a central challenge in computer science. Traditional electronic computers, constrained by the Turing machine's one-dimensional data processing and sequential operations, struggle to address these issues effectively. To overcome this bottleneck, computational models must adopt multidimensional data structures and parallel information processing mechanisms. Building on our team's proposed probe machine model (a non-Turing computational framework), this study develops a blocking probe technique that leverages DNA computing's inherent parallelism to identify all valid solutions for NP-complete problems in a single probe operation. Using the 27-vertex 3-coloring problem as a case study, we successfully retrieved all solutions through DNA molecular probe experiments. This breakthrough demonstrates the first implementation of a fully parallel computing system at the molecular level, offering a novel paradigm for tackling computational complexity. Our results indicate that the probe machine, with its parallel architecture and molecular implementation, transcends the limitations of classical models and holds promise for solving intricate real-world problems.",
      "authors": [
        "Jin Xu",
        "XiaoLong Shi",
        "Xin Chen",
        "Fang Wang",
        "Sirui Li",
        "Pali Ye",
        "Boliang Zhang",
        "Di Deng",
        "Zheng Kou and Xiaoli Qiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T00:19:58+00:00",
          "link": "https://arxiv.org/abs/2507.12470v1",
          "size": "3331kb",
          "version": "v1"
        }
      ],
      "title": "DNA Probe Computing System for Solving NP-Complete Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12470",
        "HTML": "https://arxiv.org/html/2507.12470v1",
        "PDF": "https://arxiv.org/pdf/2507.12470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on DNA computing for NP-complete problems, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12471",
      "abstract": "In order to truly benefit from RISC-V ISA modularity, the community has to address the issue of compositionality, going beyond modules at the specification level covering larger subsets of the RISC-V development flow including emulation, simulation and verification. In this paper we introduce modular SAIL, an experiment to inject compositionality into the SAIL-RISCV golden model. We show that it is, in principle, not difficult to adapt the SAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at the emulator level. We back our findings by a comparative study of the resulting pluggable emulator's performance using both static and dynamic binding, which both exhibit same functional behavior as the original monolithic emulator (aka RISC-V ISS).",
      "authors": [
        "Petr Kourzanov and Anmol"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T21:16:23+00:00",
          "link": "https://arxiv.org/abs/2507.12471v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Modular SAIL: dream or reality?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12471",
        "HTML": "https://arxiv.org/html/2507.12471v1",
        "PDF": "https://arxiv.org/pdf/2507.12471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses RISC-V modular emulation and verification, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12472",
      "abstract": "As large language models (LLMs) grow increasingly sophisticated and pervasive, their application to various Artificial Intelligence for IT Operations (AIOps) tasks has garnered significant attention. However, a comprehensive understanding of the impact, potential, and limitations of LLMs in AIOps remains in its infancy. To address this gap, we conducted a detailed survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve outcomes in this domain. We analyzed 183 research papers published between January 2020 and December 2024 to answer four key research questions (RQs). In RQ1, we examine the diverse failure data sources utilized, including advanced LLM-based processing techniques for legacy data and the incorporation of new data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks, highlighting the emergence of novel tasks and the publication trends across these tasks. RQ3 investigates the various LLM-based methods applied to address AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to assess LLM-integrated AIOps approaches. Based on our findings, we discuss the state-of-the-art advancements and trends, identify gaps in existing research, and propose promising directions for future exploration.",
      "authors": [
        "Lingzhe Zhang",
        "Tong Jia",
        "Mengxi Jia",
        "Yifan Wu",
        "Aiwei Liu",
        "Yong Yang",
        "Zhonghai Wu",
        "Xuming Hu",
        "Philip S. Yu and Ying Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T02:40:16+00:00",
          "link": "https://arxiv.org/abs/2507.12472v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of AIOps in the Era of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12472",
        "HTML": "https://arxiv.org/html/2507.12472v1",
        "PDF": "https://arxiv.org/pdf/2507.12472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys LLMs' role in AIOps, mentioning LLM-based processing techniques for data. It involves data processing to a limited extent, but it is not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12480",
      "abstract": "There exist various Software Development Kits (SDKs) tailored to different quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples include but are not limited to Qiskit, Cirq, and PennyLane. However, this diversity presents significant challenges for interoperability and cross-platform development of hybrid quantum-classical software systems. Traditional rule-based transpilers for translating code between QSDKs are time-consuming to design and maintain, requiring deep expertise and rigid mappings in the source and destination code. In this study, we explore the use of Large Language Models (LLMs) as a flexible and automated solution. Leveraging their pretrained knowledge and contextual reasoning capabilities, we position LLMs as programming language-agnostic transpilers capable of converting quantum programs from one QSDK to another while preserving functional equivalence. Our approach eliminates the need for manually defined transformation rules and offers a scalable solution to quantum software portability. This work represents a step toward enabling intelligent, general-purpose transpilation in the quantum computing ecosystem.",
      "authors": [
        "Nazanin Siavash and Armin Moin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T21:16:21+00:00",
          "link": "https://arxiv.org/abs/2507.12480v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Powered Quantum Code Transpilation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12480",
        "HTML": "https://arxiv.org/html/2507.12480v1",
        "PDF": "https://arxiv.org/pdf/2507.12480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on using LLMs for quantum code transpilation, which does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12482",
      "abstract": "Large Language Models (LLMs) have advanced code generation and software automation, but are fundamentally constrained by limited inference-time context and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a next-generation architecture for autonomous code understanding, debugging, and maintenance, designed to operate across ultra-long contexts comprising entire codebases, histories, and documentation, all without fixed window limits. Kodezi Chronos leverages a multi-level embedding memory engine, combining vector and graph-based indexing with continuous code-aware retrieval. This enables efficient and accurate reasoning over millions of lines of code, supporting repository-scale comprehension, multi-file refactoring, and real-time self-healing actions. Our evaluation introduces a novel Multi Random Retrieval benchmark, specifically tailored to the software engineering domain. Unlike classical retrieval benchmarks, this method requires the model to resolve arbitrarily distant and obfuscated associations across code artifacts, simulating realistic tasks such as variable tracing, dependency migration, and semantic bug localization. Chronos outperforms prior LLMs and code models, demonstrating a 23% improvement in real-world bug detection and reducing debugging cycles by up to 40% compared to traditional sequence-based approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos enables seamless, autonomous software maintenance, elevating code reliability and productivity while reducing manual effort. These results mark a critical advance toward self-sustaining, continuously optimized software ecosystems.",
      "authors": [
        "Ishraq Khan",
        "Assad Chowdary",
        "Sharoz Haseeb",
        "Urvish Patel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:08:21+00:00",
          "link": "https://arxiv.org/abs/2507.12482v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12482",
        "HTML": "https://arxiv.org/html/2507.12482v1",
        "PDF": "https://arxiv.org/pdf/2507.12482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a debugging-focused language model for code understanding and maintenance, with no emphasis on training data processing aspects for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12483",
      "abstract": "Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential decision-making and has attracted growing interest across various domains, particularly following the advent of Deep Reinforcement Learning (DRL) in 2015. Simultaneously, the rapid advancement of Large Language Models (LLMs) has further fueled interest in integrating RL with LLMs to enable more adaptive and intelligent systems. In the field of software engineering (SE), the increasing complexity of systems and the rising demand for automation have motivated researchers to apply RL to a broad range of tasks, from software design and development to quality assurance and maintenance. Despite growing research in RL-for-SE, there remains a lack of a comprehensive and systematic survey of this evolving field. To address this gap, we reviewed 115 peer-reviewed studies published across 22 premier SE venues since the introduction of DRL. We conducted a comprehensive analysis of publication trends, categorized SE topics and RL algorithms, and examined key factors such as dataset usage, model design and optimization, and evaluation practices. Furthermore, we identified open challenges and proposed future research directions to guide and inspire ongoing work in this evolving area. To summarize, this survey offers the first systematic mapping of RL applications in software engineering, aiming to support both researchers and practitioners in navigating the current landscape and advancing the field. Our artifacts are publicly available: https://github.com/KaiWei-Lin-lanina/RL4SE.",
      "authors": [
        "Dong Wang",
        "Hanmo You",
        "Lingwei Zhu",
        "Kaiwei Lin",
        "Zheng Chen",
        "Chen Yang",
        "Junji Yu",
        "Zan Wang",
        "Junjie Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:28:37+00:00",
          "link": "https://arxiv.org/abs/2507.12483v1",
          "size": "2050kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Reinforcement Learning for Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12483",
        "HTML": "https://arxiv.org/html/2507.12483v1",
        "PDF": "https://arxiv.org/pdf/2507.12483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys the application of reinforcement learning in software engineering, focusing on topics such as dataset usage and model optimization in software tasks. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12484",
      "abstract": "The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.",
      "authors": [
        "Jaros{\\l}aw A. Chudziak and Adam Kostka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:35:16+00:00",
          "link": "https://arxiv.org/abs/2507.12484v1",
          "size": "1914kb",
          "version": "v1"
        }
      ],
      "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12484",
        "HTML": "https://arxiv.org/html/2507.12484v1",
        "PDF": "https://arxiv.org/pdf/2507.12484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces an AI-powered tutoring platform for math education, emphasizing adaptive feedback and course generation. It does not discuss data processing techniques for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12486",
      "abstract": "We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.\n  As an illustration of our framework, we introduce and analyze a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.\n  In the particular case of perfect other predictions the algorithm that follows the self predictor is optimal but not robust to mispredictions of agent's future behavior; we give an algorithm with better robustness properties and benchmark it.",
      "authors": [
        "Gabriel Istrate",
        "Cosmin Bonchis and Victor Bogdan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:52:12+00:00",
          "link": "https://arxiv.org/abs/2507.12486v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "On multiagent online problems with predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12486",
        "HTML": "https://arxiv.org/html/2507.12486v1",
        "PDF": "https://arxiv.org/pdf/2507.12486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates competitive algorithms with predictions in multiagent settings, using examples like the ski-rental problem. It does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12487",
      "abstract": "Single-board computers, with their wide range of external interfaces, provide a cost-effective solution for studying animals and plants in their natural habitat. With the introduction of the Raspberry Pi Zero 2 W, which provides hardware-based image and video encoders, it is now possible to extend this application area to include video surveillance capabilities. This paper demonstrates a solution that offloads video stream generation from the Central Processing Unit (CPU) to hardware-based encoders. The flow of data through an encoding application is described, followed by a method of accelerating image processing by reducing the number of memory copies. The paper concludes with an example use case demonstrating the application of this new feature in an underwater camera.",
      "authors": [
        "Thomas Ederer and Igor Ivki\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Computer Science (cs.OH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.12487v1",
          "size": "2597kb",
          "version": "v1"
        }
      ],
      "title": "Implementing Video Monitoring Capabilities by using hardware-based Encoders of the Raspberry Pi Zero 2 W",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12487",
        "HTML": "https://arxiv.org/html/2507.12487v1",
        "PDF": "https://arxiv.org/pdf/2507.12487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes hardware-based video encoding capabilities using a Raspberry Pi for surveillance applications. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12488",
      "abstract": "When teaching Programming and Software Engineering in Bachelor's Degree programs, the emphasis on creating functional software projects often overshadows the focus on software quality, a trend that aligns with ACM curricula recommendations. Software Engineering courses are typically introduced later in the curriculum, and can generally allocate only limited time to quality-related topics, leaving educators with the challenge of deciding which quality aspects to prioritize. In this decision, the literature offers limited guidance, as most existing studies focus on code written by novice students and small code units, making it unclear whether those findings extend to intermediate-level students with foundational object-oriented programming skills working on more complex software projects. To address this gap, we analyze 83 object-oriented team projects developed by 172 university students across 4 different editions of the Object-Oriented Programming course. We apply a static analysis pipeline used in prior research to assess software quality, combining SonarQube and ArchUnit to detect code smells and architectural anti-patterns. Our findings highlight recurring quality issues and offer concrete evidence of the challenges students face at this stage, providing valuable guidance for educators aiming to continuously improve Software Engineering curricula and promote quality-oriented development practices.",
      "authors": [
        "Marco De Luca",
        "Sergio Di Martino",
        "Sergio Di Meglio",
        "Anna Rita Fasolino",
        "Luigi Libero Lucio Starace",
        "Porfirio Tramontana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.12488v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12488",
        "HTML": "https://arxiv.org/html/2507.12488v1",
        "PDF": "https://arxiv.org/pdf/2507.12488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on measuring software quality in student projects and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12489",
      "abstract": "Methods for Novel View Synthesis (NVS) have recently found traction in the field of LiDAR simulation and large-scale 3D scene reconstruction. While solutions for faster rendering or handling dynamic scenes have been proposed, LiDAR specific effects remain insufficiently addressed. By explicitly modeling sensor characteristics such as rolling shutter, laser power variations, and intensity falloff, our method achieves more accurate LiDAR simulation compared to existing techniques. We demonstrate the effectiveness of our approach through quantitative and qualitative comparisons with state-of-the-art methods, as well as ablation studies that highlight the importance of each sensor model component. Beyond that, we show that our approach exhibits advanced resimulation capabilities, such as generating high resolution LiDAR scans in the camera perspective.\n  Our code and the resulting dataset are available at https://github.com/richardmarcus/PBNLiDAR.",
      "authors": [
        "Richard Marcus and Marc Stamminger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T19:49:44+00:00",
          "link": "https://arxiv.org/abs/2507.12489v1",
          "size": "3885kb",
          "version": "v1"
        }
      ],
      "title": "Physically Based Neural LiDAR Resimulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12489",
        "PDF": "https://arxiv.org/pdf/2507.12489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with LiDAR simulation and reconstruction, not related to any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12490",
      "abstract": "We introduce EaGERS, a fully training-free and model-agnostic pipeline that (1) generates natural language rationales via a vision language model, (2) grounds these rationales to spatial sub-regions by computing multimodal embedding similarities over a configurable grid with majority voting, and (3) restricts the generation of responses only from the relevant regions selected in the masked image. Experiments on the DocVQA dataset demonstrate that our best configuration not only outperforms the base model on exact match accuracy and Average Normalized Levenshtein Similarity metrics but also enhances transparency and reproducibility in DocVQA without additional model fine-tuning.",
      "authors": [
        "Maximiliano Hormaz\\'abal Lagos",
        "H\\'ector Cerezo-Costas",
        "Dimosthenis Karatzas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:05:25+00:00",
          "link": "https://arxiv.org/abs/2507.12490v1",
          "size": "1324kb",
          "version": "v1"
        }
      ],
      "title": "Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12490",
        "HTML": "https://arxiv.org/html/2507.12490v1",
        "PDF": "https://arxiv.org/pdf/2507.12490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces EaGERS, a pipeline to enhance document visual question answering using spatially grounded explanations. While it does not mainly focus on LLM data processing, it involves generating natural language rationales which touch on data processing to some extent."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12493",
      "abstract": "Biometric face morphing poses a critical challenge to identity verification systems, undermining their security and robustness. To address this issue, we propose WaFusion, a novel framework combining wavelet decomposition and diffusion models to generate high-quality, realistic morphed face images efficiently. WaFusion leverages the structural details captured by wavelet transforms and the generative capabilities of diffusion models, producing face morphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and WVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art methods, producing high-resolution morphs with fewer artifacts. Our framework excels across key biometric metrics, including the Attack Presentation Classification Error Rate (APCER), Bona Fide Presentation Classification Error Rate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in biometric morph generation, offering a cutting-edge and efficient solution to enhance biometric security systems.",
      "authors": [
        "Seyed Rasoul Hosseini",
        "Omid Ahmadieh",
        "Jeremy Dawson and Nasser Nasrabadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:40:55+00:00",
          "link": "https://arxiv.org/abs/2507.12493v1",
          "size": "12655kb",
          "version": "v1"
        }
      ],
      "title": "WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12493",
        "HTML": "https://arxiv.org/html/2507.12493v1",
        "PDF": "https://arxiv.org/pdf/2507.12493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves face morph generation using wavelet transformation and diffusion models, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12494",
      "abstract": "Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.",
      "authors": [
        "Dustin Holley",
        "Jovin D'sa",
        "Hossein Nourkhiz Mahjoub",
        "Gibran Ali"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:41:00+00:00",
          "link": "https://arxiv.org/abs/2507.12494v1",
          "size": "1239kb",
          "version": "v1"
        }
      ],
      "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12494",
        "HTML": "https://arxiv.org/html/2507.12494v1",
        "PDF": "https://arxiv.org/pdf/2507.12494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving highway merge simulations using a game-theoretic model for decision-making in autonomous vehicle technology. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12496",
      "abstract": "Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is https://sites.google.com/view/founder-rl.",
      "authors": [
        "Yucen Wang",
        "Rui Yu",
        "Shenghua Wan",
        "Le Gan",
        "De-Chuan Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:49:49+00:00",
          "link": "https://arxiv.org/abs/2507.12496v1",
          "size": "6317kb",
          "version": "v1"
        }
      ],
      "title": "FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12496",
        "HTML": "https://arxiv.org/html/2507.12496v1",
        "PDF": "https://arxiv.org/pdf/2507.12496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents FOUNDER, a framework combining foundation models and world models for decision-making in embodied environments, but it does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12498",
      "abstract": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction, which effectively balances rendering quality, efficiency, and speed. However, existing 3DGS approaches usually generate plausible outputs and face significant challenges in complex scene reconstruction, manifesting as incomplete holistic structural outlines and unclear local lighting effects. To address these issues simultaneously, we propose a novel decoupled optimization framework, which integrates wavelet decomposition into 3D Gaussian Splatting and 2D sampling. Technically, through 3D wavelet decomposition, our approach divides point clouds into high-frequency and low-frequency components, enabling targeted optimization for each. The low-frequency component captures global structural outlines and manages the distribution of Gaussians through voxelization. In contrast, the high-frequency component restores intricate geometric and textural details while incorporating a relight module to mitigate lighting artifacts and enhance photorealistic rendering. Additionally, a 2D wavelet decomposition is applied to the training images, simulating radiance variations. This provides critical guidance for high-frequency detail reconstruction, ensuring seamless integration of details with the global structure. Extensive experiments on challenging datasets demonstrate our method achieves state-of-the-art performance across various metrics, surpassing existing approaches and advancing the field of 3D scene reconstruction.",
      "authors": [
        "Beizhen Zhao",
        "Yifan Zhou",
        "Sicheng Yu",
        "Zijian Wang",
        "Hao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T01:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.12498v1",
          "size": "24707kb",
          "version": "v1"
        }
      ],
      "title": "Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12498",
        "HTML": "https://arxiv.org/html/2507.12498v1",
        "PDF": "https://arxiv.org/pdf/2507.12498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel framework for 3D scene reconstruction using wavelet decomposition in Gaussian Splatting. It does not involve LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12499",
      "abstract": "End-to-end autonomous driving has emerged as a promising approach to unify perception, prediction, and planning within a single framework, reducing information loss and improving adaptability. However, existing methods often rely on fixed and sparse trajectory supervision, limiting their ability to capture the hierarchical reasoning process that human drivers naturally employ. To bridge this gap, we propose ReAL-AD, a Reasoning-Augmented Learning framework that structures decision-making in autonomous driving based on the three-tier human cognitive model: Driving Strategy, Driving Decision, and Driving Operation, where Vision-Language Models (VLMs) are incorporated to enhance situational awareness and structured reasoning across these levels. Specifically, we introduce: (1) the Strategic Reasoning Injector, which formulates high-level driving strategies by interpreting complex traffic contexts from VLM-generated insights; (2) the Tactical Reasoning Integrator, which refines strategic intent into interpretable tactical choices such as lane changes, overtaking, and speed adjustments; and (3) the Hierarchical Trajectory Decoder, which progressively translates tactical decisions into precise control actions for smooth and human-like trajectory execution. Extensive evaluations show that integrating our framework improves planning accuracy and safety by over 30%, making end-to-end autonomous driving more interpretable and aligned with human-like hierarchical reasoning. The project page can be found at: \\href{https://4dvlab.github.io/project_page/realad}{\\texttt{4dvlab.github.io/project\\_page/realad}}",
      "authors": [
        "Yuhang Lu",
        "Jiadong Tu",
        "Yuexin Ma",
        "Xinge Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T02:23:24+00:00",
          "link": "https://arxiv.org/abs/2507.12499v1",
          "size": "20339kb",
          "version": "v1"
        }
      ],
      "title": "ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12499",
        "HTML": "https://arxiv.org/html/2507.12499v1",
        "PDF": "https://arxiv.org/pdf/2507.12499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on end-to-end autonomous driving and introduces a framework for improved decision-making using Vision-Language Models, but it does not discuss LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12504",
      "abstract": "Object-centric event logs expand the conventional single-case notion event log by considering multiple objects, allowing for the analysis of more complex and realistic process behavior. However, the number of real-world object-centric event logs remains limited, and further studies are needed to test their usefulness. The increasing availability of data from team sports can facilitate object-centric process mining, leveraging both real-world data and suitable use cases. In this paper, we present a framework for transforming football (soccer) data into an object-centric event log, further enhanced with a spatial dimension. We demonstrate the effectiveness of our framework by generating object-centric event logs based on real-world football data and discuss the results for varying process representations. With our paper, we provide the first example for object-centric event logs in football analytics. Future work should consider variant analysis and filtering techniques to better handle variability",
      "authors": [
        "Vito Chan",
        "Lennart Ebert",
        "Paul-Julius Hillmann",
        "Christoffer Rubensson",
        "Stephan A. Fahrenkrog-Petersen",
        "and Jan Mendling"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:40:29+00:00",
          "link": "https://arxiv.org/abs/2507.12504v1",
          "size": "505kb",
          "version": "v1"
        }
      ],
      "title": "Transforming Football Data into Object-centric Event Logs with Spatial Context Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12504",
        "HTML": "https://arxiv.org/html/2507.12504v1",
        "PDF": "https://arxiv.org/pdf/2507.12504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with transforming football data into object-centric event logs, which is irrelevant to LLM training data processing as it does not involve pretraining or fine-tuning data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12507",
      "abstract": "Recent advancements in reasoning-focused language models such as OpenAI's O1 and DeepSeek-R1 have shown that scaling test-time computation-through chain-of-thought reasoning and iterative exploration-can yield substantial improvements on complex tasks like mathematics and code generation. These breakthroughs have been driven by large-scale reinforcement learning (RL), particularly when combined with verifiable reward signals that provide objective and grounded supervision. In this report, we investigate the effects of prolonged reinforcement learning on a small language model across a diverse set of reasoning domains. Our work identifies several key ingredients for effective training, including the use of verifiable reward tasks, enhancements to Group Relative Policy Optimization (GRPO), and practical techniques to improve training stability and generalization. We introduce controlled KL regularization, clipping ratio, and periodic reference policy resets as critical components for unlocking long-term performance gains. Our model achieves significant improvements over strong baselines, including +14.7% on math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate continued research, we release our model publicly.",
      "authors": [
        "Mingjie Liu",
        "Shizhe Diao",
        "Jian Hu",
        "Ximing Lu",
        "Xin Dong",
        "Hao Zhang",
        "Alexander Bukharin",
        "Shaokun Zhang",
        "Jiaqi Zeng",
        "Makesh Narsimhan Sreedhar",
        "Gerald Shen",
        "David Mosallanezhad",
        "Di Zhang",
        "Jonas Yang",
        "June Yang",
        "Oleksii Kuchaiev",
        "Guilin Liu",
        "Zhiding Yu",
        "Pavlo Molchanov",
        "Yejin Choi",
        "Jan Kautz",
        "Yi Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:24+00:00",
          "link": "https://arxiv.org/abs/2507.12507v1",
          "size": "6704kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12507",
        "HTML": "https://arxiv.org/html/2507.12507v1",
        "PDF": "https://arxiv.org/pdf/2507.12507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates reinforcement learning enhancements for reasoning in LLMs, focusing on training stability and generalization, but is not centered on data processing or dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12508",
      "abstract": "Spatial reasoning in 3D space is central to human cognition and indispensable for embodied tasks such as navigation and manipulation. However, state-of-the-art vision-language models (VLMs) struggle frequently with tasks as simple as anticipating how a scene will look after an egocentric motion: they perceive 2D images but lack an internal model of 3D dynamics. We therefore propose MindJourney, a test-time scaling framework that grants a VLM with this missing capability by coupling it to a controllable world model based on video diffusion. The VLM iteratively sketches a concise camera trajectory, while the world model synthesizes the corresponding view at each step. The VLM then reasons over this multi-view evidence gathered during the interactive exploration. Without any fine-tuning, our MindJourney achieves over an average 8% performance boost on the representative spatial reasoning benchmark SAT, showing that pairing VLMs with world models for test-time scaling offers a simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also improves upon the test-time inference VLMs trained through reinforcement learning, which demonstrates the potential of our method that utilizes world models for test-time scaling.",
      "authors": [
        "Yuncong Yang",
        "Jiageng Liu",
        "Zheyuan Zhang",
        "Siyuan Zhou",
        "Reuben Tan",
        "Jianwei Yang",
        "Yilun Du",
        "Chuang Gan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.12508v1",
          "size": "31209kb",
          "version": "v1"
        }
      ],
      "title": "MindJourney: Test-Time Scaling with World Models for Spatial Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12508",
        "HTML": "https://arxiv.org/html/2507.12508v1",
        "PDF": "https://arxiv.org/pdf/2507.12508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on spatial reasoning using a test-time scaling framework with video diffusion for vision-language models. It does not address data processing operations related to LLM training stages like pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12547",
      "abstract": "When faced with novel situations, people are able to marshal relevant considerations from a wide range of background knowledge and put these to use in inferences and predictions. What permits us to draw in globally relevant information and reason over it coherently? Here, we explore the hypothesis that people use a combination of distributed and symbolic representations to construct bespoke mental models tailored to novel situations. We propose a computational implementation of this idea -- a ``Model Synthesis Architecture'' (MSA) -- using language models to implement global relevance-based retrieval and model synthesis and probabilistic programs to implement bespoke, coherent world models. We evaluate our MSA as a model of human judgments on a novel reasoning dataset. The dataset -- built around a `Model Olympics` domain of sports vignettes -- tests models' capacity for human-like, open-ended reasoning by requiring (i) judgments about novel causal structures described in language; (ii) drawing on large bodies of background knowledge; and (iii) doing both in light of observations that introduce arbitrary novel variables. Our MSA approach captures human judgments better than language model-only baselines, under both direct and chain-of-thought generations from the LM that supports model synthesis. These results suggest that MSAs can be implemented in a way that mirrors people's ability to deliver locally coherent reasoning over globally relevant variables, offering a path to understanding and replicating human reasoning in open-ended domains.",
      "authors": [
        "Lionel Wong",
        "Katherine M. Collins",
        "Lance Ying",
        "Cedegao E. Zhang",
        "Adrian Weller",
        "Tobias Gersternberg",
        "Timothy O'Donnell",
        "Alexander K. Lew",
        "Jacob D. Andreas",
        "Joshua B. Tenenbaum",
        "Tyler Brooke-Wilson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:01:03+00:00",
          "link": "https://arxiv.org/abs/2507.12547v1",
          "size": "12369kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12547",
        "HTML": "https://arxiv.org/html/2507.12547v1",
        "PDF": "https://arxiv.org/pdf/2507.12547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a Model Synthesis Architecture for modeling open-world cognition, focusing on reasoning and model synthesis rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12549",
      "abstract": "While machine learning has advanced through massive parallelization, we identify a critical blind spot: some problems are fundamentally sequential. These \"inherently serial\" problems-from mathematical reasoning to physical simulations to sequential decision-making-require dependent computational steps that cannot be parallelized. Drawing from complexity theory, we formalize this distinction and demonstrate that current parallel-centric architectures face fundamental limitations on such tasks. We argue that recognizing the serial nature of computation holds profound implications on machine learning, model design, hardware development. As AI tackles increasingly complex reasoning, deliberately scaling serial computation-not just parallel computation-is essential for continued progress.",
      "authors": [
        "Yuxi Liu",
        "Konpat Preechakul",
        "Kananart Kuwaranancharoen",
        "Yutong Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Complexity (cs.CC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:01:26+00:00",
          "link": "https://arxiv.org/abs/2507.12549v1",
          "size": "1927kb",
          "version": "v1"
        }
      ],
      "title": "The Serial Scaling Hypothesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12549",
        "HTML": "https://arxiv.org/html/2507.12549v1",
        "PDF": "https://arxiv.org/pdf/2507.12549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the limitations of parallel computation for inherently serial problems and suggests scaling serial computation for complex reasoning tasks, without addressing data processing in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12553",
      "abstract": "Language models (LMs) are used for a diverse range of tasks, from question answering to writing fantastical stories. In order to reliably accomplish these tasks, LMs must be able to discern the modal category of a sentence (i.e., whether it describes something that is possible, impossible, completely nonsensical, etc.). However, recent studies have called into question the ability of LMs to categorize sentences according to modality (Michaelov et al., 2025; Kauf et al., 2023). In this work, we identify linear representations that discriminate between modal categories within a variety of LMs, or modal difference vectors. Analysis of modal difference vectors reveals that LMs have access to more reliable modal categorization judgments than previously reported. Furthermore, we find that modal difference vectors emerge in a consistent order as models become more competent (i.e., through training steps, layers, and parameter count). Notably, we find that modal difference vectors identified within LM activations can be used to model fine-grained human categorization behavior. This potentially provides a novel view into how human participants distinguish between modal categories, which we explore by correlating projections along modal difference vectors with human participants' ratings of interpretable features. In summary, we derive new insights into LM modal categorization using techniques from mechanistic interpretability, with the potential to inform our understanding of modal categorization in humans.",
      "authors": [
        "Michael A. Lepori",
        "Jennifer Hu",
        "Ishita Dasgupta",
        "Roma Patel",
        "Thomas Serre",
        "Ellie Pavlick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:04:26+00:00",
          "link": "https://arxiv.org/abs/2507.12553v1",
          "size": "659kb",
          "version": "v1"
        }
      ],
      "title": "Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12553",
        "HTML": "https://arxiv.org/html/2507.12553v1",
        "PDF": "https://arxiv.org/pdf/2507.12553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes modal categorization capabilities in language models, focusing on interpretability and human judgment modeling rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12555",
      "abstract": "Although existing models can interact with humans and provide satisfactory responses, they lack the ability to act autonomously or engage in independent reasoning. Furthermore, input data in these models is typically provided as explicit queries, even when some sensory data is already acquired.\n  In addition, AI agents, which are computational entities designed to perform tasks and make decisions autonomously based on their programming, data inputs, and learned knowledge, have shown significant progress. However, they struggle with integrating knowledge across multiple domains, unlike humans.\n  Mental imagery plays a fundamental role in the brain's thinking process, which involves performing tasks based on internal multisensory data, planned actions, needs, and reasoning capabilities. In this paper, we investigate how to integrate mental imagery into a machine thinking framework and how this could be beneficial in initiating the thinking process. Our proposed machine thinking framework integrates a Cognitive thinking unit supported by three auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery Unit. Within this framework, data is represented as natural language sentences or drawn sketches, serving both informative and decision-making purposes. We conducted validation tests for this framework, and the results are presented and discussed.",
      "authors": [
        "Slimane Larabi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.12555v1",
          "size": "3305kb",
          "version": "v1"
        }
      ],
      "title": "Can Mental Imagery Improve the Thinking Capabilities of AI Systems?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12555",
        "HTML": "https://arxiv.org/html/2507.12555v1",
        "PDF": "https://arxiv.org/pdf/2507.12555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates integrating mental imagery into AI systems for enhanced decision-making, without discussing any LLM training data processing techniques or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12557",
      "abstract": "Laser powder bed fusion (LPBF) is an additive manufacturing technique that has gained popularity thanks to its ability to produce geometrically complex, fully dense metal parts. However, these parts are prone to internal defects and geometric inaccuracies, stemming in part from variations in the melt pool. This paper proposes a novel vector-level feedforward control framework for regulating melt pool area in LPBF. By decoupling part-scale thermal behavior from small-scale melt pool physics, the controller provides a scale-agnostic prediction of melt pool area and efficient optimization over it. This is done by operating on two coupled lightweight models: a finite-difference thermal model that efficiently captures vector-level temperature fields and a reduced-order, analytical melt pool model. Each model is calibrated separately with minimal single-track and 2D experiments, and the framework is validated on a complex 3D geometry in both Inconel 718 and 316L stainless steel. Results showed that feedforward vector-level laser power scheduling reduced geometric inaccuracy in key dimensions by 62%, overall porosity by 16.5%, and photodiode variation by 6.8% on average. Overall, this modular, data-efficient approach demonstrates that proactively compensating for known thermal effects can significantly improve part quality while remaining computationally efficient and readily extensible to other materials and machines.",
      "authors": [
        "Nicholas Kirschbaum",
        "Nathaniel Wood",
        "Chang-Eun Kim",
        "Thejaswi U. Tumkur",
        "Chinedum Okwudire"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.12557v1",
          "size": "37151kb",
          "version": "v1"
        }
      ],
      "title": "Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12557",
        "HTML": "https://arxiv.org/html/2507.12557v1",
        "PDF": "https://arxiv.org/pdf/2507.12557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a feedforward control framework for laser powder bed fusion in additive manufacturing, which involves thermal modeling and process optimization, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12558",
      "abstract": "Automatically generating concise, informative comments for source code can lighten documentation effort and accelerate program comprehension. Retrieval-augmented approaches first fetch code snippets with existing comments and then synthesize a new comment, yet retrieval and generation are typically optimized in isolation, allowing irrelevant neighbors topropagate noise downstream. To tackle the issue, we propose a novel approach named RAGSum with the aim of both effectiveness and efficiency in recommendations. RAGSum is built on top offuse retrieval and generation using a single CodeT5 backbone. We report preliminary results on a unified retrieval-generation framework built on CodeT5. A contrastive pre-training phase shapes code embeddings for nearest-neighbor search; these weights then seed end-to-end training with a composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes comment-generation error. More importantly, a lightweight self-refinement loop is deployed to polish the final output. We evaluated theframework on three cross-language benchmarks (Java, Python, C), and compared it with three well-established baselines. The results show that our approach substantially outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These findings indicate that tightly coupling retrieval and generationcan raise the ceiling for comment automation and motivateforthcoming replications and qualitative developer studies.",
      "authors": [
        "Tien P. T. Le",
        "Anh M. T. Bui",
        "Huy N. D. Pham",
        "Alessio Bucaioni",
        "Phuong T. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:12:27+00:00",
          "link": "https://arxiv.org/abs/2507.12558v1",
          "size": "3076kb",
          "version": "v1"
        }
      ],
      "title": "When Retriever Meets Generator: A Joint Model for Code Comment Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12558",
        "HTML": "https://arxiv.org/html/2507.12558v1",
        "PDF": "https://arxiv.org/pdf/2507.12558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a joint model for code comment generation, focusing on retrieval and generation techniques for code snippets. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12561",
      "abstract": "Architectural smells such as God Class, Cyclic Dependency, and Hub-like Dependency degrade software quality and maintainability. Existing tools detect such smells but rarely suggest how to fix them. This paper explores the use of pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable refactorings based on detected smells. We frame the task as a three-class classification problem and fine-tune both models on over 2 million refactoring instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9% accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our results show that transformer-based models can effectively bridge the gap between smell detection and actionable repair, laying the foundation for future refactoring recommendation systems. We release all code, models, and data under an open license to support reproducibility and further research.",
      "authors": [
        "Samal Nursapa",
        "Anastassiya Samuilova",
        "Alessio Bucaioni. Phuong T. Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:19:51+00:00",
          "link": "https://arxiv.org/abs/2507.12561v1",
          "size": "1183kb",
          "version": "v1"
        }
      ],
      "title": "ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12561",
        "PDF": "https://arxiv.org/pdf/2507.12561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the fine-tuning of transformer models for a task (refactoring recommendation for architectural smells), mentioning pre-trained models and fine-tuning but does not focus on LLM-specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12562",
      "abstract": "Relational databases (RDBs) are ubiquitous in enterprise and real-world applications. Flattening the database poses challenges for deep learning models that rely on fixed-size input representations to capture relational semantics from the structured nature of relational data. Graph neural networks (GNNs) have been proposed to address this, but they often oversimplify relational structures by modeling all the tuples as monolithic nodes and ignoring intra-tuple associations. In this work, we propose a novel hypergraph-based framework, that we call rel-HNN, which models each unique attribute-value pair as a node and each tuple as a hyperedge, enabling the capture of fine-grained intra-tuple relationships. Our approach learns explicit multi-level representations across attribute-value, tuple, and table levels. To address the scalability challenges posed by large RDBs, we further introduce a split-parallel training algorithm that leverages multi-GPU execution for efficient hypergraph learning. Extensive experiments on real-world and benchmark datasets demonstrate that rel-HNN significantly outperforms existing methods in both classification and regression tasks. Moreover, our split-parallel training achieves substantial speedups -- up to 3.18x for learning on relational data and up to 2.94x for hypergraph learning -- compared to conventional single-GPU execution.",
      "authors": [
        "Md. Tanvir Alam",
        "Md. Ahasanul Alam",
        "Md Mahmudur Rahman",
        "Md. Mosaddek Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:20:45+00:00",
          "link": "https://arxiv.org/abs/2507.12562v1",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "title": "Rel-HNN: Split Parallel Hypergraph Neural Network for Learning on Relational Databases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12562",
        "HTML": "https://arxiv.org/html/2507.12562v1",
        "PDF": "https://arxiv.org/pdf/2507.12562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a hypergraph-based framework for learning on relational databases, focusing on neural network architectures and scalability rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12563",
      "abstract": "Physical modelling synthesis aims to generate audio from physical simulations of vibrating structures. Thin elastic plates are a common model for drum membranes. Traditional numerical methods like finite differences and finite elements offer high accuracy but are computationally demanding, limiting their use in real-time audio applications. This paper presents a comparative analysis of neural network-based approaches for solving the vibration of nonlinear elastic plates. We evaluate several state-of-the-art models, trained on short sequences, for prediction of long sequences in an autoregressive fashion. We show some of the limitations of these models, and why is not enough to look at the prediction error in the time domain. We discuss the implications for real-time audio synthesis and propose future directions for improving neural approaches to model nonlinear vibration.",
      "authors": [
        "Carlos De La Vega Martin",
        "Rodrigo Diaz Fernandez",
        "Mark Sandler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:25:11+00:00",
          "link": "https://arxiv.org/abs/2507.12563v1",
          "size": "1328kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Neural Surrogates for Physical Modelling Synthesis of Nonlinear Elastic Plates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12563",
        "HTML": "https://arxiv.org/html/2507.12563v1",
        "PDF": "https://arxiv.org/pdf/2507.12563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on audio synthesis using neural networks for simulating physical vibrations, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12566",
      "abstract": "This paper focuses on monolithic Multimodal Large Language Models (MLLMs), which integrate visual encoding and language decoding into a single model. Existing structures and pre-training strategies for monolithic MLLMs often suffer from unstable optimization and catastrophic forgetting. To address these challenges, our key idea is to embed a new visual parameter space into a pre-trained LLM, enabling stable learning of visual knowledge from noisy data via delta tuning. Based on this principle, we first introduce Mono-InternVL, an advanced monolithic MLLM that incorporates a set of visual experts through a multimodal mixture-of-experts architecture. In addition, we design an innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize its visual capabilities via progressive learning. Mono-InternVL achieves competitive performance against existing MLLMs but also leads to relatively expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++ introduces additional visual attention experts to Mono-InternVL-1.5 and re-organizes the pre-training process in an efficient manner. During inference, it includes a fused CUDA kernel to speed up its MoE operations. With these designs, Mono-InternVL-1.5 significantly reduces training and inference costs, while still maintaining competitive performance with Mono-InternVL. To evaluate our approach, we conduct extensive experiments across 15 benchmarks. Results demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves similar multimodal performance while reducing first-token latency by up to 69%. Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.",
      "authors": [
        "Gen Luo",
        "Wenhan Dou",
        "Wenhao Li",
        "Zhaokai Wang",
        "Xue Yang",
        "Changyao Tian",
        "Hao Li",
        "Weiyun Wang",
        "Wenhai Wang",
        "Xizhou Zhu",
        "Yu Qiao",
        "Jifeng Dai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:31:23+00:00",
          "link": "https://arxiv.org/abs/2507.12566v1",
          "size": "5133kb",
          "version": "v1"
        }
      ],
      "title": "Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12566",
        "HTML": "https://arxiv.org/html/2507.12566v1",
        "PDF": "https://arxiv.org/pdf/2507.12566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper centers on the development and optimization of monolithic multimodal large language models and mentions data efficiency, but lacks specific details about training data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12568",
      "abstract": "Federated Learning (FL) has emerged as a promising solution for privacy-preserving autonomous driving, specifically camera-based Road Condition Classification (RCC) systems, harnessing distributed sensing, computing, and communication resources on board vehicles without sharing sensitive image data. However, the collaborative nature of FL-RCC frameworks introduces new vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious clients (vehicles) deliberately alter their training data labels to compromise the learned model inference performance. Such attacks can, e.g., cause a vehicle to mis-classify slippery, dangerous road conditions as pristine and exceed recommended speed. However, TLFAs for FL-based RCC systems are largely missing. We address this challenge with a threefold contribution: 1) we disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce a novel label-distance-based metric to precisely quantify the safety risks posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive experiments across three RCC tasks, four evaluation metrics, six baselines, and three deep learning models demonstrate both the severity of TLFAs on FL-RCC systems and the effectiveness of FLARE in mitigating the attack impact.",
      "authors": [
        "Sheng Liu and Panos Papadimitratos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:33:29+00:00",
          "link": "https://arxiv.org/abs/2507.12568v1",
          "size": "3501kb",
          "version": "v1"
        }
      ],
      "title": "Safeguarding Federated Learning-based Road Condition Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12568",
        "HTML": "https://arxiv.org/html/2507.12568v1",
        "PDF": "https://arxiv.org/pdf/2507.12568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about federated learning in road condition classification and addresses security vulnerabilities without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12569",
      "abstract": "Black start (BS) of the distribution system (DS) with high penetration of distributed energy resources (DERs) requires advanced control frameworks to ensure secure and efficient restoration. This paper proposes a model predictive black start (MPBS) framework incorporating an inrush current feasibility module to dynamically generate real-time feasible and optimal restoration sequences. Short-term forecasts of DER output and transmission grid (TG) availability are utilized to construct adaptive cranking paths. The inrush current feasibility module analytically estimates the transient inrush current caused by energizing no-load distribution transformers (DTs). To mitigate excessive inrush current and avoid potential misoperations of protection devices, an emergency operation-inspired voltage control strategy and a switch blocking mechanism are developed. The proposed inrush model is validated against electromagnetic transient (EMT) simulations in PowerFactory with estimation accuracies exceeding 90 %. Case studies on a modified IEEE 123-node feeder demonstrate that the MPBS framework prevents misoperations of fuses and reclosers, reduces unnecessary DER energy consumption, and enhances load restoration efficiency during DER-led BS processes.",
      "authors": [
        "Cong Bai",
        "Salish Maharjan",
        "Zhaoyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:33:46+00:00",
          "link": "https://arxiv.org/abs/2507.12569v1",
          "size": "2630kb",
          "version": "v1"
        }
      ],
      "title": "Model Predictive Black Start for Dynamic Formation of DER-Led Microgrids with Inrush Current Impacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12569",
        "HTML": "https://arxiv.org/html/2507.12569v1",
        "PDF": "https://arxiv.org/pdf/2507.12569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on model predictive control for electric grid management involving distributed energy resources, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12571",
      "abstract": "The prevalence of short form video platforms, combined with the ineffectiveness of age verification mechanisms, raises concerns about the potential harms facing children and teenagers in an algorithm-moderated online environment. We conducted multimodal feature analysis and thematic topic modeling of 4,492 short videos recommended to children and teenagers on Instagram Reels, TikTok, and YouTube Shorts, collected as a part of an algorithm auditing experiment. This feature-level and content-level analysis revealed that unsafe (i.e., problematic, mentally distressing) short videos (a) possess darker visual features and (b) contain explicitly harmful content and implicit harm from anxiety-inducing ordinary content. We introduce a useful framework of online harm (i.e., explicit, implicit, unintended), providing a unique lens for understanding the dynamic, multifaceted online risks facing children and teenagers. The findings highlight the importance of protecting younger audiences in critical developmental stages from both explicit and implicit risks on social media, calling for nuanced content moderation, age verification, and platform regulation.",
      "authors": [
        "Haoning Xue",
        "Brian Nishimine",
        "Martin Hilbert",
        "Drew Cingel",
        "Samantha Vigil",
        "Jane Shawcroft",
        "Arti Thakur",
        "Zubair Shafiq",
        "Jingwen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:41:42+00:00",
          "link": "https://arxiv.org/abs/2507.12571v1",
          "size": "953kb",
          "version": "v1"
        }
      ],
      "title": "Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12571",
        "HTML": "https://arxiv.org/html/2507.12571v1",
        "PDF": "https://arxiv.org/pdf/2507.12571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the analysis of audiovisual content recommended to children on social media platforms and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12573",
      "abstract": "Data streams pose challenges not usually encountered in batch-based ML. One of them is concept drift, which is characterized by the change in data distribution over time. Among many approaches explored in literature, the fusion of classifiers has been showing good results and is getting growing attention. DS methods, due to the ensemble being instance-based, seem to be an efficient choice under drifting scenarios. However, some attention must be paid to adapting such methods for concept drift. The training must be done in order to create local experts, and the commonly used neighborhood-search DS may become prohibitive with the continuous arrival of data. In this work, we propose IncA-DES, which employs a training strategy that promotes the generation of local experts with the assumption that different regions of the feature space become available with time. Additionally, the fusion of a concept drift detector supports the maintenance of information and adaptation to a new concept. An overlap-based classification filter is also employed in order to avoid using the DS method when there is a consensus in the neighborhood, a strategy that we argue every DS method should employ, as it was shown to make them more applicable and quicker. Moreover, aiming to reduce the processing time of the kNN, we propose an Online K-d tree algorithm, which can quickly remove instances without becoming inconsistent and deals with unbalancing concerns that may occur in data streams. Experimental results showed that the proposed framework got the best average accuracy compared to seven state-of-the-art methods considering different levels of label availability and presented the smaller processing time between the most accurate methods. Additionally, the fusion with the Online K-d tree has improved processing time with a negligible loss in accuracy. We have made our framework available in an online repository.",
      "authors": [
        "Eduardo V. L. Barboza",
        "Paulo R. Lisboa de Almeida",
        "Alceu de Souza Britto Jr.",
        "Robert Sabourin",
        "Rafael M. O. Cruz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:42:12+00:00",
          "link": "https://arxiv.org/abs/2507.12573v1",
          "size": "736kb",
          "version": "v1"
        }
      ],
      "title": "IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12573",
        "HTML": "https://arxiv.org/html/2507.12573v1",
        "PDF": "https://arxiv.org/pdf/2507.12573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with algorithm adaptation for data streams with concept drift and classifier fusion, but it does not focus on LLM training data processing or the creation and improvement of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12574",
      "abstract": "Scientific databases aggregate vast amounts of quantitative data alongside descriptive text. In biochemistry, molecule screening assays evaluate the functional responses of candidate molecules against disease targets. Unstructured text that describes the biological mechanisms through which these targets operate, experimental screening protocols, and other attributes of assays offer rich information for new drug discovery campaigns but has been untapped because of that unstructured format. We present Assay2Mol, a large language model-based workflow that can capitalize on the vast existing biochemical screening assays for early-stage drug discovery. Assay2Mol retrieves existing assay records involving targets similar to the new target and generates candidate molecules using in-context learning with the retrieved assay screening data. Assay2Mol outperforms recent machine learning approaches that generate candidate ligand molecules for target protein structures, while also promoting more synthesizable molecule generation.",
      "authors": [
        "Yifan Deng",
        "Spencer S. Ericksen",
        "Anthony Gitter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:42:18+00:00",
          "link": "https://arxiv.org/abs/2507.12574v1",
          "size": "3397kb",
          "version": "v1"
        }
      ],
      "title": "Assay2Mol: large language model-based drug design using BioAssay context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12574",
        "PDF": "https://arxiv.org/pdf/2507.12574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on LLM-based drug design using biochemical screening assays. It does not relate to LLM training data processing as it focuses on applications in drug discovery within the field of biochemistry."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12578",
      "abstract": "Accurate modeling and control of autonomous vehicles remain a fundamental challenge due to the nonlinear and coupled nature of vehicle dynamics. While Koopman operator theory offers a framework for deploying powerful linear control techniques, learning a finite-dimensional invariant subspace for high-fidelity modeling continues to be an open problem. This paper presents a deep Koopman approach for modeling and control of vehicle dynamics within the curvilinear Frenet frame. The proposed framework uses a deep neural network architecture to simultaneously learn the Koopman operator and its associated invariant subspace from the data. Input-state bilinear interactions are captured by the algorithm while preserving convexity, which makes it suitable for real-time model predictive control (MPC) application. A multi-step prediction loss is utilized during training to ensure long-horizon prediction capability. To further enhance real-time trajectory tracking performance, the model is integrated with a cumulative error regulator (CER) module, which compensates for model mismatch by mitigating accumulated prediction errors. Closed-loop performance is evaluated through hardware-in-the-loop (HIL) experiments using a CarSim RT model as the target plant, with real-time validation conducted on a dSPACE SCALEXIO system. The proposed controller achieved significant reductions in tracking error relative to baseline controllers, confirming its suitability for real-time implementation in embedded autonomous vehicle systems.",
      "authors": [
        "Mohammad Abtahi",
        "Farhang Motallebi Araghi",
        "Navid Mojahed",
        "Shima Nazari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:49:44+00:00",
          "link": "https://arxiv.org/abs/2507.12578v1",
          "size": "9878kb",
          "version": "v1"
        }
      ],
      "title": "Deep Bilinear Koopman Model for Real-Time Vehicle Control in Frenet Frame",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12578",
        "HTML": "https://arxiv.org/html/2507.12578v1",
        "PDF": "https://arxiv.org/pdf/2507.12578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses modeling and control of vehicle dynamics using a deep Koopman approach, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12580",
      "abstract": "This study explores how age and language shape the deliberate vocal expression of emotion, addressing underexplored user groups, Teenagers (N = 12) and Adults 55+ (N = 12), within speech emotion recognition (SER). While most SER systems are trained on spontaneous, monolingual English data, our research evaluates how such models interpret intentionally performed emotional speech across age groups and languages (Danish and English). To support this, we developed a novel experimental paradigm combining a custom user interface with a backend for real-time SER prediction and data logging. Participants were prompted to hit visual targets in valence-arousal space by deliberately expressing four emotion targets. While limitations include some reliance on self-managed voice recordings and inconsistent task execution, the results suggest contrary to expectations, no significant differences between language or age groups, and a degree of cross-linguistic and age robustness in model interpretation. Though some limitations in high-arousal emotion recognition were evident. Our qualitative findings highlight the need to move beyond system-centered accuracy metrics and embrace more inclusive, human-centered SER models. By framing emotional expression as a goal-directed act and logging the real-time gap between human intent and machine interpretation, we expose the risks of affective misalignment.",
      "authors": [
        "Josephine Beatrice Skovbo Borre",
        "Malene Gorm Wold",
        "Sara Kj{\\ae}r Rasmussen",
        "Ilhan Aslan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:52:55+00:00",
          "link": "https://arxiv.org/abs/2507.12580v1",
          "size": "3062kb",
          "version": "v1"
        }
      ],
      "title": "\"How to Explore Biases in Speech Emotion AI with Users?\" A Speech-Emotion-Acting Study Exploring Age and Language Biases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12580",
        "HTML": "https://arxiv.org/html/2507.12580v1",
        "PDF": "https://arxiv.org/pdf/2507.12580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research explores biases in speech emotion AI systems but does not address aspects of LLM training data processing or enhancements related to LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12582",
      "abstract": "Pinching-antenna technology has lately showcased its promising capability for reconfiguring wireless propagation environments, especially in high-frequency communication systems like millimeter-wave and terahertz bands. By dynamically placing the antenna over a dielectric waveguide, line-of-sight (LoS) connections can be made to significantly improve system performance. Although recent research have illustrated the advantages of pinching-antenna-assisted designs, they mainly presuppose complete knowledge of user locations -- an impractical assumption in real-world systems. To address this issue, the robust resource allocation in a multi-user pinching antenna downlink system with uncertain user positions is investigated, aiming to minimize total transmit power while satisfying individual outage probability constraints. First, we address the single-user case, deriving the optimal pinching antenna position and obtaining the corresponding power allocation using a bisection method combined with geometric analysis. We then extend this solution to the multi-user case. In this case, we optimize the pinching antenna position using a particle swarm optimization (PSO) algorithm to handle the resulting non-convex and non-differentiable optimization problem. Simulation results demonstrate that the proposed scheme outperforms conventional fixed-antenna systems and validate the effectiveness of the PSO-based antenna placement strategy under location uncertainty.",
      "authors": [
        "Ming Zeng",
        "Xianbin Wang",
        "Yuanwei Liu",
        "Zhiguo Ding",
        "George K. Karagiannidis and H. Vincent Poor"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:59:57+00:00",
          "link": "https://arxiv.org/abs/2507.12582v1",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "title": "Robust Resource Allocation for Pinching-Antenna Systems under Imperfect CSI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12582",
        "HTML": "https://arxiv.org/html/2507.12582v1",
        "PDF": "https://arxiv.org/pdf/2507.12582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses resource allocation and optimization for pinching-antenna systems in wireless communication, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12583",
      "abstract": "We study the problem of clustering ranking vectors, where each vector represents preferences as an ordered list of distinct integers. Specifically, we focus on the k-centroids ranking vectors clustering problem (KRC), which aims to partition a set of ranking vectors into k clusters and identify the centroid of each cluster. Unlike classical k-means clustering (KMC), KRC constrains both the observations and centroids to be ranking vectors. We establish the NP-hardness of KRC and characterize its feasible set. For the single-cluster case, we derive a closed-form analytical solution for the optimal centroid, which can be computed in linear time. To address the computational challenges of KRC, we develop an efficient approximation algorithm, KRCA, which iteratively refines initial solutions from KMC, referred to as the baseline solution. Additionally, we introduce a branch-and-bound (BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a decision tree framework to reduce computational time while incorporating a controlling parameter to balance solution quality and efficiency. We establish theoretical error bounds for KRCA and BnB. Through extensive numerical experiments on synthetic and real-world datasets, we demonstrate that KRCA consistently outperforms baseline solutions, delivering significant improvements in solution quality with fast computational times. This work highlights the practical significance of KRC for personalization and large-scale decision making, offering methodological advancements and insights that can be built upon in future studies.",
      "authors": [
        "Ali Fattahi and Ali Eshragh and Babak Aslani and Meysam Rabiee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Complexity (cs.CC)",
        "Applications (stat.AP)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:00:09+00:00",
          "link": "https://arxiv.org/abs/2507.12583v1",
          "size": "4510kb",
          "version": "v1"
        }
      ],
      "title": "Ranking Vectors Clustering: Theory and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12583",
        "HTML": "https://arxiv.org/html/2507.12583v1",
        "PDF": "https://arxiv.org/pdf/2507.12583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on clustering ranking vectors and developing algorithms for the k-centroids ranking vectors clustering problem. It does not address LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12584",
      "abstract": "We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a related problem called cost-sensitive classification, \\citet{foster21efficient} have shown that the log loss minimizer achieves an improved generalization bound compared to that of the squared loss minimizer in the sense that the bound scales with the cost of the best classifier, which can be arbitrarily small depending on the problem at hand. Such a result is often called a first-order bound. For $[0,1]$-valued regression, we first show that the log loss minimizer leads to a similar first-order bound. We then ask if there exists a loss function that achieves a variance-dependent bound (also known as a second order bound), which is a strict improvement upon first-order bounds. We answer this question in the affirmative by proposing a novel loss function called the betting loss. Our result is ``variance-adaptive'' in the sense that the bound is attained \\textit{without any knowledge about the variance}, which is in contrast to modeling label (or reward) variance or the label distribution itself explicitly as part of the function class such as distributional reinforcement learning.",
      "authors": [
        "Yinan Li",
        "Kwang-Sung Jun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:09:58+00:00",
          "link": "https://arxiv.org/abs/2507.12584v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Second-Order Bounds for [0,1]-Valued Regression via Betting Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12584",
        "HTML": "https://arxiv.org/html/2507.12584v1",
        "PDF": "https://arxiv.org/pdf/2507.12584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with regression bounds and a novel loss function for improving generalization in regression problems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12590",
      "abstract": "Crop mapping involves identifying and classifying crop types using spatial data, primarily derived from remote sensing imagery. This study presents the first comprehensive review of large-scale, pixel-wise crop mapping workflows, encompassing both conventional supervised methods and emerging transfer learning approaches. To identify the optimal supervised crop mapping workflows, we conducted systematic experiments, comparing six widely adopted satellite image-based preprocessing methods, alongside eleven supervised pixel-wise classification models. Additionally, we assessed the synergistic impact of varied training sample sizes and variable combinations. Moreover, we identified optimal transfer learning techniques for different magnitudes of domain shift. The evaluation of best methods was conducted across five diverse agricultural sites. Landsat 8 served as the primary satellite data source. Labels come from CDL trusted pixels and field surveys.\n  Our findings reveal three key insights. First, fine-scale interval preprocessing paired with Transformer models consistently delivered optimal performance for both supervised and transferable workflows. RF offered rapid training and competitive performance in conventional supervised learning and direct transfer to similar domains. Second, transfer learning techniques enhanced workflow adaptability, with UDA being effective for homogeneous crop classes while fine-tuning remains robust across diverse scenarios. Finally, workflow choice depends heavily on the availability of labeled samples. With a sufficient sample size, supervised training typically delivers more accurate and generalizable results. Below a certain threshold, transfer learning that matches the level of domain shift is a viable alternative to achieve crop mapping. Repository: Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows",
      "authors": [
        "Judy Long",
        "Tao Liu",
        "Sean Alexander Woznicki",
        "Miljana Markovi\\'c",
        "Oskar Marko",
        "Molly Sears"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:18:25+00:00",
          "link": "https://arxiv.org/abs/2507.12590v1",
          "size": "8912kb",
          "version": "v1"
        }
      ],
      "title": "Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12590",
        "HTML": "https://arxiv.org/html/2507.12590v1",
        "PDF": "https://arxiv.org/pdf/2507.12590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study reviews large-scale crop mapping workflows using spatial data and remote sensing imagery but does not involve LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12591",
      "abstract": "Understanding radiologists' eye movement during Computed Tomography (CT) reading is crucial for developing effective interpretable computer-aided diagnosis systems. However, CT research in this area has been limited by the lack of publicly available eye-tracking datasets and the three-dimensional complexity of CT volumes. To address these challenges, we present the first publicly available eye gaze dataset on CT, called CT-ScanGaze. Then, we introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to process CT volumes and generate radiologist-like 3D fixation sequences, overcoming the limitations of current scanpath predictors that only handle 2D inputs. Since deep learning models benefit from a pretraining step, we develop a pipeline that converts existing 2D gaze datasets into 3D gaze data to pretrain CT-Searcher. Through both qualitative and quantitative evaluations on CT-ScanGaze, we demonstrate the effectiveness of our approach and provide a comprehensive assessment framework for 3D scanpath prediction in medical imaging.",
      "authors": [
        "Trong-Thang Pham",
        "Akash Awasthi",
        "Saba Khan",
        "Esteban Duran Marti",
        "Tien-Phat Nguyen",
        "Khoa Vo",
        "Minh Tran",
        "Ngoc Son Nguyen",
        "Cuong Tran Van",
        "Yuki Ikebe",
        "Anh Totti Nguyen",
        "Anh Nguyen",
        "Zhigang Deng",
        "Carol C. Wu",
        "Hien Van Nguyen",
        "Ngan Le"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:21:05+00:00",
          "link": "https://arxiv.org/abs/2507.12591v1",
          "size": "15493kb",
          "version": "v1"
        }
      ],
      "title": "CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12591",
        "HTML": "https://arxiv.org/html/2507.12591v1",
        "PDF": "https://arxiv.org/pdf/2507.12591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset and method for 3D gaze prediction in CT scans, relevant to computer-aided diagnosis, but unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12596",
      "abstract": "A simple, interpretable way to perform automatic drum transcription is by factoring the magnitude spectrogram of a recorded musical piece using a partially fixed nonnegative matrix factorization. There are two natural ways to optimize the nonnegative matrix factorization, including a multiplicative update rule and projected gradient descent with momentum. The methods differ in their empirical accuracies and theoretical convergence guarantees. This paper summarizes the methods and their time complexities, and it applies the methods to the ENST-Drums data set and an original recording from the author's band, evaluating the empirical accuracy with respect to ground-truth drum annotations. The results indicate that projected gradient descent with momentum leads to higher accuracy for a fixed runtime, and it satisfies stronger convergence guarantees.",
      "authors": [
        "Alisha L. Foster and Robert J. Webber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:33:22+00:00",
          "link": "https://arxiv.org/abs/2507.12596v1",
          "size": "256kb",
          "version": "v1"
        }
      ],
      "title": "Keep the beat going: Automatic drum transcription with momentum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12596",
        "HTML": "https://arxiv.org/html/2507.12596v1",
        "PDF": "https://arxiv.org/pdf/2507.12596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses automatic drum transcription using nonnegative matrix factorization, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12599",
      "abstract": "The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions \"What\" and \"How\". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.",
      "authors": [
        "L\\'eo Sauli\\`eres"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:41:41+00:00",
          "link": "https://arxiv.org/abs/2507.12599v1",
          "size": "8335kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12599",
        "HTML": "https://arxiv.org/html/2507.12599v1",
        "PDF": "https://arxiv.org/pdf/2507.12599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on explainable reinforcement learning (XRL) and its methods, and does not address any aspects of data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12600",
      "abstract": "Simulating hair dynamics that generalize across arbitrary hairstyles, body shapes, and motions is a critical challenge. Our novel two-stage neural solution is the first to leverage Transformer-based architectures for such a broad generalization. We propose a Transformer-powered static network that predicts static draped shapes for any hairstyle, effectively resolving hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic network with a novel cross-attention mechanism fuses static hair features with kinematic input to generate expressive dynamics and complex secondary motions. This dynamic network also allows for efficient fine-tuning of challenging motion sequences, such as abrupt head movements. Our method offers real-time inference for both static single-frame drapes and dynamic drapes over pose sequences. Our method demonstrates high-fidelity and generalizable dynamic hair across various styles, guided by physics-informed losses, and can resolve penetrations even for complex, unseen long hairstyles, highlighting its broad generalization.",
      "authors": [
        "Joy Xiaoji Zhang",
        "Jingsen Zhu",
        "Hanyu Chen",
        "Steve Marschner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:42:08+00:00",
          "link": "https://arxiv.org/abs/2507.12600v1",
          "size": "30241kb",
          "version": "v1"
        }
      ],
      "title": "HairFormer: Transformer-Based Dynamic Neural Hair Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12600",
        "HTML": "https://arxiv.org/html/2507.12600v1",
        "PDF": "https://arxiv.org/pdf/2507.12600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hair simulation using a transformer-based architecture, unrelated to any data processing relevant to LLM training methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12602",
      "abstract": "Tree species classification from terrestrial LiDAR point clouds is challenging because of the complex multi-scale geometric structures in forest environments. Existing approaches using multi-scale dynamic graph convolutional neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails to capture the semantic relationships between the hierarchical levels of the tree architecture. We present MS-DGCNN++, a hierarchical multiscale fusion dynamic graph convolutional network that uses semantically meaningful feature extraction at local, branch, and canopy scales with cross-scale information propagation. Our method employs scale-specific feature engineering, including standard geometric features for the local scale, normalized relative vectors for the branch scale, and distance information for the canopy scale. This hierarchical approach replaces uniform parallel processing with semantically differentiated representations that are aligned with the natural tree structure. Under the same proposed tree species data augmentation strategy for all experiments, MS-DGCNN++ achieved an accuracy of 94.96 \\% on STPCTLS, outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. On FOR-species20K, it achieves 67.25\\% accuracy (6.1\\% improvement compared to MS-DGCNN). For standard 3D object recognition, our method outperformed DGCNN and MS-DGCNN with overall accuracies of 93.15\\% on ModelNet40 and 94.05\\% on ModelNet10. With lower parameters and reduced complexity compared to state-of-the-art transformer approaches, our method is suitable for resource-constrained applications while maintaining a competitive accuracy. Beyond tree classification, the method generalizes to standard 3D object recognition, establishing it as a versatile solution for diverse point cloud processing applications. The implementation code is publicly available at https://github.com/said-ohamouddou/MS-DGCNN2.",
      "authors": [
        "Said Ohamouddou",
        "Abdellatif El Afia",
        "Hanaa El Afia",
        "Raddouane Chiheb"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:44:23+00:00",
          "link": "https://arxiv.org/abs/2507.12602v1",
          "size": "3184kb",
          "version": "v1"
        }
      ],
      "title": "MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12602",
        "HTML": "https://arxiv.org/html/2507.12602v1",
        "PDF": "https://arxiv.org/pdf/2507.12602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces MS-DGCNN++ for LiDAR tree species classification and 3D object recognition, which is not connected to LLM training data processing tasks or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12604",
      "abstract": "Effectively representing heterogeneous tabular datasets for meta-learning purposes is still an open problem. Previous approaches rely on representations that are intended to be universal. This paper proposes two novel methods for tabular representation learning tailored to a specific meta-task - warm-starting Bayesian Hyperparameter Optimization. Both follow the specific requirement formulated by ourselves that enforces representations to capture the properties of landmarkers. The first approach involves deep metric learning, while the second one is based on landmarkers reconstruction. We evaluate the proposed encoders in two ways. Next to the gain in the target meta-task, we also use the degree of fulfillment of the proposed requirement as the evaluation metric. Experiments demonstrate that while the proposed encoders can effectively learn representations aligned with landmarkers, they may not directly translate to significant performance gains in the meta-task of HPO warm-starting.",
      "authors": [
        "Antoni Zajko",
        "Katarzyna Wo\\'znica"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:50:28+00:00",
          "link": "https://arxiv.org/abs/2507.12604v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12604",
        "HTML": "https://arxiv.org/html/2507.12604v1",
        "PDF": "https://arxiv.org/pdf/2507.12604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for tabular representation learning to improve hyperparameter optimization in machine learning, which does not directly relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12607",
      "abstract": "We study the classic Max-Cut problem under multiple cardinality constraints, which we refer to as the Constrained Max-Cut problem. Given a graph $G=(V, E)$, a partition of the vertices into $c$ disjoint parts $V_1, \\ldots, V_c$, and cardinality parameters $k_1, \\ldots, k_c$, the goal is to select a set $S \\subseteq V$ such that $|S \\cap V_i| = k_i$ for each $i \\in [c]$, maximizing the total weight of edges crossing $S$ (i.e., edges with exactly one endpoint in $S$).\n  By designing an approximate kernel for Constrained Max-Cut and building on the correlation rounding technique of Raghavendra and Tan (2012), we present a $(0.858 - \\varepsilon)$-approximation algorithm for the problem when $c = O(1)$. The algorithm runs in time $O\\left(\\min\\{k/\\varepsilon, n\\}^{\\poly(c/\\varepsilon)} + \\poly(n)\\right)$, where $k = \\sum_{i \\in [c]} k_i$ and $n=|V|$. This improves upon the $(\\frac{1}{2} + \\varepsilon_0)$-approximation of Feige and Langberg (2001) for $\\maxcut_k$ (the special case when $c=1, k_1 = k$), and generalizes the $(0.858 - \\varepsilon)$-approximation of Raghavendra and Tan (2012), which only applies when $\\min\\{k,n-k\\}=\\Omega(n)$ and does not handle multiple constraints.\n  We also establish that, for general values of $c$, it is NP-hard to determine whether a feasible solution exists that cuts all edges. Finally, we present a $1/2$-approximation algorithm for Max-Cut under an arbitrary matroid constraint.",
      "authors": [
        "Yury Makarychev",
        "Madhusudhan Reddy Pittu",
        "Ali Vakilian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:54:48+00:00",
          "link": "https://arxiv.org/abs/2507.12607v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Max-Cut with Multiple Cardinality Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12607",
        "HTML": "https://arxiv.org/html/2507.12607v1",
        "PDF": "https://arxiv.org/pdf/2507.12607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the Max-Cut problem under multiple cardinality constraints, discussing algorithms and approximation methods, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12612",
      "abstract": "The performance of finetuned large language models (LLMs) hinges critically on the composition of the training mixture. However, selecting an optimal blend of task datasets remains a largely manual, heuristic driven process, with practitioners often relying on uniform or size based sampling strategies. We introduce TASKPGM, a principled and scalable framework for mixture optimization that selects continuous task proportions by minimizing an energy function over a Markov Random Field (MRF). Task relationships are modeled using behavioral divergences such as Jensen Shannon Divergence and Pointwise Mutual Information computed from the predictive distributions of single task finetuned models. Our method yields a closed form solution under simplex constraints and provably balances representativeness and diversity among tasks. We provide theoretical guarantees, including weak submodularity for budgeted variants, and demonstrate consistent empirical improvements on Llama 2 and Mistral across evaluation suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers interpretable insights into task influence and mixture composition, making it a powerful tool for efficient and robust LLM finetuning.",
      "authors": [
        "Prateek Chanda",
        "Saral Sureka",
        "Parth Pratim Chatterjee",
        "Krishnateja Killamsetty",
        "Nikhil Shivakumar Nayak",
        "Ganesh Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:14:55+00:00",
          "link": "https://arxiv.org/abs/2507.12612v1",
          "size": "11352kb",
          "version": "v1"
        }
      ],
      "title": "Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12612",
        "HTML": "https://arxiv.org/html/2507.12612v1",
        "PDF": "https://arxiv.org/pdf/2507.12612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TASKPGM, which optimizes task selection for LLM fine-tuning through a novel framework. While related to fine-tuning processes, the primary focus is on task selection optimization rather than explicit training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12617",
      "abstract": "Action anticipation has become a prominent topic in Human Action Recognition (HAR). However, its application to real-world sports scenarios remains limited by the availability of suitable annotated datasets. This work presents a novel dataset of manually annotated soccer penalty kicks to predict shot direction based on pre-kick player movements. We propose a deep learning classifier to benchmark this dataset that integrates HAR-based feature embeddings with contextual metadata. We evaluate twenty-two backbone models across seven architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D), achieving up to 63.9% accuracy in predicting shot direction (left or right), outperforming the real goalkeepers' decisions. These results demonstrate the dataset's value for anticipatory action recognition and validate our model's potential as a generalizable approach for sports-based predictive tasks.",
      "authors": [
        "David Freire-Obreg\\'on",
        "Oliverio J. Santana",
        "Javier Lorenzo-Navarro",
        "Daniel Hern\\'andez-Sosa",
        "Modesto Castrill\\'on-Santana"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.12617v1",
          "size": "5820kb",
          "version": "v1"
        }
      ],
      "title": "Predicting Soccer Penalty Kick Direction Using Human Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12617",
        "HTML": "https://arxiv.org/html/2507.12617v1",
        "PDF": "https://arxiv.org/pdf/2507.12617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a dataset for predicting soccer penalty kick directions using human action recognition, which is not applicable to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12619",
      "abstract": "Large Language Models (LLMs) have become a cornerstone of modern AI, driving breakthroughs in natural language processing and expanding into multimodal jobs involving images, audio, and video. As with most computational software, it is important to distinguish between ordinary runtime performance and startup overhead. Prior research has focused on runtime performance: improving training efficiency and stability. This work focuses instead on the increasingly critical issue of startup overhead in training: the delay before training jobs begin execution. Startup overhead is particularly important in large, industrial-scale LLMs, where failures occur more frequently and multiple teams operate in iterative update-debug cycles. In one of our training clusters, more than 3.5% of GPU time is wasted due to startup overhead alone.\n  In this work, we present the first in-depth characterization of LLM training startup overhead based on real production data. We analyze the components of startup cost, quantify its direct impact, and examine how it scales with job size. These insights motivate the design of Bootseer, a system-level optimization framework that addresses three primary startup bottlenecks: (a) container image loading, (b) runtime dependency installation, and (c) model checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and (c) striped HDFS-FUSE. Bootseer has been deployed in a production environment and evaluated on real LLM training workloads, demonstrating a 50% reduction in startup overhead.",
      "authors": [
        "Rui Li",
        "Xiaoyun Zhi",
        "Jinxin Chi",
        "Menghan Yu",
        "Lixin Huang",
        "Jia Zhu",
        "Weilun Zhang",
        "Xing Ma",
        "Wenjia Liu",
        "Zhicheng Zhu",
        "Daowen Luo",
        "Zuquan Song",
        "Xin Yin",
        "Chao Xiang",
        "Shuguang Wang",
        "Wencong Xiao",
        "Gene Cooperman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:32:33+00:00",
          "link": "https://arxiv.org/abs/2507.12619v1",
          "size": "1873kb",
          "version": "v1"
        }
      ],
      "title": "BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12619",
        "HTML": "https://arxiv.org/html/2507.12619v1",
        "PDF": "https://arxiv.org/pdf/2507.12619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimization of startup overhead in LLM training, focusing on system-level improvements rather than any aspect of training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12621",
      "abstract": "Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language. NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization. We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration. We strongly recommend readers check our case studies, demo video, and source code at https://nli4volvis.github.io/.",
      "authors": [
        "Kuangshi Ai",
        "Kaiyuan Tang",
        "Chaoli Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:35:46+00:00",
          "link": "https://arxiv.org/abs/2507.12621v1",
          "size": "38160kb",
          "version": "v1"
        }
      ],
      "title": "NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12621",
        "HTML": "https://arxiv.org/html/2507.12621v1",
        "PDF": "https://arxiv.org/pdf/2507.12621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a system for natural language interaction in volume visualization, which does not pertain to LLM training data processing, focusing instead on interaction and visualization functionalities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12626",
      "abstract": "We contribute to the mathematical theory of the design of low temperature Ising machines, a type of experimental probabilistic computing device implementing the Ising model. Encoding the output of a function in the ground state of a physical system allows efficient and distributed computation, but the design of the energy function is a difficult puzzle. We introduce a diagrammatic device that allows us to visualize the decision boundaries for Ising circuits. It is then used to prove two results: (1) Ising circuits are a generalization of 1-NN classifiers with a certain special structure, and (2) Elimination of local minima in the energy landscape can be formulated as a linear programming problem.",
      "authors": [
        "Andrew G. Moore",
        "Zachary Richey",
        "Isaac K. Martin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:41:09+00:00",
          "link": "https://arxiv.org/abs/2507.12626v1",
          "size": "579kb",
          "version": "v1"
        }
      ],
      "title": "Geometric Theory of Ising Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12626",
        "HTML": "https://arxiv.org/html/2507.12626v1",
        "PDF": "https://arxiv.org/pdf/2507.12626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops geometric theories for Ising machines and does not make contributions to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12628",
      "abstract": "Human-object interaction detection (HOID) refers to localizing interactive human-object pairs in images and identifying the interactions. Since there could be an exponential number of object-action combinations, labeled data is limited - leading to a long-tail distribution problem. Recently, zero-shot learning emerged as a solution, with end-to-end transformer-based object detectors adapted for HOID becoming successful frameworks. However, their primary focus is designing improved decoders for learning entangled or disentangled interpretations of interactions. We advocate that HOI-specific cues must be anticipated at the encoder stage itself to obtain a stronger scene interpretation. Consequently, we build a top-down framework named Funnel-HOI inspired by the human tendency to grasp well-defined concepts first and then associate them with abstract concepts during scene understanding. We first probe an image for the presence of objects (well-defined concepts) and then probe for actions (abstract concepts) associated with them. A novel asymmetric co-attention mechanism mines these cues utilizing multimodal information (incorporating zero-shot capabilities) and yields stronger interaction representations at the encoder level. Furthermore, a novel loss is devised that considers objectaction relatedness and regulates misclassification penalty better than existing loss functions for guiding the interaction classifier. Extensive experiments on the HICO-DET and V-COCO datasets across fully-supervised and six zero-shot settings reveal our state-of-the-art performance, with up to 12.4% and 8.4% gains for unseen and rare HOI categories, respectively.",
      "authors": [
        "Sandipan Sarma",
        "Agney Talwarr",
        "Arijit Sur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:47:24+00:00",
          "link": "https://arxiv.org/abs/2507.12628v1",
          "size": "10362kb",
          "version": "v1"
        }
      ],
      "title": "Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12628",
        "HTML": "https://arxiv.org/html/2507.12628v1",
        "PDF": "https://arxiv.org/pdf/2507.12628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-object interaction detection and zero-shot learning, which does not involve LLM training data processing or dataset operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12629",
      "abstract": "We present a unified interpolation scheme that combines compactly-supported positive-definite kernels and multivariate polynomials. This unified framework generalizes interpolation with compactly-supported kernels and also classical polynomial least squares approximation. To facilitate the efficient use of this unified interpolation scheme, we present specialized numerical linear algebra procedures that leverage standard matrix factorizations. These procedures allow for efficient computation and storage of the unified interpolant. We also present a modification to the numerical linear algebra that allows us to generalize the application of the unified framework to target functions on manifolds with and without boundary. Our numerical experiments on both Euclidean domains and manifolds indicate that the unified interpolant is superior to polynomial least",
      "authors": [
        "M. Belianovich",
        "G. E. Fasshauer",
        "A. Narayan",
        "V. Shankar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:53:30+00:00",
          "link": "https://arxiv.org/abs/2507.12629v1",
          "size": "2067kb",
          "version": "v1"
        }
      ],
      "title": "A Unified Framework for Efficient Kernel and Polynomial Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12629",
        "HTML": "https://arxiv.org/html/2507.12629v1",
        "PDF": "https://arxiv.org/pdf/2507.12629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a unified interpolation scheme for kernel and polynomial interpolation, which mainly involves numerical methods and matrix factorizations without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12634",
      "abstract": "Suppose that a group test operation is available for checking order relations in a set, can this speed up problems like finding the minimum/maximum element, rank determination and selection? We consider a one-sided group test to be available, where queries are of the form $u \\le_Q V$ or $V \\le_Q u$, and the answer is `yes' if and only if there is some $v \\in V$ such that $u \\le v$ or $v \\le u$, respectively. We restrict attention to total orders and focus on query-complexity; for min or max finding, we give a Las Vegas algorithm that makes $\\mathcal{O}(\\log^2 n)$ expected queries. We also give randomized approximate algorithms for rank determination and selection; we allow a relative error of $1 \\pm \\delta$ for $\\delta > 0$ in the estimated rank or selected element. In this case, we give a Monte Carlo algorithm for approximate rank determination with expected query complexity $\\tilde{\\mathcal{O}}(1/\\delta^2 - \\log \\epsilon)$, where $1-\\epsilon$ is the probability that the algorithm succeeds. We also give a Monte Carlo algorithm for approximate selection that has expected query complexity $\\tilde{\\mathcal{O}}(-\\log( \\epsilon \\delta^2) / \\delta^4)$; it has probability at least $\\frac{1}{2}$ to output an element $x$, and if so, $x$ has the desired approximate rank with probability $1-\\epsilon$.",
      "authors": [
        "Adiesha Liyanage and Braeden Sopp and Brendan Mumey"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:16:39+00:00",
          "link": "https://arxiv.org/abs/2507.12634v1",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "title": "Fast Approximate Rank Determination and Selection with Group Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12634",
        "HTML": "https://arxiv.org/html/2507.12634v1",
        "PDF": "https://arxiv.org/pdf/2507.12634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses algorithms related to rank determination and selection using group testing operations, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12635",
      "abstract": "We study the multiprocessor scheduling with rejection problem under a machine cost constraint. In this problem, each job is either rejected with a rejection penalty or; accepted and scheduled on one of the machines for processing. The machine cost is proportional to the total processing time of the jobs scheduled on it. The problem aims to minimize the makespan of accepted jobs plus the total rejection penalty of rejected jobs while the total machine cost does not exceed a given upper bound. We present a simple $2$-approximation algorithm for the problem and we achieve an EPTAS when the number $m$ of machines is a fixed constant.",
      "authors": [
        "Mingyang Gong",
        "Brendan Mumey"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:17:08+00:00",
          "link": "https://arxiv.org/abs/2507.12635v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "An EPTAS for multiprocessor scheduling with rejection under a machine cost constraint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12635",
        "HTML": "https://arxiv.org/html/2507.12635v1",
        "PDF": "https://arxiv.org/pdf/2507.12635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on multiprocessor scheduling under constraints and does not relate to LLM training data processing or operations that improve training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12638",
      "abstract": "Backtracking, an emergent behavior elicited by reasoning fine-tuning, has been shown to be a key mechanism in reasoning models' enhanced capabilities. Prior work has succeeded in manipulating this behavior via steering vectors, but the underlying mechanism remains poorly understood. In this work, we show that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part driven by a repurposed direction already present in base model activations. Specifically, we identify a direction in base Llama-3.1-8B's residual stream which systematically induces backtracking when used to steer the distilled reasoning model, and find that the effects of steering with this direction cannot be trivially explained by token-level attributes. We further find that this direction does not induce backtracking in the base model, suggesting that the reasoning finetuning process repurposes pre-existing representations to form new behavioral circuits. Additionally, we hypothesize that this direction is one of several which may work together to mediate backtracking. Our findings offer a compelling picture that reasoning-finetuned models repurpose pre-existing base model representations, rather than learn new capabilities from scratch.",
      "authors": [
        "Jake Ward",
        "Chuqiao Lin",
        "Constantin Venhoff",
        "Neel Nanda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:21:03+00:00",
          "link": "https://arxiv.org/abs/2507.12638v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning-Finetuning Repurposes Latent Representations in Base Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12638",
        "HTML": "https://arxiv.org/html/2507.12638v1",
        "PDF": "https://arxiv.org/pdf/2507.12638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses 'reasoning fine-tuning' which leans towards fine-tuning techniques rather than directly addressing training data processing. It relates to model behavior after fine-tuning rather than data operations like collection or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12640",
      "abstract": "The standard dual-numbers construction works well for forward-mode automatic differentiation (AD) and is attractive due to its simplicity; recently, it also has been adapted to reverse-mode AD, but practical performance, especially on array programs, leaves a lot to be desired. In this paper we introduce first-class support for multidimensional arrays in dual-numbers reverse-mode AD with little to no performance overhead. The algorithm consists of three loosely-coupled components: a semantics-preserving vectorisation code transformation (the bulk-operation transform or BOT), a fairly straightforward lifting of the basic dual-numbers reverse AD algorithm to a mostly first-order array language, and symbolic interpretation to achieve an end-to-end compilation pipeline. Unfortunately, we lose some of the nice generalisable aspects of dual-numbers AD in the process, most importantly support for higher-order code.\n  We do support some higher-order array combinators, but only a carefully-chosen set: 'build' (elementwise array construction), 'gather' and 'scatter'. In return, the BOT can eliminate the essential (for AD) higher-orderness of the input program, meaning that AD gets essentially presented with a first-order program. This allows the naive trick of lifting dual numbers to \"dual arrays\" to work without much modification.",
      "authors": [
        "Tom Smeding",
        "Miko{\\l}aj Konarski",
        "Simon Peyton Jones",
        "Andrew Fitzgibbon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:21:52+00:00",
          "link": "https://arxiv.org/abs/2507.12640v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Numbers Reverse AD for Functional Array Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12640",
        "HTML": "https://arxiv.org/html/2507.12640v1",
        "PDF": "https://arxiv.org/pdf/2507.12640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces improvements in automatic differentiation for array languages, but it doesn't discuss LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12642",
      "abstract": "Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit HumanEval benchmark, ORPO reaches 56.29\\% Pass@1 ($\\approx+10$ pp over Granite-8B-QK) and GRPO hits 49\\%, both beating all general-purpose baselines; on the original HumanEval they score 65.90\\% and 63.00\\%. GRPO excels on basic tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five advanced tasks, highlighting clear gains yet room for progress in AI-assisted quantum programming.",
      "authors": [
        "Kiana Kheiri and Aamna Aamir and Andriy Miranskyy and Chen Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:27:31+00:00",
          "link": "https://arxiv.org/abs/2507.12642v1",
          "size": "1728kb",
          "version": "v1"
        }
      ],
      "title": "QSpark: Towards Reliable Qiskit Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12642",
        "HTML": "https://arxiv.org/html/2507.12642v1",
        "PDF": "https://arxiv.org/pdf/2507.12642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions fine-tuning a language model with RL methods on a synthetic dataset, indicating some level of dataset creation. However, the focus rests on improving quantum code generation rather than making substantial contributions to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12644",
      "abstract": "Tool design and use reflect the ability to understand and manipulate the physical world through creativity, planning, and foresight. As such, these capabilities are often regarded as measurable indicators of intelligence across biological species. While much of today's research on robotic intelligence focuses on generating better controllers, inventing smarter tools offers a complementary form of physical intelligence: shifting the onus of problem-solving onto the tool's design. Given the vast and impressive common-sense, reasoning, and creative capabilities of today's foundation models, we investigate whether these models can provide useful priors to automatically design and effectively wield such tools? We present VLMgineer, a framework that harnesses the code generation abilities of vision language models (VLMs) together with evolutionary search to iteratively co-design physical tools and the action plans that operate them to perform a task. We evaluate VLMgineer on a diverse new benchmark of everyday manipulation scenarios that demand creative tool design and use. Across this suite, VLMgineer consistently discovers tools and policies that solve tasks more effectively and innovatively, transforming challenging robotics problems into straightforward executions. It also outperforms VLM-generated designs from human specifications and existing human-crafted tools for everyday tasks. To facilitate future research on automated tool invention, we will release our benchmark and code.",
      "authors": [
        "George Jiayuan Gao",
        "Tianyu Li",
        "Junyao Shi",
        "Yihan Li",
        "Zizhe Zhang",
        "Nadia Figueroa",
        "Dinesh Jayaraman"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:30:05+00:00",
          "link": "https://arxiv.org/abs/2507.12644v1",
          "size": "13301kb",
          "version": "v1"
        }
      ],
      "title": "VLMgineer: Vision Language Models as Robotic Toolsmiths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12644",
        "HTML": "https://arxiv.org/html/2507.12644v1",
        "PDF": "https://arxiv.org/pdf/2507.12644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the use of VLMs for tool design and robotics, not on training data processing for LLMs. It does not cover data collection, augmentation, or similar aspects for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12646",
      "abstract": "We explore novel-view synthesis for dynamic scenes from monocular videos. Prior approaches rely on costly test-time optimization of 4D representations or do not preserve scene geometry when trained in a feed-forward manner. Our approach is based on three key insights: (1) covisible pixels (that are visible in both the input and target views) can be rendered by first reconstructing the dynamic 3D scene and rendering the reconstruction from the novel-views and (2) hidden pixels in novel views can be \"inpainted\" with feed-forward 2D video diffusion models. Notably, our video inpainting diffusion model (CogNVS) can be self-supervised from 2D videos, allowing us to train it on a large corpus of in-the-wild videos. This in turn allows for (3) CogNVS to be applied zero-shot to novel test videos via test-time finetuning. We empirically verify that CogNVS outperforms almost all prior art for novel-view synthesis of dynamic scenes from monocular videos.",
      "authors": [
        "Kaihua Chen",
        "Tarasha Khurana",
        "Deva Ramanan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:40:29+00:00",
          "link": "https://arxiv.org/abs/2507.12646v1",
          "size": "5245kb",
          "version": "v1"
        }
      ],
      "title": "Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12646",
        "HTML": "https://arxiv.org/html/2507.12646v1",
        "PDF": "https://arxiv.org/pdf/2507.12646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on dynamic novel-view synthesis from monocular videos using video inpainting and feed-forward models. It does not address any aspect of LLM training data processing or data engineering operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12649",
      "abstract": "The ongoing digitalisation of the smart grid is resulting in an increase in automated information exchanges across distributed energy systems. This process has led to the development of new information and data models when the existing ones fall short. To prevent potential disruptions caused by flaws in the newly designed information and data models, it is essential to evaluate them during the design process before they are implemented in operation.\n  Currently, general explicit evaluation approaches outside the smart grid domain stay at a high level without defining clear steps. Meanwhile, implicit evaluation approaches in the smart grid domain focus on testing systems that utilise information and data models already in use for functionality in terms of conformance and interoperability. Notably, no combination of explicit and implicit evaluation approaches for newly designed information and data models offers a clearly defined set of steps during their design process in the smart grid context.\n  Consequently, we design a three-phase evaluation approach using design science research to address this gap. Our evaluation approach combines explicit and implicit evaluation methods and is applicable when developing new information and data models. We use the development of an information model and data model focused on industrial flexibility descriptions to refine our evaluation approach. Additionally, we provide lessons learned from our experience.",
      "authors": [
        "Christine van Stiphoudt",
        "Sergio Potenciano Menci",
        "Gilbert Fridgen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:51:45+00:00",
          "link": "https://arxiv.org/abs/2507.12649v1",
          "size": "218kb",
          "version": "v1"
        }
      ],
      "title": "A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12649",
        "HTML": "https://arxiv.org/html/2507.12649v1",
        "PDF": "https://arxiv.org/pdf/2507.12649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses evaluation approaches for information and data models in the smart grid domain. It does not involve any LLM training data processing or techniques related to data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12652",
      "abstract": "Invasive and non-invasive neural interfaces hold promise as high-bandwidth input devices for next-generation technologies. However, neural signals inherently encode sensitive information about an individual's identity and health, making data sharing for decoder training a critical privacy challenge. Federated learning (FL), a distributed, privacy-preserving learning framework, presents a promising solution, but it remains unexplored in closed-loop adaptive neural interfaces. Here, we introduce FL-based neural decoding and systematically evaluate its performance and privacy using high-dimensional electromyography signals in both open- and closed-loop scenarios. In open-loop simulations, FL significantly outperformed local learning baselines, demonstrating its potential for high-performance, privacy-conscious neural decoding. In contrast, closed-loop user studies required adapting FL methods to accommodate single-user, real-time interactions, a scenario not supported by standard FL. This modification resulted in local learning decoders surpassing the adapted FL approach in closed-loop performance, yet local learning still carried higher privacy risks. Our findings highlight a critical performance-privacy tradeoff in real-time adaptive applications and indicate the need for FL methods specifically designed for co-adaptive, single-user applications.",
      "authors": [
        "Kai Malcolm",
        "C\\'esar Uribe",
        "Momona Yamagami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:59:25+00:00",
          "link": "https://arxiv.org/abs/2507.12652v1",
          "size": "2783kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12652",
        "HTML": "https://arxiv.org/html/2507.12652v1",
        "PDF": "https://arxiv.org/pdf/2507.12652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study applies federated learning to neural decoding tasks for electromyography signals, focusing on privacy and performance. It does not contribute to LLM training data processing or dataset enhancement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12653",
      "abstract": "This paper introduces a novel approach to project success evaluation by integrating fuzzy logic into an existing construct. Traditional Likert-scale measures often overlook the context-dependent and multifaceted nature of project success. The proposed hierarchical Type-1 Mamdani fuzzy system prioritizes sustained positive impact for end-users, reducing emphasis on secondary outcomes like stakeholder satisfaction and internal project success. This dynamic approach may provide a more accurate measure of project success and could be adaptable to complex evaluations. Future research will focus on empirical testing and broader applications of fuzzy logic in social science.",
      "authors": [
        "Jo\\~ao Granja-Correia",
        "Remedios Hern\\'andez-Linares",
        "Luca Ferranti and Arm\\'enio Rego"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:05:13+00:00",
          "link": "https://arxiv.org/abs/2507.12653v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "A Fuzzy Approach to Project Success: Measuring What Matters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12653",
        "HTML": "https://arxiv.org/html/2507.12653v1",
        "PDF": "https://arxiv.org/pdf/2507.12653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a fuzzy logic-based approach for evaluating project success. It lacks any relevance to the data processing needs or methods of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12659",
      "abstract": "Physics-Informed Neural Networks (PINNs) are deep learning models that incorporate the governing physical laws of a system into the learning process, making them well-suited for solving complex scientific and engineering problems. Recently, PINNs have gained widespread attention as a powerful framework for combining physical principles with data-driven modeling to improve prediction accuracy. Despite their successes, however, PINNs often exhibit poor extrapolation performance outside the training domain and are highly sensitive to the choice of activation functions (AFs). In this paper, we introduce a transfer learning (TL) method to improve the extrapolation capability of PINNs. Our approach applies transfer learning (TL) within an extended training domain, using only a small number of carefully selected collocation points. Additionally, we propose an adaptive AF that takes the form of a linear combination of standard AFs, which improves both the robustness and accuracy of the model. Through a series of experiments, we demonstrate that our method achieves an average of 40% reduction in relative L2 error and an average of 50% reduction in mean absolute error in the extrapolation domain, all without a significant increase in computational cost. The code is available at https://github.com/LiuzLab/PINN-extrapolation .",
      "authors": [
        "Athanasios Papastathopoulos-Katsaros and Alexandra Stavrianidi and Zhandong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:19:53+00:00",
          "link": "https://arxiv.org/abs/2507.12659v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12659",
        "HTML": "https://arxiv.org/html/2507.12659v1",
        "PDF": "https://arxiv.org/pdf/2507.12659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving physics-informed neural networks' extrapolation performance using transfer learning and adaptive activation functions. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12663",
      "abstract": "Cardiovascular disease (CVD) remains the leading global cause of mortality, yet current risk stratification methods often fail to detect early, subclinical changes. Previous studies have generally not integrated retinal microvasculature characteristics with comprehensive serum lipidomic profiles as potential indicators of CVD risk. In this study, an innovative imaging omics framework was introduced, combining retinal microvascular traits derived through deep learning based image processing with serum lipidomic data to highlight asymptomatic biomarkers of cardiovascular risk beyond the conventional lipid panel. This represents the first large scale, covariate adjusted and stratified correlation analysis conducted in a healthy population, which is essential for identifying early indicators of disease. Retinal phenotypes were quantified using automated image analysis tools, while serum lipid profiling was performed by Ultra High Performance Liquid Chromatography Electrospray ionization High resolution mass spectrometry (UHPLC ESI HRMS). Strong, age- and sex-independent correlations were established, particularly between average artery width, vessel density, and lipid subclasses such as triacylglycerols (TAGs), diacylglycerols (DAGs), and ceramides (Cers). These associations suggest a converging mechanism of microvascular remodeling under metabolic stress. By linking detailed\n  vascular structural phenotypes to specific lipid species, this study fills a critical gap in the understanding of early CVD pathogenesis. This integration not only offers a novel perspective on microvascular metabolic associations but also presents a significant opportunity for the identification of robust, non-invasive biomarkers. Ultimately, these findings may support improved early detection, targeted prevention, and personalized approaches in cardiovascular healthcare.",
      "authors": [
        "Inamullah",
        "Ernesto Elias Vidal Rosas",
        "Imran Razzak",
        "Shoaib Jameel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:40:17+00:00",
          "link": "https://arxiv.org/abs/2507.12663v1",
          "size": "7787kb",
          "version": "v1"
        }
      ],
      "title": "Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in a Healthy Cohort",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12663",
        "HTML": "https://arxiv.org/html/2507.12663v1",
        "PDF": "https://arxiv.org/pdf/2507.12663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework integrating oculomics and lipidomics for cardiovascular health, focusing on imaging omics and lipid profiles, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12665",
      "abstract": "We propose the Single Conversation Methodology (SCM), a novel and pragmatic approach to software development using large language models (LLMs). In contrast to ad hoc interactions with generative AI, SCM emphasizes a structured and persistent development dialogue, where all stages of a project - from requirements to architecture and implementation - unfold within a single, long-context conversation. The methodology is grounded on principles of cognitive clarity, traceability, modularity, and documentation. We define its phases, best practices, and philosophical stance, while arguing that SCM offers a necessary correction to the passive reliance on LLMs prevalent in current practices. We aim to reassert the active role of the developer as architect and supervisor of the intelligent tool.",
      "authors": [
        "Salvador D. Escobedo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:43:30+00:00",
          "link": "https://arxiv.org/abs/2507.12665v1",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "title": "Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12665",
        "HTML": "https://arxiv.org/html/2507.12665v1",
        "PDF": "https://arxiv.org/pdf/2507.12665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a structured development methodology using LLMs for software development, it does not focus on training data processing for LLMs but rather on development practices and project management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12666",
      "abstract": "Game design hinges on understanding how static rules and content translate into dynamic player behavior - something modern generative systems that inspect only a game's code or assets struggle to capture. We present an automated design iteration framework that closes this gap by pairing a reinforcement learning (RL) agent, which playtests the game, with a large multimodal model (LMM), which revises the game based on what the agent does. In each loop the RL player completes several episodes, producing (i) numerical play metrics and/or (ii) a compact image strip summarising recent video frames. The LMM designer receives a gameplay goal and the current game configuration, analyses the play traces, and edits the configuration to steer future behaviour toward the goal. We demonstrate results that LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design.",
      "authors": [
        "Alex Zook",
        "Josef Spjut",
        "Jonathan Tremblay"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:45:40+00:00",
          "link": "https://arxiv.org/abs/2507.12666v1",
          "size": "5074kb",
          "version": "v1"
        }
      ],
      "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12666",
        "HTML": "https://arxiv.org/html/2507.12666v1",
        "PDF": "https://arxiv.org/pdf/2507.12666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores an iterative game design framework using reinforcement learning and large multimodal models, which does not pertain to LLM training data processing topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12667",
      "abstract": "Visualization of large-scale time-dependent simulation data is crucial for domain scientists to analyze complex phenomena, but it demands significant I/O bandwidth, storage, and computational resources. To enable effective visualization on local, low-end machines, recent advances in view synthesis techniques, such as neural radiance fields, utilize neural networks to generate novel visualizations for volumetric scenes. However, these methods focus on reconstruction quality rather than facilitating interactive visualization exploration, such as feature extraction and tracking. We introduce VolSegGS, a novel Gaussian splatting framework that supports interactive segmentation and tracking in dynamic volumetric scenes for exploratory visualization and analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic volumetric scene, allowing for real-time novel view synthesis. For accurate segmentation, we leverage the view-independent colors of Gaussians for coarse-level segmentation and refine the results with an affinity field network for fine-level segmentation. Additionally, by embedding segmentation results within the Gaussians, we ensure that their deformation enables continuous tracking of segmented regions over time. We demonstrate the effectiveness of VolSegGS with several time-varying datasets and compare our solutions against state-of-the-art methods. With the ability to interact with a dynamic scene in real time and provide flexible segmentation and tracking capabilities, VolSegGS offers a powerful solution under low computational demands. This framework unlocks exciting new possibilities for time-varying volumetric data analysis and visualization.",
      "authors": [
        "Siyuan Yao and Chaoli Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:57:03+00:00",
          "link": "https://arxiv.org/abs/2507.12667v1",
          "size": "45705kb",
          "version": "v1"
        }
      ],
      "title": "VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12667",
        "HTML": "https://arxiv.org/html/2507.12667v1",
        "PDF": "https://arxiv.org/pdf/2507.12667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visualization and segmentation in dynamic volumetric scenes using deformable 3D Gaussians, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12668",
      "abstract": "Compared to frequent pattern mining, sequential pattern mining emphasizes the temporal aspect and finds broad applications across various fields. However, numerous studies treat temporal events as single time points, neglecting their durations. Time-interval-related pattern (TIRP) mining is introduced to address this issue and has been applied to healthcare analytics, stock prediction, etc. Typically, mining all patterns is not only computationally challenging for accurate forecasting but also resource-intensive in terms of time and memory. Targeting the extraction of time-interval-related patterns based on specific criteria can improve data analysis efficiency and better align with customer preferences. Therefore, this paper proposes a novel algorithm called TaTIRP to discover Targeted Time-Interval Related Patterns. Additionally, we develop multiple pruning strategies to eliminate redundant extension operations, thereby enhancing performance on large-scale datasets. Finally, we conduct experiments on various real-world and synthetic datasets to validate the accuracy and efficiency of the proposed algorithm.",
      "authors": [
        "Shuang Liang",
        "Lili Chen",
        "Wensheng Gan",
        "Philip S. Yu",
        "Shengjie Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:57:53+00:00",
          "link": "https://arxiv.org/abs/2507.12668v1",
          "size": "401kb",
          "version": "v1"
        }
      ],
      "title": "Targeted Mining of Time-Interval Related Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12668",
        "HTML": "https://arxiv.org/html/2507.12668v1",
        "PDF": "https://arxiv.org/pdf/2507.12668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel algorithm for targeted mining of time-interval-related patterns, which is unrelated to LLM training data processing or any specific dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12670",
      "abstract": "An address is indicated as an identifier of the user on the blockchain, and is defined by a hash value of the ECDSA verification key. A vanity address is an address that embeds custom characters such as a name. To generate a vanity address, a classical try-and-error method is employed, and thus the number of characters to be embedded is limited. In this paper, we focus on the functionality of identity-based signatures (IBS) where any strings can be employed as a verification key, and explore whether IBS can be used for generating a vanity address. We attach importance to the fact that it is not realistic to replace ECDSA with key recovery, which is currently employed for issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is possible, it is not a reasonable price for the ease of the vanity address generation. Thus, we pay attention to a generic construction of IBS from signatures, and construct an IBS scheme from ECDSA with key recovery. Though we cannot directly generate a vanity address due to the key recovery functionality of the underlying ECDSA, we can connect any string with an address due to the functionality of IBS that can give additional meaning to the address. We implement our system by Solidity, and demonstrate that the gas cost is almost same as that of the ECDSA signature verification.",
      "authors": [
        "Shogo Murasaki and Kazumasa Omote and Keita Emura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:04:57+00:00",
          "link": "https://arxiv.org/abs/2507.12670v1",
          "size": "11kb",
          "version": "v1"
        }
      ],
      "title": "On the Consideration of Vanity Address Generation via Identity-Based Signatures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12670",
        "HTML": "https://arxiv.org/html/2507.12670v1",
        "PDF": "https://arxiv.org/pdf/2507.12670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on vanity address generation via identity-based signatures related to blockchain technology, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12672",
      "abstract": "We introduce the first open-source model for translation between the vulnerable Chechen language and Russian, and the dataset collected to train and evaluate it. We explore fine-tuning capabilities for including a new language into a large language model system for multilingual translation NLLB-200. The BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for translation from Russian to Chechen and reverse direction, respectively. The release of the translation models is accompanied by the distribution of parallel words, phrases and sentences corpora and multilingual sentence encoder adapted to the Chechen language.",
      "authors": [
        "Abu-Viskhan A. Umishov and Vladislav A. Grigorian"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:07:07+00:00",
          "link": "https://arxiv.org/abs/2507.12672v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "The first open machine translation system for the Chechen language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12672",
        "HTML": "https://arxiv.org/html/2507.12672v1",
        "PDF": "https://arxiv.org/pdf/2507.12672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions dataset collection for training and evaluating translation models, its primary focus is on creating a machine translation system rather than making significant contributions to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12674",
      "abstract": "Large Language Models (LLMs) have shown strong performance on programming tasks, but can they generate student-like code like real students - imperfect, iterative, and stylistically diverse? We present ParaStudent, a systematic study of LLM-based \"student-like\" code generation in an introductory programming course setting. Using a dataset of timestamped student submissions across multiple semesters, we design low- and high-resolution experiments to model student progress and evaluate code outputs along semantic, functional, and stylistic dimensions. Our results show that fine-tuning significantly improves alignment with real student trajectories and captures error patterns, incremental improvements, and stylistic variations more faithfully. This study shows that modeling realistic student code requires capturing learning dynamics through context-aware generation, temporal modeling, and multi-dimensional evaluation. Code for experiments and evaluation is available at \\href{https://github.com/mmiroyan/ParaStudent}{\\texttt{github.com/mmiroyan/ParaStudent}}.",
      "authors": [
        "Mihran Miroyan",
        "Rose Niousha",
        "Joseph E. Gonzalez",
        "Gireeja Ranade",
        "Narges Norouzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:12:14+00:00",
          "link": "https://arxiv.org/abs/2507.12674v1",
          "size": "4080kb",
          "version": "v1"
        }
      ],
      "title": "ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12674",
        "HTML": "https://arxiv.org/html/2507.12674v1",
        "PDF": "https://arxiv.org/pdf/2507.12674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses fine-tuning LLMs to mimic student-like code generation, the focus is not on data processing for LLM training. The paper mainly explores modeling student code through fine-tuning, which touches on training data adaptation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12675",
      "abstract": "Automated structural defect segmentation in civil infrastructure faces a critical challenge: achieving high accuracy while maintaining computational efficiency for real-time deployment. This paper presents FORTRESS (Function-composition Optimized Real-Time Resilient Structural Segmentation), a new architecture that balances accuracy and speed by using a special method that combines depthwise separable convolutions with adaptive Kolmogorov-Arnold Network integration. FORTRESS incorporates three key innovations: a systematic depthwise separable convolution framework achieving a 3.6x parameter reduction per layer, adaptive TiKAN integration that selectively applies function composition transformations only when computationally beneficial, and multi-scale attention fusion combining spatial, channel, and KAN-enhanced features across decoder levels. The architecture achieves remarkable efficiency gains with 91% parameter reduction (31M to 2.9M), 91% computational complexity reduction (13.7 to 1.17 GFLOPs), and 3x inference speed improvement while delivering superior segmentation performance. Evaluation on benchmark infrastructure datasets demonstrates state-of-the-art results with an F1- score of 0.771 and a mean IoU of 0.677, significantly outperforming existing methods including U-Net, SA-UNet, and U- KAN. The dual optimization strategy proves essential for optimal performance, establishing FORTRESS as a robust solution for practical structural defect segmentation in resource-constrained environments where both accuracy and computational efficiency are paramount. Comprehensive architectural specifications are provided in the Supplemental Material. Source code is available at URL: https://github.com/faeyelab/fortress-paper-code.",
      "authors": [
        "Christina Thrainer",
        "Md Meftahul Ferdaus",
        "Mahdi Abdelguerfi",
        "Christian Guetl",
        "Steven Sloan",
        "Kendall N. Niles",
        "Ken Pathak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:17:58+00:00",
          "link": "https://arxiv.org/abs/2507.12675v1",
          "size": "3958kb",
          "version": "v1"
        }
      ],
      "title": "FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation via Kolmogorov-Arnold Enhanced Spatial Attention Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12675",
        "HTML": "https://arxiv.org/html/2507.12675v1",
        "PDF": "https://arxiv.org/pdf/2507.12675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a new architecture for structural defect segmentation in civil infrastructure, without any emphasis on LLM training data processing or improvements in data quality related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12677",
      "abstract": "Data heterogeneity is a prevalent issue, stemming from various conflicting factors, making its utilization complex. This uncertainty, particularly resulting from disparities in data formats, frequently necessitates the involvement of experts to find resolutions. Current methodologies primarily address conflicts related to data structures and schemas, often overlooking the pivotal role played by data transformation. As the utilization of artificial intelligence (AI) continues to expand, there is a growing demand for a more streamlined data preparation process, and data transformation becomes paramount. It customizes training data to enhance AI learning efficiency and adapts input formats to suit diverse AI models. Selecting an appropriate transformation technique is paramount in preserving crucial data details. Despite the widespread integration of AI across various industries, comprehensive reviews concerning contemporary data transformation approaches are scarce. This survey explores the intricacies of data heterogeneity and its underlying sources. It systematically categorizes and presents strategies to address heterogeneity stemming from differences in data formats, shedding light on the inherent challenges associated with each strategy.",
      "authors": [
        "Sangbong Yoo",
        "Jaeyoung Lee",
        "Chanyoung Yoon",
        "Geonyeong Son",
        "Hyein Hong",
        "Seongbum Seo",
        "Soobin Yim",
        "Chanyoung Jung",
        "Jungsoo Park",
        "Misuk Kim",
        "and Yun Jang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:27:24+00:00",
          "link": "https://arxiv.org/abs/2507.12677v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Data Transformation Strategies to Remove Heterogeneity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12677",
        "HTML": "https://arxiv.org/html/2507.12677v1",
        "PDF": "https://arxiv.org/pdf/2507.12677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys data transformation strategies to address data heterogeneity, which is relevant to data processing. However, it does not specifically contribute to LLM training data processing, but rather provides a general discussion of data transformation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12679",
      "abstract": "The rising rate of drug-related deaths in the United States, largely driven by fentanyl, requires timely and accurate surveillance. However, critical overdose data are often buried in free-text coroner reports, leading to delays and information loss when coded into ICD (International Classification of Disease)-10 classifications. Natural language processing (NLP) models may automate and enhance overdose surveillance, but prior applications have been limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in 2020 was used for model training and internal testing. External validation was conducted using a novel separate dataset of 3,335 records from 2023-2024. Multiple NLP approaches were evaluated for classifying specific drug involvement from unstructured death certificate text. These included traditional single- and multi-label classifiers, as well as fine-tuned encoder-only language models such as Bidirectional Encoder Representations from Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large language models such as Qwen 3 and Llama 3. Model performance was assessed using macro-averaged F1 scores, and 95% confidence intervals were calculated to quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect performance, with macro F1 scores >=0.998 on the internal test set. External validation confirmed robustness (macro F1=0.966), outperforming conventional machine learning, general-domain BERT models, and various decoder-only large language models. NLP models, particularly fine-tuned clinical variants like BioClinicalBERT, offer a highly accurate and scalable solution for overdose death classification from free-text reports. These methods can significantly accelerate surveillance workflows, overcoming the limitations of manual ICD-10 coding and supporting near real-time detection of emerging substance use trends.",
      "authors": [
        "Arthur J. Funnell",
        "Panayiotis Petousis",
        "Fabrice Harel-Canada",
        "Ruby Romero",
        "Alex A. T. Bui",
        "Adam Koncsol",
        "Hritika Chaturvedi",
        "Chelsea Shover",
        "David Goodman-Meza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:29:19+00:00",
          "link": "https://arxiv.org/abs/2507.12679v1",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "title": "Improving Drug Identification in Overdose Death Surveillance using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12679",
        "PDF": "https://arxiv.org/pdf/2507.12679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The research involves fine-tuning BERT models for drug identification in text data, which relates to fine-tuning. Yet, it does not focus on the broader LLM training data processing operations like dataset creation or novel data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12691",
      "abstract": "AI assistants will occasionally respond deceptively to user queries. Recently, linear classifiers (called \"deception probes\") have been trained to distinguish the internal activations of a language model during deceptive versus honest responses. However, it's unclear how effective these probes are at detecting deception in practice, nor whether such probes are resistant to simple counter strategies from a deceptive assistant who wishes to evade detection. In this paper, we compare white-box monitoring (where the monitor has access to token-level probe activations) to black-box monitoring (without such access). We benchmark deception probes by the extent to which the white box monitor outperforms the black-box monitor, i.e. the black-to-white performance boost. We find weak but encouraging black-to-white performance boosts from existing deception probes.",
      "authors": [
        "Avi Parrack",
        "Carlo Leonardo Attubato",
        "Stefan Heimersheim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:49:55+00:00",
          "link": "https://arxiv.org/abs/2507.12691v1",
          "size": "297kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Deception Probes via Black-to-White Performance Boosts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12691",
        "PDF": "https://arxiv.org/pdf/2507.12691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates deception probes in AI assistants by analyzing white-box and black-box performance, which does not involve processing data for training or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12695",
      "abstract": "We introduce AdaptiSent, a new framework for Multimodal Aspect-Based Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms to improve sentiment classification and aspect term extraction from both text and images. Our model integrates dynamic modality weighting and context-adaptive attention, enhancing the extraction of sentiment and aspect-related information by focusing on how textual cues and visual context interact. We tested our approach against several baselines, including traditional text-based models and other multimodal methods. Results from standard Twitter datasets show that AdaptiSent surpasses existing models in precision, recall, and F1 score, and is particularly effective in identifying nuanced inter-modal relationships that are crucial for accurate sentiment and aspect term extraction. This effectiveness comes from the model's ability to adjust its focus dynamically based on the context's relevance, improving the depth and accuracy of sentiment analysis across various multimodal data sets. AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.",
      "authors": [
        "S M Rafiuddin",
        "Sadia Kamal",
        "Mohammed Rakib",
        "Arunkumar Bagavathi",
        "and Atriya Sen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:06:43+00:00",
          "link": "https://arxiv.org/abs/2507.12695v1",
          "size": "306kb",
          "version": "v1"
        }
      ],
      "title": "AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12695",
        "HTML": "https://arxiv.org/html/2507.12695v1",
        "PDF": "https://arxiv.org/pdf/2507.12695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for multimodal sentiment analysis, focusing on adaptive attention mechanisms for text and images, without addressing LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12699",
      "abstract": "Computing equilibrium concentrations of molecular complexes is generally analytically intractable and requires numerical approaches. In this work we focus on the polymer-monomer level, where indivisible molecules (monomers) combine to form complexes (polymers). Rather than employing free-energy parameters for each polymer, we focus on the athermic setting where all interactions preserve enthalpy. This setting aligns with the strongly bonded (domain-based) regime in DNA nanotechnology when strands can bind in different ways, but always with maximum overall bonding -- and is consistent with the saturated configurations in the Thermodynamic Binding Networks (TBNs) model. Within this context, we develop an iterative algorithm for assigning polymer concentrations to satisfy detailed-balance, where on-target (desired) polymers are in high concentrations and off-target (undesired) polymers are in low. Even if not directly executed, our algorithm provides effective insights into upper bounds on concentration of off-target polymers, connecting combinatorial arguments about discrete configurations such as those in the TBN model to real-valued concentrations. We conclude with an application of our method to decreasing leak in DNA logic and signal propagation. Our results offer a new framework for design and verification of equilibrium concentrations when configurations are distinguished by entropic forces.",
      "authors": [
        "Hamidreza Akef",
        "Minki Hhan",
        "David Soloveichik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:26:38+00:00",
          "link": "https://arxiv.org/abs/2507.12699v1",
          "size": "529kb",
          "version": "v1"
        }
      ],
      "title": "Computing and Bounding Equilibrium Concentrations in Athermic Chemical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12699",
        "HTML": "https://arxiv.org/html/2507.12699v1",
        "PDF": "https://arxiv.org/pdf/2507.12699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on computing polymer concentrations in chemical systems, which is unrelated to any aspect of LLM training data processing or text data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12700",
      "abstract": "Magnetohydrodynamics (MHD) describes the interaction between electrically conducting fluids and electromagnetic fields. We propose and analyze a symplectic, second-order algorithm for the evolutionary MHD system in Els\\\"asser variables. We reduce the computational cost of the iterative non-linear solver, at each time step, by partitioning the coupled system into two subproblems of half size, solved in parallel. We prove that the iterations converge linearly, under a time step restriction similar to the one required in the full space-time error analysis. The variable step algorithm unconditionally conserves the energy, cross-helicity and magnetic helicity, and numerical solutions are second-order accurate in the $L^{2}$ and $H^{1}$-norms. The time adaptive mechanism, based on a local truncation error criterion, helps the variable step algorithm balance accuracy and time efficiency. Several numerical tests support the theoretical findings and verify the advantage of time adaptivity.",
      "authors": [
        "Zhen Yao",
        "Catalin Trenchea and Wenlong Pei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:27:25+00:00",
          "link": "https://arxiv.org/abs/2507.12700v1",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "title": "Partitioned Conservative, Variable Step, Second-Order Method for Magneto-hydrodynamics In Els\\\"asser Variables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12700",
        "HTML": "https://arxiv.org/html/2507.12700v1",
        "PDF": "https://arxiv.org/pdf/2507.12700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with a second-order algorithm for magnetohydrodynamics in Els\u00e4sser variables, focusing on computational cost reduction and time adaptivity in numerical simulations, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12701",
      "abstract": "Neural audio codecs, leveraging quantization algorithms, have significantly impacted various speech/audio tasks. While high-fidelity reconstruction is paramount for human perception, audio coding for machines (ACoM) prioritizes efficient compression and downstream task performance, disregarding perceptual nuances. This work introduces an efficient ACoM method that can compress and quantize any chosen intermediate feature representation of an already trained speech/audio downstream model. Our approach employs task-specific loss guidance alongside residual vector quantization (RVQ) losses, providing ultra-low bitrates (i.e., less than 200 bps) with a minimal loss of the downstream model performance. The resulting tokenizer is adaptable to various bitrates and model sizes for flexible deployment. Evaluated on automatic speech recognition and audio classification, our method demonstrates its efficacy and potential for broader task and architectural applicability through appropriate regularization.",
      "authors": [
        "Anastasia Kuznetsova",
        "Inseon Jang",
        "Wootaek Lim",
        "Minje Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:32:07+00:00",
          "link": "https://arxiv.org/abs/2507.12701v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "Task-Specific Audio Coding for Machines: Machine-Learned Latent Features Are Codes for That Machine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12701",
        "HTML": "https://arxiv.org/html/2507.12701v1",
        "PDF": "https://arxiv.org/pdf/2507.12701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on neural audio codecs and efficient audio coding for machines, aimed at audio compression for tasks like speech recognition, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12703",
      "abstract": "Demand charge often constitutes a significant portion of electricity costs for commercial electric vehicle charging station operators. This paper explores control methods to reduce peak power consumption at workplace EV charging stations in a joint price and power optimization framework. We optimize a menu of price options to incentivize users to select controllable charging service. Using this framework, we propose several solutions to achieve a reduction in both demand charge and overall operator costs. Through a Monte Carlo simulation, we find that model predictive control using a time series forecast can significantly reduce station operator costs.",
      "authors": [
        "Thibaud Cambronne",
        "Samuel Bobick",
        "Wente Zeng",
        "Scott Moura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:34:01+00:00",
          "link": "https://arxiv.org/abs/2507.12703v1",
          "size": "499kb",
          "version": "v1"
        }
      ],
      "title": "Joint Price and Power MPC for Peak Power Reduction at Workplace EV Charging Stations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12703",
        "HTML": "https://arxiv.org/html/2507.12703v1",
        "PDF": "https://arxiv.org/pdf/2507.12703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores control methods to reduce peak power consumption at EV charging stations, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12704",
      "abstract": "User activity sequences have emerged as one of the most important signals in recommender systems. We present a foundational model, PinFM, for understanding user activity sequences across multiple applications at a billion-scale visual discovery platform. We pretrain a transformer model with 20B+ parameters using extensive user activity data, then fine-tune it for specific applications, efficiently coupling it with existing models. While this pretraining-and-fine-tuning approach has been popular in other domains, such as Vision and NLP, its application in industrial recommender systems presents numerous challenges. The foundational model must be scalable enough to score millions of items every second while meeting tight cost and latency constraints imposed by these systems. Additionally, it should capture the interactions between user activities and other features and handle new items that were not present during the pretraining stage.\n  We developed innovative techniques to address these challenges. Our infrastructure and algorithmic optimizations, such as the Deduplicated Cross-Attention Transformer (DCAT), improved our throughput by 600% on Pinterest internal data. We demonstrate that PinFM can learn interactions between user sequences and candidate items by altering input sequences, leading to a 20% increase in engagement with new items. PinFM is now deployed to help improve the experience of more than a half billion users across various applications.",
      "authors": [
        "Xiangyi Chen",
        "Kousik Rajesh",
        "Matthew Lawhon",
        "Zelun Wang",
        "Hanyu Li",
        "Haomiao Li",
        "Saurabh Vishwas Joshi",
        "Pong Eksombatchai",
        "Jaewon Yang",
        "Yi-Ping Hsu",
        "Jiajing Xu",
        "Charles Rosenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:37:59+00:00",
          "link": "https://arxiv.org/abs/2507.12704v1",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "title": "PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12704",
        "PDF": "https://arxiv.org/pdf/2507.12704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses the PinFM model for user activity sequences in recommender systems, including pretraining with user data and fine-tuning, but its main focus is not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12705",
      "abstract": "Current speech evaluation suffers from two critical limitations: the need and difficulty of designing specialized systems targeting individual audio characteristics, and poor correlation between automatic evaluation methods and human preferences. This work presents a systematic study of Large Audio Model (LAM) as a Judge, AudioJudge, investigating whether it can provide a unified evaluation framework that addresses both challenges. We systematically explore AudioJudge across audio characteristic detection tasks, including pronunciation, speaking rate, speaker identification and speech quality, and system-level human preference simulation for automated benchmarking. We investigate different prompt engineering strategies, finding that audio concatenation combined with in-context learning significantly improves performance across both audio characteristic detection and human preference simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to enable general-purpose multi-aspect audio evaluation. This method decomposes speech assessment into specialized judges for lexical content, speech quality, and paralinguistic features, achieving up to 0.91 Spearman correlation with human preferences on our system ranking benchmark. Robustness analysis reveals that while LAMs maintain strong performance under acoustic noise, they exhibit significant verbosity and positional biases that require careful mitigation.",
      "authors": [
        "Potsawee Manakul",
        "Woody Haosheng Gan",
        "Michael J. Ryan",
        "Ali Sartaz Khan",
        "Warit Sirichotedumrong",
        "Kunat Pipatanakul",
        "William Held",
        "Diyi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:39:18+00:00",
          "link": "https://arxiv.org/abs/2507.12705v1",
          "size": "1133kb",
          "version": "v1"
        }
      ],
      "title": "AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12705",
        "HTML": "https://arxiv.org/html/2507.12705v1",
        "PDF": "https://arxiv.org/pdf/2507.12705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates using Large Audio Models for systematic audio evaluation, exploring audio characteristic detection and human preference correlation, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12707",
      "abstract": "Weighted equitable partitioning of a graph has been of interest lately due to several applications, including redistricting, network algorithms, and image decomposition. Weighting a partition according to the spanning-tree metric has been of mathematical and practical interest because it typically favors partitions with more compact pieces. An appealing algorithm suggested by Charikar et al. is to sample a random spanning tree and remove k-1 edges, producing a random forest. If the components of the forest form a balanced partition, the partition is equitable under an easily computed acceptance probability. Cannon et al. recently showed that spanning trees on grid graphs and grid-like graphs on $n$ vertices are splittable into $k$ equal sized pieces with probability at least $n^{-2k}$, leading to the first rigorous sampling algorithm for a class of graphs. We present complementary results showing that spanning trees on dense random graphs also have inverse polynomial probability of being splittable, giving another class of graphs where equitable partitions can be efficiently sampled exactly. These proofs also guarantee fast almost-uniform sampling for the up-down walk on forests, giving another provably efficient randomized method for generating equitable partitions.\n  Further, we show that problems with the well-studied ReCom algorithm for equitable partitioning are more extensive than previously known, even in special cases that were believed to be more promising. We present a family of graphs where the Markov chain fails to be irreducible when it must keep the components perfectly equitable; yet when the chain is allowed an imbalance of just one vertex between components, the rejection sampling step may take exponential time. This is true even when the graph satisfies desirable properties that have been conjectured to be sufficient for fast sampling.",
      "authors": [
        "David Gillman and Jacob Platnick and Dana Randall"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:57:55+00:00",
          "link": "https://arxiv.org/abs/2507.12707v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "Splittable Spanning Trees and Balanced Forests in Dense Random Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12707",
        "HTML": "https://arxiv.org/html/2507.12707v1",
        "PDF": "https://arxiv.org/pdf/2507.12707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on equitable partitioning of graphs and sampling algorithms, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12708",
      "abstract": "In this paper, we investigate on the modeling of demand response activities between the single aggregator and multiple participating consumers. The model incorporates the bilevel structure that naturally occurs in the information structure and decision sequence, where the aggregator assumes the role of a leader and the participating consumers play the role of followers. The proposed model is demonstrated to be effective in load control, helping the aggregator to meet the target reduction while the consumers pay cheaper electricity bill.",
      "authors": [
        "Seangleng Khe",
        "Parin Chaipunya",
        "Athikom Bangviwat"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.12708v1",
          "size": "228kb",
          "version": "v1"
        }
      ],
      "title": "A Stackelberg Game of Demand Response from the Aggregator's Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12708",
        "HTML": "https://arxiv.org/html/2507.12708v1",
        "PDF": "https://arxiv.org/pdf/2507.12708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves modeling demand response activities between aggregators and consumers, and does not discuss any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12709",
      "abstract": "Deep neural networks have revolutionized machine learning, yet their training dynamics remain theoretically unclear-we develop a continuous-time, matrix-valued stochastic differential equation (SDE) framework that rigorously connects the microscopic dynamics of SGD to the macroscopic evolution of singular-value spectra in weight matrices. We derive exact SDEs showing that squared singular values follow Dyson Brownian motion with eigenvalue repulsion, and characterize stationary distributions as gamma-type densities with power-law tails, providing the first theoretical explanation for the empirically observed 'bulk+tail' spectral structure in trained networks. Through controlled experiments on transformer and MLP architectures, we validate our theoretical predictions and demonstrate quantitative agreement between SDE-based forecasts and observed spectral evolution, providing a rigorous foundation for understanding why deep learning works.",
      "authors": [
        "Brian Richard Olsen",
        "Sam Fatehmanesh",
        "Frank Xiao",
        "Adarsh Kumarappan",
        "Anirudh Gajula"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.12709v1",
          "size": "1369kb",
          "version": "v1"
        }
      ],
      "title": "From SGD to Spectra: A Theory of Neural Network Weight Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12709",
        "HTML": "https://arxiv.org/html/2507.12709v1",
        "PDF": "https://arxiv.org/pdf/2507.12709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural network weight dynamics using a stochastic differential equation framework, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12711",
      "abstract": "Dismantling criminal networks or containing epidemics or misinformation through node removal is a well-studied problem. To evaluate the effectiveness of such efforts, one must measure the strength of the network before and after node removal. Process P1 is considered more effective than P2 if the strength of the residual network after removing k nodes via P1 is smaller than that from P2. This leads to the central question: How should network strength be measured?\n  Existing metrics rely solely on structural properties of the graph, such as connectivity. However, in real-world scenarios, particularly in law enforcement, the perception of agents regarding network strength can differ significantly from structural assessments. These perceptions are often ignored in traditional metrics.\n  We propose a new strength metric that integrates both structural properties and human perception. Using human subject surveys, we validate our approach against existing metrics. Our metric not only aligns more closely with human judgment but also outperforms traditional methods in identifying authoritative nodes and effectively dismantling both synthetic and real-world networks.",
      "authors": [
        "Kartikeya Kansal and Arunabha Sen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:21:14+00:00",
          "link": "https://arxiv.org/abs/2507.12711v1",
          "size": "1269kb",
          "version": "v1"
        }
      ],
      "title": "Identification of Authoritative Nodes and Dismantling of Illicit Networks Using a Novel Metric for Measuring Strength of a Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12711",
        "HTML": "https://arxiv.org/html/2507.12711v1",
        "PDF": "https://arxiv.org/pdf/2507.12711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on measuring the strength of networks for dismantling illicit networks, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12713",
      "abstract": "The proliferation of generative AI systems has created new challenges for the Free and Open Source Software (FOSS) community, particularly regarding how traditional copyleft principles should apply when open source code is used to train AI models. This article introduces the Contextual Copyleft AI (CCAI) license, a novel licensing mechanism that extends copyleft requirements from training data to the resulting generative AI models. The CCAI license offers significant advantages, including enhanced developer control, incentivization of open source AI development, and mitigation of openwashing practices. This is demonstrated through a structured three-part evaluation framework that examines (1) legal feasibility under current copyright law, (2) policy justification comparing traditional software and AI contexts, and (3) synthesis of cross-contextual benefits and risks. However, the increased risk profile of open source AI, particularly the potential for direct misuse, necessitates complementary regulatory approaches to achieve an appropriate risk-benefit balance. The paper concludes that when implemented within a robust regulatory environment focused on responsible AI usage, the CCAI license provides a viable mechanism for preserving and adapting core FOSS principles to the evolving landscape of generative AI development.",
      "authors": [
        "Grant Shanklin",
        "Emmie Hine",
        "Claudio Novelli",
        "Tyler Schroder",
        "Luciano Floridi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:42:51+00:00",
          "link": "https://arxiv.org/abs/2507.12713v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12713",
        "PDF": "https://arxiv.org/pdf/2507.12713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a licensing mechanism for open-source training data and generative AI, but it does not address the processing or creation of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12714",
      "abstract": "We develop a neural parametric model for 3D leaves for plant modeling and reconstruction that are essential for agriculture and computer graphics. While neural parametric models are actively studied for humans and animals, plant leaves present unique challenges due to their diverse shapes and flexible deformation. To this problem, we introduce a neural parametric model for leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into their 2D base shapes and 3D deformations. This representation allows learning from rich sources of 2D leaf image datasets for the base shapes, and also has the advantage of simultaneously learning textures aligned with the geometry. To model the 3D deformation, we propose a novel skeleton-free skinning model and create a newly captured 3D leaf dataset called DeformLeaf. We show that NeuraLeaf successfully generates a wide range of leaf shapes with deformation, resulting in accurate model fitting to 3D observations like depth maps and point clouds. Our implementation and dataset are available at https://neuraleaf-yang.github.io/.",
      "authors": [
        "Yang Yang",
        "Dongni Mao",
        "Hiroaki Santo",
        "Yasuyuki Matsushita",
        "Fumio Okura"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:46:24+00:00",
          "link": "https://arxiv.org/abs/2507.12714v1",
          "size": "5215kb",
          "version": "v1"
        }
      ],
      "title": "NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12714",
        "HTML": "https://arxiv.org/html/2507.12714v1",
        "PDF": "https://arxiv.org/pdf/2507.12714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural parametric models for 3D leaves, aiming at enhancing plant modeling and reconstruction. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12716",
      "abstract": "Soil moisture is a quantity of interest in many application areas including agriculture and climate modeling. Existing methods are not suitable for scale applications due to large deployment costs in high-resolution sensing applications such as for variable irrigation. In this work, we design, build and field deploy an autonomous mobile robot, MoistureMapper, for soil moisture sensing. The robot is equipped with Time Domain Reflectometry (TDR) sensors and a direct push drill mechanism for deploying the sensor to measure volumetric water content in the soil. Additionally, we implement and evaluate multiple adaptive sampling strategies based on a Gaussian Process based modeling to build a spatial mapping of moisture distribution in the soil. We present results from large scale computational simulations and proof-of-concept deployment on the field. The adaptive sampling approach outperforms a greedy benchmark approach and results in up to 30\\% reduction in travel distance and 5\\% reduction in variance in the reconstructed moisture maps. Link to video showing field experiments: https://youtu.be/S4bJ4tRzObg",
      "authors": [
        "Nathaniel Rose",
        "Hannah Chuang",
        "Manuel A Andrade-Rodriguez",
        "Rishi Parashar",
        "Dani Or",
        "Parikshit Maini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:47:37+00:00",
          "link": "https://arxiv.org/abs/2507.12716v1",
          "size": "10537kb",
          "version": "v1"
        }
      ],
      "title": "MoistureMapper: An Autonomous Mobile Robot for High-Resolution Soil Moisture Mapping at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12716",
        "HTML": "https://arxiv.org/html/2507.12716v1",
        "PDF": "https://arxiv.org/pdf/2507.12716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an autonomous mobile robot for soil moisture mapping, focusing on agricultural and climate applications. It does not address LLM training data processing or relevant data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12717",
      "abstract": "Control barrier functions provide a powerful means for synthesizing safety filters that ensure safety framed as forward set invariance. Key to CBFs' effectiveness is the simple inequality on the system dynamics: $\\dot{h} \\geq - \\alpha(h)$. Yet determining the class $\\mathcal{K}^e$ function $\\alpha$ is a user defined choice that can have a dramatic effect on the resulting system behavior. This paper formalizes the process of choosing $\\alpha$ using optimal-decay control barrier functions (OD-CBFs). These modify the traditional CBF inequality to: $\\dot{h} \\geq - \\omega \\alpha(h)$, where $\\omega \\geq 0$ is automatically determined by the safety filter. A comprehensive characterization of this framework is elaborated, including tractable conditions on OD-CBF validity, control invariance of the underlying sets in the state space, forward invariance conditions for safe sets, and discussion on optimization-based safe controllers in terms of their feasibility, Lipschitz continuity, and closed-form expressions. The framework also extends existing higher-order CBF techniques, addressing safety constraints with vanishing relative degrees. The proposed method is demonstrated on a satellite control problem in simulation.",
      "authors": [
        "Pio Ong",
        "Max H. Cohen",
        "Tamas G. Molnar",
        "Aaron D. Ames"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.12717v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "On the Properties of Optimal-Decay Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12717",
        "HTML": "https://arxiv.org/html/2507.12717v1",
        "PDF": "https://arxiv.org/pdf/2507.12717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores control barrier functions and their application to safety filters, with a focus on system dynamics. It does not pertain to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12719",
      "abstract": "Neural operators have emerged as a powerful tool for solving partial differential equations (PDEs) and other complex scientific computing tasks. However, the performance of single operator block is often limited, thus often requiring composition of basic operator blocks to achieve better per-formance. The traditional way of composition is staking those blocks like feedforward neural networks, which may not be very economic considering parameter-efficiency tradeoff. In this pa-per, we propose a novel dual path architecture that significantly enhances the capabilities of basic neural operators. The basic operator block is organized in parallel two paths which are similar with ResNet and DenseNet. By introducing this parallel processing mechanism, our architecture shows a more powerful feature extraction and solution approximation ability compared with the original model. We demonstrate the effectiveness of our approach through extensive numerical experi-ments on a variety of PDE problems, including the Burgers' equation, Darcy Flow Equation and the 2d Navier-Stokes equation. The experimental results indicate that on certain standard test cas-es, our model achieves a relative improvement of over 30% compared to the basic model. We also apply this structure on two standard neural operators (DeepONet and FNO) selected from different paradigms, which suggests that the proposed architecture has excellent versatility and offering a promising direction for neural operator structure design.",
      "authors": [
        "Yichen Wang",
        "Wenlian Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.12719v1",
          "size": "877kb",
          "version": "v1"
        }
      ],
      "title": "DPNO: A Dual Path Architecture For Neural Operator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12719",
        "PDF": "https://arxiv.org/pdf/2507.12719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a dual path architecture for neural operators, targeting the solution of partial differential equations. It does not relate to LLM training data processing or operations related to training dataset handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12720",
      "abstract": "Language models (LMs) are challenging to adapt to new data distributions by simple finetuning. This is due to the rigidity of their subword tokenizers, which typically remain unchanged during adaptation. This inflexibility often leads to inefficient tokenization, causing overfragmentation of out-of-distribution domains, unseen languages, or scripts. In this work, we develop byte-level LMs with learnable tokenizers to make tokenization adaptive. Our models include a submodule that learns to predict boundaries between the input byte sequence, encoding it into variable-length segments. Existing tokenizer-free methods train this boundary predictor using an auxiliary loss that enforces a fixed compression rate across the training corpus, introducing a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective that enables significantly greater flexibility during adaptation. Evaluating across multiple multilingual benchmarks, morphologically diverse tasks, and domains, we demonstrate that FLEXITOKENS consistently reduces token over-fragmentation and achieves up to 10\\% improvements on downstream task performance compared to subword and other gradient-based tokenizers. Code and data for our experiments will be released at https://github.com/owos/flexitokens",
      "authors": [
        "Abraham Toluase Owodunni",
        "Orevaoghene Ahia",
        "Sachin Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:55:41+00:00",
          "link": "https://arxiv.org/abs/2507.12720v1",
          "size": "4293kb",
          "version": "v1"
        }
      ],
      "title": "FLEXITOKENS: Flexible Tokenization for Evolving Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12720",
        "PDF": "https://arxiv.org/pdf/2507.12720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on flexible tokenization\u2014a process relevant to data processing in LLMs\u2014to adapt models to new data distributions. The main contribution is in model adaptation and tokenization, but it indirectly impacts data processing through tokenization improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12721",
      "abstract": "Human-AI interfaces play a crucial role in advancing practices and research within the healthcare domain. However, designing such interfaces presents a substantial challenge for designers. In this paper, we propose systematic guidance for designing human-AI interfaces in typical healthcare scenarios by summarizing the design patterns for presenting and interacting with common information entities. To deepen our understanding of these 12 design patterns, we interviewed 12 healthcare professionals to explore potential usage scenarios and important considerations. Furthermore, we conducted workshops with 14 participants recruited online to evaluate our design patterns. Finally, we discussed the generalizability of the design patterns to other application domains, the limitations, and the future work.",
      "authors": [
        "Rui Sheng",
        "Chuhan Shi",
        "Sobhan Lotfi",
        "Shiyi Liu",
        "Adam Perer",
        "Huamin Qu",
        "Furui Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:56:31+00:00",
          "link": "https://arxiv.org/abs/2507.12721v1",
          "size": "9901kb",
          "version": "v1"
        }
      ],
      "title": "Design Patterns of Human-AI Interfaces in Healthcare",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12721",
        "PDF": "https://arxiv.org/pdf/2507.12721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses designing human-AI interfaces in the healthcare domain, which is not related to LLM data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12723",
      "abstract": "Recent advances in voice cloning and lip synchronization models have enabled Synthesized Audiovisual Forgeries (SAVFs), where both audio and visuals are manipulated to mimic a target speaker. This significantly increases the risk of misinformation by making fake content seem real. To address this issue, existing methods detect or localize manipulations but cannot recover the authentic audio that conveys the semantic content of the message. This limitation reduces their effectiveness in combating audiovisual misinformation. In this work, we introduce the task of Authentic Audio Recovery (AAR) and Tamper Localization in Audio (TLA) from SAVFs and propose a cross-modal watermarking framework to embed authentic audio into visuals before manipulation. This enables AAR, TLA, and a robust defense against misinformation. Extensive experiments demonstrate the strong performance of our method in AAR and TLA against various manipulations, including voice cloning and lip synchronization.",
      "authors": [
        "Minyoung Kim",
        "Sehwan Park",
        "Sungmin Cha",
        "Paul Hongsuck Seo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:02:39+00:00",
          "link": "https://arxiv.org/abs/2507.12723v1",
          "size": "381kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Modal Watermarking for Authentic Audio Recovery and Tamper Localization in Synthesized Audiovisual Forgeries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12723",
        "HTML": "https://arxiv.org/html/2507.12723v1",
        "PDF": "https://arxiv.org/pdf/2507.12723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on cross-modal watermarking for authentic audio recovery, a task unrelated to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12724",
      "abstract": "We present TransEvalnia, a prompting-based translation evaluation and ranking system that uses reasoning in performing its evaluations and ranking. This system presents fine-grained evaluations based on a subset of the Multidimensional Quality Metrics (https://themqm.org/), returns an assessment of which translation it deems the best, and provides numerical scores for the various dimensions and for the overall translation. We show that TransEvalnia performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al. 2024) on our own English-Japanese data as well as several language pairs from various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations returned are deemed highly acceptable to human raters, and that the scores assigned to the translations by Sonnet, as well as other LLMs, correlate well with scores assigned by the human raters. We also note the sensitivity of our system -- as well as MT-Ranker -- to the order in which the translations are presented, and we propose methods to address this position bias. All data, including the system's evaluation and reasoning, human assessments, as well as code is released.",
      "authors": [
        "Richard Sproat",
        "Tianyu Zhao",
        "Llion Jones"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.12724v1",
          "size": "353kb",
          "version": "v1"
        }
      ],
      "title": "TransEvalnia: Reasoning-based Evaluation and Ranking of Translations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12724",
        "PDF": "https://arxiv.org/pdf/2507.12724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "TransEvalnia is about translation evaluation and ranking, which pertains to translation quality assessment using LLMs, but does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12727",
      "abstract": "Small object detection remains a challenging problem in the field of object detection. To address this challenge, we propose an enhanced YOLOv8-based model, SOD-YOLO. This model integrates an ASF mechanism in the neck to enhance multi-scale feature fusion, adds a Small Object Detection Layer (named P2) to provide higher-resolution feature maps for better small object detection, and employs Soft-NMS to refine confidence scores and retain true positives. Experimental results demonstrate that SOD-YOLO significantly improves detection performance, achieving a 36.1% increase in mAP$_{50:95}$ and 20.6% increase in mAP$_{50}$ on the VisDrone2019-DET dataset compared to the baseline model. These enhancements make SOD-YOLO a practical and efficient solution for small object detection in UAV imagery. Our source code, hyper-parameters, and model weights are available at https://github.com/iamwangxiaobai/SOD-YOLO.",
      "authors": [
        "Peijun Wang",
        "Jinhua Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:04:54+00:00",
          "link": "https://arxiv.org/abs/2507.12727v1",
          "size": "182kb",
          "version": "v1"
        }
      ],
      "title": "SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12727",
        "HTML": "https://arxiv.org/html/2507.12727v1",
        "PDF": "https://arxiv.org/pdf/2507.12727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes improvements in small object detection using YOLO-based models for UAV imagery, which is not related to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12730",
      "abstract": "We propose a privacy-preserving semantic-segmentation method for applying perceptual encryption to images used for model training in addition to test images. This method also provides almost the same accuracy as models without any encryption. The above performance is achieved using a domain-adaptation technique on the embedding structure of the Vision Transformer (ViT). The effectiveness of the proposed method was experimentally confirmed in terms of the accuracy of semantic segmentation when using a powerful semantic-segmentation model with ViT called Segmentation Transformer.",
      "authors": [
        "Homare Sueyoshi",
        "Kiyoshi Nishikawa and Hitoshi Kiya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.12730v1",
          "size": "2660kb",
          "version": "v1"
        }
      ],
      "title": "A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12730",
        "HTML": "https://arxiv.org/html/2507.12730v1",
        "PDF": "https://arxiv.org/pdf/2507.12730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy-preserving semantic segmentation using domain-adaptation techniques and perceptual encryption, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12731",
      "abstract": "Navigating in off-road environments for wheeled mobile robots is challenging due to dynamic and rugged terrain. Traditional physics-based stability metrics, such as Static Stability Margin (SSM) or Zero Moment Point (ZMP) require knowledge of contact forces, terrain geometry, and the robot's precise center-of-mass that are difficult to measure accurately in real-world field conditions. In this work, we propose a learning-based approach to estimate robot platform stability directly from proprioceptive data using a lightweight neural network, IMUnet. Our method enables data-driven inference of robot stability without requiring an explicit terrain model or force sensing.\n  We also develop a novel vision-based ArUco tracking method to compute a scalar score to quantify robot platform stability called C3 score. The score captures image-space perturbations over time as a proxy for physical instability and is used as a training signal for the neural network based model. As a pilot study, we evaluate our approach on data collected across multiple terrain types and speeds and demonstrate generalization to previously unseen conditions. These initial results highlight the potential of using IMU and robot velocity as inputs to estimate platform stability. The proposed method finds application in gating robot tasks such as precision actuation and sensing, especially for mobile manipulation tasks in agricultural and space applications. Our learning method also provides a supervision mechanism for perception based traversability estimation and planning.",
      "authors": [
        "Nathaniel Rose",
        "Arif Ahmed",
        "Emanuel Gutierrez-Cornejo",
        "Parikshit Maini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:24:35+00:00",
          "link": "https://arxiv.org/abs/2507.12731v1",
          "size": "5649kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Predict Mobile Robot Stability in Off-Road Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12731",
        "HTML": "https://arxiv.org/html/2507.12731v1",
        "PDF": "https://arxiv.org/pdf/2507.12731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a learning-based approach for estimating mobile robot stability, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12732",
      "abstract": "This study proposes a method to improve the performance of Werewolf agents by switching between predefined strategies based on the attitudes of other players and the context of conversations. While prior works of Werewolf agents using prompt engineering have employed methods where effective strategies are implicitly defined, they cannot adapt to changing situations. In this research, we propose a method that explicitly selects an appropriate strategy based on the game context and the estimated roles of other players. We compare the strategy adaptation Werewolf agents with baseline agents using implicit or fixed strategies and verify the effectiveness of our proposed method.",
      "authors": [
        "Fuya Nakamori",
        "Yin Jou Huang",
        "Fei Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:27:45+00:00",
          "link": "https://arxiv.org/abs/2507.12732v1",
          "size": "320kb",
          "version": "v1"
        }
      ],
      "title": "Strategy Adaptation in Large Language Model Werewolf Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12732",
        "HTML": "https://arxiv.org/html/2507.12732v1",
        "PDF": "https://arxiv.org/pdf/2507.12732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes strategy adaptation in Werewolf agents; however, it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12733",
      "abstract": "We study repeated \\textsf{Uniform Pricing} mechanisms with multiple buyers. In each round, the platform sets a uniform price for all buyers; a transaction occurs if at least one buyer bids at or above this price. Prior work demonstrates that structural assumptions on bid distributions -- such as regularity or monotone hazard rate (MHR) property -- enable significant improvements in pricing query complexity (from $\\Theta\\left(\\varepsilon^{-3}\\right)$ to $\\widetilde\\Theta\\left(\\varepsilon^{-2}\\right)$\\footnote{The $\\widetilde \\Theta$ notation omits polylogarithmic factors.}) and regret bounds (from $\\Theta\\left(T^{2/3}\\right)$ to $\\widetilde\\Theta\\left(T^{1/2}\\right)$) for single-buyer settings. Strikingly, we demonstrate that these improvements vanish with multiple buyers: both general and structured distributions (including regular/MHR) share identical asymptotic performance, achieving pricing query complexity of $\\widetilde\\Theta\\left(\\varepsilon^{-3}\\right)$ and regret of $\\widetilde\\Theta\\left(T^{2/3}\\right)$.\n  This result reveals a dichotomy between single-agent and multi-agent environments. While the special structure of distributions simplifies learning for a single buyer, competition among multiple buyers erases these benefits, forcing platforms to adopt universally robust pricing strategies. Our findings challenge conventional wisdom from single-buyer theory and underscore the necessity of revisiting mechanism design principles in more competitive settings.",
      "authors": [
        "Houshuang Chen",
        "Yaonan Jin",
        "Pinyan Lu",
        "Chihao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.12733v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "Competition Erases Simplicity: Tight Regret Bounds for Uniform Pricing with Multiple Buyers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12733",
        "PDF": "https://arxiv.org/pdf/2507.12733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses uniform pricing mechanisms in scenarios with multiple buyers. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12734",
      "abstract": "Research has shown that an audiences' age impacts their engagement in digital media. Interactive narrative visualization is an increasingly popular form of digital media that combines data visualization and storytelling to convey important information. However, audience age is often overlooked by interactive narrative visualization authors. Using an established visualization engagement questionnaire, we ran an empirical experiment where we compared end-user engagement to audience age. We found a small difference in engagement scores where older age cohorts were less engaged than the youngest age cohort. Our qualitative analysis revealed that the terminology and overall understanding of interactive narrative patterns integrated into narrative visualization was more apparent in the feedback from younger age cohorts relative to the older age cohorts. We conclude this paper with a series of recommendations for authors of interactive narrative visualization on how to design inclusively for audiences according to their age.",
      "authors": [
        "Nina Errey",
        "Yi Chen",
        "Yu Dong",
        "Quang Vinh Nguyen",
        "Xiaoru Yuan",
        "Tuck Wah Leong and Christy Jie Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:33:22+00:00",
          "link": "https://arxiv.org/abs/2507.12734v1",
          "size": "2136kb",
          "version": "v1"
        }
      ],
      "title": "An Age-based Study into Interactive Narrative Visualization Engagement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12734",
        "HTML": "https://arxiv.org/html/2507.12734v1",
        "PDF": "https://arxiv.org/pdf/2507.12734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on audience engagement in digital media, specifically interactive narrative visualization, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12739",
      "abstract": "Spatial grounding, the process of associating natural language expressions with corresponding image regions, has rapidly advanced due to the introduction of transformer-based models, significantly enhancing multimodal representation and cross-modal alignment. Despite this progress, the field lacks a comprehensive synthesis of current methodologies, dataset usage, evaluation metrics, and industrial applicability. This paper presents a systematic literature review of transformer-based spatial grounding approaches from 2018 to 2025. Our analysis identifies dominant model architectures, prevalent datasets, and widely adopted evaluation metrics, alongside highlighting key methodological trends and best practices. This study provides essential insights and structured guidance for researchers and practitioners, facilitating the development of robust, reliable, and industry-ready transformer-based spatial grounding models.",
      "authors": [
        "Ijazul Haq",
        "Muhammad Saqib",
        "Yingjie Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:44:01+00:00",
          "link": "https://arxiv.org/abs/2507.12739v1",
          "size": "1276kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-based Spatial Grounding: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12739",
        "HTML": "https://arxiv.org/html/2507.12739v1",
        "PDF": "https://arxiv.org/pdf/2507.12739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a survey of transformer-based spatial grounding in multimodal applications, examining methodologies and datasets. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12741",
      "abstract": "Cybernetic avatars (CAs) are key components of an avatar-symbiotic society, enabling individuals to overcome physical limitations through virtual agents and robotic assistants. While semi-autonomous CAs intermittently require human teleoperation and supervision, the deployment of fully autonomous CAs remains a challenge. This study evaluates public perception and potential social impacts of fully autonomous CAs for physical support in daily life. To this end, we conducted a large-scale demonstration and survey during Avatar Land, a 19-day public event in Osaka, Japan, where fully autonomous robotic CAs, alongside semi-autonomous CAs, performed daily object retrieval tasks. Specifically, we analyzed responses from 2,285 visitors who engaged with various CAs, including a subset of 333 participants who interacted with fully autonomous CAs and shared their perceptions and concerns through a survey questionnaire. The survey results indicate interest in CAs for physical support in daily life and at work. However, concerns were raised regarding task execution reliability. In contrast, cost and human-like interaction were not dominant concerns. Project page: https://lotfielhafi.github.io/FACA-Survey/.",
      "authors": [
        "Lotfi El Hafi",
        "Kazuma Onishi",
        "Shoichi Hasegawa",
        "Akira Oyama",
        "Tomochika Ishikawa",
        "Masashi Osada",
        "Carl Tornberg",
        "Ryoma Kado",
        "Kento Murata",
        "Saki Hashimoto",
        "Sebastian Carrera Villalobos",
        "Akira Taniguchi",
        "Gustavo Alfonso Garcia Ricardez",
        "Yoshinobu Hagiwara",
        "Tatsuya Aoki",
        "Kensuke Iwata",
        "Takato Horii",
        "Yukiko Horikawa",
        "Takahiro Miyashita",
        "Tadahiro Taniguchi",
        "Hiroshi Ishiguro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:49:43+00:00",
          "link": "https://arxiv.org/abs/2507.12741v1",
          "size": "1113kb",
          "version": "v1"
        }
      ],
      "title": "Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12741",
        "HTML": "https://arxiv.org/html/2507.12741v1",
        "PDF": "https://arxiv.org/pdf/2507.12741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates public perception of cybernetic avatars and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12742",
      "abstract": "We verify quasi-optimality of the Crouzeix-Raviart FEM for nonlinear problems of $p$-Laplace type. More precisely, we show that the error of the Crouzeix-Raviart FEM with respect to a quasi-norm is bounded from above by a uniformly bounded constant times the best-approximation error plus a data oscillation term. As a byproduct, we verify a novel more localized a priori error estimate for the conforming lowest-order Lagrange FEM.",
      "authors": [
        "Johannes Storn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.12742v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Quasi-optimality of the Crouzeix-Raviart FEM for p-Laplace-type problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12742",
        "HTML": "https://arxiv.org/html/2507.12742v1",
        "PDF": "https://arxiv.org/pdf/2507.12742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concerns quasi-optimality in FEM for p-Laplace-type problems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12743",
      "abstract": "Constructing a control invariant set with an appropriate shape that fits within a given state constraint is a fundamental problem in safety-critical control but is known to be difficult, especially for large or complex spaces. This paper introduces a safe control framework of utilizing PCBF: continuously parametrized control barrier functions (CBFs). In PCBF, each choice of parameter corresponds to a control invariant set of relatively simple shape. Invariance-preserving control is done by dynamically selecting a parameter whose corresponding invariant set lies within the safety bound. This eliminates the need for synthesizing a single complex CBF that matches the entire free space. It also enables easier adaptation to diverse environments. By assigning a differentiable dynamics on the parameter space, we derive a lightweight feedback controller based on quadratic programming (QP), namely PCBF-QP. We also discuss on how to build a valid PCBF for a class of systems and how to constrain the parameter so that the invariant set does not exceed the safety bound. The concept is also extended to cover continuously parametrized high-order CBFs, which is called high-order PCBF. Finally, simulation experiments are conducted to validate the proposed approach.",
      "authors": [
        "Inkyu Jang and H. Jin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:56:05+00:00",
          "link": "https://arxiv.org/abs/2507.12743v1",
          "size": "951kb",
          "version": "v1"
        }
      ],
      "title": "Invariance Guarantees using Continuously Parametrized Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12743",
        "PDF": "https://arxiv.org/pdf/2507.12743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a control framework for safety-critical systems using control barrier functions, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12744",
      "abstract": "With the rapid development of lightweight visual neural network architectures, traditional high-performance vision models have undergone significant compression, greatly improving their computational efficiency and energy consumption ratio. This makes them feasible for deployment on resource-constrained edge computing devices. We propose a visual-assisted navigation framework called Atrous Strip Convolution-Sliding Window (ASC-SW), which leverages a depth camera and a lightweight visual neural network to assist map-based mobile robot navigation. This framework compensates for the inability of traditional light detection and range (LiDAR) sensors to detect ground-level obstacles such as ground-level wires. We introduce a lightweight and efficient segmentation model, Atrous Strip Convolution Network (ASCnet), for detecting deformable linear objects (DLOs). MobileNetV2 is used as the backbone network, and Atrous Strip Convolution Spatial Pyramid Pooling (ASCSPP) is designed to extract DLO features more effectively. Atrous Strip Convolution is integrated into ASCSPP to accurately identify the linear structure of DLOs with low computational cost. Additionally, a Sliding Window (SW) post-processing module is proposed to denoise the output in complex environments, improving recognition accuracy. Our method strikes a balance between inference speed and segmentation performance. It achieves a mean Intersection over Union (Miou) score of 75.3% on a self-built dataset and reaches 9.3 FPS inference speed on the Jetson Orin Nano edge device. Overall, our approach outperforms existing DLO detection models and has been successfully validated on a physical robotic platform.",
      "authors": [
        "Cheng Liu and Fan Zhu and Yaoyu Zhuang Zhinan Chen Jiefeng Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.12744v1",
          "size": "10826kb",
          "version": "v1"
        }
      ],
      "title": "ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12744",
        "HTML": "https://arxiv.org/html/2507.12744v1",
        "PDF": "https://arxiv.org/pdf/2507.12744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a visual-assisted navigation framework for mobile robots using depth cameras and lightweight neural networks, without any mention of LLM training data processing or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12745",
      "abstract": "With the growing demand for renewable energy, countries are accelerating the construction of photovoltaic (PV) power stations. However, accurately forecasting power data for newly constructed PV stations is extremely challenging due to limited data availability. To this end, we propose a novel interpretable dynamic selection network (IDS-Net) based on feature information fusion to achieve accurate few-shot prediction. This transfer learning framework primarily consists of two parts. In the first stage, we pre-train on the large dataset, utilizing Maximum Mean Discrepancy (MMD) to select the source domain dataset most similar to the target domain data distribution. Subsequently, the ReliefF algorithm is utilized for feature selection, reducing the influence of feature redundancy. Then, the Hampel Identifier (HI) is used for training dataset outlier correction. In the IDS-Net model, we first obtain the initial extracted features from a pool of predictive models. Following this, two separate weighting channels are utilized to determine the interpretable weights for each sub-model and the adaptive selection outcomes, respectively. Subsequently, the extracted feature results from each sub-model are multiplied by their corresponding weights and then summed to obtain the weighted extracted features. Then, we perform cross-embedding on the additional features and fuse them with the extracted weighted features. This fused information is then passed through the MLP (Multi-Layer Perceptron) layer to obtain predictions. In the second stage, we design an end-to-end adaptive transfer learning strategy to obtain the final prediction results on the target dataset. We validate the transfer learning process using two PV power datasets from Hebei province, China, to demonstrate the effectiveness and generalization of our framework and transfer learning strategy.",
      "authors": [
        "Hang Fan",
        "Weican Liu",
        "Zuhan Zhang",
        "Ying Lu",
        "Wencai Run",
        "Dunnan Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:03:07+00:00",
          "link": "https://arxiv.org/abs/2507.12745v1",
          "size": "3782kb",
          "version": "v1"
        }
      ],
      "title": "IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12745",
        "HTML": "https://arxiv.org/html/2507.12745v1",
        "PDF": "https://arxiv.org/pdf/2507.12745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses IDS-Net, a framework for photovoltaic power prediction using a transfer learning approach and feature selection, with no relevance to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12749",
      "abstract": "The boom in visualization generation tools has significantly lowered the threshold for chart authoring. Nevertheless, chart authors with an insufficient understanding of perceptual theories may encounter difficulties in evaluating the effectiveness of chart representations, thereby struggling to identify the appropriate chart design to convey the intended data patterns. To address this issue, we propose a perception simulation model that can assess the perceptual effectiveness of charts by predicting graphical patterns that chart viewers are likely to notice. The perception simulation model integrates perceptual theory into visual feature extraction of chart elements to provide interpretable model outcomes. Human perceptual results proved that the outcome of our model can simulate the perceptual grouping behaviors of most chart viewers and cover diverse perceptual results. We also embed the model into a prototype interface called PatternSight to facilitate chart authors in assessing whether the chart design can satisfy their pattern representation requirements as expected and determining feasible improvements of visual design. According to the results of a user experiment, PatternSight can effectively assist chart authors in optimizing chart design for representing data patterns.",
      "authors": [
        "Xumeng Wang",
        "Xiangxuan Zhang",
        "Zhiqi Gao",
        "Shuangcheng Jiao",
        "and Yuxin Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:05:38+00:00",
          "link": "https://arxiv.org/abs/2507.12749v1",
          "size": "5779kb",
          "version": "v1"
        }
      ],
      "title": "PatternSight: A Perceptual Grouping Effectiveness Assessment Approach for Graphical Patterns in Charts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12749",
        "HTML": "https://arxiv.org/html/2507.12749v1",
        "PDF": "https://arxiv.org/pdf/2507.12749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with assessing perceptual grouping effectiveness in chart designs using a perception simulation model, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12750",
      "abstract": "Modern deep models are trained on large real-world datasets, where data quality varies and redundancy is common. Data-centric approaches such as dataset pruning have shown promise in improving training efficiency and model performance. However, most existing methods rely on static heuristics or task-specific metrics, limiting their robustness and generalizability across domains. In this work, we introduce a dynamic dataset pruning framework that adaptively selects training samples based on both task-driven difficulty and cross-modality semantic consistency. By incorporating supervision from pretrained multimodal foundation models, our approach captures training dynamics while effectively filtering out uninformative samples. Our work highlights the potential of integrating cross-modality alignment for robust sample selection, advancing data-centric learning toward more efficient and robust practices across application domains.",
      "authors": [
        "Suorong Yang",
        "Peijia Li",
        "Yujie Liu",
        "Zhiming Xu",
        "Peng Ye",
        "Wanli Ouyang",
        "Furao Shen",
        "Dongzhan Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:08:26+00:00",
          "link": "https://arxiv.org/abs/2507.12750v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12750",
        "HTML": "https://arxiv.org/html/2507.12750v1",
        "PDF": "https://arxiv.org/pdf/2507.12750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a dynamic dataset pruning framework focusing on task-driven difficulty and cross-modality semantic consistency, which touches upon data quality improvement but not specifically in the LLM training context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12751",
      "abstract": "Energy efficiency is a critical factor in the performance and autonomy of quadrupedal robots. While previous research has focused on mechanical design and actuation improvements, the impact of gait parameters on energetics has been less explored. In this paper, we hypothesize that gait parameters, specifically duty factor, phase shift, and stride duration, are key determinants of energy consumption in quadrupedal locomotion. To test this hypothesis, we modeled the Unitree A1 quadrupedal robot and developed a locomotion controller capable of independently adjusting these gait parameters. Simulations of bounding gaits were conducted in Gazebo across a range of gait parameters at three different speeds: low, medium, and high. Experimental tests were also performed to validate the simulation results. The findings demonstrate that optimizing gait parameters can lead to significant reductions in energy consumption, enhancing the overall efficiency of quadrupedal locomotion. This work contributes to the advancement of energy-efficient control strategies for legged robots, offering insights directly applicable to commercially available platforms.",
      "authors": [
        "Yasser G. Alqaham",
        "Jing Cheng",
        "and Zhenyu Gan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:11:08+00:00",
          "link": "https://arxiv.org/abs/2507.12751v1",
          "size": "2687kb",
          "version": "v1"
        }
      ],
      "title": "Refining Motion for Peak Performance: Identifying Optimal Gait Parameters for Energy-Efficient Quadrupedal Bounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12751",
        "HTML": "https://arxiv.org/html/2507.12751v1",
        "PDF": "https://arxiv.org/pdf/2507.12751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores optimal gait parameters for energy efficiency in quadrupedal robots, unrelated to any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12753",
      "abstract": "Recent open-vocabulary robot mapping methods enrich dense geometric maps with pre-trained visual-language features, achieving a high level of detail and guiding robots to find objects specified by open-vocabulary language queries. While the issue of scalability for such approaches has received some attention, another fundamental problem is that high-detail object mapping quickly becomes outdated, as objects get moved around a lot. In this work, we develop a mapping and navigation system for object-goal navigation that, from the ground up, considers the possibilities that a queried object can have moved, or may not be mapped at all. Instead of striving for high-fidelity mapping detail, we consider that the main purpose of a map is to provide environment grounding and context, which we combine with the semantic priors of LLMs to reason about object locations and deploy an active, online approach to navigate to the objects. Through simulated and real-world experiments we find that our approach tends to have higher retrieval success at shorter path lengths for static objects and by far outperforms prior approaches in cases of dynamic or unmapped object queries. We provide our code and dataset at: https://anonymous.4open.science/r/osmAG-LLM.",
      "authors": [
        "Fujing Xie",
        "S\\\"oren Schwertfeger",
        "Hermann Blum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:14:37+00:00",
          "link": "https://arxiv.org/abs/2507.12753v1",
          "size": "12744kb",
          "version": "v1"
        }
      ],
      "title": "osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12753",
        "HTML": "https://arxiv.org/html/2507.12753v1",
        "PDF": "https://arxiv.org/pdf/2507.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on object navigation in robotic systems, utilizing semantic maps and LLMs for reasoning. It doesn't address training data processing relevant to LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12755",
      "abstract": "Developing precise and computationally efficient traffic accident anticipation system is crucial for contemporary autonomous driving technologies, enabling timely intervention and loss prevention. In this paper, we propose an accident anticipation framework employing a dual-branch architecture that effectively integrates visual information from dashcam videos with structured textual data derived from accident reports. Furthermore, we introduce a feature aggregation method that facilitates seamless integration of multimodal inputs through large models (GPT-4o, Long-CLIP), complemented by targeted prompt engineering strategies to produce actionable feedback and standardized accident archives. Comprehensive evaluations conducted on benchmark datasets (DAD, CCD, and A3D) validate the superior predictive accuracy, enhanced responsiveness, reduced computational overhead, and improved interpretability of our approach, thus establishing a new benchmark for state-of-the-art performance in traffic accident anticipation.",
      "authors": [
        "Yanchen Guan",
        "Haicheng Liao",
        "Chengyue Wang",
        "Bonan Wang",
        "Jiaxun Zhang",
        "Jia Hu",
        "Zhenning Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:16:28+00:00",
          "link": "https://arxiv.org/abs/2507.12755v1",
          "size": "19527kb",
          "version": "v1"
        }
      ],
      "title": "Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12755",
        "HTML": "https://arxiv.org/html/2507.12755v1",
        "PDF": "https://arxiv.org/pdf/2507.12755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses large models and prompt engineering for accident anticipation, it doesn't make a significant contribution to LLM training data processing, focusing instead on model architecture and task design."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12758",
      "abstract": "Hair transfer is increasingly valuable across domains such as social media, gaming, advertising, and entertainment. While significant progress has been made in single-image hair transfer, video-based hair transfer remains challenging due to the need for temporal consistency, spatial fidelity, and dynamic adaptability. In this work, we propose HairShifter, a novel \"Anchor Frame + Animation\" framework that unifies high-quality image hair transfer with smooth and coherent video animation. At its core, HairShifter integrates a Image Hair Transfer (IHT) module for precise per-frame transformation and a Multi-Scale Gated SPADE Decoder to ensure seamless spatial blending and temporal coherence. Our method maintains hairstyle fidelity across frames while preserving non-hair regions. Extensive experiments demonstrate that HairShifter achieves state-of-the-art performance in video hairstyle transfer, combining superior visual quality, temporal consistency, and scalability. The code will be publicly available. We believe this work will open new avenues for video-based hairstyle transfer and establish a robust baseline in this field.",
      "authors": [
        "Wangzheng Shi",
        "Yinglin Zheng",
        "Yuxin Lin",
        "Jianmin Bao",
        "Ming Zeng",
        "Dong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:22:39+00:00",
          "link": "https://arxiv.org/abs/2507.12758v1",
          "size": "1798kb",
          "version": "v1"
        }
      ],
      "title": "HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12758",
        "HTML": "https://arxiv.org/html/2507.12758v1",
        "PDF": "https://arxiv.org/pdf/2507.12758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with video hair transfer, focusing on graphical techniques and animation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12759",
      "abstract": "Large reasoning models (LRMs) can do complex reasoning via long chain-of-thought (CoT) involving cognitive strategies such as backtracking and self-correction. Recent studies suggest that some models inherently possess these long reasoning abilities, which may be unlocked via extra training. Our work first investigates whether we can elicit such behavior without any training. To this end, we propose a decoding-time approach, ThinkLogit, which utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for long reasoning using a substantially smaller model as guider. We then show that we can further boost performance by training the guider model with preference optimization over correct/incorrect reasoning pairs sampled from both the target and guider model -- a setup we refer to as ThinkLogit-DPO. Our experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative improvement in pass@1 by 26% and 29%, respectively, over four mathematical datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model 21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills acquired through reinforcement learning, improving pass@1 by 13% relative compared to the Qwen2.5-32B base model. Our work presents a computationally-efficient method to elicit long reasoning in large models with minimal or no additional training.",
      "authors": [
        "Yunxiang Zhang",
        "Muhammad Khalifa",
        "Lechen Zhang",
        "Xin Liu",
        "Ayoung Lee",
        "Xinliang Frederick Zhang",
        "Farima Fatahi Bayat",
        "Lu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:31:36+00:00",
          "link": "https://arxiv.org/abs/2507.12759v1",
          "size": "414kb",
          "version": "v1"
        }
      ],
      "title": "Logit Arithmetic Elicits Long Reasoning Capabilities Without Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12759",
        "HTML": "https://arxiv.org/html/2507.12759v1",
        "PDF": "https://arxiv.org/pdf/2507.12759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods to improve reasoning capabilities in LLMs without training, focusing on inference techniques, not training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12760",
      "abstract": "Unified Medical Image Segmentation (UMIS) is critical for comprehensive anatomical assessment but faces challenges due to multi-scale structural heterogeneity. Conventional pixel-based approaches, lacking object-level anatomical insight and inter-organ relational modeling, struggle with morphological complexity and feature conflicts, limiting their efficacy in UMIS. We propose Mamba Snake, a novel deep snake framework enhanced by state space modeling for UMIS. Mamba Snake frames multi-contour evolution as a hierarchical state space atlas, effectively modeling macroscopic inter-organ topological relationships and microscopic contour refinements. We introduce a snake-specific vision state space module, the Mamba Evolution Block (MEB), which leverages effective spatiotemporal information aggregation for adaptive refinement of complex morphologies. Energy map shape priors further ensure robust long-range contour evolution in heterogeneous data. Additionally, a dual-classification synergy mechanism is incorporated to concurrently optimize detection and segmentation, mitigating under-segmentation of microstructures in UMIS. Extensive evaluations across five clinical datasets reveal Mamba Snake's superior performance, with an average Dice improvement of 3\\% over state-of-the-art methods.",
      "authors": [
        "Ruicheng Zhang",
        "Haowei Guo",
        "Kanghui Tian",
        "Jun Zhou",
        "Mingliang Yan",
        "Zeyu Zhang",
        "Shen Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:32:32+00:00",
          "link": "https://arxiv.org/abs/2507.12760v1",
          "size": "7387kb",
          "version": "v1"
        }
      ],
      "title": "Unified Medical Image Segmentation with State Space Modeling Snake",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12760",
        "HTML": "https://arxiv.org/html/2507.12760v1",
        "PDF": "https://arxiv.org/pdf/2507.12760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper pertains to medical image segmentation using state space modeling, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12761",
      "abstract": "Emotional talking-head generation has emerged as a pivotal research area at the intersection of computer vision and multimodal artificial intelligence, with its core value lying in enhancing human-computer interaction through immersive and empathetic engagement.With the advancement of multimodal large language models, the driving signals for emotional talking-head generation has shifted from audio and video to more flexible text. However, current text-driven methods rely on predefined discrete emotion label texts, oversimplifying the dynamic complexity of real facial muscle movements and thus failing to achieve natural emotional expressiveness.This study proposes the Think-Before-Draw framework to address two key challenges: (1) In-depth semantic parsing of emotions--by innovatively introducing Chain-of-Thought (CoT), abstract emotion labels are transformed into physiologically grounded facial muscle movement descriptions, enabling the mapping from high-level semantics to actionable motion features; and (2) Fine-grained expressiveness optimization--inspired by artists' portrait painting process, a progressive guidance denoising strategy is proposed, employing a \"global emotion localization--local muscle control\" mechanism to refine micro-expression dynamics in generated videos.Our experiments demonstrate that our approach achieves state-of-the-art performance on widely-used benchmarks, including MEAD and HDTF. Additionally, we collected a set of portrait images to evaluate our model's zero-shot generation capability.",
      "authors": [
        "Hanlei Shi",
        "Leyuan Qu",
        "Yu Liu",
        "Di Gao",
        "Yuhua Zheng",
        "Taihao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:33:46+00:00",
          "link": "https://arxiv.org/abs/2507.12761v1",
          "size": "15155kb",
          "version": "v1"
        }
      ],
      "title": "Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12761",
        "HTML": "https://arxiv.org/html/2507.12761v1",
        "PDF": "https://arxiv.org/pdf/2507.12761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for expressive talking-head generation and does not address any aspects related to LLM training data processing, such as data collection, filtering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12762",
      "abstract": "Reliable anticipation of traffic accidents is essential for advancing autonomous driving systems. However, this objective is limited by two fundamental challenges: the scarcity of diverse, high-quality training data and the frequent absence of crucial object-level cues due to environmental disruptions or sensor deficiencies. To tackle these issues, we propose a comprehensive framework combining generative scene augmentation with adaptive temporal reasoning. Specifically, we develop a video generation pipeline that utilizes a world model guided by domain-informed prompts to create high-resolution, statistically consistent driving scenarios, particularly enriching the coverage of edge cases and complex interactions. In parallel, we construct a dynamic prediction model that encodes spatio-temporal relationships through strengthened graph convolutions and dilated temporal operators, effectively addressing data incompleteness and transient visual noise. Furthermore, we release a new benchmark dataset designed to better capture diverse real-world driving risks. Extensive experiments on public and newly released datasets confirm that our framework enhances both the accuracy and lead time of accident anticipation, offering a robust solution to current data and modeling limitations in safety-critical autonomous driving applications.",
      "authors": [
        "Yanchen Guan",
        "Haicheng Liao",
        "Chengyue Wang",
        "Xingcheng Liu",
        "Jiaxun Zhang",
        "Zhenning Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:34:54+00:00",
          "link": "https://arxiv.org/abs/2507.12762v1",
          "size": "35151kb",
          "version": "v1"
        }
      ],
      "title": "World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12762",
        "HTML": "https://arxiv.org/html/2507.12762v1",
        "PDF": "https://arxiv.org/pdf/2507.12762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a generative scene augmentation framework for enriching autonomous driving datasets, which is related to data quality improvement, but the focus is more on autonomous driving applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12763",
      "abstract": "This paper introduces an autonomous UAV vision system for continuous, real-time tracking of marine animals, specifically sharks, in dynamic marine environments. The system integrates an onboard computer with a stabilised RGB-D camera and a custom-trained OSTrack pipeline, enabling visual identification under challenging lighting, occlusion, and sea-state conditions. A key innovation is the inter-UAV handoff protocol, which enables seamless transfer of tracking responsibilities between drones, extending operational coverage beyond single-drone battery limitations. Performance is evaluated on a curated shark dataset of 5,200 frames, achieving a tracking success rate of 81.9\\% during real-time flight control at 100 Hz, and robustness to occlusion, illumination variation, and background clutter. We present a seamless UAV handoff framework, where target transfer is attempted via high-confidence feature matching, achieving 82.9\\% target coverage. These results confirm the viability of coordinated UAV operations for extended marine tracking and lay the groundwork for scalable, autonomous monitoring.",
      "authors": [
        "Heegyeong Kim (1)",
        "Alice James (1)",
        "Avishkar Seth (1)",
        "Endrowednes Kuantama (1)",
        "Jane Williamson (2)",
        "Yimeng Feng (1)",
        "Richard Han (1) ((1) School of Computing",
        "Macquarie University",
        "(2) School of Natural Sciences",
        "Macquarie University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:35:53+00:00",
          "link": "https://arxiv.org/abs/2507.12763v1",
          "size": "14944kb",
          "version": "v1"
        }
      ],
      "title": "Continuous Marine Tracking via Autonomous UAV Handoff",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12763",
        "HTML": "https://arxiv.org/html/2507.12763v1",
        "PDF": "https://arxiv.org/pdf/2507.12763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a UAV system for marine tracking and does not involve any contributions to LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12766",
      "abstract": "In this paper, we propose a new optimization framework, the layer separation (LySep) model, to improve the deep learning-based methods in solving partial differential equations. Due to the highly non-convex nature of the loss function in deep learning, existing optimization algorithms often converge to suboptimal local minima or suffer from gradient explosion or vanishing, resulting in poor performance. To address these issues, we introduce auxiliary variables to separate the layers of deep neural networks. Specifically, the output and its derivatives of each layer are represented by auxiliary variables, effectively decomposing the deep architecture into a series of shallow architectures. New loss functions with auxiliary variables are established, in which only variables from two neighboring layers are coupled. Corresponding algorithms based on alternating directions are developed, where many variables can be updated optimally in closed forms. Moreover, we provide theoretical analyses demonstrating the consistency between the LySep model and the original deep model. High-dimensional numerical results validate our theory and demonstrate the advantages of LySep in minimizing loss and reducing solution error.",
      "authors": [
        "Yaru Liu",
        "Yiqi Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:43:18+00:00",
          "link": "https://arxiv.org/abs/2507.12766v1",
          "size": "102kb",
          "version": "v1"
        }
      ],
      "title": "Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12766",
        "HTML": "https://arxiv.org/html/2507.12766v1",
        "PDF": "https://arxiv.org/pdf/2507.12766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a deep learning model for solving partial differential equations and does not connect to LLM training data processing or operations such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12767",
      "abstract": "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.",
      "authors": [
        "Jiaxin An"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:46:13+00:00",
          "link": "https://arxiv.org/abs/2507.12767v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "Autonomy for Older Adult-Agent Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12767",
        "HTML": "https://arxiv.org/html/2507.12767v1",
        "PDF": "https://arxiv.org/pdf/2507.12767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-powered agents for older adults, examining autonomy preferences. It does not discuss LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12768",
      "abstract": "Vision-language-action (VLA) models have shown promise on task-conditioned control in complex settings such as bimanual manipulation. However, the heavy reliance on task-specific human demonstrations limits their generalization and incurs high data acquisition costs. In this work, we present a new notion of task-agnostic action paradigm that decouples action execution from task-specific conditioning, enhancing scalability, efficiency, and cost-effectiveness. To address the data collection challenges posed by this paradigm -- such as low coverage density, behavioral redundancy, and safety risks -- we introduce ATARA (Automated Task-Agnostic Random Actions), a scalable self-supervised framework that accelerates collection by over $ 30\\times $ compared to human teleoperation. To further enable effective learning from task-agnostic data, which often suffers from distribution mismatch and irrelevant trajectories, we propose AnyPos, an inverse dynamics model equipped with Arm-Decoupled Estimation and a Direction-Aware Decoder (DAD). We additionally integrate a video-conditioned action validation module to verify the feasibility of learned policies across diverse manipulation tasks. Extensive experiments show that the AnyPos-ATARA pipeline yields a 51% improvement in test accuracy and achieves 30-40% higher success rates in downstream tasks such as lifting, pick-and-place, and clicking, using replay-based video validation. Project Page: https://embodiedfoundation.github.io/vidar_anypos",
      "authors": [
        "Hengkai Tan",
        "Yao Feng",
        "Xinyi Mao",
        "Shuhe Huang",
        "Guodong Liu",
        "Zhongkai Hao",
        "Hang Su",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:48:57+00:00",
          "link": "https://arxiv.org/abs/2507.12768v1",
          "size": "2754kb",
          "version": "v1"
        }
      ],
      "title": "AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12768",
        "HTML": "https://arxiv.org/html/2507.12768v1",
        "PDF": "https://arxiv.org/pdf/2507.12768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a task-agnostic action paradigm for bimanual manipulation, focusing on task execution and self-supervised data collection. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12769",
      "abstract": "In this paper, we present Synergy, a language model that bridges different levels of abstraction in an end-to-end fashion through a learned routing mechanism. Focusing on low-level linguistic abstraction, we trained our model as a byte-level language model. Our model spontaneously learns to tokenize bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE) tokenizers while keeping comparable performance. By comparing with Llama3, we observed an advantage of Synergy under the same model scale and training dataset size. Further studies show that the middle part (the higher abstraction part) of our model performs better when positional encodings are removed, suggesting the emergence of position-independent concepts. These findings demonstrate the feasibility of tokenizer-free architectures, paving the way for more robust and flexible pipelines.",
      "authors": [
        "Keli Zheng and Zerong Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:01:28+00:00",
          "link": "https://arxiv.org/abs/2507.12769v1",
          "size": "167kb",
          "version": "v1"
        }
      ],
      "title": "Synergy: End-to-end Concept Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12769",
        "HTML": "https://arxiv.org/html/2507.12769v1",
        "PDF": "https://arxiv.org/pdf/2507.12769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the Synergy model, emphasizing tokenizer-free architectures and linguistic abstraction. While it touches on data tokenization, it primarily focuses on model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12771",
      "abstract": "Stable diffusion is an outstanding image generation model for text-to-image, but its time-consuming generation process remains a challenge due to the quadratic complexity of attention operations. Recent token merging methods improve efficiency by reducing the number of tokens during attention operations, but often overlook the characteristics of attention-based image generation models, limiting their effectiveness. In this paper, we propose local representative token guided merging (ReToM), a novel token merging strategy applicable to any attention mechanism in image generation. To merge tokens based on various contextual information, ReToM defines local boundaries as windows within attention inputs and adjusts window sizes. Furthermore, we introduce a representative token, which represents the most representative token per window by computing similarity at a specific timestep and selecting the token with the highest average similarity. This approach preserves the most salient local features while minimizing computational overhead. Experimental results show that ReToM achieves a 6.2% improvement in FID and higher CLIP scores compared to the baseline, while maintaining comparable inference time. We empirically demonstrate that ReToM is effective in balancing visual quality and computational efficiency.",
      "authors": [
        "Min-Jeong Lee",
        "Hee-Dong Kim",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:16:24+00:00",
          "link": "https://arxiv.org/abs/2507.12771v1",
          "size": "625kb",
          "version": "v1"
        }
      ],
      "title": "Local Representative Token Guided Merging for Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12771",
        "HTML": "https://arxiv.org/html/2507.12771v1",
        "PDF": "https://arxiv.org/pdf/2507.12771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a token merging strategy to improve efficiency in text-to-image generation. It is centered on computational efficiency in attention mechanisms rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12773",
      "abstract": "We consider the problem of personalizing audio to maximize user experience. Briefly, we aim to find a filter $h^*$, which applied to any music or speech, will maximize the user's satisfaction. This is a black-box optimization problem since the user's satisfaction function is unknown. Substantive work has been done on this topic where the key idea is to play audio samples to the user, each shaped by a different filter $h_i$, and query the user for their satisfaction scores $f(h_i)$. A family of ``surrogate\" functions is then designed to fit these scores and the optimization method gradually refines these functions to arrive at the filter $\\hat{h}^*$ that maximizes satisfaction. In certain applications, we observe that a second type of querying is possible where users can tell us the individual elements $h^*[j]$ of the optimal filter $h^*$. Consider an analogy from cooking where the goal is to cook a recipe that maximizes user satisfaction. A user can be asked to score various cooked recipes (e.g., tofu fried rice) or to score individual ingredients (say, salt, sugar, rice, chicken, etc.). Given a budget of $B$ queries, where a query can be of either type, our goal is to find the recipe that will maximize this user's satisfaction. Our proposal builds on Sparse Gaussian Process Regression (GPR) and shows how a hybrid approach can outperform any one type of querying. Our results are validated through simulations and real world experiments, where volunteers gave feedback on music/speech audio and were able to achieve high satisfaction levels. We believe this idea of hybrid querying opens new problems in black-box optimization and solutions can benefit other applications beyond audio personalization.",
      "authors": [
        "Rajalaxmi Rajagopalan",
        "Yu-Lin Wei",
        "Romit Roy Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:26:57+00:00",
          "link": "https://arxiv.org/abs/2507.12773v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "Sample-Constrained Black Box Optimization for Audio Personalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12773",
        "HTML": "https://arxiv.org/html/2507.12773v1",
        "PDF": "https://arxiv.org/pdf/2507.12773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses audio personalization through black-box optimization and surrogate functions, which is unrelated to LLM training data processing or any relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12774",
      "abstract": "Artificial intelligence (AI) has demonstrated significant potential in transforming healthcare through the analysis and modeling of electronic health records (EHRs). However, the inherent heterogeneity, temporal irregularity, and domain-specific nature of EHR data present unique challenges that differ fundamentally from those in vision and natural language tasks. This survey offers a comprehensive overview of recent advancements at the intersection of deep learning, large language models (LLMs), and EHR modeling. We introduce a unified taxonomy that spans five key design dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. Within each dimension, we review representative methods addressing data quality enhancement, structural and temporal representation, self-supervised learning, and integration with clinical knowledge. We further highlight emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning. Finally, we discuss open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings. This survey aims to provide a structured roadmap for advancing AI-driven EHR modeling and clinical decision support. For a comprehensive list of EHR-related methods, kindly refer to https://survey-on-tabular-data.github.io/.",
      "authors": [
        "Weijieying Ren",
        "Jingxi Zhu",
        "Zehao Liu",
        "Tianxiang Zhao",
        "Vasant Honavar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:31:55+00:00",
          "link": "https://arxiv.org/abs/2507.12774v1",
          "size": "2094kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12774",
        "HTML": "https://arxiv.org/html/2507.12774v1",
        "PDF": "https://arxiv.org/pdf/2507.12774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a survey on EHR modeling in the context of AI and LLMs, focusing on EHR-specific challenges and methodologies rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12780",
      "abstract": "Self-attention and transformer architectures have become foundational components in modern deep learning. Recent efforts have integrated transformer blocks into compact neural architectures for computer vision, giving rise to various efficient vision transformers. In this work, we introduce Transformer with Kernel Complexity Reduction, or KCR-Transformer, a compact transformer block equipped with differentiable channel selection, guided by a novel and sharp theoretical generalization bound. KCR-Transformer performs input/output channel selection in the MLP layers of transformer blocks to reduce the computational cost. Furthermore, we provide a rigorous theoretical analysis establishing a tight generalization bound for networks equipped with KCR-Transformer blocks. Leveraging such strong theoretical results, the channel pruning by KCR-Transformer is conducted in a generalization-aware manner, ensuring that the resulting network retains a provably small generalization error. Our KCR-Transformer is compatible with many popular and compact transformer networks, such as ViT and Swin, and it reduces the FLOPs of the vision transformers while maintaining or even improving the prediction accuracy. In the experiments, we replace all the transformer blocks in the vision transformers with KCR-Transformer blocks, leading to KCR-Transformer networks with different backbones. The resulting TCR-Transformers achieve superior performance on various computer vision tasks, achieving even better performance than the original models with even less FLOPs and parameters.",
      "authors": [
        "Yancheng Wang",
        "Yingzhen Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:41:18+00:00",
          "link": "https://arxiv.org/abs/2507.12780v1",
          "size": "645kb",
          "version": "v1"
        }
      ],
      "title": "Compact Vision Transformer by Reduction of Kernel Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12780",
        "HTML": "https://arxiv.org/html/2507.12780v1",
        "PDF": "https://arxiv.org/pdf/2507.12780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a transformer model architecture for computer vision tasks, concentrating on reducing kernel complexity to improve efficiency, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12782",
      "abstract": "Despite rapid adoption of autoregressive large language models, smaller text encoders still play an important role in text understanding tasks that require rich contextualized representations. Negation is an important semantic function that is still not properly captured by such methods, affecting many downstream applications relying on text embeddings. We propose a strategy to improve negation robustness of text encoders, by distilling data from large language models using diverse patterns of negation and hedging. We adopt a standard contrastive learning strategy to finetune a strong BERT-based model, and observe large improvement in negation understanding capabilities while maintaining competitive performance on general benchmarks. In addition, we also show that our method can be adapted to LLMs, leading to improved performance on negation benchmarks.",
      "authors": [
        "Thinh Hung Truong",
        "Karin Verspoor",
        "Trevor Cohn",
        "Timothy Baldwin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:48:54+00:00",
          "link": "https://arxiv.org/abs/2507.12782v1",
          "size": "95kb",
          "version": "v1"
        }
      ],
      "title": "Learning Robust Negation Text Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12782",
        "PDF": "https://arxiv.org/pdf/2507.12782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus is on improving text encoders through negation handling, the paper describes a data distillation process from LLMs, briefly touching upon a training data processing aspect but not making it the primary contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12787",
      "abstract": "With the continuous evolution of China's multi-level capital market, the National Equities Exchange and Quotations (NEEQ), also known as the \"New Third Board,\" has become a critical financing platform for small and medium-sized enterprises (SMEs). However, due to their limited scale and financial resilience, many NEEQ-listed companies face elevated risks of financial distress. To address this issue, we propose a multi-channel deep learning framework that integrates structured financial indicators, textual disclosures, and enterprise relationship data for comprehensive financial risk prediction. Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that processes numeric, textual, and graph-based inputs separately. These modality-specific representations are fused using an attention-based mechanism followed by a gating unit to enhance robustness and prediction accuracy. Experimental results on data from 7,731 real-world NEEQ companies demonstrate that our model significantly outperforms traditional machine learning methods and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score. This work provides theoretical and practical insights into risk modeling for SMEs and offers a data-driven tool to support financial regulators and investors.",
      "authors": [
        "Jianyu Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:57:51+00:00",
          "link": "https://arxiv.org/abs/2507.12787v1",
          "size": "740kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12787",
        "HTML": "https://arxiv.org/html/2507.12787v1",
        "PDF": "https://arxiv.org/pdf/2507.12787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research proposes a graph neural network model for financial risk prediction, focusing on multi-channel data processing other than LLM-centric training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12791",
      "abstract": "We introduce a new method for analyzing midpoint discretizations of stochastic differential equations (SDEs), which are frequently used in Markov chain Monte Carlo (MCMC) methods for sampling from a target measure $\\pi \\propto \\exp(-V)$. Borrowing techniques from Malliavin calculus, we compute estimates for the Radon-Nikodym derivative for processes on $L^2([0, T); \\mathbb{R}^d)$ which may anticipate the Brownian motion, in the sense that they may not be adapted to the filtration at the same time. Applying these to various popular midpoint discretizations, we are able to improve the regularity and cross-regularity results in the literature on sampling methods. We also obtain a query complexity bound of $\\widetilde{O}(\\frac{\\kappa^{5/4} d^{1/4}}{\\varepsilon^{1/2}})$ for obtaining a $\\varepsilon^2$-accurate sample in $\\mathsf{KL}$ divergence, under log-concavity and strong smoothness assumptions for $\\nabla^2 V$.",
      "authors": [
        "Matthew S. Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:05:27+00:00",
          "link": "https://arxiv.org/abs/2507.12791v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of Langevin midpoint methods using an anticipative Girsanov theorem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12791",
        "HTML": "https://arxiv.org/html/2507.12791v1",
        "PDF": "https://arxiv.org/pdf/2507.12791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on midpoint discretizations of stochastic differential equations for Markov chain Monte Carlo methods, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12792",
      "abstract": "Distributed systems, such as state machine replication, are critical infrastructures for modern applications. Practical distributed protocols make minimum assumptions about the underlying network: They typically assume a partially synchronous or fully asynchronous network model. In this work, we argue that modern data center systems can be designed to provide strong synchrony properties in the common case, where servers move in synchronous lock-step rounds. We prove this hypothesis by engineering a practical design that uses a combination of kernel-bypass network, multithreaded architecture, and loosened round length, achieving a tight round bound under 2us. Leveraging our engineered networks with strong synchrony, we co-design a new replication protocol, Chora. Chora exploits the network synchrony property to efficiently pipeline multiple replication instances, while allowing all replicas to propose in parallel without extra coordination. Through experiments, we show that Chora achieves 255% and 109% improvement in throughput over state-of-the-art single-leader and multi-leader protocols, respectively.",
      "authors": [
        "Yiliang Wan",
        "Nitin Shivaraman",
        "Akshaye Shenoi",
        "Xiang Liu",
        "Tao Luo",
        "and Jialin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:09:13+00:00",
          "link": "https://arxiv.org/abs/2507.12792v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "Building State Machine Replication Using Practical Network Synchrony",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12792",
        "HTML": "https://arxiv.org/html/2507.12792v1",
        "PDF": "https://arxiv.org/pdf/2507.12792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses distributed systems and state machine replication protocols which do not involve LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12793",
      "abstract": "Structural pests, such as termites, pose a serious threat to wooden buildings, resulting in significant economic losses due to their hidden and progressive damage. Traditional detection methods, such as visual inspections and chemical treatments, are invasive, labor intensive, and ineffective for early stage infestations. To bridge this gap, this study proposes a non invasive deep learning based acoustic classification framework for early termite detection. We aim to develop a robust, scalable model that distinguishes termite generated acoustic signals from background noise. We introduce a hybrid Convolutional Neural Network Long Short Term Memory architecture that captures both spatial and temporal features of termite activity. Audio data were collected from termite infested and clean wooden samples. We extracted Mel Frequency Cepstral Coefficients and trained the CNN LSTM model to classify the signals. Experimental results show high performance, with 94.5% accuracy, 93.2% precision, and 95.8% recall. Comparative analysis reveals that the hybrid model outperforms standalone CNN and LSTM architectures, underscoring its combined strength. Notably, the model yields low false-negative rates, which is essential for enabling timely intervention. This research contributes a non invasive, automated solution for early termite detection, with practical implications for improved pest monitoring, minimized structural damage, and better decision making by homeowners and pest control professionals. Future work may integrate IoT for real time alerts and extend detection to other structural pests.",
      "authors": [
        "J. M. Chan Sri Manukalpa",
        "H. S. Bopage",
        "W. A. M. Jayawardena",
        "P. K. P. G. Panduwawala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Human-Computer Interaction (cs.HC)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:10:02+00:00",
          "link": "https://arxiv.org/abs/2507.12793v1",
          "size": "273kb",
          "version": "v1"
        }
      ],
      "title": "Early Detection of Furniture-Infesting Wood-Boring Beetles Using CNN-LSTM Networks and MFCC-Based Acoustic Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12793",
        "PDF": "https://arxiv.org/pdf/2507.12793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study uses deep learning methods for early detection of wood-boring beetles and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12795",
      "abstract": "Scene understanding enables intelligent agents to interpret and comprehend their environment. While existing large vision-language models (LVLMs) for scene understanding have primarily focused on indoor household tasks, they face two significant limitations when applied to outdoor large-scale scene understanding. First, outdoor scenarios typically encompass larger-scale environments observed through various sensors from multiple viewpoints (e.g., bird view and terrestrial view), while existing indoor LVLMs mainly analyze single visual modalities within building-scale contexts from humanoid viewpoints. Second, existing LVLMs suffer from missing multidomain perception outdoor data and struggle to effectively integrate 2D and 3D visual information. To address the aforementioned limitations, we build the first multidomain perception outdoor scene understanding dataset, named \\textbf{\\underline{SVM-City}}, deriving from multi\\textbf{\\underline{S}}cale scenarios with multi\\textbf{\\underline{V}}iew and multi\\textbf{\\underline{M}}odal instruction tuning data. It contains $420$k images and $4, 811$M point clouds with $567$k question-answering pairs from vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To effectively fuse the multimodal data in the absence of one modality, we introduce incomplete multimodal learning to model outdoor scene understanding and design the LVLM named \\textbf{\\underline{City-VLM}}. Multimodal fusion is realized by constructing a joint probabilistic distribution space rather than implementing directly explicit fusion operations (e.g., concatenation). Experimental results on three typical outdoor scene understanding tasks show City-VLM achieves $18.14 \\%$ performance surpassing existing LVLMs in question-answering tasks averagely. Our method demonstrates pragmatic and generalization performance across multiple outdoor scenes.",
      "authors": [
        "Penglei Sun",
        "Yaoxian Song",
        "Xiangru Zhu",
        "Xiang Liu",
        "Qiang Wang",
        "Yue Liu",
        "Changqun Xia",
        "Tiefeng Li",
        "Yang Yang",
        "Xiaowen Chu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:21:21+00:00",
          "link": "https://arxiv.org/abs/2507.12795v1",
          "size": "1398kb",
          "version": "v1"
        }
      ],
      "title": "City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12795",
        "HTML": "https://arxiv.org/html/2507.12795v1",
        "PDF": "https://arxiv.org/pdf/2507.12795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The creation of the SVM-City dataset for scene understanding may indirectly relate to language models in terms of multimodal data interaction, but the main focus is on multimodal perception, not specifically on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12796",
      "abstract": "Document quality assessment is critical for a wide range of applications including document digitization, OCR, and archival. However, existing approaches often struggle to provide accurate and robust quality scores, limiting their applicability in practical scenarios. With the rapid progress in Multi-modal Large Language Models (MLLMs), recent MLLM-based methods have achieved remarkable performance in image quality assessment. In this work, we extend this success to the document domain by adapting DeQA-Score, a state-of-the-art MLLM-based image quality scorer, for document quality assessment. We propose DeQA-Doc, a framework that leverages the visual language capabilities of MLLMs and a soft label strategy to regress continuous document quality scores. To adapt DeQA-Score to DeQA-Doc, we adopt two complementary solutions to construct soft labels without the variance information. Also, we relax the resolution constrains to support the large resolution of document images. Finally, we introduce ensemble methods to further enhance the performance. Extensive experiments demonstrate that DeQA-Doc significantly outperforms existing baselines, offering accurate and generalizable document quality assessment across diverse degradation types. Codes and model weights are available in https://github.com/Junjie-Gao19/DeQA-Doc.",
      "authors": [
        "Junjie Gao",
        "Runze Liu",
        "Yingzhe Peng",
        "Shujian Yang",
        "Jin Zhang",
        "Kai Yang",
        "Zhiyuan You"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:23:53+00:00",
          "link": "https://arxiv.org/abs/2507.12796v1",
          "size": "23713kb",
          "version": "v1"
        }
      ],
      "title": "DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12796",
        "HTML": "https://arxiv.org/html/2507.12796v1",
        "PDF": "https://arxiv.org/pdf/2507.12796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper adapts an image quality assessment method for document quality, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12800",
      "abstract": "Though visual and repeat navigation is a convenient solution for mobile robot self-navigation, achieving balance between efficiency and robustness in task environment still remains challenges. In this paper, we propose a novel visual and repeat robotic autonomous navigation method that requires no accurate localization and dense reconstruction modules, which makes our system featured by lightweight and robustness. Firstly, feature flow is introduced and we develop a qualitative mapping between feature flow and robot's motion, in which feature flow is defined as pixel location bias between matched features. Based on the mapping model, the map outputted by the teaching phase is represented as a keyframe graph, in which the feature flow on the edge encodes the relative motion between adjacent keyframes. Secondly, the visual repeating navigation is essentially modeled as a feature flow minimization problem between current observation and the map keyframe. To drive the robot to consistently reduce the feature flow between current frame and map keyframes without accurate localization, a probabilistic motion planning is developed based on our qualitative feature flow-motion mapping indicator. Extensive experiments using our mobile platform demonstrates that our proposed method is lightweight, robust, and superior to baselines. The source code has been made public at https://github.com/wangjks/FFI-VTR to benefit the community.",
      "authors": [
        "Jikai Wang",
        "Yunqi Cheng",
        "and Zonghai Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:36:14+00:00",
          "link": "https://arxiv.org/abs/2507.12800v1",
          "size": "2016kb",
          "version": "v1"
        }
      ],
      "title": "FFI-VTR: Lightweight and Robust Visual Teach and Repeat Navigation based on Feature Flow Indicator and Probabilistic Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12800",
        "HTML": "https://arxiv.org/html/2507.12800v1",
        "PDF": "https://arxiv.org/pdf/2507.12800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on visual teach and repeat navigation in robotics, leveraging feature flow and probabilistic motion planning. There is no relation to LLM training data processing, which involves data collection, filtering, or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12801",
      "abstract": "In recent years, peer learning has gained attention as a method that promotes spontaneous thinking among learners, and its effectiveness has been confirmed by numerous studies. This study aims to develop an AI Agent as a learning companion that enables peer learning anytime and anywhere. However, peer learning between humans has various limitations, and it is not always effective. Effective peer learning requires companions at the same proficiency levels. In this study, we assume that a learner's peers with the same proficiency level as the learner make the same mistakes as the learner does and focus on English composition as a specific example to validate this approach.",
      "authors": [
        "Sosui Moribe",
        "Taketoshi Ushiama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:37:07+00:00",
          "link": "https://arxiv.org/abs/2507.12801v1",
          "size": "2002kb",
          "version": "v1"
        }
      ],
      "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12801",
        "HTML": "https://arxiv.org/html/2507.12801v1",
        "PDF": "https://arxiv.org/pdf/2507.12801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study develops an AI agent for peer learning, focusing on mimicking mistakes in English composition learning. The paper does not address any data processing for LLM training, such as dataset generation or data quality enhancement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12803",
      "abstract": "Time series prediction, a crucial task across various domains, faces significant challenges due to the inherent complexities of time series data, including non-stationarity, multi-scale periodicity, and transient dynamics, particularly when tackling long-term predictions. While Transformer-based architectures have shown promise, their quadratic complexity with sequence length hinders their efficiency for long-term predictions. Recent advancements in State-Space Models, such as Mamba, offer a more efficient alternative for long-term modeling, but they cannot capture multi-scale periodicity and transient dynamics effectively. Meanwhile, they are susceptible to data noise issues in time series. This paper proposes a novel framework, FLDmamba (Fourier and Laplace Transform Decomposition Mamba), addressing these limitations. FLDmamba leverages the strengths of both Fourier and Laplace transforms to effectively capture both multi-scale periodicity, transient dynamics within time series data, and improve the robustness of the model to the data noise issue. Our extensive experiments demonstrate that FLDmamba achieves superior performance on time series prediction benchmarks, outperforming both Transformer-based and other Mamba-based architectures. To promote the reproducibility of our method, we have made both the code and data accessible via the following URL:{\\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\\model}.",
      "authors": [
        "Qianru Zhang",
        "Chenglei Yu",
        "Haixin Wang",
        "Yudong Yan",
        "Yuansheng Cao",
        "Siu-Ming Yiu",
        "Tailin Wu",
        "Hongzhi Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:39:15+00:00",
          "link": "https://arxiv.org/abs/2507.12803v1",
          "size": "600kb",
          "version": "v1"
        }
      ],
      "title": "FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12803",
        "HTML": "https://arxiv.org/html/2507.12803v1",
        "PDF": "https://arxiv.org/pdf/2507.12803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces FLDmamba for time series prediction improvement using Fourier and Laplace transforms. It does not contribute to LLM training data processing, as it does not involve any data operations or dataset creations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12804",
      "abstract": "Audio-driven talking head generation requires precise synchronization between facial animations and audio signals. This paper introduces ATL-Diff, a novel approach addressing synchronization limitations while reducing noise and computational costs. Our framework features three key components: a Landmark Generation Module converting audio to facial landmarks, a Landmarks-Guide Noise approach that decouples audio by distributing noise according to landmarks, and a 3D Identity Diffusion network preserving identity characteristics. Experiments on MEAD and CREMA-D datasets demonstrate that ATL-Diff outperforms state-of-the-art methods across all metrics. Our approach achieves near real-time processing with high-quality animations, computational efficiency, and exceptional preservation of facial nuances. This advancement offers promising applications for virtual assistants, education, medical communication, and digital platforms. The source code is available at: \\href{https://github.com/sonvth/ATL-Diff}{https://github.com/sonvth/ATL-Diff}",
      "authors": [
        "Hoang-Son Vo",
        "Quang-Vinh Nguyen",
        "Seungwon Kim",
        "Hyung-Jeong Yang",
        "Soonja Yeom",
        "and Soo-Hyung Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:40:51+00:00",
          "link": "https://arxiv.org/abs/2507.12804v1",
          "size": "1920kb",
          "version": "v1"
        }
      ],
      "title": "ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12804",
        "HTML": "https://arxiv.org/html/2507.12804v1",
        "PDF": "https://arxiv.org/pdf/2507.12804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for audio-driven talking head generation, focusing on synchronizing facial animation with audio. It does not address LLM training data processing, which would involve steps like dataset curation or deduplication specifically for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12805",
      "abstract": "Learning-based lossless compressors play a crucial role in large-scale genomic database backup, storage, transmission, and management. However, their 1) inadequate compression ratio, 2) low compression \\& decompression throughput, and 3) poor compression robustness limit their widespread adoption and application in both industry and academia. To solve those challenges, we propose a novel \\underline{P}arallel \\underline{M}ulti-\\underline{K}nowledge \\underline{L}earning-based \\underline{C}ompressor (PMKLC) with four crucial designs: 1) We propose an automated multi-knowledge learning-based compression framework as compressors' backbone to enhance compression ratio and robustness; 2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression throughput and computing resource usage; 3) we introduce data block partitioning and Step-wise Model Passing (SMP) mechanisms for parallel acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet the complex application scenarios, where the former runs on a resource-constrained single GPU and the latter is multi-GPU accelerated. We benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15 real-world datasets with different species and data sizes. Compared to baselines on the testing datasets, PMKLC-S/M achieve the average compression ratio improvement up to 73.609\\% and 73.480\\%, the average throughput improvement up to 3.036$\\times$ and 10.710$\\times$, respectively. Besides, PMKLC-S/M also achieve the best robustness and competitive memory cost, indicating its greater stability against datasets with different probability distribution perturbations, and its strong ability to run on memory-constrained devices.",
      "authors": [
        "Hui Sun",
        "Yanfeng Ding",
        "Liping Yi",
        "Huidong Ma",
        "Gang Wang",
        "Xiaoguang Liu",
        "Cheng Zhong",
        "Wentong Cai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:46:08+00:00",
          "link": "https://arxiv.org/abs/2507.12805v1",
          "size": "2436kb",
          "version": "v1"
        }
      ],
      "title": "PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12805",
        "PDF": "https://arxiv.org/pdf/2507.12805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes PMKLC, a learning-based lossless compressor for genomics databases, focusing on compression efficiency and throughput. It is unrelated to LLM training data processing as it does not involve data processing operations for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12806",
      "abstract": "The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment. We introduce \\oursystemname, an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains. MCPEval standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines. Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance. We publicly release MCPEval https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and standardized LLM agent evaluation.",
      "authors": [
        "Zhiwei Liu",
        "Jielin Qiu",
        "Shiyu Wang",
        "Jianguo Zhang",
        "Zuxin Liu",
        "Roshan Ram",
        "Haolin Chen",
        "Weiran Yao",
        "Huan Wang",
        "Shelby Heinecke",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:46:27+00:00",
          "link": "https://arxiv.org/abs/2507.12806v1",
          "size": "1035kb",
          "version": "v1"
        }
      ],
      "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12806",
        "HTML": "https://arxiv.org/html/2507.12806v1",
        "PDF": "https://arxiv.org/pdf/2507.12806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the MCPEval framework for evaluating LLM agents, which automates task generation and evaluation but does not address data processing aspects related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12807",
      "abstract": "The variance in class-wise sample sizes within long-tailed scenarios often results in degraded performance in less frequent classes. Fortunately, foundation models, pre-trained on vast open-world datasets, demonstrate strong potential for this task due to their generalizable representation, which promotes the development of adaptive strategies on pre-trained models in long-tailed learning. Advanced fine-tuning methods typically adjust visual encoders while neglecting the semantics derived from the frozen text encoder, overlooking the visual and textual alignment. To strengthen this alignment, we propose a novel approach, Semantic-guided fine-tuning of foundation model for long-tailed visual recognition (Sage), which incorporates semantic guidance derived from textual modality into the visual fine-tuning process. Specifically, we introduce an SG-Adapter that integrates class descriptions as semantic guidance to guide the fine-tuning of the visual encoder. The introduced guidance is passesed through the attention mechanism and enables the model to focus more on semantically relevant content, strengthening the alignment between the visual and textual modalities. Due to the inconsistent class-conditional distributions neglected by the existing loss function, the resulting prediction bias causes performance improvements for the tail class less than for the head class, even when the multi-modal alignment is enhanced. To address this challenge, we propose a novel distribution mismatch-aware compensation factor, which is specifically designed to rectify the prediction bias caused by the ignored inconsistent distribution based on our theoretical analysis, and is seamlessly integrated into the loss function. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed Sage in enhancing performance in long-tailed learning.",
      "authors": [
        "Yufei Peng",
        "Yonggang Zhang",
        "Yiu-ming Cheung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.12807v1",
          "size": "11458kb",
          "version": "v1"
        }
      ],
      "title": "Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12807",
        "HTML": "https://arxiv.org/html/2507.12807v1",
        "PDF": "https://arxiv.org/pdf/2507.12807"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses fine-tuning techniques for foundation models, it focuses on semantic guidance and prediction bias in visual recognition rather than LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12808",
      "abstract": "Large language models (LLMs) excel at modeling relationships between strings in natural language and have shown promise in extending to other symbolic domains like coding or mathematics. However, the extent to which they implicitly model symbolic music remains underexplored. This paper investigates how LLMs represent musical concepts by generating symbolic music data from textual prompts describing combinations of genres and styles, and evaluating their utility through recognition and generation tasks. We produce a dataset of LLM-generated MIDI files without relying on explicit musical training. We then train neural networks entirely on this LLM-generated MIDI dataset and perform genre and style classification as well as melody completion, benchmarking their performance against established models. Our results demonstrate that LLMs can infer rudimentary musical structures and temporal relationships from text, highlighting both their potential to implicitly encode musical patterns and their limitations due to a lack of explicit musical context, shedding light on their generative capabilities for symbolic music.",
      "authors": [
        "Andrew Shin",
        "Kunitake Kaneko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T05:48:45+00:00",
          "link": "https://arxiv.org/abs/2507.12808v1",
          "size": "509kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models' Internal Perception of Symbolic Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12808",
        "HTML": "https://arxiv.org/html/2507.12808v1",
        "PDF": "https://arxiv.org/pdf/2507.12808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses generating symbolic music data with LLMs and creating a dataset of LLM-generated MIDI files, but the primary focus is on LLMs' capability to understand musical structures rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12814",
      "abstract": "Time-dependent partial differential equations are ubiquitous in physics-based modeling, but they remain computationally intensive in many-query scenarios, such as real-time forecasting, optimal control, and uncertainty quantification. Reduced-order modeling (ROM) addresses these challenges by constructing a low-dimensional surrogate model but relies on a fixed discretization, which limits flexibility across varying meshes during evaluation. Operator learning approaches, such as neural operators, offer an alternative by parameterizing mappings between infinite-dimensional function spaces, enabling adaptation to data across different resolutions. Whereas ROM provides rigorous numerical error estimates, neural operator learning largely focuses on discretization convergence and invariance without quantifying the error between the infinite-dimensional and the discretized operators. This work introduces the reduced-order neural operator modeling (RONOM) framework, which bridges concepts from ROM and operator learning. We establish a discretization error bound analogous to those in ROM, and get insights into RONOM's discretization convergence and discretization robustness. Moreover, two numerical examples are presented that compare RONOM to existing neural operators for solving partial differential equations. The results demonstrate that RONOM using standard vector-to-vector neural networks achieves comparable performance in input generalization and superior performance in both spatial super-resolution and discretization robustness, while also offering novel insights into temporal super-resolution scenarios.",
      "authors": [
        "Sven Dummer",
        "Dongwei Ye",
        "Christoph Brune"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:14:19+00:00",
          "link": "https://arxiv.org/abs/2507.12814v1",
          "size": "3433kb",
          "version": "v1"
        }
      ],
      "title": "RONOM: Reduced-Order Neural Operator Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12814",
        "HTML": "https://arxiv.org/html/2507.12814v1",
        "PDF": "https://arxiv.org/pdf/2507.12814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "RONOM introduces a framework for reduced-order neural operator modeling, focusing on numerical modeling and discretization rather than any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12815",
      "abstract": "Offline Reinforcement Learning (RL) aims to learn effective policies from a static dataset without requiring further agent-environment interactions. However, its practical adoption is often hindered by the need for explicit reward annotations, which can be costly to engineer or difficult to obtain retrospectively. To address this, we propose ReLOAD (Reinforcement Learning with Offline Reward Annotation via Distillation), a novel reward annotation framework for offline RL. Unlike existing methods that depend on complex alignment procedures, our approach adapts Random Network Distillation (RND) to generate intrinsic rewards from expert demonstrations using a simple yet effective embedding discrepancy measure. First, we train a predictor network to mimic a fixed target network's embeddings based on expert state transitions. Later, the prediction error between these networks serves as a reward signal for each transition in the static dataset. This mechanism provides a structured reward signal without requiring handcrafted reward annotations. We provide a formal theoretical construct that offers insights into how RND prediction errors effectively serve as intrinsic rewards by distinguishing expert-like transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables robust offline policy learning and achieves performance competitive with traditional reward-annotated methods.",
      "authors": [
        "Gaurav Chaudhary and Laxmidhar Behera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:16:06+00:00",
          "link": "https://arxiv.org/abs/2507.12815v1",
          "size": "199kb",
          "version": "v1"
        }
      ],
      "title": "From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12815",
        "PDF": "https://arxiv.org/pdf/2507.12815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a reward annotation framework for offline reinforcement learning, which involves generating reward structures and policies, but it is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12816",
      "abstract": "Video question answering (VQA) is a multimodal task that requires the interpretation of a video to answer a given question. Existing VQA methods primarily utilize question and answer (Q&A) pairs to learn the spatio-temporal characteristics of video content. However, these annotations are typically event-centric, which is not enough to capture the broader context of each video. The absence of essential details such as object types, spatial layouts, and descriptive attributes restricts the model to learning only a fragmented scene representation. This issue limits the model's capacity for generalization and higher-level reasoning. In this paper, we propose a fundamental question generation with the integration of question embeddings for video question answering (FIQ), a novel approach designed to strengthen the reasoning ability of the model by enhancing the fundamental understanding of videos. FIQ generates Q&A pairs based on descriptions extracted from videos, enriching the training data with fundamental scene information. Generated Q&A pairs enable the model to understand the primary context, leading to enhanced generalizability and reasoning ability. Furthermore, we incorporate a VQ-CAlign module that assists task-specific question embeddings with visual features, ensuring that essential domain-specific details are preserved to increase the adaptability of downstream tasks. Experiments on SUTD-TrafficQA demonstrate that our FIQ achieves state-of-the-art performance compared to existing baseline methods.",
      "authors": [
        "Ju-Young Oh",
        "Ho-Joong Kim",
        "and Seong-Whan Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:19:38+00:00",
          "link": "https://arxiv.org/abs/2507.12816v1",
          "size": "2847kb",
          "version": "v1"
        }
      ],
      "title": "FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12816",
        "HTML": "https://arxiv.org/html/2507.12816v1",
        "PDF": "https://arxiv.org/pdf/2507.12816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on generating question and answer pairs to enhance the training data for video question answering. It briefly touches on data generation but its primary contribution is in enhancing model reasoning and generalizability, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12819",
      "abstract": "Composed Image Retrieval (CIR) is the task of retrieving a target image from a gallery using a composed query consisting of a reference image and a modification text. Among various CIR approaches, training-free zero-shot methods based on pre-trained models are cost-effective but still face notable limitations. For example, sequential VLM-LLM pipelines process each modality independently, which often results in information loss and limits cross-modal interaction. In contrast, methods based on multimodal large language models (MLLMs) often focus exclusively on applying changes indicated by the text, without fully utilizing the contextual visual information from the reference image. To address these issues, we propose multi-faceted Chain-of-Thought with re-ranking (MCoT-RE), a training-free zero-shot CIR framework. MCoT-RE utilizes multi-faceted Chain-of-Thought to guide the MLLM to balance explicit modifications and contextual visual cues, generating two distinct captions: one focused on modification and the other integrating comprehensive visual-textual context. The first caption is used to filter candidate images. Subsequently, we combine these two captions and the reference image to perform multi-grained re-ranking. This two-stage approach facilitates precise retrieval by aligning with the textual modification instructions while preserving the visual context of the reference image. Through extensive experiments, MCoT-RE achieves state-of-the-art results among training-free methods, yielding improvements of up to 6.24% in Recall@10 on FashionIQ and 8.58% in Recall@1 on CIRR.",
      "authors": [
        "Jeong-Woo Park",
        "Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:22:49+00:00",
          "link": "https://arxiv.org/abs/2507.12819v1",
          "size": "3728kb",
          "version": "v1"
        }
      ],
      "title": "MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12819",
        "HTML": "https://arxiv.org/html/2507.12819v1",
        "PDF": "https://arxiv.org/pdf/2507.12819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a framework for composed image retrieval using pre-trained models and focuses on improving retrieval performance through a chain-of-thought mechanism. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12820",
      "abstract": "Emotional Support Conversation (ESC) aims to provide empathetic and effective emotional assistance through dialogue, addressing the growing demand for mental health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC evaluation, where we leverage large-scale language models enhanced by prompt engineering and finetuning techniques. We explore both parameter-efficient Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the model's ability to generate supportive and contextually appropriate responses. Our best model ranked second in the competition, highlighting the potential of combining LLMs with effective adaptation methods for ESC tasks. Future work will focus on further enhancing emotional understanding and response personalization to build more practical and reliable emotional support systems.",
      "authors": [
        "Shiquan Wang",
        "Ruiyu Fang",
        "Zhongjiang He",
        "Shuangyong Song",
        "Yongxiang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:24:20+00:00",
          "link": "https://arxiv.org/abs/2507.12820v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Emotional Support with LLM-based Empathetic Dialogue Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12820",
        "HTML": "https://arxiv.org/html/2507.12820v1",
        "PDF": "https://arxiv.org/pdf/2507.12820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves fine-tuning LLMs for emotional support dialogue systems, it primarily focuses on model adaptation techniques rather than on LLM training data processing operations like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12821",
      "abstract": "Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence (AI) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in AI. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in AI and provide a crucial step towards developing AI systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.",
      "authors": [
        "Lance Ying",
        "Katherine M. Collins",
        "Prafull Sharma",
        "Cedric Colas",
        "Kaiya Ivy Zhao",
        "Adrian Weller",
        "Zenna Tavares",
        "Phillip Isola",
        "Samuel J. Gershman",
        "Jacob D. Andreas",
        "Thomas L. Griffiths",
        "Francois Chollet",
        "Kelsey R. Allen",
        "Joshua B. Tenenbaum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:28:14+00:00",
          "link": "https://arxiv.org/abs/2507.12821v1",
          "size": "2541kb",
          "version": "v1"
        }
      ],
      "title": "Assessing adaptive world models in machines with novel games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12821",
        "HTML": "https://arxiv.org/html/2507.12821v1",
        "PDF": "https://arxiv.org/pdf/2507.12821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses world model induction and proposes an evaluation framework with novel games, focusing on adaptability and generalization in AI. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12822",
      "abstract": "We revisit the well-known online traveling salesman problem (OLTSP) and its extension, the online dial-a-ride problem (OLDARP). A server starting at a designated origin in a metric space, is required to serve online requests, and return to the origin such that the completion time is minimized. The SmartStart algorithm, introduced by Ascheuer et al., incorporates a waiting approach into an online schedule-based algorithm and attains the optimal upper bound of 2 for the OLTSP and the OLDARP if each schedule is optimal. Using the Christofides' heuristic to approximate each schedule leads to the currently best upper bound of (7 + sqrt(13)) / 4 approximately 2.6514 in polynomial time.\n  In this study, we investigate how an online algorithm with predictions, a recent popular framework (i.e. the so-called learning-augmented algorithms), can be used to improve the best competitive ratio in polynomial time. In particular, we develop a waiting strategy with online predictions, each of which is only a binary decision-making for every schedule in a whole route, rather than forecasting an entire set of requests in the beginning (i.e. offline predictions). That is, it does not require knowing the number of requests in advance. The proposed online schedule-based algorithm can achieve 1.1514 * lambda + 1.5-consistency and 1.5 + 1.5 / (2.3028 * lambda - 1)-robustness in polynomial time, where lambda lies in the interval (1/theta, 1] and theta is set to (1 + sqrt(13)) / 2 approximately 2.3028. The best consistency tends to approach to 2 when lambda is close to 1/theta. Meanwhile, we show any online schedule-based algorithms cannot derive a competitive ratio of less than 2 even with perfect online predictions.",
      "authors": [
        "Ya-Chun Liang",
        "Meng-Hsi Li",
        "Chung-Shou Liao",
        "Clifford Stein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:28:28+00:00",
          "link": "https://arxiv.org/abs/2507.12822v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "Waiting is worth it and can be improved with predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12822",
        "HTML": "https://arxiv.org/html/2507.12822v1",
        "PDF": "https://arxiv.org/pdf/2507.12822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses online algorithms and predictions in the context of optimization problems, specifically the traveling salesman problem, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12823",
      "abstract": "Composed image retrieval (CIR) is a vision language task that retrieves a target image using a reference image and modification text, enabling intuitive specification of desired changes. While effectively fusing visual and textual modalities is crucial, existing methods typically adopt either early or late fusion. Early fusion tends to excessively focus on explicitly mentioned textual details and neglect visual context, whereas late fusion struggles to capture fine-grained semantic alignments between image regions and textual tokens. To address these issues, we propose FAR-Net, a multi-stage fusion framework designed with enhanced semantic alignment and adaptive reconciliation, integrating two complementary modules. The enhanced semantic alignment module (ESAM) employs late fusion with cross-attention to capture fine-grained semantic relationships, while the adaptive reconciliation module (ARM) applies early fusion with uncertainty embeddings to enhance robustness and adaptability. Experiments on CIRR and FashionIQ show consistent performance gains, improving Recall@1 by up to 2.4% and Recall@50 by 1.04% over existing state-of-the-art methods, empirically demonstrating that FAR Net provides a robust and scalable solution to CIR tasks.",
      "authors": [
        "Jeong-Woo Park",
        "Young-Eun Kim",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:30:41+00:00",
          "link": "https://arxiv.org/abs/2507.12823v1",
          "size": "1884kb",
          "version": "v1"
        }
      ],
      "title": "FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12823",
        "HTML": "https://arxiv.org/html/2507.12823v1",
        "PDF": "https://arxiv.org/pdf/2507.12823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on a multi-stage fusion network for composed image retrieval, addressing issues in vision-language tasks, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12825",
      "abstract": "In speech processing pipelines, improving the quality and intelligibility of real-world recordings is crucial. While supervised regression is the primary method for speech enhancement, audio tokenization is emerging as a promising alternative for a smooth integration with other modalities. However, research on speech enhancement using discrete representations is still limited. Previous work has mainly focused on semantic tokens, which tend to discard key acoustic details such as speaker identity. Additionally, these studies typically employ non-autoregressive models, assuming conditional independence of outputs and overlooking the potential improvements offered by autoregressive modeling. To address these gaps we: 1) conduct a comprehensive study of the performance of acoustic tokens for speech enhancement, including the effect of bitrate and noise strength; 2) introduce a novel transducer-based autoregressive architecture specifically designed for this task. Experiments on VoiceBank and Libri1Mix datasets show that acoustic tokens outperform semantic tokens in terms of preserving speaker identity, and that our autoregressive approach can further improve performance. Nevertheless, we observe that discrete representations still fall short compared to continuous ones, highlighting the need for further research in this area.",
      "authors": [
        "Luca Della Libera",
        "Cem Subakan",
        "Mirco Ravanelli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:32:22+00:00",
          "link": "https://arxiv.org/abs/2507.12825v1",
          "size": "548kb",
          "version": "v1"
        }
      ],
      "title": "Autoregressive Speech Enhancement via Acoustic Tokens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12825",
        "HTML": "https://arxiv.org/html/2507.12825v1",
        "PDF": "https://arxiv.org/pdf/2507.12825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with speech enhancement using acoustic tokens, examining speech processing pipelines, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12828",
      "abstract": "Food is not only a core component of humans' daily diets, but also an important carrier of cultural heritage and emotional bonds. With the development of technology, the need for accurate classification of food images has grown, which is crucial for a variety of application scenarios. However, existing Convolutional Neural Networks (CNNs) face significant challenges when dealing with fine-grained food images that are similar in shape but subtle in detail. To address this challenge, this study presents an innovative method for classifying food images, named Feature-Enhanced TResNet (FE-TResNet), specifically designed to address fine-grained food images and accurately capture subtle features within them. The FE-TResNet method is based on the TResNet model and integrates Style-based Recalibration Module (StyleRM) and Deep Channel-wise Attention (DCA) technologies to enhance feature extraction capabilities. In experimental validation on Chinese food image datasets ChineseFoodNet and CNFOOD-241, the FE-TResNet method significantly improved classification accuracy, achieving rates of 81.37% and 80.29%, respectively, demonstrating its effectiveness and superiority in fine-grained food image classification.",
      "authors": [
        "Lulu Liu and Zhiyong Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:37:45+00:00",
          "link": "https://arxiv.org/abs/2507.12828v1",
          "size": "5650kb",
          "version": "v1"
        }
      ],
      "title": "Feature-Enhanced TResNet for Fine-Grained Food Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12828",
        "HTML": "https://arxiv.org/html/2507.12828v1",
        "PDF": "https://arxiv.org/pdf/2507.12828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing a network for fine-grained food image classification, which is not related to the topic of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12830",
      "abstract": "We consider the problem of data storage in a geographically distributed (or geo-distributed) network of servers (or nodes) where inter-node communication incurs certain round-trip delays. Every node serves a set of users who can request any file in the network. If the requested file is not available at the node, it communicates with other nodes to obtain the file, thus causing the user to experience latency in obtaining the file. The files can be placed uncoded, where each node stores exact copies of the files, or in coded fashion, where certain linear combination of files are placed at each node. We aim to obtain an optimal file placement on the nodes with respect to minimizing the worst-case latency at each node, as well as the system-average latency. The prior literature considered the case of equiprobable file demands at the nodes. In this paper, we investigate the generic case of non-uniform file-demand probabilities at each node. The scheme presented here is optimal within the family of uncoded schemes. It is obtained first by modeling the worst-case latency constraint as a vertex coloring problem, and then converting the system-average latency optimization to a problem of balanced-assignment.",
      "authors": [
        "Srivathsa Acharya",
        "P. Vijay Kumar",
        "Viveck R. Cadambe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:38:33+00:00",
          "link": "https://arxiv.org/abs/2507.12830v1",
          "size": "572kb",
          "version": "v1"
        }
      ],
      "title": "Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12830",
        "HTML": "https://arxiv.org/html/2507.12830v1",
        "PDF": "https://arxiv.org/pdf/2507.12830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses latency in geo-distributed storage systems with preferential file demands. It deals with data placement and optimization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12832",
      "abstract": "Small Multi-Object Tracking (SMOT) is particularly challenging when targets occupy only a few dozen pixels, rendering detection and appearance-based association unreliable. Building on the success of the MVA2023 SOD4SB challenge, this paper introduces the SMOT4SB challenge, which leverages temporal information to address limitations of single-frame detection. Our three main contributions are: (1) the SMOT4SB dataset, consisting of 211 UAV video sequences with 108,192 annotated frames under diverse real-world conditions, designed to capture motion entanglement where both camera and targets move freely in 3D; (2) SO-HOTA, a novel metric combining Dot Distance with HOTA to mitigate the sensitivity of IoU-based metrics to small displacements; and (3) a competitive MVA2025 challenge with 78 participants and 308 submissions, where the winning method achieved a 5.1x improvement over the baseline. This work lays a foundation for advancing SMOT in UAV scenarios with applications in bird strike avoidance, agriculture, fisheries, and ecological monitoring.",
      "authors": [
        "Yuki Kondo",
        "Norimichi Ukita",
        "Riku Kanayama",
        "Yuki Yoshida",
        "Takayuki Yamaguchi",
        "Xiang Yu",
        "Guang Liang",
        "Xinyao Liu",
        "Guan-Zhang Wang",
        "Wei-Ta Chu",
        "Bing-Cheng Chuang",
        "Jia-Hua Lee",
        "Pin-Tseng Kuo",
        "I-Hsuan Chu",
        "Yi-Shein Hsiao",
        "Cheng-Han Wu",
        "Po-Yi Wu",
        "Jui-Chien Tsou",
        "Hsuan-Chi Liu",
        "Chun-Yi Lee",
        "Yuan-Fu Yang",
        "Kosuke Shigematsu",
        "Asuka Shin",
        "Ba Tran"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:45:47+00:00",
          "link": "https://arxiv.org/abs/2507.12832v1",
          "size": "10055kb",
          "version": "v1"
        }
      ],
      "title": "MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12832",
        "HTML": "https://arxiv.org/html/2507.12832v1",
        "PDF": "https://arxiv.org/pdf/2507.12832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the SMOT4SB dataset for small multi-object tracking, which is relevant to data processing but not specifically for LLMs. The main focus is on tracking methods rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12835",
      "abstract": "Financial trading environments are characterized by high volatility, numerous macroeconomic signals, and dynamically shifting market regimes, where traditional reinforcement learning methods often fail to deliver breakthrough performance. In this study, we design a reinforcement learning framework tailored for financial systems by integrating quantum circuits. We compare (1) the performance of classical A3C versus quantum A3C algorithms, and (2) the impact of incorporating LSTM-based predictions of the following week's economic trends on learning outcomes. The experimental framework adopts a custom Gymnasium-compatible trading environment, simulating discrete trading actions and evaluating rewards based on portfolio feedback. Experimental results show that quantum models - especially when combined with predictive signals - demonstrate superior performance and stability under noisy financial conditions, even with shallow quantum circuit depth.",
      "authors": [
        "Yen-Ku Liu",
        "Yun-Huei Pan",
        "Pei-Fan Lu",
        "Yun-Cheng Tsai",
        "Samuel Yen-Chi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:50:48+00:00",
          "link": "https://arxiv.org/abs/2507.12835v1",
          "size": "1969kb",
          "version": "v1"
        }
      ],
      "title": "Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12835",
        "HTML": "https://arxiv.org/html/2507.12835v1",
        "PDF": "https://arxiv.org/pdf/2507.12835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a reinforcement learning framework for fintech trading using quantum circuits and LSTM predictions. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12837",
      "abstract": "The study of Neural Tangent Kernels (NTKs) in deep learning has drawn increasing attention in recent years. NTKs typically actively change during training and are related to feature learning. In parallel, recent work on Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in which the largest eigenvalue of the NTK oscillates around a value inversely proportional to the step size. However, although follow-up works have explored the underlying mechanism of such eigenvalue behavior in depth, the understanding of the behavior of the NTK eigenvectors during EoS is still missing. This paper examines the dynamics of NTK eigenvectors during EoS in detail. Across different architectures, we observe that larger learning rates cause the leading eigenvectors of the final NTK, as well as the full NTK matrix, to have greater alignment with the training target. We then study the underlying mechanism of this phenomenon and provide a theoretical analysis for a two-layer linear network. Our study enhances the understanding of GD training dynamics in deep learning.",
      "authors": [
        "Kaiqi Jiang",
        "Jeremy Cohen",
        "Yuanzhi Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:52:56+00:00",
          "link": "https://arxiv.org/abs/2507.12837v1",
          "size": "450kb",
          "version": "v1"
        }
      ],
      "title": "Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12837",
        "HTML": "https://arxiv.org/html/2507.12837v1",
        "PDF": "https://arxiv.org/pdf/2507.12837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the dynamics of Neural Tangent Kernels during Gradient Descent training. It does not address LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12838",
      "abstract": "Cross-lingual consistency should be considered to assess cross-lingual transferability, maintain the factuality of the model knowledge across languages, and preserve the parity of language model performance. We are thus interested in analyzing, evaluating, and interpreting cross-lingual consistency for factual knowledge. We examine code-mixed coreferential statements conveyed identical knowledge across languages to study cross-lingual knowledge consistency. We use some interpretability approaches to analyze the behavior of a model in cross-lingual contexts, discovering that multilingual models show different levels of consistency, subject to language families, linguistic factors, and a bottleneck in cross-lingual consistency on a particular layer. In addition, we evaluate common strategies aimed at improving multilingual performance to observe whether these strategies can improve knowledge consistency at the same time. While knowledge is not cross-lingual consistency in many cases, code-switching training and cross-lingual word alignment objectives show the most promising results, emphasizing the noteworthiness of cross-lingual alignment supervision and code-switching training for both multilingual performance and cross-lingual consistency enhancement.",
      "authors": [
        "Xi Ai",
        "Mahardika Krisna Ihsani",
        "Min-Yen Kan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:55:15+00:00",
          "link": "https://arxiv.org/abs/2507.12838v1",
          "size": "4499kb",
          "version": "v1"
        }
      ],
      "title": "Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12838",
        "HTML": "https://arxiv.org/html/2507.12838v1",
        "PDF": "https://arxiv.org/pdf/2507.12838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines cross-lingual consistency in multilingual language models, focusing on knowledge consistency across languages. While it touches on multilingual model performance, it does not directly contribute to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12840",
      "abstract": "Vaccine hesitancy threatens public health, leading to delayed or rejected vaccines. Social media is a vital source for understanding public concerns, and traditional methods like topic modelling often struggle to capture nuanced opinions. Though trained for query answering, large Language Models (LLMs) often miss current events and community concerns. Additionally, hallucinations in LLMs can compromise public health communication. To address these limitations, we developed a tool (VaxPulse Query Corner) using the Retrieval Augmented Generation technique. It addresses complex queries about public vaccine concerns on various online platforms, aiding public health administrators and stakeholders in understanding public concerns and implementing targeted interventions to boost vaccine confidence. Analysing 35,103 Shingrix social media posts, it achieved answer faithfulness (0.96) and relevance (0.94).",
      "authors": [
        "Muhammad Javed",
        "Sedigh Khademi Habibabadi",
        "Christopher Palmer",
        "Hazel Clothier",
        "Jim Buttery",
        "and Gerardo Luis Dimaguila"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:59:52+00:00",
          "link": "https://arxiv.org/abs/2507.12840v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the Gap: Leveraging Retrieval-Augmented Generation to Better Understand Public Concerns about Vaccines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12840",
        "PDF": "https://arxiv.org/pdf/2507.12840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using Retrieval-Augmented Generation to address public concerns about vaccines, primarily using LLMs for understanding social media data. It does not discuss training data processing for pretraining or fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12841",
      "abstract": "Controllable captioning is essential for precise multimodal alignment and instruction following, yet existing models often lack fine-grained control and reliable evaluation protocols. To address this gap, we present the AnyCap Project, an integrated solution spanning model, dataset, and evaluation. We introduce AnyCapModel (ACM), a lightweight plug-and-play framework that enhances the controllability of existing foundation models for omni-modal captioning without retraining the base model. ACM reuses the original captions from base models while incorporating user instructions and modality features to generate improved captions. To remedy the data scarcity in controllable multimodal captioning, we build AnyCapDataset (ACD), covering three modalities, 28 user-instruction types, and 300\\,k high-quality data entries. We further propose AnyCapEval, a new benchmark that provides more reliable evaluation metrics for controllable captioning by decoupling content accuracy and stylistic fidelity. ACM markedly improves caption quality across a diverse set of base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\\'s content scores by 45\\% and style scores by 12\\%, and it also achieves substantial gains on widely used benchmarks such as MIA-Bench and VidCapBench.",
      "authors": [
        "Yiming Ren",
        "Zhiqiang Lin",
        "Yu Li",
        "Gao Meng",
        "Weiyun Wang",
        "Junjie Wang",
        "Zicheng Lin",
        "Jifeng Dai",
        "Yujiu Yang",
        "Wenhai Wang",
        "and Ruihang Chu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:04:05+00:00",
          "link": "https://arxiv.org/abs/2507.12841v1",
          "size": "9663kb",
          "version": "v1"
        }
      ],
      "title": "AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12841",
        "HTML": "https://arxiv.org/html/2507.12841v1",
        "PDF": "https://arxiv.org/pdf/2507.12841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces AnyCapDataset to aid in multi-modal captioning, its primary focus is on model development and evaluation metrics for captioning, rather than contributing directly to LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12843",
      "abstract": "The distribution closeness testing (DCT) assesses whether the distance between a distribution pair is at least $\\epsilon$-far. Existing DCT methods mainly measure discrepancies between a distribution pair defined on discrete one-dimensional spaces (e.g., using total variation), which limits their applications to complex data (e.g., images). To extend DCT to more types of data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful measurement of the distributional discrepancy between two complex distributions, into DCT scenarios. However, we find that MMD's value can be the same for many pairs of distributions that have different norms in the same reproducing kernel Hilbert space (RKHS), making MMD less informative when assessing the closeness levels for multiple distribution pairs. To mitigate the issue, we design a new measurement of distributional discrepancy, norm-adaptive MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions. Based on the asymptotic distribution of NAMMD, we finally propose the NAMMD-based DCT to assess the closeness levels of a distribution pair. Theoretically, we prove that NAMMD-based DCT has higher test power compared to MMD-based DCT, with bounded type-I error, which is also validated by extensive experiments on many types of data (e.g., synthetic noise, real images). Furthermore, we also apply the proposed NAMMD for addressing the two-sample testing problem and find NAMMD-based two-sample test has higher test power than the MMD-based two-sample test in both theory and experiments.",
      "authors": [
        "Zhijian Zhou",
        "Liuhua Peng",
        "Xunye Tian and Feng Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:08:54+00:00",
          "link": "https://arxiv.org/abs/2507.12843v1",
          "size": "551kb",
          "version": "v1"
        }
      ],
      "title": "A Kernel Distribution Closeness Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12843",
        "HTML": "https://arxiv.org/html/2507.12843v1",
        "PDF": "https://arxiv.org/pdf/2507.12843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new method for distribution closeness testing and does not relate to LLM training data operations like data collection, filtering, or dataset creation specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12844",
      "abstract": "Autonomous multimodal language models are rapidly evolving into web agents that can browse, click, and purchase items on behalf of users, posing a threat to display advertising designed for human eyes. Yet little is known about how these agents interact with ads or which design principles ensure reliable engagement. To address this, we ran a controlled experiment using a faithful clone of the news site TT.com, seeded with diverse ads: static banners, GIFs, carousels, videos, cookie dialogues, and paywalls. We ran 300 initial trials plus follow-ups using the Document Object Model (DOM)-centric Browser Use framework with GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash, and the pixel-based OpenAI Operator, across 10 realistic user tasks. Our results show these agents display severe satisficing: they never scroll beyond two viewports and ignore purely visual calls to action, clicking banners only when semantic button overlays or off-screen text labels are present. Critically, when sweepstake participation required a purchase, GPT-4o and Claude 3.7 Sonnet subscribed in 100% of trials, and Gemini 2.0 Flash in 70%, revealing gaps in cost-benefit analysis. We identified five actionable design principles-semantic overlays, hidden labels, top-left placement, static frames, and dialogue replacement, that make human-centric creatives machine-detectable without harming user experience. We also evaluated agent trustworthiness through \"behavior patterns\" such as cookie consent handling and subscription choices, highlighting model-specific risk boundaries and the urgent need for robust trust evaluation frameworks in real-world advertising.",
      "authors": [
        "Joel Nitu",
        "Heidrun M\\\"uhle",
        "Andreas St\\\"ockl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:10:27+00:00",
          "link": "https://arxiv.org/abs/2507.12844v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Machine-Readable Ads: Accessibility and Trust Patterns for AI Web Agents interacting with Online Advertisements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12844",
        "HTML": "https://arxiv.org/html/2507.12844v1",
        "PDF": "https://arxiv.org/pdf/2507.12844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates how AI web agents interact with online advertisements and proposes design principles for improved agent interaction with ads, not contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12845",
      "abstract": "Image captioning has emerged as a crucial task in the intersection of computer vision and natural language processing, enabling automated generation of descriptive text from visual content. In the context of remote sensing, image captioning plays a significant role in interpreting vast and complex satellite imagery, aiding applications such as environmental monitoring, disaster assessment, and urban planning. This motivates us, in this paper, to present a transformer based network architecture for remote sensing image captioning (RSIC) in which multiple techniques of Static Expansion, Memory-Augmented Self-Attention, Mesh Transformer are evaluated and integrated. We evaluate our proposed models using two benchmark remote sensing image datasets of UCM-Caption and NWPU-Caption. Our best model outperforms the state-of-the-art systems on most of evaluation metrics, which demonstrates potential to apply for real-life remote sensing image systems.",
      "authors": [
        "Khang Truong",
        "Lam Pham",
        "Hieu Tang",
        "Jasmin Lampert",
        "Martin Boyer",
        "Son Phan",
        "Truong Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:11:01+00:00",
          "link": "https://arxiv.org/abs/2507.12845v1",
          "size": "3534kb",
          "version": "v1"
        }
      ],
      "title": "SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12845",
        "HTML": "https://arxiv.org/html/2507.12845v1",
        "PDF": "https://arxiv.org/pdf/2507.12845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on developing a new network architecture for image captioning in remote sensing, with no discussion on methods or techniques for training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12846",
      "abstract": "As robots become increasingly capable of operating over extended periods -- spanning days, weeks, and even months -- they are expected to accumulate knowledge of their environments and leverage this experience to assist humans more effectively. This paper studies the problem of Long-term Active Embodied Question Answering (LA-EQA), a new task in which a robot must both recall past experiences and actively explore its environment to answer complex, temporally-grounded questions. Unlike traditional EQA settings, which typically focus either on understanding the present environment alone or on recalling a single past observation, LA-EQA challenges an agent to reason over past, present, and possible future states, deciding when to explore, when to consult its memory, and when to stop gathering observations and provide a final answer. Standard EQA approaches based on large models struggle in this setting due to limited context windows, absence of persistent memory, and an inability to combine memory recall with active exploration. To address this, we propose a structured memory system for robots, inspired by the mind palace method from cognitive science. Our method encodes episodic experiences as scene-graph-based world instances, forming a reasoning and planning algorithm that enables targeted memory retrieval and guided navigation. To balance the exploration-recall trade-off, we introduce value-of-information-based stopping criteria that determines when the agent has gathered sufficient information. We evaluate our method on real-world experiments and introduce a new benchmark that spans popular simulation environments and actual industrial sites. Our approach significantly outperforms state-of-the-art baselines, yielding substantial gains in both answer accuracy and exploration efficiency.",
      "authors": [
        "Muhammad Fadhil Ginting",
        "Dong-Ki Kim",
        "Xiangyun Meng",
        "Andrzej Reinke",
        "Bandi Jai Krishna",
        "Navid Kayhani",
        "Oriana Peltzer",
        "David D. Fan",
        "Amirreza Shaban",
        "Sung-Kyun Kim",
        "Mykel J. Kochenderfer",
        "Ali-akbar Agha-mohammadi",
        "and Shayegan Omidshafiei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:11:32+00:00",
          "link": "https://arxiv.org/abs/2507.12846v1",
          "size": "7371kb",
          "version": "v1"
        }
      ],
      "title": "Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12846",
        "HTML": "https://arxiv.org/html/2507.12846v1",
        "PDF": "https://arxiv.org/pdf/2507.12846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on Long-term Active Embodied Question Answering (LA-EQA) tasks for robots and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12847",
      "abstract": "We propose an $O(\\log n)$-approximation algorithm for the bipartiteness ratio for undirected graphs introduced by Trevisan (SIAM Journal on Computing, vol. 41, no. 6, 2012), where $n$ is the number of vertices. Our approach extends the cut-matching game framework for sparsest cut to the bipartiteness ratio. Our algorithm requires only $\\mathrm{poly}\\log n$ many single-commodity undirected maximum flow computations. Therefore, with the current fastest undirected max-flow algorithms, it runs in nearly linear time. Along the way, we introduce the concept of well-linkedness for skew-symmetric graphs and prove a novel characterization of bipartitness ratio in terms of well-linkedness in an auxiliary skew-symmetric graph, which may be of independent interest.\n  As an application, we devise an $\\tilde{O}(mn)$-time algorithm that given a graph whose maximum cut deletes a $1-\\eta$ fraction of edges, finds a cut that deletes a $1 - O(\\log n \\log(1/\\eta)) \\cdot \\eta$ fraction of edges, where $m$ is the number of edges.",
      "authors": [
        "Tasuku Soma",
        "Mingquan Ye",
        "Yuichi Yoshida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.12847v1",
          "size": "135kb",
          "version": "v1"
        }
      ],
      "title": "Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12847",
        "HTML": "https://arxiv.org/html/2507.12847v1",
        "PDF": "https://arxiv.org/pdf/2507.12847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an approximation algorithm for the bipartiteness ratio in undirected graphs, which is unrelated to LLM training data processing in terms of methods or applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12850",
      "abstract": "Joint source-channel coding (JSCC) is an effective approach for semantic communication. However, current JSCC methods are difficult to integrate with existing communication network architectures, where application and network providers are typically different entities. Recently, a novel paradigm termed Split DeepJSCC has been under consideration to address this challenge. Split DeepJSCC employs a bit-level interface that enables separate design of source and channel codes, ensuring compatibility with existing communication networks while preserving the advantages of JSCC in terms of semantic fidelity and channel adaptability. In this paper, we propose a learning-based interface design by treating its parameters as trainable, achieving improved end-to-end performance compared to Split DeepJSCC. In particular, the interface enables specification of bit-level importance at the output of the source code. Furthermore, we propose an Importance-Aware Net that utilizes the interface-derived bit importance information, enabling dynamical adaptation to diverse channel bandwidth ratios and time-varying channel conditions. Experimental results show that our method improves performance in wireless image transmission tasks. This work provides a potential solution for realizing semantic communications in existing wireless networks.",
      "authors": [
        "Wenzheng Kong and Wenyi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:20:12+00:00",
          "link": "https://arxiv.org/abs/2507.12850v1",
          "size": "4110kb",
          "version": "v1"
        }
      ],
      "title": "Learning-Based Interface for Semantic Communication with Bit Importance Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12850",
        "HTML": "https://arxiv.org/html/2507.12850v1",
        "PDF": "https://arxiv.org/pdf/2507.12850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered around semantic communication and learning-based interfaces for JSCC methods, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12851",
      "abstract": "Domain generalization (DG) aims to learn a model from source domains and apply it to unseen target domains with out-of-distribution data. Owing to CLIP's strong ability to encode semantic concepts, it has attracted increasing interest in domain generalization. However, CLIP often struggles to focus on task-relevant regions across domains, i.e., domain-invariant regions, resulting in suboptimal performance on unseen target domains. To address this challenge, we propose an attention-refocusing scheme, called Simulate, Refocus and Ensemble (SRE), which learns to reduce the domain shift by aligning the attention maps in CLIP via attention refocusing. SRE first simulates domain shifts by performing augmentation on the source data to generate simulated target domains. SRE then learns to reduce the domain shifts by refocusing the attention in CLIP between the source and simulated target domains. Finally, SRE utilizes ensemble learning to enhance the ability to capture domain-invariant attention maps between the source data and the simulated target data. Extensive experimental results on several datasets demonstrate that SRE generally achieves better results than state-of-the-art methods. The code is available at: https://github.com/bitPrincy/SRE-DG.",
      "authors": [
        "Ziyi Wang",
        "Zhi Gao",
        "Jin Chen",
        "Qingjie Zhao",
        "Xinxiao Wu",
        "Jiebo Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:20:32+00:00",
          "link": "https://arxiv.org/abs/2507.12851v1",
          "size": "5975kb",
          "version": "v1"
        }
      ],
      "title": "Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12851",
        "HTML": "https://arxiv.org/html/2507.12851v1",
        "PDF": "https://arxiv.org/pdf/2507.12851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses domain generalization using attention refocusing and CLIP models, focusing on domain shifts rather than any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12853",
      "abstract": "The note provides new apparoaches and results for the search of 6-bit APN-functions based on the classification of 6-bits Boolean functions.",
      "authors": [
        "Val\\'erie Gillot",
        "Philippe Langevin",
        "Abdoulaye Lo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:25:08+00:00",
          "link": "https://arxiv.org/abs/2507.12853v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Spectral Moment of Order Four and the Uniqueness of the CCZ class of Dublin APN Permutation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12853",
        "HTML": "https://arxiv.org/html/2507.12853v1",
        "PDF": "https://arxiv.org/pdf/2507.12853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This note addresses classification methods for specific Boolean functions, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12854",
      "abstract": "Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving alternative to vision-based systems for human identification. However, person identification through wireless signals, particularly without user motion, remains largely unexplored. Most prior wireless-based approaches rely on movement patterns, such as walking gait, to extract biometric cues. In contrast, we propose a transformer-based method that identifies individuals from Channel State Information (CSI) recorded while the subject remains stationary. CSI captures fine-grained amplitude and phase distortions induced by the unique interaction between the human body and the radio signal. To support evaluation, we introduce a dataset acquired with ESP32 devices in a controlled indoor environment, featuring six participants observed across multiple orientations. A tailored preprocessing pipeline, including outlier removal, smoothing, and phase calibration, enhances signal quality. Our dual-branch transformer architecture processes amplitude and phase modalities separately and achieves 99.82\\% classification accuracy, outperforming convolutional and multilayer perceptron baselines. These results demonstrate the discriminative potential of CSI perturbations, highlighting their capacity to encode biometric traits in a consistent manner. They further confirm the viability of passive, device-free person identification using low-cost commodity Wi-Fi hardware in real-world settings.",
      "authors": [
        "Danilo Avola",
        "Andrea Bernardini",
        "Francesco Danese",
        "Mario Lezoche",
        "Maurizio Mancini",
        "Daniele Pannone",
        "and Amedeo Ranaldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:26:07+00:00",
          "link": "https://arxiv.org/abs/2507.12854v1",
          "size": "2917kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12854",
        "HTML": "https://arxiv.org/html/2507.12854v1",
        "PDF": "https://arxiv.org/pdf/2507.12854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Wi-Fi based person identification using CSI data and a transformer architecture. It doesn't cover LLM training data processing, nor does it address any aspect related to pretraining or fine-tuning of LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12855",
      "abstract": "The integration of large language models (LLMs) with control systems has demonstrated significant potential in various settings, such as task completion with a robotic manipulator. A main reason for this success is the ability of LLMs to perform in-context learning, which, however, strongly relies on the design of task examples, closely related to the target tasks. Consequently, employing LLMs to formulate optimal control problems often requires task examples that contain explicit mathematical expressions, designed by trained engineers. Furthermore, there is often no principled way to evaluate for hallucination before task execution. To address these challenges, we propose DEMONSTRATE, a novel methodology that avoids the use of LLMs for complex optimization problem generations, and instead only relies on the embedding representations of task descriptions. To do this, we leverage tools from inverse optimal control to replace in-context prompt examples with task demonstrations, as well as the concept of multitask learning, which ensures target and example task similarity by construction. Given the fact that hardware demonstrations can easily be collected using teleoperation or guidance of the robot, our approach significantly reduces the reliance on engineering expertise for designing in-context examples. Furthermore, the enforced multitask structure enables learning from few demonstrations and assessment of hallucinations prior to task execution. We demonstrate the effectiveness of our method through simulation and hardware experiments involving a robotic arm tasked with tabletop manipulation.",
      "authors": [
        "Rahel Rickenbach",
        "Bruce Lee",
        "Ren\\'e Zurbr\\\"ugg",
        "Carmen Amo Alonso",
        "Melanie N. Zeilinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:26:22+00:00",
          "link": "https://arxiv.org/abs/2507.12855v1",
          "size": "6342kb",
          "version": "v1"
        }
      ],
      "title": "DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12855",
        "HTML": "https://arxiv.org/html/2507.12855v1",
        "PDF": "https://arxiv.org/pdf/2507.12855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using LLMs for robotic control and demonstration learning, not LLM training data processing. There are no contributions regarding dataset creation, data processing techniques for training LLMs, or similar activities associated with LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12856",
      "abstract": "Behavior Cloning (BC) on curated (or filtered) data is the predominant paradigm for supervised fine-tuning (SFT) of large language models; as well as for imitation learning of control policies. Here, we draw on a connection between this successful strategy and the theory and practice of finding optimal policies via Reinforcement Learning (RL). Building on existing literature, we clarify that SFT can be understood as maximizing a lower bound on the RL objective in a sparse reward setting. Giving support to its often observed good performance. From this viewpoint, we realize that a small modification to SFT leads to an importance weighted variant that behaves closer to training with RL as it: i) optimizes a tighter bound to the RL objective and, ii) can improve performance compared to SFT on curated data. We refer to this variant as importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to implement and can be further generalized to training with quality scored data. The resulting SFT variants are competitive with more advanced RL algorithms for large language models and for training policies in continuous control tasks. For example achieving 66.7% on the AIME 2024 dataset.",
      "authors": [
        "Chongli Qin",
        "Jost Tobias Springenberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:26:54+00:00",
          "link": "https://arxiv.org/abs/2507.12856v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12856",
        "HTML": "https://arxiv.org/html/2507.12856v1",
        "PDF": "https://arxiv.org/pdf/2507.12856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions supervised fine-tuning on curated data and introduces an improved approach called iw-SFT. While it discusses data quality aspects in fine-tuning, the focus is primarily on an optimization technique related to RL rather than detailed contributions to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12857",
      "abstract": "Most existing remote sensing instance segmentation approaches are designed for close-vocabulary prediction, limiting their ability to recognize novel categories or generalize across datasets. This restricts their applicability in diverse Earth observation scenarios. To address this, we introduce open-vocabulary (OV) learning for remote sensing instance segmentation. While current OV segmentation models perform well on natural image datasets, their direct application to remote sensing faces challenges such as diverse landscapes, seasonal variations, and the presence of small or ambiguous objects in aerial imagery. To overcome these challenges, we propose $\\textbf{SCORE}$ ($\\textbf{S}$cene $\\textbf{C}$ontext matters in $\\textbf{O}$pen-vocabulary $\\textbf{RE}$mote sensing instance segmentation), a framework that integrates multi-granularity scene context, i.e., regional context and global context, to enhance both visual and textual representations. Specifically, we introduce Region-Aware Integration, which refines class embeddings with regional context to improve object distinguishability. Additionally, we propose Global Context Adaptation, which enriches naive text embeddings with remote sensing global context, creating a more adaptable and expressive linguistic latent space for the classifier. We establish new benchmarks for OV remote sensing instance segmentation across diverse datasets. Experimental results demonstrate that, our proposed method achieves SOTA performance, which provides a robust solution for large-scale, real-world geospatial analysis. Our code is available at https://github.com/HuangShiqi128/SCORE.",
      "authors": [
        "Shiqi Huang",
        "Shuting He",
        "Huaiyuan Qin",
        "Bihan Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:27:00+00:00",
          "link": "https://arxiv.org/abs/2507.12857v1",
          "size": "4790kb",
          "version": "v1"
        }
      ],
      "title": "SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12857",
        "HTML": "https://arxiv.org/html/2507.12857v1",
        "PDF": "https://arxiv.org/pdf/2507.12857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research relates to remote sensing and instance segmentation, introducing the SCORE framework. It does not address LLM training data processing or contribute any relevant datasets or data processing techniques in the context of training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12862",
      "abstract": "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.",
      "authors": [
        "Hussein Abbass",
        "Taylan Akay",
        "Harrison Tolley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:34:24+00:00",
          "link": "https://arxiv.org/abs/2507.12862v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12862",
        "HTML": "https://arxiv.org/html/2507.12862v1",
        "PDF": "https://arxiv.org/pdf/2507.12862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using simulations to explore ethical implications of decisions and does not engage with LLMs or their training data processing. It focuses on ethical simulations rather than tasks related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12869",
      "abstract": "Person Re-Identification is a key and challenging task in video surveillance. While traditional methods rely on visual data, issues like poor lighting, occlusion, and suboptimal angles often hinder performance. To address these challenges, we introduce WhoFi, a novel pipeline that utilizes Wi-Fi signals for person re-identification. Biometric features are extracted from Channel State Information (CSI) and processed through a modular Deep Neural Network (DNN) featuring a Transformer-based encoder. The network is trained using an in-batch negative loss function to learn robust and generalizable biometric signatures. Experiments on the NTU-Fi dataset show that our approach achieves competitive results compared to state-of-the-art methods, confirming its effectiveness in identifying individuals via Wi-Fi signals.",
      "authors": [
        "Danilo Avola",
        "Daniele Pannone",
        "Dario Montagnini",
        "Emad Emam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:40:50+00:00",
          "link": "https://arxiv.org/abs/2507.12869v1",
          "size": "428kb",
          "version": "v1"
        }
      ],
      "title": "WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12869",
        "HTML": "https://arxiv.org/html/2507.12869v1",
        "PDF": "https://arxiv.org/pdf/2507.12869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on person re-identification using Wi-Fi signals, which does not relate to LLM training data processing, pretraining, or fine-tuning operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12870",
      "abstract": "A child's spoken ability continues to change until their adult age. Until 7-8yrs, their speech sound development and language structure evolve rapidly. This dynamic shift in their spoken communication skills and data privacy make it challenging to curate technology-ready speech corpora for children. This study aims to bridge this gap and provide researchers and practitioners with the best practices and considerations for developing such a corpus based on an intended goal. Although primarily focused on educational goals, applications of child speech data have spread across fields including clinical and forensics fields. Motivated by this goal, we describe the WHO, WHAT, WHEN, and WHERE of data collection inspired by prior collection efforts and our experience/knowledge. We also provide a guide to establish collaboration, trust, and for navigating the human subjects research protocol. This study concludes with guidelines for corpus quality check, triage, and annotation.",
      "authors": [
        "John Hansen",
        "Satwik Dutta",
        "Ellen Grand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computers and Society (cs.CY)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:44:04+00:00",
          "link": "https://arxiv.org/abs/2507.12870v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Best Practices and Considerations for Child Speech Corpus Collection and Curation in Educational, Clinical, and Forensic Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12870",
        "HTML": "https://arxiv.org/html/2507.12870v1",
        "PDF": "https://arxiv.org/pdf/2507.12870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses best practices for corpus collection and curation, it focuses on child speech data for educational, clinical, and forensic applications rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12871",
      "abstract": "Recently, there has been a surge of interest in Multi-Target Cross-Domain Recommendation (MTCDR), which aims to enhance recommendation performance across multiple domains simultaneously. Existing MTCDR methods primarily rely on domain-shared entities (\\eg users or items) to fuse and transfer cross-domain knowledge, which may be unavailable in non-overlapped recommendation scenarios. Some studies model user preferences and item features as domain-sharable semantic representations, which can be utilized to tackle the MTCDR task. Nevertheless, they often require extensive auxiliary data for pre-training. Developing more effective solutions for MTCDR remains an important area for further exploration.\n  Inspired by recent advancements in generative recommendation, this paper introduces GMC, a generative paradigm-based approach for multi-target cross-domain recommendation. The core idea of GMC is to leverage semantically quantized discrete item identifiers as a medium for integrating multi-domain knowledge within a unified generative model. GMC first employs an item tokenizer to generate domain-shared semantic identifiers for each item, and then formulates item recommendation as a next-token generation task by training a domain-unified sequence-to-sequence model. To further leverage the domain information to enhance performance, we incorporate a domain-aware contrastive loss into the semantic identifier learning, and perform domain-specific fine-tuning on the unified recommender. Extensive experiments on five public datasets demonstrate the effectiveness of GMC compared to a range of baseline methods.",
      "authors": [
        "Jinqiu Jin",
        "Yang Zhang",
        "Junwei Pan",
        "Fuli Feng",
        "Hua Lu",
        "Haijie Gu",
        "Xiangnan He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:44:05+00:00",
          "link": "https://arxiv.org/abs/2507.12871v1",
          "size": "839kb",
          "version": "v1"
        }
      ],
      "title": "Generative Multi-Target Cross-Domain Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12871",
        "HTML": "https://arxiv.org/html/2507.12871v1",
        "PDF": "https://arxiv.org/pdf/2507.12871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses cross-domain recommendation using a generative model, which involves recommendation system improvement rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12872",
      "abstract": "Frontier AI systems are rapidly advancing in their capabilities to persuade, deceive, and influence human behaviour, with current models already demonstrating human-level persuasion and strategic deception in specific contexts. Humans are often the weakest link in cybersecurity systems, and a misaligned AI system deployed internally within a frontier company may seek to undermine human oversight by manipulating employees. Despite this growing threat, manipulation attacks have received little attention, and no systematic framework exists for assessing and mitigating these risks. To address this, we provide a detailed explanation of why manipulation attacks are a significant threat and could lead to catastrophic outcomes. Additionally, we present a safety case framework for manipulation risk, structured around three core lines of argument: inability, control, and trustworthiness. For each argument, we specify evidence requirements, evaluation methodologies, and implementation considerations for direct application by AI companies. This paper provides the first systematic methodology for integrating manipulation risk into AI safety governance, offering AI companies a concrete foundation to assess and mitigate these threats before deployment.",
      "authors": [
        "Rishane Dassanayake",
        "Mario Demetroudi",
        "James Walpole",
        "Lindley Lentati",
        "Jason R. Brown",
        "Edward James Young"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:45:53+00:00",
          "link": "https://arxiv.org/abs/2507.12872v1",
          "size": "571kb",
          "version": "v1"
        }
      ],
      "title": "Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12872",
        "HTML": "https://arxiv.org/html/2507.12872v1",
        "PDF": "https://arxiv.org/pdf/2507.12872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with manipulation attacks and AI system safety, without addressing issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12873",
      "abstract": "This work explores the feasibility of biometric authentication using EEG signals acquired through in-ear devices, commonly referred to as ear-EEG. Traditional EEG-based biometric systems, while secure, often suffer from low usability due to cumbersome scalp-based electrode setups. In this study, we propose a novel and practical framework leveraging ear-EEG signals as a user-friendly alternative for everyday biometric authentication. The system extracts an original combination of temporal and spectral features from ear-EEG signals and feeds them into a fully connected deep neural network for subject identification. Experimental results on the only currently available ear-EEG dataset suitable for different purposes, including biometric authentication, demonstrate promising performance, with an average accuracy of 82\\% in a subject identification scenario. These findings confirm the potential of ear-EEG as a viable and deployable direction for next-generation real-world biometric systems.",
      "authors": [
        "Danilo Avola",
        "Giancarlo Crocetti",
        "Gian Luca Foresti",
        "Daniele Pannone",
        "Claudio Piciarelli",
        "Amedeo Ranaldi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:48:05+00:00",
          "link": "https://arxiv.org/abs/2507.12873v1",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "title": "An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12873",
        "HTML": "https://arxiv.org/html/2507.12873v1",
        "PDF": "https://arxiv.org/pdf/2507.12873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus of this study is on biometric authentication using ear-EEG signals, which is unrelated to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12874",
      "abstract": "This study explores novel activation functions that enhance the ability of neural networks to manipulate data topology during training. Building on the limitations of traditional activation functions like $\\mathrm{ReLU}$, we propose $\\mathrm{SmoothSplit}$ and $\\mathrm{ParametricSplit}$, which introduce topology \"cutting\" capabilities. These functions enable networks to transform complex data manifolds effectively, improving performance in scenarios with low-dimensional layers. Through experiments on synthetic and real-world datasets, we demonstrate that $\\mathrm{ParametricSplit}$ outperforms traditional activations in low-dimensional settings while maintaining competitive performance in higher-dimensional ones. Our findings highlight the potential of topology-aware activation functions in advancing neural network architectures. The code is available via https://github.com/Snopoff/Topology-Aware-Activations.",
      "authors": [
        "Pavel Snopov",
        "Oleg R. Musin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:48:36+00:00",
          "link": "https://arxiv.org/abs/2507.12874v1",
          "size": "6305kb",
          "version": "v1"
        }
      ],
      "title": "Topology-Aware Activation Functions in Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12874",
        "HTML": "https://arxiv.org/html/2507.12874v1",
        "PDF": "https://arxiv.org/pdf/2507.12874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses novel activation functions for neural networks, which are not related to training data processing for LLMs. The focus is on improving neural network architectures, not on data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12875",
      "abstract": "A $k$-submodular function naturally generalizes submodular functions by taking as input $k$ disjoint subsets, rather than a single subset. Unlike standard submodular maximization, which only requires selecting elements for the solution, $k$-submodular maximization adds the challenge of determining the subset to which each selected element belongs. Prior research has shown that the greedy algorithm is a 1/2-approximation for the monotone $k$-submodular maximization problem under cardinality or matroid constraints. However, whether a firm 1/2-approximation exists for the budgeted version (i.e., with a knapsack constraint) has remained open for several years. We resolve this question affirmatively by proving that the 1-Guess Greedy algorithm, which first guesses an appropriate element from an optimal solution before proceeding with the greedy algorithm, achieves a 1/2-approximation. This result is asymptotically tight as $((k+1)/(2k)+\\epsilon)$-approximation requires exponentially many value oracle queries even without constraints (Iwata et al., SODA 2016). We further show that 1-Guess Greedy is 1/3-approximation for the non-monotone problem. This algorithm is both simple and parallelizable, making it well-suited for practical applications. Using the thresholding technique from (Badanidiyuru and Vondrak, SODA 2014), it runs in nearly $\\tilde O(n^2k^2)$ time.\n  The proof idea is simple: we introduce a novel continuous transformation from an optimal solution to a greedy solution, using the multilinear extension to evaluate every fractional solution during the transformation. This continuous analysis approach yields two key extensions. First, it enables improved approximation ratios of various existing algorithms. Second, our method naturally extends to $k$-submodular maximization problems under broader constraints, offering a more flexible and unified analysis framework.",
      "authors": [
        "Chenhao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.12875v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "A 1/2-Approximation for Budgeted $k$-Submodular Maximization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12875",
        "HTML": "https://arxiv.org/html/2507.12875v1",
        "PDF": "https://arxiv.org/pdf/2507.12875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a 1/2-approximation for budgeted k-submodular maximization, which is a mathematical optimization approach. It does not address LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12879",
      "abstract": "This paper proposes a reinforcement learning-based method for microservice resource scheduling and optimization, aiming to address issues such as uneven resource allocation, high latency, and insufficient throughput in traditional microservice architectures. In microservice systems, as the number of services and the load increase, efficiently scheduling and allocating resources such as computing power, memory, and storage becomes a critical research challenge. To address this, the paper employs an intelligent scheduling algorithm based on reinforcement learning. Through the interaction between the agent and the environment, the resource allocation strategy is continuously optimized. In the experiments, the paper considers different resource conditions and load scenarios, evaluating the proposed method across multiple dimensions, including response time, throughput, resource utilization, and cost efficiency. The experimental results show that the reinforcement learning-based scheduling method significantly improves system response speed and throughput under low load and high concurrency conditions, while also optimizing resource utilization and reducing energy consumption. Under multi-dimensional resource conditions, the proposed method can consider multiple objectives and achieve optimized resource scheduling. Compared to traditional static resource allocation methods, the reinforcement learning model demonstrates stronger adaptability and optimization capability. It can adjust resource allocation strategies in real time, thereby maintaining good system performance in dynamically changing load and resource environments.",
      "authors": [
        "Yujun Zou",
        "Nia Qi",
        "Yingnan Deng",
        "Zhihao Xue",
        "Ming Gong",
        "Wuyang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:58:16+00:00",
          "link": "https://arxiv.org/abs/2507.12879v1",
          "size": "1011kb",
          "version": "v1"
        }
      ],
      "title": "Autonomous Resource Management in Microservice Systems via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12879",
        "PDF": "https://arxiv.org/pdf/2507.12879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a reinforcement learning approach for resource management in microservice systems. This is unrelated to LLM training data processing, focusing instead on system performance optimization."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12880",
      "abstract": "Information diffusion prediction (IDP) is a pivotal task for understanding how information propagates among users. Most existing methods commonly adhere to a conventional training-test paradigm, where models are pretrained on training data and then directly applied to test samples. However, the success of this paradigm hinges on the assumption that the data are independently and identically distributed, which often fails in practical social networks due to the inherent uncertainty and variability of user behavior. In the paper, we address the novel challenge of distribution shifts within IDP tasks and propose a robust test-time training (TTT)-based framework for multi-scale diffusion prediction, named T3MAL. The core idea is to flexibly adapt a trained model to accommodate the distribution of each test instance before making predictions via a self-supervised auxiliary task. Specifically, T3MAL introduces a BYOL-inspired self-supervised auxiliary network that shares a common feature extraction backbone with the primary diffusion prediction network to guide instance-specific adaptation during testing. Furthermore, T3MAL enables fast and accurate test-time adaptation by incorporating a novel meta-auxiliary learning scheme and a lightweight adaptor, which together provide better weight initialization for TTT and mitigate catastrophic forgetting. Extensive experiments on three public datasets demonstrate that T3MAL outperforms various state-of-the-art methods.",
      "authors": [
        "Wenting Zhu",
        "Chaozhuo Li",
        "Qingpo Yang",
        "Xi Zhang and Philip S. Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.12880v1",
          "size": "3156kb",
          "version": "v1"
        }
      ],
      "title": "T3MAL: Test-Time Fast Adaptation for Robust Multi-Scale Information Diffusion Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12880",
        "HTML": "https://arxiv.org/html/2507.12880v1",
        "PDF": "https://arxiv.org/pdf/2507.12880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for test-time adaptation in information diffusion prediction tasks, addressing distribution shifts. It does not contribute to LLM training data processing, data engineering, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12881",
      "abstract": "This letter investigates the robust beamforming design for a near-field secure integrated sensing and communication (ISAC) system with multiple communication users (CUs) and targets, as well as multiple eavesdroppers. Taking into account the channel uncertainty constraints, we maximize the minimum sensing beampattern gain for targets, subject to the minimum signal-to-interference-plus-noise ratio (SINR) constraint for each CU and the maximum SINR constraint for each eavesdropper, as well as the ISAC transmit power constraint. The formulated design problem is non-convex. As a low-complexity suboptimal solution, we first apply the S-Procedure to convert semi-infinite channel uncertainty constraints into linear matrix inequalities (LMIs) and then use the state-of-the-art sequential rank-one constraint relaxation (SROCR) method to address the rank-one constraints. The numerical results show that the proposed ISAC beamforming design scheme outperforms the existing semidefinite relaxation (SDR) and other baseline schemes, and it significantly enhances security and robustness for near-field ISAC systems.",
      "authors": [
        "Ziqiang CHen",
        "Feng Wang",
        "Guojun Han",
        "Xin Wang",
        "Vincent K. N. Lau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:01:08+00:00",
          "link": "https://arxiv.org/abs/2507.12881v1",
          "size": "5211kb",
          "version": "v1"
        }
      ],
      "title": "Robust Beamforming Design for Secure Near-Field ISAC Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12881",
        "HTML": "https://arxiv.org/html/2507.12881v1",
        "PDF": "https://arxiv.org/pdf/2507.12881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robust beamforming design for secure near-field integrated sensing and communication systems, which does not involve data processing for LLM pretraining or fine-tuning nor contribute to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12883",
      "abstract": "The reasoning segmentation task involves segmenting objects within an image by interpreting implicit user instructions, which may encompass subtleties such as contextual cues and open-world knowledge. Despite significant advancements made by existing approaches, they remain constrained by low perceptual resolution, as visual encoders are typically pre-trained at lower resolutions. Furthermore, simply interpolating the positional embeddings of visual encoders to enhance perceptual resolution yields only marginal performance improvements while incurring substantial computational costs. To address this, we propose HRSeg, an efficient model with high-resolution fine-grained perception. It features two key innovations: High-Resolution Perception (HRP) and High-Resolution Enhancement (HRE). The HRP module processes high-resolution images through cropping, integrating local and global features for multi-granularity quality. The HRE module enhances mask features by integrating fine-grained information from high-resolution images, refining their alignment with text features for precise segmentation. Extensive ablation studies validate the effectiveness of our modules, while comprehensive experiments on multiple benchmark datasets demonstrate HRSeg's superior performance.",
      "authors": [
        "Weihuang Lin",
        "Yiwei Ma",
        "Xiaoshuai Sun",
        "Shuting He",
        "Jiayi Ji",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:09:31+00:00",
          "link": "https://arxiv.org/abs/2507.12883v1",
          "size": "5598kb",
          "version": "v1"
        }
      ],
      "title": "HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12883",
        "HTML": "https://arxiv.org/html/2507.12883v1",
        "PDF": "https://arxiv.org/pdf/2507.12883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the reasoning segmentation task within computer vision, focusing on high-resolution visual perception and enhancement, with no mention of LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12884",
      "abstract": "We present NeckSense, a novel wearable system for head pose tracking that leverages multi-channel bio-impedance sensing with soft, dry electrodes embedded in a lightweight, necklace-style form factor. NeckSense captures dynamic changes in tissue impedance around the neck, which are modulated by head rotations and subtle muscle activations. To robustly estimate head pose, we propose a deep learning framework that integrates anatomical priors, including joint constraints and natural head rotation ranges, into the loss function design. We validate NeckSense on 7 participants using the current SOTA pose estimation model as ground truth. Our system achieves a mean per-vertex error of 25.9 mm across various head movements with a leave-one-person-out cross-validation method, demonstrating that a compact, line-of-sight-free bio-impedance wearable can deliver head-tracking performance comparable to SOTA vision-based methods.",
      "authors": [
        "Mengxi Liu",
        "Lala Shakti Swarup Ray",
        "Sizhen Bian",
        "Ko Watanabe",
        "Ankur Bhatt",
        "Joanna Sorysz",
        "Russel Torah",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:09:57+00:00",
          "link": "https://arxiv.org/abs/2507.12884v1",
          "size": "7601kb",
          "version": "v1"
        }
      ],
      "title": "From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12884",
        "HTML": "https://arxiv.org/html/2507.12884v1",
        "PDF": "https://arxiv.org/pdf/2507.12884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a wearable system for head pose tracking using bio-impedance sensing, unrelated to LLM training data processing, as it does not involve LLM pretraining or fine-tuning data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12885",
      "abstract": "Recent advances in reinforcement learning (RL) have led to substantial improvements in the mathematical reasoning abilities of large language models (LLMs), as measured by standard benchmarks. However, these gains often persist even when models are trained with flawed signals, such as random or inverted rewards, raising a fundamental question: do such improvements reflect true reasoning, or are they merely artifacts of overfitting to benchmark-specific patterns? To address this question, we take an evaluation-centric perspective and identify two critical shortcomings in existing protocols. First, \\emph{benchmark contamination} arises from the public availability of test problems, increasing the risk of data leakage. Second, \\emph{evaluation fragility} stems from the reliance on single-instance assessments, which are highly sensitive to stochastic outputs and fail to capture reasoning consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic evaluation framework designed to probe genuine reasoning ability. By converting fixed numerical problems into symbolic templates and requiring models to solve multiple instantiations of each, VAR-MATH enforces consistent reasoning across structurally equivalent variants, thereby mitigating contamination and improving evaluation robustness. We apply VAR-MATH to transform two popular benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and VAR-AIME24. Experimental results reveal substantial performance drops for RL-trained models on the variabilized versions, especially for smaller models, with average declines of 48.0\\% on AMC23 and 58.3\\% on AIME24. These findings suggest that many existing RL methods rely on superficial heuristics and fail to generalize beyond specific numerical forms. Overall, VAR-MATH offers a principled, contamination-resistant evaluation paradigm for mathematical reasoning.",
      "authors": [
        "Jian Yao",
        "Ran Cheng",
        "and Kay Chen Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:10:55+00:00",
          "link": "https://arxiv.org/abs/2507.12885v1",
          "size": "1708kb",
          "version": "v1"
        }
      ],
      "title": "VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12885",
        "HTML": "https://arxiv.org/html/2507.12885v1",
        "PDF": "https://arxiv.org/pdf/2507.12885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses evaluating mathematical reasoning in LLMs using symbolic benchmarks, focusing on evaluation methodology, not LLM training data processing operations like dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12889",
      "abstract": "Emotion recognition,as a step toward mind reading,seeks to infer internal states from external cues.Most existing methods rely on explicit signals-such as facial expressions,speech,or gestures-that reflect only bodily responses and overlook the influence of environmental context.These cues are often voluntary,easy to mask,and insufficient for capturing deeper,implicit emotions. Physiological signal-based approaches offer more direct access to internal states but require complex sensors that compromise natural behavior and limit scalability.Gaze-based methods typically rely on static fixation analysis and fail to capture the rich,dynamic interactions between gaze and the environment,and thus cannot uncover the deep connection between emotion and implicit behavior.To address these limitations,we propose a novel camera-based,user-unaware emotion recognition approach that integrates gaze fixation patterns with environmental semantics and temporal dynamics.Leveraging standard HD cameras,our method unobtrusively captures users'eye appearance and head movements in natural settings-without the need for specialized hardware or active user participation.From these visual cues,the system estimates gaze trajectories over time and space, providing the basis for modeling the spatial, semantic,and temporal dimensions of gaze behavior. This allows us to capture the dynamic interplay between visual attention and the surrounding environment,revealing that emotions are not merely physiological responses but complex outcomes of human-environment interactions.The proposed approach enables user-unaware,real-time,and continuous emotion recognition,offering high generalizability and low deployment cost.",
      "authors": [
        "Mengke Song",
        "Yuge Xie",
        "Qi Cui",
        "Luming Li",
        "Xinyu Liu",
        "Guotao Wang",
        "Chenglizhao Chen",
        "and Shanchen Pang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:17:35+00:00",
          "link": "https://arxiv.org/abs/2507.12889v1",
          "size": "16092kb",
          "version": "v1"
        }
      ],
      "title": "Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12889",
        "HTML": "https://arxiv.org/html/2507.12889v1",
        "PDF": "https://arxiv.org/pdf/2507.12889"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a camera-based emotion recognition approach focusing on human gaze analysis within environmental contexts, which does not relate to LLM training data processing or any associated data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12892",
      "abstract": "Load balancing between base stations (BSs) allows BS capacity to be efficiently utilised and avoid outages. Currently, data-driven mechanisms strive to balance inter-BS load and reduce unnecessary handovers. The challenge is that over a large number of BSs, networks observe an oscillatory effect of load evolution that causes high inter-BS messaging. Without a calculus function that integrates network topology to describe the evolution of load states, current data-driven algorithms cannot explain the oscillation phenomenon observed in load states, nor can they provide theoretical guarantees on the stability of the ideal synchronised state. Whilst we know load state oscillation is coupled with the load balancing process algorithms and the topology structure of inter-BS boundary relations, we do not have a theoretical framework to prove this and a pathway to improving load balancing algorithms. Here, we abstract generic and heterogeneous data-driven algorithms into a calculus dynamics space, so that we can establish the synchronization conditions for networked load balancing dynamics with any network topology. By incorporating what is known as \"non-conservative error\" and the eigenvalue spectrum of the networked dynamics, we can adjust the inter-BS load balancing mechanisms to achieve high efficiency and convergence guarantee, or to mitigate the oscillation when the synchronisation condition cannot be satisfied.",
      "authors": [
        "Mengbang Zou",
        "Yun Tang",
        "Adolfo Perrusqu\\'ia",
        "Weisi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:21:39+00:00",
          "link": "https://arxiv.org/abs/2507.12892v1",
          "size": "1445kb",
          "version": "v1"
        }
      ],
      "title": "Guaranteeing and Explaining Stability across Heterogeneous Load Balancing using Calculus Network Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12892",
        "HTML": "https://arxiv.org/html/2507.12892v1",
        "PDF": "https://arxiv.org/pdf/2507.12892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses load balancing in networks using calculus network dynamics, which is unrelated to LLM training data processing or improving data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12894",
      "abstract": "Lane detection is a critical component of Advanced Driver-Assistance Systems (ADAS) and Automated Driving System (ADS), providing essential spatial information for lateral control. However, domain shifts often undermine model reliability when deployed in new environments. Ensuring the robustness and safety of lane detection models typically requires collecting and annotating target domain data, which is resource-intensive. Estimating model performance without ground-truth labels offers a promising alternative for efficient robustness assessment, yet remains underexplored in lane detection. While previous work has addressed performance estimation in image classification, these methods are not directly applicable to lane detection tasks. This paper first adapts five well-performing performance estimation methods from image classification to lane detection, building a baseline. Addressing the limitations of prior approaches that solely rely on softmax scores or lane features, we further propose a new Lane Performance Estimation Framework (LanePerf), which integrates image and lane features using a pretrained image encoder and a DeepSets-based architecture, effectively handling zero-lane detection scenarios and large domain-shift cases. Extensive experiments on the OpenLane dataset, covering diverse domain shifts (scenes, weather, hours), demonstrate that our LanePerf outperforms all baselines, achieving a lower MAE of 0.117 and a higher Spearman's rank correlation coefficient of 0.727. These findings pave the way for robust, label-free performance estimation in ADAS, supporting more efficient testing and improved safety in challenging driving scenarios.",
      "authors": [
        "Yin Wu",
        "Daniel Slieter",
        "Ahmed Abouelazm",
        "Christian Hubschneider",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.12894v1",
          "size": "4139kb",
          "version": "v1"
        }
      ],
      "title": "LanePerf: a Performance Estimation Framework for Lane Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12894",
        "HTML": "https://arxiv.org/html/2507.12894v1",
        "PDF": "https://arxiv.org/pdf/2507.12894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on performance estimation for lane detection in ADAS, which involves robustness assessment without ground-truth labels and domain shifts. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12898",
      "abstract": "Bimanual robotic manipulation, which involves the coordinated control of two robotic arms, is foundational for solving challenging tasks. Despite recent progress in general-purpose manipulation, data scarcity and embodiment heterogeneity remain serious obstacles to further scaling up in bimanual settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning (VIDAR), a two-stage framework that leverages large-scale, diffusion-based video pre-training and a novel masked inverse dynamics model for action prediction. We pre-train the video diffusion model on 750K multi-view videos from three real-world bimanual robot platforms, utilizing a unified observation space that encodes robot, camera, task, and scene contexts. Our masked inverse dynamics model learns masks to extract action-relevant information from generated trajectories without requiring pixel-level labels, and the masks can effectively generalize to unseen backgrounds. Our experiments demonstrate that with only 20 minutes of human demonstrations on an unseen robot platform (only 1% of typical data requirements), VIDAR generalizes to unseen tasks and backgrounds with strong semantic understanding, surpassing state-of-the-art methods. Our findings highlight the potential of video foundation models, coupled with masked action prediction, to enable scalable and generalizable robotic manipulation in diverse real-world settings.",
      "authors": [
        "Yao Feng",
        "Hengkai Tan",
        "Xinyi Mao",
        "Guodong Liu",
        "Shuhe Huang",
        "Chendong Xiang",
        "Hang Su",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:31:55+00:00",
          "link": "https://arxiv.org/abs/2507.12898v1",
          "size": "19334kb",
          "version": "v1"
        }
      ],
      "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12898",
        "HTML": "https://arxiv.org/html/2507.12898v1",
        "PDF": "https://arxiv.org/pdf/2507.12898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for bimanual robotic manipulation using video diffusion models. It focuses on action prediction and generalizing to unseen tasks and settings, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12900",
      "abstract": "Machine Learning predictors are increasingly being employed in high-stakes applications such as credit scoring. Explanations help users unpack the reasons behind their predictions, but are not always \"high quality''. That is, end-users may have difficulty interpreting or believing them, which can complicate trust assessment and downstream decision-making. We argue that classifiers should have the option to refuse handling inputs whose predictions cannot be explained properly and introduce a framework for learning to reject low-quality explanations (LtX) in which predictors are equipped with a rejector that evaluates the quality of explanations. In this problem setting, the key challenges are how to properly define and assess explanation quality and how to design a suitable rejector. Focusing on popular attribution techniques, we introduce ULER (User-centric Low-quality Explanation Rejector), which learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality. Our experiments show that ULER outperforms both state-of-the-art and explanation-aware learning to reject strategies at LtX on eight classification and regression benchmarks and on a new human-annotated dataset, which we will publicly release to support future research.",
      "authors": [
        "Luca Stradiotti",
        "Dario Pesenti",
        "Stefano Teso",
        "Jesse Davis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:40:28+00:00",
          "link": "https://arxiv.org/abs/2507.12900v1",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Reject Low-Quality Explanations via User Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12900",
        "HTML": "https://arxiv.org/html/2507.12900v1",
        "PDF": "https://arxiv.org/pdf/2507.12900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for learning to reject low-quality explanations in machine learning models, with a focus on understanding and explaining predictions. This does not involve LLM training data processing or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12901",
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated remarkable general reasoning capabilities, holding significant potential for applications in the financial domain, a field that requires robust and reliable reasoning. It has been demonstrated that distilling high-quality chain-of-thought (CoT) rationales from advanced general reasoning models offers a promising and efficient path to the financial reasoning model. However, existing CoT synthesis methods suffer from shallow CoT sampling, leaving the question of how to construct a well-designed knowledge space for finance reasoning unexplored. In this paper, we present \\textbf{Agentar-DeepFinance-300K }, a large-scale financial reasoning dataset characterized by its systematic CoT synthesis optimization. We first introduce a comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge Extraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and deep financial reasoning trajectories. Furthermore, a systematic investigation, termed CoT Cube, is conducted to analyze critical factors that influence CoT effectiveness, such as necessity, length and synthesizer, yielding valuable insights for high-quality financial CoT construction. Experiments demonstrate that models trained on our Agentar-DeepFinance-300K achieve significant improvements on financial benchmarks. We publicly release Agentar-DeepFinance-300K , hoping to advance the research in financial reasoning models.",
      "authors": [
        "Xiaoke Zhao",
        "Zhaowen Zhou",
        "Lin Chen",
        "Lihong Wang",
        "Zhiyi Huang",
        "Kaiyuan Zheng",
        "Yanjun Zheng",
        "Xiyang Du",
        "Longfei Liao",
        "Jiawei Liu",
        "Xiang Qi",
        "Bo Zhang",
        "Peng Zhang",
        "Zhe Li",
        "Wei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.12901v1",
          "size": "776kb",
          "version": "v1"
        }
      ],
      "title": "Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12901",
        "HTML": "https://arxiv.org/html/2507.12901v1",
        "PDF": "https://arxiv.org/pdf/2507.12901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents Agentar-DeepFinance-300K, a large-scale financial reasoning dataset featuring a CoT synthesis pipeline to enhance data quality and reasoning capabilities. It involves systematic optimization and synthesis of reasoning data, providing a significant contribution to LLM training data processing, especially in the financial domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12903",
      "abstract": "Federated Learning is a collaborative machine learning paradigm that enables multiple clients to learn a global model without exposing their data to each other. Consequently, it provides a secure learning platform with privacy-preserving capabilities. This paper introduces a new dataset containing 23,326 images collected from eight different commercial sources and classified into 31 categories, similar to the Office-31 dataset. To the best of our knowledge, this is the first image classification dataset specifically designed for Federated Learning. We also propose two new Federated Learning algorithms, namely Fed-Cyclic and Fed-Star. In Fed-Cyclic, a client receives weights from its previous client, updates them through local training, and passes them to the next client, thus forming a cyclic topology. In Fed-Star, a client receives weights from all other clients, updates its local weights through pre-aggregation (to address statistical heterogeneity) and local training, and sends its updated local weights to all other clients, thus forming a star-like topology. Our experiments reveal that both algorithms perform better than existing baselines on our newly introduced dataset.",
      "authors": [
        "Shreyansh Jain",
        "Koteswar Rao Jerripothula"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:42:48+00:00",
          "link": "https://arxiv.org/abs/2507.12903v1",
          "size": "1126kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning for Commercial Image Sources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12903",
        "HTML": "https://arxiv.org/html/2507.12903v1",
        "PDF": "https://arxiv.org/pdf/2507.12903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an image classification dataset specifically designed for Federated Learning, mainly relevant to machine learning frameworks involving privacy-preserving data sharing and novel training algorithms. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12904",
      "abstract": "Transformers have revolutionized deep learning with applications in natural language processing, computer vision, and beyond. However, their computational demands make it challenging to deploy them on low-power edge devices. This paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA) architecture specifically designed to accelerate General Matrix Multiplication (GEMM) operations in transformer models tailored for the energy and resource constraints of edge applications. The proposed architecture integrates a 4 x 4 array of Processing Elements (PEs) for efficient parallel computation and dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE operations, reducing memory bandwidth demands and enhancing data reuse. A switchless mesh torus interconnect network further minimizes power and latency by enabling direct communication between PEs and MOBs, eliminating the need for centralized switching. Through its heterogeneous array design and efficient dataflow, this CGRA architecture addresses the unique computational needs of transformers, offering a scalable pathway to deploy sophisticated machine learning models on edge devices.",
      "authors": [
        "Rohit Prasad"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:43:14+00:00",
          "link": "https://arxiv.org/abs/2507.12904v1",
          "size": "384kb",
          "version": "v1"
        }
      ],
      "title": "An ultra-low-power CGRA for accelerating Transformers at the edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12904",
        "PDF": "https://arxiv.org/pdf/2507.12904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an ultra-low-power CGRA architecture for accelerating GEMM operations in transformers on edge devices, which is related to hardware and computational efficiency, not on training data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12905",
      "abstract": "Monocular 3D pose estimation is a promising, flexible alternative to costly motion capture systems for sports analysis. However, its practical application is hindered by two factors: a lack of realistic sports datasets and unclear reliability for sports tasks. To address these challenges, we introduce the AthleticsPose dataset, a new public dataset featuring ``real'' motions captured from 23 athletes performing various athletics events on an athletic field. Using this dataset, we trained a representative 3D pose estimation model and performed a comprehensive evaluation. Our results show that the model trained on AthleticsPose significantly outperforms a baseline model trained on an imitated sports motion dataset, reducing MPJPE by approximately 75 %. These results show the importance of training on authentic sports motion data, as models based on imitated motions do not effectively transfer to real-world motions. Further analysis reveals that estimation accuracy is sensitive to camera view and subject scale. In case studies of kinematic indicators, the model demonstrated the potential to capture individual differences in knee angles but struggled with higher-speed metrics, such as knee-drive velocity, due to prediction biases. This work provides the research community with a valuable dataset and clarifies the potential and practical limitations of using monocular 3D pose estimation for sports motion analysis. Our dataset, code, and checkpoints are available at https://github.com/SZucchini/AthleticsPose.",
      "authors": [
        "Tomohiro Suzuki",
        "Ryota Tanaka",
        "Calvin Yeung",
        "Keisuke Fujii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:43:23+00:00",
          "link": "https://arxiv.org/abs/2507.12905v1",
          "size": "3843kb",
          "version": "v1"
        }
      ],
      "title": "AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12905",
        "HTML": "https://arxiv.org/html/2507.12905v1",
        "PDF": "https://arxiv.org/pdf/2507.12905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the AthleticsPose dataset for monocular 3D pose estimation in sports, emphasizing the importance of authentic data. Although the dataset creation is relevant to training data, the main focus is on pose estimation models, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12908",
      "abstract": "Workload forecasting is pivotal in cloud service applications, such as auto-scaling and scheduling, with profound implications for operational efficiency. Although Transformer-based forecasting models have demonstrated remarkable success in general tasks, their computational efficiency often falls short of the stringent requirements in large-scale cloud environments. Given that most workload series exhibit complicated periodic patterns, addressing these challenges in the frequency domain offers substantial advantages. To this end, we propose Fremer, an efficient and effective deep forecasting model. Fremer fulfills three critical requirements: it demonstrates superior efficiency, outperforming most Transformer-based forecasting models; it achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in workload forecasting; and it exhibits robust performance for multi-period series. Furthermore, we collect and open-source four high-quality, open-source workload datasets derived from ByteDance's cloud services, encompassing workload data from thousands of computing instances. Extensive experiments on both our proprietary datasets and public benchmarks demonstrate that Fremer consistently outperforms baseline models, achieving average improvements of 5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while simultaneously reducing parameter scale and computational costs. Additionally, in a proactive auto-scaling test based on Kubernetes, Fremer improves average latency by 18.78% and reduces resource consumption by 2.35%, underscoring its practical efficacy in real-world applications.",
      "authors": [
        "Jiadong Chen",
        "Hengyu Ye",
        "Fuxin Jiang",
        "Xiao He",
        "Tieying Zhang",
        "Jianjun Chen",
        "Xiaofeng Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:51:28+00:00",
          "link": "https://arxiv.org/abs/2507.12908v1",
          "size": "2982kb",
          "version": "v1"
        }
      ],
      "title": "Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12908",
        "HTML": "https://arxiv.org/html/2507.12908v1",
        "PDF": "https://arxiv.org/pdf/2507.12908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes Fremer, a model for workload forecasting, and provides datasets for cloud services forecasting. It deals with time series data processing for cloud applications, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12910",
      "abstract": "The growing demand for low-latency computing in 6G is driving the use of UAV-based low-altitude mobile edge computing (MEC) systems. However, limited spectrum often leads to severe uplink interference among ground terminals (GTs). In this paper, we investigate a rate-splitting multiple access (RSMA)-enabled low-altitude MEC system, where a UAV-based edge server assists multiple GTs in concurrently offloading their tasks over a shared uplink. We formulate a joint optimization problem involving the UAV 3D trajectory, RSMA decoding order, task offloading decisions, and resource allocation, aiming to mitigate multi-user interference and maximize energy efficiency. Given the high dimensionality, non-convex nature, and dynamic characteristics of this optimization problem, we propose a generative AI-enhanced deep reinforcement learning (DRL) framework to solve it efficiently. Specifically, we embed a diffusion model into the actor network to generate high-quality action samples, improving exploration in hybrid action spaces and avoiding local optima. In addition, a priority-based RSMA decoding strategy is designed to facilitate efficient successive interference cancellation with low complexity. Simulation results demonstrate that the proposed method for low-altitude MEC systems outperforms baseline methods, and that integrating GDM with RSMA can achieve significantly improved energy efficiency performance.",
      "authors": [
        "Xudong Wang",
        "Hongyang Du",
        "Lei Feng",
        "Kaibin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:57:21+00:00",
          "link": "https://arxiv.org/abs/2507.12910v1",
          "size": "3178kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Efficient RSMA-enabled Low-altitude MEC Optimization Via Generative AI-enhanced Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12910",
        "HTML": "https://arxiv.org/html/2507.12910v1",
        "PDF": "https://arxiv.org/pdf/2507.12910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on energy-efficient optimization in UAV-based mobile edge computing systems using generative AI and deep reinforcement learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12911",
      "abstract": "Out-of-distribution (OOD) scenarios in autonomous driving refer to situations that deviate from the training domain, often leading to unexpected and potentially hazardous behavior from planners that lack prior exposure to such cases. Recently, Vision-Language Models (VLMs) have been introduced into autonomous driving research for their promising generalization capabilities in OOD settings. Early studies demonstrated that VLMs could recognize OOD scenarios and generate user-level decisions such as \"go straight\" or \"turn right.\" However, a new challenge has emerged due to the misalignment between the VLM's high-level decisions or visual reasoning expressed in language, and the low-level predicted trajectories interpreted as actions. In this paper, we propose LaViPlan, a framework that leverages Reinforcement Learning with Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics. This approach addresses the vision-language-action misalignment observed in existing VLMs fine-tuned via supervised learning, which can recognize driving scenarios but often produce context-unaware decisions. Experimental results demonstrate that our method improves situational awareness and decision-making under OOD conditions, highlighting its potential to mitigate the misalignment issue. This work introduces a promising post-training paradigm for VLM agents in the context of autonomous driving.",
      "authors": [
        "Hayeon Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.12911v1",
          "size": "5639kb",
          "version": "v1"
        }
      ],
      "title": "LaViPlan : Language-Guided Visual Path Planning with RLVR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12911",
        "HTML": "https://arxiv.org/html/2507.12911v1",
        "PDF": "https://arxiv.org/pdf/2507.12911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses autonomous driving scenarios and misalignment issues in vision-language models using reinforcement learning, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12913",
      "abstract": "Recent advancements in machine learning have emphasized the need for transparency in model predictions, particularly as interpretability diminishes when using increasingly complex architectures. In this paper, we propose leveraging prediction uncertainty as a complementary approach to classical explainability methods. Specifically, we distinguish between aleatoric (data-related) and epistemic (model-related) uncertainty to guide the selection of appropriate explanations. Epistemic uncertainty serves as a rejection criterion for unreliable explanations and, in itself, provides insight into insufficient training (a new form of explanation). Aleatoric uncertainty informs the choice between feature-importance explanations and counterfactual explanations. This leverages a framework of explainability methods driven by uncertainty quantification and disentanglement. Our experiments demonstrate the impact of this uncertainty-aware approach on the robustness and attainability of explanations in both traditional machine learning and deep learning scenarios.",
      "authors": [
        "Chenrui Zhu",
        "Louenas Bounia",
        "Vu Linh Nguyen",
        "S\\'ebastien Destercke",
        "Arthur Hoarau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:00:05+00:00",
          "link": "https://arxiv.org/abs/2507.12913v1",
          "size": "320kb",
          "version": "v1"
        }
      ],
      "title": "Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12913",
        "HTML": "https://arxiv.org/html/2507.12913v1",
        "PDF": "https://arxiv.org/pdf/2507.12913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores robust explanations through uncertainty decomposition in machine learning, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12916",
      "abstract": "Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend Large Language Models (LLMs) for tackling tasks of 3D scene understanding. Current methods rely heavily on 3D point clouds, but the 3D point cloud reconstruction of an indoor scene often results in information loss. Some textureless planes or repetitive patterns are prone to omission and manifest as voids within the reconstructed 3D point clouds. Besides, objects with complex structures tend to introduce distortion of details caused by misalignments between the captured images and the dense reconstructed point clouds. 2D multi-view images present visual consistency with 3D point clouds and provide more detailed representations of scene components, which can naturally compensate for these deficiencies. Based on these insights, we propose Argus, a novel 3D multimodal framework that leverages multi-view images for enhanced 3D scene understanding with LLMs. In general, Argus can be treated as a 3D Large Multimodal Foundation Model (3D-LMM) since it takes various modalities as input(text instructions, 2D multi-view images, and 3D point clouds) and expands the capability of LLMs to tackle 3D tasks. Argus involves fusing and integrating multi-view images and camera poses into view-as-scene features, which interact with the 3D features to create comprehensive and detailed 3D-aware scene embeddings. Our approach compensates for the information loss while reconstructing 3D point clouds and helps LLMs better understand the 3D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks.",
      "authors": [
        "Yifan Xu",
        "Chao Zhang",
        "Hanqi Jiang",
        "Xiaoyan Wang",
        "Ruifei Ma",
        "Yiwei Li",
        "Zihao Wu",
        "Zeju Li",
        "Xiangde Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:02:04+00:00",
          "link": "https://arxiv.org/abs/2507.12916v1",
          "size": "14805kb",
          "version": "v1"
        }
      ],
      "title": "Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12916",
        "HTML": "https://arxiv.org/html/2507.12916v1",
        "PDF": "https://arxiv.org/pdf/2507.12916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on improving 3D scene understanding using multimodal data, extending LLM capabilities in this regard, but it does not contribute to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12918",
      "abstract": "The dependency pair (DP) framework is one of the most powerful techniques for automatic termination and complexity analysis of term rewrite systems. While DPs were extended to prove almost-sure termination of probabilistic term rewrite systems (PTRSs), automatic complexity analysis for PTRSs is largely unexplored. We introduce the first DP framework for analyzing expected complexity and for proving positive or strong almost-sure termination (SAST) of innermost rewriting with PTRSs, i.e., finite expected runtime. We implemented our framework in the tool AProVE and demonstrate its power compared to existing techniques for proving SAST.",
      "authors": [
        "Jan-Christoph Kassing",
        "Leon Spitzer",
        "J\\\"urgen Giesl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.12918v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Dependency Pairs for Expected Innermost Runtime Complexity and Strong Almost-Sure Termination of Probabilistic Term Rewriting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12918",
        "HTML": "https://arxiv.org/html/2507.12918v1",
        "PDF": "https://arxiv.org/pdf/2507.12918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the dependency pair framework for termination and complexity analysis in probabilistic term rewriting systems, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12919",
      "abstract": "Architectural backdoors pose an under-examined but critical threat to deep neural networks, embedding malicious logic directly into a model's computational graph. Unlike traditional data poisoning or parameter manipulation, architectural backdoors evade standard mitigation techniques and persist even after clean retraining. This survey systematically consolidates research on architectural backdoors, spanning compiler-level manipulations, tainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging detection and defense strategies, including static graph inspection, dynamic fuzzing, and partial formal verification, and highlight their limitations against distributed or stealth triggers. Despite recent progress, scalable and practical defenses remain elusive. We conclude by outlining open challenges and proposing directions for strengthening supply-chain security, cryptographic model attestations, and next-generation benchmarks. This survey aims to guide future research toward comprehensive defenses against structural backdoor threats in deep learning systems.",
      "authors": [
        "Victoria Childress",
        "Josh Collyer and Jodie Knapp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.12919v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12919",
        "HTML": "https://arxiv.org/html/2507.12919v1",
        "PDF": "https://arxiv.org/pdf/2507.12919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on vulnerabilities and defenses against architectural backdoors in deep learning models, rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12920",
      "abstract": "Marker-based optical motion capture (MoCap) systems are widely used to provide ground truth (GT) trajectories for benchmarking SLAM algorithms. However, the accuracy of MoCap-based GT trajectories is mainly affected by two factors: spatiotemporal calibration errors between the MoCap system and the device under test (DUT), and inherent MoCap jitter. Consequently, existing benchmarks focus primarily on absolute translation error, as accurate assessment of rotation and inter-frame errors remains challenging, hindering thorough SLAM evaluation. This paper proposes MoCap2GT, a joint optimization approach that integrates MoCap data and inertial measurement unit (IMU) measurements from the DUT for generating high-precision GT trajectories. MoCap2GT includes a robust state initializer to ensure global convergence, introduces a higher-order B-spline pose parameterization on the SE(3) manifold with variable time offset to effectively model MoCap factors, and employs a degeneracy-aware measurement rejection strategy to enhance estimation accuracy. Experimental results demonstrate that MoCap2GT outperforms existing methods and significantly contributes to precise SLAM benchmarking. The source code is available at https://anonymous.4open.science/r/mocap2gt (temporarily hosted anonymously for double-blind review).",
      "authors": [
        "Zichao Shu",
        "Shitao Bei",
        "Jicheng Dai",
        "Lijun Li",
        "Zetao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:03:00+00:00",
          "link": "https://arxiv.org/abs/2507.12920v1",
          "size": "1540kb",
          "version": "v1"
        }
      ],
      "title": "MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12920",
        "HTML": "https://arxiv.org/html/2507.12920v1",
        "PDF": "https://arxiv.org/pdf/2507.12920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the MoCap2GT system for improving ground truth trajectory estimation for SLAM benchmarking, which is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12925",
      "abstract": "Breadth-first search (BFS) is known as a basic search strategy for learning graph properties. As the scales of graph databases have increased tremendously in recent years, large-scale graphs G are often disk-resident. Obtaining the BFS results of G in semi-external memory model is inevitable, because the in-memory BFS algorithm has to maintain the entire G in the main memory, and external BFS algorithms consume high computational costs. As a good trade-off between the internal and external memory models, semi-external memory model assumes that the main memory can at least reside a spanning tree of G. Nevertheless, the semi-external BFS problem is still an open issue due to its difficulty. Therefore, this paper presents a comprehensive study for processing BFS in semi-external memory model. After discussing the naive solutions based on the basic framework of semi-external graph algorithms, this paper presents an efficient algorithm, named EP-BFS, with a small minimum memory space requirement, which is an important factor for evaluating semi-external algorithms. Extensive experiments are conducted on both real and synthetic large-scale graphs, where graph WDC-2014 contains over 1.7 billion nodes, and graph eu-2015 has over 91 billion edges. Experimental results confirm that EP-BFS can achieve up to 10 times faster.",
      "authors": [
        "Xiaolong Wan and Xixian Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:07:34+00:00",
          "link": "https://arxiv.org/abs/2507.12925v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Semi-External Breadth-First Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12925",
        "HTML": "https://arxiv.org/html/2507.12925v1",
        "PDF": "https://arxiv.org/pdf/2507.12925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents an algorithm for efficient BFS in the semi-external memory model, with no focus on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12927",
      "abstract": "The general trace reconstruction problem seeks to recover an original sequence from its noisy copies independently corrupted by deletions, insertions, and substitutions. This problem arises in applications such as DNA data storage, a promising storage medium due to its high information density and longevity. However, errors introduced during DNA synthesis, storage, and sequencing require correction through algorithms and codes, with trace reconstruction often used as part of the data retrieval process. In this work, we propose TReconLM, which leverages language models trained on next-token prediction for trace reconstruction. We pretrain language models on synthetic data and fine-tune on real-world data to adapt to technology-specific error patterns. TReconLM outperforms state-of-the-art trace reconstruction algorithms, including prior deep learning approaches, recovering a substantially higher fraction of sequences without error.",
      "authors": [
        "Franziska Weindel",
        "Michael Girsch and Reinhard Heckel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:08:41+00:00",
          "link": "https://arxiv.org/abs/2507.12927v1",
          "size": "1246kb",
          "version": "v1"
        }
      ],
      "title": "Trace Reconstruction with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12927",
        "HTML": "https://arxiv.org/html/2507.12927v1",
        "PDF": "https://arxiv.org/pdf/2507.12927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The trace reconstruction method TReconLM utilizes LLMs for reconstructing sequences and includes fine-tuning on real-world data, briefly touching on training data processing, although it's primarily concerned with sequence reconstruction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12930",
      "abstract": "Decoder-only language models, such as GPT and LLaMA, generally decode on the last layer. Motivated by human's hierarchical thinking capability, we propose that a hierarchical decoder architecture could be built with different layers decoding texts simultaneously. Due to limited time and computationally resources, we choose to adapt a pretrained language model into this form of hierarchical decoder. Language heads of the last layer are copied to different selected intermediate layers, and fine-tuned with different task inputs. By thorough experiments, we validate that these selective intermediate layers could be adapted to speak meaningful and reasonable contents, and this paradigm of hierarchical decoder can obtain state-of-the-art performances on multiple tasks such as hierarchical text classification, classification-guided generation, and hierarchical text generation. This study suggests the possibility of a generalized hierarchical reasoner, pretraining from scratch.",
      "authors": [
        "Yihong Wang",
        "Zhonglin Jiang",
        "Ningyuan Xi",
        "Yue Zhao",
        "Qingqing Gu",
        "Xiyuan Chen",
        "Hao Wu",
        "Sheng Xu",
        "Hange Zhou",
        "Yong Chen",
        "Luo Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:09:53+00:00",
          "link": "https://arxiv.org/abs/2507.12930v1",
          "size": "359kb",
          "version": "v1"
        }
      ],
      "title": "Making Language Model a Hierarchical Classifier and Generator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12930",
        "HTML": "https://arxiv.org/html/2507.12930v1",
        "PDF": "https://arxiv.org/pdf/2507.12930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper adapts a pretrained LLM for hierarchical decoding, involving some fine-tuning which ties to data processing for fine-tuning, yet the main focus is on a novel architecture rather than data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12931",
      "abstract": "This paper introduces two novel modifications to the Differentiable Automatic Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy perspective. Standard policy gradient methods can suffer from instability and sample inefficiency, particularly in sparse reward settings. To address this, we first propose a method that incorporates a pre-trained, stable guiding policy ($\\piphi$) to provide off-policy experience, thereby regularizing the training of the target policy ($\\pion$). This approach improves training stability and convergence speed by adaptively adjusting the learning step size. Secondly, we extend this idea to re-utilize zero-reward samples, which are often discarded by dynamic sampling strategies like DAPO's. By treating these samples as a distinct batch guided by the expert policy, we further enhance sample efficiency. We provide a theoretical analysis for both methods, demonstrating that their objective functions converge to the optimal solution within the established theoretical framework of reinforcement learning. The proposed mixed-policy framework effectively balances exploration and exploitation, promising more stable and efficient policy optimization.",
      "authors": [
        "Hongze Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.12931v1",
          "size": "5kb",
          "version": "v1"
        }
      ],
      "title": "From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12931",
        "HTML": "https://arxiv.org/html/2507.12931v1",
        "PDF": "https://arxiv.org/pdf/2507.12931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the Differentiable Automatic Post-editing Optimization algorithm through policy gradient methods, which is unrelated to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12932",
      "abstract": "The rapid advancement of voice deepfake technologies has raised serious concerns about user audio privacy, as attackers increasingly exploit publicly available voice data to generate convincing fake audio for malicious purposes such as identity theft, financial fraud, and misinformation campaigns. While existing defense methods offer partial protection, they face critical limitations, including weak adaptability to unseen user data, poor scalability to long audio, rigid reliance on white-box knowledge, and high computational and temporal costs during the encryption process. To address these challenges and defend against personalized voice deepfake threats, we propose Enkidu, a novel user-oriented privacy-preserving framework that leverages universal frequential perturbations generated through black-box knowledge and few-shot training on a small amount of user data. These highly malleable frequency-domain noise patches enable real-time, lightweight protection with strong generalization across variable-length audio and robust resistance to voice deepfake attacks, all while preserving perceptual quality and speech intelligibility. Notably, Enkidu achieves over 50 to 200 times processing memory efficiency (as low as 0.004 gigabytes) and 3 to 7000 times runtime efficiency (real-time coefficient as low as 0.004) compared to six state-of-the-art countermeasures. Extensive experiments across six mainstream text-to-speech models and five cutting-edge automated speaker verification models demonstrate the effectiveness, transferability, and practicality of Enkidu in defending against both vanilla and adaptive voice deepfake attacks.",
      "authors": [
        "Zhou Feng",
        "Jiahao Chen",
        "Chunyi Zhou",
        "Yuwen Pu",
        "Qingming Li",
        "Tianyu Du",
        "and Shouling Ji"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:12:36+00:00",
          "link": "https://arxiv.org/abs/2507.12932v1",
          "size": "1494kb",
          "version": "v1"
        }
      ],
      "title": "Enkidu: Universal Frequential Perturbation for Real-Time Audio Privacy Protection against Voice Deepfakes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12932",
        "HTML": "https://arxiv.org/html/2507.12932v1",
        "PDF": "https://arxiv.org/pdf/2507.12932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses real-time audio privacy protection against voice deepfakes with a framework called Enkidu, which is not related to LLM training data processing or dataset creation, filtering, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12933",
      "abstract": "Diffusion models have achieved remarkable success in image generation but come with significant computational costs, posing challenges for deployment in resource-constrained environments. Recent post-training quantization (PTQ) methods have attempted to mitigate this issue by focusing on the iterative nature of diffusion models. However, these approaches often overlook outliers, leading to degraded performance at low bit-widths. In this paper, we propose a DMQ which combines Learned Equivalent Scaling (LES) and channel-wise Power-of-Two Scaling (PTS) to effectively address these challenges. Learned Equivalent Scaling optimizes channel-wise scaling factors to redistribute quantization difficulty between weights and activations, reducing overall quantization error. Recognizing that early denoising steps, despite having small quantization errors, crucially impact the final output due to error accumulation, we incorporate an adaptive timestep weighting scheme to prioritize these critical steps during learning. Furthermore, identifying that layers such as skip connections exhibit high inter-channel variance, we introduce channel-wise Power-of-Two Scaling for activations. To ensure robust selection of PTS factors even with small calibration set, we introduce a voting algorithm that enhances reliability. Extensive experiments demonstrate that our method significantly outperforms existing works, especially at low bit-widths such as W4A6 (4-bit weight, 6-bit activation) and W4A8, maintaining high image generation quality and model stability. The code is available at https://github.com/LeeDongYeun/dmq.",
      "authors": [
        "Dongyeun Lee",
        "Jiwan Hur",
        "Hyounguk Shon",
        "Jae Young Lee",
        "Junmo Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:15:29+00:00",
          "link": "https://arxiv.org/abs/2507.12933v1",
          "size": "7419kb",
          "version": "v1"
        }
      ],
      "title": "DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12933",
        "HTML": "https://arxiv.org/html/2507.12933v1",
        "PDF": "https://arxiv.org/pdf/2507.12933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantization techniques for diffusion models to improve computational efficiency, focusing on model optimization rather than LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12935",
      "abstract": "An increasing number of applications are exploiting sampling-based algorithms for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC) algorithms form the computational backbone of this emerging branch of machine learning. Unfortunately, the high computational cost limits their feasibility for large-scale problems and real-world applications, and the existing MCMC acceleration solutions are either limited in hardware flexibility or fail to maintain efficiency at the system level across a variety of end-to-end applications. This paper introduces \\textbf{MC$^2$A}, an algorithm-hardware co-design framework, enabling efficient and flexible optimization for MCMC acceleration. Firstly, \\textbf{MC$^2$A} analyzes the MCMC workload diversity through an extension of the processor performance roofline model with a 3rd dimension to derive the optimal balance between the compute, sampling and memory parameters. Secondly, \\textbf{MC$^2$A} proposes a parametrized hardware accelerator architecture with flexible and efficient support of MCMC kernels with a pipeline of ISA-programmable tree-structured processing units, reconfigurable samplers and a crossbar interconnect to support irregular access. Thirdly, the core of \\textbf{MC$^2$A} is powered by a novel Gumbel sampler that eliminates exponential and normalization operations. In the end-to-end case study, \\textbf{MC$^2$A} achieves an overall {$307.6\\times$, $1.4\\times$, $2.0\\times$, $84.2\\times$} speedup compared to the CPU, GPU, TPU and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC workloads, this work demonstrates and exploits the feasibility of general hardware acceleration to popularize MCMC-based solutions in diverse application domains.",
      "authors": [
        "Shirui Zhao",
        "Jun Yin",
        "Lingyun Yao",
        "Martin Andraud",
        "Wannes Meert",
        "Marian Verhelst"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:20:51+00:00",
          "link": "https://arxiv.org/abs/2507.12935v1",
          "size": "3279kb",
          "version": "v1"
        }
      ],
      "title": "MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12935",
        "HTML": "https://arxiv.org/html/2507.12935v1",
        "PDF": "https://arxiv.org/pdf/2507.12935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MC\u00b2A for efficient acceleration of Markov Chain Monte Carlo algorithms, focusing on hardware optimization and not addressing LLM training data processing or related dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12937",
      "abstract": "This paper presents a comprehensive analysis of T-Mobile's critical data breaches in 2021 and 2023, alongside a full-spectrum security audit targeting its systems, infrastructure, and publicly exposed endpoints. By combining case-based vulnerability assessments with active ethical hacking techniques--including Shodan reconnaissance, API misuse simulations, VNC brute-forcing, firmware reverse engineering, and web application scans--we uncover structural weaknesses persisting beyond the initial breach events. Building on these findings, we propose a multi-layered defensive strategy encompassing Zero Trust Architecture, granular role-based access control, network segmentation, firmware encryption using AES with integrity checks, and API rate limiting and token lifecycle control. Financial modelling demonstrates that a five-year investment yields less than 1.1% of expected breach losses, validating the cost-effectiveness of proactive security measures. Our work bridges post-incident forensic analysis with hands-on security evaluation, providing an actionable blueprint for large-scale telecoms seeking operational resilience, regulatory compliance, and cross-domain threat readiness.",
      "authors": [
        "Zhuohan Cui and Zikun Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:22:52+00:00",
          "link": "https://arxiv.org/abs/2507.12937v1",
          "size": "2011kb",
          "version": "v1"
        }
      ],
      "title": "Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12937",
        "HTML": "https://arxiv.org/html/2507.12937v1",
        "PDF": "https://arxiv.org/pdf/2507.12937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides analysis and countermeasures for enterprise security incidents, specifically the T-Mobile data breach, which is not related to LLM training data processing or dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12939",
      "abstract": "The use of satellite imagery combined with deep learning to support automatic landslide detection is becoming increasingly widespread. However, selecting an appropriate deep learning architecture to optimize performance while avoiding overfitting remains a critical challenge. To address these issues, we propose a deep-learning based framework for landslide detection from remote sensing image in this paper. The proposed framework presents an effective combination of the online an offline data augmentation to tackle the imbalanced data, a backbone EfficientNet\\_Large deep learning model for extracting robust embedding features, and a post-processing SVM classifier to balance and enhance the classification performance. The proposed model achieved an F1-score of 0.8938 on the public test set of the Zindi challenge.",
      "authors": [
        "Hieu Tang",
        "Truong Vo",
        "Dong Pham",
        "Toan Nguyen",
        "Lam Pham",
        "Truong Nguyen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:25:43+00:00",
          "link": "https://arxiv.org/abs/2507.12939v1",
          "size": "4545kb",
          "version": "v1"
        }
      ],
      "title": "A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12939",
        "HTML": "https://arxiv.org/html/2507.12939v1",
        "PDF": "https://arxiv.org/pdf/2507.12939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a deep-learning framework for landslide detection from remote sensing images, focusing on architecture selection and performance optimization, which do not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12941",
      "abstract": "Partial differential equations (PDEs) with low-regularity solutions pose significant challenges for traditional numerical methods, particularly in complex geometries where mesh generation and adaptive refinement become computationally expensive. While deep-learning-based approaches, such as Physics-Informed Neural Networks (PINNs) and the Random Feature Method (RFM), offer mesh-free alternatives, they often lack adaptive resolution in critical regions, limiting their accuracy for solutions with steep gradients or singularities. In this work, we propose the Adaptive Feature Capture Method (AFCM), a novel machine learning framework that adaptively redistributes neurons and collocation points in high-gradient regions to enhance local expressive power. Inspired by adaptive moving mesh techniques, AFCM employs the gradient norm of an approximate solution as a monitor function to guide the reinitialization of feature function parameters. This ensures that partition hyperplanes and collocation points cluster where they are most needed, achieving higher resolution without increasing computational overhead. The AFCM extends the capabilities of RFM to handle PDEs with near-singular solutions while preserving its mesh-free efficiency. Numerical experiments demonstrate the method's effectiveness in accurately resolving low-regularity problems, even in complex geometries. By bridging the gap between adaptive mesh refinement and randomized neural networks, AFCM offers a robust and scalable approach for solving challenging PDEs in scientific and engineering applications.",
      "authors": [
        "Yangtao Deng",
        "Qiaolin He",
        "Xiaoping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:29:22+00:00",
          "link": "https://arxiv.org/abs/2507.12941v1",
          "size": "8810kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive feature capture method for solving partial differential equations with low regularity solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12941",
        "HTML": "https://arxiv.org/html/2507.12941v1",
        "PDF": "https://arxiv.org/pdf/2507.12941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a novel method for solving partial differential equations with low regularity solutions using machine learning. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12942",
      "abstract": "To reduce the reliance of visible-infrared person re-identification (ReID) models on labeled cross-modal samples, this paper explores a weakly supervised cross-modal person ReID method that uses only single-modal sample identity labels, addressing scenarios where cross-modal identity labels are unavailable. To mitigate the impact of missing cross-modal labels on model performance, we propose a heterogeneous expert collaborative consistency learning framework, designed to establish robust cross-modal identity correspondences in a weakly supervised manner. This framework leverages labeled data from each modality to independently train dedicated classification experts. To associate cross-modal samples, these classification experts act as heterogeneous predictors, predicting the identities of samples from the other modality. To improve prediction accuracy, we design a cross-modal relationship fusion mechanism that effectively integrates predictions from different experts. Under the implicit supervision provided by cross-modal identity correspondences, collaborative and consistent learning among the experts is encouraged, significantly enhancing the model's ability to extract modality-invariant features and improve cross-modal identity recognition. Experimental results on two challenging datasets validate the effectiveness of the proposed method.",
      "authors": [
        "Yafei Zhang",
        "Lingqi Kong",
        "Huafeng Li",
        "Jie Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:31:34+00:00",
          "link": "https://arxiv.org/abs/2507.12942v1",
          "size": "2929kb",
          "version": "v1"
        }
      ],
      "title": "Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12942",
        "HTML": "https://arxiv.org/html/2507.12942v1",
        "PDF": "https://arxiv.org/pdf/2507.12942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores a weakly supervised method for person re-identification, primarily concerned with modality-invariant feature extraction, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12945",
      "abstract": "Multimodal large language models (MLLMs) can process and integrate information from multimodality sources, such as text and images. However, interrelationship among input modalities, uncertainties due to individual uni-modal data and potential clinical applications following such an uncertainty decomposition are yet fully understood in the context of large-scale MLLMs. In this work, we propose a multimodal uncertainty propagation model (MUPM) based on uncertainty propagation, to characterise the relationship among the uncertainties arising from image-only, text-only, and joint image-text variations in MLLM inputs. Using real clinical data consisting of cardiac MR scans and digital health records, we describe that MUPMs can be optimised robustly with a few samples. We then show that the fitted MUPMs are generalisable across different input data distributions and, perhaps surprisingly, across different downstream tasks. Such a transferability may be explained by the shared pretraining, comparatively light MLLM fine-tuning, along with the low-dimensional nature of the MUPMs. More importantly, this learned transferability, quantifying the relationship between these uncertainties, led to direct clinical applications in which uncertainties may be estimated and thus analysed robustly for varying data or even a novel set of cardiac disease prediction tasks. In addition, we show experimentally the efficiency in multimodal data required for estimating the overall uncertainty and its ability to identify redundant factors, both of which are considered practical yet clinically useful applications with the proposed MUPMs. Codes are available at https://github.com/yucheng722/MUPM.",
      "authors": [
        "Yucheng Tang",
        "Yunguan Fu",
        "Weixi Yi",
        "Yipei Wang",
        "Daniel C. Alexander",
        "Rhodri Davies",
        "and Yipeng Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:34:21+00:00",
          "link": "https://arxiv.org/abs/2507.12945v1",
          "size": "975kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12945",
        "HTML": "https://arxiv.org/html/2507.12945v1",
        "PDF": "https://arxiv.org/pdf/2507.12945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates uncertainty propagation in multimodal large language models with a focus on clinical applications, but it does not relate to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12948",
      "abstract": "In reasoning chains generated by large language models (LLMs), initial errors often propagate and undermine the reliability of the final conclusion. Current LLM-based error detection methods often fail to detect propagated errors because they do not properly account for how earlier errors might corrupt judgments of downstream reasoning. To better detect such propagated errors, we introduce Autoregressive Reasoning Entailment Stability (ARES), a novel probabilistic framework that prevents error propagation by judging each claim based only on previously-assessed sound premises. This inductive method yields a nuanced score for each step and provides certified statistical guarantees of its soundness, rather than a brittle binary label. ARES achieves state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2 points) and demonstrates superior robustness on very long synthetic reasoning chains, where it excels at detecting propagated errors (90.3% F1, +27.6 points).",
      "authors": [
        "Weiqiu You",
        "Anton Xue",
        "Shreya Havaldar",
        "Delip Rao",
        "Helen Jin",
        "Chris Callison-Burch",
        "Eric Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:40:56+00:00",
          "link": "https://arxiv.org/abs/2507.12948v1",
          "size": "1570kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Soundness Guarantees in LLM Reasoning Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12948",
        "HTML": "https://arxiv.org/html/2507.12948v1",
        "PDF": "https://arxiv.org/pdf/2507.12948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving error detection in reasoning chains generated by large language models using probabilistic frameworks. It does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12950",
      "abstract": "Interpretability can improve the safety, transparency and trust of AI models, which is especially important in healthcare applications where decisions often carry significant consequences. Mechanistic interpretability, particularly through the use of sparse autoencoders (SAEs), offers a promising approach for uncovering human-interpretable features within large transformer-based models. In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal large language model, MAIRA-2, to interpret its internal representations. Using large-scale automated interpretability of the SAE features, we identify a range of clinically relevant concepts - including medical devices (e.g., line and tube placements, pacemaker presence), pathologies such as pleural effusion and cardiomegaly, longitudinal changes and textual features. We further examine the influence of these features on model behaviour through steering, demonstrating directional control over generations with mixed success. Our results reveal practical and methodological challenges, yet they offer initial insights into the internal concepts learned by MAIRA-2 - marking a step toward deeper mechanistic understanding and interpretability of a radiology-adapted multimodal large language model, and paving the way for improved model transparency. We release the trained SAEs and interpretations: https://huggingface.co/microsoft/maira-2-sae.",
      "authors": [
        "Kenza Bouzid",
        "Shruthi Bannur",
        "Daniel Coelho de Castro",
        "Anton Schwaighofer",
        "Javier Alvarez-Valle",
        "Stephanie L. Hyland"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:43:20+00:00",
          "link": "https://arxiv.org/abs/2507.12950v1",
          "size": "878kb",
          "version": "v1"
        }
      ],
      "title": "Insights into a radiology-specialised multimodal large language model with sparse autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12950",
        "PDF": "https://arxiv.org/pdf/2507.12950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores interpretability in radiology-specialized multimodal LLMs using sparse autoencoders, not focusing on LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12952",
      "abstract": "Despite recent advances in diffusion transformers (DiTs) for text-to-video generation, scaling to long-duration content remains challenging due to the quadratic complexity of self-attention. While prior efforts -- such as sparse attention and temporally autoregressive models -- offer partial relief, they often compromise temporal coherence or scalability. We introduce LoViC, a DiT-based framework trained on million-scale open-domain videos, designed to produce long, coherent videos through a segment-wise generation process. At the core of our approach is FlexFormer, an expressive autoencoder that jointly compresses video and text into unified latent representations. It supports variable-length inputs with linearly adjustable compression rates, enabled by a single query token design based on the Q-Former architecture. Additionally, by encoding temporal context through position-aware mechanisms, our model seamlessly supports prediction, retradiction, interpolation, and multi-shot generation within a unified paradigm. Extensive experiments across diverse tasks validate the effectiveness and versatility of our approach.",
      "authors": [
        "Jiaxiu Jiang",
        "Wenbo Li",
        "Jingjing Ren",
        "Yuping Qiu",
        "Yong Guo",
        "Xiaogang Xu",
        "Han Wu",
        "Wangmeng Zuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:46:43+00:00",
          "link": "https://arxiv.org/abs/2507.12952v1",
          "size": "14131kb",
          "version": "v1"
        }
      ],
      "title": "LoViC: Efficient Long Video Generation with Context Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12952",
        "HTML": "https://arxiv.org/html/2507.12952v1",
        "PDF": "https://arxiv.org/pdf/2507.12952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces LoViC for efficient long video generation, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12953",
      "abstract": "Regularization is essential in deformable image registration (DIR) to ensure that the estimated Deformation Vector Field (DVF) remains smooth, physically plausible, and anatomically consistent. However, fine-tuning regularization parameters in learning-based DIR frameworks is computationally expensive, often requiring multiple training iterations. To address this, we propose cIDI, a novel DIR framework based on Implicit Neural Representations (INRs) that conditions the registration process on regularization hyperparameters. Unlike conventional methods that require retraining for each regularization hyperparameter setting, cIDIR is trained over a prior distribution of these hyperparameters, then optimized over the regularization hyperparameters by using the segmentations masks as an observation. Additionally, cIDIR models a continuous and differentiable DVF, enabling seamless integration of advanced regularization techniques via automatic differentiation. Evaluated on the DIR-LAB dataset, $\\operatorname{cIDIR}$ achieves high accuracy and robustness across the dataset.",
      "authors": [
        "Sidaty El Hadramy",
        "Oumeymah Cherkaoui",
        "Philippe C. Cattin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:48:53+00:00",
          "link": "https://arxiv.org/abs/2507.12953v1",
          "size": "185kb",
          "version": "v1"
        }
      ],
      "title": "cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12953",
        "HTML": "https://arxiv.org/html/2507.12953v1",
        "PDF": "https://arxiv.org/pdf/2507.12953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for regularized deformable image registration using implicit neural representations, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12956",
      "abstract": "Producing expressive facial animations from static images is a challenging task. Prior methods relying on explicit geometric priors (e.g., facial landmarks or 3DMM) often suffer from artifacts in cross reenactment and struggle to capture subtle emotions. Furthermore, existing approaches lack support for multi-character animation, as driving features from different individuals frequently interfere with one another, complicating the task. To address these challenges, we propose FantasyPortrait, a diffusion transformer based framework capable of generating high-fidelity and emotion-rich animations for both single- and multi-character scenarios. Our method introduces an expression-augmented learning strategy that utilizes implicit representations to capture identity-agnostic facial dynamics, enhancing the model's ability to render fine-grained emotions. For multi-character control, we design a masked cross-attention mechanism that ensures independent yet coordinated expression generation, effectively preventing feature interference. To advance research in this area, we propose the Multi-Expr dataset and ExprBench, which are specifically designed datasets and benchmarks for training and evaluating multi-character portrait animations. Extensive experiments demonstrate that FantasyPortrait significantly outperforms state-of-the-art methods in both quantitative metrics and qualitative evaluations, excelling particularly in challenging cross reenactment and multi-character contexts. Our project page is https://fantasy-amap.github.io/fantasy-portrait/.",
      "authors": [
        "Qiang Wang",
        "Mengchao Wang",
        "Fan Jiang",
        "Yaqi Fan",
        "Yonggang Qi",
        "Mu Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:50:43+00:00",
          "link": "https://arxiv.org/abs/2507.12956v1",
          "size": "20796kb",
          "version": "v1"
        }
      ],
      "title": "FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12956",
        "HTML": "https://arxiv.org/html/2507.12956v1",
        "PDF": "https://arxiv.org/pdf/2507.12956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on facial animation using diffusion transformers and introduces a new dataset for portrait animations, rather than contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12957",
      "abstract": "Emerging technologies challenge conventional governance approaches, especially when uncertainty is not a temporary obstacle but a foundational feature as in quantum computing. This paper reframes uncertainty from a governance liability to a generative force, using the paradigms of quantum mechanics to propose adaptive, probabilistic frameworks for responsible innovation. We identify three interdependent layers of uncertainty--physical, technical, and societal--central to the evolution of quantum technologies. The proposed Quantum Risk Simulator (QRS) serves as a conceptual example, an imaginative blueprint rather than a prescriptive tool, meant to illustrate how probabilistic reasoning could guide dynamic, uncertainty-based governance. By foregrounding epistemic and ontological ambiguity, and drawing analogies from cognitive neuroscience and predictive processing, we suggest a new model of governance aligned with the probabilistic essence of quantum systems. This model, we argue, is especially promising for the European Union as a third way between laissez-faire innovation and state-led control, offering a flexible yet responsible pathway for regulating quantum and other frontier technologies.",
      "authors": [
        "Miriam Meckel",
        "Philipp Hacker",
        "Lea Steinacker",
        "Aurelija Lukoseviciene",
        "Surjo R. Soekadar",
        "Jacob Slosser",
        "Gina-Maria Poehlmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.12957v1",
          "size": "597kb",
          "version": "v1"
        }
      ],
      "title": "The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12957",
        "PDF": "https://arxiv.org/pdf/2507.12957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses governance frameworks for technologies like quantum computing, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12963",
      "abstract": "Reservoir computing has been successfully applied to graphs as a preprocessing method to improve the training efficiency of Graph Neural Networks (GNNs). However, a common issue that arises when repeatedly applying layer operators on graphs is over-smoothing, which consists in the convergence of graph signals toward low-frequency components of the graph Laplacian. This work revisits the definition of the reservoir in the Multiresolution Reservoir Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a variant based on a Fairing algorithm originally introduced in the field of surface design in computer graphics. This algorithm provides a pass-band spectral filter that allows smoothing without shrinkage, and it can be adapted to the graph setting through the Laplacian operator. Given its spectral formulation, this method naturally connects to GNN architectures for tasks where smoothing, when properly controlled, can be beneficial,such as graph classification. The core contribution of the paper lies in the theoretical analysis of the algorithm from a random walks perspective. In particular, it shows how tuning the spectral coefficients can be interpreted as modulating the contribution of redundant random walks. Exploratory experiments based on the MRGNN architecture illustrate the potential of this approach and suggest promising directions for future research.",
      "authors": [
        "Anna Bison and Alessandro Sperduti"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.12963v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "A Spectral Interpretation of Redundancy in a Graph Reservoir",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12963",
        "HTML": "https://arxiv.org/html/2507.12963v1",
        "PDF": "https://arxiv.org/pdf/2507.12963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on spectral redundancy in graph reservoirs for GNNs, without addressing LLM training data processing or dataset contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12964",
      "abstract": "Wrist pathologies are frequently observed, particularly among children who constitute the majority of fracture cases. However, diagnosing these conditions is time-consuming and requires specialized expertise. Computer vision presents a promising avenue, contingent upon the availability of extensive datasets, a notable challenge in medical imaging. Therefore, reliance solely on one modality, such as images, proves inadequate, especially in an era of diverse and plentiful data types. In this study, we employ a multifaceted approach to address the challenge of recognizing wrist pathologies using an extremely limited dataset. Initially, we approach the problem as a fine-grained recognition task, aiming to identify subtle X-ray pathologies that conventional CNNs overlook. Secondly, we enhance network performance by fusing patient metadata with X-ray images. Thirdly, rather than pre-training on a coarse-grained dataset like ImageNet, we utilize weights trained on a fine-grained dataset. While metadata integration has been used in other medical domains, this is a novel application for wrist pathologies. Our results show that a fine-grained strategy and metadata integration improve diagnostic accuracy by 2% with a limited dataset and by over 10% with a larger fracture-focused dataset.",
      "authors": [
        "Ammar Ahmed",
        "Ali Shariq Imran",
        "Zenun Kastrati",
        "Sher Muhammad Daudpota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:03:57+00:00",
          "link": "https://arxiv.org/abs/2507.12964v1",
          "size": "653kb",
          "version": "v1"
        }
      ],
      "title": "Demographic-aware fine-grained classification of pediatric wrist fractures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12964",
        "HTML": "https://arxiv.org/html/2507.12964v1",
        "PDF": "https://arxiv.org/pdf/2507.12964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study applies a multifaceted approach to medical imaging analysis, focusing on pediatric wrist fractures, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12967",
      "abstract": "Spectral reconstruction (SR) is a crucial problem in image processing that requires reconstructing hyperspectral images (HSIs) from the corresponding RGB images. A key difficulty in SR is estimating the unobservable feature, which encapsulates significant spectral information not captured by RGB imaging sensors. The solution lies in effectively constructing the spectral-spatial joint distribution conditioned on the RGB image to complement the unobservable feature. Since HSIs share a similar spatial structure with the corresponding RGB images, it is rational to capitalize on the rich spatial knowledge in RGB pre-trained models for spectral-spatial joint distribution learning. To this end, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to an unobservable feature LDM (ULDM) for SR. As the RGB-LDM and its corresponding spatial autoencoder (SpaAE) already excel in spatial knowledge, the ULDM can focus on modeling spectral structure. Moreover, separating the unobservable feature from the HSI reduces the redundant spectral information and empowers the ULDM to learn the joint distribution in a compact latent space. Specifically, we propose a two-stage pipeline consisting of spectral structure representation learning and spectral-spatial joint distribution learning to transform the RGB-LDM into the ULDM. In the first stage, a spectral unobservable feature autoencoder (SpeUAE) is trained to extract and compress the unobservable feature into a 3D manifold aligned with RGB space. In the second stage, the spectral and spatial structures are sequentially encoded by the SpeUAE and the SpaAE, respectively. The ULDM is then acquired to model the distribution of the coded unobservable feature with guidance from the corresponding RGB images. Experimental results on SR and downstream relighting tasks demonstrate that our proposed method achieves state-of-the-art performance.",
      "authors": [
        "Keli Deng",
        "Jie Nie",
        "and Yuntao Qian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:07:32+00:00",
          "link": "https://arxiv.org/abs/2507.12967v1",
          "size": "13686kb",
          "version": "v1"
        }
      ],
      "title": "RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12967",
        "HTML": "https://arxiv.org/html/2507.12967v1",
        "PDF": "https://arxiv.org/pdf/2507.12967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with RGB pre-training for spectral reconstruction, which is unrelated to LLM training data processing. It focuses on image processing tasks rather than text data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12969",
      "abstract": "This paper presents a novel deep learning-based framework for infrastructure health monitoring using drive-by vibration response signals. Recognizing the importance of spectral and temporal information, we introduce the WaveletInception-BiLSTM network. The WaveletInception feature extractor utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting vibration signal features, incorporating spectral information in the early network layers. This is followed by 1D Inception networks that extract multi-scale, high-level features at deeper layers. The extracted vibration signal features are then integrated with operational conditions via a Long Short-term Memory (LSTM) layer. The resulting feature extraction network effectively analyzes drive-by vibration signals across various measurement speeds without preprocessing and uses LSTM to capture interrelated temporal dependencies among different modes of information and to create feature vectors for health condition estimation. The estimator head is designed with a sequential modeling architecture using bidirectional LSTM (BiLSTM) networks, capturing bi-directional temporal relationships from drive-by measurements. This architecture allows for a high-resolution, beam-level assessment of infrastructure health conditions. A case study focusing on railway track stiffness estimation with simulated drive-by vibration signals shows that the model significantly outperforms state-of-the-art methods in estimating railway ballast and railpad stiffness parameters. Results underscore the potential of this approach for accurate, localized, and fully automated drive-by infrastructure health monitoring.",
      "authors": [
        "Reza Riahi Samani",
        "Alfredo Nunez",
        "Bart De Schutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.12969v1",
          "size": "6577kb",
          "version": "v1"
        }
      ],
      "title": "WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12969",
        "HTML": "https://arxiv.org/html/2507.12969v1",
        "PDF": "https://arxiv.org/pdf/2507.12969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for infrastructure health monitoring using drive-by vibration signals. It does not pertain to LLM training data processing in any way."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12975",
      "abstract": "We consider the cyber-physical security of parallel server systems, which is relevant for a variety of engineering applications such as networking, manufacturing, and transportation. These systems rely on feedback control and may thus be vulnerable to malicious attacks such as denial-of-service, data falsification, and instruction manipulations. In this paper, we develop a learning algorithm that computes a defensive strategy to balance technological cost for defensive actions and performance degradation due to cyber attacks as mentioned above. We consider a zero-sum Markov security game. We develop an approximate minimax-Q learning algorithm that efficiently computes the equilibrium of the game, and thus a cost-aware defensive strategy. The algorithm uses interpretable linear function approximation tailored to the system structure. We show that, under mild assumptions, the algorithm converges with probability one to an approximate Markov perfect equilibrium. We first use a Lyapunov method to address the unbounded temporal-difference error due to the unbounded state space. We then use an ordinary differential equation-based argument to establish convergence. Simulation results demonstrate that our algorithm converges about 50 times faster than a representative neural network-based method, with an insignificant optimality gap between 4\\%--8\\%, depending on the complexity of the linear approximator and the number of parallel servers.",
      "authors": [
        "Yuzhen Zhan and Li Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:23:50+00:00",
          "link": "https://arxiv.org/abs/2507.12975v1",
          "size": "3128kb",
          "version": "v1"
        }
      ],
      "title": "Learning-Based Cost-Aware Defense of Parallel Server Systems against Malicious Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12975",
        "HTML": "https://arxiv.org/html/2507.12975v1",
        "PDF": "https://arxiv.org/pdf/2507.12975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a learning-based defensive strategy for cyber-physical systems against malicious attacks. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12977",
      "abstract": "Safe and effective motion planning is crucial for autonomous robots. Diffusion models excel at capturing complex agent interactions, a fundamental aspect of decision-making in dynamic environments. Recent studies have successfully applied diffusion models to motion planning, demonstrating their competence in handling complex scenarios and accurately predicting multi-modal future trajectories. Despite their effectiveness, diffusion models have limitations in training objectives, as they approximate data distributions rather than explicitly capturing the underlying decision-making dynamics. However, the crux of motion planning lies in non-differentiable downstream objectives, such as safety (collision avoidance) and effectiveness (goal-reaching), which conventional learning algorithms cannot directly optimize. In this paper, we propose a reinforcement learning-based training scheme for diffusion motion planning models, enabling them to effectively learn non-differentiable objectives that explicitly measure safety and effectiveness. Specifically, we introduce a reward-weighted dynamic thresholding algorithm to shape a dense reward signal, facilitating more effective training and outperforming models trained with differentiable objectives. State-of-the-art performance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various baselines demonstrates the versatility of our approach for safe and effective motion planning.",
      "authors": [
        "Giwon Lee",
        "Daehee Park",
        "Jaewoo Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:26:06+00:00",
          "link": "https://arxiv.org/abs/2507.12977v1",
          "size": "1880kb",
          "version": "v1"
        }
      ],
      "title": "Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12977",
        "HTML": "https://arxiv.org/html/2507.12977v1",
        "PDF": "https://arxiv.org/pdf/2507.12977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion planning using diffusion models and reinforcement learning, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12979",
      "abstract": "Federated Learning has gained increasing attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing their raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables the utilization of distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experimental results shows that our approach demonstrates consistent and significant improvements across key performance metrics, where it achieves 1.1x -- 2.2x higher image generation scores, an average 10% boost in classification metrics (up to 50% in multi-domain non-IID settings), in much lower latency compared to several benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.",
      "authors": [
        "Youssef Tawfilis",
        "Hossam Amer",
        "Minar El-Aasser",
        "and Tallal Elshabrawy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:31:31+00:00",
          "link": "https://arxiv.org/abs/2507.12979v1",
          "size": "7660kb",
          "version": "v1"
        }
      ],
      "title": "A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12979",
        "PDF": "https://arxiv.org/pdf/2507.12979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses GAN training in a federated setting, which involves data processing challenges, it primarily deals with device heterogeneity and privacy constraints rather than LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12981",
      "abstract": "This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas y Respuestas sobre Tablas en Espa\\~nol (Questions and Answers about Tables in Spanish). Our solution obtains answers to the questions by implementing Python code generation with LLMs that is used to filter and process the table. This solution evolves from the MRT implementation for the Semeval 2025 related task. The process consists of multiple steps: analyzing and understanding the content of the table, selecting the useful columns, generating instructions in natural language, translating these instructions to code, running it, and handling potential errors or exceptions. These steps use open-source LLMs and fine-grained optimized prompts for each step. With this approach, we achieved an accuracy score of 85\\% in the task.",
      "authors": [
        "Maximiliano Hormaz\\'abal Lagos,\\'Alvaro Bueno S\\'aez",
        "H\\'ector Cerezo-Costas",
        "Pedro Alonso Doval",
        "Jorge Alcalde Vesteiro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:33:36+00:00",
          "link": "https://arxiv.org/abs/2507.12981v1",
          "size": "126kb",
          "version": "v1"
        }
      ],
      "title": "MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12981",
        "HTML": "https://arxiv.org/html/2507.12981v1",
        "PDF": "https://arxiv.org/pdf/2507.12981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of LLMs for generating Python code to process tables in a specific task, involving data filtering and processing. However, it focuses more on task-specific implementation rather than broader LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12983",
      "abstract": "Fairness has emerged as one of the key challenges in federated learning. In horizontal federated settings, data heterogeneity often leads to substantial performance disparities across clients, raising concerns about equitable model behavior. To address this issue, we propose FedGA, a fairness-aware federated learning algorithm. We first employ the Gini coefficient to measure the performance disparity among clients. Based on this, we establish a relationship between the Gini coefficient $G$ and the update scale of the global model ${U_s}$, and use this relationship to adaptively determine the timing of fairness intervention. Subsequently, we dynamically adjust the aggregation weights according to the system's real-time fairness status, enabling the global model to better incorporate information from clients with relatively poor performance.We conduct extensive experiments on the Office-Caltech-10, CIFAR-10, and Synthetic datasets. The results show that FedGA effectively improves fairness metrics such as variance and the Gini coefficient, while maintaining strong overall performance, demonstrating the effectiveness of our approach.",
      "authors": [
        "ShanBin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.12983v1",
          "size": "612kb",
          "version": "v1"
        }
      ],
      "title": "FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12983",
        "HTML": "https://arxiv.org/html/2507.12983v1",
        "PDF": "https://arxiv.org/pdf/2507.12983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses fairness in federated learning using the Gini coefficient and is not concerned with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12984",
      "abstract": "We consider the problem of online assignment of indivisible chores under \\MMS\\ criteria. The previous work proves that any deterministic online algorithm for chore division has a competitive ratio of at least 2. In this work, we improve this bound by showing that no deterministic online algorithm can obtain a competitive ratio better than $n$ for $n$ agents.",
      "authors": [
        "Masoud Seddighin and Saeed Seddighin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:39:27+00:00",
          "link": "https://arxiv.org/abs/2507.12984v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Lower Bound for Online MMS Assignment of Indivisible Chores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12984",
        "HTML": "https://arxiv.org/html/2507.12984v1",
        "PDF": "https://arxiv.org/pdf/2507.12984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with chore division problem under MMS criteria, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12986",
      "abstract": "AI-based robots and vehicles are expected to operate safely in complex and dynamic environments, even in the presence of component degradation. In such systems, perception relies on sensors such as cameras to capture environmental data, which is then processed by AI models to support decision-making. However, degradation in sensor performance directly impacts input data quality and can impair AI inference. Specifying safety requirements for all possible sensor degradation scenarios leads to unmanageable complexity and inevitable gaps. In this position paper, we present a novel framework that integrates camera noise factor identification with situation coverage analysis to systematically elicit robustness-related safety requirements for AI-based perception systems. We focus specifically on camera degradation in the automotive domain. Building on an existing framework for identifying degradation modes, we propose involving domain, sensor, and safety experts, and incorporating Operational Design Domain specifications to extend the degradation model by incorporating noise factors relevant to AI performance. Situation coverage analysis is then applied to identify representative operational contexts. This work marks an initial step toward integrating noise factor analysis and situational coverage to support principled formulation and completeness assessment of robustness requirements for camera-based AI perception.",
      "authors": [
        "Sepeedeh Shahbeigi",
        "Nawshin Mannan Proma",
        "Victoria Hodge",
        "Richard Hawkins",
        "Boda Li",
        "Valentina Donzella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:46:00+00:00",
          "link": "https://arxiv.org/abs/2507.12986v1",
          "size": "927kb",
          "version": "v1"
        }
      ],
      "title": "Robustness Requirement Coverage using a Situation Coverage Approach for Vision-based AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12986",
        "HTML": "https://arxiv.org/html/2507.12986v1",
        "PDF": "https://arxiv.org/pdf/2507.12986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses robustness requirements for AI systems using a situation coverage approach, particularly in the context of AI-based robotics and vehicles. This is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12987",
      "abstract": "This study presents a non-iterative tuning technique for a linear fractional-order (FO) controller, based on the integral of the time-weighted absolute error (ITAE) criterion. Minimizing the ITAE is a traditional approach for tuning FO controllers. This technique reduces the over/undershoot and suppresses the steady-state error. In contrast to conventional approaches of ITAE-based controller tuning, the proposed approach does not require multiple closed-loop experiments or model-based simulations to evaluate the ITAE. The one-shot input/output data is collected from the controlled plant. A fictitious reference signal is defined on the basis of the collected input and output signal, which enables us to evaluate the closed-loop response provided by the arbitrary controller parameters. To avoid repeated experiments that are necessary in the conventional approach, we reformulate the ITAE minimization problem using the fictitious reference signal. The desired FO controller parameters minimizing the ITAE are obtained by solving the optimization problem that is based on the fictitious reference signal. The validity of the proposed approach is demonstrated by a numerical study. The avoidance of repeated experiments significantly reduces the development cost of linear FO controllers, thereby facilitating their practical application.",
      "authors": [
        "Ansei Yonezawa",
        "Heisei Yonezawa",
        "Shuichi Yahagi",
        "Itsuro Kajiwara",
        "Shinya Kijimoto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:48:57+00:00",
          "link": "https://arxiv.org/abs/2507.12987v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Fractional-order controller tuning via minimization of integral of time-weighted absolute error without multiple closed-loop tests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12987",
        "HTML": "https://arxiv.org/html/2507.12987v1",
        "PDF": "https://arxiv.org/pdf/2507.12987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a method for tuning fractional-order controllers without requiring multiple closed-loop tests. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12988",
      "abstract": "Increasingly expensive training of ever larger models such as Vision Transfomers motivate reusing the vast library of already trained state-of-the-art networks. However, their latency, high computational costs and memory demands pose significant challenges for deployment, especially on resource-constrained hardware. While structured pruning methods can reduce these factors, they often require costly retraining, sometimes for up to hundreds of epochs, or even training from scratch to recover the lost accuracy resulting from the structural modifications. Maintaining the provided performance of trained models after structured pruning and thereby avoiding extensive retraining remains a challenge. To solve this, we introduce Variance-Based Pruning, a simple and structured one-shot pruning technique for efficiently compressing networks, with minimal finetuning. Our approach first gathers activation statistics, which are used to select neurons for pruning. Simultaneously the mean activations are integrated back into the model to preserve a high degree of performance. On ImageNet-1k recognition tasks, we demonstrate that directly after pruning DeiT-Base retains over 70% of its original performance and requires only 10 epochs of fine-tuning to regain 99% of the original accuracy while simultaneously reducing MACs by 35% and model size by 36%, thus speeding up the model by 1.44x.",
      "authors": [
        "Uranik Berisha",
        "Jens Mehnert",
        "Alexandru Paul Condurache"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:54:17+00:00",
          "link": "https://arxiv.org/abs/2507.12988v1",
          "size": "448kb",
          "version": "v1"
        }
      ],
      "title": "Variance-Based Pruning for Accelerating and Compressing Trained Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12988",
        "HTML": "https://arxiv.org/html/2507.12988v1",
        "PDF": "https://arxiv.org/pdf/2507.12988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a pruning method to compress and accelerate trained networks. It focuses on model efficiency rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12989",
      "abstract": "Probabilistic Event Calculus (PEC) is a logical framework for reasoning about actions and their effects in uncertain environments, which enables the representation of probabilistic narratives and computation of temporal projections. The PEC formalism offers significant advantages in interpretability and expressiveness for narrative reasoning. However, it lacks mechanisms for goal-directed reasoning. This paper bridges this gap by developing a formal translation of PEC domains into Markov Decision Processes (MDPs), introducing the concept of \"action-taking situations\" to preserve PEC's flexible action semantics. The resulting PEC-MDP formalism enables the extensive collection of algorithms and theoretical tools developed for MDPs to be applied to PEC's interpretable narrative domains. We demonstrate how the translation supports both temporal reasoning tasks and objective-driven planning, with methods for mapping learned policies back into human-readable PEC representations, maintaining interpretability while extending PEC's capabilities.",
      "authors": [
        "Lyris Xu",
        "Fabio Aurelio D'Asaro",
        "Luke Dickens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:56:22+00:00",
          "link": "https://arxiv.org/abs/2507.12989v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "A Translation of Probabilistic Event Calculus into Markov Decision Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12989",
        "HTML": "https://arxiv.org/html/2507.12989v1",
        "PDF": "https://arxiv.org/pdf/2507.12989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper translates probabilistic event calculus into Markov Decision Processes for narrative reasoning. It does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12990",
      "abstract": "Sparse Autoencoders have emerged as powerful tools for interpreting the internal representations of Large Language Models, yet they often fail to capture domain-specific features not prevalent in their training corpora. This paper introduces a residual learning approach that addresses this feature blindness without requiring complete retraining. We propose training a secondary SAE specifically to model the reconstruction error of a pretrained SAE on domain-specific texts, effectively capturing features missed by the primary model. By summing the outputs of both models during inference, we demonstrate significant improvements in both LLM cross-entropy and explained variance metrics across multiple specialized domains. Our experiments show that this method efficiently incorporates new domain knowledge into existing SAEs while maintaining their performance on general tasks. This approach enables researchers to selectively enhance SAE interpretability for specific domains of interest, opening new possibilities for targeted mechanistic interpretability of LLMs.",
      "authors": [
        "Nikita Koriagin",
        "Yaroslav Aksenov",
        "Daniil Laptev",
        "Gleb Gerasimov",
        "Nikita Balagansky",
        "Daniil Gavrilov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:57:49+00:00",
          "link": "https://arxiv.org/abs/2507.12990v1",
          "size": "1667kb",
          "version": "v1"
        }
      ],
      "title": "Teach Old SAEs New Domain Tricks with Boosting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12990",
        "HTML": "https://arxiv.org/html/2507.12990v1",
        "PDF": "https://arxiv.org/pdf/2507.12990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the interpretability of Sparse Autoencoders for LLMs in specific domains, but does not address training data processing, dataset creation, or data quality improvement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12996",
      "abstract": "Contrastive learning and equivariant learning are effective methods for self-supervised learning (SSL) for audio content analysis. Yet, their application to music information retrieval (MIR) faces a dilemma: the former is more effective on tagging (e.g., instrument recognition) but less effective on structured prediction (e.g., tonality estimation); The latter can match supervised methods on the specific task it is designed for, but it does not generalize well to other tasks. In this article, we adopt a best-of-both-worlds approach by training a deep neural network on both kinds of pretext tasks at once. The proposed new architecture is a Vision Transformer with 1-D spectrogram patches (ViT-1D), equipped with two class tokens, which are specialized to different self-supervised pretext tasks but optimized through the same model: hence the qualification of self-supervised multi-class-token multitask (MT2). The former class token optimizes cross-power spectral density (CPSD) for equivariant learning over the circle of fifths, while the latter optimizes normalized temperature-scaled cross-entropy (NT-Xent) for contrastive learning. MT2 combines the strengths of both pretext tasks and outperforms consistently both single-class-token ViT-1D models trained with either contrastive or equivariant learning. Averaging the two class tokens further improves performance on several tasks, highlighting the complementary nature of the representations learned by each class token. Furthermore, using the same single-linear-layer probing method on the features of last layer, MT2 outperforms MERT on all tasks except for beat tracking; achieving this with 18x fewer parameters thanks to its multitasking capabilities. Our SSL benchmark demonstrates the versatility of our multi-class-token multitask learning approach for MIR applications.",
      "authors": [
        "Yuexuan Kong",
        "Vincent Lostanlen",
        "Romain Hennequin",
        "Mathieu Lagrange",
        "Gabriel Meseguer-Brocal"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:13:11+00:00",
          "link": "https://arxiv.org/abs/2507.12996v1",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Class-Token Transformer for Multitask Self-supervised Music Information Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12996",
        "HTML": "https://arxiv.org/html/2507.12996v1",
        "PDF": "https://arxiv.org/pdf/2507.12996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses self-supervised learning for music information retrieval using a transformer model, which does not pertain to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12998",
      "abstract": "The remarkable success of contrastive-learning-based multimodal models has been greatly driven by training on ever-larger datasets with expensive compute consumption. Sample selection as an alternative efficient paradigm plays an important direction to accelerate the training process. However, recent advances on sample selection either mostly rely on an oracle model to offline select a high-quality coreset, which is limited in the cold-start scenarios, or focus on online selection based on real-time model predictions, which has not sufficiently or efficiently considered the noisy correspondence. To address this dilemma, we propose a novel Differential-Informed Sample Selection (DISSect) method, which accurately and efficiently discriminates the noisy correspondence for training acceleration. Specifically, we rethink the impact of noisy correspondence on contrastive learning and propose that the differential between the predicted correlation of the current model and that of a historical model is more informative to characterize sample quality. Based on this, we construct a robust differential-based sample selection and analyze its theoretical insights. Extensive experiments on three benchmark datasets and various downstream tasks demonstrate the consistent superiority of DISSect over current state-of-the-art methods. Source code is available at: https://github.com/MediaBrain-SJTU/DISSect.",
      "authors": [
        "Zihua Zhao",
        "Feng Hong",
        "Mengxi Chen",
        "Pengyi Chen",
        "Benyuan Liu",
        "Jiangchao Yao",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:13:44+00:00",
          "link": "https://arxiv.org/abs/2507.12998v1",
          "size": "2286kb",
          "version": "v1"
        }
      ],
      "title": "Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12998",
        "HTML": "https://arxiv.org/html/2507.12998v1",
        "PDF": "https://arxiv.org/pdf/2507.12998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on improving multimodal contrastive learning through a sample selection method, but does not make contributions to LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13001",
      "abstract": "Knowledge graph representation learning approaches provide a mapping between symbolic knowledge in the form of triples in a knowledge graph (KG) and their feature vectors. Knowledge graph embedding (KGE) models often represent relations in a KG as geometric transformations. Most state-of-the-art (SOTA) KGE models are derived from elementary geometric transformations (EGTs), such as translation, scaling, rotation, and reflection, or their combinations. These geometric transformations enable the models to effectively preserve specific structural and relational patterns of the KG. However, the current use of EGTs by KGEs remains insufficient without considering relation-specific transformations. Although recent models attempted to address this problem by ensembling SOTA baseline models in different ways, only a single or composite version of geometric transformations are used by such baselines to represent all the relations. In this paper, we propose a framework that evaluates how well each relation fits with different geometric transformations. Based on this ranking, the model can: (1) assign the best-matching transformation to each relation, or (2) use majority voting to choose one transformation type to apply across all relations. That is, the model learns a single relation-specific EGT in low dimensional vector space through an attention mechanism. Furthermore, we use the correlation between relations and EGTs, which are learned in a low dimension, for relation embeddings in a high dimensional vector space. The effectiveness of our models is demonstrated through comprehensive evaluations on three benchmark KGs as well as a real-world financial KG, witnessing a performance comparable to leading models",
      "authors": [
        "Kossi Amouzouvi",
        "Bowen Song",
        "Andrea Coletta",
        "Luigi Bellomarini",
        "Jens Lehmann",
        "Sahar Vahdati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:18:08+00:00",
          "link": "https://arxiv.org/abs/2507.13001v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13001",
        "HTML": "https://arxiv.org/html/2507.13001v1",
        "PDF": "https://arxiv.org/pdf/2507.13001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a model for knowledge graph embedding using learned geometric transformations, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13007",
      "abstract": "Following the recent push for trustworthy AI, there has been an increasing interest in developing contrastive explanation techniques for optimisation, especially concerning the solution of specific decision-making processes formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic approach for building contrastive explanations for MILPs based on constraint reasoning techniques. First, we show how to encode the queries a user makes about the solution of an MILP problem as additional constraints. Then, we determine the reasons that constitute the answer to the user's query by computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set of constraints. Finally, we represent our explanation as a \"graph of reasons\" constructed from the IIS, which helps the user understand the structure among the reasons that answer their query. We test our method on instances of well-known optimisation problems to evaluate the empirical hardness of computing explanations.",
      "authors": [
        "Roger Xavier Lera-Leri",
        "Filippo Bistaffa",
        "Athina Georgara",
        "Juan Antonio Rodriguez-Aguilar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:25:33+00:00",
          "link": "https://arxiv.org/abs/2507.13007v1",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13007",
        "HTML": "https://arxiv.org/html/2507.13007v1",
        "PDF": "https://arxiv.org/pdf/2507.13007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for creating graphical explanations for mixed-integer linear programming problems, which does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13008",
      "abstract": "As the field of Trust and Safety in digital spaces continues to grow, it has become increasingly necessary - but also increasingly complex - to collaborate on research across the academic, industry, governmental and non-governmental sectors. This paper examines how cross-affiliation research partnerships can be structured to overcome misaligned incentives, timelines and constraints while delivering on the unique strengths of each stakeholder. Drawing on our own experience of cross-sector collaboration, we define the main types of affiliation and highlight the common differences in research priorities, operational pressures and evaluation metrics across sectors. We then propose a practical, step-by-step framework for initiating and managing effective collaborations, including strategies for building trust, aligning goals, and distributing roles. We emphasize the critical yet often invisible work of articulation and argue that cross-sector partnerships are essential for developing more ethical, equitable and impactful research in trust and safety. Ultimately, we advocate collaborative models that prioritize inclusivity, transparency and real-world relevance in order to meet the interdisciplinary demands of this emerging field.",
      "authors": [
        "Amanda Menking",
        "Mona Elswah",
        "David J. Gr\\\"uning",
        "Lasse H. Hansen",
        "Irene Huang",
        "Julia Kamin",
        "Catrine Normann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:27:32+00:00",
          "link": "https://arxiv.org/abs/2507.13008v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13008",
        "PDF": "https://arxiv.org/pdf/2507.13008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on research collaborations in the field of Trust and Safety, examining structures for partnerships across sectors. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13015",
      "abstract": "This work presents a novel Nonlinear Model Predictive Control (NMPC) strategy for high-speed Maglev vehicles that explicitly incorporates mechanical suspension dynamics into the control model. Unlike conventional approaches, which often neglect the interaction between levitation magnet and car body motion, the proposed method enables predictive vibration mitigation by modeling both electromagnetic forces and suspension behavior. This integrated approach significantly improves passenger comfort and ride quality by reducing vertical oscillations caused by track irregularities. Moreover, it allows for a more effective tuning of the trade-off between precise air gap tracking and ride comfort. Simulations based on a detailed multibody model of the Transrapid demonstrate that the method outperforms existing controllers in vibration suppression, making it a promising solution for future high-speed Maglev applications.",
      "authors": [
        "Mario Hermle and Arnim Kargl and Peter Eberhard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.13015v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "Vertical Vibration Reduction of Maglev Vehicles using Nonlinear MPC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13015",
        "HTML": "https://arxiv.org/html/2507.13015v1",
        "PDF": "https://arxiv.org/pdf/2507.13015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a Nonlinear Model Predictive Control strategy for Maglev vehicles, focusing on mechanical dynamics and passenger comfort. There is no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13018",
      "abstract": "Deep learning-based image manipulation localization (IML) methods have achieved remarkable performance in recent years, but typically rely on large-scale pixel-level annotated datasets. To address the challenge of acquiring high-quality annotations, some recent weakly supervised methods utilize image-level labels to segment manipulated regions. However, the performance is still limited due to insufficient supervision signals. In this study, we explore a form of weak supervision that improves the annotation efficiency and detection performance, namely scribble annotation supervision. We re-annotated mainstream IML datasets with scribble labels and propose the first scribble-based IML (Sc-IML) dataset. Additionally, we propose the first scribble-based weakly supervised IML framework. Specifically, we employ self-supervised training with a structural consistency loss to encourage the model to produce consistent predictions under multi-scale and augmented inputs. In addition, we propose a prior-aware feature modulation module (PFMM) that adaptively integrates prior information from both manipulated and authentic regions for dynamic feature adjustment, further enhancing feature discriminability and prediction consistency in complex scenes. We also propose a gated adaptive fusion module (GAFM) that utilizes gating mechanisms to regulate information flow during feature fusion, guiding the model toward emphasizing potential tampered regions. Finally, we propose a confidence-aware entropy minimization loss (${\\mathcal{L}}_{ {CEM }}$). This loss dynamically regularizes predictions in weakly annotated or unlabeled regions based on model uncertainty, effectively suppressing unreliable predictions. Experimental results show that our method outperforms existing fully supervised approaches in terms of average performance both in-distribution and out-of-distribution.",
      "authors": [
        "Songlin Li",
        "Guofeng Yu",
        "Zhiqing Guo",
        "Yunfeng Diao",
        "Dan Ma",
        "Gaobo Yang",
        "Liejun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:45:27+00:00",
          "link": "https://arxiv.org/abs/2507.13018v1",
          "size": "6242kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13018",
        "HTML": "https://arxiv.org/html/2507.13018v1",
        "PDF": "https://arxiv.org/pdf/2507.13018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a new scribble-annotated dataset and weakly supervised framework for image manipulation localization, which includes data annotation improvements. However, it does not directly focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13019",
      "abstract": "Recent Vision-and-Language Navigation (VLN) advancements are promising, but their idealized assumptions about robot movement and control fail to reflect physically embodied deployment challenges. To bridge this gap, we introduce VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and wheeled robots. For the first time, we systematically evaluate several ego-centric VLN methods in physical robotic settings across different technical pipelines, including classification models for single-step discrete action prediction, a diffusion model for dense waypoint prediction, and a train-free, map-based large language model (LLM) integrated with path planning. Our results reveal significant performance degradation due to limited robot observation space, environmental lighting variations, and physical challenges like collisions and falls. This also exposes locomotion constraints for legged robots in complex environments. VLN-PE is highly extensible, allowing seamless integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN evaluation. Despite the weak generalization of current models in physical deployment, VLN-PE provides a new pathway for improving cross-embodiment's overall adaptability. We hope our findings and tools inspire the community to rethink VLN limitations and advance robust, practical VLN models. The code is available at https://crystalsixone.github.io/vln_pe.github.io/.",
      "authors": [
        "Liuyi Wang",
        "Xinyuan Xia",
        "Hui Zhao",
        "Hanqing Wang",
        "Tai Wang",
        "Yilun Chen",
        "Chengju Liu",
        "Qijun Chen",
        "Jiangmiao Pang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:46:00+00:00",
          "link": "https://arxiv.org/abs/2507.13019v1",
          "size": "17515kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13019",
        "HTML": "https://arxiv.org/html/2507.13019v1",
        "PDF": "https://arxiv.org/pdf/2507.13019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a platform for evaluating vision-and-language navigation in robot settings but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13022",
      "abstract": "In the context of the health monitoring for the next generation of reusable space launchers, we outline a first step toward developing an onboard fault detection and diagnostic capability for the electrical system that controls the engine valves. Unlike existing approaches in the literature, our solution is designed to meet a broader range of key requirements. This includes estimating confidence levels for predictions, detecting out-of-distribution (OOD) cases, and controlling false alarms. The proposed solution is based on a temporal convolutional autoencoder to automatically extract low-dimensional features from raw sensor data. Fault detection and diagnosis are respectively carried out using a binary and a multiclass classifier trained on the autoencoder latent and residual spaces. The classifiers are histogram-based gradient boosting models calibrated to output probabilities that can be interpreted as confidence levels. A relatively simple technique, based on inductive conformal anomaly detection, is used to identify OOD data. We leverage other simple yet effective techniques, such as cumulative sum control chart (CUSUM) to limit the false alarms, and threshold moving to address class imbalance in fault detection. The proposed framework is highly configurable and has been evaluated on simulated data, covering both nominal and anomalous operational scenarios. The results indicate that our solution is a promising first step, though testing with real data will be necessary to ensure that it achieves the required maturity level for operational use.",
      "authors": [
        "Luis Basora",
        "Louison Bocquet-Nouaille",
        "Elinirina Robinson",
        "Serge Le Gonidec"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:50:29+00:00",
          "link": "https://arxiv.org/abs/2507.13022v1",
          "size": "3920kb",
          "version": "v1"
        }
      ],
      "title": "Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13022",
        "HTML": "https://arxiv.org/html/2507.13022v1",
        "PDF": "https://arxiv.org/pdf/2507.13022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fault detection and diagnostics for engine electrical systems in space launchers, leveraging techniques like temporal convolutional autoencoder, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13023",
      "abstract": "This paper provides a comprehensive empirical analysis of the economics and dynamics behind arbitrages between centralized and decentralized exchanges (CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions from on-chain data and introduce a robust empirical framework to estimate arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging an extensive dataset spanning 19 months from August 2023 to March 2025, we estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from 7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing centralization trends as three searchers captured three-quarters of both volume and extracted value. We also demonstrate that searchers' profitability is tied to their integration level with block builders and uncover exclusive searcher-builder relationships and their market impact. Finally, we correct the previously underestimated profitability of block builders who vertically integrate with a searcher. These insights illuminate the darkest corner of the MEV landscape and highlight the critical implications of CEX-DEX arbitrages for Ethereum's decentralization.",
      "authors": [
        "Fei Wu",
        "Danning Sui",
        "Thomas Thiery",
        "Mallesh Pai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Trading and Market Microstructure (q-fin.TR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:50:42+00:00",
          "link": "https://arxiv.org/abs/2507.13023v1",
          "size": "7167kb",
          "version": "v1"
        }
      ],
      "title": "Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13023",
        "HTML": "https://arxiv.org/html/2507.13023v1",
        "PDF": "https://arxiv.org/pdf/2507.13023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides an empirical analysis of CEX-DEX arbitrages in Ethereum, focusing on the economic dynamics and profitability, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13026",
      "abstract": "This paper introduces the concept of the \"Price of Diversity\" (PoD) in discrete optimization problems, quantifying the trade-off between solution diversity and cost. For a minimization problem, the PoD is defined as the worst-case ratio, over all instances, of the minimum achievable cost of a diverse set of $k$ solutions to the cost of a single optimal solution for the same instance. Here, the cost of a $k$-solution set is determined by the most expensive solution within the set. Focusing on the Traveling Salesman Problem (TSP) as a key example, we study the PoD in the setting where $k$ edge-disjoint tours are required. We establish that, asymptotically, the PoD of finding two edge-disjoint tours is $\\frac{8}{5}$ in a special one-dimensional case and 2 in a general metric space. We obtain these results from analyzing a related fundamental problem: the Shortest Hamiltonian Path problem (SHP), for which we establish similar results.",
      "authors": [
        "Mark de Berg",
        "Andr\\'es L\\'opez Mart\\'inez",
        "Frits Spieksma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:55:42+00:00",
          "link": "https://arxiv.org/abs/2507.13026v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "The Price of Diversity of the Traveling Salesman Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13026",
        "HTML": "https://arxiv.org/html/2507.13026v1",
        "PDF": "https://arxiv.org/pdf/2507.13026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses the 'Price of Diversity' in discrete optimization, specifically within the Traveling Salesman Problem, and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13028",
      "abstract": "Hardening computer systems against cyberattacks is crucial for security. However, past incidents illustrated, that many system operators struggle with effective system hardening. Hence, many computer systems and applications remain insecure. So far, the research community lacks an in-depth understanding of system operators motivation, practices, and challenges around system hardening. With a focus on practices and challenges, we qualitatively analyzed 316 Stack Exchange (SE) posts related to system hardening. We find that access control and deployment-related issues are the most challenging, and system operators suffer from misconceptions and unrealistic expectations. Most frequently, posts focused on operating systems and server applications. System operators were driven by the fear of their systems getting attacked or by compliance reasons. Finally, we discuss our research questions, make recommendations for future system hardening, and illustrate the implications of our work.",
      "authors": [
        "Niklas Busch (1)",
        "Philip Klostermeyer (1)",
        "Jan H. Klemmer (1)",
        "Yasemin Acar (2)",
        "Sascha Fahl (1) ((1) CISPA Helmholtz Center for Information Security",
        "(2) Paderborn University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:57:11+00:00",
          "link": "https://arxiv.org/abs/2507.13028v1",
          "size": "491kb",
          "version": "v1"
        }
      ],
      "title": "From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13028",
        "PDF": "https://arxiv.org/pdf/2507.13028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines system hardening practices from Stack Exchange posts, focusing on security improvement and challenges, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13032",
      "abstract": "AutoRegressive (AR) models have made notable progress in image generation, with Masked AutoRegressive (MAR) models gaining attention for their efficient parallel decoding. However, MAR models have traditionally underperformed when compared to standard AR models. This study refines the MAR architecture to improve image generation quality. We begin by evaluating various image tokenizers to identify the most effective one. Subsequently, we introduce an improved Bidirectional LLaMA architecture by replacing causal attention with bidirectional attention and incorporating 2D RoPE, which together form our advanced model, MaskGIL. Scaled from 111M to 1.4B parameters, MaskGIL achieves a FID score of 3.71, matching state-of-the-art AR models in the ImageNet 256x256 benchmark, while requiring only 8 inference steps compared to the 256 steps of AR models. Furthermore, we develop a text-driven MaskGIL model with 775M parameters for generating images from text at various resolutions. Beyond image generation, MaskGIL extends to accelerate AR-based generation and enable real-time speech-to-image conversion. Our codes and models are available at https://github.com/synbol/MaskGIL.",
      "authors": [
        "Yi Xin",
        "Le Zhuo",
        "Qi Qin",
        "Siqi Luo",
        "Yuewen Cao",
        "Bin Fu",
        "Yangfan He",
        "Hongsheng Li",
        "Guangtao Zhai",
        "Xiaohong Liu",
        "Peng Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:02:38+00:00",
          "link": "https://arxiv.org/abs/2507.13032v1",
          "size": "12717kb",
          "version": "v1"
        }
      ],
      "title": "Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13032",
        "HTML": "https://arxiv.org/html/2507.13032v1",
        "PDF": "https://arxiv.org/pdf/2507.13032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving image generation models and their architectural enhancements, but it does not discuss any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13034",
      "abstract": "Protected natural areas play a vital role in ecological balance and ecosystem services. Monitoring these regions at scale using satellite imagery and machine learning is promising, but current methods often lack interpretability and uncertainty-awareness, and do not address how uncertainty affects naturalness assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a data-centric framework that combines LRP Attention Rollout with Deep Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty influences the interpretability of relevance heatmaps. CFR partitions the dataset into subsets based on uncertainty thresholds, enabling systematic analysis of how uncertainty shapes the explanations of naturalness in satellite imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to shrublands, forests, and wetlands, aligning with other research on naturalness assessment. Moreover, our analysis shows that as uncertainty increases, the interpretability of these relevance heatmaps declines and their entropy grows, indicating less selective and more ambiguous attributions. CFR provides a data-centric approach to assess the relevance of patterns to naturalness in satellite imagery based on their associated certainty.",
      "authors": [
        "Ahmed Emam",
        "Ribana Roscher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:06:08+00:00",
          "link": "https://arxiv.org/abs/2507.13034v1",
          "size": "3336kb",
          "version": "v1"
        }
      ],
      "title": "Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13034",
        "HTML": "https://arxiv.org/html/2507.13034v1",
        "PDF": "https://arxiv.org/pdf/2507.13034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a data-centric framework for satellite imagery analysis, dealing with uncertainty and interpretability; however, it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13035",
      "abstract": "Manual testing, in which testers follow natural language instructions to validate system behavior, remains crucial for uncovering issues not easily captured by automation. However, these test cases often suffer from test smells, quality issues such as ambiguity, redundancy, or missing checks that reduce test reliability and maintainability. While detection tools exist, they typically require manual rule definition and lack scalability. This study investigates the potential of Small Language Models (SLMs) for automatically detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143 real-world Ubuntu test cases, covering seven types of test smells. Phi-4 achieved the best results, reaching a pass@2 of 97% in detecting sentences with test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond detection, SLMs autonomously explained issues and suggested improvements, even without explicit prompt instructions. They enabled low-cost, concept-driven identification of diverse test smells without relying on extensive rule definitions or syntactic analysis. These findings highlight the potential of SLMs as efficient tools that preserve data privacy and can improve test quality in real-world scenarios.",
      "authors": [
        "Keila Lucas",
        "Rohit Gheyi",
        "M\\'arcio Ribeiro",
        "Fabio Palomba",
        "Luana Martins",
        "Elvys Soares"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:06:29+00:00",
          "link": "https://arxiv.org/abs/2507.13035v1",
          "size": "523kb",
          "version": "v1"
        }
      ],
      "title": "Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13035",
        "PDF": "https://arxiv.org/pdf/2507.13035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper evaluates small language models for detecting 'test smells' in manual testing, it does not contribute to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13038",
      "abstract": "Multi-agent debate (MAD) systems leverage collaborative interactions among large language models (LLMs) agents to improve reasoning capabilities. While recent studies have focused on increasing the accuracy and scalability of MAD systems, their security vulnerabilities have received limited attention. In this work, we introduce MAD-Spear, a targeted prompt injection attack that compromises a small subset of agents but significantly disrupts the overall MAD process. Manipulated agents produce multiple plausible yet incorrect responses, exploiting LLMs' conformity tendencies to propagate misinformation and degrade consensus quality. Furthermore, the attack can be composed with other strategies, such as communication attacks, to further amplify its impact by increasing the exposure of agents to incorrect responses. To assess MAD's resilience under attack, we propose a formal definition of MAD fault-tolerance and develop a comprehensive evaluation framework that jointly considers accuracy, consensus efficiency, and scalability. Extensive experiments on five benchmark datasets with varying difficulty levels demonstrate that MAD-Spear consistently outperforms the baseline attack in degrading system performance. Additionally, we observe that agent diversity substantially improves MAD performance in mathematical reasoning tasks, which challenges prior work suggesting that agent diversity has minimal impact on performance. These findings highlight the urgent need to improve the security in MAD design.",
      "authors": [
        "Yu Cui and Hongyang Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:09:39+00:00",
          "link": "https://arxiv.org/abs/2507.13038v1",
          "size": "640kb",
          "version": "v1"
        }
      ],
      "title": "MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13038",
        "HTML": "https://arxiv.org/html/2507.13038v1",
        "PDF": "https://arxiv.org/pdf/2507.13038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on security vulnerabilities and prompt injection attacks in multi-agent debate systems, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13041",
      "abstract": "As robots find their way into more and more aspects of everyday life, questions around trust are becoming increasingly important. What does it mean to trust a robot? And how should we think about trust in relationships that involve both humans and non-human agents? While the field of Human-Robot Interaction (HRI) has made trust a central topic, the concept is often approached in fragmented ways. At the same time, established work in sociology, where trust has long been a key theme, is rarely brought into conversation with developments in robotics. This article argues that we need a more interdisciplinary approach. By drawing on insights from both social sciences and social robotics, we explore how trust is shaped, tested and made visible. Our goal is to open up a dialogue between disciplines and help build a more grounded and adaptable framework for understanding trust in the evolving world of human-robot interaction.",
      "authors": [
        "Julien Wacquez (ETIS",
        "CNRS)",
        "Elisabetta Zibetti (CHART)",
        "Joffrey Becker (ENSEA",
        "ETIS)",
        "Lorenzo Aloe (ETIS",
        "CHART)",
        "Fabio Amadio (LARSEN)",
        "Salvatore Anzalone (CHART)",
        "Lola Ca\\~namero (ETIS",
        "CY",
        "CNRS",
        "ENSEA)",
        "Serena Ivaldi (LARSEN",
        "LORIA - AIS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:10:34+00:00",
          "link": "https://arxiv.org/abs/2507.13041v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13041",
        "PDF": "https://arxiv.org/pdf/2507.13041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on trust in human-robot interaction from an interdisciplinary perspective, involving social sciences and robotics. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13042",
      "abstract": "The integration of security and energy efficiency in Internet of Things systems remains a critical challenge, particularly for battery-free and resource-constrained devices. This paper explores the scalability and protocol-agnostic nature of a backscattering-based security mechanism by integrating it into Bluetooth Low Energy battery-free Wireless Sensor Network. The proposed approach leverages the Wireless Power Transfer link, traditionally used for energy harvesting, to generate additional identification signals without increasing energy consumption or computational demands. Experimental validation demonstrates the solution's functionality using compact, low-gain antenna, ensuring compatibility with size-constrained applications such as Structural Health Monitoring and smart transport. Furthermore, this work addresses the challenges associated with backscattering dynamic range and multi-node Wireless Sensor Network scenarios, discussing potential collisions between identification signals and proposing future improvements to enhance generalizability and scalability. The findings underscore the potential of the backscattering-based security mechanism for creating secure, sustainable, and scalable IoT deployments across diverse protocols and applications.",
      "authors": [
        "Taki Eddine Djidjekh (INSA Toulouse",
        "LAAS-MINC)",
        "Ga\\\"el Loubet (LAAS-MINC",
        "INSA Toulouse)",
        "Alexandru Takacs (LAAS-MINC",
        "UT)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:15:09+00:00",
          "link": "https://arxiv.org/abs/2507.13042v1",
          "size": "713kb",
          "version": "v1"
        }
      ],
      "title": "Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13042",
        "PDF": "https://arxiv.org/pdf/2507.13042"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with security in wireless power transfer systems for IoT devices and does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13043",
      "abstract": "Transformer-based models have recently become dominant in Long-term Time Series Forecasting (LTSF), yet the variations in their architecture, such as encoder-only, encoder-decoder, and decoder-only designs, raise a crucial question: What Transformer architecture works best for LTSF tasks? However, existing models are often tightly coupled with various time-series-specific designs, making it difficult to isolate the impact of the architecture itself. To address this, we propose a novel taxonomy that disentangles these designs, enabling clearer and more unified comparisons of Transformer architectures. Our taxonomy considers key aspects such as attention mechanisms, forecasting aggregations, forecasting paradigms, and normalization layers. Through extensive experiments, we uncover several key insights: bi-directional attention with joint-attention is most effective; more complete forecasting aggregation improves performance; and the direct-mapping paradigm outperforms autoregressive approaches. Furthermore, our combined model, utilizing optimal architectural choices, consistently outperforms several existing models, reinforcing the validity of our conclusions. We hope these findings offer valuable guidance for future research on Transformer architectural designs in LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.",
      "authors": [
        "Lefei Shen",
        "Mouxiang Chen",
        "Han Fu",
        "Xiaoxue Ren",
        "Xiaoyun Joy Wang",
        "Jianling Sun",
        "Zhuo Li",
        "Chenghao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.13043v1",
          "size": "836kb",
          "version": "v1"
        }
      ],
      "title": "The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13043",
        "HTML": "https://arxiv.org/html/2507.13043v1",
        "PDF": "https://arxiv.org/pdf/2507.13043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on Transformer architectures for long-term time series forecasting, analyzing architecture designs rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13044",
      "abstract": "Expanders are powerful algorithmic structures with two key properties: they are\n  a) routable: for any multi-commodity flow unit demand, there exists a routing with low congestion over short paths, where a demand is unit if the amount of demand sent / received by any vertex is at most the number of edges adjacent to it.\n  b) stable / prunable: for any (sequence of) edge failures, there exists a proportionally small subset of vertices that can be disabled, such that the graph induced on the remaining vertices is an expander.\n  Two natural algorithmic problems correspond to these two existential guarantees: expander routing, i.e. computing a low-congestion routing for a unit multi-commodity demand on an expander, and expander pruning, i.e., maintaining the subset of disabled vertices under a sequence of edge failures.\n  This paper considers the combination of the two problems: maintaining a routing for a unit multi-commodity demand under pruning steps. This is done through the introduction of a family of expander graphs that, like hypercubes, are easy to route in, and are self-pruning: for an online sequence of edge deletions, a simple self-contained algorithm can find a few vertices to prune with each edge deletion, such that the remaining graph always remains an easy-to-route-in expander in the family.\n  Notably, and with considerable technical work, this self-pruning can be made worst-case, i.e., such that every single adversarial deletion only causes a small number of additional deletions. Our results also allow tight constant-factor control over the length of routing paths (with the usual trade-offs in congestion and pruning ratio) and therefore extend to constant-hop and length-constrained expanders in which routing over constant length paths is crucial.",
      "authors": [
        "Bernhard Haeupler",
        "Antti Roeyskoe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:16:35+00:00",
          "link": "https://arxiv.org/abs/2507.13044v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "Maintaining Routing Structures under Deletions via Self-Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13044",
        "PDF": "https://arxiv.org/pdf/2507.13044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithmic structures for maintaining routing structures under deletions. It does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13052",
      "abstract": "The advancement and maturity of large language models (LLMs) and robotics have unlocked vast potential for human-computer interaction, particularly in the field of robotic ultrasound. While existing research primarily focuses on either patient-robot or physician-robot interaction, the role of an intelligent virtual sonographer (IVS) bridging physician-robot-patient communication remains underexplored. This work introduces a conversational virtual agent in Extended Reality (XR) that facilitates real-time interaction between physicians, a robotic ultrasound system(RUS), and patients. The IVS agent communicates with physicians in a professional manner while offering empathetic explanations and reassurance to patients. Furthermore, it actively controls the RUS by executing physician commands and transparently relays these actions to the patient. By integrating LLM-powered dialogue with speech-to-text, text-to-speech, and robotic control, our system enhances the efficiency, clarity, and accessibility of robotic ultrasound acquisition. This work constitutes a first step toward understanding how IVS can bridge communication gaps in physician-robot-patient interaction, providing more control and therefore trust into physician-robot interaction while improving patient experience and acceptance of robotic ultrasound.",
      "authors": [
        "Tianyu Song",
        "Feng Li",
        "Yuan Bi",
        "Angelos Karlas",
        "Amir Yousefi",
        "Daniela Branzan",
        "Zhongliang Jiang",
        "Ulrich Eck",
        "Nassir Navab"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:25:01+00:00",
          "link": "https://arxiv.org/abs/2507.13052v1",
          "size": "1078kb",
          "version": "v1"
        }
      ],
      "title": "Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13052",
        "HTML": "https://arxiv.org/html/2507.13052v1",
        "PDF": "https://arxiv.org/pdf/2507.13052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores the integration of LLMs into a virtual sonographer system, which involves LLM-powered dialogue, it primarily focuses on human-robot-patient interaction rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13053",
      "abstract": "Robotic information gathering (RIG) techniques refer to methods where mobile robots are used to acquire data about the physical environment with a suite of sensors. Informative planning is an important part of RIG where the goal is to find sequences of actions or paths that maximize efficiency or the quality of information collected. Many existing solutions solve this problem by assuming that the environment is known in advance. However, real environments could be unknown or time-varying, and adaptive informative planning remains an active area of research. Adaptive planning and incremental online mapping are required for mapping initially unknown or varying spatial fields. Gaussian process (GP) regression is a widely used technique in RIG for mapping continuous spatial fields. However, it falls short in many applications as its real-time performance does not scale well to large datasets. To address these challenges, this paper proposes an efficient adaptive informative planning approach for mapping continuous scalar fields with GPs with streaming sparse GPs. Simulation experiments are performed with a synthetic dataset and compared against existing benchmarks. Finally, it is also verified with a real-world dataset to further validate the efficacy of the proposed method. Results show that our method achieves similar mapping accuracy to the baselines while reducing computational complexity for longer missions.",
      "authors": [
        "Sanjeev Ramkumar Sudha",
        "Joel Jose and Erlend M. Coates"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:26:03+00:00",
          "link": "https://arxiv.org/abs/2507.13053v1",
          "size": "4770kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Online Learning and Adaptive Planning for Robotic Information Gathering Based on Streaming Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13053",
        "HTML": "https://arxiv.org/html/2507.13053v1",
        "PDF": "https://arxiv.org/pdf/2507.13053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robotic information gathering and adaptive planning using Gaussian processes. It does not relate to LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13054",
      "abstract": "We study PAC and online learnability of hypothesis classes formed by copies of a countably infinite graph G, where each copy is induced by permuting G's vertices. This corresponds to learning a graph's labeling, knowing its structure and label set. We consider classes where permutations move only finitely many vertices. Our main result shows that PAC learnability of all such finite-support copies implies online learnability of the full isomorphism type of G, and is equivalent to the condition of automorphic triviality. We also characterize graphs where copies induced by swapping two vertices are not learnable, using a relaxation of the extension property of the infinite random graph. Finally, we show that, for all G and k>2, learnability for k-vertex permutations is equivalent to that for 2-vertex permutations, yielding a four-class partition of infinite graphs, whose complexity we also determine using tools coming from both descriptive set theory and computability theory.",
      "authors": [
        "Vittorio Cipriani",
        "Valentino Delle Rose",
        "Luca San Mauro",
        "Giovanni Solda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:26:25+00:00",
          "link": "https://arxiv.org/abs/2507.13054v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "On statistical learning of graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13054",
        "HTML": "https://arxiv.org/html/2507.13054v1",
        "PDF": "https://arxiv.org/pdf/2507.13054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies the learnability of hypothesis classes in graph structures, which does not pertain to LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13055",
      "abstract": "This study investigates the extent to which local public equity indices can statistically hedge real purchasing power loss during compounded structural macro-financial collapses in emerging markets. We employ a non-linear multiplicative real return calculations consistent with Fisher-parity logics for both domestic and foreign investors with a principled quantile regression, tail dependence copula analysis, and Shapley Additive Explanations (SHAP) to assess the explanatory power of macro variables. The analysis focuses on three recent and data-accessible exemplary collapse episodes: Turkey (2018), Nigeria (2020), and Pakistan (2021). Such cases, selected to align with post-2018 improvements in data standardization and crisis comparability, span varied monetary regimes and crisis triggers. Our tail-focused modeling reveals a systematic breakdown in public-equity-based purchasing power protection precisely during simultaneous macroeconomic and monetary dislocations when such protection is most needed. The findings call into question conventional inflation and devaluation hedge presumptions in equity pricing theory, emphasizing the limitations of equity-based protection and the need for context-sensitive strategies during compounded macro-financial distress.",
      "authors": [
        "Artem Alkhamov",
        "Boris Kriuk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:26:56+00:00",
          "link": "https://arxiv.org/abs/2507.13055v1",
          "size": "681kb",
          "version": "v1"
        }
      ],
      "title": "To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13055",
        "HTML": "https://arxiv.org/html/2507.13055v1",
        "PDF": "https://arxiv.org/pdf/2507.13055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the statistical hedging capabilities of equity indices during macro-financial crises. It does not deal with LLM training data processing or contribute to data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13057",
      "abstract": "We study cyclic proof systems for $\\mu\\mathsf{PA}$, an extension of Peano arithmetic by positive inductive definitions that is arithmetically equivalent to the (impredicative) subsystem of second-order arithmetic $\\Pi^1_2$-$\\mathsf{CA}_0$ by M\\\"{o}llefeld. The main result of this paper is that cyclic and inductive $\\mu\\mathsf{PA}$ have the same proof-theoretic strength. First, we translate cyclic proofs into an annotated variant based on Sprenger and Dam's systems for first-order $\\mu$-calculus, whose stronger validity condition allows for a simpler proof of soundness. We then formalise this argument within $\\Pi^1_2$-$\\mathsf{CA}_0$, leveraging M\\\"{o}llerfeld's conservativity properties. To this end, we build on prior work by Curzi and Das on the reverse mathematics of the Knaster-Tarski theorem. As a byproduct of our proof methods we show that, despite the stronger validity condition, annotated and \"plain\" cyclic proofs for $\\mu\\mathsf{PA}$ prove the same theorems. This work represents a further step in the non-wellfounded proof-theoretic analysis of theories of arithmetic via impredicative fragments of second-order arithmetic, an approach initiated by Simpson's Cyclic Arithmetic, and continued by Das and Melgaard in the context of arithmetical inductive definitions.",
      "authors": [
        "Gianluca Curzi and Lukas Melgaard"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.13057v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Cyclic proof theory of positive inductive definitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13057",
        "HTML": "https://arxiv.org/html/2507.13057v1",
        "PDF": "https://arxiv.org/pdf/2507.13057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is concerned with cyclic proof systems and proof-theoretic strength in mathematics, which has no relation to LLM training data processing or relevant data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13058",
      "abstract": "Noticing the similarity between the monotone weak distributive laws combining two layers of nondeterminism in sets and in compact Hausdorff spaces, we study whether the latter law can be obtained automatically as a weak lifting of the former. This holds partially, but does not generalize to other categories of algebras: we then characterize when exactly monotone weak distributive laws over powerset monads in categories of algebras exist, exhibiting a law combining probabilities and non-determinism in compact Hausdorff spaces and showing on the other hand that such laws do not exist in a lot of other cases.",
      "authors": [
        "Quentin Aristote (UPCit\\'e",
        "IRIF",
        "PICUBE)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:28:26+00:00",
          "link": "https://arxiv.org/abs/2507.13058v1",
          "size": "173kb",
          "version": "v1"
        }
      ],
      "title": "Monotone weak distributive laws over the lifted powerset monad in categories of algebras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13058",
        "PDF": "https://arxiv.org/pdf/2507.13058"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates monotone weak distributive laws in algebraic categories, which is unrelated to LLM training data processing or improvements in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13059",
      "abstract": "We revisit the classical friendship paradox which states that on an average one's friends have at least as many friends as oneself and generalize it to a variety of network centrality measures. In particular, we show that for any irreducible, undirected graph $G$, the \"friends-average\" of degree, eigenvector-centrality, walk-count, Katz, and PageRank centralities exceeds the global average. We show that the result follows from the variational characterisation of the eigenvector corresponding to the Perron eigenvalue.",
      "authors": [
        "Rajat Subhra Hazra",
        "Evgeny Verbitskiy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:28:42+00:00",
          "link": "https://arxiv.org/abs/2507.13059v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "The Centrality Paradox: Why Your Friends Are Always More Important",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13059",
        "HTML": "https://arxiv.org/html/2507.13059v1",
        "PDF": "https://arxiv.org/pdf/2507.13059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses network centrality measures and the classical friendship paradox, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13061",
      "abstract": "Scene understanding is one of the core tasks in computer vision, aiming to extract semantic information from images to identify objects, scene categories, and their interrelationships. Although advancements in Vision-Language Models (VLMs) have driven progress in this field, existing VLMs still face challenges in adaptation to unseen complex wide-area scenes. To address the challenges, this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to advance the adaptation of VLMs in complex wide-area scene understanding. It progressively refines the selected regions based on the proposed theoretically guaranteed importance function, which considers utility, representativeness, robustness, and synergy. Without requiring additional fine-tuning, HCS enables VLMs to achieve rapid understandings of unseen scenes at any scale using minimal interpretable regions while mitigating insufficient feature density. HCS is a plug-and-play method that is compatible with any VLM. Experiments demonstrate that HCS achieves superior performance and universality in various tasks.",
      "authors": [
        "Jingyao Wang",
        "Yiming Chen",
        "Lingyu Si",
        "Changwen Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:29:06+00:00",
          "link": "https://arxiv.org/abs/2507.13061v1",
          "size": "896kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13061",
        "HTML": "https://arxiv.org/html/2507.13061v1",
        "PDF": "https://arxiv.org/pdf/2507.13061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scene understanding in computer vision using a Hierarchical Coresets Selection mechanism, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13062",
      "abstract": "Write-ahead logs (WALs) are a fundamental fault-tolerance technique found in many areas of computer science. WALs must be reliable while maintaining high performance, because all operations will be written to the WAL to ensure their stability. Without reliability a WAL is useless, because its utility is tied to its ability to recover data after a failure. In this paper we describe our experience creating a prototype user space WAL in Rust. We observed that Rust is easy to use, compact and has a very rich set of libraries. More importantly, we have found that the overhead is minimal, with the WAL prototype operating at basically the expected performance of the stable memory device.",
      "authors": [
        "Vitor K. F. Pellegatti and Gustavo M. D. Vieira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Operating Systems (cs.OS)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.13062v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "Design and Reliability of a User Space Write-Ahead Log in Rust",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13062",
        "HTML": "https://arxiv.org/html/2507.13062v1",
        "PDF": "https://arxiv.org/pdf/2507.13062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about the design and reliability of a user space write-ahead log in Rust, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13065",
      "abstract": "Deepfake technology is often used to create non-consensual synthetic intimate imagery (NSII), mainly of celebrity women. Through Critical Discursive Psychological analysis we ask; i) how celebrities construct being targeted by deepfakes and ii) how they navigate infrastructural and social obstacles when seeking recourse. In this paper, we adopt Baumers concept of Usees (stakeholders who are non-consenting, unaware and directly targeted by technology), to understand public statements made by eight celebrity women and one non-binary individual targeted with NSII. Celebrities describe harms of being non-consensually targeted by deepfakes and the distress of becoming aware of these videos. They describe various infrastructural/social factors (e.g. blaming/ silencing narratives and the industry behind deepfake abuse) which hinder activism and recourse. This work has implications in recognizing the roles of various stakeholders in the infrastructures underlying deepfake abuse and the potential of human-computer interaction to improve existing recourses for NSII. We also contribute to understanding how false beliefs online facilitate deepfake abuse. Future work should involve interventions which challenge the values and false beliefs which motivate NSII creation/dissemination.",
      "authors": [
        "John Twomey",
        "Sarah Foley",
        "Sarah Robinson",
        "Michael Quayle",
        "Matthew Peter Aylett",
        "Conor Linehan",
        "Gillian Murphy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:31:12+00:00",
          "link": "https://arxiv.org/abs/2507.13065v1",
          "size": "427kb",
          "version": "v1"
        }
      ],
      "title": "\"What do you expect? You're part of the internet\": Analyzing Celebrities' Experiences as Usees of Deepfake Technology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13065",
        "PDF": "https://arxiv.org/pdf/2507.13065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes experiences of celebrities with deepfake technology, focusing on critical discursive psychological analysis, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13066",
      "abstract": "We consider the numerical solution of large scale time-harmonic Maxwell equations. To this day, this problem remains difficult, in particular because the equations are neither Hermitian nor semi-definite. Our approach is to compare different strategies for solving this set of equations with preconditioners that are available either in PETSc, MUMPS, or in hypre. Four different preconditioners are considered. The first is the sparse approximate inverse, which is often applied to electromagnetic problems. The second is Restricted Additive Schwarz, a domain decomposition preconditioner. The third is the Hiptmair-Xu preconditioner which is tailored to the positive Maxwell equations, a nearby problem. The final preconditioner is MUMPS's Block Low-Rank method, a compressed block procedure. We also compare the performance of this method to the standard LU factorization technique, which is a direct solver. Performance with respect to the mesh size, the number of CPU cores, the wavelength and the physical size of the domain are considered. This work in progress yields temporary conclusions in favour of the Hiptmair-Xu and the Block Low-Rank preconditioners.",
      "authors": [
        "Elise Fressart (CMAP)",
        "S\\'ebastien Dubois (CMAP)",
        "Lo\\\"ic Gouarin (X",
        "CNRS)",
        "Marc Massot (CMAP)",
        "Michel Nowak",
        "Nicole Spillane (CMAP)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:32:09+00:00",
          "link": "https://arxiv.org/abs/2507.13066v1",
          "size": "1376kb",
          "version": "v1"
        }
      ],
      "title": "High Performance Parallel Solvers for the time-harmonic Maxwell Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13066",
        "PDF": "https://arxiv.org/pdf/2507.13066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with numerical solutions for time-harmonic Maxwell equations, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13071",
      "abstract": "Let K be the unit-cube in Rn and f\\,: K $\\rightarrow$ R^n be a Morse function. We assume that the function f is given by an evaluation program $\\Gamma$ in the noisy model, i.e., the evaluation program $\\Gamma$ takes an extra parameter $\\eta$ as input and returns an approximation that is $\\eta$-close to the true value of f . In this article, we design an algorithm able to compute all local minimizers of f on K . Our algorithm takes as input $\\Gamma$, $\\eta$, a numerical accuracy parameter $\\epsilon$ as well as some extra regularity parameters which are made explicit. Under assumptions of probabilistic nature -- related to the choice of the evaluation points used to feed $\\Gamma$ --, it returns finitely many rational points of K , such that the set of balls of radius $\\epsilon$ centered at these points contains and separates the set of all local minimizers of f . Our method is based on approximation theory, yielding polynomial approximants for f , combined with computer algebra techniques for solving systems of polynomial equations. We provide bit complexity estimates for our algorithm when all regularity parameters are known. Practical experiments show that our implementation of this algorithm in the Julia package Globtim can tackle examples that were not reachable until now.",
      "authors": [
        "Mohab Safey El Din (PolSys)",
        "Georgy Scholten",
        "Emmanuel Tr\\'elat (LJLL (UMR\\_7598)",
        "CaGE)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:40:14+00:00",
          "link": "https://arxiv.org/abs/2507.13071v1",
          "size": "3867kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic algorithm for computing all local minimizers of Morse functions on a compact domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13071",
        "PDF": "https://arxiv.org/pdf/2507.13071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a probabilistic algorithm for computing local minimizers of Morse functions on a compact domain. It deals with numerical algorithms and approximation theory, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13073",
      "abstract": "Traffic Movement Count (TMC) at intersections is crucial for optimizing signal timings, assessing the performance of existing traffic control measures, and proposing efficient lane configurations to minimize delays, reduce congestion, and promote safety. Traditionally, methods such as manual counting, loop detectors, pneumatic road tubes, and camera-based recognition have been used for TMC estimation. Although generally reliable, camera-based TMC estimation is prone to inaccuracies under poor lighting conditions during harsh weather and nighttime. In contrast, Light Detection and Ranging (LiDAR) technology is gaining popularity in recent times due to reduced costs and its expanding use in 3D object detection, tracking, and related applications. This paper presents the authors' endeavor to develop, deploy and evaluate a dual-LiDAR system at an intersection in the city of Rialto, California, for TMC estimation. The 3D bounding box detections from the two LiDARs are used to classify vehicle counts based on traffic directions, vehicle movements, and vehicle classes. This work discusses the estimated TMC results and provides insights into the observed trends and irregularities. Potential improvements are also discussed that could enhance not only TMC estimation, but also trajectory forecasting and intent prediction at intersections.",
      "authors": [
        "Saswat Priyadarshi Nayak",
        "Guoyuan Wu",
        "Kanok Boriboonsomsin",
        "Matthew Barth"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:42:28+00:00",
          "link": "https://arxiv.org/abs/2507.13073v1",
          "size": "5516kb",
          "version": "v1"
        }
      ],
      "title": "Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13073",
        "PDF": "https://arxiv.org/pdf/2507.13073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a dual LiDAR-based system for traffic movement count estimation. It focuses on deployment, data collection, and analysis for traffic systems, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13074",
      "abstract": "Dataset distillation (DD) aims to generate a compact yet informative dataset that achieves performance comparable to the original dataset, thereby reducing demands on storage and computational resources. Although diffusion models have made significant progress in dataset distillation, the generated surrogate datasets often contain samples with label inconsistencies or insufficient structural detail, leading to suboptimal downstream performance. To address these issues, we propose a detector-guided dataset distillation framework that explicitly leverages a pre-trained detector to identify and refine anomalous synthetic samples, thereby ensuring label consistency and improving image quality. Specifically, a detector model trained on the original dataset is employed to identify anomalous images exhibiting label mismatches or low classification confidence. For each defective image, multiple candidates are generated using a pre-trained diffusion model conditioned on the corresponding image prototype and label. The optimal candidate is then selected by jointly considering the detector's confidence score and dissimilarity to existing qualified synthetic samples, thereby ensuring both label accuracy and intra-class diversity. Experimental results demonstrate that our method can synthesize high-quality representative images with richer details, achieving state-of-the-art performance on the validation set.",
      "authors": [
        "Yawen Zou",
        "Guang Li",
        "Zi Wang",
        "Chunzhi Gu",
        "Chao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:42:54+00:00",
          "link": "https://arxiv.org/abs/2507.13074v1",
          "size": "916kb",
          "version": "v1"
        }
      ],
      "title": "Label-Consistent Dataset Distillation with Detector-Guided Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13074",
        "HTML": "https://arxiv.org/html/2507.13074v1",
        "PDF": "https://arxiv.org/pdf/2507.13074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses dataset distillation to create compact datasets. While this involves data refinement and quality improvement, it primarily targets image datasets and not LLM-specific training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13076",
      "abstract": "Organizations face an ever-changing threat landscape. They must continuously dedicate significant efforts to protect their assets, making their adoption of increased cybersecurity automation inevitable. However, process automation requires formalization of input data. Through this paper, we address this need for processes that use attack scenarios as input. Among these processes, one can mention both the generation of scripts for attack simulation and training purposes, as well as the analysis of attacks. Therefore, the paper's main research contribution is a novel formal model that encompasses the attack's context description and its scenario. It is abstracted using UML class model. Once the description of our model done, we will show how it could serve an upstream attack analysis process. We will show also its use for an automatic generation of attack scripts in the context of cybersecurity training. These two uses cases constitute the second contribution of this present research work.",
      "authors": [
        "Quentin Goux (CEDRIC - ISID)",
        "Nadira Lammari (CEDRIC - ISID)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:45:37+00:00",
          "link": "https://arxiv.org/abs/2507.13076v1",
          "size": "1187kb",
          "version": "v1"
        }
      ],
      "title": "Formalizing Attack Scenario Description: A Proposed Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13076",
        "PDF": "https://arxiv.org/pdf/2507.13076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on formalizing attack scenario descriptions for cybersecurity applications, including script generation for attack simulations. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13079",
      "abstract": "Designing effective neural networks is a cornerstone of deep learning, and Neural Architecture Search (NAS) has emerged as a powerful tool for automating this process. Among the existing NAS approaches, Differentiable Architecture Search (DARTS) has gained prominence for its efficiency and ease of use, inspiring numerous advancements. Since the rise of Vision Transformers (ViT), researchers have applied NAS to explore ViT architectures, often focusing on macro-level search spaces and relying on discrete methods like evolutionary algorithms. While these methods ensure reliability, they face challenges in discovering innovative architectural designs, demand extensive computational resources, and are time-intensive. To address these limitations, we introduce Differentiable Architecture Search for Vision Transformer (DASViT), which bridges the gap in differentiable search for ViTs and uncovers novel designs. Experiments show that DASViT delivers architectures that break traditional Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and achieve superior efficiency with fewer parameters and FLOPs.",
      "authors": [
        "Pengjin Wu",
        "Ferrante Neri and Zhenhua Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:48:00+00:00",
          "link": "https://arxiv.org/abs/2507.13079v1",
          "size": "1784kb",
          "version": "v1"
        }
      ],
      "title": "DASViT: Differentiable Architecture Search for Vision Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13079",
        "HTML": "https://arxiv.org/html/2507.13079v1",
        "PDF": "https://arxiv.org/pdf/2507.13079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Differentiable Architecture Search for Vision Transformers, which involves designing neural network architectures. This is not related to data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13081",
      "abstract": "Requirements development is a critical phase as it is responsible for providing a clear understanding of what stakeholders need. It involves collaboration among stakeholders to extract explicit requirements and address potential conflicts, which is time-consuming and labor-intensive. Recently, multi-agent systems for software development have attracted much attention. However, existing research provides limited support for requirements development and overlooks the injection of human knowledge into agents and the human-agent collaboration. % To address these issues, this paper proposes a knowledge-driven multi-agent framework for intelligent requirement development, named iReDev. iReDev features: iReDev consists of six knowledge-driven agents to support the entire requirements development. They collaboratively perform various tasks to produce a software requirements specification. iReDev focuses on integrating human knowledge for agents, enabling them to simulate real-world stakeholders. iReDev uses an event-driven communication mechanism based on an artifact pool. Agents continuously monitor the pool and autonomously trigger the next action based on its changes, enabling iReDev to handle new requirements quickly. iReDev introduces a human-in-the-loop mechanism to support human-agent collaboration, ensuring that the generated artifacts align with the expectations of stakeholders. We evaluated the generated artifacts and results show that iReDev outperforms existing baselines in multiple aspects. We further envision three key directions and hope this work can facilitate the development of intelligent requirements development.",
      "authors": [
        "Dongming Jin and Weisong Sun and Jiangping Huang and Peng Liang and Jifeng Xuan and Yang Liu and Zhi Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:51:07+00:00",
          "link": "https://arxiv.org/abs/2507.13081v1",
          "size": "410kb",
          "version": "v1"
        }
      ],
      "title": "iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13081",
        "HTML": "https://arxiv.org/html/2507.13081v1",
        "PDF": "https://arxiv.org/pdf/2507.13081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for intelligent requirements development in software engineering, using multi-agent systems and human-agent collaboration. It does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13082",
      "abstract": "For safety-critical robotics applications such as autonomous driving, it is important to detect all required objects accurately in real-time. Motion segmentation offers a solution by identifying dynamic objects from the scene in a class-agnostic manner. Recently, various motion segmentation models have been proposed, most of which jointly use subnetworks to estimate Depth, Pose, Optical Flow, and Scene Flow. As a result, the overall computational cost of the model increases, hindering real-time performance.\n  In this paper, we propose a novel cost-volume-based motion feature representation, Channel-wise Motion Features. By extracting depth features of each instance in the feature map and capturing the scene's 3D motion information, it offers enhanced efficiency. The only subnetwork used to build Channel-wise Motion Features is the Pose Network, and no others are required. Our method not only achieves about 4 times the FPS of state-of-the-art models in the KITTI Dataset and Cityscapes of the VCAS-Motion Dataset, but also demonstrates equivalent accuracy while reducing the parameters to about 25$\\%$.",
      "authors": [
        "Riku Inoue",
        "Masamitsu Tsuchiya",
        "Yuji Yasui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:53:38+00:00",
          "link": "https://arxiv.org/abs/2507.13082v1",
          "size": "4626kb",
          "version": "v1"
        }
      ],
      "title": "Channel-wise Motion Features for Efficient Motion Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13082",
        "HTML": "https://arxiv.org/html/2507.13082v1",
        "PDF": "https://arxiv.org/pdf/2507.13082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about motion segmentation for robotics applications and introduces a novel motion feature representation. It does not relate to LLM training data processing or its methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13085",
      "abstract": "Open World Object Detection (OWOD) is a challenging computer vision task that extends standard object detection by (1) detecting and classifying unknown objects without supervision, and (2) incrementally learning new object classes without forgetting previously learned ones. The absence of ground truths for unknown objects makes OWOD tasks particularly challenging. Many methods have addressed this by using pseudo-labels for unknown objects. The recently proposed Probabilistic Objectness transformer-based open-world detector (PROB) is a state-of-the-art model that does not require pseudo-labels for unknown objects, as it predicts probabilistic objectness. However, this method faces issues with learning conflicts between objectness and class predictions.\n  To address this issue and further enhance performance, we propose a novel model, Decoupled PROB. Decoupled PROB introduces Early Termination of Objectness Prediction (ETOP) to stop objectness predictions at appropriate layers in the decoder, resolving the learning conflicts between class and objectness predictions in PROB. Additionally, we introduce Task-Decoupled Query Initialization (TDQI), which efficiently extracts features of known and unknown objects, thereby improving performance. TDQI is a query initialization method that combines query selection and learnable queries, and it is a module that can be easily integrated into existing DETR-based OWOD models. Extensive experiments on OWOD benchmarks demonstrate that Decoupled PROB surpasses all existing methods across several metrics, significantly improving performance.",
      "authors": [
        "Riku Inoue",
        "Masamitsu Tsuchiya",
        "Yuji Yasui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.13085v1",
          "size": "18824kb",
          "version": "v1"
        }
      ],
      "title": "Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13085",
        "HTML": "https://arxiv.org/html/2507.13085v1",
        "PDF": "https://arxiv.org/pdf/2507.13085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on open-world object detection in computer vision, proposing enhancements in detection methods. There is no connection to LLM training data processing decisions or developments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13087",
      "abstract": "Annotation variability remains a substantial challenge in medical image segmentation, stemming from ambiguous imaging boundaries and diverse clinical expertise. Traditional deep learning methods producing single deterministic segmentation predictions often fail to capture these annotator biases. Although recent studies have explored multi-rater segmentation, existing methods typically focus on a single perspective -- either generating a probabilistic ``gold standard'' consensus or preserving expert-specific preferences -- thus struggling to provide a more omni view. In this study, we propose DiffOSeg, a two-stage diffusion-based framework, which aims to simultaneously achieve both consensus-driven (combining all experts' opinions) and preference-driven (reflecting experts' individual assessments) segmentation. Stage I establishes population consensus through a probabilistic consensus strategy, while Stage II captures expert-specific preference via adaptive prompts. Demonstrated on two public datasets (LIDC-IDRI and NPC-170), our model outperforms existing state-of-the-art methods across all evaluated metrics. Source code is available at https://github.com/string-ellipses/DiffOSeg .",
      "authors": [
        "Han Zhang",
        "Xiangde Luo",
        "Yong Chen",
        "and Kang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:57:27+00:00",
          "link": "https://arxiv.org/abs/2507.13087v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13087",
        "HTML": "https://arxiv.org/html/2507.13087v1",
        "PDF": "https://arxiv.org/pdf/2507.13087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for medical image segmentation using a diffusion model. It is not related to LLM training data processing or improvements in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13088",
      "abstract": "The computational burden of model predictive control (MPC) limits its application on real-time systems, such as robots, and often requires the use of short prediction horizons. This not only affects the control performance, but also increases the difficulty of designing MPC cost functions that reflect the desired long-term objective. This paper proposes ZipMPC, a method that imitates a long-horizon MPC behaviour by learning a compressed and context-dependent cost function for a short-horizon MPC. It improves performance over alternative methods, such as approximate explicit MPC and automatic cost parameter tuning, in particular in terms of i) optimizing the long term objective; ii) maintaining computational costs comparable to a short-horizon MPC; iii) ensuring constraint satisfaction; and iv) generalizing control behaviour to environments not observed during training. For this purpose, ZipMPC leverages the concept of differentiable MPC with neural networks to propagate gradients of the imitation loss through the MPC optimization. We validate our proposed method in simulation and real-world experiments on autonomous racing. ZipMPC consistently completes laps faster than selected baselines, achieving lap times close to the long-horizon MPC baseline. In challenging scenarios where the short-horizon MPC baseline fails to complete a lap, ZipMPC is able to do so. In particular, these performance gains are also observed on tracks unseen during training.",
      "authors": [
        "Rahel Rickenbach",
        "Alan A. Lahoud",
        "Erik Schaffernicht",
        "Melanie N. Zeilinger",
        "Johannes A. Stork"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:58:11+00:00",
          "link": "https://arxiv.org/abs/2507.13088v1",
          "size": "19330kb",
          "version": "v1"
        }
      ],
      "title": "ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13088",
        "HTML": "https://arxiv.org/html/2507.13088v1",
        "PDF": "https://arxiv.org/pdf/2507.13088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses improving model predictive control (MPC) for autonomous systems through compressed cost functions and imitation learning, but does not involve LLM training data processing or associated methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13089",
      "abstract": "Pre-trained vision-language models, such as CLIP, show impressive zero-shot recognition ability and can be easily transferred to specific downstream tasks via prompt tuning, even with limited training data. However, existing prompt tuning methods face two main challenges: (1) In few-shot scenarios, data scarcity often leads to overfitting, making the model sensitive to changes in the input domain. (2) To mitigate overfitting, these methods typically rely on complex task-specific model architectures and sensitive hyperparameter tuning, severely restricting their general applicability. To address these issues, we propose a simpler and more general framework called GLAD (Generalizable LoRA tuning with RegulArized GraDient). We show that merely applying LoRA achieves performance in downstream tasks comparable to current state-of-the-art prompt-based methods. While LoRA is effective and easy to use, it remains susceptible to overfitting in few-shot learning scenarios. To mitigate this risk, we introduce a gradient-based regularization technique. This technique effectively steers the optimization trajectory, encouraging the model to find a more stable parameter region that is robust to variations in data distribution. Through extensive experiments conducted on 15 benchmark datasets, we demonstrate that GLAD outperforms previous tuning approaches in terms of base-to-novel class generalization, image domain generalization, and cross-dataset generalization. The code will be publicly available.",
      "authors": [
        "Yuqi Peng",
        "Pengfei Wang",
        "Jianzhuang Liu",
        "Shifeng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:58:15+00:00",
          "link": "https://arxiv.org/abs/2507.13089v1",
          "size": "305kb",
          "version": "v1"
        }
      ],
      "title": "GLAD: Generalizable Tuning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13089",
        "HTML": "https://arxiv.org/html/2507.13089v1",
        "PDF": "https://arxiv.org/pdf/2507.13089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vision-language model adaptation and proposes a tuning framework called GLAD, primarily addressing overfitting issues and generalization. It does not make contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13090",
      "abstract": "Robust XAI techniques should ideally be simultaneously deterministic, model agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability technique, with guaranteed convergency. MUPAX measure theoretic formulation gives principled feature importance attribution through structured perturbation analysis that discovers inherent input patterns and eliminates spurious relationships. We evaluate MUPAX on an extensive range of data modalities and tasks: audio classification (1D), image classification (2D), volumetric medical image analysis (3D), and anatomical landmark detection, demonstrating dimension agnostic effectiveness. The rigorous convergence guarantees extend to any loss function and arbitrary dimensions, making MUPAX applicable to virtually any problem context for AI. By contrast with other XAI methods that typically decrease performance when masking, MUPAX not only preserves but actually enhances model accuracy by capturing only the most important patterns of the original data. Extensive benchmarking against the state of the XAI art demonstrates MUPAX ability to generate precise, consistent and understandable explanations, a crucial step towards explainable and trustworthy AI systems. The source code will be released upon publication.",
      "authors": [
        "Vincenzo Dentamaro",
        "Felice Franchini",
        "Giuseppe Pirlo",
        "Irina Voiculescu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:59:27+00:00",
          "link": "https://arxiv.org/abs/2507.13090v1",
          "size": "10127kb",
          "version": "v1"
        }
      ],
      "title": "MUPAX: Multidimensional Problem Agnostic eXplainable AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13090",
        "HTML": "https://arxiv.org/html/2507.13090v1",
        "PDF": "https://arxiv.org/pdf/2507.13090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MUPAX, an explainable AI technique focusing on model agnosticism and deterministic attribution. It is concerned with feature importance and explainability, unrelated to any LLM training data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13091",
      "abstract": "We present the first mechanized, succinct, practical, complete, and proven-faithful semantics for a modern regular expression language with backtracking semantics. We ensure its faithfulness by proving it equivalent to a preexisting line-by-line embedding of the official ECMAScript specification of JavaScript regular expressions. We demonstrate its practicality by presenting two real-world applications. First, a new notion of contextual equivalence for modern regular expressions, which we use to prove or disprove rewrites drawn from previous work. Second, the first formal proof of the PikeVM algorithm used in many real-world engines. In contrast with the specification and other formalization work, our semantics captures not only the top-priority match, but a full backtracking tree recording all possible matches and their respective priority. All our definitions and results have been mechanized in the Rocq proof assistant.",
      "authors": [
        "Aur\\`ele Barri\\`ere",
        "Victor Deng",
        "Cl\\'ement Pit-Claudel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:02:00+00:00",
          "link": "https://arxiv.org/abs/2507.13091v1",
          "size": "98kb",
          "version": "v1"
        }
      ],
      "title": "Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13091",
        "HTML": "https://arxiv.org/html/2507.13091v1",
        "PDF": "https://arxiv.org/pdf/2507.13091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a formal verification framework for JavaScript regular expressions, unrelated to LLM training data processing. Its focus is on proving semantics for regular expressions, with no mention of data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13092",
      "abstract": "Electroencephalography (EEG) is a fundamental modality for cognitive state monitoring in brain-computer interfaces (BCIs). However, it is highly susceptible to intrinsic signal errors and human-induced labeling errors, which lead to label noise and ultimately degrade model performance. To enhance EEG learning, multimodal knowledge distillation (KD) has been explored to transfer knowledge from visual models with rich representations to EEG-based models. Nevertheless, KD faces two key challenges: modality gap and soft label misalignment. The former arises from the heterogeneous nature of EEG and visual feature spaces, while the latter stems from label inconsistencies that create discrepancies between ground truth labels and distillation targets. This paper addresses semantic uncertainty caused by ambiguous features and weakly defined labels. We propose a novel cross-modal knowledge distillation framework that mitigates both modality and label inconsistencies. It aligns feature semantics through a prototype-based similarity module and introduces a task-specific distillation head to resolve label-induced inconsistency in supervision. Experimental results demonstrate that our approach improves EEG-based emotion regression and classification performance, outperforming both unimodal and multimodal baselines on a public multimodal dataset. These findings highlight the potential of our framework for BCI applications.",
      "authors": [
        "Hyo-Jeong Jang",
        "Hye-Bin Shin",
        "Seong-Whan Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:03:20+00:00",
          "link": "https://arxiv.org/abs/2507.13092v1",
          "size": "495kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13092",
        "HTML": "https://arxiv.org/html/2507.13092v1",
        "PDF": "https://arxiv.org/pdf/2507.13092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses knowledge distillation for brain-computer interfaces using EEG data, addressing challenges like modality and label inconsistencies. It does not focus on LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13095",
      "abstract": "Recent advances in large pretrained models have led to their widespread integration as core components in modern software systems. The trend is expected to continue in the foreseeable future. Unlike traditional software systems governed by deterministic logic, systems powered by pretrained models exhibit distinctive and emergent characteristics, such as ambiguous capability boundaries, context-dependent behavior, and continuous evolution. These properties fundamentally challenge long-standing assumptions in requirements engineering, including functional decomposability and behavioral predictability. This paper investigates this problem and advocates for a rethinking of existing requirements engineering methodologies. We propose a conceptual framework tailored to requirements engineering of pretrained-model-enabled software systems and outline several promising research directions within this framework. This vision helps provide a guide for researchers and practitioners to tackle the emerging challenges in requirements engineering of pretrained-model-enabled systems.",
      "authors": [
        "Dongming Jin and Zhi Jin and Linyu Li and Xiaohong Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:06:25+00:00",
          "link": "https://arxiv.org/abs/2507.13095v1",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "title": "A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13095",
        "HTML": "https://arxiv.org/html/2507.13095v1",
        "PDF": "https://arxiv.org/pdf/2507.13095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on requirements engineering for systems that integrate pretrained models but does not address data processing for pretraining or fine-tuning LLMs specifically, making it irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13096",
      "abstract": "Tutte's celebrated barycentric embedding theorem describes a natural way to build straight-line embeddings (crossing-free drawings) of a (3-connected) planar graph: map the vertices of the outer face to the vertices of a convex polygon, and ensure that each remaining vertex is in convex position, namely, a barycenter with positive coefficients of its neighbors. Actually computing an embedding then boils down to solving a system of linear equations. A particularly appealing feature of this method is the flexibility given by the choice of the barycentric weights. Generalizations of Tutte's theorem to surfaces of nonpositive curvature are known, but due to their inherently continuous nature, they do not lead to an algorithm.\n  In this paper, we propose a purely discrete analog of Tutte's theorem for surfaces (with or without boundary) of nonpositive curvature, based on the recently introduced notion of reducing triangulations. We prove a Tutte theorem in this setting: every drawing homotopic to an embedding such that each vertex is harmonious (a discrete analog of being in convex position) is a weak embedding (arbitrarily close to an embedding). We also provide a polynomial-time algorithm to make an input drawing harmonious without increasing the length of any edge, in a similar way as a drawing can be put in convex position without increasing the edge lengths.",
      "authors": [
        "\\'Eric Colin de Verdi\\`ere",
        "Vincent Despr\\'e",
        "Lo\\\"ic Dubois"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.13096v1",
          "size": "2135kb",
          "version": "v1"
        }
      ],
      "title": "A Discrete Analog of Tutte's Barycentric Embeddings on Surfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13096",
        "HTML": "https://arxiv.org/html/2507.13096v1",
        "PDF": "https://arxiv.org/pdf/2507.13096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about a discrete analog of Tutte's barycentric embeddings on surfaces, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13097",
      "abstract": "Grasping is a fundamental robot skill, yet despite significant research advancements, learning-based 6-DOF grasping approaches are still not turnkey and struggle to generalize across different embodiments and in-the-wild settings. We build upon the recent success on modeling the object-centric grasp generation process as an iterative diffusion process. Our proposed framework, GraspGen, consists of a DiffusionTransformer architecture that enhances grasp generation, paired with an efficient discriminator to score and filter sampled grasps. We introduce a novel and performant on-generator training recipe for the discriminator. To scale GraspGen to both objects and grippers, we release a new simulated dataset consisting of over 53 million grasps. We demonstrate that GraspGen outperforms prior methods in simulations with singulated objects across different grippers, achieves state-of-the-art performance on the FetchBench grasping benchmark, and performs well on a real robot with noisy visual observations.",
      "authors": [
        "Adithyavairavan Murali and Balakumar Sundaralingam and Yu-Wei Chao and Wentao Yuan and Jun Yamada and Mark Carlson and Fabio Ramos and Stan Birchfield and Dieter Fox and Clemens Eppner"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:09:28+00:00",
          "link": "https://arxiv.org/abs/2507.13097v1",
          "size": "10857kb",
          "version": "v1"
        }
      ],
      "title": "GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13097",
        "HTML": "https://arxiv.org/html/2507.13097v1",
        "PDF": "https://arxiv.org/pdf/2507.13097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new dataset for robot grasping, it mainly focuses on a diffusion-based framework for grasp generation and evaluation, with the dataset serving as a tool rather than the primary contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13100",
      "abstract": "Shared Mobility Services (SMS), e.g., demand-responsive transport or ride-sharing, can improve mobility in low-density areas, which are often poorly served by conventional Public Transport (PT). Such improvement is generally measured via basic performance indicators, such as waiting or travel time. However, such basic indicators do not account for the most important contribution that SMS can provide to territories, i.e., increasing the potential, for users, to reach surrounding opportunities, such as jobs, schools, businesses, etc. Such potential can be measured by isochrone-based accessibility indicators, which count the number of opportunities reachable in a limited time, and are thus easy for the public to understand. %\nThe potential impact of SMS on accessibility has been qualitatively discussed and implications on equity have been empirically studied. However, to date, there are no quantitative methods to compute isochrone-based indicators of the accessibility achieved via SMS.\n  This work fills this gap by proposing a first method to compute isochrone accessibility of PT systems composed of conventional PT and SMS, acting as a feeder for access and egress trips to/from PT hubs. This method is grounded on spatial-temporal statistical analysis, performed via Kriging. It takes as input observed trips of SMS and summarizes them in a graph. On such a graph, isochrone accessibility indicators are computed. We apply the proposed method to a MATSim simulation study concerning demand-responsive transport integrated into PT, in the suburban area of Paris-Saclay.",
      "authors": [
        "Severin Diepolder",
        "Andrea Araldo",
        "Tarek Chouaki",
        "Santa Maiti",
        "Sebastian H\\\"orl",
        "Constantinos Antoniou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:13:45+00:00",
          "link": "https://arxiv.org/abs/2507.13100v1",
          "size": "8062kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13100",
        "HTML": "https://arxiv.org/html/2507.13100v1",
        "PDF": "https://arxiv.org/pdf/2507.13100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for computing accessibility metrics for shared mobility services, but it does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13105",
      "abstract": "We introduce SemCSE, an unsupervised method for learning semantic embeddings of scientific texts. Building on recent advances in contrastive learning for text embeddings, our approach leverages LLM-generated summaries of scientific abstracts to train a model that positions semantically related summaries closer together in the embedding space. This resulting objective ensures that the model captures the true semantic content of a text, in contrast to traditional citation-based approaches that do not necessarily reflect semantic similarity. To validate this, we propose a novel benchmark designed to assess a model's ability to understand and encode the semantic content of scientific texts, demonstrating that our method enforces a stronger semantic separation within the embedding space. Additionally, we evaluate SemCSE on the comprehensive SciRepEval benchmark for scientific text embeddings, where it achieves state-of-the-art performance among models of its size, thus highlighting the benefits of a semantically focused training approach.",
      "authors": [
        "Marc Brinner and Sina Zarriess"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:19:50+00:00",
          "link": "https://arxiv.org/abs/2507.13105v1",
          "size": "1308kb",
          "version": "v1"
        }
      ],
      "title": "SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13105",
        "HTML": "https://arxiv.org/html/2507.13105v1",
        "PDF": "https://arxiv.org/pdf/2507.13105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method for semantic embeddings using LLM-generated summaries and evaluates it on scientific texts, which includes data generation and embedding quality improvement, but its focus is not on LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13106",
      "abstract": "Fetal lung maturity is a critical indicator for predicting neonatal outcomes and the need for post-natal intervention, especially for pregnancies affected by fetal growth restriction. Intra-voxel incoherent motion analysis has shown promising results for non-invasive assessment of fetal lung development, but its reliance on manual segmentation is time-consuming, thus limiting its clinical applicability. In this work, we present an automated lung maturity evaluation pipeline for diffusion-weighted magnetic resonance images that consists of a deep learning-based fetal lung segmentation model and a model-fitting lung maturity assessment. A 3D nnU-Net model was trained on manually segmented images selected from the baseline frames of 4D diffusion-weighted MRI scans. The segmentation model demonstrated robust performance, yielding a mean Dice coefficient of 82.14%. Next, voxel-wise model fitting was performed based on both the nnU-Net-predicted and manual lung segmentations to quantify IVIM parameters reflecting tissue microstructure and perfusion. The results suggested no differences between the two. Our work shows that a fully automated pipeline is possible for supporting fetal lung maturity assessment and clinical decision-making.",
      "authors": [
        "Zhennan Xiao",
        "Katharine Brudkiewicz",
        "Zhen Yuan",
        "Rosalind Aughwane",
        "Magdalena Sokolska",
        "Joanna Chappell",
        "Trevor Gaunt",
        "Anna L. David",
        "Andrew P. King",
        "and Andrew Melbourne"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:21:42+00:00",
          "link": "https://arxiv.org/abs/2507.13106v1",
          "size": "268kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13106",
        "HTML": "https://arxiv.org/html/2507.13106v1",
        "PDF": "https://arxiv.org/pdf/2507.13106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep learning-based method for fetal lung segmentation and maturity evaluation from MRI images, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13107",
      "abstract": "Enabling large-scale generative models to continuously learn new visual concepts is essential for personalizing pre-trained models to meet individual user preferences. Existing approaches for continual visual concept learning are constrained by two fundamental challenges: catastrophic forgetting and parameter expansion. In this paper, we propose Redundancy-Removal Mixture of Experts (R^2MoE), a parameter-efficient framework for lifelong visual concept learning that effectively learns new concepts while incurring minimal parameter overhead. Our framework includes three key innovative contributions: First, we propose a mixture-of-experts framework with a routing distillation mechanism that enables experts to acquire concept-specific knowledge while preserving the gating network's routing capability, thereby effectively mitigating catastrophic forgetting. Second, we propose a strategy for eliminating redundant layer-wise experts that reduces the number of expert parameters by fully utilizing previously learned experts. Third, we employ a hierarchical local attention-guided inference approach to mitigate interference between generated visual concepts. Extensive experiments have demonstrated that our method generates images with superior conceptual fidelity compared to the state-of-the-art (SOTA) method, achieving an impressive 87.8\\% reduction in forgetting rates and 63.3\\% fewer parameters on the CustomConcept 101 dataset. Our code is available at {https://github.com/learninginvision/R2MoE}",
      "authors": [
        "Xiaohan Guo",
        "Yusong Cai",
        "Zejia Liu",
        "Zhengning Wang",
        "Lili Pan",
        "Hongliang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:22:40+00:00",
          "link": "https://arxiv.org/abs/2507.13107v1",
          "size": "4400kb",
          "version": "v1"
        }
      ],
      "title": "R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13107",
        "HTML": "https://arxiv.org/html/2507.13107v1",
        "PDF": "https://arxiv.org/pdf/2507.13107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for lifelong learning of visual concepts, focusing on model architecture and parameter efficiency, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13108",
      "abstract": "We study the stability of one-dimensional linear scalar lattice Boltzmann schemes for hyperbolic equations with respect to boundary data. Our approach is based on the original raw algorithm on several unknowns, thereby avoiding the need for a transformation into an equivalent scalar formulation-a challenging process in presence of boundaries. To address different behaviors exhibited by the numerical scheme, we introduce appropriate notions of strong stability. They account for the potential absence of a continuous extension of the stable vector bundle associated with the bulk scheme on the unit circle for certain components. Rather than developing a general theory, complicated by the fact that discrete boundaries in lattice Boltzmann schemes are inherently characteristic, we focus on strong stability-instability for methods whose characteristic equations have stencils of breadth one to the left. In this context, we study three representative schemes. These are endowed with various boundary conditions drawn from the literature, and our theoretical results are supported by numerical simulations.",
      "authors": [
        "Thomas Bellotti (EM2C)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:22:42+00:00",
          "link": "https://arxiv.org/abs/2507.13108v1",
          "size": "1782kb",
          "version": "v1"
        }
      ],
      "title": "Stability of lattice Boltzmann schemes for initial boundary value problems in raw formulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13108",
        "PDF": "https://arxiv.org/pdf/2507.13108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses lattice Boltzmann schemes for boundary value problems, which pertains to numerical methods for differential equations rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13110",
      "abstract": "High-resolution 3D point clouds are highly effective for detecting subtle structural anomalies in industrial inspection. However, their dense and irregular nature imposes significant challenges, including high computational cost, sensitivity to spatial misalignment, and difficulty in capturing localized structural differences. This paper introduces a registration-based anomaly detection framework that combines multi-prototype alignment with cluster-wise discrepancy analysis to enable precise 3D anomaly localization. Specifically, each test sample is first registered to multiple normal prototypes to enable direct structural comparison. To evaluate anomalies at a local level, clustering is performed over the point cloud, and similarity is computed between features from the test sample and the prototypes within each cluster. Rather than selecting cluster centroids randomly, a keypoint-guided strategy is employed, where geometrically informative points are chosen as centroids. This ensures that clusters are centered on feature-rich regions, enabling more meaningful and stable distance-based comparisons. Extensive experiments on the Real3D-AD benchmark demonstrate that the proposed method achieves state-of-the-art performance in both object-level and point-level anomaly detection, even using only raw features.",
      "authors": [
        "Zi Wang",
        "Katsuya Hotta",
        "Koichiro Kamide",
        "Yawen Zou",
        "Chao Zhang",
        "Jun Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:25:17+00:00",
          "link": "https://arxiv.org/abs/2507.13110v1",
          "size": "885kb",
          "version": "v1"
        }
      ],
      "title": "3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13110",
        "HTML": "https://arxiv.org/html/2507.13110v1",
        "PDF": "https://arxiv.org/pdf/2507.13110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses anomaly detection in 3D point clouds, focusing on structural comparison between test samples and prototypes, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13112",
      "abstract": "The study \"Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data\" presents a machine learning-based traffic flow prediction model to address global traffic congestion issues. The research utilized 30-second interval traffic data from California Highway 78 over a five-month period from July to November 2022, analyzing a 7.24 km westbound section connecting \"Melrose Dr\" and \"El-Camino Real\" in the San Diego area. The study employed Multiple Linear Regression (MLR) and Random Forest (RF) algorithms, analyzing data collection intervals ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance metrics, the analysis revealed that both MLR and RF models performed optimally with 10-minute data collection intervals. These findings are expected to contribute to future traffic congestion solutions and efficient traffic management.",
      "authors": [
        "Junseong Lee",
        "Jaegwan Cho",
        "Yoonju Cho",
        "Seoyoon Choi",
        "Yejin Shin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:27:38+00:00",
          "link": "https://arxiv.org/abs/2507.13112v1",
          "size": "913kb",
          "version": "v1"
        }
      ],
      "title": "Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13112",
        "HTML": "https://arxiv.org/html/2507.13112v1",
        "PDF": "https://arxiv.org/pdf/2507.13112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves using machine learning algorithms for predicting highway traffic flow based on traffic data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13113",
      "abstract": "IRSTD (InfraRed Small Target Detection) detects small targets in infrared blurry backgrounds and is essential for various applications. The detection task is challenging due to the small size of the targets and their sparse distribution in infrared small target datasets. Although existing IRSTD methods and datasets have led to significant advancements, they are limited by their reliance solely on the image modality. Recent advances in deep learning and large vision-language models have shown remarkable performance in various visual recognition tasks. In this work, we propose a novel multimodal IRSTD framework that incorporates language priors to guide small target detection. We leverage language-guided attention weights derived from the language prior to enhance the model's ability for IRSTD, presenting a novel approach that combines textual information with image data to improve IRSTD capabilities. Utilizing the state-of-the-art GPT-4 vision model, we generate text descriptions that provide the locations of small targets in infrared images, employing careful prompt engineering to ensure improved accuracy. Due to the absence of multimodal IR datasets, existing IRSTD methods rely solely on image data. To address this shortcoming, we have curated a multimodal infrared dataset that includes both image and text modalities for small target detection, expanding upon the popular IRSTD-1k and NUDT-SIRST datasets. We validate the effectiveness of our approach through extensive experiments and comprehensive ablation studies. The results demonstrate significant improvements over the state-of-the-art method, with relative percentage differences of 9.74%, 13.02%, 1.25%, and 67.87% in IoU, nIoU, Pd, and Fa on the NUAA-SIRST subset, and 4.41%, 2.04%, 2.01%, and 113.43% on the IRSTD-1k subset of the LangIR dataset, respectively.",
      "authors": [
        "Pranav Singh and Pravendra Singh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:29:09+00:00",
          "link": "https://arxiv.org/abs/2507.13113v1",
          "size": "11895kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Language Prior for Infrared Small Target Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13113",
        "HTML": "https://arxiv.org/html/2507.13113v1",
        "PDF": "https://arxiv.org/pdf/2507.13113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a multimodal infrared dataset, which includes textual information for infrared small target detection. It involves expanding existing datasets by incorporating text, aligning with LLM data processing to some extent, but the main focus is on infrared small target detection rather than LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13115",
      "abstract": "This Ph.D. proposal introduces a plan to develop a computational framework to identify Self-aspects in text. The Self is a multifaceted construct and it is reflected in language. While it is described across disciplines like cognitive science and phenomenology, it remains underexplored in natural language processing (NLP). Many of the aspects of the Self align with psychological and other well-researched phenomena (e.g., those related to mental health), highlighting the need for systematic NLP-based analysis. In line with this, we plan to introduce an ontology of Self-aspects and a gold-standard annotated dataset. Using this foundation, we will develop and evaluate conventional discriminative models, generative large language models, and embedding-based retrieval approaches against four main criteria: interpretability, ground-truth adherence, accuracy, and computational efficiency. Top-performing models will be applied in case studies in mental health and empirical phenomenology.",
      "authors": [
        "Jaya Caporusso",
        "Matthew Purver",
        "Senja Pollak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:31:04+00:00",
          "link": "https://arxiv.org/abs/2507.13115v1",
          "size": "66kb",
          "version": "v1"
        }
      ],
      "title": "A Computational Framework to Identify Self-Aspects in Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13115",
        "HTML": "https://arxiv.org/html/2507.13115v1",
        "PDF": "https://arxiv.org/pdf/2507.13115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes the development of a gold-standard annotated dataset for NLP-based analysis of Self-aspects in texts. This involves creating new datasets and evaluating LLMs, making it directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13117",
      "abstract": "Software systems that process structured inputs often lack complete and up-to-date specifications, which specify the input syntax and the semantics of input processing. While grammar mining techniques have focused on recovering syntactic structures, the semantics of input processing remains largely unexplored. In this work, we introduce a novel approach for inferring attributed grammars from parser implementations. Given an input grammar, our technique dynamically analyzes the implementation of recursive descent parsers to reconstruct the semantic aspects of input handling, resulting in specifications in the form of attributed grammars. By observing program executions and mapping the program's runtime behavior to the grammar, we systematically extract and embed semantic actions into the grammar rules. This enables comprehensive specification recovery. We demonstrate the feasibility of our approach using an initial set of programs, showing that it can accurately reproduce program behavior through the generated attributed grammars.",
      "authors": [
        "Andreas Pointner and Josef Pichler and Herbert Pr\\\"ahofer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:32:59+00:00",
          "link": "https://arxiv.org/abs/2507.13117v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "Inferring Attributed Grammars from Parser Implementations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13117",
        "HTML": "https://arxiv.org/html/2507.13117v1",
        "PDF": "https://arxiv.org/pdf/2507.13117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on inferring attributed grammars from parser implementations, which involves grammar analysis rather than LLM training data processing, making it irrelevant to this context."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13119",
      "abstract": "This paper presents a unified and efficient framework for analyzing antennas embedded in spherically stratified media -- a model broadly applicable to implantable antennas in biomedical systems and radome-enclosed antennas in engineering applications. The proposed method decouples the modeling of the antenna and its surrounding medium by combining the antenna's free-space generalized scattering matrix (GSM) with a set of extended spherical scattering operators (SSOs) that rigorously capture the electromagnetic interactions with multilayered spherical environments. This decoupling enables rapid reevaluation under arbitrary material variations without re-simulating the antenna, offering substantial computational advantages over traditional dyadic Green's function (DGF)-based MoM approaches. The framework supports a wide range of spherical media, including radially inhomogeneous and uniaxially anisotropic layers. Extensive case studies demonstrate excellent agreement with full-wave and DGF-based solutions, confirming the method's accuracy, generality, and scalability. Code implementations are provided to facilitate adoption and future development.",
      "authors": [
        "Chenbo Shi",
        "Xin Gu",
        "Shichen Liang and Jin Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:33:54+00:00",
          "link": "https://arxiv.org/abs/2507.13119v1",
          "size": "1666kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Scattering Matrix Framework for Modeling Implantable Antennas in Multilayered Spherical Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13119",
        "HTML": "https://arxiv.org/html/2507.13119v1",
        "PDF": "https://arxiv.org/pdf/2507.13119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with modeling implantable antennas in multilayered spherical media, which is unrelated to LLM training data processing or any aspect of data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13120",
      "abstract": "Detecting tiny objects in remote sensing (RS) imagery has been a long-standing challenge due to their extremely limited spatial information, weak feature representations, and dense distributions across complex backgrounds. Despite numerous efforts devoted, mainstream detectors still underperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, a multi-stage feature fusion and enhancement model explicitly tailored for RS tiny object detection in various RS scenarios. RS-TinyNet comes with two novel designs: tiny object saliency modeling and feature integrity reconstruction. Guided by these principles, we design three step-wise feature enhancement modules. Among them, the multi-dimensional collaborative attention (MDCA) module employs multi-dimensional attention to enhance the saliency of tiny objects. Additionally, the auxiliary reversible branch (ARB) and a progressive fusion detection head (PFDH) module are introduced to preserve information flow and fuse multi-level features to bridge semantic gaps and retain structural detail. Comprehensive experiments on public RS dataset AI-TOD show that our RS-TinyNet surpasses existing state-of-the-art (SOTA) detectors by 4.0% AP and 6.5% AP75. Evaluations on DIOR benchmark dataset further validate its superior detection performance in diverse RS scenarios. These results demonstrate that the proposed multi-stage feature fusion strategy offers an effective and practical solution for tiny object detection in complex RS environments.",
      "authors": [
        "Xiaozheng Jiang",
        "Wei Zhang",
        "Xuerui Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:34:21+00:00",
          "link": "https://arxiv.org/abs/2507.13120v1",
          "size": "37951kb",
          "version": "v1"
        }
      ],
      "title": "RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13120",
        "HTML": "https://arxiv.org/html/2507.13120v1",
        "PDF": "https://arxiv.org/pdf/2507.13120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on detecting tiny objects in remote sensing images with a new network architecture. It does not address any aspect of LLM training data processing, making it irrelevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13123",
      "abstract": "With the rapid development of Large Language Models (LLMs), their powerful code-generation capabilities have been widely applied in tasks like code completion and automated development, demonstrating the value of improving coding efficiency. However, the extensive use of LLM-generated code also raises several new challenges. On the one hand, issues such as the regulation of code provenance, copyright disputes, and code quality have become increasingly concerning. How to effectively detect LLM-generated code and ensure its compliant and responsible use has become a critical and urgent issue. On the other hand, in practical applications, LLM-generated code is often subject to manual modifications, such as variable renaming or structural adjustments. Although some recent studies have proposed training-based and zero-shot methods for detecting LLM-generated code, these approaches show insufficient robustness when facing modified LLM-generated code, and there is a lack of an effective solution. To address the real-world scenario where LLM-generated code may undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of CodeGPTSensor, which employs adversarial training to improve robustness against input perturbations. CodeGPTSensor+ integrates an adversarial sample generation module, Multi-objective Identifier and Structure Transformation (MIST), which systematically generates both high-quality and representative adversarial samples. This module effectively enhances the model's resistance against diverse adversarial attacks. Experimental results on the HMCorp dataset demonstrate that CodeGPTSensor+ significantly improves detection accuracy on the adversarial test set while maintaining high accuracy on the original test set, showcasing superior robustness compared to CodeGPTSensor.",
      "authors": [
        "Xin Yin",
        "Xinrui Li",
        "Chao Ni",
        "Xiaodan Xu",
        "Xiaohu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:38:16+00:00",
          "link": "https://arxiv.org/abs/2507.13123v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Detecting LLM-generated Code with Subtle Modification by Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13123",
        "HTML": "https://arxiv.org/html/2507.13123v1",
        "PDF": "https://arxiv.org/pdf/2507.13123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses the detection of LLM-generated code with adversarial training, it does not involve improvements or processing of training data for LLMs themselves, thus is irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13129",
      "abstract": "For a fixed graph $H$, the $H$-Coloring problem asks whether a given graph admits an edge-preserving function from its vertex set to that of $H$. A seminal theorem of Hell and Ne\\v{s}et\\v{r}il asserts that the $H$-Coloring problem is NP-hard whenever $H$ is loopless and non-bipartite. A result of Jansen and Pieterse implies that for every graph $H$, the $H$-Coloring problem parameterized by the vertex cover number $k$ admits a kernel with $O(k^{\\Delta(H)})$ vertices and bit-size bounded by $O(k^{\\Delta(H)} \\cdot \\log k)$, where $\\Delta(H)$ denotes the maximum degree in $H$. For the case where $H$ is a complete graph on at least three vertices, this kernel size nearly matches conditional lower bounds established by Jansen and Kratsch and by Jansen and Pieterse.\n  This paper presents new upper and lower bounds on the kernel size of $H$-Coloring problems parameterized by the vertex cover number. The upper bounds arise from two kernelization algorithms. The first is purely combinatorial, and its size is governed by a structural quantity of the graph $H$, called the non-adjacency witness number. As applications, we obtain kernels whose size is bounded by a fixed polynomial for natural classes of graphs $H$ with unbounded maximum degree. More strikingly, we show that for almost every graph $H$, the degree of the polynomial that bounds the size of our combinatorial kernel grows only logarithmically in $\\Delta(H)$. Our second kernel leverages linear-algebraic tools and involves the notion of faithful independent representations of graphs. It strengthens the general bound from prior work and, among other applications, yields near-optimal kernels for problems concerning the dimension of orthogonal graph representations over finite fields. We complement these results with conditional lower bounds, thereby nearly settling the kernel complexity of the problem for various target graphs $H$.",
      "authors": [
        "Yael Berkman and Ishay Haviv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:46:17+00:00",
          "link": "https://arxiv.org/abs/2507.13129v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Kernelization for $H$-Coloring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13129",
        "HTML": "https://arxiv.org/html/2507.13129v1",
        "PDF": "https://arxiv.org/pdf/2507.13129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about kernelization for $H$-Coloring in graph theory, which does not relate to LLM training data processing or dataset generation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13131",
      "abstract": "In this letter, a pinching antenna (PA)-aided scheme for establishing a secure integrated sensing and communication system (ISAC) is investigated. The underlying system comprises a dual-functional radar communication (DFRC) base station (BS) linked to multiple waveguides to serve several downlink users while sensing a set of malicious targets in a given area. The PA-aided BS aims at preserving communication confidentiality with the legitimate users while being able to detect malicious targets. One objective of the proposed scheme is to optimize the PA locations, based on which an optimal design of the legitimate signal beamforming and artificial noise covariance matrices is provided to maximize the network's sensing performance, subject to secrecy and total power constraints. We demonstrate the efficacy of the proposed scheme through numerical examples and compare that against a traditional DFRC ISAC system with a uniform linear array of half-wavelength-spaced antennas. We show that the proposed scheme outperforms the baseline PA-aided scheme with equidistant PAs by $3$ dB in terms of illumination power, while it can provide gains of up to $30$ dB of the same metric against a traditional ISAC system with half-wavelength-space uniform linear arrays.",
      "authors": [
        "Elmehdi Illi",
        "Marwa Qaraqe",
        "Ali Ghrayeb"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:48:25+00:00",
          "link": "https://arxiv.org/abs/2507.13131v1",
          "size": "472kb",
          "version": "v1"
        }
      ],
      "title": "Secure Pinching Antenna-aided ISAC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13131",
        "HTML": "https://arxiv.org/html/2507.13131v1",
        "PDF": "https://arxiv.org/pdf/2507.13131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on secure integrated sensing and communication systems with pinching antennas, and it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13133",
      "abstract": "Graph generation plays a pivotal role across numerous domains, including molecular design and knowledge graph construction. Although existing methods achieve considerable success in generating realistic graphs, their interpretability remains limited, often obscuring the rationale behind structural decisions. To address this challenge, we propose the Neural Graph Topic Model (NGTM), a novel generative framework inspired by topic modeling in natural language processing. NGTM represents graphs as mixtures of latent topics, each defining a distribution over semantically meaningful substructures, which facilitates explicit interpretability at both local and global scales. The generation process transparently integrates these topic distributions with a global structural variable, enabling clear semantic tracing of each generated graph. Experiments demonstrate that NGTM achieves competitive generation quality while uniquely enabling fine-grained control and interpretability, allowing users to tune structural features or induce biological properties through topic-level adjustments.",
      "authors": [
        "Yuanxin Zhuang and Dazhong Shen and Ying Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:54:42+00:00",
          "link": "https://arxiv.org/abs/2507.13133v1",
          "size": "12748kb",
          "version": "v1"
        }
      ],
      "title": "NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13133",
        "HTML": "https://arxiv.org/html/2507.13133v1",
        "PDF": "https://arxiv.org/pdf/2507.13133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a Neural Graph Topic Model for graph generation, which does not pertain to the processing or creation of datasets for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13136",
      "abstract": "Image classification currently faces significant security challenges due to adversarial attacks, which consist of intentional alterations designed to deceive classification models based on artificial intelligence. This article explores an approach to generate adversarial attacks against image classifiers using a combination of evolutionary algorithms and generative adversarial networks. The proposed approach explores the latent space of a generative adversarial network with an evolutionary algorithm to find vectors representing adversarial attacks. The approach was evaluated in two case studies corresponding to the classification of handwritten digits and object images. The results showed success rates of up to 35% for handwritten digits, and up to 75% for object images, improving over other search methods and reported results in related works. The applied method proved to be effective in handling data diversity on the target datasets, even in problem instances that presented additional challenges due to the complexity and richness of information.",
      "authors": [
        "Sergio Nesmachnow",
        "Jamal Toutouh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:57:21+00:00",
          "link": "https://arxiv.org/abs/2507.13136v1",
          "size": "1533kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial attacks to image classification systems using evolutionary algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13136",
        "HTML": "https://arxiv.org/html/2507.13136v1",
        "PDF": "https://arxiv.org/pdf/2507.13136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on generating adversarial attacks on image classifiers using evolutionary algorithms and GANs, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13138",
      "abstract": "Understanding the sources of variability in annotations is crucial for developing fair NLP systems, especially for tasks like sexism detection where demographic bias is a concern. This study investigates the extent to which annotator demographic features influence labeling decisions compared to text content. Using a Generalized Linear Mixed Model, we quantify this inf luence, finding that while statistically present, demographic factors account for a minor fraction ( 8%) of the observed variance, with tweet content being the dominant factor. We then assess the reliability of Generative AI (GenAI) models as annotators, specifically evaluating if guiding them with demographic personas improves alignment with human judgments. Our results indicate that simplistic persona prompting often fails to enhance, and sometimes degrades, performance compared to baseline models. Furthermore, explainable AI (XAI) techniques reveal that model predictions rely heavily on content-specific tokens related to sexism, rather than correlates of demographic characteristics. We argue that focusing on content-driven explanations and robust annotation protocols offers a more reliable path towards fairness than potentially persona simulation.",
      "authors": [
        "Hadi Mohammadi",
        "Tina Shahedi",
        "Pablo Mosteiro",
        "Massimo Poesio",
        "Ayoub Bagheri",
        "Anastasia Giachanou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:00:13+00:00",
          "link": "https://arxiv.org/abs/2507.13138v1",
          "size": "424kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13138",
        "HTML": "https://arxiv.org/html/2507.13138v1",
        "PDF": "https://arxiv.org/pdf/2507.13138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates the reliability of LLM annotations and investigates biases, which slightly touches on data quality but mainly centers on fairness, bias in NLP, and model explanation rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13140",
      "abstract": "Sixth generation (6G) networks demand tight integration of artificial intelligence (AI) into radio access networks (RANs) to meet stringent quality of service (QoS) and resource efficiency requirements. Existing solutions struggle to bridge the gap between high level user intents and the low level, parameterized configurations required for optimal performance. To address this challenge, we propose RIDAS, a multi agent framework composed of representation driven agents (RDAs) and an intention driven agent (IDA). RDAs expose open interface with tunable control parameters (rank and quantization bits, enabling explicit trade) offs between distortion and transmission rate. The IDA employs a two stage planning scheme (bandwidth pre allocation and reallocation) driven by a large language model (LLM) to map user intents and system state into optimal RDA configurations. Experiments demonstrate that RIDAS supports 44.71\\% more users than WirelessAgent under equivalent QoS constraints. These results validate ability of RIDAS to capture user intent and allocate resources more efficiently in AI RAN environments.",
      "authors": [
        "Kuiyuan Ding",
        "Caili Guo",
        "Yang Yang and Jianzhang Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.13140v1",
          "size": "491kb",
          "version": "v1"
        }
      ],
      "title": "RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and Intention-Driven Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13140",
        "HTML": "https://arxiv.org/html/2507.13140v1",
        "PDF": "https://arxiv.org/pdf/2507.13140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although this paper uses a language model within its multi-agent framework for 6G networks, its focus is on resource allocation rather than core LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13142",
      "abstract": "Modern language models address complex questions through chain-of-thought (CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al., 2021), yet struggle with error propagation and knowledge integration. Tree-structured reasoning methods, particularly the Probabilistic Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues by decomposing questions into hierarchical structures and selecting answers through confidence-weighted aggregation of parametric and retrieved knowledge (Yao et al., 2023). However, ProbTree's static implementation introduces two key limitations: (1) the reasoning tree is fixed during the initial construction phase, preventing dynamic adaptation to intermediate results, and (2) each node requires exhaustive evaluation of all possible solution strategies, creating computational inefficiency. We present a dynamic reinforcement learning (Sutton and Barto, 2018) framework that transforms tree-based reasoning into an adaptive process. Our approach incrementally constructs the reasoning tree based on real-time confidence estimates, while learning optimal policies for action selection (decomposition, retrieval, or aggregation). This maintains ProbTree's probabilistic rigor while improving both solution quality and computational efficiency through selective expansion and focused resource allocation. The work establishes a new paradigm for treestructured reasoning that balances the reliability of probabilistic frameworks with the flexibility required for real-world question answering systems.",
      "authors": [
        "Ahmed Bahloul",
        "Simon Malberg"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:06:19+00:00",
          "link": "https://arxiv.org/abs/2507.13142v1",
          "size": "192kb",
          "version": "v1"
        }
      ],
      "title": "From Roots to Rewards: Dynamic Tree Reasoning with RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13142",
        "HTML": "https://arxiv.org/html/2507.13142v1",
        "PDF": "https://arxiv.org/pdf/2507.13142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a dynamic reinforcement learning framework for tree-structured reasoning, which relates to improving reasoning frameworks rather than addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13143",
      "abstract": "In research, measuring instruments play a crucial role in producing the data that underpin scientific discoveries. Information about instruments is essential in data interpretation and, thus, knowledge production. However, if at all available and accessible, such information is scattered across numerous data sources. Relating the relevant details, e.g. instrument specifications or calibrations, with associated research assets (data, but also operating infrastructures) is challenging. Moreover, understanding the (possible) use of instruments is essential for researchers in experiment design and execution. To address these challenges, we propose a Knowledge Graph (KG) based approach for representing, publishing, and using information, extracted from various data sources, about instruments and associated scholarly artefacts. The resulting KG serves as a foundation for exploring and gaining a deeper understanding of the use and role of instruments in research, discovering relations between instruments and associated artefacts (articles and datasets), and opens the possibility to quantify the impact of instruments in research.",
      "authors": [
        "Muhammad Haris",
        "S\\\"oren Auer",
        "Markus Stocker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:08:12+00:00",
          "link": "https://arxiv.org/abs/2507.13143v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "Managing Comprehensive Research Instrument Descriptions within a Scholarly Knowledge Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13143",
        "HTML": "https://arxiv.org/html/2507.13143v1",
        "PDF": "https://arxiv.org/pdf/2507.13143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a Knowledge Graph approach for managing research instrument descriptions, which is not related to any LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13145",
      "abstract": "Learning-based monocular visual odometry (VO) poses robustness, generalization, and efficiency challenges in robotics. Recent advances in visual foundation models, such as DINOv2, have improved robustness and generalization in various vision tasks, yet their integration in VO remains limited due to coarse feature granularity. In this paper, we present DINO-VO, a feature-based VO system leveraging DINOv2 visual foundation model for its sparse feature matching. To address the integration challenge, we propose a salient keypoints detector tailored to DINOv2's coarse features. Furthermore, we complement DINOv2's robust-semantic features with fine-grained geometric features, resulting in more localizable representations. Finally, a transformer-based matcher and differentiable pose estimation layer enable precise camera motion estimation by learning good matches. Against prior detector-descriptor networks like SuperPoint, DINO-VO demonstrates greater robustness in challenging environments. Furthermore, we show superior accuracy and generalization of the proposed feature descriptors against standalone DINOv2 coarse features. DINO-VO outperforms prior frame-to-frame VO methods on the TartanAir and KITTI datasets and is competitive on EuRoC dataset, while running efficiently at 72 FPS with less than 1GB of memory usage on a single GPU. Moreover, it performs competitively against Visual SLAM systems on outdoor driving scenarios, showcasing its generalization capabilities.",
      "authors": [
        "Maulana Bisyir Azhari and David Hyunchul Shim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:09:34+00:00",
          "link": "https://arxiv.org/abs/2507.13145v1",
          "size": "1287kb",
          "version": "v1"
        }
      ],
      "title": "DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13145",
        "HTML": "https://arxiv.org/html/2507.13145v1",
        "PDF": "https://arxiv.org/pdf/2507.13145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving visual odometry using a feature-based system with the DINOv2 visual foundation model. It does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13152",
      "abstract": "Recent advances in vision-language navigation (VLN) were mainly attributed to emerging large language models (LLMs). These methods exhibited excellent generalization capabilities in instruction understanding and task reasoning. However, they were constrained by the fixed knowledge bases and reasoning abilities of LLMs, preventing fully incorporating experiential knowledge and thus resulting in a lack of efficient evolutionary capacity. To address this, we drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed. Specifically, SE-VLN comprised three core modules, i.e., a hierarchical memory module to transfer successful and failure cases into reusable knowledge, a retrieval-augmented thought-based reasoning module to retrieve experience and enable multi-step decision-making, and a reflection module to realize continual evolution. Comprehensive tests illustrated that the SE-VLN achieved navigation success rates of 57% and 35.2% in unseen environments, representing absolute performance improvements of 23.9% and 15.0% over current state-of-the-art methods on R2R and REVERSE datasets, respectively. Moreover, the SE-VLN showed performance improvement with increasing experience repository, elucidating its great potential as a self-evolving agent framework for VLN.",
      "authors": [
        "Xiangyu Dong",
        "Haoran Zhao",
        "Jiang Gao",
        "Haozhou Li",
        "Xiaoguang Ma",
        "Yaoming Zhou",
        "Fuhai Chen",
        "Juan Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:13:50+00:00",
          "link": "https://arxiv.org/abs/2507.13152v1",
          "size": "1619kb",
          "version": "v1"
        }
      ],
      "title": "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13152",
        "HTML": "https://arxiv.org/html/2507.13152v1",
        "PDF": "https://arxiv.org/pdf/2507.13152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a self-evolving vision-language navigation framework but does not involve any processing of training data specific to LLMs, instead focusing on navigation and task reasoning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13155",
      "abstract": "Current expressive speech synthesis models are constrained by the limited availability of open-source datasets containing diverse nonverbal vocalizations (NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional categories. The dataset is derived from popular sources, VoxCeleb and Expresso, using automated detection followed by human validation. We propose a comprehensive pipeline that integrates automatic speech recognition (ASR), NV tagging, emotion classification, and a fusion algorithm to merge transcriptions from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models on the NVTTS dataset achieves parity with closed-source systems such as CosyVoice2, as measured by both human evaluation and automatic metrics, including speaker similarity and NV fidelity. By releasing NVTTS and its accompanying annotation guidelines, we address a key bottleneck in expressive TTS research. The dataset is available at https://huggingface.co/datasets/deepvk/NonverbalTTS.",
      "authors": [
        "Maksim Borisov",
        "Egor Spirin",
        "Daria Diatlova"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:17:40+00:00",
          "link": "https://arxiv.org/abs/2507.13155v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13155",
        "HTML": "https://arxiv.org/html/2507.13155v1",
        "PDF": "https://arxiv.org/pdf/2507.13155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the NonverbalTTS dataset, a new open-access dataset with text-aligned nonverbal vocalizations and emotion annotations. This contribution is relevant as it provides a new dataset that can be used for fine-tuning models in expressive TTS, which is a form of LLM task."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13157",
      "abstract": "Generative adversarial networks (GANs) are powerful generative models but remain challenging to train due to pathologies suchas mode collapse and instability. Recent research has explored co-evolutionary approaches, in which populations of generators and discriminators are evolved, as a promising solution. This paper presents an empirical analysis of different coevolutionary GAN training strategies, focusing on the impact of selection and replacement mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda) with tournament selection coevolutionary schemes, along with a non-evolutionary population based multi-generator multi-discriminator GAN baseline, across both synthetic low-dimensional datasets (blob and gaussian mixtures) and an image-based benchmark (MNIST). Results show that full generational replacement, i.e., (mu,lambda), consistently outperforms in terms of both sample quality and diversity, particularly when combined with larger offspring sizes. In contrast, elitist approaches tend to converge prematurely and suffer from reduced diversity. These findings highlight the importance of balancing exploration and exploitation dynamics in coevolutionary GAN training and provide guidance for designing more effective population-based generative models.",
      "authors": [
        "Walter P. Casas",
        "Jamal Toutouh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:19:17+00:00",
          "link": "https://arxiv.org/abs/2507.13157v1",
          "size": "4116kb",
          "version": "v1"
        }
      ],
      "title": "Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13157",
        "HTML": "https://arxiv.org/html/2507.13157v1",
        "PDF": "https://arxiv.org/pdf/2507.13157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates multiple GAN training strategies with an emphasis on co-evolutionary algorithms, which does not entail LLM training data processing operations such as dataset creation or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13158",
      "abstract": "In the era of Large Language Models (LLMs), alignment has emerged as a fundamental yet challenging problem in the pursuit of more reliable, controllable, and capable machine intelligence. The recent success of reasoning models and conversational AI systems has underscored the critical role of reinforcement learning (RL) in enhancing these systems, driving increased research interest at the intersection of RL and LLM alignment. This paper provides a comprehensive review of recent advances in LLM alignment through the lens of inverse reinforcement learning (IRL), emphasizing the distinctions between RL techniques employed in LLM alignment and those in conventional RL tasks. In particular, we highlight the necessity of constructing neural reward models from human data and discuss the formal and practical implications of this paradigm shift. We begin by introducing fundamental concepts in RL to provide a foundation for readers unfamiliar with the field. We then examine recent advances in this research agenda, discussing key challenges and opportunities in conducting IRL for LLM alignment. Beyond methodological considerations, we explore practical aspects, including datasets, benchmarks, evaluation metrics, infrastructure, and computationally efficient training and inference techniques. Finally, we draw insights from the literature on sparse-reward RL to identify open questions and potential research directions. By synthesizing findings from diverse studies, we aim to provide a structured and critical overview of the field, highlight unresolved challenges, and outline promising future directions for improving LLM alignment through RL and IRL techniques.",
      "authors": [
        "Hao Sun and Mihaela van der Schaar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:22:24+00:00",
          "link": "https://arxiv.org/abs/2507.13158v1",
          "size": "1476kb",
          "version": "v1"
        }
      ],
      "title": "Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13158",
        "HTML": "https://arxiv.org/html/2507.13158v1",
        "PDF": "https://arxiv.org/pdf/2507.13158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper provides an overview of LLM alignment through inverse reinforcement learning and mentions practical aspects such as datasets and evaluation metrics, its primary focus is on IRL techniques for LLM alignment, not on training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13159",
      "abstract": "A rounding scheme for set cover has served as an important component in design of approximation algorithms for the problem, and there exists an H_s-approximate rounding scheme, where s denotes the maximum subset size, directly implying an approximation algorithm with the same approximation guarantee. A rounding scheme has also been considered under some online models, and in particular, under the element arrival model used as a crucial subroutine in algorithms for online set cover, an O(log s)-competitive rounding scheme is known [Buchbinder, Chen, and Naor, SODA 2014]. On the other hand, under a more general model, called the subset arrival model, only a simple O(log n)-competitive rounding scheme is known, where n denotes the number of elements in the ground set.\n  In this paper, we present an O(log^2 s)-competitive rounding scheme under the subset arrival model, with one mild assumption that s is known upfront. Using our rounding scheme, we immediately obtain an O(log^2 s)-approximation algorithm for multi-stage stochastic set cover, improving upon the existing algorithms [Swamy and Shmoys, SICOMP 2012; Byrka and Srinivasan, SIDMA 2018] when s is small enough compared to the number of stages and the number of elements. Lastly, for set cover with s = 2, also known as edge cover, we present a 1.8-competitive rounding scheme under the edge arrival model.",
      "authors": [
        "Jaros{\\l}aw Byrka",
        "Yongho Shin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:23:28+00:00",
          "link": "https://arxiv.org/abs/2507.13159v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Online Rounding for Set Cover under Subset Arrivals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13159",
        "HTML": "https://arxiv.org/html/2507.13159v1",
        "PDF": "https://arxiv.org/pdf/2507.13159"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rounding schemes for set cover problems in the context of approximation algorithms and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13162",
      "abstract": "Existing world models for autonomous driving struggle with long-horizon generation and generalization to challenging scenarios. In this work, we develop a model using simple design choices, and without additional supervision or sensors, such as maps, depth, or multiple cameras. We show that our model yields state-of-the-art performance, despite having only 469M parameters and being trained on 280h of video data. It particularly stands out in difficult scenarios like turning maneuvers and urban traffic. We test whether discrete token models possibly have advantages over continuous models based on flow matching. To this end, we set up a hybrid tokenizer that is compatible with both approaches and allows for a side-by-side comparison. Our study concludes in favor of the continuous autoregressive model, which is less brittle on individual design choices and more powerful than the model built on discrete tokens. Code, models and qualitative results are publicly available at https://lmb-freiburg.github.io/orbis.github.io/.",
      "authors": [
        "Arian Mousakhan and Sudhanshu Mittal and Silvio Galesso and Karim Farid and Thomas Brox"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:29:34+00:00",
          "link": "https://arxiv.org/abs/2507.13162v1",
          "size": "6349kb",
          "version": "v1"
        }
      ],
      "title": "Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13162",
        "HTML": "https://arxiv.org/html/2507.13162v1",
        "PDF": "https://arxiv.org/pdf/2507.13162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses predictive models for autonomous driving and compares discrete versus continuous models; it does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13164",
      "abstract": "Oral narrative skills are strong predictors of later literacy development. This study examines the features of oral narratives from children who were identified by experts as requiring intervention. Using simple machine learning methods, we analyse recorded stories from four- and five-year-old Afrikaans- and isiXhosa-speaking children. Consistent with prior research, we identify lexical diversity (unique words) and length-based features (mean utterance length) as indicators of typical development, but features like articulation rate prove less informative. Despite cross-linguistic variation in part-of-speech patterns, the use of specific verbs and auxiliaries associated with goal-directed storytelling is correlated with a reduced likelihood of requiring intervention. Our analysis of two linguistically distinct languages reveals both language-specific and shared predictors of narrative proficiency, with implications for early assessment in multilingual contexts.",
      "authors": [
        "Emma Sharratt",
        "Annelien Smith",
        "Retief Louw",
        "Daleen Klop",
        "Febe de Wet and Herman Kamper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:31:32+00:00",
          "link": "https://arxiv.org/abs/2507.13164v1",
          "size": "688kb",
          "version": "v1"
        }
      ],
      "title": "Feature-based analysis of oral narratives from Afrikaans and isiXhosa children",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13164",
        "HTML": "https://arxiv.org/html/2507.13164v1",
        "PDF": "https://arxiv.org/pdf/2507.13164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes narrative skills in children using machine learning techniques but does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13167",
      "abstract": "Like the prehistoric twig and stone, tangible user interfaces (TUIs) are objects manipulated by humans. TUI success will depend on how well they exploit spatiality, the intuitive spatial skills humans have with the objects they use. In this paper we carefully examine the relationship between humans and physical objects, and related previous research. From this examination we distill a set of observations, and turn these into heuristics for incorporation of spatiality into TUI application design, a cornerstone for their success. Following this line of thought, we identify spatial TUIs, the subset of TUIs that mediate interaction with shape, space and structure. We then examine several existing spatial TUIs using our heuristics.",
      "authors": [
        "Ehud Sharlin",
        "Benjamin Watson",
        "Yoshifumi Kitamura",
        "Fumio Kishino",
        "Yuichi Itoh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:33:09+00:00",
          "link": "https://arxiv.org/abs/2507.13167v1",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "title": "On tangible user interfaces, humans and spatiality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13167",
        "PDF": "https://arxiv.org/pdf/2507.13167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses tangible user interfaces and spatiality, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13169",
      "abstract": "Prompt injection attacks, where malicious input is designed to manipulate AI systems into ignoring their original instructions and following unauthorized commands instead, were first discovered by Preamble, Inc. in May 2022 and responsibly disclosed to OpenAI. Over the last three years, these attacks have continued to pose a critical security threat to LLM-integrated systems. The emergence of agentic AI systems, where LLMs autonomously perform multistep tasks through tools and coordination with other agents, has fundamentally transformed the threat landscape. Modern prompt injection attacks can now combine with traditional cybersecurity exploits to create hybrid threats that systematically evade traditional security controls. This paper presents a comprehensive analysis of Prompt Injection 2.0, examining how prompt injections integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other web security vulnerabilities to bypass traditional security measures. We build upon Preamble's foundational research and mitigation technologies, evaluating them against contemporary threats, including AI worms, multi-agent infections, and hybrid cyber-AI attacks. Our analysis incorporates recent benchmarks that demonstrate how traditional web application firewalls, XSS filters, and CSRF tokens fail against AI-enhanced attacks. We also present architectural solutions that combine prompt isolation, runtime security, and privilege separation with novel threat detection capabilities.",
      "authors": [
        "Jeremy McHugh",
        "Kristina \\v{S}ekrst",
        "and Jon Cefalu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:33:36+00:00",
          "link": "https://arxiv.org/abs/2507.13169v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Injection 2.0: Hybrid AI Threats",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13169",
        "HTML": "https://arxiv.org/html/2507.13169v1",
        "PDF": "https://arxiv.org/pdf/2507.13169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on prompt injection attacks and cybersecurity threats, without any mention of LLM training data processing or dataset creation for pretraining or fine-tuning purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13170",
      "abstract": "Audio plays a crucial role in applications like speaker verification, voice-enabled smart devices, and audio conferencing. However, audio manipulations, such as deepfakes, pose significant risks by enabling the spread of misinformation. Our empirical analysis reveals that existing methods for detecting deepfake audio are often vulnerable to anti-forensic (AF) attacks, particularly those attacked using generative adversarial networks. In this article, we propose a novel collaborative learning method called SHIELD to defend against generative AF attacks. To expose AF signatures, we integrate an auxiliary generative model, called the defense (DF) generative model, which facilitates collaborative learning by combining input and output. Furthermore, we design a triplet model to capture correlations for real and AF attacked audios with real-generated and attacked-generated audios using auxiliary generative models. The proposed SHIELD strengthens the defense against generative AF attacks and achieves robust performance across various generative models. The proposed AF significantly reduces the average detection accuracy from 95.49% to 59.77% for ASVspoof2019, from 99.44% to 38.45% for In-the-Wild, and from 98.41% to 51.18% for HalfTruth for three different generative models. The proposed SHIELD mechanism is robust against AF attacks and achieves an average accuracy of 98.13%, 98.58%, and 99.57% in match, and 98.78%, 98.62%, and 98.85% in mismatch settings for the ASVspoof2019, In-the-Wild, and HalfTruth datasets, respectively.",
      "authors": [
        "Kutub Uddin",
        "Awais Khan",
        "Muhammad Umar Farooq",
        "Khalid Malik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:33:54+00:00",
          "link": "https://arxiv.org/abs/2507.13170v1",
          "size": "4551kb",
          "version": "v1"
        }
      ],
      "title": "SHIELD: A Secure and Highly Enhanced Integrated Learning for Robust Deepfake Detection against Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13170",
        "HTML": "https://arxiv.org/html/2507.13170v1",
        "PDF": "https://arxiv.org/pdf/2507.13170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is primarily concerned with deepfake audio detection and developing robust defenses against adversarial attacks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13171",
      "abstract": "Conventional reinforcement learning (RL) ap proaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, rein forcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, en abling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.",
      "authors": [
        "Suzie Kim",
        "Hye-Bin Shin",
        "and Seong-Whan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.13171v1",
          "size": "1040kb",
          "version": "v1"
        }
      ],
      "title": "Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13171",
        "HTML": "https://arxiv.org/html/2507.13171v1",
        "PDF": "https://arxiv.org/pdf/2507.13171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on reinforcement learning with implicit human feedback, particularly in the context of robotics, without addressing LLM training data processing or related dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13175",
      "abstract": "The advancement of powerful yet opaque large language models (LLMs) necessitates a fundamental revision of the philosophical criteria used to evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the assumption of transparent architectures, which LLMs defy due to their stochastic outputs and opaque internal states. This paper argues that traditional ethical criteria are pragmatically obsolete for LLMs due to this mismatch. Engaging with core themes in the philosophy of technology, this paper proffers a revised set of ten functional criteria to evaluate LLM-based artificial moral agents: moral concordance, context sensitivity, normative integrity, metaethical awareness, system resilience, trustworthiness, corrigibility, partial transparency, functional autonomy, and moral imagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating Moral Agency through Large Language Systems), aim to steer AMAs toward greater alignment and beneficial societal integration in the coming years. We illustrate these criteria using hypothetical scenarios involving an autonomous public bus (APB) to demonstrate their practical applicability in morally salient contexts.",
      "authors": [
        "Matthew E. Brophy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:39:29+00:00",
          "link": "https://arxiv.org/abs/2507.13175v1",
          "size": "1066kb",
          "version": "v1"
        }
      ],
      "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13175",
        "PDF": "https://arxiv.org/pdf/2507.13175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses ethical criteria for evaluating artificial moral agents in the LLM era, not directly contributing to LLM training data processing or dataset generation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13178",
      "abstract": "We study randomized generation of sequences of test-inputs to a system using Prolog. Prolog is a natural fit to generate test-sequences that have complex logical inter-dependent structure. To counter the problems posed by a large (or infinite) set of possible tests, randomization is a natural choice. We study the impact that randomization in conjunction with SLD resolution have on the test performance. To this end, this paper proposes two strategies to add randomization to a test-generating program. One strategy works on top of standard Prolog semantics, whereas the other alters the SLD selection function. We analyze the mean time to reach a test-case, and the mean number of generated test-cases in the framework of Markov chains. Finally, we provide an additional empirical evaluation and comparison between both approaches. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "authors": [
        "Marcus Gelderie",
        "Maximilian Luff",
        "Maximilian Peltzer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:44:33+00:00",
          "link": "https://arxiv.org/abs/2507.13178v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Impact and Performance of Randomized Test-Generation using Prolog",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13178",
        "PDF": "https://arxiv.org/pdf/2507.13178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about randomized test generation using Prolog, which does not involve any aspect of LLM training data processing or improvements in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13179",
      "abstract": "As 6G networks are developed and defined, offloading of XR applications is emerging as one of the strong new use cases. The reduced 6G latency coupled with edge processing infrastructure will for the first time provide a realistic offloading scenario in cellular networks where several computationally intensive functions, including rendering, can migrate from the user device and into the network. A key advantage of doing so is the lowering of the battery needs in the user devices and the possibility to design new devices with smaller form factors.",
      "authors": [
        "Ziyu Zhong",
        "Hector A Caltenco",
        "Bj\\\"orn Landfeldt",
        "G\\\"unter Alce"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:45:56+00:00",
          "link": "https://arxiv.org/abs/2507.13179v1",
          "size": "1123kb",
          "version": "v1"
        }
      ],
      "title": "Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13179",
        "HTML": "https://arxiv.org/html/2507.13179v1",
        "PDF": "https://arxiv.org/pdf/2507.13179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses offloading XR applications with 6G networks, focusing on reducing latency and device battery needs. It doesn't involve LLM training data processing or data-related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13181",
      "abstract": "The effect of representation has been demonstrated in reinforcement learning, from both theoretical and empirical successes. However, the existing representation learning mainly induced from model learning aspects, misaligning with our RL tasks. This work introduces Spectral Bellman Representation, a novel framework derived from the Inherent Bellman Error (IBE) condition, which aligns with the fundamental structure of Bellman updates across a space of possible value functions, therefore, directly towards value-based RL. Our key insight is the discovery of a fundamental spectral relationship: under the zero-IBE condition, the transformation of a distribution of value functions by the Bellman operator is intrinsically linked to the feature covariance structure. This spectral connection yields a new, theoretically-grounded objective for learning state-action features that inherently capture this Bellman-aligned covariance. Our method requires a simple modification to existing algorithms. We demonstrate that our learned representations enable structured exploration, by aligning feature covariance with Bellman dynamics, and improve overall performance, particularly in challenging hard-exploration and long-horizon credit assignment tasks. Our framework naturally extends to powerful multi-step Bellman operators, further broadening its impact. Spectral Bellman Representation offers a principled and effective path toward learning more powerful and structurally sound representations for value-based reinforcement learning.",
      "authors": [
        "Ofir Nabati",
        "Bo Dai",
        "Shie Mannor",
        "Guy Tennenholtz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.13181v1",
          "size": "312kb",
          "version": "v1"
        }
      ],
      "title": "Spectral Bellman Method: Unifying Representation and Exploration in RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13181",
        "PDF": "https://arxiv.org/pdf/2507.13181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for representation learning in reinforcement learning, emphasizing the Spectral Bellman Representation. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13188",
      "abstract": "For the model problem of the heat equation discretized by an implicit Euler method in time and a conforming finite element method in space, we prove the efficiency of a posteriori error estimators with respect to the energy norm of the error, when considering the numerical solution as the average between the usual continuous piecewise affine-in-time and piecewise constant-in-time reconstructions. This illustrates how the efficiency of the estimators is not only possibly dependent on the choice of norm, but also on the choice of notion of numerical solution.",
      "authors": [
        "Iain Smears"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.13188v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "On the efficiency of a posteriori error estimators for parabolic partial differential equations in the energy norm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13188",
        "HTML": "https://arxiv.org/html/2507.13188v1",
        "PDF": "https://arxiv.org/pdf/2507.13188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with error estimators for parabolic partial differential equations and their efficiency. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13190",
      "abstract": "Multi-agent systems built on language models have shown strong performance on collaborative reasoning tasks. However, existing evaluations focus only on the correctness of the final output, overlooking how inefficient communication and poor coordination contribute to redundant reasoning and higher computational costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes the internal collaboration process by modeling agent interactions as a directed acyclic graph. To capture collaboration quality, we propose two process-level metrics: Information Diversity Score (IDS) to measure semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant reasoning paths. We evaluate GEMMAS across five benchmarks and highlight results on GSM8K, where systems with only a 2.1% difference in accuracy differ by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal collaboration. These findings demonstrate that outcome-only metrics are insufficient for evaluating multi-agent performance and highlight the importance of process-level diagnostics in designing more interpretable and resource-efficient collaborative AI systems.",
      "authors": [
        "Jisoo Lee",
        "Raeyoung Chang",
        "Dongwook Kwon",
        "Harmanpreet Singh",
        "Nikhil Verma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:59:20+00:00",
          "link": "https://arxiv.org/abs/2507.13190v1",
          "size": "9970kb",
          "version": "v1"
        }
      ],
      "title": "GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13190",
        "HTML": "https://arxiv.org/html/2507.13190v1",
        "PDF": "https://arxiv.org/pdf/2507.13190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces GEMMAS, a graph-based evaluation framework for multi-agent systems. It focuses on evaluation metrics and is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13191",
      "abstract": "Monotone gradient functions play a central role in solving the Monge formulation of the optimal transport problem, which arises in modern applications ranging from fluid dynamics to robot swarm control. When the transport cost is the squared Euclidean distance, Brenier's theorem guarantees that the unique optimal map is the gradient of a convex function, namely a monotone gradient map, and it satisfies a Monge-Amp\\`ere equation. In [arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks (mGradNets), neural networks that directly parameterize the space of monotone gradient maps. In this work, we leverage mGradNets to directly learn the optimal transport mapping by minimizing a training loss function defined using the Monge-Amp\\`ere equation. We empirically show that the structural bias of mGradNets facilitates the learning of optimal transport maps and employ our method for a robot swarm control problem.",
      "authors": [
        "Shreyas Chaudhari",
        "Srinivasa Pranav",
        "Jos\\'e M. F. Moura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:59:24+00:00",
          "link": "https://arxiv.org/abs/2507.13191v1",
          "size": "873kb",
          "version": "v1"
        }
      ],
      "title": "GradNetOT: Learning Optimal Transport Maps with GradNets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13191",
        "HTML": "https://arxiv.org/html/2507.13191v1",
        "PDF": "https://arxiv.org/pdf/2507.13191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses learning optimal transport maps using neural networks. It is focused on optimal transport problems and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13198",
      "abstract": "We verify the correctness of a variety of mutual exclusion algorithms through model checking. We look at algorithms where communication is via shared read/write registers, where those registers can be atomic or non-atomic. For the verification of liveness properties, it is necessary to assume a completeness criterion to eliminate spurious counterexamples. We use justness as completeness criterion. Justness depends on a concurrency relation; we consider several such relations, modelling different assumptions on the working of the shared registers. We present executions demonstrating the violation of correctness properties by several algorithms, and in some cases suggest improvements.",
      "authors": [
        "Rob van Glabbeek",
        "Bas Luttik and Myrthe Spronck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.13198v1",
          "size": "141kb",
          "version": "v1"
        }
      ],
      "title": "Just Verification of Mutual Exclusion Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13198",
        "HTML": "https://arxiv.org/html/2507.13198v1",
        "PDF": "https://arxiv.org/pdf/2507.13198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the verification of mutual exclusion algorithms using model checking. It does not involve any aspect of data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13200",
      "abstract": "Tools extend the manipulation abilities of robots, much like they do for humans. Despite human expertise in tool manipulation, teaching robots these skills faces challenges. The complexity arises from the interplay of two simultaneous points of contact: one between the robot and the tool, and another between the tool and the environment. Tactile and proximity sensors play a crucial role in identifying these complex contacts. However, learning tool manipulation using these sensors remains challenging due to limited real-world data and the large sim-to-real gap. To address this, we propose a few-shot tool-use skill transfer framework using multimodal sensing. The framework involves pre-training the base policy to capture contact states common in tool-use skills in simulation and fine-tuning it with human demonstrations collected in the real-world target domain to bridge the domain gap. We validate that this framework enables teaching surface-following tasks using tools with diverse physical and geometric properties with a small number of demonstrations on the Franka Emika robot arm. Our analysis suggests that the robot acquires new tool-use skills by transferring the ability to recognise tool-environment contact relationships from pre-trained to fine-tuned policies. Additionally, combining proximity and tactile sensors enhances the identification of contact states and environmental geometry.",
      "authors": [
        "Marina Y. Aoyama",
        "Sethu Vijayakumar",
        "Tetsuya Narita"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:10:12+00:00",
          "link": "https://arxiv.org/abs/2507.13200v1",
          "size": "8038kb",
          "version": "v1"
        }
      ],
      "title": "Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13200",
        "HTML": "https://arxiv.org/html/2507.13200v1",
        "PDF": "https://arxiv.org/pdf/2507.13200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the transfer of tool-use skills in robots using human demonstrations, focusing on proximity and tactile sensing. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13204",
      "abstract": "Derivative computation is a key component of optimization, sensitivity analysis, uncertainty quantification, and nonlinear solvers. Automatic differentiation (AD) is a powerful technique for evaluating such derivatives, and in recent years, has been integrated into programming environments such as Jax, PyTorch, and TensorFlow to support derivative computations needed for training of machine learning models, resulting in widespread use of these technologies. The C++ language has become the de facto standard for scientific computing due to numerous factors, yet language complexity has made the adoption of AD technologies for C++ difficult, hampering the incorporation of powerful differentiable programming approaches into C++ scientific simulations. This is exacerbated by the increasing emergence of architectures such as GPUs, which have limited memory capabilities and require massive thread-level concurrency. Portable scientific codes rely on domain specific programming models such as Kokkos making AD for such codes even more complex. In this paper, we will investigate source transformation-based automatic differentiation using Clad to automatically generate portable and efficient gradient computations of Kokkos-based code. We discuss the modifications of Clad required to differentiate Kokkos abstractions. We will illustrate the feasibility of our proposed strategy by comparing the wall-clock time of the generated gradient code with the wall-clock time of the input function on different cutting edge GPU architectures such as NVIDIA H100, AMD MI250x, and Intel Ponte Vecchio GPU. For these three architectures and for the considered example, evaluating up to 10 000 entries of the gradient only took up to 2.17x the wall-clock time of evaluating the input function.",
      "authors": [
        "Kim Liegeois",
        "Brian Kelley",
        "Eric Phipps",
        "Sivasankaran Rajamanickam",
        "Vassil Vassilev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:15:25+00:00",
          "link": "https://arxiv.org/abs/2507.13204v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "Performance Portable Gradient Computations Using Source Transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13204",
        "HTML": "https://arxiv.org/html/2507.13204v1",
        "PDF": "https://arxiv.org/pdf/2507.13204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses source transformation-based automatic differentiation for gradient computation in scientific codes, focusing on hardware architectures. It is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13205",
      "abstract": "Developing narrative and comprehension skills in early childhood is critical for later literacy. However, teachers in large preschool classrooms struggle to accurately identify students who require intervention. We present a system for automatically assessing oral narratives of preschool children in Afrikaans and isiXhosa. The system uses automatic speech recognition followed by a machine learning scoring model to predict narrative and comprehension scores. For scoring predicted transcripts, we compare a linear model to a large language model (LLM). The LLM-based system outperforms the linear model in most cases, but the linear system is competitive despite its simplicity. The LLM-based system is comparable to a human expert in flagging children who require intervention. We lay the foundation for automatic oral assessments in classrooms, giving teachers extra capacity to focus on personalised support for children's learning.",
      "authors": [
        "R. Louw (1)",
        "E. Sharratt (1)",
        "F. de Wet (1)",
        "C. Jacobs (1)",
        "A. Smith (1)",
        "H. Kamper (1) ((1) Stellenbosch University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:15:43+00:00",
          "link": "https://arxiv.org/abs/2507.13205v1",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "title": "Automatically assessing oral narratives of Afrikaans and isiXhosa children",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13205",
        "HTML": "https://arxiv.org/html/2507.13205v1",
        "PDF": "https://arxiv.org/pdf/2507.13205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a system for assessing oral narratives using LLMs for scoring. It does not involve any significant aspect of training data processing such as dataset creation or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13207",
      "abstract": "Recent years have witnessed a growing interest for time series foundation models, with a strong emphasis on the forecasting task. Yet, the crucial task of out-of-domain imputation of missing values remains largely underexplored. We propose a first step to fill this gap by leveraging implicit neural representations (INRs). INRs model time series as continuous functions and naturally handle various missing data scenarios and sampling rates. While they have shown strong performance within specific distributions, they struggle under distribution shifts. To address this, we introduce MoTM (Mixture of Timeflow Models), a step toward a foundation model for time series imputation. Building on the idea that a new time series is a mixture of previously seen patterns, MoTM combines a basis of INRs, each trained independently on a distinct family of time series, with a ridge regressor that adapts to the observed context at inference. We demonstrate robust in-domain and out-of-domain generalization across diverse imputation scenarios (e.g., block and pointwise missingness, variable sampling rates), paving the way for adaptable foundation imputation models.",
      "authors": [
        "Etienne Le Naour",
        "Tahar Nabil",
        "Ghislain Agoua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:16:30+00:00",
          "link": "https://arxiv.org/abs/2507.13207v1",
          "size": "1296kb",
          "version": "v1"
        }
      ],
      "title": "MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13207",
        "HTML": "https://arxiv.org/html/2507.13207v1",
        "PDF": "https://arxiv.org/pdf/2507.13207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses time series imputation using implicit neural representations. It is not related to data processing for LLM pretraining or fine-tuning, nor does it discuss improving data quality or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13208",
      "abstract": "The combination of higher-order theories and fuzzy logic can be useful in decision-making tasks that involve reasoning across abstract functions and predicates, where exact matches are often rare or unnecessary. Developing efficient reasoning and computational techniques for such a combined formalism presents a significant challenge. In this paper, we adopt a more straightforward approach aiming at integrating two well-established and computationally well-behaved components: higher-order patterns on one side and fuzzy equivalences expressed through similarity relations based on minimum T-norm on the other. We propose a unification algorithm for higher-order patterns modulo these similarity relations and prove its termination, soundness, and completeness. This unification problem, like its crisp counterpart, is unitary. The algorithm computes a most general unifier with the highest degree of approximation when the given terms are unifiable.",
      "authors": [
        "Besik Dundua and Temur Kutsia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:18:22+00:00",
          "link": "https://arxiv.org/abs/2507.13208v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "Higher-Order Pattern Unification Modulo Similarity Relations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13208",
        "HTML": "https://arxiv.org/html/2507.13208v1",
        "PDF": "https://arxiv.org/pdf/2507.13208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an algorithm for higher-order pattern unification and does not make a contribution to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13221",
      "abstract": "While recent advancements in deep neural networks (DNNs) have substantially enhanced visual AI's capabilities, the challenge of inadequate data diversity and volume remains, particularly in construction domain. This study presents a novel image synthesis methodology tailored for construction worker detection, leveraging the generative-AI platform Midjourney. The approach entails generating a collection of 12,000 synthetic images by formulating 3000 different prompts, with an emphasis on image realism and diversity. These images, after manual labeling, serve as a dataset for DNN training. Evaluation on a real construction image dataset yielded promising results, with the model attaining average precisions (APs) of 0.937 and 0.642 at intersection-over-union (IoU) thresholds of 0.5 and 0.5 to 0.95, respectively. Notably, the model demonstrated near-perfect performance on the synthetic dataset, achieving APs of 0.994 and 0.919 at the two mentioned thresholds. These findings reveal both the potential and weakness of generative AI in addressing DNN training data scarcity.",
      "authors": [
        "Hongyang Zhao",
        "Tianyu Liang",
        "Sina Davari",
        "Daeho Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:35:27+00:00",
          "link": "https://arxiv.org/abs/2507.13221v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13221",
        "PDF": "https://arxiv.org/pdf/2507.13221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This study utilizes generative AI to produce synthetic images for training data of a specific detection model. Although it discusses data generation to enhance DNN training, it does not focus on LLMs specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13222",
      "abstract": "A central question in computer science and statistics is whether efficient algorithms can achieve the information-theoretic limits of statistical problems. Many computational-statistical tradeoffs have been shown under average-case assumptions, but since statistical problems are average-case in nature, it has been a challenge to base them on standard worst-case assumptions.\n  In PAC learning where such tradeoffs were first studied, the question is whether computational efficiency can come at the cost of using more samples than information-theoretically necessary. We base such tradeoffs on $\\mathsf{NP}$-hardness and obtain:\n  $\\circ$ Sharp computational-statistical tradeoffs assuming $\\mathsf{NP}$ requires exponential time: For every polynomial $p(n)$, there is an $n$-variate class $C$ with VC dimension $1$ such that the sample complexity of time-efficiently learning $C$ is $\\Theta(p(n))$.\n  $\\circ$ A characterization of $\\mathsf{RP}$ vs. $\\mathsf{NP}$ in terms of learning: $\\mathsf{RP} = \\mathsf{NP}$ iff every $\\mathsf{NP}$-enumerable class is learnable with $O(\\mathrm{VCdim}(C))$ samples in polynomial time. The forward implication has been known since (Pitt and Valiant, 1988); we prove the reverse implication.\n  Notably, all our lower bounds hold against improper learners. These are the first $\\mathsf{NP}$-hardness results for improperly learning a subclass of polynomial-size circuits, circumventing formal barriers of Applebaum, Barak, and Xiao (2008).",
      "authors": [
        "Guy Blanc",
        "Caleb Koch",
        "Carmen Strassle",
        "and Li-Yang Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:35:36+00:00",
          "link": "https://arxiv.org/abs/2507.13222v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Computational-Statistical Tradeoffs from NP-hardness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13222",
        "HTML": "https://arxiv.org/html/2507.13222v1",
        "PDF": "https://arxiv.org/pdf/2507.13222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computational-statistical tradeoffs related to NP-hardness and is concerned with learning theory rather than training data processing or dataset creation for LLMs or similar models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13224",
      "abstract": "Recent advances in Generative AI (GenAI) have led to significant improvements in the quality of generated visual content. As AI-generated visual content becomes increasingly indistinguishable from real content, the challenge of detecting the generated content becomes critical in combating misinformation, ensuring privacy, and preventing security threats. Although there has been substantial progress in detecting AI-generated images, current methods for video detection are largely focused on deepfakes, which primarily involve human faces. However, the field of video generation has advanced beyond DeepFakes, creating an urgent need for methods capable of detecting AI-generated videos with generic content. To address this gap, we propose a novel approach that leverages pre-trained visual models to distinguish between real and generated videos. The features extracted from these pre-trained models, which have been trained on extensive real visual content, contain inherent signals that can help distinguish real from generated videos. Using these extracted features, we achieve high detection performance without requiring additional model training, and we further improve performance by training a simple linear classification layer on top of the extracted features. We validated our method on a dataset we compiled (VID-AID), which includes around 10,000 AI-generated videos produced by 9 different text-to-video models, along with 4,000 real videos, totaling over 7 hours of video content. Our evaluation shows that our approach achieves high detection accuracy, above 90% on average, underscoring its effectiveness. Upon acceptance, we plan to publicly release the code, the pre-trained models, and our dataset to support ongoing research in this critical area.",
      "authors": [
        "Keerthi Veeramachaneni and Praveen Tirupattur and Amrit Singh Bedi and Mubarak Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:36:39+00:00",
          "link": "https://arxiv.org/abs/2507.13224v1",
          "size": "26064kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Pre-Trained Visual Models for AI-Generated Video Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13224",
        "HTML": "https://arxiv.org/html/2507.13224v1",
        "PDF": "https://arxiv.org/pdf/2507.13224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions compiling a dataset (VID-AID) for detecting AI-generated videos, but the primary focus is on using pre-trained visual models for detection, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13225",
      "abstract": "This work presents a novel co-design strategy that integrates trajectory planning and control to handle STL-based tasks in autonomous robots. The method consists of two phases: $(i)$ learning spatio-temporal motion primitives to encapsulate the inherent robot-specific constraints and $(ii)$ constructing an STL-compliant motion plan from these primitives. Initially, we employ reinforcement learning to construct a library of control policies that perform trajectories described by the motion primitives. Then, we map motion primitives to spatio-temporal characteristics. Subsequently, we present a sampling-based STL-compliant motion planning strategy tailored to meet the STL specification. The proposed model-free approach, which generates feasible STL-compliant motion plans across various environments, is validated on differential-drive and quadruped robots across various STL specifications. Demonstration videos are available at https://tinyurl.com/m6zp7rsm.",
      "authors": [
        "Manas Sashank Juvvi",
        "Tushar Dilip Kurne",
        "Vaishnavi J",
        "Shishir Kolathaya and Pushpak Jagtap"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:37:24+00:00",
          "link": "https://arxiv.org/abs/2507.13225v1",
          "size": "3722kb",
          "version": "v1"
        }
      ],
      "title": "Signal Temporal Logic Compliant Co-design of Planning and Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13225",
        "HTML": "https://arxiv.org/html/2507.13225v1",
        "PDF": "https://arxiv.org/pdf/2507.13225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a co-design strategy for trajectory planning and control in autonomous robots. It does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13229",
      "abstract": "The pursuit of a generalizable stereo matching model, capable of performing across varying resolutions and disparity ranges without dataset-specific fine-tuning, has revealed a fundamental trade-off. Iterative local search methods achieve high scores on constrained benchmarks, but their core mechanism inherently limits the global consistency required for true generalization. On the other hand, global matching architectures, while theoretically more robust, have been historically rendered infeasible by prohibitive computational and memory costs. We resolve this dilemma with $S^2M^2$: a global matching architecture that achieves both state-of-the-art accuracy and high efficiency without relying on cost volume filtering or deep refinement stacks. Our design integrates a multi-resolution transformer for robust long-range correspondence, trained with a novel loss function that concentrates probability on feasible matches. This approach enables a more robust joint estimation of disparity, occlusion, and confidence. $S^2M^2$ establishes a new state of the art on the Middlebury v3 and ETH3D benchmarks, significantly outperforming prior methods across most metrics while reconstructing high-quality details with competitive efficiency.",
      "authors": [
        "Junhong Min",
        "Youngpil Jeon",
        "Jimin Kim",
        "Minyong Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:40:18+00:00",
          "link": "https://arxiv.org/abs/2507.13229v1",
          "size": "4684kb",
          "version": "v1"
        }
      ],
      "title": "$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13229",
        "HTML": "https://arxiv.org/html/2507.13229v1",
        "PDF": "https://arxiv.org/pdf/2507.13229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on stereo matching model improvements for depth estimation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13231",
      "abstract": "We present VITA, a Vision-To-Action flow matching policy that evolves latent visual representations into latent actions for visuomotor control. Traditional flow matching and diffusion policies sample from standard source distributions (e.g., Gaussian noise) and require additional conditioning mechanisms like cross-attention to condition action generation on visual information, creating time and space overheads. VITA proposes a novel paradigm that treats latent images as the flow source, learning an inherent mapping from vision to action while eliminating separate conditioning modules and preserving generative modeling capabilities. Learning flows between fundamentally different modalities like vision and action is challenging due to sparse action data lacking semantic structures and dimensional mismatches between high-dimensional visual representations and raw actions. We address this by creating a structured action latent space via an autoencoder as the flow matching target, up-sampling raw actions to match visual representation shapes. Crucially, we supervise flow matching with both encoder targets and final action outputs through flow latent decoding, which backpropagates action reconstruction loss through sequential flow matching ODE solving steps for effective end-to-end learning. Implemented as simple MLP layers, VITA is evaluated on challenging bi-manual manipulation tasks on the ALOHA platform, including 5 simulation and 2 real-world tasks. Despite its simplicity, MLP-only VITA outperforms or matches state-of-the-art generative policies while reducing inference latency by 50-130% compared to conventional flow matching policies requiring different conditioning mechanisms or complex architectures. To our knowledge, VITA is the first MLP-only flow matching policy capable of solving complex bi-manual manipulation tasks like those in ALOHA benchmarks.",
      "authors": [
        "Dechen Gao",
        "Boqi Zhao",
        "Andrew Lee",
        "Ian Chuang",
        "Hanchu Zhou",
        "Hang Wang",
        "Zhe Zhao",
        "Junshan Zhang",
        "Iman Soltani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:41:57+00:00",
          "link": "https://arxiv.org/abs/2507.13231v1",
          "size": "1045kb",
          "version": "v1"
        }
      ],
      "title": "VITA: Vision-to-Action Flow Matching Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13231",
        "HTML": "https://arxiv.org/html/2507.13231v1",
        "PDF": "https://arxiv.org/pdf/2507.13231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on VITA, a vision-to-action flow matching policy for visuomotor control, which doesn\u2019t relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13235",
      "abstract": "Cognitive load is key to ensuring an optimal learning experience. However, measuring the cognitive load of educational tasks typically relies on self-report measures which has been criticized by researchers for being subjective. In this study, we investigated the feasibility of using item difficulty parameters as a proxy for measuring cognitive load in an online learning platform. Difficulty values that were derived using item-response theory were consistent with theories of how intrinsic and extraneous load contribute to cognitive load. This finding suggests that we can use item difficulty to represent intrinsic load when modelling cognitive load in learning games.",
      "authors": [
        "Minghao Cai",
        "Guher Gorgun",
        "and Carrie Demmans Epp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:44:44+00:00",
          "link": "https://arxiv.org/abs/2507.13235v1",
          "size": "352kb",
          "version": "v1"
        }
      ],
      "title": "Difficulty as a Proxy for Measuring Intrinsic Cognitive Load Item",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13235",
        "PDF": "https://arxiv.org/pdf/2507.13235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates cognitive load measurement in educational settings, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13236",
      "abstract": "Large language models (LLMs) have shown impressive abilities in leveraging pretrained knowledge through prompting, but they often struggle with unseen tasks, particularly in data-scarce scenarios. While cross-task in-context learning offers a direct solution for transferring knowledge across tasks, it still faces critical challenges in terms of robustness, scalability, and efficiency. In this paper, we investigate whether cross-task transfer can be achieved via latent space steering without parameter updates or input expansion. Through an analysis of activation patterns in the latent space of LLMs, we observe that the enhanced activations induced by in-context examples have consistent patterns across different tasks. Inspired by these findings, we propose CAST, a novel Cross-task Activation Steering Transfer framework that enables effective transfer by manipulating the model's internal activation states. Our approach first selects influential and diverse samples from high-resource tasks, then utilizes their contrastive representation-enhanced activations to adapt LLMs to low-resource tasks. Extensive experiments across both cross-domain and cross-lingual transfer settings show that our method outperforms competitive baselines and demonstrates superior scalability and lower computational costs.",
      "authors": [
        "Xinyu Tang",
        "Zhihao Lv",
        "Xiaoxue Cheng",
        "Junyi Li",
        "Wayne Xin Zhao",
        "Zujie Wen",
        "Zhiqiang Zhang",
        "Jun Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:47:22+00:00",
          "link": "https://arxiv.org/abs/2507.13236v1",
          "size": "416kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Cross-task Transfer of Large Language Models via Activation Steering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13236",
        "HTML": "https://arxiv.org/html/2507.13236v1",
        "PDF": "https://arxiv.org/pdf/2507.13236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving cross-task transfer in LLMs via a technique called activation steering. It primarily addresses model optimization and cross-task learning rather than any aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13238",
      "abstract": "Analogies test a model's ability to infer implicit relationships between concepts, making them a key benchmark for evaluating reasoning capabilities. While large language models (LLMs) are widely evaluated for reasoning in English, their abilities in Indic languages remain understudied, limiting our understanding of whether these models generalize across languages. To address this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405 multiple-choice questions sourced from Indian government exams. We benchmark state-of-the-art multilingual LLMs using various prompting strategies and introduce a grounded Chain of Thought approach that leverages cognitive theories of analogical reasoning. This approach improves model performance on Hindi analogy questions. Our experiments show that models perform best with English prompts, irrespective of the prompting strategy. Our test set addresses the lack of a critical resource to evaluate LLM reasoning capabilities in Hindi.",
      "authors": [
        "Ashray Gupta and Rohan Joseph and Sunny Rai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.13238v1",
          "size": "576kb",
          "version": "v1"
        }
      ],
      "title": "HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13238",
        "PDF": "https://arxiv.org/pdf/2507.13238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new Hindi Analogy Test Set (HATS) for evaluating reasoning in LLMs, which involves dataset creation. However, its main focus is on reasoning evaluation and cross-language model analysis, not on LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13242",
      "abstract": "In this work, we consider the resource allocation problem for task offloading from Internet of Medical Things (IoMT) devices, to a non-terrestrial network. The architecture considers clusters of IoMT devices that offload their tasks to a dedicated unmanned aerial vehicle (UAV) serving as a multi-access edge computing (MEC) server, which can compute the task or further offload it to an available high-altitude platform station (HAPS) or to a low-earth orbit (LEO) satellite for remote computing. We formulate a problem that has as objective the minimization of the weighted sum delay of the tasks. Given the non-convex nature of the problem, and acknowledging that the complexity of the optimization algorithms impact their performance, we derive a low-complexity joint subchannel allocation and offloading decision algorithm with dynamic computing resource initialization, developed as a greedy heuristic based on convex optimization criteria. Simulations show the gain obtained by including the different non-terrestrial nodes against architectures without them.",
      "authors": [
        "Alejandro Flores C.",
        "Konstantinos Ntontin",
        "Ashok Bandi",
        "Symeon Chatzinotas"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:52:14+00:00",
          "link": "https://arxiv.org/abs/2507.13242v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "QTCAJOSA: Low-Complexity Joint Offloading and Subchannel Allocation for NTN-Enabled IoMT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13242",
        "HTML": "https://arxiv.org/html/2507.13242v1",
        "PDF": "https://arxiv.org/pdf/2507.13242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses resource allocation in Internet of Medical Things (IoMT) devices, not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13247",
      "abstract": "Reminiscence activities, which involve recalling and sharing past experiences, have proven beneficial for improving cognitive function, mood, and overall well-being. However, urbanization has led to the disappearance of familiar environments, removing visual and audio cues for effective reminiscence. While old photos can serve as visual cues to aid reminiscence, it is challenging for people to reconstruct the reminisced content and environment that are not in the photos. Virtual reality (VR) and artificial intelligence (AI) offer the ability to reconstruct an immersive environment with dynamic content and to converse with people to help them gradually reminisce. We designed RemVerse, an AI-empowered VR prototype aimed to support reminiscence activities. Integrating generative models and AI agent into a VR environment, RemVerse helps older adults reminisce with AI-generated visual cues and interactive dialogues. Our user study with 14 older adults showed that RemVerse effectively supported reminiscence activities by triggering, concretizing, and deepening personal memories, while fostering increased engagement and autonomy among older adults. Based on our findings, we proposed design implications to make reminiscence activities in AI-assisted VR more accessible and engaging for older adults.",
      "authors": [
        "Ruohao Li",
        "Jiawei Li",
        "Jia Sun",
        "Zhiqing Wu",
        "Zisu Li",
        "Ziyan Wang",
        "Ge Lin Kan",
        "Mingming Fan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:55:38+00:00",
          "link": "https://arxiv.org/abs/2507.13247v1",
          "size": "21649kb",
          "version": "v1"
        }
      ],
      "title": "RemVerse: Supporting Reminiscence Activities for Older Adults through AI-Assisted Virtual Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13247",
        "HTML": "https://arxiv.org/html/2507.13247v1",
        "PDF": "https://arxiv.org/pdf/2507.13247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on using AI-assisted virtual reality for reminiscence activities for older adults. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13250",
      "abstract": "Accurate short-term electricity price forecasting is crucial for strategically scheduling demand and generation bids in day-ahead markets. While data-driven techniques have shown considerable prowess in achieving high forecast accuracy in recent years, they rely heavily on the quality of input covariates. In this paper, we investigate whether asynchronously published prices as a result of differing gate closure times (GCTs) in some bidding zones can improve forecasting accuracy in other markets with later GCTs. Using a state-of-the-art ensemble of models, we show significant improvements of 22% and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3) respectively, when including price data from interconnected markets with earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement holds for both general as well as extreme market conditions. Our analysis also yields further important insights: frequent model recalibration is necessary for maximum accuracy but comes at substantial additional computational costs, and using data from more markets does not always lead to better performance - a fact we delve deeper into with interpretability analysis of the forecast models. Overall, these findings provide valuable guidance for market participants and decision-makers aiming to optimize bidding strategies within increasingly interconnected and volatile European energy markets.",
      "authors": [
        "Maria Margarida Mascarenhas",
        "Jilles De Blauwe",
        "Mikael Amelin",
        "Hussain Kazmi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:59:00+00:00",
          "link": "https://arxiv.org/abs/2507.13250v1",
          "size": "956kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13250",
        "HTML": "https://arxiv.org/html/2507.13250v1",
        "PDF": "https://arxiv.org/pdf/2507.13250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on electricity price forecasting using asynchronous cross-border market data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13255",
      "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) has unlocked powerful cross-modal reasoning abilities, but also raised new safety concerns, particularly when faced with adversarial multimodal inputs. To improve the safety of MLLMs during inference, we introduce a modular and adaptive inference-time intervention technology, AutoSteer, without requiring any fine-tuning of the underlying model. AutoSteer incorporates three core components: (1) a novel Safety Awareness Score (SAS) that automatically identifies the most safety-relevant distinctions among the model's internal layers; (2) an adaptive safety prober trained to estimate the likelihood of toxic outputs from intermediate representations; and (3) a lightweight Refusal Head that selectively intervenes to modulate generation when safety risks are detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical benchmarks demonstrate that AutoSteer significantly reduces the Attack Success Rate (ASR) for textual, visual, and cross-modal threats, while maintaining general abilities. These findings position AutoSteer as a practical, interpretable, and effective framework for safer deployment of multimodal AI systems.",
      "authors": [
        "Lyucheng Wu",
        "Mengru Wang",
        "Ziwen Xu",
        "Tri Cao",
        "Nay Oo",
        "Bryan Hooi",
        "Shumin Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:04:55+00:00",
          "link": "https://arxiv.org/abs/2507.13255v1",
          "size": "20968kb",
          "version": "v1"
        }
      ],
      "title": "Automating Steering for Safe Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13255",
        "HTML": "https://arxiv.org/html/2507.13255v1",
        "PDF": "https://arxiv.org/pdf/2507.13255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper introduces safety mechanisms for multimodal LLMs, it primarily addresses inference-time interventions rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13260",
      "abstract": "A prevalent approach in Parameter-Efficient Fine-Tuning (PEFT) of pre-trained Vision Transformers (ViT) involves freezing the majority of the backbone parameters and solely learning low-rank adaptation weight matrices to accommodate downstream tasks. These low-rank matrices are commonly derived through the multiplication structure of down-projection and up-projection matrices, exemplified by methods such as LoRA and Adapter. In this work, we observe an approximate orthogonality among any two row or column vectors within any weight matrix of the backbone parameters; however, this property is absent in the vectors of the down/up-projection matrices. Approximate orthogonality implies a reduction in the upper bound of the model's generalization error, signifying that the model possesses enhanced generalization capability. If the fine-tuned down/up-projection matrices were to exhibit this same property as the pre-trained backbone matrices, could the generalization capability of fine-tuned ViTs be further augmented? To address this question, we propose an Approximately Orthogonal Fine-Tuning (AOFT) strategy for representing the low-rank weight matrices. This strategy employs a single learnable vector to generate a set of approximately orthogonal vectors, which form the down/up-projection matrices, thereby aligning the properties of these matrices with those of the backbone. Extensive experimental results demonstrate that our method achieves competitive performance across a range of downstream image classification tasks, confirming the efficacy of the enhanced generalization capability embedded in the down/up-projection matrices.",
      "authors": [
        "Yiting Yang",
        "Hao Luo",
        "Yuan Sun",
        "Qingsen Yan",
        "Haokui Zhang",
        "Wei Dong",
        "Guoqing Wang",
        "Peng Wang",
        "Yang Yang",
        "Hengtao Shen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:09:05+00:00",
          "link": "https://arxiv.org/abs/2507.13260v1",
          "size": "341kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13260",
        "HTML": "https://arxiv.org/html/2507.13260v1",
        "PDF": "https://arxiv.org/pdf/2507.13260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the fine-tuning of Vision Transformers, focusing on parameter-efficient strategies, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13263",
      "abstract": "Bayesian Optimization (BO) algorithm is a standard tool for black-box optimization problems. The current state-of-the-art BO approach for permutation spaces relies on the Mallows kernel-an $\\Omega(n^2)$ representation that explicitly enumerates every pairwise comparison. Inspired by the close relationship between the Mallows kernel and pairwise comparison, we propose a novel framework for generating kernel functions on permutation space based on sorting algorithms. Within this framework, the Mallows kernel can be viewed as a special instance derived from bubble sort. Further, we introduce the \\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic complexity with $\\Theta(n\\log n)$ to achieve the lowest possible complexity. The resulting feature vector is significantly shorter, can be computed in linearithmic time, yet still efficiently captures meaningful permutation distances. To boost robustness and right-invariance without sacrificing compactness, we further incorporate three lightweight, task-agnostic descriptors: (1) a shift histogram, which aggregates absolute element displacements and supplies a global misplacement signal; (2) a split-pair line, which encodes selected long-range comparisons by aligning elements across the two halves of the whole permutation; and (3) sliding-window motifs, which summarize local order patterns that influence near-neighbor objectives. Our empirical evaluation demonstrates that the proposed kernel consistently outperforms the state-of-the-art Mallows kernel across various permutation optimization benchmarks. Results confirm that the Merge Kernel provides a more compact yet more effective solution for Bayesian optimization in permutation space.",
      "authors": [
        "Zikai Xie",
        "Linjiang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.13263v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "Merge Kernel for Bayesian Optimization on Permutation Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13263",
        "HTML": "https://arxiv.org/html/2507.13263v1",
        "PDF": "https://arxiv.org/pdf/2507.13263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work presented introduces a kernel for Bayesian optimization on permutation space, which is not related to LLM training data processing or improvements in data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13264",
      "abstract": "We present Voxtral Mini and Voxtral Small, two multimodal audio chat models. Voxtral is trained to comprehend both spoken audio and text documents, achieving state-of-the-art performance across a diverse range of audio benchmarks, while preserving strong text capabilities. Voxtral Small outperforms a number of closed-source models, while being small enough to run locally. A 32K context window enables the model to handle audio files up to 40 minutes in duration and long multi-turn conversations. We also contribute three benchmarks for evaluating speech understanding models on knowledge and trivia. Both Voxtral models are released under Apache 2.0 license.",
      "authors": [
        "Alexander H. Liu",
        "Andy Ehrenberg",
        "Andy Lo",
        "Cl\\'ement Denoix",
        "Corentin Barreau",
        "Guillaume Lample",
        "Jean-Malo Delignon",
        "Khyathi Raghavi Chandu",
        "Patrick von Platen",
        "Pavankumar Reddy Muddireddy",
        "Sanchit Gandhi",
        "Soham Ghosh",
        "Srijan Mishra",
        "Thomas Foubert",
        "Abhinav Rastogi",
        "Adam Yang",
        "Albert Q. Jiang",
        "Alexandre Sablayrolles",
        "Am\\'elie H\\'eliou",
        "Am\\'elie Martin",
        "Anmol Agarwal",
        "Antoine Roux",
        "Arthur Darcet",
        "Arthur Mensch",
        "Baptiste Bout",
        "Baptiste Rozi\\`ere",
        "Baudouin De Monicault",
        "Chris Bamford",
        "Christian Wallenwein",
        "Christophe Renaudin",
        "Cl\\'emence Lanfranchi",
        "Darius Dabert",
        "Devendra Singh Chaplot",
        "Devon Mizelle",
        "Diego de las Casas",
        "Elliot Chane-Sane",
        "Emilien Fugier",
        "Emma Bou Hanna",
        "Gabrielle Berrada",
        "Gauthier Delerce",
        "Gauthier Guinet",
        "Georgii Novikov",
        "Guillaume Martin",
        "Himanshu Jaju",
        "Jan Ludziejewski",
        "Jason Rute",
        "Jean-Hadrien Chabran",
        "Jessica Chudnovsky",
        "Joachim Studnia",
        "Joep Barmentlo",
        "Jonas Amar",
        "Josselin Somerville Roberts",
        "Julien Denize",
        "Karan Saxena",
        "Karmesh Yadav",
        "Kartik Khandelwal",
        "Kush Jain",
        "L\\'elio Renard Lavaud",
        "L\\'eonard Blier",
        "Lingxiao Zhao",
        "Louis Martin",
        "Lucile Saulnier",
        "Luyu Gao",
        "Marie Pellat",
        "Mathilde Guillaumin",
        "Mathis Felardos",
        "Matthieu Dinot",
        "Maxime Darrin",
        "Maximilian Augustin",
        "Micka\\\"el Seznec",
        "Neha Gupta",
        "Nikhil Raghuraman",
        "Olivier Duchenne",
        "Patricia Wang",
        "Patryk Saffer",
        "Paul Jacob",
        "Paul Wambergue",
        "Paula Kurylowicz",
        "Philom\\`ene Chagniot",
        "Pierre Stock",
        "Pravesh Agrawal",
        "R\\'emi Delacourt",
        "Romain Sauvestre",
        "Roman Soletskyi",
        "Sagar Vaze",
        "Sandeep Subramanian",
        "Saurabh Garg",
        "Shashwat Dalal",
        "Siddharth Gandhi",
        "Sumukh Aithal",
        "Szymon Antoniak",
        "Teven Le Scao",
        "Thibault Schueller",
        "Thibaut Lavril",
        "Thomas Robert",
        "Thomas Wang",
        "Timoth\\'ee Lacroix",
        "Tom Bewley",
        "Valeriia Nemychnikova",
        "Victor Paltz",
        "Virgile Richard",
        "Wen-Ding Li",
        "William Marshall",
        "Xuanyu Zhang",
        "Yihan Wan",
        "Yunhao Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:17:37+00:00",
          "link": "https://arxiv.org/abs/2507.13264v1",
          "size": "5813kb",
          "version": "v1"
        }
      ],
      "title": "Voxtral",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13264",
        "HTML": "https://arxiv.org/html/2507.13264v1",
        "PDF": "https://arxiv.org/pdf/2507.13264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal audio chat models and their performance across audio benchmarks, with no discussion of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13265",
      "abstract": "This paper introduces a framework to address the critical loss of transient stability caused by reduced inertia in grids with high inverter-based resource (IBR) penetration. The proposed method integrates a predictive deep learning (DL) model with information gap decision theory (IGDT) to create a risk-averse dispatch strategy. By reformulating the conventional virtual inertia scheduling (VIS) problem, the framework uses early predictions of post-fault dynamics to proactively redispatch resources, ensuring the system's center of inertia remains stable under worst-case contingencies. Validated on the IEEE 39-bus system with 70% IBR penetration, the proposed approach prevents system collapse where a conventional VIS strategy fails, ensuring frequency stability at a cost increase of only 5%.",
      "authors": [
        "Amin Masoumi",
        "Mert Korkali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:18:55+00:00",
          "link": "https://arxiv.org/abs/2507.13265v1",
          "size": "718kb",
          "version": "v1"
        }
      ],
      "title": "Transient-Stability-Aware Frequency Provision in IBR-Rich Grids via Information Gap Decision Theory and Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13265",
        "HTML": "https://arxiv.org/html/2507.13265v1",
        "PDF": "https://arxiv.org/pdf/2507.13265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for addressing transient stability in grids with high inverter-based resource penetration using deep learning, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13266",
      "abstract": "Reinforcement learning (RL) has become a key component in training large language reasoning models (LLMs). However, recent studies questions its effectiveness in improving multi-step reasoning-particularly on hard problems. To address this challenge, we propose a simple yet effective strategy via Question Augmentation: introduce partial solutions during training to reduce problem difficulty and provide more informative learning signals. Our method, QuestA, when applied during RL training on math reasoning tasks, not only improves pass@1 but also pass@k-particularly on problems where standard RL struggles to make progress. This enables continual improvement over strong open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing their reasoning capabilities. We achieve new state-of-the-art results on math benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%) on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical explanations that QuestA improves sample efficiency, offering a practical and generalizable pathway for expanding reasoning capability through RL.",
      "authors": [
        "Jiazheng Li",
        "Hong Lu",
        "Kaiyue Wen",
        "Zaiwen Yang",
        "Jiaxuan Gao",
        "Hongzhou Lin",
        "Yi Wu",
        "Jingzhao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.13266v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13266",
        "PDF": "https://arxiv.org/pdf/2507.13266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a strategy called Question Augmentation to improve LLMs' reasoning capabilities through reduced problem difficulty, focusing on training improvements rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13275",
      "abstract": "Advances in natural language processing and large language models are driving a major transformation in Human Capital Management, with a growing interest in building smart systems based on language technologies for talent acquisition, upskilling strategies, and workforce planning. However, the adoption and progress of these technologies critically depend on the development of reliable and fair models, properly evaluated on public data and open benchmarks, which have so far been unavailable in this domain.\n  To address this gap, we present TalentCLEF 2025, the first evaluation campaign focused on skill and job title intelligence. The lab consists of two tasks: Task A - Multilingual Job Title Matching, covering English, Spanish, German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English. Both corpora were built from real job applications, carefully anonymized, and manually annotated to reflect the complexity and diversity of real-world labor market data, including linguistic variability and gender-marked expressions.\n  The evaluations included monolingual and cross-lingual scenarios and covered the evaluation of gender bias.\n  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most systems relied on information retrieval techniques built with multilingual encoder-based models fine-tuned with contrastive learning, and several of them incorporated large language models for data augmentation or re-ranking. The results show that the training strategies have a larger effect than the size of the model alone. TalentCLEF provides the first public benchmark in this field and encourages the development of robust, fair, and transferable language technologies for the labor market.",
      "authors": [
        "Luis Gasco",
        "Hermenegildo Fabregat",
        "Laura Garc\\'ia-Sardi\\~na",
        "Paula Estrella",
        "Daniel Deniz",
        "Alvaro Rodrigo",
        "and Rabih Zbib"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:33:57+00:00",
          "link": "https://arxiv.org/abs/2507.13275v1",
          "size": "909kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13275",
        "HTML": "https://arxiv.org/html/2507.13275v1",
        "PDF": "https://arxiv.org/pdf/2507.13275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents TalentCLEF 2025 with tasks involving job title and skill intelligence, discussing data annotation and evaluation in the human capital field, but not focused specifically on dataset processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13277",
      "abstract": "Robots are increasingly integrated across industries, particularly in healthcare. However, many valuable applications for quadrupedal robots remain overlooked. This research explores the effectiveness of three reinforcement learning algorithms in training a simulated quadruped robot for autonomous navigation and obstacle avoidance. The goal is to develop a robotic guide dog simulation capable of path following and obstacle avoidance, with long-term potential for real-world assistance to guide dogs and visually impaired individuals. It also seeks to expand research into medical 'pets', including robotic guide and alert dogs.\n  A comparative analysis of thirteen related research papers shaped key evaluation criteria, including collision detection, pathfinding algorithms, sensor usage, robot type, and simulation platforms. The study focuses on sensor inputs, collision frequency, reward signals, and learning progression to determine which algorithm best supports robotic navigation in complex environments.\n  Custom-made environments were used to ensure fair evaluation of all three algorithms under controlled conditions, allowing consistent data collection. Results show that Proximal Policy Optimization (PPO) outperformed Deep Q-Network (DQN) and Q-learning across all metrics, particularly in average and median steps to goal per episode.\n  By analysing these results, this study contributes to robotic navigation, AI and medical robotics, offering insights into the feasibility of AI-driven quadruped mobility and its role in assistive robotics.",
      "authors": [
        "Emma M. A. Harrison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:38:14+00:00",
          "link": "https://arxiv.org/abs/2507.13277v1",
          "size": "1345kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13277",
        "PDF": "https://arxiv.org/pdf/2507.13277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning algorithms for robotic navigation in quadruped robots, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13281",
      "abstract": "This work-in-progress paper presents a case study in which counterfeit TL074 operational amplifiers, discovered in a junior level electronics course, became the basis for a hands on learning experience. Counterfeit integrated circuits (IC) are increasingly common, posing a significant threat to the integrity of undergraduate electronics laboratories. Instead of simply replacing the counterfeit components, we turned the issue into a teaching moment. Students engaged in hands-on diagnostics measuring current, analyzing waveforms, and troubleshooting. By working with fake chip components, they gained deeper insight into analog circuits, supply chain security, and practical engineering.",
      "authors": [
        "Haniye Mehraban",
        "Saad Azmeen-ur-Rahman",
        "John Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:47:14+00:00",
          "link": "https://arxiv.org/abs/2507.13281v1",
          "size": "8460kb",
          "version": "v1"
        }
      ],
      "title": "WIP: Turning Fake Chips into Learning Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13281",
        "HTML": "https://arxiv.org/html/2507.13281v1",
        "PDF": "https://arxiv.org/pdf/2507.13281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a case study concerning counterfeit chips in electronics education, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13282",
      "abstract": "Earlier we introduced the notion of a stable set of points (SSP). We proved that a CNF formula is unsatisfiable iff there is a set of points (i.e. complete assignments) that is stable with respect to this formula. Experiments showed that SSPs for CNF formulas of practical interest are very large. So computing an SSP for a CNF formula point by point is, in general, infeasible. In this report, we show how an SSP can be computed in clusters, each cluster being a large set of points that are processed simultaneously. The appeal of computing SSPs is twofold. First, it allows one to better take into account formula structure and hence, arguably, design more efficient SAT algorithms. Second, SAT solving by SSPs facilitates parallel computing.",
      "authors": [
        "Eugene Goldberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.13282v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "Solving SAT By Computing A Stable Set Of Points In Clusters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13282",
        "HTML": "https://arxiv.org/html/2507.13282v1",
        "PDF": "https://arxiv.org/pdf/2507.13282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for solving SAT problems using the concept of stable sets of points, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13284",
      "abstract": "This paper presents high-order, well-balanced, path-conservative discontinuous Galerkin (DG) methods for the shallow water linearized moment equations (SWLME), designed to preserve both still and moving water equilibrium states. Unlike the multi-layer shallow water equations, which model vertical velocity variations using multiple distinct layers, the SWLME employs a polynomial expansion of velocity profiles with up to $N$ moments. This approach enables a more detailed representation of vertical momentum transfer and complex velocity profiles while retaining hyperbolicity. However, the presence of non-conservative terms and complex steady-state structures introduces significant numerical challenges. Addressing these challenges, we develop path-conservative DG schemes grounded in the Dal Maso-LeFloch-Murat (DLM) theory for non-conservative products. Our method balances flux gradients, non-conservative terms, and source terms through equilibrium-preserving spaces. For the still water equilibrium, we reformulate the equations into a quasilinear form that eliminates source terms, inherently preserving steady states. For the moving water equilibrium, we extend the DG method by transforming conservative variables into equilibrium variables and employing linear segment paths. Theoretical analysis and numerical experiments demonstrate that the proposed methods achieve exact equilibrium preservation while maintaining high-order accuracy, even in scenarios with vertical velocity variations and complex topographies.",
      "authors": [
        "Ruilin Fan",
        "Julian Koellermeier",
        "Yinhua Xia",
        "Yan Xu",
        "Jiahui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:49:01+00:00",
          "link": "https://arxiv.org/abs/2507.13284v1",
          "size": "793kb",
          "version": "v1"
        }
      ],
      "title": "Well-balanced path-conservative discontinuous Galerkin methods with equilibrium preserving space for shallow water linearized moment equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13284",
        "HTML": "https://arxiv.org/html/2507.13284v1",
        "PDF": "https://arxiv.org/pdf/2507.13284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents numerical methods for solving shallow water equations, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13285",
      "abstract": "Automated generation of high-quality media presentations is challenging, requiring robust content extraction, narrative planning, visual design, and overall quality optimization. Existing methods often produce presentations with logical inconsistencies and suboptimal layouts, thereby struggling to meet professional standards. To address these challenges, we introduce RCPS (Reflective Coherent Presentation Synthesis), a novel framework integrating three key components: (1) Deep Structured Narrative Planning; (2) Adaptive Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose PREVAL, a preference-based evaluation framework employing rationale-enhanced multi-dimensional models to assess presentation quality across Content, Coherence, and Design. Experimental results demonstrate that RCPS significantly outperforms baseline methods across all quality dimensions, producing presentations that closely approximate human expert standards. PREVAL shows strong correlation with human judgments, validating it as a reliable automated tool for assessing presentation quality.",
      "authors": [
        "Wang Xi",
        "Quan Shi",
        "Tian Yu",
        "Yujie Peng",
        "Jiayi Sun",
        "Mengxing Ren",
        "Zenghui Ding",
        "Ningguang Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.13285v1",
          "size": "6319kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13285",
        "HTML": "https://arxiv.org/html/2507.13285v1",
        "PDF": "https://arxiv.org/pdf/2507.13285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automated generation of visual media presentations, emphasizing narrative planning, adaptive layout generation, and quality optimization, but it does not address any aspects of LLM training data processing or data operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13286",
      "abstract": "Wireless sensor networks (WSNs) are critical components in modern cyber-physical systems, enabling efficient data collection and fusion through spatially distributed sensors. However, the inherent risks of eavesdropping and packet dropouts in such networks pose significant challenges to secure state estimation. In this paper, we address the privacy-preserving fusion estimation (PPFE) problem for multi-sensor systems under multiple packet dropouts and eavesdropping attacks. To mitigate these issues, we propose a distributed encoding-based privacy-preserving mechanism (PPM) within a control-theoretic framework, ensuring data privacy during transmission while maintaining the performance of legitimate state estimation. A centralized fusion filter is developed, accounting for the coupling effects of packet dropouts and the encoding-based PPM. Boundedness conditions for the legitimate user's estimation error covariance are derived via a modified algebraic Riccati equation. Additionally, by demonstrating the divergence of the eavesdropper's mean estimation error, the proposed PPFE algorithm's data confidentiality is rigorously analyzed. Simulation results for an Internet-based three-tank system validate the effectiveness of the proposed approach, highlighting its potential to enhance privacy without compromising estimation accuracy.",
      "authors": [
        "Jie Huang",
        "and Jason J. R. Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:50:15+00:00",
          "link": "https://arxiv.org/abs/2507.13286v1",
          "size": "496kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Fusion for Multi-Sensor Systems Under Multiple Packet Dropouts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13286",
        "HTML": "https://arxiv.org/html/2507.13286v1",
        "PDF": "https://arxiv.org/pdf/2507.13286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with privacy-preserving data fusion in wireless sensor networks, addressing issues like eavesdropping and packet dropouts, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13290",
      "abstract": "In the past few years LLMs have emerged as a tool that can aid programmers by taking natural language descriptions and generating code based on it. However, LLMs often generate incorrect code that users need to fix and the literature suggests users often struggle to detect these errors. In this work we seek to offer formal guarantees of correctness to LLM generated code; such guarantees could improve the experience of using AI Code Assistants and potentially enable natural language programming for users with little or no programming knowledge. To address this challenge we propose to incorporate a formal query language that can represent a user's intent in a formally defined but natural language-like manner that a user can confirm matches their intent. Then, using such a query we propose to verify LLM generated code to ensure it matches the user's intent. We implement these ideas in our system, Astrogator, for the Ansible programming language which includes such a formal query language, a calculus for representing the behavior of Ansible programs, and a symbolic interpreter which is used for the verification. On a benchmark suite of 21 code-generation tasks, our verifier is able to verify correct code in 83% of cases and identify incorrect code in 92%.",
      "authors": [
        "Aaron Councilman",
        "David Fu",
        "Aryan Gupta",
        "Chengxiao Wang",
        "David Grove",
        "Yu-Xiong Wang",
        "Vikram Adve"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:54:42+00:00",
          "link": "https://arxiv.org/abs/2507.13290v1",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "title": "Towards Formal Verification of LLM-Generated Code from Natural Language Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13290",
        "HTML": "https://arxiv.org/html/2507.13290v1",
        "PDF": "https://arxiv.org/pdf/2507.13290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses formal verification of code generated by LLMs, aiming to improve correctness in AI-generated code. It does not contribute to the processing of training data for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13292",
      "abstract": "Accurate age verification can protect underage users from unauthorized access to online platforms and e-commerce sites that provide age-restricted services. However, accurate age estimation can be confounded by several factors, including facial makeup that can induce changes to alter perceived identity and age to fool both humans and machines. In this work, we propose DiffClean which erases makeup traces using a text-guided diffusion model to defend against makeup attacks. DiffClean improves age estimation (minor vs. adult accuracy by 4.8%) and face verification (TMR by 8.9% at FMR=0.01%) over competing baselines on digitally simulated and real makeup images.",
      "authors": [
        "Ekta Balkrishna Gavas",
        "Chinmay Hegde",
        "Nasir Memon and Sudipta Banerjee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.13292v1",
          "size": "6327kb",
          "version": "v1"
        }
      ],
      "title": "DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13292",
        "HTML": "https://arxiv.org/html/2507.13292v1",
        "PDF": "https://arxiv.org/pdf/2507.13292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on age estimation improvements through makeup removal, using diffusion models. It is unrelated to LLM training data processing, including dataset creation or enhancement for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13294",
      "abstract": "We reinvestigate the general distributed secure source coding based on the common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They proposed a framework of distributed source encryption and derived the necessary and sufficient conditions to have reliable and secure transmission. However, the bounds of the rate region, which specifies both necessary and sufficient conditions to have reliable and secure transmission under the proposed cryptosystem, were derived based on a self-tailored non-standard} security criterion. In this paper we adopt the standard security criterion, i.e., standard mutual information. We successfully establish the bounds of the rate region based on this security criterion. Information spectrum method and a variant of Birkhoff-von Neumann theorem play an important role in deriving the result.",
      "authors": [
        "Yasutada Oohama and Bagus Santoso"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:58:52+00:00",
          "link": "https://arxiv.org/abs/2507.13294v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13294",
        "HTML": "https://arxiv.org/html/2507.13294v1",
        "PDF": "https://arxiv.org/pdf/2507.13294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for distributed source encryption based on a mutual information security criterion. This topic is unrelated to LLM training data processing as it focuses on secure transmission in cryptosystems rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13296",
      "abstract": "Graph-based nearest neighbor search methods have seen a surge of popularity in recent years, offering state-of-the-art performance across a wide variety of applications. Central to these methods is the task of constructing a sparse navigable search graph for a given dataset endowed with a distance function. Unfortunately, doing so is computationally expensive, so heuristics are universally used in practice.\n  In this work, we initiate the study of fast algorithms with provable guarantees for search graph construction. For a dataset with $n$ data points, the problem of constructing an optimally sparse navigable graph can be framed as $n$ separate but highly correlated minimum set cover instances. This yields a naive $O(n^3)$ time greedy algorithm that returns a navigable graph whose sparsity is at most $O(\\log n)$ higher than optimal. We improve significantly on this baseline, taking advantage of correlation between the set cover instances to leverage techniques from streaming and sublinear-time set cover algorithms. Combined with problem-specific pre-processing techniques, we present an $\\tilde{O}(n^2)$ time algorithm for constructing an $O(\\log n)$-approximate sparsest navigable graph under any distance function.\n  The runtime of our method is optimal up to logarithmic factors under the Strong Exponential Time Hypothesis via a reduction from Monochromatic Closest Pair. Moreover, we prove that, as with general set cover, obtaining better than an $O(\\log n)$-approximation is NP-hard, despite the significant additional structure present in the navigable graph problem. Finally, we show that our techniques can also beat cubic time for the closely related and practically important problems of constructing $\\alpha$-shortcut reachable and $\\tau$-monotonic graphs, which are also used for nearest neighbor search. For such graphs, we obtain $\\tilde{O}(n^{2.5})$ time or better algorithms.",
      "authors": [
        "Alex Conway",
        "Laxman Dhulipala",
        "Martin Farach-Colton",
        "Rob Johnson",
        "Ben Landrum",
        "Christopher Musco",
        "Yarin Shechter",
        "Torsten Suel",
        "Richard Wen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:04:18+00:00",
          "link": "https://arxiv.org/abs/2507.13296v1",
          "size": "250kb",
          "version": "v1"
        }
      ],
      "title": "Efficiently Constructing Sparse Navigable Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13296",
        "PDF": "https://arxiv.org/pdf/2507.13296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on constructing sparse navigable graphs for nearest neighbor search, which is not directly relevant to LLM training data processing. The work involves computational efficiency in graph construction rather than data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13300",
      "abstract": "We introduce AbGen, the first benchmark designed to evaluate the capabilities of LLMs in designing ablation studies for scientific research. AbGen consists of 1,500 expert-annotated examples derived from 807 NLP papers. In this benchmark, LLMs are tasked with generating detailed ablation study designs for a specified module or process based on the given research context. Our evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a significant performance gap between these models and human experts in terms of the importance, faithfulness, and soundness of the ablation study designs. Moreover, we demonstrate that current automated evaluation methods are not reliable for our task, as they show a significant discrepancy when compared to human assessment. To better investigate this, we develop AbGen-Eval, a meta-evaluation benchmark designed to assess the reliability of commonly used automated evaluation systems in measuring LLM performance on our task. We investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for future research on developing more effective and reliable LLM-based evaluation systems for complex scientific tasks.",
      "authors": [
        "Yilun Zhao",
        "Weiyuan Chen",
        "Zhijian Xu",
        "Manasi Patwardhan",
        "Yixin Liu",
        "Chengye Wang",
        "Lovekesh Vig",
        "Arman Cohan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:09:22+00:00",
          "link": "https://arxiv.org/abs/2507.13300v1",
          "size": "6581kb",
          "version": "v1"
        }
      ],
      "title": "AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13300",
        "HTML": "https://arxiv.org/html/2507.13300v1",
        "PDF": "https://arxiv.org/pdf/2507.13300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents AbGen, a benchmark for evaluating LLMs in designing ablation studies. Although it touches on generating detailed study designs, it's more about evaluation benchmarking rather than processing data specifically for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13302",
      "abstract": "The evaluation of large language models is a complex task, in which several approaches have been proposed. The most common is the use of automated benchmarks in which LLMs have to answer multiple-choice questions of different topics. However, this method has certain limitations, being the most concerning, the poor correlation with the humans. An alternative approach, is to have humans evaluate the LLMs. This poses scalability issues as there is a large and growing number of models to evaluate making it impractical (and costly) to run traditional studies based on recruiting a number of evaluators and having them rank the responses of the models. An alternative approach is the use of public arenas, such as the popular LM arena, on which any user can freely evaluate models on any question and rank the responses of two models. The results are then elaborated into a model ranking. An increasingly important aspect of LLMs is their energy consumption and, therefore, evaluating how energy awareness influences the decisions of humans in selecting a model is of interest. In this paper, we present GEA, the Generative Energy Arena, an arena that incorporates information on the energy consumption of the model in the evaluation process. Preliminary results obtained with GEA are also presented, showing that for most questions, when users are aware of the energy consumption, they favor smaller and more energy efficient models. This suggests that for most user interactions, the extra cost and energy incurred by the more complex and top-performing models do not provide an increase in the perceived quality of the responses that justifies their use.",
      "authors": [
        "Carlos Arriaga",
        "Gonzalo Mart\\'inez",
        "Eneko Sendin",
        "Javier Conde",
        "Pedro Reviriego"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.13302v1",
          "size": "502kb",
          "version": "v1"
        }
      ],
      "title": "The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13302",
        "PDF": "https://arxiv.org/pdf/2507.13302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Generative Energy Arena for evaluating LLMs with energy awareness. It primarily addresses model evaluation based on energy consumption rather than training data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13305",
      "abstract": "Team modeling remains a fundamental challenge at the intersection of Artificial Intelligence and the Social Sciences. Social Science research emphasizes the need to jointly model dynamics and relations, while practical applications demand unified models capable of inferring multiple team constructs simultaneously, providing interpretable insights and actionable recommendations to enhance team performance. However, existing works do not meet these practical demands. To bridge this gap, we present TRENN, a novel tempo-relational architecture that integrates: (i) an automatic temporal graph extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct prediction, and (iv) two complementary explainability modules. TRENN jointly captures relational and temporal team dynamics, providing a solid foundation for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task head, enabling the model to learn shared Social Embeddings and simultaneously predict multiple team constructs, including Emergent Leadership, Leadership Style, and Teamwork components. Experimental results demonstrate that our approach significantly outperforms approaches that rely exclusively on temporal or relational information. Additionally, experimental evaluation has shown that the explainability modules integrated in MT-TRENN yield interpretable insights and actionable suggestions to support team improvement. These capabilities make our approach particularly well-suited for Human-Centered AI applications, such as intelligent decision-support systems in high-stakes collaborative environments.",
      "authors": [
        "Vincenzo Marco De Luca",
        "Giovanna Varni",
        "Andrea Passerini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:22:41+00:00",
          "link": "https://arxiv.org/abs/2507.13305v1",
          "size": "1559kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Team Modeling through Tempo-Relational Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13305",
        "HTML": "https://arxiv.org/html/2507.13305v1",
        "PDF": "https://arxiv.org/pdf/2507.13305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a tempo-relational representation learning model for team modeling, focusing on AI and social science intersection. It does not relate to LLM training data processing or improvements in training dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13307",
      "abstract": "As the main issue in pinching-antenna system design, antenna location optimization is key to realizing channel reconfigurability and system flexibility. Most existing works in this area adopt sophisticated optimization and learning tools to identify the optimal antenna locations in a numerical manner, where insightful understandings of the pinching antenna placement are still missing. Motivated by this research gap, this paper aims to carry out analytical optimization for pinching antenna placement, where closed-form solutions for the optimal antenna locations are obtained to reveal the impact of antenna placement on the system performance. In particular, for the user-fairness-oriented orthogonal multiple access (OMA) based transmission, analytical results are obtained to reveal that the pinching antenna needs to be activated at the place that would be beneficial to all served users; however, the users' distances to the waveguide have no impact on the location selection. For the greedy-allocation-based OMA transmission, an asymptotic study based on a high signal-to-noise ratio approximation is carried out to show that the optimal antenna location is in close proximity to the user who is nearest to the waveguide. For non-orthogonal multiple access (NOMA) based transmission, even with a user-fairness-oriented objective, the obtained analytical results show that the optimal antenna location is not the position that can benefit all users, but rather is near the user positioned closest to the waveguide.",
      "authors": [
        "Zhiguo Ding and H. Vincent Poor"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:23:03+00:00",
          "link": "https://arxiv.org/abs/2507.13307v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "Analytical Optimization for Antenna Placement in Pinching-Antenna Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13307",
        "HTML": "https://arxiv.org/html/2507.13307v1",
        "PDF": "https://arxiv.org/pdf/2507.13307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing antenna placement in pinching-antenna systems and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13309",
      "abstract": "While videos have become increasingly prevalent in delivering information across different educational and professional contexts, individuals with ADHD often face attention challenges when watching informational videos due to the dynamic, multimodal, yet potentially distracting video elements. To understand and address this critical challenge, we designed \\textit{FocusView}, a video customization interface that allows viewers with ADHD to customize informational videos from different aspects. We evaluated FocusView with 12 participants with ADHD and found that FocusView significantly improved the viewability of videos by reducing distractions. Through the study, we uncovered participants' diverse perceptions of video distractions (e.g., background music as a distraction vs. stimulation boost) and their customization preferences, highlighting unique ADHD-relevant needs in designing video customization interfaces (e.g., reducing the number of options to avoid distraction caused by customization itself). We further derived design considerations for future video customization systems for the ADHD community.",
      "authors": [
        "Hanxiu 'Hazel' Zhu",
        "Ruijia Chen",
        "Yuhang Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.13309v1",
          "size": "11991kb",
          "version": "v1"
        }
      ],
      "title": "FocusView: Understanding and Customizing Informational Video Watching Experiences for Viewers with ADHD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13309",
        "HTML": "https://arxiv.org/html/2507.13309v1",
        "PDF": "https://arxiv.org/pdf/2507.13309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses video customization for ADHD viewers, focusing on video viewing experiences and interface design, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13311",
      "abstract": "Realistic and controllable garment visualization is critical for fashion e-commerce, where users expect personalized previews under diverse poses and lighting conditions. Existing methods often rely on predefined poses, limiting semantic flexibility and illumination adaptability. To address this, we introduce FashionPose, the first unified text-to-pose-to-relighting generation framework. Given a natural language description, our method first predicts a 2D human pose, then employs a diffusion model to generate high-fidelity person images, and finally applies a lightweight relighting module, all guided by the same textual input. By replacing explicit pose annotations with text-driven conditioning, FashionPose enables accurate pose alignment, faithful garment rendering, and flexible lighting control. Experiments demonstrate fine-grained pose synthesis and efficient, consistent relighting, providing a practical solution for personalized virtual fashion display.",
      "authors": [
        "Chuancheng Shi",
        "Yixiang Chen",
        "Burong Lei",
        "Jichao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:30:29+00:00",
          "link": "https://arxiv.org/abs/2507.13311v1",
          "size": "3133kb",
          "version": "v1"
        }
      ],
      "title": "FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13311",
        "HTML": "https://arxiv.org/html/2507.13311v1",
        "PDF": "https://arxiv.org/pdf/2507.13311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces FashionPose, a framework for personalized fashion visualization through text-to-pose and image generation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13312",
      "abstract": "Virtual dynamic environments (VDEs) such as the Metaverse and digital twins (DTs) require proper representation of the interacting entities to map their characteristics within the simulated or augmented space. Keeping these representations accurate and up-to-date is crucial for seamless interaction and system reliability. In this paper, we propose bidirectional age of incorrect information (BAoII) to address this aspect. BAoII quantifies the time-dependent penalty paid by an entity in a VDE due to incorrect or outdated knowledge about itself and the overall dynamically changing space. This extends the concept of age of incorrect information for a bidirectional information exchange, capturing that a VDE requires mutual awareness of the entity's own representation, measured in the virtual space, and what the other entities share about their representations. Using a continuous-time Markov chain model, we derive a closed-form expression for long-term BAoII and identify a transmission cost threshold for optimal update strategies. We describe a trade-off between communication cost and information freshness and validate our model through numerical simulations, demonstrating the impact of BAoII on evaluating system performance and highlighting its relevance for real-time collaboration in the Metaverse and DTs.",
      "authors": [
        "Chiara Schiavo",
        "Manuele Favero",
        "Alessandro Buratto and Leonardo Badia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (cs.IT)",
        "Multimedia (cs.MM)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:31:50+00:00",
          "link": "https://arxiv.org/abs/2507.13312v1",
          "size": "1403kb",
          "version": "v1"
        }
      ],
      "title": "Bidirectional Age of Incorrect Information: A Performance Metric for Status Updates in Virtual Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13312",
        "HTML": "https://arxiv.org/html/2507.13312v1",
        "PDF": "https://arxiv.org/pdf/2507.13312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a metric for performance in virtual dynamic environments, focusing on information accuracy and updates, which do not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13313",
      "abstract": "This paper introduces a dataset and experimental study for decentralized federated learning (DFL) applied to IoT crowdsensing malware detection. The dataset comprises behavioral records from benign and eight malware families. A total of 21,582,484 original records were collected from system calls, file system activities, resource usage, kernel events, input/output events, and network records. These records were aggregated into 30-second windows, resulting in 342,106 features used for model training and evaluation. Experiments on the DFL platform compare traditional machine learning (ML), centralized federated learning (CFL), and DFL across different node counts, topologies, and data distributions. Results show that DFL maintains competitive performance while preserving data locality, outperforming CFL in most settings. This dataset provides a solid foundation for studying the security of IoT crowdsensing environments.",
      "authors": [
        "Chao Feng",
        "Alberto Huertas Celdran",
        "Jing Han",
        "Heqing Ren",
        "Xi Cheng",
        "Zien Zeng",
        "Lucas Krauter",
        "Gerome Bovet",
        "Burkhard Stiller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:33:11+00:00",
          "link": "https://arxiv.org/abs/2507.13313v1",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "title": "A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13313",
        "HTML": "https://arxiv.org/html/2507.13313v1",
        "PDF": "https://arxiv.org/pdf/2507.13313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset for decentralized federated learning for IoT crowdsensing malware detection, focusing on security and federated learning techniques, which are not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13314",
      "abstract": "The reasoning-based pose estimation (RPE) benchmark has emerged as a widely adopted evaluation standard for pose-aware multimodal large language models (MLLMs). Despite its significance, we identified critical reproducibility and benchmark-quality issues that hinder fair and consistent quantitative evaluations. Most notably, the benchmark utilizes different image indices from those of the original 3DPW dataset, forcing researchers into tedious and error-prone manual matching processes to obtain accurate ground-truth (GT) annotations for quantitative metrics (\\eg, MPJPE, PA-MPJPE). Furthermore, our analysis reveals several inherent benchmark-quality limitations, including significant image redundancy, scenario imbalance, overly simplistic poses, and ambiguous textual descriptions, collectively undermining reliable evaluations across diverse scenarios. To alleviate manual effort and enhance reproducibility, we carefully refined the GT annotations through meticulous visual matching and publicly release these refined annotations as an open-source resource, thereby promoting consistent quantitative evaluations and facilitating future advancements in human pose-aware multimodal reasoning.",
      "authors": [
        "Junsu Kim",
        "Naeun Kim",
        "Jaeho Lee",
        "Incheol Park",
        "Dongyoon Han",
        "Seungryul Baek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:33:11+00:00",
          "link": "https://arxiv.org/abs/2507.13314v1",
          "size": "1061kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13314",
        "HTML": "https://arxiv.org/html/2507.13314v1",
        "PDF": "https://arxiv.org/pdf/2507.13314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses reliability issues in a benchmark for pose estimation and refines ground-truth annotations but does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13318",
      "abstract": "Haptic signals, from smartphone vibrations to virtual reality touch feedback, can effectively convey information and enhance realism, but designing signals that resonate meaningfully with users is challenging. To facilitate this, we introduce a multimodal dataset and task, of matching user descriptions to vibration haptic signals, and highlight two primary challenges: (1) lack of large haptic vibration datasets annotated with textual descriptions as collecting haptic descriptions is time-consuming, and (2) limited capability of existing tasks and models to describe vibration signals in text. To advance this area, we create HapticCap, the first fully human-annotated haptic-captioned dataset, containing 92,070 haptic-text pairs for user descriptions of sensory, emotional, and associative attributes of vibrations. Based on HapticCap, we propose the haptic-caption retrieval task and present the results of this task from a supervised contrastive learning framework that brings together text representations within specific categories and vibrations. Overall, the combination of language model T5 and audio model AST yields the best performance in the haptic-caption retrieval task, especially when separately trained for each description category.",
      "authors": [
        "Guimin Hu and Daniel Hershcovich and Hasti Seifi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:37:24+00:00",
          "link": "https://arxiv.org/abs/2507.13318v1",
          "size": "21279kb",
          "version": "v1"
        }
      ],
      "title": "HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13318",
        "HTML": "https://arxiv.org/html/2507.13318v1",
        "PDF": "https://arxiv.org/pdf/2507.13318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a haptic-caption dataset and retrieval task related to user experience with vibration signals, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13323",
      "abstract": "Socio-economic indicators like regional GDP, population, and education levels, are crucial to shaping policy decisions and fostering sustainable development. This research introduces GeoReg a regression model that integrates diverse data sources, including satellite imagery and web-based geospatial information, to estimate these indicators even for data-scarce regions such as developing countries. Our approach leverages the prior knowledge of large language model (LLM) to address the scarcity of labeled data, with the LLM functioning as a data engineer by extracting informative features to enable effective estimation in few-shot settings. Specifically, our model obtains contextual relationships between data features and the target indicator, categorizing their correlations as positive, negative, mixed, or irrelevant. These features are then fed into the linear estimator with tailored weight constraints for each category. To capture nonlinear patterns, the model also identifies meaningful feature interactions and integrates them, along with nonlinear transformations. Experiments across three countries at different stages of development demonstrate that our model outperforms baselines in estimating socio-economic indicators, even for low-income countries with limited data availability.",
      "authors": [
        "Kyeongjin Ahn",
        "Sungwon Han",
        "Seungeon Lee",
        "Donghyun Ahn",
        "Hyoshin Kim",
        "Jungwon Kim",
        "Jihee Kim",
        "Sangyoon Park",
        "Meeyoung Cha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:42:29+00:00",
          "link": "https://arxiv.org/abs/2507.13323v1",
          "size": "5317kb",
          "version": "v1"
        }
      ],
      "title": "GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13323",
        "HTML": "https://arxiv.org/html/2507.13323v1",
        "PDF": "https://arxiv.org/pdf/2507.13323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "GeoReg uses an LLM for feature extraction in estimating socio-economic indicators. It indirectly involves the use of an LLM as a data engineer but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13325",
      "abstract": "Search engines play a crucial role in shaping public discourse by influencing how information is accessed and framed. While prior research has extensively examined various dimensions of search bias -- such as content prioritization, indexical bias, political polarization, and sources of bias -- an important question remains underexplored: how do search engines and ideologically-motivated user queries contribute to bias in search results. This study analyzes the outputs of major search engines using a dataset of political and social topics. The findings reveal that search engines not only prioritize content in ways that reflect underlying biases but also that ideologically-driven user queries exacerbate these biases, resulting in the amplification of specific narratives. Moreover, significant differences were observed across search engines in terms of the sources they prioritize. These results suggest that search engines may play a pivotal role in shaping public perceptions by reinforcing ideological divides, thereby contributing to the broader issue of information polarization.",
      "authors": [
        "Amrit Poudel",
        "Tim Weninger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:44:33+00:00",
          "link": "https://arxiv.org/abs/2507.13325v1",
          "size": "305kb",
          "version": "v1"
        }
      ],
      "title": "Social and Political Framing in Search Engine Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13325",
        "PDF": "https://arxiv.org/pdf/2507.13325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines biases in search engine results related to social and political framing, not the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13326",
      "abstract": "Hand-object interaction detection remains an open challenge in real-time applications, where intuitive user experiences depend on fast and accurate detection of interactions with surrounding objects. We propose an efficient approach for detecting hand-objects interactions from streaming egocentric vision that operates in real time. Our approach consists of an action recognition module and an object detection module for identifying active objects upon confirmed interaction. Our Mamba model with EfficientNetV2 as backbone for action recognition achieves 38.52% p-AP on the ENIGMA-51 benchmark at 30fps, while our fine-tuned YOLOWorld reaches 85.13% AP for hand and object. We implement our models in a cascaded architecture where the action recognition and object detection modules operate sequentially. When the action recognition predicts a contact state, it activates the object detection module, which in turn performs inference on the relevant frame to detect and classify the active object.",
      "authors": [
        "Antonio Finocchiaro",
        "Alessandro Sebastiano Catinello",
        "Michele Mazzamuto",
        "Rosario Leonardi",
        "Antonino Furnari",
        "Giovanni Maria Farinella"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:45:09+00:00",
          "link": "https://arxiv.org/abs/2507.13326v1",
          "size": "12448kb",
          "version": "v1"
        }
      ],
      "title": "A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13326",
        "HTML": "https://arxiv.org/html/2507.13326v1",
        "PDF": "https://arxiv.org/pdf/2507.13326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hand-object interaction detection using vision-based models in industrial settings. Its main contribution is on real-time detection systems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13328",
      "abstract": "Does vision-and-language (VL) training change the linguistic representations of language models in meaningful ways? Most results in the literature have shown inconsistent or marginal differences, both behaviorally and representationally. In this work, we start from the hypothesis that the domain in which VL training could have a significant effect is lexical-conceptual knowledge, in particular its taxonomic organization. Through comparing minimal pairs of text-only LMs and their VL-trained counterparts, we first show that the VL models often outperform their text-only counterparts on a text-only question-answering task that requires taxonomic understanding of concepts mentioned in the questions. Using an array of targeted behavioral and representational analyses, we show that the LMs and VLMs do not differ significantly in terms of their taxonomic knowledge itself, but they differ in how they represent questions that contain concepts in a taxonomic relation vs. a non-taxonomic relation. This implies that the taxonomic knowledge itself does not change substantially through additional VL training, but VL training does improve the deployment of this knowledge in the context of a specific task, even when the presentation of the task is purely linguistic.",
      "authors": [
        "Yulu Qin",
        "Dheeraj Varghese",
        "Adam Dahlgren Lindstr\\\"om",
        "Lucia Donatelli",
        "Kanishka Misra and Najoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.13328v1",
          "size": "5144kb",
          "version": "v1"
        }
      ],
      "title": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13328",
        "HTML": "https://arxiv.org/html/2507.13328v1",
        "PDF": "https://arxiv.org/pdf/2507.13328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the effects of vision-and-language training on linguistic representations, with a focus on taxonomic knowledge. It does not discuss training data processing for LLMs at any stage."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13332",
      "abstract": "Length generalization, the ability to solve problems of longer sequences than those observed during training, poses a core challenge of Transformer-based large language models (LLM). Although existing studies have predominantly focused on data-driven approaches for arithmetic operations and symbolic manipulation tasks, these approaches tend to be task-specific with limited overall performance. To pursue a more general solution, this paper focuses on a broader case of reasoning problems that are computable, i.e., problems that algorithms can solve, thus can be solved by the Turing Machine. From this perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to improve the length generalization ability of LLMs. TAIL synthesizes chain-of-thoughts (CoT) data that imitate the execution process of a Turing Machine by computer programs, which linearly expands the reasoning steps into atomic states to alleviate shortcut learning and explicit memory fetch mechanism to reduce the difficulties of dynamic and long-range data access in elementary operations. To validate the reliability and universality of TAIL, we construct a challenging synthetic dataset covering 8 classes of algorithms and 18 tasks. Without bells and whistles, TAIL significantly improves the length generalization ability as well as the performance of Qwen2.5-7B on various tasks using only synthetic data, surpassing previous methods and DeepSeek-R1. The experimental results reveal that the key concepts in the Turing Machine, instead of the thinking styles, are indispensable for TAIL for length generalization, through which the model exhibits read-and-write behaviors consistent with the properties of the Turing Machine in their attention layers. This work provides a promising direction for future research in the learning of LLM reasoning from synthetic data.",
      "authors": [
        "Zhouqi Hua",
        "Wenwei Zhang",
        "Chengqi Lyu",
        "Yuzhe Gu",
        "Songyang Gao",
        "Kuikun Liu",
        "Kai Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.13332v1",
          "size": "22322kb",
          "version": "v1"
        }
      ],
      "title": "The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13332",
        "HTML": "https://arxiv.org/html/2507.13332v1",
        "PDF": "https://arxiv.org/pdf/2507.13332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves synthesizing chain-of-thoughts data for improving LLMs' reasoning abilities. While it uses synthetic data, the main focus is on reasoning and length generalization rather than data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13334",
      "abstract": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1300 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.",
      "authors": [
        "Lingrui Mei",
        "Jiayu Yao",
        "Yuyao Ge",
        "Yiwei Wang",
        "Baolong Bi",
        "Yujun Cai",
        "Jiazhi Liu",
        "Mingyu Li",
        "Zhong-Zhi Li",
        "Duzhen Zhang",
        "Chenlin Zhou",
        "Jiayi Mao",
        "Tianze Xia",
        "Jiafeng Guo",
        "Shenghua Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.13334v1",
          "size": "2126kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Context Engineering for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13334",
        "HTML": "https://arxiv.org/html/2507.13334v1",
        "PDF": "https://arxiv.org/pdf/2507.13334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys context engineering for LLMs, focusing on inference-time context optimization. It does not address pretraining or fine-tuning data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13335",
      "abstract": "Humour, as a complex language form, is derived from myriad aspects of life, whilst existing work on computational humour has focussed almost exclusively on short pun-based jokes. In this work, we investigate whether the ability of Large Language Models (LLMs) to explain humour depends on the particular humour form. We compare models on simple puns and more complex topical humour that requires knowledge of real-world entities and events. In doing so, we curate a dataset of 600 jokes split across 4 joke types and manually write high-quality explanations. These jokes include heterographic and homographic puns, contemporary internet humour, and topical jokes, where understanding relies on reasoning beyond \"common sense\", rooted instead in world knowledge regarding news events and pop culture. Using this dataset, we compare the zero-shot abilities of a range of LLMs to accurately and comprehensively explain jokes of different types, identifying key research gaps in the task of humour explanation. We find that none of the tested models (inc. reasoning models) are capable of reliably generating adequate explanations of all joke types, further highlighting the narrow focus of most works in computational humour on overly simple joke forms.",
      "authors": [
        "Tyler Loakman",
        "William Thorne and Chenghua Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:51:20+00:00",
          "link": "https://arxiv.org/abs/2507.13335v1",
          "size": "3643kb",
          "version": "v1"
        }
      ],
      "title": "Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13335",
        "HTML": "https://arxiv.org/html/2507.13335v1",
        "PDF": "https://arxiv.org/pdf/2507.13335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper curates a dataset of jokes to assess LLM humor understanding, involving data processing for evaluation. However, its main focus is not on training data processing for LLMs but on using the dataset to test existing models' abilities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13336",
      "abstract": "Recommender systems (RecSys) are essential for online platforms, providing personalized suggestions to users within a vast sea of information. Self-supervised graph learning seeks to harness high-order collaborative filtering signals through unsupervised augmentation on the user-item bipartite graph, primarily leveraging a multi-task learning framework that includes both supervised recommendation loss and self-supervised contrastive loss. However, this separate design introduces additional graph convolution processes and creates inconsistencies in gradient directions due to disparate losses, resulting in prolonged training times and sub-optimal performance. In this study, we introduce a unified framework of Supervised Graph Contrastive Learning for recommendation (SGCL) to address these issues. SGCL uniquely combines the training of recommendation and unsupervised contrastive losses into a cohesive supervised contrastive learning loss, aligning both tasks within a single optimization direction for exceptionally fast training. Extensive experiments on three real-world datasets show that SGCL outperforms state-of-the-art methods, achieving superior accuracy and efficiency.",
      "authors": [
        "Weizhi Zhang",
        "Liangwei Yang",
        "Zihe Song",
        "Henrry Peng Zou",
        "Ke Xu",
        "Yuanjie Zhu",
        "Philip S. Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:53:50+00:00",
          "link": "https://arxiv.org/abs/2507.13336v1",
          "size": "146kb",
          "version": "v1"
        }
      ],
      "title": "SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13336",
        "HTML": "https://arxiv.org/html/2507.13336v1",
        "PDF": "https://arxiv.org/pdf/2507.13336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph learning for recommendation systems, with no mention of data processing related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13337",
      "abstract": "Frontier AI models demonstrate formidable breadth of knowledge. But how close are they to true human -- or superhuman -- expertise? Genuine experts can tackle the hardest problems and push the boundaries of scientific understanding. To illuminate the limits of frontier model capabilities, we turn away from contrived competitive programming puzzles, and instead focus on real-life research problems.\n  We construct FormulaOne, a benchmark that lies at the intersection of graph theory, logic, and algorithms, all well within the training distribution of frontier models. Our problems are incredibly demanding, requiring an array of reasoning steps. The dataset has three key properties. First, it is of commercial interest and relates to practical large-scale optimisation problems, such as those arising in routing, scheduling, and network design. Second, it is generated from the highly expressive framework of Monadic Second-Order (MSO) logic on graphs, paving the way toward automatic problem generation at scale; ideal for building RL environments. Third, many of our problems are intimately related to the frontier of theoretical computer science, and to central conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As such, any significant algorithmic progress on our dataset, beyond known results, could carry profound theoretical implications.\n  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on FormulaOne, solving less than 1% of the questions, even when given 10 attempts and explanatory fewshot examples -- highlighting how far they remain from expert-level understanding in some domains. To support further research, we additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from the same distribution. We release the full corpus along with a comprehensive evaluation framework.",
      "authors": [
        "Gal Beniamini",
        "Yuval Dor",
        "Alon Vinnikov",
        "Shir Granot Peled",
        "Or Weinstein",
        "Or Sharir",
        "Noam Wies",
        "Tomer Nussbaum",
        "Ido Ben Shaul",
        "Tomer Zekharya",
        "Yoav Levine",
        "Shai Shalev-Shwartz",
        "Amnon Shashua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Complexity (cs.CC)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:53:55+00:00",
          "link": "https://arxiv.org/abs/2507.13337v1",
          "size": "386kb",
          "version": "v1"
        }
      ],
      "title": "FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13337",
        "PDF": "https://arxiv.org/pdf/2507.13337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the FormulaOne dataset and a related benchmark for algorithmic reasoning, which supports the evaluation of AI models. While it involves dataset creation, it is aimed at testing model capabilities in reasoning, not specifically LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13338",
      "abstract": "Neural networks are often highly sensitive to input and weight perturbations. This sensitivity has been linked to pathologies such as vulnerability to adversarial examples, divergent training, and overfitting. To combat these problems, past research has looked at building neural networks entirely from Lipschitz components. However, these techniques have not matured to the point where researchers have trained a modern architecture such as a transformer with a Lipschitz certificate enforced beyond initialization. To explore this gap, we begin by developing and benchmarking novel, computationally-efficient tools for maintaining norm-constrained weight matrices. Applying these tools, we are able to train transformer models with Lipschitz bounds enforced throughout training. We find that optimizer dynamics matter: switching from AdamW to Muon improves standard methods -- weight decay and spectral normalization -- allowing models to reach equal performance with a lower Lipschitz bound. Inspired by Muon's update having a fixed spectral norm, we co-design a weight constraint method that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter transformers. Our 2-Lipschitz transformer on Shakespeare text reaches validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz transformer reaches 21% accuracy on internet text. However, to match the NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound increases to 10^264. Nonetheless, our Lipschitz transformers train without stability measures such as layer norm, QK norm, and logit tanh softcapping.",
      "authors": [
        "Laker Newhouse",
        "R. Preston Hess",
        "Franz Cesista",
        "Andrii Zahorodnii",
        "Jeremy Bernstein",
        "Phillip Isola"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:55:00+00:00",
          "link": "https://arxiv.org/abs/2507.13338v1",
          "size": "1076kb",
          "version": "v1"
        }
      ],
      "title": "Training Transformers with Enforced Lipschitz Constants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13338",
        "PDF": "https://arxiv.org/pdf/2507.13338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses techniques for training transformers with enforced Lipschitz constants, focusing on model architecture and optimization, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13340",
      "abstract": "Learning visuomotor policies via imitation has proven effective across a wide range of robotic domains. However, the performance of these policies is heavily dependent on the number of training demonstrations, which requires expensive data collection in the real world. In this work, we aim to reduce data collection efforts when learning visuomotor robot policies by leveraging existing or cost-effective data from a wide range of embodiments, such as public robot datasets and the datasets of humans playing with objects (human data from play). Our approach leverages two key insights. First, we use optic flow as an embodiment-agnostic action representation to train a World Model (WM) across multi-embodiment datasets, and finetune it on a small amount of robot data from the target embodiment. Second, we develop a method, Latent Policy Steering (LPS), to improve the output of a behavior-cloned policy by searching in the latent space of the WM for better action sequences. In real world experiments, we observe significant improvements in the performance of policies trained with a small amount of data (over 50% relative improvement with 30 demonstrations and over 20% relative improvement with 50 demonstrations) by combining the policy with a WM pretrained on two thousand episodes sampled from the existing Open X-embodiment dataset across different robots or a cost-effective human dataset from play.",
      "authors": [
        "Yiqi Wang",
        "Mrinal Verghese and Jeff Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:57:57+00:00",
          "link": "https://arxiv.org/abs/2507.13340v1",
          "size": "6983kb",
          "version": "v1"
        }
      ],
      "title": "Latent Policy Steering with Embodiment-Agnostic Pretrained World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13340",
        "HTML": "https://arxiv.org/html/2507.13340v1",
        "PDF": "https://arxiv.org/pdf/2507.13340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on learning robotic visuomotor policies using pretrained world models and does not address LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13343",
      "abstract": "Diffusion Transformers (DiT) have shown strong performance in video generation tasks, but their high computational cost makes them impractical for resource-constrained devices like smartphones, and real-time generation is even more challenging. In this work, we propose a series of novel optimizations to significantly accelerate video generation and enable real-time performance on mobile platforms. First, we employ a highly compressed variational autoencoder (VAE) to reduce the dimensionality of the input data without sacrificing visual quality. Second, we introduce a KD-guided, sensitivity-aware tri-level pruning strategy to shrink the model size to suit mobile platform while preserving critical performance characteristics. Third, we develop an adversarial step distillation technique tailored for DiT, which allows us to reduce the number of inference steps to four. Combined, these optimizations enable our model to achieve over 10 frames per second (FPS) generation on an iPhone 16 Pro Max, demonstrating the feasibility of real-time, high-quality video generation on mobile devices.",
      "authors": [
        "Yushu Wu",
        "Yanyu Li",
        "Anil Kag",
        "Ivan Skorokhodov",
        "Willi Menapace",
        "Ke Ma",
        "Arpit Sahni",
        "Ju Hu",
        "Aliaksandr Siarohin",
        "Dhritiman Sagar",
        "Yanzhi Wang",
        "Sergey Tulyakov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:10+00:00",
          "link": "https://arxiv.org/abs/2507.13343v1",
          "size": "2101kb",
          "version": "v1"
        }
      ],
      "title": "Taming Diffusion Transformer for Real-Time Mobile Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13343",
        "HTML": "https://arxiv.org/html/2507.13343v1",
        "PDF": "https://arxiv.org/pdf/2507.13343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses optimizations for real-time video generation on mobile devices using Diffusion Transformers and does not touch upon any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13344",
      "abstract": "This paper addresses the challenge of high-fidelity view synthesis of humans with sparse-view videos as input. Previous methods solve the issue of insufficient observation by leveraging 4D diffusion models to generate videos at novel viewpoints. However, the generated videos from these models often lack spatio-temporal consistency, thus degrading view synthesis quality. In this paper, we propose a novel sliding iterative denoising process to enhance the spatio-temporal consistency of the 4D diffusion model. Specifically, we define a latent grid in which each latent encodes the image, camera pose, and human pose for a certain viewpoint and timestamp, then alternately denoising the latent grid along spatial and temporal dimensions with a sliding window, and finally decode the videos at target viewpoints from the corresponding denoised latents. Through the iterative sliding, information flows sufficiently across the latent grid, allowing the diffusion model to obtain a large receptive field and thus enhance the 4D consistency of the output, while making the GPU memory consumption affordable. The experiments on the DNA-Rendering and ActorsHQ datasets demonstrate that our method is able to synthesize high-quality and consistent novel-view videos and significantly outperforms the existing approaches. See our project page for interactive demos and video results: https://diffuman4d.github.io/ .",
      "authors": [
        "Yudong Jin",
        "Sida Peng",
        "Xuan Wang",
        "Tao Xie",
        "Zhen Xu",
        "Yifan Yang",
        "Yujun Shen",
        "Hujun Bao",
        "Xiaowei Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:17+00:00",
          "link": "https://arxiv.org/abs/2507.13344v1",
          "size": "16497kb",
          "version": "v1"
        }
      ],
      "title": "Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13344",
        "HTML": "https://arxiv.org/html/2507.13344v1",
        "PDF": "https://arxiv.org/pdf/2507.13344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this study is on synthesizing human view videos using diffusion models, which is unrelated to LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13345",
      "abstract": "In visual generation tasks, the responses and combinations of complex concepts often lack stability and are error-prone, which remains an under-explored area. In this paper, we attempt to explore the causal factors for poor concept responses through elaborately designed experiments. We also design a concept-wise equalization loss function (IMBA loss) to address this issue. Our proposed method is online, eliminating the need for offline dataset processing, and requires minimal code changes. In our newly proposed complex concept benchmark Inert-CompBench and two other public test sets, our method significantly enhances the concept response capability of baseline models and yields highly competitive results with only a few codes.",
      "authors": [
        "Yukai Shi",
        "Jiarong Ou",
        "Rui Chen",
        "Haotian Yang",
        "Jiahao Wang",
        "Xin Tao",
        "Pengfei Wan",
        "Di Zhang",
        "Kun Gai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:47+00:00",
          "link": "https://arxiv.org/abs/2507.13345v1",
          "size": "7748kb",
          "version": "v1"
        }
      ],
      "title": "Imbalance in Balance: Online Concept Balancing in Generation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13345",
        "HTML": "https://arxiv.org/html/2507.13345v1",
        "PDF": "https://arxiv.org/pdf/2507.13345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores visual generation tasks and proposes a loss function to improve concept responses. It does not deal with LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13346",
      "abstract": "We introduce AutoPartGen, a model that generates objects composed of 3D parts in an autoregressive manner. This model can take as input an image of an object, 2D masks of the object's parts, or an existing 3D object, and generate a corresponding compositional 3D reconstruction. Our approach builds upon 3DShape2VecSet, a recent latent 3D representation with powerful geometric expressiveness. We observe that this latent space exhibits strong compositional properties, making it particularly well-suited for part-based generation tasks. Specifically, AutoPartGen generates object parts autoregressively, predicting one part at a time while conditioning on previously generated parts and additional inputs, such as 2D images, masks, or 3D objects. This process continues until the model decides that all parts have been generated, thus determining automatically the type and number of parts. The resulting parts can be seamlessly assembled into coherent objects or scenes without requiring additional optimization. We evaluate both the overall 3D generation capabilities and the part-level generation quality of AutoPartGen, demonstrating that it achieves state-of-the-art performance in 3D part generation.",
      "authors": [
        "Minghao Chen",
        "Jianyuan Wang",
        "Roman Shapovalov",
        "Tom Monnier",
        "Hyunyoung Jung",
        "Dilin Wang",
        "Rakesh Ranjan",
        "Iro Laina",
        "Andrea Vedaldi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:47+00:00",
          "link": "https://arxiv.org/abs/2507.13346v1",
          "size": "15452kb",
          "version": "v1"
        }
      ],
      "title": "AutoPartGen: Autogressive 3D Part Generation and Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13346",
        "HTML": "https://arxiv.org/html/2507.13346v1",
        "PDF": "https://arxiv.org/pdf/2507.13346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "AutoPartGen is centered around 3D part generation and does not provide any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13347",
      "abstract": "We introduce $\\pi^3$, a feed-forward neural network that offers a novel approach to visual geometry reconstruction, breaking the reliance on a conventional fixed reference view. Previous methods often anchor their reconstructions to a designated viewpoint, an inductive bias that can lead to instability and failures if the reference is suboptimal. In contrast, $\\pi^3$ employs a fully permutation-equivariant architecture to predict affine-invariant camera poses and scale-invariant local point maps without any reference frames. This design makes our model inherently robust to input ordering and highly scalable. These advantages enable our simple and bias-free approach to achieve state-of-the-art performance on a wide range of tasks, including camera pose estimation, monocular/video depth estimation, and dense point map reconstruction. Code and models are publicly available.",
      "authors": [
        "Yifan Wang",
        "Jianjun Zhou",
        "Haoyi Zhu",
        "Wenzheng Chang",
        "Yang Zhou",
        "Zizun Li",
        "Junyi Chen",
        "Jiangmiao Pang",
        "Chunhua Shen",
        "Tong He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.13347v1",
          "size": "9853kb",
          "version": "v1"
        }
      ],
      "title": "$\\pi^3$: Scalable Permutation-Equivariant Visual Geometry Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13347",
        "HTML": "https://arxiv.org/html/2507.13347v1",
        "PDF": "https://arxiv.org/pdf/2507.13347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the $\\pi^3$ network for visual geometry learning, specifically for tasks like camera pose estimation and depth estimation. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13348",
      "abstract": "Recent advancements in vision-language models (VLMs) have improved performance by increasing the number of visual tokens, which are often significantly longer than text tokens. However, we observe that most real-world scenarios do not require such an extensive number of visual tokens. While the performance drops significantly in a small subset of OCR-related tasks, models still perform accurately in most other general VQA tasks with only 1/4 resolution. Therefore, we propose to dynamically process distinct samples with different resolutions, and present a new paradigm for visual token compression, namely, VisionThink. It starts with a downsampled image and smartly decides whether it is sufficient for problem solving. Otherwise, the model could output a special token to request the higher-resolution image. Compared to existing Efficient VLM methods that compress tokens using fixed pruning ratios or thresholds, VisionThink autonomously decides whether to compress tokens case by case. As a result, it demonstrates strong fine-grained visual understanding capability on OCR-related tasks, and meanwhile saves substantial visual tokens on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge strategy to successfully apply RL to general VQA tasks. Moreover, we carefully design a reward function and penalty mechanism to achieve a stable and reasonable image resize call ratio. Extensive experiments demonstrate the superiority, efficiency, and effectiveness of our method. Our code is available at https://github.com/dvlab-research/VisionThink.",
      "authors": [
        "Senqiao Yang",
        "Junyi Li",
        "Xin Lai",
        "Bei Yu",
        "Hengshuang Zhao",
        "Jiaya Jia"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.13348v1",
          "size": "2460kb",
          "version": "v1"
        }
      ],
      "title": "VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13348",
        "HTML": "https://arxiv.org/html/2507.13348v1",
        "PDF": "https://arxiv.org/pdf/2507.13348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces VisionThink for improving vision-language models efficiency using reinforcement learning. Its focus is on token compression in visual data processing, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13350",
      "abstract": "Flow matching has emerged as a compelling generative modeling approach that is widely used across domains. To generate data via a flow matching model, an ordinary differential equation (ODE) is numerically solved via forward integration of the modeled velocity field. To better capture the multi-modality that is inherent in typical velocity fields, hierarchical flow matching was recently introduced. It uses a hierarchy of ODEs that are numerically integrated when generating data. This hierarchy of ODEs captures the multi-modal velocity distribution just like vanilla flow matching is capable of modeling a multi-modal data distribution. While this hierarchy enables to model multi-modal velocity distributions, the complexity of the modeled distribution remains identical across levels of the hierarchy. In this paper, we study how to gradually adjust the complexity of the distributions across different levels of the hierarchy via mini-batch couplings. We show the benefits of mini-batch couplings in hierarchical rectified flow matching via compelling results on synthetic and imaging data. Code is available at https://riccizz.github.io/HRF_coupling.",
      "authors": [
        "Yichi Zhang",
        "Yici Yan",
        "Alex Schwing",
        "Zhizhen Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2507.13350v1",
          "size": "2234kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Rectified Flow Matching with Mini-Batch Couplings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13350",
        "HTML": "https://arxiv.org/html/2507.13350v1",
        "PDF": "https://arxiv.org/pdf/2507.13350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on generative modeling using flow matching for data synthesis, not specifically related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13353",
      "abstract": "Recent studies have revealed that selecting informative and relevant video frames can significantly improve the performance of Video Large Language Models (Video-LLMs). Current methods, such as reducing inter-frame redundancy, employing separate models for image-text relevance assessment, or utilizing temporal video grounding for event localization, substantially adopt unsupervised learning paradigms, whereas they struggle to address the complex scenarios in long video understanding. We propose Instructed Temporal Grounding for Videos (VideoITG), featuring customized frame sampling aligned with user instructions. The core of VideoITG is the VidThinker pipeline, an automated annotation framework that explicitly mimics the human annotation process. First, it generates detailed clip-level captions conditioned on the instruction; then, it retrieves relevant video segments through instruction-guided reasoning; finally, it performs fine-grained frame selection to pinpoint the most informative visual evidence. Leveraging VidThinker, we construct the VideoITG-40K dataset, containing 40K videos and 500K instructed temporal grounding annotations. We then design a plug-and-play VideoITG model, which takes advantage of visual language alignment and reasoning capabilities of Video-LLMs, for effective frame selection in a discriminative manner. Coupled with Video-LLMs, VideoITG achieves consistent performance improvements across multiple multimodal video understanding benchmarks, showing its superiority and great potentials for video understanding.",
      "authors": [
        "Shihao Wang",
        "Guo Chen",
        "De-an Huang",
        "Zhiqi Li",
        "Minghan Li",
        "Guilin Li",
        "Jose M. Alvarez",
        "Lei Zhang",
        "Zhiding Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2507.13353v1",
          "size": "8832kb",
          "version": "v1"
        }
      ],
      "title": "VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13353",
        "HTML": "https://arxiv.org/html/2507.13353v1",
        "PDF": "https://arxiv.org/pdf/2507.13353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "VideoITG proposes a method for video frame selection and captioning tailored to video understanding. It does not make contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.02740",
      "abstract": "Gaussian Processes have become an indispensable part of the spatial statistician's toolbox but are unsuitable for analyzing large dataset because of the significant time and memory needed to fit the associated model exactly. Vecchia Approximation is widely used to reduce the computational complexity and can be calculated with embarrassingly parallel algorithms. While multi-core software has been developed for Vecchia Approximation, such as the GpGp R package, software designed to run on graphics processing units (GPU) is lacking, despite the tremendous success GPUs have had in statistics and machine learning. We compare three different ways to implement Vecchia Approximation on a GPU: two of which are similar to methods used for other Gaussian Process approximations and one that is new. The impact of memory type on performance is investigated and the final method is optimized accordingly. We show that our new method outperforms the other two and then present it in the GpGpU R package. We compare GpGpU to existing multi-core and GPU-accelerated software by fitting Gaussian Process models on various datasets, including a large spatial-temporal dataset of $n>10^6$ points collected from an earth-observing satellite. Our results show that GpGpU achieves faster runtimes and better predictive accuracy.",
      "authors": [
        "Zachary James",
        "Joseph Guinness"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-03T01:24:44+00:00",
          "link": "https://arxiv.org/abs/2407.02740v1",
          "size": "12240kb",
          "version": "v1"
        }
      ],
      "title": "Implementation and Analysis of GPU Algorithms for Vecchia Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02740",
        "HTML": "https://arxiv.org/html/2407.02740v1",
        "PDF": "https://arxiv.org/pdf/2407.02740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about implementing GPU algorithms for Vecchia Approximation to improve Gaussian Process model performance, without any focus on LLM training data processing or dataset-related improvements."
      },
      "tasks": [
        "Gaussian Processes"
      ],
      "repo_urls": [
        "https://github.com/zjames12/GpGpU"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02707",
      "abstract": "Molecular Dynamics (MD) simulations are essential for accurately predicting the physical and chemical properties of large molecular systems across various pressure and temperature ensembles. However, the high computational costs associated with All-Atom (AA) MD simulations have led to the development of Coarse-Grained Molecular Dynamics (CGMD), providing a lower-dimensional compression of the AA structure into representative CG beads, offering reduced computational expense at the cost of predictive accuracy. Existing CGMD methods, such as CG-Martini (calibrated against experimental data), aim to generate an embedding of a topology that sufficiently generalizes across a range of structures. Detrimentally, in attempting to specify parameterization with applicability across molecular classes, it is unable to specialize to domain-specific applications, where sufficient accuracy and computational speed are critical. This work presents a novel approach to optimize derived results from CGMD simulations by refining the general-purpose Martini3 topologies specifically the bonded interaction parameters within a given coarse-grained mapping - for domain-specific applications using Bayesian Optimization methodologies. We have developed and validated a CG potential applicable to any degree of polymerization, representing a significant advancement in the field. Our optimized CG potential, based on the Martini3 framework, aims to achieve accuracy comparable to AAMD while maintaining the computational efficiency of CGMD. This approach bridges the gap between efficiency and accuracy in multiscale molecular simulations, potentially enabling more rapid and cost-effective molecular discovery across various scientific and technological domains.",
      "authors": [
        "Pranoy Ray",
        "Adam P. Generale",
        "Nikhith Vankireddy",
        "Yuichiro Asoma",
        "Masataka Nakauchi",
        "Haein Lee",
        "Katsuhisa Yoshida",
        "Yoshishige Okuno",
        "Surya R. Kalidindi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T01:18:47+00:00",
          "link": "https://arxiv.org/abs/2501.02707v1",
          "size": "1097kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T17:49:48+00:00",
          "link": "https://arxiv.org/abs/2501.02707v2",
          "size": "1137kb",
          "version": "v2"
        },
        {
          "date": "2025-01-14T18:32:12+00:00",
          "link": "https://arxiv.org/abs/2501.02707v3",
          "size": "1136kb",
          "version": "v3"
        },
        {
          "date": "2025-06-11T23:28:47+00:00",
          "link": "https://arxiv.org/abs/2501.02707v4",
          "size": "1063kb",
          "version": "v4"
        }
      ],
      "title": "Refining Coarse-Grained Molecular Topologies: A Bayesian Optimization Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02707",
        "PDF": "https://arxiv.org/pdf/2501.02707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on refining molecular topologies using Bayesian Optimization for molecular simulations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11958",
      "abstract": "Microbiomes, which are collections of interacting microbes in an environment, often substantially impact the environmental patches or living hosts that they occupy. In microbiome models, it is important to consider both the local dynamics within an environment and exchanges of microbiomes between environments. One way to incorporate these and other interactions across multiple scales is to employ metacommunity theory. Metacommunity models commonly assume continuous microbiome dispersal between the environments in which local microbiome dynamics occur. Under this assumption, a single parameter between each pair of environments controls the dispersal rate between those environments. This metacommunity framework is well-suited to abiotic environmental patches, but it fails to capture an essential aspect of the microbiomes of living hosts, which generally do not interact continuously with each other. Instead, living hosts interact with each other in discrete time intervals. In this paper, we develop a modeling framework that encodes such discrete interactions and uses two parameters to separately control the interaction frequencies between hosts and the amount of microbiome exchange during each interaction. We derive analytical approximations of models in our framework in three parameter regimes and prove that they are accurate in those regimes. We compare these approximations to numerical simulations for an illustrative model. We demonstrate that both parameters in our modeling framework are necessary to determine microbiome dynamics. Key features of the dynamics, such as microbiome convergence across hosts, depend sensitively on the interplay between interaction frequency and strength.",
      "authors": [
        "Michael Johnson and Mason A. Porter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Social and Information Networks (cs.SI)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T06:44:02+00:00",
          "link": "https://arxiv.org/abs/2507.11958v1",
          "size": "4829kb",
          "version": "v1"
        }
      ],
      "title": "Interacting Hosts with Microbiome Exchange: An Extension of Metacommunity Theory for Discrete Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11958",
        "HTML": "https://arxiv.org/html/2507.11958v1",
        "PDF": "https://arxiv.org/pdf/2507.11958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores microbiome dynamics through metacommunity theory and discrete interactions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12473",
      "abstract": "While modern AI continues to advance, the biological brain remains the pinnacle of neural networks in its robustness, adaptability, and efficiency. This review explores an AI architectural path inspired by the brain's structure, particularly the minicolumn hypothesis, which views the neocortex as a distributed system of repeated modules - a structure we connect to collective intelligence (CI). Despite existing work, there is a lack of comprehensive reviews connecting the cortical column to the architectures of repeated neural modules. This review aims to fill that gap by synthesizing historical, theoretical, and methodological perspectives on neural module repetition. We distinguish between architectural repetition - reusing structure - and parameter-shared module repetition, where the same functional unit is repeated across a network. The latter exhibits key CI properties such as robustness, adaptability, and generalization. Evidence suggests that the repeated module tends to converge toward a generalist module: simple, flexible problem solvers capable of handling many roles in the ensemble. This generalist tendency may offer solutions to longstanding challenges in modern AI: improved energy efficiency during training through simplicity and scalability, and robust embodied control via generalization. While empirical results suggest such systems can generalize to out-of-distribution problems, theoretical results are still lacking. Overall, architectures featuring module repetition remain an emerging and unexplored architectural strategy, with significant untapped potential for both efficiency, robustness, and adaptiveness. We believe that a system that adopts the benefits of CI, while adhering to architectural and functional principles of the minicolumns, could challenge the modern AI problems of scalability, energy consumption, and democratization.",
      "authors": [
        "Mia-Katrin Kvalsund and Mikkel Elle Lepper{\\o}d"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:13:10+00:00",
          "link": "https://arxiv.org/abs/2507.12473v1",
          "size": "2737kb",
          "version": "v1"
        }
      ],
      "title": "The Generalist Brain Module: Module Repetition in Neural Networks in Light of the Minicolumn Hypothesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12473",
        "HTML": "https://arxiv.org/html/2507.12473v1",
        "PDF": "https://arxiv.org/pdf/2507.12473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on architectural design inspired by biological structures and does not involve training data processing operations related to LLMs, such as data engineering or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12475",
      "abstract": "The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.",
      "authors": [
        "Takashi Izumo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T07:34:46+00:00",
          "link": "https://arxiv.org/abs/2507.12475v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12475",
        "HTML": "https://arxiv.org/html/2507.12475v1",
        "PDF": "https://arxiv.org/pdf/2507.12475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses decision theory and mathematical modeling with no connection to data processing for LLM training, pretraining, or fine-tuning stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12479",
      "abstract": "We demonstrate the feedback control of a weakly conducting magnetohydrodynamic (MHD) flow via Lorentz forces generated by externally applied electric and magnetic fields. Specifically, we steer the flow of an electrolyte toward prescribed velocity or vorticity patterns using arrays of electrodes and electromagnets positioned around and beneath a fluid reservoir, with feedback provided by planar particle image velocimetry (PIV). Control is implemented using a model predictive control (MPC) framework, in which control signals are computed by minimizing a cost function over the predicted evolution of the flow. The predictor is constructed entirely from data using Koopman operator theory, which enables a linear representation of the underlying nonlinear fluid dynamics. This linearity allows the MPC problem to be solved by alternating between two small and efficiently solvable convex quadratic programs (QPs): one for the electrodes and one for the electromagnets. The resulting controller runs in a closed loop on a standard laptop, enabling real-time control of the flow. We demonstrate the functionality of the approach through experiments in which the flow is shaped to match a range of reference velocity fields and a time-varying vorticity field.",
      "authors": [
        "Adam Uchytil",
        "Milan Korda and Ji\\v{r}\\'i Zem\\'anek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:17:43+00:00",
          "link": "https://arxiv.org/abs/2507.12479v1",
          "size": "12597kb",
          "version": "v1"
        }
      ],
      "title": "Real-time control of a magnetohydrodynamic flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12479",
        "HTML": "https://arxiv.org/html/2507.12479v1",
        "PDF": "https://arxiv.org/pdf/2507.12479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses real-time control of MHD flow using a model predictive control framework, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12485",
      "abstract": "Dementia is a devastating condition with profound implications for individuals, families, and healthcare systems. Early and accurate detection of dementia is critical for timely intervention and improved patient outcomes. While classical machine learning and deep learning approaches have been explored extensively for dementia prediction, these solutions often struggle with high-dimensional biomedical data and large-scale datasets, quickly reaching computational and performance limitations. To address this challenge, quantum machine learning (QML) has emerged as a promising paradigm, offering faster training and advanced pattern recognition capabilities. This work aims to demonstrate the potential of quantum transfer learning (QTL) to enhance the performance of a weak classical deep learning model applied to a binary classification task for dementia detection. Besides, we show the effect of noise on the QTL-based approach, investigating the reliability and robustness of this method. Using the OASIS 2 dataset, we show how quantum techniques can transform a suboptimal classical model into a more effective solution for biomedical image classification, highlighting their potential impact on advancing healthcare technology.",
      "authors": [
        "Sounak Bhowmik",
        "Talita Perciano",
        "Himanshu Thapliyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:10:50+00:00",
          "link": "https://arxiv.org/abs/2507.12485v1",
          "size": "618kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Transfer Learning to Boost Dementia Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12485",
        "HTML": "https://arxiv.org/html/2507.12485v1",
        "PDF": "https://arxiv.org/pdf/2507.12485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum transfer learning for dementia detection, focusing on improving model performance for biomedical tasks. It does not relate to LLM training data processing practices."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12492",
      "abstract": "Quantum Federated Learning (QFL) is an emerging paradigm that combines quantum computing and federated learning (FL) to enable decentralized model training while maintaining data privacy over quantum networks. However, quantum noise remains a significant barrier in QFL, since modern quantum devices experience heterogeneous noise levels due to variances in hardware quality and sensitivity to quantum decoherence, resulting in inadequate training performance. To address this issue, we propose SpoQFL, a novel QFL framework that leverages sporadic learning to mitigate quantum noise heterogeneity in distributed quantum systems. SpoQFL dynamically adjusts training strategies based on noise fluctuations, enhancing model robustness, convergence stability, and overall learning efficiency. Extensive experiments on real-world datasets demonstrate that SpoQFL significantly outperforms conventional QFL approaches, achieving superior training performance and more stable convergence.",
      "authors": [
        "Ratun Rahman",
        "Atit Pokharel",
        "Dinh C. Nguyen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T20:30:11+00:00",
          "link": "https://arxiv.org/abs/2507.12492v1",
          "size": "606kb",
          "version": "v1"
        }
      ],
      "title": "Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12492",
        "HTML": "https://arxiv.org/html/2507.12492v1",
        "PDF": "https://arxiv.org/pdf/2507.12492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a federated learning approach in a quantum context, focusing on handling quantum noise, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12495",
      "abstract": "Space weather events pose a growing threat to modern economies, yet their macroeconomic consequences still remain underexplored. This study presents the first dedicated economic assessment of geomagnetic storm impacts on Aotearoa New Zealand, quantifying potential GDP losses across seven disruption and mitigation scenarios due to an extreme coronal mass ejection (CME). The primary focus is upon the damaging impacts of geomagnetically induced currents (GICs) on the electrical power transmission network. The goal is to support decision-making around space weather mitigation investments by providing a first-order approximation of their potential economic benefits. We find that in the absence of mitigation, a severe but realistic storm could result in up to NZ\\$8.36 billion in lost GDP, with more than half stemming from cascading supply chain effects. Yet, even less severe scenarios incur losses exceeding NZ\\$3 billion. Importantly, research-led operational strategies, such as optimized switching and islanding, can avoid up to NZ\\$370 million in losses for as little as NZ\\$500,000 in expenditure, delivering a benefit-cost ratio of 740 to 1. Moreover, physical protections such as GIC blocking devices further reduce disruption to as low as NZ\\$1.12 billion, with avoided GDP losses up to NZ\\$2.3 billion, and benefit-cost returns up to 80 to 1. When also acknowledging unmodelled impacts, including multi-billion losses in capital equipment and long-term revenue, the economic rationale for pre-emptive mitigation becomes even more pertinent. Future research needs to integrate the modelling of capital and revenue losses for strategically important industrial facilities.",
      "authors": [
        "Edward J. Oughton",
        "Andrew Renton",
        "Daniel Mac Marnus",
        "Craig J. Rodger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Plasma Physics (physics.plasm-ph)",
        "Physics and Society (physics.soc-ph)",
        "Space Physics (physics.space-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T21:01:40+00:00",
          "link": "https://arxiv.org/abs/2507.12495v1",
          "size": "3383kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the economic benefits of space weather mitigation investment decisions: Evidence from Aotearoa New Zealand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12495",
        "PDF": "https://arxiv.org/pdf/2507.12495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper assesses the economic benefits of space weather mitigation and its impact on New Zealand's economy. It does not relate to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12497",
      "abstract": "Most Differentially Private (DP) approaches focus on limiting privacy leakage from learners based on the data that they are trained on, there are fewer approaches that consider leakage when procedures involve a calibration dataset which is common in uncertainty quantification methods such as Conformal Prediction (CP). Since there is a limited amount of approaches in this direction, in this work we deliver a general DP approach for CP that we call Private Conformity via Quantile Search (P-COQS). The proposed approach adapts an existing randomized binary search algorithm for computing DP quantiles in the calibration phase of CP thereby guaranteeing privacy of the consequent prediction sets. This however comes at a price of slightly under-covering with respect to the desired $(1 - \\alpha)$-level when using finite-sample calibration sets (although broad empirical results show that the P-COQS generally targets the required level in the considered cases). Confirming properties of the adapted algorithm and quantifying the approximate coverage guarantees of the consequent CP, we conduct extensive experiments to examine the effects of privacy noise, sample size and significance level on the performance of our approach compared to existing alternatives. In addition, we empirically evaluate our approach on several benchmark datasets, including CIFAR-10, ImageNet and CoronaHack. Our results suggest that the proposed method is robust to privacy noise and performs favorably with respect to the current DP alternative in terms of empirical coverage, efficiency, and informativeness. Specifically, the results indicate that P-COQS produces smaller conformal prediction sets while simultaneously targeting the desired coverage and privacy guarantees in all these experimental settings.",
      "authors": [
        "Ogonnaya M. Romanus",
        "Roberto Molinari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Computation (stat.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T22:08:02+00:00",
          "link": "https://arxiv.org/abs/2507.12497v1",
          "size": "214kb",
          "version": "v1"
        }
      ],
      "title": "Differentially Private Conformal Prediction via Quantile Binary Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12497",
        "HTML": "https://arxiv.org/html/2507.12497v1",
        "PDF": "https://arxiv.org/pdf/2507.12497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a differentially private approach to conformal prediction, focusing on privacy in uncertainty quantification, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12502",
      "abstract": "We establish the first quantitative Berry-Esseen bounds for edge eigenvector statistics in random regular graphs. For any $d$-regular graph on $N$ vertices with fixed $d \\geq 3$ and deterministic unit vector $\\mathbf{q} \\perp \\mathbf{e}$, we prove that the normalized overlap $\\sqrt{N}\\langle \\mathbf{q}, \\mathbf{u}_2 \\rangle$ satisfies \\[ \\sup_{x \\in \\mathbb{R}} \\left|\\mathbb{P}\\left(\\sqrt{N}\\langle \\mathbf{q}, \\mathbf{u}_2 \\rangle \\leq x\\right) - \\Phi(x)\\right| \\leq C_d N^{-1/6+\\varepsilon} \\] where $\\mathbf{u}_2$ is the second eigenvector and $C_d \\leq \\tilde{C}d^3\\varepsilon^{-10}$ for an absolute constant $\\tilde{C}$. This provides the first explicit convergence rate for the recent edge eigenvector universality results of He, Huang, and Yau \\cite{HHY25}.\n  Our proof introduces a single-scale comparison method using constrained Dyson Brownian motion that preserves the degree constraint $\\tilde{H}_t\\mathbf{e} = 0$ throughout the evolution. The key technical innovation is a sharp edge isotropic local law with explicit constant $C(d,\\varepsilon) \\leq \\tilde{C}d\\varepsilon^{-5}$, enabling precise control of eigenvector overlap dynamics.\n  At the critical time $t_* = N^{-1/3+\\varepsilon}$, we perform a fourth-order cumulant comparison with constrained GOE, achieving optimal error bounds through a single comparison rather than the traditional multi-scale approach. We extend our results to joint universality for the top $K$ edge eigenvectors with $K \\leq N^{1/10-\\delta}$, showing they converge to independent Gaussians. Through analysis of eigenvalue spacing barriers, critical time scales, and comparison across multiple proof methods, we provide evidence that the $N^{-1/6}$ rate is optimal for sparse regular graphs. All constants are tracked explicitly throughout, enabling finite-size applications in spectral algorithms and network analysis.",
      "authors": [
        "Leonhard Nagel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)",
        "Spectral Theory (math.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:31:51+00:00",
          "link": "https://arxiv.org/abs/2507.12502v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative Edge Eigenvector Universality for Random Regular Graphs: Berry-Esseen Bounds with Explicit Constants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12502",
        "HTML": "https://arxiv.org/html/2507.12502v1",
        "PDF": "https://arxiv.org/pdf/2507.12502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study provides a quantitative analysis of eigenvector statistics in random regular graphs, lacking any discussion on LLM training data processing or the creation and management of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12503",
      "abstract": "Graph representation matrices are essential tools in graph data analysis. Recently, Hermitian adjacency matrices have been proposed to investigate directed graph structures. Previous studies have demonstrated that these matrices can extract valuable information for clustering. In this paper, we propose the complex non-backtracking matrix that integrates the properties of the Hermitian adjacency matrix and the non-backtracking matrix. The proposed matrix has similar properties with the non-backtracking matrix of undirected graphs. We reveal relationships between the complex non-backtracking matrix and the Hermitian adjacency matrix. Also, we provide intriguing insights that this matrix representation holds cluster information, particularly for sparse directed graphs.",
      "authors": [
        "Keishi Sando",
        "Hideitsu Hino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T05:57:11+00:00",
          "link": "https://arxiv.org/abs/2507.12503v1",
          "size": "1408kb",
          "version": "v1"
        }
      ],
      "title": "Complex non-backtracking matrix for directed graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12503",
        "HTML": "https://arxiv.org/html/2507.12503v1",
        "PDF": "https://arxiv.org/pdf/2507.12503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a complex non-backtracking matrix for analyzing directed graphs but does not address any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12560",
      "abstract": "The present work revisits and provides a new approach on a result by Charles Ballantine, on the factorization of a square matrix with positive determinant into a product of positive definite factors. {\\em Ballantine-type} factorizations, that bound the number of positive definite factors, proved central in solving a basic, yet elusive control problem--the strong controllability of a linear system via control in the form of state feedback. Ballantine's result transcends control engineering, and highlights the little appreciated fact that rotations can be realized by the successive application of irrotational motions. Our approach is constructive and is based on the theory of optimal mass transport, specifically, it relates successive rotations of Gaussian distributions to corresponding optimal transport maps that constitute the sought factors.",
      "authors": [
        "Mahmoud Abdelgalil and Tryphon T. Georgiou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:19:14+00:00",
          "link": "https://arxiv.org/abs/2507.12560v1",
          "size": "303kb",
          "version": "v1"
        }
      ],
      "title": "On the factorization of matrices into products of positive definite ones",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12560",
        "HTML": "https://arxiv.org/html/2507.12560v1",
        "PDF": "https://arxiv.org/pdf/2507.12560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores matrix factorization related to control engineering and optimal transport, which has no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12567",
      "abstract": "Background/Introduction: In this paper, the neural network class of Self-Organising Maps (SOMs) is investigated in terms of its theoretical and applied validity for cognitive modelling, particularly of neurodevelopmental disorders.\n  Methods: A modified SOM network type, with increased biological plausibility, incorporating a type of cortical columnar oscillation in the form of an oscillating Topological Neighbourhood (TN), is introduced and applied alongside the standard SOM. Aspects of two neurodevelopmental disorders, autism and schizophrenia, are modelled using SOM networks, based on existing neurocomputational theories. Both standard and oscillating-TN SOM training is employed with targeted modifications in the TN width function. Computer simulations are conducted using revised versions of a previously introduced model (IPSOM) based on a new modelling hypothesis.\n  Results/Conclusions: The results demonstrate that there is strong similarity between standard and oscillating-TN SOM modelling in terms of map formation behaviour, output and structure, while the oscillating version offers a more realistic computational analogue of brain function. Neuroscientific and computational arguments are presented to validate the proposed SOM modification within a cognitive modelling framework.",
      "authors": [
        "Spyridon Revithis",
        "Nadine Marcus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T18:33:16+00:00",
          "link": "https://arxiv.org/abs/2507.12567v1",
          "size": "1926kb",
          "version": "v1"
        }
      ],
      "title": "Cognitive Modelling Aspects of Neurodevelopmental Disorders Using Standard and Oscillating Neighbourhood SOM Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12567",
        "PDF": "https://arxiv.org/pdf/2507.12567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses cognitive modeling in terms of neurodevelopmental disorders using Self-Organising Maps, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12593",
      "abstract": "Zak-transform based orthogonal time frequency space (Zak-OTFS) is a delay-Doppler (DD) domain modulation scheme in which the signal processing is carried out in the DD domain. The channel when viewed in the DD domain is predictable. However, even with Zak-OTFS, pilots need to be sent periodically, albeit at a lower rate. In this paper, we propose a differential communication scheme for Zak-OTFS systems that alleviates the need for periodic pilot transmission. Towards this, we analytically show that the detected data can be used as a pilot and that the channel estimate obtained from the detected data can enable further detection enabling the \"differential\" aspect of the communication. Specifically, we leverage the prediction capability of the DD channel in Zak-OTFS to use the channel estimate (obtained from detected data symbols treated as pilots) in the previous instant to detect data in the next instant and propagate this forward. The advantages are two fold. First, it allows the data symbols to enjoy higher energy since the energy that would otherwise be required for pilot symbols can also be allocated to data symbols. Second, it allows for full spectral efficiency compared to point or embedded pilots. Comparison with the full spectral efficiency achieving spread pilot scheme shows that the proposed method achieves better bit-error rate at lower complexity.",
      "authors": [
        "Sandesh Rao Mattu",
        "Nishant Mehrotra and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T19:22:42+00:00",
          "link": "https://arxiv.org/abs/2507.12593v1",
          "size": "454kb",
          "version": "v1"
        }
      ],
      "title": "Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12593",
        "HTML": "https://arxiv.org/html/2507.12593v1",
        "PDF": "https://arxiv.org/pdf/2507.12593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses differential communication in Zak-OTFS systems and focuses on channel estimation and pilot usage, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12615",
      "abstract": "This paper investigates the stabilization of a coupled system comprising a parabolic PDE and an elliptic PDE with nonlinear terms. A rigorous backstepping design provides an explicit boundary control law and exponentially convergent observers from partial boundary measurements. Several theorems ensure exponential stability and well-posedness of the nonlinear closed-loop system.",
      "authors": [
        "Kamal Fenza",
        "Moussa Labbadi and Mohamed Ouzahra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:20:17+00:00",
          "link": "https://arxiv.org/abs/2507.12615v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Boundary Feedback and Observer Synthesis for a Class of Nonlinear Parabolic--Elliptic PDE Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12615",
        "HTML": "https://arxiv.org/html/2507.12615v1",
        "PDF": "https://arxiv.org/pdf/2507.12615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses boundary feedback and observer synthesis for nonlinear PDE systems, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12624",
      "abstract": "Virtual staining has emerged as a powerful alternative to traditional histopathological staining techniques, enabling rapid, reagent-free image transformations. However, existing evaluation methods predominantly rely on full-reference image quality assessment (FR-IQA) metrics such as structural similarity, which are originally designed for natural images and often fail to capture pathology-relevant features. Expert pathology reviews have also been used, but they are inherently subjective and time-consuming.\n  In this study, we introduce PaPIS (Pathology-Aware Perceptual Image Similarity), a novel FR-IQA metric specifically tailored for virtual staining evaluation. PaPIS leverages deep learning-based features trained on cell morphology segmentation and incorporates Retinex-inspired feature decomposition to better reflect histological perceptual quality. Comparative experiments demonstrate that PaPIS more accurately aligns with pathology-relevant visual cues and distinguishes subtle cellular structures that traditional and existing perceptual metrics tend to overlook. Furthermore, integrating PaPIS as a guiding loss function in a virtual staining model leads to improved histological fidelity.\n  This work highlights the critical need for pathology-aware evaluation frameworks to advance the development and clinical readiness of virtual staining technologies.",
      "authors": [
        "Qiankai Wang",
        "James E.D. Tweel",
        "Parsin Haji Reza",
        "Anita Layton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:39:55+00:00",
          "link": "https://arxiv.org/abs/2507.12624v1",
          "size": "7969kb",
          "version": "v1"
        }
      ],
      "title": "Pathology-Guided Virtual Staining Metric for Evaluation and Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12624",
        "HTML": "https://arxiv.org/html/2507.12624v1",
        "PDF": "https://arxiv.org/pdf/2507.12624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel evaluation metric for virtual staining in histopathology and does not address LLM training data processing or any relevant data engineering tasks for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12625",
      "abstract": "Recent advances have shown promise in emotion recognition from electroencephalogram (EEG) signals by employing bi-hemispheric neural architectures that incorporate neuroscientific priors into deep learning models. However, interpretability remains a significant limitation for their application in sensitive fields such as affective computing and cognitive modeling. In this work, we introduce a post-hoc interpretability framework tailored to dual-stream EEG classifiers, extending the Local Interpretable Model-Agnostic Explanations (LIME) approach to accommodate structured, bi-hemispheric inputs. Our method adapts LIME to handle structured two-branch inputs corresponding to left and right-hemisphere EEG channel groups. It decomposes prediction relevance into per-channel contributions across hemispheres and emotional classes. We apply this framework to a previously validated dual-branch recurrent neural network trained on EmoNeuroDB, a dataset of EEG recordings captured during a VR-based emotion elicitation task. The resulting explanations reveal emotion-specific hemispheric activation patterns consistent with known neurophysiological phenomena, such as frontal lateralization in joy and posterior asymmetry in sadness. Furthermore, we aggregate local explanations across samples to derive global channel importance profiles, enabling a neurophysiologically grounded interpretation of the model's decisions. Correlation analysis between symmetric electrodes further highlights the model's emotion-dependent lateralization behavior, supporting the functional asymmetries reported in affective neuroscience.",
      "authors": [
        "David Freire-Obreg\\'on",
        "Agnieszka Dubiel",
        "Prasoon Kumar Vinodkumar",
        "Gholamreza Anbarjafari",
        "Dorota Kami\\'nska",
        "Modesto Castrill\\'on-Santana"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Human-Computer Interaction (cs.HC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T20:39:58+00:00",
          "link": "https://arxiv.org/abs/2507.12625v1",
          "size": "563kb",
          "version": "v1"
        }
      ],
      "title": "Mapping Emotions in the Brain: A Bi-Hemispheric Neural Model with Explainable Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12625",
        "HTML": "https://arxiv.org/html/2507.12625v1",
        "PDF": "https://arxiv.org/pdf/2507.12625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces an interpretability framework for EEG-based emotion recognition models. It is not related to LLM training data processing, concentrating instead on model interpretability and emotion recognition."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12630",
      "abstract": "Channel estimation is crucial in cognitive communications, as it enables intelligent spectrum sensing and adaptive transmission by providing accurate information about the current channel state. However, in many papers neural networks are frequently tested by training and testing on one example channel or similar channels. This is because data-driven methods often degrade on new data which they are not trained on, as they cannot extrapolate their training knowledge. This is despite the fact physical channels are often assumed to be time-variant. However, due to the low latency requirements and limited computing resources, neural networks may not have enough time and computing resources to execute online training to fine-tune the parameters. This motivates us to design offline-trained neural networks that can perform robustly over wireless channels, but without any actual channel information being known at design time. In this paper, we propose design criteria to generate synthetic training datasets for neural networks, which guarantee that after training the resulting networks achieve a certain mean squared error (MSE) on new and previously unseen channels. Therefore, neural network solutions require no prior channel information or parameters update for real-world implementations. Based on the proposed design criteria, we further propose a benchmark design which ensures intelligent operation for different channel profiles. To demonstrate general applicability, we use neural networks with different levels of complexity to show that the generalization achieved appears to be independent of neural network architecture. From simulations, neural networks achieve robust generalization to wireless channels with both fixed channel profiles and variable delay spreads.",
      "authors": [
        "Dianxin Luan and John Thompson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:04:37+00:00",
          "link": "https://arxiv.org/abs/2507.12630v1",
          "size": "2484kb",
          "version": "v1"
        }
      ],
      "title": "Achieving Robust Channel Estimation Neural Networks by Designed Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12630",
        "HTML": "https://arxiv.org/html/2507.12630v1",
        "PDF": "https://arxiv.org/pdf/2507.12630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with designing training data for neural networks in wireless communication systems. It does not pertain to LLMs or their training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12645",
      "abstract": "The increasing need for accurate and unified analysis of diverse biological signals, such as ECG and EEG, is paramount for comprehensive patient assessment, especially in synchronous monitoring. Despite advances in multi-sensor fusion, a critical gap remains in developing unified architectures that effectively process and extract features from fundamentally different physiological signals. Another challenge is the inherent class imbalance in many biomedical datasets, often causing biased performance in traditional methods. This study addresses these issues by proposing a novel and unified deep learning framework that achieves state-of-the-art performance across different signal types. Our method integrates a ResNet-based CNN with an attention mechanism, enhanced by a novel data augmentation strategy: time-domain concatenation of multiple augmented variants of each signal to generate richer representations. Unlike prior work, we scientifically increase signal complexity to achieve future-reaching capabilities, which resulted in the best predictions compared to the state of the art. Preprocessing steps included wavelet denoising, baseline removal, and standardization. Class imbalance was effectively managed through the combined use of this advanced data augmentation and the Focal Loss function. Regularization techniques were applied during training to ensure generalization. We rigorously evaluated the proposed architecture on three benchmark datasets: UCI Seizure EEG, MIT-BIH Arrhythmia, and PTB Diagnostic ECG. It achieved accuracies of 99.96%, 99.78%, and 100%, respectively, demonstrating robustness across diverse signal types and clinical contexts. Finally, the architecture requires ~130 MB of memory and processes each sample in ~10 ms, suggesting suitability for deployment on low-end or wearable devices.",
      "authors": [
        "Mohammed Guhdar",
        "Ramadhan J. Mstafa",
        "Abdulhakeem O. Mohammed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T21:38:10+00:00",
          "link": "https://arxiv.org/abs/2507.12645v1",
          "size": "681kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Data Augmentation Strategy for Robust Deep Learning Classification of Biomedical Time-Series Data: Application to ECG and EEG Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12645",
        "HTML": "https://arxiv.org/html/2507.12645v1",
        "PDF": "https://arxiv.org/pdf/2507.12645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses data augmentation strategies for biomedical time-series data, particularly in deep learning, making it unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12657",
      "abstract": "We reinterpret and propose a framework for pricing path-dependent financial derivatives by estimating the full distribution of payoffs using Distributional Reinforcement Learning (DistRL). Unlike traditional methods that focus on expected option value, our approach models the entire conditional distribution of payoffs, allowing for risk-aware pricing, tail-risk estimation, and enhanced uncertainty quantification. We demonstrate the efficacy of this method on Asian options, using quantile-based value function approximators.",
      "authors": [
        "Ahmet Umur \\\"Ozsoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Finance (q-fin.MF)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:14:54+00:00",
          "link": "https://arxiv.org/abs/2507.12657v1",
          "size": "304kb",
          "version": "v1"
        }
      ],
      "title": "Distributional Reinforcement Learning on Path-dependent Options",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12657",
        "HTML": "https://arxiv.org/html/2507.12657v1",
        "PDF": "https://arxiv.org/pdf/2507.12657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for pricing financial derivatives using Distributional Reinforcement Learning. It is unrelated to LLM training data processing or dataset creation/enhancement relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12661",
      "abstract": "Accurate state estimation requires careful consideration of uncertainty surrounding the process and measurement models; these characteristics are usually not well-known and need an experienced designer to select the covariance matrices. An error in the selection of covariance matrices could impact the accuracy of the estimation algorithm and may sometimes cause the filter to diverge. Identifying noise characteristics has long been a challenging problem due to uncertainty surrounding noise sources and difficulties in systematic noise modeling. Most existing approaches try identifying unknown covariance matrices through an optimization algorithm involving innovation sequences. In recent years, learning approaches have been utilized to determine the stochastic characteristics of process and measurement models. We present a learning-based methodology with different loss functions to identify noise characteristics and test these approaches' performance for real-time vehicle state estimation",
      "authors": [
        "Pardha Sai Krishna Ala",
        "Ameya Salvi",
        "Venkat Krovi",
        "Matthias Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T22:31:29+00:00",
          "link": "https://arxiv.org/abs/2507.12661v1",
          "size": "2044kb",
          "version": "v1"
        }
      ],
      "title": "Physics constrained learning of stochastic characteristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12661",
        "HTML": "https://arxiv.org/html/2507.12661v1",
        "PDF": "https://arxiv.org/pdf/2507.12661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a learning-based methodology to identify stochastic characteristics for state estimation with physics constraints, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12669",
      "abstract": "Background/Objectives: Age-related macular degeneration, glaucoma, diabetic retinopathy (DR), diabetic macular edema, and pathological myopia affect hundreds of millions of people worldwide. Early screening for these diseases is essential, yet access to medical care remains limited in low- and middle-income countries as well as in resource-limited settings. We develop InSight, an AI-based app that combines patient metadata with fundus images for accurate diagnosis of five common eye diseases to improve accessibility of screenings.\n  Methods: InSight features a three-stage pipeline: real-time image quality assessment, disease diagnosis model, and a DR grading model to assess severity. Our disease diagnosis model incorporates three key innovations: (a) Multimodal fusion technique (MetaFusion) combining clinical metadata and images; (b) Pretraining method leveraging supervised and self-supervised loss functions; and (c) Multitask model to simultaneously predict 5 diseases. We make use of BRSET (lab-captured images) and mBRSET (smartphone-captured images) datasets, both of which also contain clinical metadata for model training/evaluation.\n  Results: Trained on a dataset of BRSET and mBRSET images, the image quality checker achieves near-100% accuracy in filtering out low-quality fundus images. The multimodal pretrained disease diagnosis model outperforms models using only images by 6% in balanced accuracy for BRSET and 4% for mBRSET.\n  Conclusions: The InSight pipeline demonstrates robustness across varied image conditions and has high diagnostic accuracy across all five diseases, generalizing to both smartphone and lab captured images. The multitask model contributes to the lightweight nature of the pipeline, making it five times computationally efficient compared to having five individual models corresponding to each disease.",
      "authors": [
        "Ananya Raghu",
        "Anisha Raghu",
        "Alice S. Tang",
        "Yannis M. Paulus",
        "Tyson N. Kim",
        "Tomiko T. Oskotsky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:00:10+00:00",
          "link": "https://arxiv.org/abs/2507.12669v1",
          "size": "1385kb",
          "version": "v1"
        }
      ],
      "title": "InSight: AI Mobile Screening Tool for Multiple Eye Disease Detection using Multimodal Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12669",
        "PDF": "https://arxiv.org/pdf/2507.12669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AI tool for eye disease detection using multimodal fusion but does not address LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12686",
      "abstract": "We study the Finite-Dimensional Distributions (FDDs) of deep neural networks with randomly initialized weights that have finite-order moments. Specifically, we establish Gaussian approximation bounds in the Wasserstein-$1$ norm between the FDDs and their Gaussian limit assuming a Lipschitz activation function and allowing the layer widths to grow to infinity at arbitrary relative rates. In the special case where all widths are proportional to a common scale parameter $n$ and there are $L-1$ hidden layers, we obtain convergence rates of order $n^{-({1}/{6})^{L-1} + \\epsilon}$, for any $\\epsilon > 0$.",
      "authors": [
        "Krishnakumar Balasubramanian",
        "Nathan Ross"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:41:09+00:00",
          "link": "https://arxiv.org/abs/2507.12686v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Finite-Dimensional Gaussian Approximation for Deep Neural Networks: Universality in Random Weights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12686",
        "HTML": "https://arxiv.org/html/2507.12686v1",
        "PDF": "https://arxiv.org/pdf/2507.12686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses theoretical aspects of neural networks with random weights but does not address LLM training data processing or improvements in data quality related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12687",
      "abstract": "Image Quality Assessment (IQA) models aim to predict perceptual image quality in alignment with human judgments. No-Reference (NR) IQA remains particularly challenging due to the absence of a reference image. While deep learning has significantly advanced this field, a major hurdle in developing NR-IQA models is the limited availability of subjectively labeled data. Most existing deep learning-based NR-IQA approaches rely on pre-training on large-scale datasets before fine-tuning for IQA tasks. To further advance progress in this area, we propose a novel approach that constructs a custom dataset using a limited number of reference content images and introduces a no-reference IQA model that incorporates both content and quality features for perceptual quality prediction. Specifically, we train a quality-aware model using contrastive triplet-based learning, enabling efficient training with fewer samples while achieving strong generalization performance across publicly available datasets. Our repository is available at https://github.com/rajeshsureddi/triqa.",
      "authors": [
        "Rajesh Sureddi",
        "Saman Zadtootaghaj",
        "Nabajeet Barman",
        "Alan C. Bovik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T23:43:12+00:00",
          "link": "https://arxiv.org/abs/2507.12687v1",
          "size": "4826kb",
          "version": "v1"
        }
      ],
      "title": "TRIQA: Image Quality Assessment by Contrastive Pretraining on Ordered Distortion Triplets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12687",
        "HTML": "https://arxiv.org/html/2507.12687v1",
        "PDF": "https://arxiv.org/pdf/2507.12687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on image quality assessment using contrastive learning techniques, which is not related to LLM training data processing, as it deals with perceptual image quality prediction rather than text data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12698",
      "abstract": "Medical image synthesis presents unique challenges due to the inherent complexity and high-resolution details required in clinical contexts. Traditional generative architectures such as Generative Adversarial Networks (GANs) or Variational Auto Encoder (VAEs) have shown great promise for high-resolution image generation but struggle with preserving fine-grained details that are key for accurate diagnosis. To address this issue, we introduce Pixel Perfect MegaMed, the first vision-language foundation model to synthesize images at resolutions of 1024x1024. Our method deploys a multi-scale transformer architecture designed specifically for ultra-high resolution medical image generation, enabling the preservation of both global anatomical context and local image-level details. By leveraging vision-language alignment techniques tailored to medical terminology and imaging modalities, Pixel Perfect MegaMed bridges the gap between textual descriptions and visual representations at unprecedented resolution levels. We apply our model to the CheXpert dataset and demonstrate its ability to generate clinically faithful chest X-rays from text prompts. Beyond visual quality, these high-resolution synthetic images prove valuable for downstream tasks such as classification, showing measurable performance gains when used for data augmentation, particularly in low-data regimes. Our code is accessible through the project website - https://tehraninasab.github.io/pixelperfect-megamed.",
      "authors": [
        "Zahra TehraniNasab",
        "Amar Kumar",
        "Tal Arbel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T00:17:50+00:00",
          "link": "https://arxiv.org/abs/2507.12698v1",
          "size": "8702kb",
          "version": "v1"
        }
      ],
      "title": "Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12698",
        "HTML": "https://arxiv.org/html/2507.12698v1",
        "PDF": "https://arxiv.org/pdf/2507.12698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a vision-language model for generating high-resolution medical images and does not contribute to LLM training data processing, as it is not focused on text data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12718",
      "abstract": "This paper presents a novel approach for computing enlarged Region of Attractions (ROA) for nonlinear dynamical systems through the integration of multiple coordinate transformations and piecewise quadratic Lyapunov functions within the Takagi-Sugeno (TS) modeling framework. While existing methods typically follow a single-path approach of original system $\\rightarrow$ TS model $\\rightarrow$ ROA computation, the proposed methodology systematically applies a sequence of coordinate transformations to generate multiple system representations, each yielding distinct ROA estimations. Specifically, the approach transforms the original nonlinear system using transformation matrices $T_1, T_2, \\ldots, T_N$ to obtain $N$ different coordinate representations, constructs corresponding TS models for each transformed system, and computes individual ROAs using piecewise quadratic Lyapunov functions. The final ROA estimate is obtained as the union of all computed regions, leveraging the flexibility inherent in piecewise quadratic Lyapunov functions compared to traditional quadratic approaches. The enhanced methodology demonstrates significant improvements in ROA size estimation compared to conventional single-transformation techniques, as evidenced through comparative analysis with existing TS-based stability methods.",
      "authors": [
        "Artun Sel and Mehmet Koruturk and Erdi Sayar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T01:51:39+00:00",
          "link": "https://arxiv.org/abs/2507.12718v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Estimation of Regions of Attraction for Nonlinear Systems via Coordinate-Transformed TS Models and Piecewise Quadratic Lyapunov Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12718",
        "HTML": "https://arxiv.org/html/2507.12718v1",
        "PDF": "https://arxiv.org/pdf/2507.12718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a methodology for estimating regions of attraction for nonlinear systems using coordinate-transformed models. It does not involve LLM training data processing or relevant dataset operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12729",
      "abstract": "The $\\star_M$-family of tensor-tensor products is a framework which generalizes many properties from linear algebra to third order tensors. Here, we investigate positive semidefiniteness and semidefinite programming under the $\\star_M$-product. Critical to our investigation is a connection between the choice of matrix M in the $\\star_M$-product and the representation theory of an underlying group action. Using this framework, third order tensors equipped with the $\\star_M$-product are a natural setting for the study of invariant semidefinite programs. As applications of the M-SDP framework, we provide a characterization of certain nonnegative quadratic forms and solve low-rank tensor completion problems.",
      "authors": [
        "Alex Dunbar and Elizabeth Newman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Representation Theory (math.RT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T02:08:14+00:00",
          "link": "https://arxiv.org/abs/2507.12729v1",
          "size": "8941kb",
          "version": "v1"
        }
      ],
      "title": "Tensor-Tensor Products, Group Representations, and Semidefinite Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12729",
        "HTML": "https://arxiv.org/html/2507.12729v1",
        "PDF": "https://arxiv.org/pdf/2507.12729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores advanced mathematical frameworks related to tensor products and semidefinite programming. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12765",
      "abstract": "Improving quantum algorithms run-time performance involves several strategies such as reducing the quantum gate counts, decreasing the number of measurements, advancement in QPU technology for faster gate operations, or optimizing the classical processing. This work focuses on the latter, specifically reducing classical processing and compilation time via hardware-assisted parameterized circuit execution (PCE) for computing dynamical properties of quantum systems. PCE was previously validated for QCVV protocols, which leverages structural circuit equivalencies. We demonstrate the applicability of this approach to computing dynamical properties of quantum many-body systems using structurally equivalent time evolution circuits, specifically calculating correlation functions of spin models using constant-depth circuits generated via Cartan decomposition. Implementing this for spin-spin correlation functions in Transverse field XY (up to 6-sites) and Heisenberg spin models (up to 3-sites), we observed a run-time reduction of up to 50\\% compared to standard compilation methods. This highlights the adaptability of time-evolution circuit with hardware-assisted PCE to potentially mitigate the classical bottlenecks in near-term quantum algorithms.",
      "authors": [
        "Akhil Francis",
        "Abhi D. Rajagopala",
        "Norm M. Tubman",
        "Katherine Klymko",
        "and Kasra Nowrouzi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T03:40:08+00:00",
          "link": "https://arxiv.org/abs/2507.12765v1",
          "size": "133kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Classical-Processing of Constant-Depth Time Evolution Circuits in Control Hardware",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12765",
        "HTML": "https://arxiv.org/html/2507.12765v1",
        "PDF": "https://arxiv.org/pdf/2507.12765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research relates to quantum computing optimizations and does not address any issues related to LLM training data processing, like data collection or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12784",
      "abstract": "As the data volume of astronomical imaging surveys rapidly increases, traditional methods for image anomaly detection, such as visual inspection by human experts, are becoming impractical. We introduce a machine-learning-based approach to detect poor-quality exposures in large imaging surveys, with a focus on the DECam Legacy Survey (DECaLS) in regions of low extinction (i.e., $E(B-V)<0.04$). Our semi-supervised pipeline integrates a vision transformer (ViT), trained via self-supervised learning (SSL), with a k-Nearest Neighbor (kNN) classifier. We train and validate our pipeline using a small set of labeled exposures observed by surveys with the Dark Energy Camera (DECam). A clustering-space analysis of where our pipeline places images labeled in ``good'' and ``bad'' categories suggests that our approach can efficiently and accurately determine the quality of exposures. Applied to new imaging being reduced for DECaLS Data Release 11, our pipeline identifies 780 problematic exposures, which we subsequently verify through visual inspection. Being highly efficient and adaptable, our method offers a scalable solution for quality control in other large imaging surveys.",
      "authors": [
        "Yufeng Luo",
        "Adam D. Myers",
        "Alex Drlica-Wagner",
        "Dario Dematties",
        "Salma Borchani",
        "Frank Valdes",
        "Arjun Dey",
        "David Schlegel",
        "Rongpu Zhou",
        "and DESI Legacy Imaging Surveys Team"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T04:52:05+00:00",
          "link": "https://arxiv.org/abs/2507.12784v1",
          "size": "38183kb",
          "version": "v1"
        }
      ],
      "title": "A Semi-Supervised Learning Method for the Identification of Bad Exposures in Large Imaging Surveys",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12784",
        "HTML": "https://arxiv.org/html/2507.12784v1",
        "PDF": "https://arxiv.org/pdf/2507.12784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper covers a machine-learning method for detecting bad exposures in imaging surveys, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12818",
      "abstract": "In observational studies, confounding variables affect both treatment and outcome. Moreover, instrumental variables also influence the treatment assignment mechanism. This situation sets the study apart from a standard randomized controlled trial, where the treatment assignment is random. Due to this situation, the estimated average treatment effect becomes biased. To address this issue, a standard approach is to incorporate the estimated propensity score when estimating the average treatment effect. However, these methods incur the risk of misspecification in propensity score models. To solve this issue, a novel method called the \"Self balancing neural network\" (Sbnet), which lets the model itself obtain its pseudo propensity score from the balancing net, is proposed in this study. The proposed method estimates the average treatment effect by using the balancing net as a key part of the feedforward neural network. This formulation resolves the estimation of the average treatment effect in one step. Moreover, the multi-pseudo propensity score framework, which is estimated from the diversified balancing net and used for the estimation of the average treatment effect, is presented. Finally, the proposed methods are compared with state-of-the-art methods on three simulation setups and real-world datasets. It has been shown that the proposed self-balancing neural network shows better performance than state-of-the-art methods.",
      "authors": [
        "Atomsa Gemechu Abdisa",
        "Yingchun Zhou and Yuqi Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:22:17+00:00",
          "link": "https://arxiv.org/abs/2507.12818v1",
          "size": "2559kb",
          "version": "v1"
        }
      ],
      "title": "Self Balancing Neural Network: A Novel Method to Estimate Average Treatment Effect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12818",
        "HTML": "https://arxiv.org/html/2507.12818v1",
        "PDF": "https://arxiv.org/pdf/2507.12818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel method for estimating the average treatment effect in observational studies using self-balancing neural networks. It does not relate to LLM training data processing or dataset creation for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12831",
      "abstract": "We consider the multilinear polytope defined as the convex hull of the feasible region of a linearized binary polynomial optimization problem. We define a relaxation in an extended space for this polytope, which we refer to as the complete edge relaxation. The complete edge relaxation is stronger than several well-known relaxations of the multilinear polytope, including the standard linearization, the flower relaxation, and the intersection of all possible recursive McCormick relaxations. We prove that the complete edge relaxation is an extension of the multilinear polytope if and only if the corresponding hypergraph is alpha-acyclic; i.e., the most general type of hypergraph acyclicity. This is in stark contrast with the widely-used standard linearization which describes the multilinear polytope if and only if the hypergraph is Berge-acyclic; i.e., the most restrictive type of hypergraph acyclicity. We then introduce a new class of facet-defining inequalities for the multilinear polytope of alpha-cycles of length three, which serve as the generalization of the well-known triangle inequalities for the Boolean quadric polytope.",
      "authors": [
        "Alberto Del Pia and Aida Khajavirad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T06:45:14+00:00",
          "link": "https://arxiv.org/abs/2507.12831v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "The complete edge relaxation for binary polynomial optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12831",
        "HTML": "https://arxiv.org/html/2507.12831v1",
        "PDF": "https://arxiv.org/pdf/2507.12831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on binary polynomial optimization and introduces a complete edge relaxation technique. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12878",
      "abstract": "The identification of Linear Time-Variant (LTV) systems from input-output data is a fundamental yet challenging ill-posed inverse problem. This work introduces a unified Bayesian framework that models the system's impulse response, $h(t, \\tau)$, as a stochastic process. We decompose the response into a posterior mean and a random fluctuation term, a formulation that provides a principled approach for quantifying uncertainty and naturally defines a new, useful system class we term Linear Time-Invariant in Expectation (LTIE). To perform inference, we leverage modern machine learning techniques, including Bayesian neural networks and Gaussian Processes, using scalable variational inference. We demonstrate through a series of experiments that our framework can robustly infer the properties of an LTI system from a single noisy observation, show superior data efficiency compared to classical methods in a simulated ambient noise tomography problem, and successfully track a continuously varying LTV impulse response by using a structured Gaussian Process prior. This work provides a flexible and robust methodology for uncertainty-aware system identification in dynamic environments.",
      "authors": [
        "Yaniv Shulman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T07:55:34+00:00",
          "link": "https://arxiv.org/abs/2507.12878v1",
          "size": "4030kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Modeling and Estimation of Linear Time-Variant Systems using Neural Networks and Gaussian Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12878",
        "HTML": "https://arxiv.org/html/2507.12878v1",
        "PDF": "https://arxiv.org/pdf/2507.12878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with Bayesian modeling and system identification of linear time-variant systems. It focuses on uncertainty quantification and system inference, not on LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12890",
      "abstract": "Songs, as a central form of musical art, exemplify the richness of human intelligence and creativity. While recent advances in generative modeling have enabled notable progress in long-form song generation, current systems for full-length song synthesis still face major challenges, including data imbalance, insufficient controllability, and inconsistent musical quality. DiffRhythm, a pioneering diffusion-based model, advanced the field by generating full-length songs with expressive vocals and accompaniment. However, its performance was constrained by an unbalanced model training dataset and limited controllability over musical style, resulting in noticeable quality disparities and restricted creative flexibility. To address these limitations, we propose DiffRhythm+, an enhanced diffusion-based framework for controllable and flexible full-length song generation. DiffRhythm+ leverages a substantially expanded and balanced training dataset to mitigate issues such as repetition and omission of lyrics, while also fostering the emergence of richer musical skills and expressiveness. The framework introduces a multi-modal style conditioning strategy, enabling users to precisely specify musical styles through both descriptive text and reference audio, thereby significantly enhancing creative control and diversity. We further introduce direct performance optimization aligned with user preferences, guiding the model toward consistently preferred outputs across evaluation metrics. Extensive experiments demonstrate that DiffRhythm+ achieves significant improvements in naturalness, arrangement complexity, and listener satisfaction over previous systems.",
      "authors": [
        "Huakang Chen",
        "Yuepeng Jiang",
        "Guobin Ma",
        "Chunbo Hao",
        "Shuai Wang",
        "Jixun Yao",
        "Ziqian Ning",
        "Meng Meng",
        "Jian Luan",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T08:18:55+00:00",
          "link": "https://arxiv.org/abs/2507.12890v1",
          "size": "219kb",
          "version": "v1"
        }
      ],
      "title": "DiffRhythm+: Controllable and Flexible Full-Length Song Generation with Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12890",
        "HTML": "https://arxiv.org/html/2507.12890v1",
        "PDF": "https://arxiv.org/pdf/2507.12890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for song generation, focusing on issues like data imbalance in musical datasets and enhancing creative controllability, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12938",
      "abstract": "Accurate coronary artery segmentation is critical for computeraided diagnosis of coronary artery disease (CAD), yet it remains challenging due to the small size, complex morphology, and low contrast with surrounding tissues. To address these challenges, we propose a novel segmentation framework that leverages the power of vision foundation models (VFMs) through a parallel encoding architecture. Specifically, a vision transformer (ViT) encoder within the VFM captures global structural features, enhanced by the activation of the final two ViT blocks and the integration of an attention-guided enhancement (AGE) module, while a convolutional neural network (CNN) encoder extracts local details. These complementary features are adaptively fused using a cross-branch variational fusion (CVF) module, which models latent distributions and applies variational attention to assign modality-specific weights. Additionally, we introduce an evidential-learning uncertainty refinement (EUR) module, which quantifies uncertainty using evidence theory and refines uncertain regions by incorporating multi-scale feature aggregation and attention mechanisms, further enhancing segmentation accuracy. Extensive evaluations on one in-house and two public datasets demonstrate that the proposed framework significantly outperforms state-of-the-art methods, achieving superior performance in accurate coronary artery segmentation and showcasing strong generalization across multiple datasets. The code is available at https://github.com/d1c2x3/CAseg.",
      "authors": [
        "Caixia Dong",
        "Duwei Dai",
        "Xinyi Han",
        "Fan Liu",
        "Xu Yang",
        "Zongfang Li",
        "Songhua Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:25:00+00:00",
          "link": "https://arxiv.org/abs/2507.12938v1",
          "size": "1782kb",
          "version": "v1"
        }
      ],
      "title": "Unleashing Vision Foundation Models for Coronary Artery Segmentation: Parallel ViT-CNN Encoding and Variational Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12938",
        "HTML": "https://arxiv.org/html/2507.12938v1",
        "PDF": "https://arxiv.org/pdf/2507.12938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on coronary artery segmentation using vision foundation models and innovative feature fusion techniques, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12951",
      "abstract": "Spoken Language Understanding (SLU) plays a crucial role in speech-centric multimedia applications, enabling machines to comprehend spoken language in scenarios such as meetings, interviews, and customer service interactions. SLU encompasses multiple tasks, including Automatic Speech Recognition (ASR), spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA). However, existing methods often rely on separate model architectures for individual tasks such as spoken NER and SA, which increases system complexity, limits cross-task interaction, and fails to fully exploit heterogeneous datasets available across tasks. To address these limitations, we propose UniSLU, a unified framework that jointly models multiple SLU tasks within a single architecture. Specifically, we propose a unified representation for diverse SLU tasks, enabling full utilization of heterogeneous datasets across multiple tasks. Built upon this representation, we propose a unified generative method that jointly models ASR, spoken NER, and SA tasks, enhancing task interactions and enabling seamless integration with large language models to harness their powerful generative capabilities. Extensive experiments on public SLU datasets demonstrate the effectiveness of our approach, achieving superior SLU performance compared to several benchmark methods, making it well-suited for real-world speech-based multimedia scenarios. We will release all code and models at github to facilitate future research.",
      "authors": [
        "Zhichao Sheng",
        "Shilin Zhou",
        "Chen Gong and Zhenghua Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T09:45:49+00:00",
          "link": "https://arxiv.org/abs/2507.12951v1",
          "size": "2507kb",
          "version": "v1"
        }
      ],
      "title": "UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12951",
        "HTML": "https://arxiv.org/html/2507.12951v1",
        "PDF": "https://arxiv.org/pdf/2507.12951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a unified framework for SLU tasks leveraging heterogeneous datasets, the main focus is on task modeling within SLU rather than LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12961",
      "abstract": "Pigmented skin lesions represent localized areas of increased melanin and can indicate serious conditions like melanoma, a major contributor to skin cancer mortality. The MedMNIST v2 dataset, inspired by MNIST, was recently introduced to advance research in biomedical imaging and includes DermaMNIST, a dataset for classifying pigmented lesions based on the HAM10000 dataset. This study assesses ResNet-50 and EfficientNetV2L models for multi-class classification using DermaMNIST, employing transfer learning and various layer configurations. One configuration achieves results that match or surpass existing methods. This study suggests that convolutional neural networks (CNNs) can drive progress in biomedical image analysis, significantly enhancing diagnostic accuracy.",
      "authors": [
        "Nerma Kadric and Amila Akagic and Medina Kapo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:00:07+00:00",
          "link": "https://arxiv.org/abs/2507.12961v1",
          "size": "1490kb",
          "version": "v1"
        }
      ],
      "title": "Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12961",
        "HTML": "https://arxiv.org/html/2507.12961v1",
        "PDF": "https://arxiv.org/pdf/2507.12961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates CNNs on a medical image dataset for skin lesion classification, not involving any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12966",
      "abstract": "Emerging in December 2019, the COVID-19 pandemic caused widespread health, economic, and social disruptions. Rapid global transmission overwhelmed healthcare systems, resulting in high infection rates, hospitalisations, and fatalities. To minimise the spread, governments implemented several non-pharmaceutical interventions like lockdowns and travel restrictions. While effective in controlling transmission, these measures also posed significant economic and societal challenges. Although the WHO declared COVID-19 no longer a global health emergency in May 2023, its impact persists, shaping public health strategies. The vast amount of data collected during the pandemic offers valuable insights into disease dynamics, transmission, and intervention effectiveness. Leveraging these insights can improve forecasting models, enhancing preparedness and response to future outbreaks while mitigating their social and economic impact. This paper presents a large-scale case study on COVID-19 forecasting in Cyprus, utilising a two-year dataset that integrates epidemiological data, vaccination records, policy measures, and weather conditions. We analyse infection trends, assess forecasting performance, and examine the influence of external factors on disease dynamics. The insights gained contribute to improved pandemic preparedness and response strategies.",
      "authors": [
        "Zacharias Komodromos",
        "Kleanthis Malialis",
        "Panayiotis Kolios"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:06:43+00:00",
          "link": "https://arxiv.org/abs/2507.12966v1",
          "size": "2114kb",
          "version": "v1"
        }
      ],
      "title": "Investigating Forecasting Models for Pandemic Infections Using Heterogeneous Data Sources: A 2-year Study with COVID-19",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12966",
        "HTML": "https://arxiv.org/html/2507.12966v1",
        "PDF": "https://arxiv.org/pdf/2507.12966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on forecasting models for pandemic infections using COVID-19 data. It does not address LLM training data processing or any related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12972",
      "abstract": "Separating target speech from mixed signals containing flexible speaker quantities presents a challenging task. While existing methods demonstrate strong separation performance and noise robustness, they predominantly assume prior knowledge of speaker counts in mixtures. The limited research addressing unknown speaker quantity scenarios exhibits significantly constrained generalization capabilities in real acoustic environments. To overcome these challenges, this paper proposes AVFSNet -- an audio-visual speech separation model integrating multi-scale encoding and parallel architecture -- jointly optimized for speaker counting and multi-speaker separation tasks. The model independently separates each speaker in parallel while enhancing environmental noise adaptability through visual information integration. Comprehensive experimental evaluations demonstrate that AVFSNet achieves state-of-the-art results across multiple evaluation metrics and delivers outstanding performance on diverse datasets.",
      "authors": [
        "Daning Zhang and Ying Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:19:00+00:00",
          "link": "https://arxiv.org/abs/2507.12972v1",
          "size": "1892kb",
          "version": "v1"
        }
      ],
      "title": "AVFSNet: Audio-Visual Speech Separation for Flexible Number of Speakers with Multi-Scale and Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12972",
        "HTML": "https://arxiv.org/html/2507.12972v1",
        "PDF": "https://arxiv.org/pdf/2507.12972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents an audio-visual speech separation model, which does not contribute to LLM training data processing. The focus is on speech processing rather than text data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12985",
      "abstract": "Accurate segmentation of orbital bones in facial computed tomography (CT) images is essential for the creation of customized implants for reconstruction of defected orbital bones, particularly challenging due to the ambiguous boundaries and thin structures such as the orbital medial wall and orbital floor. In these ambiguous regions, existing segmentation approaches often output disconnected or under-segmented results. We propose a novel framework that corrects segmentation results by leveraging consensus from multiple diffusion model outputs. Our approach employs a conditional Bernoulli diffusion model trained on diverse annotation patterns per image to generate multiple plausible segmentations, followed by a consensus-driven correction that incorporates position proximity, consensus level, and gradient direction similarity to correct challenging regions. Experimental results demonstrate that our method outperforms existing methods, significantly improving recall in ambiguous regions while preserving the continuity of thin structures. Furthermore, our method automates the manual process of segmentation result correction and can be applied to image-guided surgical planning and surgery.",
      "authors": [
        "Jinseo An",
        "Min Jin Lee",
        "Kyu Won Shim",
        "Helen Hong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T10:44:06+00:00",
          "link": "https://arxiv.org/abs/2507.12985v1",
          "size": "1640kb",
          "version": "v1"
        }
      ],
      "title": "From Variability To Accuracy: Conditional Bernoulli Diffusion Models with Consensus-Driven Correction for Thin Structure Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12985",
        "HTML": "https://arxiv.org/html/2507.12985v1",
        "PDF": "https://arxiv.org/pdf/2507.12985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on image segmentation techniques using conditional Bernoulli diffusion models for medical imaging. It does not relate to LLM training data processing or any relevant data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13017",
      "abstract": "The precise insertion of CubeSats into designated orbits is a complex task, primarily due to the limited propulsion capabilities and constrained fuel reserves onboard, which severely restrict the scope for large orbital corrections. This limitation necessitates the development of more efficient maneuvering techniques to ensure mission success. In this paper, we propose a maneuvering sequence that exploits the natural J2 perturbation caused by the Earth's oblateness. By utilizing the secular effects of this perturbation, it is possible to passively influence key orbital parameters such as the argument of perigee and the right ascension of the ascending node, thereby reducing the need for extensive propulsion-based corrections. The approach is designed to optimize the CubeSat's orbital insertion and minimize the total fuel required for trajectory adjustments, making it particularly suitable for fuel-constrained missions. The proposed methodology is validated through comprehensive numerical simulations that examine different initial orbital conditions and perturbation environments. Case studies are presented to demonstrate the effectiveness of the J2-augmented strategy in achieving accurate orbital insertion, showing a major reduction in fuel consumption compared to traditional methods. The results underscore the potential of this approach to extend the operational life and capabilities of CubeSats, offering a viable solution for future low-Earth orbit missions.",
      "authors": [
        "M. Amin Alandihallaj",
        "M. Reza Emami"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Earth and Planetary Astrophysics (astro-ph.EP)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:45:09+00:00",
          "link": "https://arxiv.org/abs/2507.13017v1",
          "size": "954kb",
          "version": "v1"
        }
      ],
      "title": "CubeSat Orbit Insertion Maneuvering Using J2 Perturbation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13017",
        "PDF": "https://arxiv.org/pdf/2507.13017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a method for optimizing CubeSat orbital maneuvers using J2 perturbation, which is unrelated to the topic of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13024",
      "abstract": "Predicting a response with partially missing inputs remains a challenging task even in parametric models, since parameter estimation in itself is not sufficient to predict on partially observed inputs. Several works study prediction in linear models. In this paper, we focus on logistic models, which present their own difficulties. From a theoretical perspective, we prove that a Pattern-by-Pattern strategy (PbP), which learns one logistic model per missingness pattern, accurately approximates Bayes probabilities in various missing data scenarios (MCAR, MAR and MNAR). Empirically, we thoroughly compare various methods (constant and iterative imputations, complete case analysis, PbP, and an EM algorithm) across classification, probability estimation, calibration, and parameter inference. Our analysis provides a comprehensive view on the logistic regression with missing values. It reveals that mean imputation can be used as baseline for low sample sizes, and improved performance is obtained via nonlinear multiple iterative imputation techniques with the labels (MICE.RF.Y). For large sample sizes, PbP is the best method for Gaussian mixtures, and we recommend MICE.RF.Y in presence of nonlinear features.",
      "authors": [
        "Christophe Muller (PREMEDICAL)",
        "Erwan Scornet (LPSM)",
        "Julie Josse (PREMEDICAL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T11:52:27+00:00",
          "link": "https://arxiv.org/abs/2507.13024v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "When Pattern-by-Pattern Works: Theoretical and Empirical Insights for Logistic Models with Missing Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13024",
        "PDF": "https://arxiv.org/pdf/2507.13024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores logistic models with missing values, focusing on prediction and parameter estimation in scenarios with missing data, without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13033",
      "abstract": "Symbolic regression is the machine learning method for learning functions from data. After a brief overview of the symbolic regression landscape, I will describe the two main challenges that traditional algorithms face: they have an unknown (and likely significant) probability of failing to find any given good function, and they suffer from ambiguity and poorly-justified assumptions in their function-selection procedure. To address these I propose an exhaustive search and model selection by the minimum description length principle, which allows accuracy and complexity to be directly traded off by measuring each in units of information. I showcase the resulting publicly available Exhaustive Symbolic Regression algorithm on three open problems in astrophysics: the expansion history of the universe, the effective behaviour of gravity in galaxies and the potential of the inflaton field. In each case the algorithm identifies many functions superior to the literature standards. This general purpose methodology should find widespread utility in science and beyond.",
      "authors": [
        "Harry Desmond"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Astrophysics of Galaxies (astro-ph.GA)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T12:04:15+00:00",
          "link": "https://arxiv.org/abs/2507.13033v1",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "title": "(Exhaustive) Symbolic Regression and model selection by minimum description length",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13033",
        "HTML": "https://arxiv.org/html/2507.13033v1",
        "PDF": "https://arxiv.org/pdf/2507.13033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with symbolic regression and model selection techniques, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13094",
      "abstract": "Data classification without access to labeled samples remains a challenging problem. It usually depends on an appropriately chosen distance between features, a topic addressed in metric learning. Recently, Huizing, Cantini and Peyr\\'e proposed to simultaneously learn optimal transport (OT) cost matrices between samples and features of the dataset. This leads to the task of finding positive eigenvectors of a certain nonlinear function that maps cost matrices to OT distances. Having this basic idea in mind, we consider both the algorithmic and the modeling part of unsupervised metric learning. First, we examine appropriate algorithms and their convergence. In particular, we propose to use the stochastic random function iteration algorithm and prove that it converges linearly for our setting, although our operators are not paracontractive as it was required for convergence so far. Second, we ask the natural question if the OT distance can be replaced by other distances. We show how Mahalanobis-like distances fit into our considerations. Further, we examine an approach via graph Laplacians. In contrast to the previous settings, we have just to deal with linear functions in the wanted matrices here, so that simple algorithms from linear algebra can be applied.",
      "authors": [
        "Janis Auffenberg",
        "Jonas Bresch",
        "Oleh Melnyk",
        "Gabriele Steidl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:06:24+00:00",
          "link": "https://arxiv.org/abs/2507.13094v1",
          "size": "1928kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Ground Metric Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13094",
        "HTML": "https://arxiv.org/html/2507.13094v1",
        "PDF": "https://arxiv.org/pdf/2507.13094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses unsupervised ground metric learning for data classification, focusing on metric learning and optimal transport. It does not address LLM training data processing or any related methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13122",
      "abstract": "We use machine learning to search for examples of Z/2 eigenfunctions on the 2-sphere. For this we created a multivalued version of a feedforward deep neural network, and we implemented it using the JAX library. We found Z/2 eigenfunctions for three cases: In the first two cases we fixed the branch points at the vertices of a tetrahedron and at a cube respectively. In a third case, we allowed the AI to move the branch points around and, in the end, it positioned the branch points at the vertices of a squashed tetrahedron.",
      "authors": [
        "Andriy Haydys",
        "Willem Adriaan Salm"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T13:38:02+00:00",
          "link": "https://arxiv.org/abs/2507.13122v1",
          "size": "2717kb",
          "version": "v1"
        }
      ],
      "title": "Search for Z/2 eigenfunctions on the sphere using machine learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13122",
        "HTML": "https://arxiv.org/html/2507.13122v1",
        "PDF": "https://arxiv.org/pdf/2507.13122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the use of machine learning to find Z/2 eigenfunctions on the sphere, which is unrelated to any aspect of LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13146",
      "abstract": "Healthy tissue inpainting has significant applications, including the generation of pseudo-healthy baselines for tumor growth models and the facilitation of image registration. In previous editions of the BraTS Local Synthesis of Healthy Brain Tissue via Inpainting Challenge, denoising diffusion probabilistic models (DDPMs) demonstrated qualitatively convincing results but suffered from low sampling speed. To mitigate this limitation, we adapted a 2D image generation approach, combining DDPMs with generative adversarial networks (GANs) and employing a variance-preserving noise schedule, for the task of 3D inpainting. Our experiments showed that the variance-preserving noise schedule and the selected reconstruction losses can be effectively utilized for high-quality 3D inpainting in a few time steps without requiring adversarial training. We applied our findings to a different architecture, a 3D wavelet diffusion model (WDM3D) that does not include a GAN component. The resulting model, denoted as fastWDM3D, obtained a SSIM of 0.8571, a MSE of 0.0079, and a PSNR of 22.26 on the BraTS inpainting test set. Remarkably, it achieved these scores using only two time steps, completing the 3D inpainting process in 1.81 s per image. When compared to other DDPMs used for healthy brain tissue inpainting, our model is up to 800 x faster while still achieving superior performance metrics. Our proposed method, fastWDM3D, represents a promising approach for fast and accurate healthy tissue inpainting. Our code is available at https://github.com/AliciaDurrer/fastWDM3D.",
      "authors": [
        "Alicia Durrer",
        "Florentin Bieder",
        "Paul Friedrich",
        "Bjoern Menze",
        "Philippe C. Cattin",
        "Florian Kofler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T14:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.13146v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "fastWDM3D: Fast and Accurate 3D Healthy Tissue Inpainting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13146",
        "HTML": "https://arxiv.org/html/2507.13146v1",
        "PDF": "https://arxiv.org/pdf/2507.13146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for fast and accurate 3D healthy tissue inpainting using DDPMs and GANs. It is unrelated to LLM training data processing or dataset creation for LLM purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13194",
      "abstract": "The Sliced Gromov-Wasserstein (SGW) distance, aiming to relieve the computational cost of solving a non-convex quadratic program that is the Gromov-Wasserstein distance, utilizes projecting directions sampled uniformly from unit hyperspheres. This slicing mechanism incurs unnecessary computational costs due to uninformative directions, which also affects the representative power of the distance. However, finding a more appropriate distribution over the projecting directions (slicing distribution) is often an optimization problem in itself that comes with its own computational cost. In addition, with more intricate distributions, the sampling itself may be expensive. As a remedy, we propose an optimization-free slicing distribution that provides fast sampling for the Monte Carlo approximation. We do so by introducing the Relation-Aware Projecting Direction (RAPD), effectively capturing the pairwise association of each of two pairs of random vectors, each following their ambient law. This enables us to derive the Relation-Aware Slicing Distribution (RASD), a location-scale law corresponding to sampled RAPDs. Finally, we introduce the RASGW distance and its variants, e.g., IWRASGW (Importance Weighted RASGW), which overcome the shortcomings experienced by SGW. We theoretically analyze its properties and substantiate its empirical prowess using extensive experiments on various alignment tasks.",
      "authors": [
        "Dhruv Sarkar",
        "Aprameyo Chakrabartty",
        "Anish Chakrabarty",
        "Swagatam Das"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:03:25+00:00",
          "link": "https://arxiv.org/abs/2507.13194v1",
          "size": "7964kb",
          "version": "v1"
        }
      ],
      "title": "Relation-Aware Slicing in Cross-Domain Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13194",
        "HTML": "https://arxiv.org/html/2507.13194v1",
        "PDF": "https://arxiv.org/pdf/2507.13194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computational geometry and optimization techniques for alignment tasks, specifically improving the efficiency of the Sliced Gromov-Wasserstein distance. It does not address any training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13203",
      "abstract": "We study a family of groups consisting of the simplest extensions of lamplighter groups. We use these groups to answer multiple open questions in combinatorial group theory, providing groups that exhibit various combinations of properties: 1) Decidable Subgroup Membership and undecidable Uniform Subgroup Membership Problem, 2) Rational volume growth series and undecidable Word Problem and 3) Recursive (even context-free) language of conjugacy geodesics, decidable Word Problem, and undecidable Conjugacy Problem. We also consider the co-Word Problem, residual finiteness and the Isomorphism Problem within this class.",
      "authors": [
        "Corentin Bodart"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Group Theory (math.GR)",
        "Discrete Mathematics (cs.DM)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:13:39+00:00",
          "link": "https://arxiv.org/abs/2507.13203v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "On finite extensions of lamplighter groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13203",
        "PDF": "https://arxiv.org/pdf/2507.13203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores combinatorial group theory and group properties of certain families of lamplighter groups. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13246",
      "abstract": "Computational screening has become a powerful complement to experimental efforts in the discovery of high-performance photovoltaic (PV) materials. Most workflows rely on density functional theory (DFT) to estimate electronic and optical properties relevant to solar energy conversion. Although more efficient than laboratory-based methods, DFT calculations still entail substantial computational and environmental costs. Machine learning (ML) models have recently gained attention as surrogates for DFT, offering drastic reductions in resource use with competitive predictive performance. In this study, we reproduce a canonical DFT-based workflow to estimate the maximum efficiency limit and progressively replace its components with ML surrogates. By quantifying the CO$_2$ emissions associated with each computational strategy, we evaluate the trade-offs between predictive efficacy and environmental cost. Our results reveal multiple hybrid ML/DFT strategies that optimize different points along the accuracy--emissions front. We find that direct prediction of scalar quantities, such as maximum efficiency, is significantly more tractable than using predicted absorption spectra as an intermediate step. Interestingly, ML models trained on DFT data can outperform DFT workflows using alternative exchange--correlation functionals in screening applications, highlighting the consistency and utility of data-driven approaches. We also assess strategies to improve ML-driven screening through expanded datasets and improved model architectures tailored to PV-relevant features. This work provides a quantitative framework for building low-emission, high-throughput discovery pipelines.",
      "authors": [
        "Matthew Walker",
        "Keith T. Butler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T15:55:02+00:00",
          "link": "https://arxiv.org/abs/2507.13246v1",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "title": "The carbon cost of materials discovery: Can machine learning really accelerate the discovery of new photovoltaics?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13246",
        "HTML": "https://arxiv.org/html/2507.13246v1",
        "PDF": "https://arxiv.org/pdf/2507.13246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with the use of machine learning to reduce computational costs in photovoltaic materials discovery, not with any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13253",
      "abstract": "There has been a long debate on how new levels of organization have evolved. It might seem unlikely, as cooperation must prevail over competition. One well-studied example is the emergence of autocatalytic sets, which seem to be a prerequisite for the evolution of life. Using a simple model, we investigate how varying bias toward cooperation versus antagonism shapes network dynamics, revealing that higher-order organization emerges even amid pervasive antagonistic interactions. In general, we observe that a quantitative increase in the number of elements in a system leads to a qualitative transition.\n  We present a random threshold-directed network model that integrates node-specific traits with dynamic edge formation and node removal, simulating arbitrary levels of cooperation and competition. In our framework, intrinsic node values determine directed links through various threshold rules. Our model generates a multi-digraph with signed edges (reflecting support/antagonism, labeled ``help''/``harm''), which ultimately yields two parallel yet interdependent threshold graphs. Incorporating temporal growth and node turnover in our approach allows exploration of the evolution, adaptation, and potential collapse of communities and reveals phase transitions in both connectivity and resilience.\n  Our findings extend classical random threshold and Erd\\H{o}s-R\\'enyi models, offering new insights into adaptive systems in biological and economic contexts, with emphasis on the application to Collective Affordance Sets. This framework should also be useful for making predictions that will be tested by ongoing experiments of microbial communities in soil.",
      "authors": [
        "Sean P. Maley",
        "Carlos Gershenson",
        "Stuart A. Kauffman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:01:00+00:00",
          "link": "https://arxiv.org/abs/2507.13253v1",
          "size": "1836kb",
          "version": "v1"
        }
      ],
      "title": "Life Finds A Way: Emergence of Cooperative Structures in Adaptive Threshold Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13253",
        "HTML": "https://arxiv.org/html/2507.13253v1",
        "PDF": "https://arxiv.org/pdf/2507.13253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is on the emergence of cooperative structures in adaptive networks, which does not pertain to LLM training data processing or improvement related methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13268",
      "abstract": "We introduce a partial decidability protocol for the Wang tiling problem (which is the prototype of undecidable problems in combinatorics and statistical physics) by constructing a suitable mapping from tilings of finite squares of different sizes. Such mapping depends on the initial family of Wang tiles (the alphabet) with which one would like to tile the plane. This allows to define effective entropy and temperature associated to the alphabet (together with the corresponding partition function). We identify a subclass of good alphabets by observing that when the entropy and temperature of a given alphabet are well-behaved in the thermodynamical sense then such alphabet can tile the infinite two-dimensional plane. Our proposal is tested successfully with the known available good alphabets (which produce periodic tilings, aperiodic but self-similar tilings as well as tilings which are neither periodic nor self-similar). Our analysis shows that the Kendall Tau coefficient is able to distinguish alphabets with a good thermodynamical behavior from alphabets with bad thermodynamical behavior. The transition from good to undecidable behavior is related to a transition from non-chaotic to chaotic regime in discrete dynamical systems of logistic type.",
      "authors": [
        "Fabrizio Canfora",
        "Marco Cedeno"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Information Theory (cs.IT)",
        "High Energy Physics - Theory (hep-th)",
        "Information Theory (math.IT)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:25:03+00:00",
          "link": "https://arxiv.org/abs/2507.13268v1",
          "size": "1642kb",
          "version": "v1"
        }
      ],
      "title": "Partial decidability protocol for the Wang tiling problem from statistical mechanics and chaotic mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13268",
        "PDF": "https://arxiv.org/pdf/2507.13268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a decidability protocol for the Wang tiling problem, which is unrelated to LLM training data processing or data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13283",
      "abstract": "An increasing number of studies have focused on stochastic first-order methods (SFOMs) under heavy-tailed gradient noises, which have been observed in the training of practical deep learning models. In this paper, we focus on two types of gradient noises: one is sub-Weibull noise, and the other is noise under the assumption that it has a bounded $p$-th central moment ($p$-BCM) with $p\\in (1, 2]$. The latter is more challenging due to the occurrence of infinite variance when $p\\in (1, 2)$. Under these two gradient noise assumptions, the in-expectation and high-probability convergence of SFOMs have been extensively studied in the contexts of convex optimization and standard smooth optimization. However, for weakly convex objectives-a class that includes all Lipschitz-continuous convex objectives and smooth objectives-our understanding of the in-expectation and high-probability convergence of SFOMs under these two types of noises remains incomplete. We investigate the high-probability convergence of the vanilla stochastic subgradient descent (SsGD) method under sub-Weibull noises, as well as the high-probability and in-expectation convergence of clipped SsGD under the $p$-BCM noises. Both analyses are conducted in the context of weakly convex optimization. For weakly convex objectives that may be non-convex and non-smooth, our results demonstrate that the theoretical dependence of vanilla SsGD on the failure probability and number of iterations under sub-Weibull noises does not degrade compared to the case of smooth objectives. Under $p$-BCM noises, our findings indicate that the non-smoothness and non-convexity of weakly convex objectives do not impact the theoretical dependence of clipped SGD on the failure probability relative to the smooth case; however, the sample complexity we derived is worse than a well-known lower bound for smooth optimization.",
      "authors": [
        "Tianxi Zhu",
        "Yi Xu",
        "Xiangyang Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:48:45+00:00",
          "link": "https://arxiv.org/abs/2507.13283v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Weakly Convex Optimization Under Heavy-Tailed Noises",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13283",
        "HTML": "https://arxiv.org/html/2507.13283v1",
        "PDF": "https://arxiv.org/pdf/2507.13283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with stochastic optimization techniques and their convergence properties under certain noise conditions, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13287",
      "abstract": "Temporal distribution shifts pose a key challenge for machine learning models trained and deployed in dynamically evolving environments. This paper introduces RIDER (RIsk minimization under Dynamically Evolving Regimes) which derives optimally-weighted empirical risk minimization procedures under temporal distribution shifts. Our approach is theoretically grounded in the random distribution shift model, where random shifts arise as a superposition of numerous unpredictable changes in the data-generating process. We show that common weighting schemes, such as pooling all data, exponentially weighting data, and using only the most recent data, emerge naturally as special cases in our framework. We demonstrate that RIDER consistently improves out-of-sample predictive performance when applied as a fine-tuning step on the Yearbook dataset, across a range of benchmark methods in Wild-Time. Moreover, we show that RIDER outperforms standard weighting strategies in two other real-world tasks: predicting stock market volatility and forecasting ride durations in NYC taxi data.",
      "authors": [
        "Yujin Jeong",
        "Ramesh Johari",
        "Dominik Rothenh\\\"ausler",
        "Emily Fox"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T16:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.13287v1",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Empirical Risk Minimization under Temporal Distribution Shifts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13287",
        "HTML": "https://arxiv.org/html/2507.13287v1",
        "PDF": "https://arxiv.org/pdf/2507.13287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper tackles empirical risk minimization in the context of temporal distribution shifts but does not relate to LLM training data processing. Its focus is on optimization techniques for predictive tasks, not on dataset creation or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13310",
      "abstract": "Social media is transforming various aspects of offline life, from everyday decisions such as dining choices to the progression of conflicts. In this study, we propose a coupled modelling framework with an online social network layer to analyse how engagement on a specific topic spills over into offline protest activities. We develop a stochastic model and derive several mean-field models of varying complexity. These models allow us to estimate the reproductive number and anticipate when surges in activity are likely to occur. A key factor is the transmission rate between the online and offline domains; for offline outbursts to emerge, this rate must fall within a critical range, neither too low nor too high. Additionally, using synthetic networks, we examine how network structure influences the accuracy of these approximations. Our findings indicate that low-density networks need more complex approximations, whereas simpler models can effectively represent higher-density networks. When tested on two real-world networks, however, increased complexity did not enhance accuracy.",
      "authors": [
        "Moyi Tian",
        "P. Jeffrey Brantingham",
        "Nancy Rodr\\'iguez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)",
        "Dynamical Systems (math.DS)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:30:13+00:00",
          "link": "https://arxiv.org/abs/2507.13310v1",
          "size": "9052kb",
          "version": "v1"
        }
      ],
      "title": "Modelling the spillover from online engagement to offline protest: stochastic dynamics and mean-field approximations on networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13310",
        "HTML": "https://arxiv.org/html/2507.13310v1",
        "PDF": "https://arxiv.org/pdf/2507.13310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for analyzing online engagement's spillover into offline protests, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13333",
      "abstract": "We describe and analyze a generalization of the classic ``Four Bugs on a Square'' cyclic pursuit problem. Instead of allowing the bugs to spiral towards one another, we constrain $N$ bugs to the perimeter of the unit circle. Depending on their configuration, each bug moves either clockwise or counterclockwise with a constant angular speed, or remains stationary. Unlike the original problem where bugs always coalesce, this generalization produces three possible steady states: all bugs coalescing to a single point, clusters of bugs located at two antipodal points, or bugs entering a stable infinite chase cycle where they never meet. We analyze the stability of these steady states and calculate the probability that randomly initialized bugs reach each state. For $N \\leq 4$, we derive exact analytical expressions for these probabilities. For larger values, we employ Monte Carlo simulations to estimate the probability of coalescing, finding it approximately follows an inverse square root relationship with the number of bugs. This generalization reveals rich dynamical behaviors that are absent in the classic problem. Our analysis provides insight into how restricting the bugs to the circle's perimeter fundamentally alters the long-term behavior of pursuing agents compared to unrestricted pursuit problems.",
      "authors": [
        "Josh Briley and Bryan Quaife"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:50:22+00:00",
          "link": "https://arxiv.org/abs/2507.13333v1",
          "size": "979kb",
          "version": "v1"
        }
      ],
      "title": "N Bugs on a Circle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13333",
        "HTML": "https://arxiv.org/html/2507.13333v1",
        "PDF": "https://arxiv.org/pdf/2507.13333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a mathematical analysis of a cyclic pursuit problem involving bugs on a circle. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.13339",
      "abstract": "High-spatial-resolution hyperspectral images (HSI) are essential for applications such as remote sensing and medical imaging, yet HSI sensors inherently trade spatial detail for spectral richness. Fusing high-spatial-resolution multispectral images (HR-MSI) with low-spatial-resolution hyperspectral images (LR-HSI) is a promising route to recover fine spatial structures without sacrificing spectral fidelity. Most state-of-the-art methods for HSI-MSI fusion demand point spread function (PSF) calibration or ground truth high resolution HSI (HR-HSI), both of which are impractical to obtain in real world settings. We present SpectraLift, a fully self-supervised framework that fuses LR-HSI and HR-MSI inputs using only the MSI's Spectral Response Function (SRF). SpectraLift trains a lightweight per-pixel multi-layer perceptron (MLP) network using ($i$)~a synthetic low-spatial-resolution multispectral image (LR-MSI) obtained by applying the SRF to the LR-HSI as input, ($ii$)~the LR-HSI as the output, and ($iii$)~an $\\ell_1$ spectral reconstruction loss between the estimated and true LR-HSI as the optimization objective. At inference, SpectraLift uses the trained network to map the HR-MSI pixel-wise into a HR-HSI estimate. SpectraLift converges in minutes, is agnostic to spatial blur and resolution, and outperforms state-of-the-art methods on PSNR, SAM, SSIM, and RMSE benchmarks.",
      "authors": [
        "Ritik Shah",
        "Marco F. Duarte"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-17T17:57:18+00:00",
          "link": "https://arxiv.org/abs/2507.13339v1",
          "size": "16338kb",
          "version": "v1"
        }
      ],
      "title": "SpectraLift: Physics-Guided Spectral-Inversion Network for Self-Supervised Hyperspectral Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.13339",
        "HTML": "https://arxiv.org/html/2507.13339v1",
        "PDF": "https://arxiv.org/pdf/2507.13339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for hyperspectral image super-resolution, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.00618",
      "abstract": "Compared to regular cameras, Dynamic Vision Sensors or Event Cameras can output compact visual data based on a change in the intensity in each pixel location asynchronously. In this paper, we study the application of current image-based SLAM techniques to these novel sensors. To this end, the information in adaptively selected event windows is processed to form motion-compensated images. These images are then used to reconstruct the scene and estimate the 6-DOF pose of the camera. We also propose an inertial version of the event-only pipeline to assess its capabilities. We compare the results of different configurations of the proposed algorithm against the ground truth for sequences of two publicly available event datasets. We also compare the results of the proposed event-inertial pipeline with the state-of-the-art and show it can produce comparable or more accurate results provided the map estimate is reliable.",
      "authors": [
        "Masoud Dayani Najafabadi and Mohammad Reza Ahmadzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-02T12:16:18+00:00",
          "link": "https://arxiv.org/abs/2301.00618v1",
          "size": "442kb",
          "version": "v1"
        },
        {
          "date": "2023-01-10T05:37:35+00:00",
          "link": "https://arxiv.org/abs/2301.00618v2",
          "size": "442kb",
          "version": "v2"
        },
        {
          "date": "2024-06-26T02:42:30+00:00",
          "link": "https://arxiv.org/abs/2301.00618v3",
          "size": "478kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T12:54:20+00:00",
          "link": "https://arxiv.org/abs/2301.00618v4",
          "size": "299kb",
          "version": "v4"
        }
      ],
      "title": "An Event-based Algorithm for Simultaneous 6-DOF Camera Pose Tracking and Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.00618",
        "HTML": "https://arxiv.org/html/2301.00618v4",
        "PDF": "https://arxiv.org/pdf/2301.00618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on 6-DOF camera pose tracking and mapping using Dynamic Vision Sensors. It does not address LLM training data processing or contribute to any related data engineering operations."
      },
      "tasks": [
        "Pose Tracking"
      ],
      "repo_urls": [
        "https://github.com/m-dayani/eorb_slam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2302.04810",
      "abstract": "Engineers are deploying ML models as parts of real-world systems with the upsurge of AI technologies. Real-world environments challenge the deployment of such systems because these environments produce large amounts of heterogeneous data, and users require increasingly efficient responses. These requirements push prevalent software architectures to the limit when deploying ML-based systems. Data-oriented Architecture (DOA) is an emerging style that equips systems better for integrating ML models. Even though papers on deployed ML systems do not mention DOA, their authors made design decisions that implicitly follow DOA. Implicit decisions create a knowledge gap, limiting the practitioners' ability to implement ML-based systems. \\hlb{This paper surveys why, how, and to what extent practitioners have adopted DOA to implement and deploy ML-based systems.} We overcome the knowledge gap by answering these questions and explicitly showing the design decisions and practices behind these systems. The survey follows a well-known systematic and semi-automated methodology for reviewing papers in software engineering. The majority of reviewed works partially adopt DOA. Such an adoption enables systems to address requirements such as Big Data management, low latency processing, resource management, security and privacy. Based on these findings, we formulate practical advice to facilitate the deployment of ML-based systems.",
      "authors": [
        "Christian Cabrera",
        "Andrei Paleyes",
        "Pierre Thodoroff",
        "Neil D. Lawrence"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-09T17:57:02+00:00",
          "link": "https://arxiv.org/abs/2302.04810v1",
          "size": "381kb",
          "version": "v1"
        },
        {
          "date": "2023-10-09T16:31:46+00:00",
          "link": "https://arxiv.org/abs/2302.04810v2",
          "size": "441kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T18:10:49+00:00",
          "link": "https://arxiv.org/abs/2302.04810v3",
          "size": "319kb",
          "version": "v3"
        }
      ],
      "title": "Machine Learning Systems: A Survey from a Data-Oriented Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.04810",
        "HTML": "https://arxiv.org/html/2302.04810v3",
        "PDF": "https://arxiv.org/pdf/2302.04810"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys machine learning systems from a data-oriented perspective but does not specifically contribute to LLM training data processing. It focuses on deployment and integration of ML systems rather than data processing techniques."
      },
      "tasks": [
        "Management",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/cabrerac/semi-automatic-literature-survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.02838",
      "abstract": "APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.",
      "authors": [
        "Nan Wang",
        "Xuezhi Wen",
        "Dalin Zhang",
        "Xibin Zhao",
        "Jiahui Ma",
        "Mengxia Luo",
        "Fan Xu",
        "Sen Nie",
        "Shi Wu",
        "Jiqiang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-06T03:08:09+00:00",
          "link": "https://arxiv.org/abs/2304.02838v1",
          "size": "2039kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:37:05+00:00",
          "link": "https://arxiv.org/abs/2304.02838v2",
          "size": "1841kb",
          "version": "v2"
        }
      ],
      "title": "TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.02838",
        "HTML": "https://arxiv.org/html/2304.02838v2",
        "PDF": "https://arxiv.org/pdf/2304.02838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on utilizing a transformer-based method for detecting advanced persistent threats (APT) in provenance graphs, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Decoder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.12207",
      "abstract": "We introduce Boolformer, a Transformer-based model trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions not seen during training, given their full truth table. Then, we demonstrate that even with incomplete or noisy observations, Boolformer is still able to find good approximate expressions. We evaluate Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modeling the dynamics of gene regulatory networks and show through a benchmark that Boolformer is competitive with state-of-the-art genetic algorithms, with a speedup of several orders of magnitude. Our code and models are available publicly.",
      "authors": [
        "St\\'ephane d'Ascoli",
        "Arthur Renard",
        "Vassilis Papadopoulos",
        "Samy Bengio",
        "Josh Susskind",
        "Emmanuel Abb\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-21T16:11:38+00:00",
          "link": "https://arxiv.org/abs/2309.12207v1",
          "size": "4421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T20:21:16+00:00",
          "link": "https://arxiv.org/abs/2309.12207v2",
          "size": "2606kb",
          "version": "v2"
        }
      ],
      "title": "Boolformer: Symbolic Regression of Logic Functions with Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.12207",
        "PDF": "https://arxiv.org/pdf/2309.12207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Boolformer, which focuses on symbolic regression of Boolean functions using transformers, aimed at improving interpretability in binary classification and gene regulatory networks, without contributions to LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "regression",
        "Symbolic Regression"
      ],
      "repo_urls": [
        "https://github.com/sdascoli/boolformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.00437",
      "abstract": "Consider a graph drawn on a surface (for example, the plane minus a finite set of obstacle points), possibly with crossings. We provide an algorithm to decide whether such a drawing can be untangled, namely, if one can slide the vertices and edges of the graph on the surface (avoiding the obstacles) to remove all crossings; in other words, whether the drawing is homotopic to an embedding. While the problem boils down to planarity testing when the surface is the sphere or the disk (or equivalently the plane without any obstacle), the other cases have never been studied before, except when the input graph is a cycle, in an abundant literature in topology and more recently by Despr\\'e and Lazarus [SoCG 2017, J. ACM 2019].\n  Our algorithm runs in O(m + poly(g+b) n log n) time, where g >= 0 and b >= 0 are the genus and the number of boundary components of the input orientable surface S, and n is the size of the input graph drawing, lying on some fixed graph of size m cellularly embedded on S.\n  We use various techniques from two-dimensional computational topology and from the theory of hyperbolic surfaces. Most notably, we introduce reducing triangulations, a novel discrete analog of hyperbolic surfaces in the spirit of systems of quads by Lazarus and Rivaud [FOCS 2012] and Erickson and Whittlesey [SODA 2013], which have the additional benefit that reduced paths are unique and stable upon reversal; they are likely of independent interest. Tailored data structures are needed to achieve certain homotopy tests efficiently on these triangulations. As a key subroutine, we rely on an algorithm to test the weak simplicity of a graph drawn on a surface by Akitaya, Fulek, and T\\'oth [SODA 2018, TALG 2019].",
      "authors": [
        "\\'Eric Colin de Verdi\\`ere",
        "Vincent Despr\\'e",
        "Lo\\\"ic Dubois"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-01T11:00:13+00:00",
          "link": "https://arxiv.org/abs/2311.00437v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:38:23+00:00",
          "link": "https://arxiv.org/abs/2311.00437v2",
          "size": "534kb",
          "version": "v2"
        }
      ],
      "title": "Untangling Graphs on Surfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.00437",
        "HTML": "https://arxiv.org/html/2311.00437v2",
        "PDF": "https://arxiv.org/pdf/2311.00437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with algorithms for untangling graphs on surfaces, focusing on computational topology and planarity testing. There is no discussion of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.01890",
      "abstract": "We study two classic variants of block-structured integer programming. Two-stage stochastic programs are integer programs of the form $\\{A_i \\mathbf{x} + D_i \\mathbf{y}_i = \\mathbf{b}_i\\textrm{ for all }i=1,\\ldots,n\\}$, where $A_i$ and $D_i$ are bounded-size matrices. On the other hand, $n$-fold programs are integer programs of the form $\\{{\\sum_{i=1}^n C_i\\mathbf{y}_i=\\mathbf{a}} \\textrm{ and } D_i\\mathbf{y}_i=\\mathbf{b}_i\\textrm{ for all }i=1,\\ldots,n\\}$, where again $C_i$ and $D_i$ are bounded-size matrices. It is known that solving these kind of programs is fixed-parameter tractable when parameterized by the maximum dimension among the relevant matrices $A_i,C_i,D_i$ and the maximum absolute value of any entry appearing in the constraint matrix.\n  We show that the parameterized tractability results for two-stage stochastic and $n$-fold programs persist even when one allows large entries in the global part of the program. More precisely, we prove that:\n  - The feasibility problem for two-stage stochastic programs is fixed-parameter tractable when parameterized by the dimensions of matrices $A_i,D_i$ and by the maximum absolute value of the entries of matrices $D_i$. That is, we allow matrices $A_i$ to have arbitrarily large entries.\n  - The linear optimization problem for $n$-fold integer programs that are uniform -- all matrices $C_i$ are equal -- is fixed-parameter tractable when parameterized by the dimensions of matrices $C_i$ and $D_i$ and by the maximum absolute value of the entries of matrices $D_i$. That is, we require that $C_i=C$ for all $i=1,\\ldots,n$, but we allow $C$ to have arbitrarily large entries.\n  In the second result, the uniformity assumption is necessary; otherwise the problem is $\\mathsf{NP}$-hard already when the parameters take constant values. Both our algorithms are weakly polynomial: the running time is measured in the total bitsize of the input.",
      "authors": [
        "Jana Cslovjecsek",
        "Martin Kouteck\\'y",
        "Alexandra Lassota",
        "Micha{\\l} Pilipczuk",
        "Adam Polak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-03T13:05:25+00:00",
          "link": "https://arxiv.org/abs/2311.01890v1",
          "size": "281kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:26:55+00:00",
          "link": "https://arxiv.org/abs/2311.01890v2",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "title": "Parameterized algorithms for block-structured integer programs with large entries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.01890",
        "HTML": "https://arxiv.org/html/2311.01890v2",
        "PDF": "https://arxiv.org/pdf/2311.01890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses parameterized algorithms for block-structured integer programs, which is unrelated to any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.18149",
      "abstract": "Trajectory prediction is a challenging task that aims to predict the future trajectory of vehicles or pedestrians over a short time horizon based on their historical positions. The main reason is that the trajectory is a kind of complex data, including spatial and temporal information, which is crucial for accurate prediction. Intuitively, the more information the model can capture, the more precise the future trajectory can be predicted. However, previous works based on deep learning methods processed spatial and temporal information separately, leading to inadequate spatial information capture, which means they failed to capture the complete spatial information. Therefore, it is of significance to capture information more fully and effectively on vehicle interactions. In this study, we introduced an integrated 3D graph that incorporates both spatial and temporal edges. Based on this, we proposed the integrated 3D graph, which considers the cross-time interaction information. In specific, we design a Spatial-Temporal Fusion (STF) model including Multi-layer perceptions (MLP) and Graph Attention (GAT) to capture the spatial and temporal information historical trajectories simultaneously on the 3D graph. Our experiment on the ApolloScape Trajectory Datasets shows that the proposed STF outperforms several baseline methods, especially on the long-time-horizon trajectory prediction.",
      "authors": [
        "Pengqian Han",
        "Jiamou Liu",
        "Tianzhe Bao",
        "Yifei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-29T23:31:40+00:00",
          "link": "https://arxiv.org/abs/2311.18149v1",
          "size": "1000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T02:05:09+00:00",
          "link": "https://arxiv.org/abs/2311.18149v2",
          "size": "436kb",
          "version": "v2"
        }
      ],
      "title": "STF: Spatial Temporal Fusion for Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.18149",
        "HTML": "https://arxiv.org/html/2311.18149v2",
        "PDF": "https://arxiv.org/pdf/2311.18149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on trajectory prediction using a Spatial Temporal Fusion model. It does not mention any processes or techniques related to LLM training data processing."
      },
      "tasks": [
        "Graph Attention",
        "Prediction",
        "Trajectory Prediction"
      ],
      "repo_urls": [
        "https://github.com/pengqianhan/STF-Spatial-Temporal-Fusion-for-Trajectory-Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.02419",
      "abstract": "Learning from human demonstrations is an emerging trend for designing intelligent robotic systems. However, previous methods typically regard videos as instructions, simply dividing them into action sequences for robotic repetition, which poses obstacles to generalization to diverse tasks or object instances. In this paper, we propose a different perspective, considering human demonstration videos not as mere instructions, but as a source of knowledge for robots. Motivated by this perspective and the remarkable comprehension and generalization capabilities exhibited by large language models (LLMs), we propose DigKnow, a method that DIstills Generalizable KNOWledge with a hierarchical structure. Specifically, DigKnow begins by converting human demonstration video frames into observation knowledge. This knowledge is then subjected to analysis to extract human action knowledge and further distilled into pattern knowledge compassing task and object instances, resulting in the acquisition of generalizable knowledge with a hierarchical structure. In settings with different tasks or object instances, DigKnow retrieves relevant knowledge for the current task and object instances. Subsequently, the LLM-based planner conducts planning based on the retrieved knowledge, and the policy executes actions in line with the plan to achieve the designated task. Utilizing the retrieved knowledge, we validate and rectify planning and execution outcomes, resulting in a substantial enhancement of the success rate. Experimental results across a range of tasks and scenes demonstrate the effectiveness of this approach in facilitating real-world robots to accomplish tasks with the knowledge derived from human demonstrations.",
      "authors": [
        "Te Cui",
        "Tianxing Zhou",
        "Zicai Peng",
        "Mengxiao Hu",
        "Haoyang Lu",
        "Haizhou Li",
        "Guangyan Chen",
        "Meiling Wang",
        "Yufeng Yue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-05T01:35:39+00:00",
          "link": "https://arxiv.org/abs/2312.02419v1",
          "size": "2276kb",
          "version": "v1"
        },
        {
          "date": "2024-05-12T09:27:33+00:00",
          "link": "https://arxiv.org/abs/2312.02419v2",
          "size": "2296kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T12:34:14+00:00",
          "link": "https://arxiv.org/abs/2312.02419v3",
          "size": "1445kb",
          "version": "v3"
        }
      ],
      "title": "Human Demonstrations are Generalizable Knowledge for Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.02419",
        "HTML": "https://arxiv.org/html/2312.02419v3",
        "PDF": "https://arxiv.org/pdf/2312.02419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses learning from human demonstrations applied to robotic systems and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.16054",
      "abstract": "Zero-shot stance detection (ZSSD) aims to detect stances toward unseen targets. Incorporating background knowledge to enhance transferability between seen and unseen targets constitutes the primary approach of ZSSD. However, these methods often struggle with a knowledge-task disconnect and lack logical consistency in their predictions. To address these issues, we introduce a novel approach named Logically Consistent Chain-of-Thought (LC-CoT) for ZSSD, which improves stance detection by ensuring relevant and logically sound knowledge extraction. LC-CoT employs a three-step process. Initially, it assesses whether supplementary external knowledge is necessary. Subsequently, it uses API calls to retrieve this knowledge, which can be processed by a separate LLM. Finally, a manual exemplar guides the LLM to infer stance categories, using an if-then logical structure to maintain relevance and logical coherence. This structured approach to eliciting background knowledge enhances the model's capability, outperforming traditional supervised methods without relying on labeled data.",
      "authors": [
        "Bowen Zhang",
        "Daijun Ding",
        "Liwen Jing and Hu Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-26T13:54:00+00:00",
          "link": "https://arxiv.org/abs/2312.16054v1",
          "size": "2372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:13:07+00:00",
          "link": "https://arxiv.org/abs/2312.16054v2",
          "size": "2377kb",
          "version": "v2"
        }
      ],
      "title": "A Logically Consistent Chain-of-Thought Approach for Stance Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.16054",
        "HTML": "https://arxiv.org/html/2312.16054v2",
        "PDF": "https://arxiv.org/pdf/2312.16054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel approach for zero-shot stance detection using logical consistency, chain-of-thought, and external knowledge. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Stance Detection",
        "Zero-Shot Stance Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.09617",
      "abstract": "Graph recommendation methods, representing a connected interaction perspective, reformulate user-item interactions as graphs to leverage graph structure and topology to recommend and have proved practical effectiveness at scale. Large language models, representing a textual generative perspective, excel at modeling user languages, understanding behavioral contexts, capturing user-item semantic relationships, analyzing textual sentiments, and generating coherent and contextually relevant texts as recommendations. However, there is a gap between the connected graph perspective and the text generation perspective as the task formulations are different. A research question arises: how can we effectively integrate the two perspectives for more personalized recsys? To fill this gap, we propose to incorporate graph-edge information into LLMs via prompt and attention innovations. We reformulate recommendations as a probabilistic generative problem using prompts. We develop a framework to incorporate graph edge information from the prompt and attention mechanisms for graph-structured LLM recommendations. We develop a new prompt design that brings in both first-order and second-order graph relationships; we devise an improved LLM attention mechanism to embed direct the spatial and connectivity information of edges. Our evaluation of real-world datasets demonstrates the framework's ability to understand connectivity information in graph data and to improve the relevance and quality of recommendation results.",
      "authors": [
        "Xinyuan Wang",
        "Liang Wu",
        "Liangjie Hong",
        "Hao Liu",
        "Yanjie Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-14T23:12:09+00:00",
          "link": "https://arxiv.org/abs/2402.09617v1",
          "size": "5308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:51:28+00:00",
          "link": "https://arxiv.org/abs/2402.09617v2",
          "size": "2668kb",
          "version": "v2"
        }
      ],
      "title": "LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09617",
        "HTML": "https://arxiv.org/html/2402.09617v2",
        "PDF": "https://arxiv.org/pdf/2402.09617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes incorporating graph-edge information into LLMs to improve recommendation systems. While it involves LLMs and mentions framework adjustments, it focuses more on utilizing existing data structure rather than processing or generating data for LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/anord-wang/llm4rec"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.13722",
      "abstract": "Aspect-Based Sentiment Analysis (ABSA) is a fine-grained linguistics problem that entails the extraction of multifaceted aspects, opinions, and sentiments from the given text. Both standalone and compound ABSA tasks have been extensively used in the literature to examine the nuanced information present in online reviews and social media posts. Current ABSA methods often rely on static hyperparameters for attention-masking mechanisms, which can struggle with context adaptation and may overlook the unique relevance of words in varied situations. This leads to challenges in accurately analyzing complex sentences containing multiple aspects with differing sentiments. In this work, we present adaptive masking methods that remove irrelevant tokens based on context to assist in Aspect Term Extraction and Aspect Sentiment Classification subtasks of ABSA. We show with our experiments that the proposed methods outperform the baseline methods in terms of accuracy and F1 scores on four benchmark online review datasets. Further, we show that the proposed methods can be extended with multiple adaptations and demonstrate a qualitative analysis of the proposed approach using sample text for aspect term extraction.",
      "authors": [
        "S M Rafiuddin",
        "Mohammed Rakib",
        "Sadia Kamal",
        "Arunkumar Bagavathi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T11:33:09+00:00",
          "link": "https://arxiv.org/abs/2402.13722v1",
          "size": "273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T00:24:33+00:00",
          "link": "https://arxiv.org/abs/2402.13722v2",
          "size": "271kb",
          "version": "v2"
        }
      ],
      "title": "Exploiting Adaptive Contextual Masking for Aspect-Based Sentiment Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13722",
        "HTML": "https://arxiv.org/html/2402.13722v2",
        "PDF": "https://arxiv.org/pdf/2402.13722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adaptive masking methods for aspect-based sentiment analysis, aiming to improve token relevance in complex sentences. It is not related to LLM training data processing."
      },
      "tasks": [
        "Aspect-Based Sentiment Analysis",
        "Aspect-Based Sentiment Analysis (ABSA)",
        "Sentiment Analysis",
        "Sentiment Classification",
        "Term Extraction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.03117",
      "abstract": "This letter proposes a method to integrate auxiliary actuators that enhance the task-space capabilities of commercial underactuated systems, while leaving the internal certified low-level controller untouched. The additional actuators are combined with a feedback-linearizing outer-loop controller, enabling full-pose tracking. We provide conditions under which legacy high-level commands and new actuator inputs can be cohesively coordinated to achieve decoupled control of all degrees of freedom. A comparative study with a standard quadrotor-originally not designed for physical interaction-demonstrates that the proposed modified platform remains stable under contact, while the baseline system diverges. Additionally, simulation results under parameter uncertainty illustrate the robustness of the proposed approach.",
      "authors": [
        "Mirko Mizzoni",
        "Amr Afifi",
        "and Antonio Franchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-05T16:58:13+00:00",
          "link": "https://arxiv.org/abs/2403.03117v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T17:42:14+00:00",
          "link": "https://arxiv.org/abs/2403.03117v2",
          "size": "3420kb",
          "version": "v2"
        },
        {
          "date": "2025-07-12T17:37:21+00:00",
          "link": "https://arxiv.org/abs/2403.03117v3",
          "size": "2991kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T13:34:54+00:00",
          "link": "https://arxiv.org/abs/2403.03117v4",
          "size": "1490kb",
          "version": "v4"
        }
      ],
      "title": "Input-Output Extension of Underactuated Nonlinear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.03117",
        "HTML": "https://arxiv.org/html/2403.03117v4",
        "PDF": "https://arxiv.org/pdf/2403.03117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with integrating auxiliary actuators in underactuated systems and does not mention any aspects of LLM training data processing or related activities."
      },
      "tasks": [
        "Pose Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.13132",
      "abstract": "In-hand manipulation is a crucial ability for reorienting and repositioning objects within grasps. The main challenges in this are not only the complexity of the computational models, but also the risks of grasp instability caused by active finger motions, such as rolling, sliding, breaking, and remaking contacts. This paper presents the development of the Roller Ring (RR), a modular robotic attachment with active surfaces that is wearable by both robot and human hands to manipulate without lifting a finger. By installing the angled RRs on hands, such that their spatial motions are not colinear, we derive a general differential motion model for manipulating objects. Our motion model shows that complete in-hand manipulation skill sets can be provided by as few as only 2 RRs through non-holonomic object motions, while more RRs can enable enhanced manipulation dexterity with fewer motion constraints. Through extensive experiments, we test the RRs on both a robot hand and a human hand to evaluate their manipulation capabilities. We show that the RRs can be employed to manipulate arbitrary object shapes to provide dexterous in-hand manipulation.",
      "authors": [
        "Hayden Webb",
        "Podshara Chanrungmaneekul",
        "Shenli Yuan",
        "Kaiyu Hang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T20:04:35+00:00",
          "link": "https://arxiv.org/abs/2403.13132v1",
          "size": "20147kb",
          "version": "v1"
        },
        {
          "date": "2024-04-07T21:13:35+00:00",
          "link": "https://arxiv.org/abs/2403.13132v2",
          "size": "16597kb",
          "version": "v2"
        },
        {
          "date": "2024-09-15T00:25:20+00:00",
          "link": "https://arxiv.org/abs/2403.13132v3",
          "size": "17953kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T21:28:22+00:00",
          "link": "https://arxiv.org/abs/2403.13132v4",
          "size": "10880kb",
          "version": "v4"
        }
      ],
      "title": "Wearable Roller Rings to Augment In-Hand Manipulation through Active Surfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13132",
        "HTML": "https://arxiv.org/html/2403.13132v4",
        "PDF": "https://arxiv.org/pdf/2403.13132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on the development of Roller Rings for in-hand manipulation in robotics, which is unrelated to LLM training data processing or any associated data handling techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.13189",
      "abstract": "Mixed methods for linear elasticity with strongly symmetric stresses of lowest order are studied in this paper. On each simplex, the stress space has piecewise linear components with respect to its Alfeld split (which connects the vertices to barycenter), generalizing the Johnson--Mercier two-dimensional element to higher dimensions. Further reductions in the stress space in the three-dimensional case (to 24 degrees of freedom per tetrahedron) are possible when the displacement space is reduced to local rigid displacements. Proofs of optimal error estimates of numerical solutions and improved error estimates via postprocessing and the duality argument are presented.",
      "authors": [
        "Jay Gopalakrishnan",
        "Johnny Guzman",
        "Jeonghun J. Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T22:57:17+00:00",
          "link": "https://arxiv.org/abs/2403.13189v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2024-11-09T00:34:13+00:00",
          "link": "https://arxiv.org/abs/2403.13189v2",
          "size": "39kb",
          "version": "v2"
        },
        {
          "date": "2025-01-31T19:24:37+00:00",
          "link": "https://arxiv.org/abs/2403.13189v3",
          "size": "39kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T07:32:20+00:00",
          "link": "https://arxiv.org/abs/2403.13189v4",
          "size": "73kb",
          "version": "v4"
        }
      ],
      "title": "The Johnson-Krizek-Mercier elasticity element in any dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13189",
        "HTML": "https://arxiv.org/html/2403.13189v4",
        "PDF": "https://arxiv.org/pdf/2403.13189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines mixed methods for linear elasticity, extending mathematical elements to higher dimensions, with no connection to LLM training data processing or improvement in data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.01445",
      "abstract": "This paper presents an approach to design control barrier functions (CBFs) for arbitrary state and input constraints using tools from the reference governor literature. In particular, it is shown that dynamic safety margins (DSMs) are CBFs for an augmented system obtained by concatenating the state with a virtual reference. The proposed approach is agnostic to the relative degree and can handle multiple state and input constraints using the control-sharing property of CBFs. The construction of CBFs using Lyapunov-based DSMs is then investigated in further detail. Numerical simulations show that the method outperforms existing DSM-based approaches, while also guaranteeing safety and persistent feasibility of the associated optimization program.",
      "authors": [
        "Victor Freire",
        "and Marco M. Nicotra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T19:32:30+00:00",
          "link": "https://arxiv.org/abs/2404.01445v1",
          "size": "208kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T11:32:32+00:00",
          "link": "https://arxiv.org/abs/2404.01445v2",
          "size": "758kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T15:18:54+00:00",
          "link": "https://arxiv.org/abs/2404.01445v3",
          "size": "1944kb",
          "version": "v3"
        }
      ],
      "title": "Using Dynamic Safety Margins as Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01445",
        "HTML": "https://arxiv.org/html/2404.01445v3",
        "PDF": "https://arxiv.org/pdf/2404.01445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing control barrier functions (CBFs) for control systems, with no discussion of LLM training data processing or related topics such as data engineering operations or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.01485",
      "abstract": "Designing multiscale visualizations, particularly when the ratio between the largest scale and the smallest item is large, can be challenging, and designers have developed many approaches to overcome this challenge. We present a design space for visualization with multiple scales. The design space includes three dimensions, with eight total subdimensions. We demonstrate its descriptive power by using it to code approaches from a corpus we compiled of 52 examples, created by a mix of academics and practitioners. We demonstrate descriptive power by analyzing and partitioning these examples into four high-level strategies for designing multiscale visualizations, which are shared approaches with respect to design space dimension choices. We demonstrate generative power by analyzing missed opportunities within the corpus of examples, identified through analysis of the design space, where we note how certain examples could have benefited from different choices. We discuss patterns in the use of different dimension and strategy choices in the different visualization contexts of analysis and presentation.\n  Supplemental materials: https://osf.io/wbrdm/\n  Design space website: https://marasolen.github.io/multiscale-vis-ds/",
      "authors": [
        "Mara Solen",
        "Matt Oddo",
        "Tamara Munzner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T21:10:52+00:00",
          "link": "https://arxiv.org/abs/2404.01485v1",
          "size": "716kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T19:13:18+00:00",
          "link": "https://arxiv.org/abs/2404.01485v2",
          "size": "1585kb",
          "version": "v2"
        }
      ],
      "title": "A Design Space for Multiscale Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01485",
        "HTML": "https://arxiv.org/html/2404.01485v2",
        "PDF": "https://arxiv.org/pdf/2404.01485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses design space for multiscale visualizations, which does not relate to LLM training data processing, as it addresses visualization strategies rather than data processing techniques or datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.04631",
      "abstract": "In this work, we introduce a new hallucination metric - Simple Hallucination Index (SHI) and provide insight into one important limitation of the parametric knowledge of large language models (LLMs), i.e. false attribution. The task of automatic author attribution for relatively small chunks of text is an important NLP task but can be challenging. We empirically evaluate the power of 3 open SotA LLMs in zero-shot setting (Gemma-7B, Mixtral 8x7B, and LLaMA-2-13B). We acquired the top 10 most popular books of a month, according to Project Gutenberg, divided each one into equal chunks of 400 words, and prompted each LLM to predict the author. We then randomly sampled 162 chunks per book for human evaluation, based on the error margin of 7% and a confidence level of 95%. The average results show that Mixtral 8x7B has the highest prediction accuracy, the lowest SHI, and a Pearson's correlation (r) of 0.724, 0.263, and -0.9996, respectively, followed by LLaMA-2-13B and Gemma-7B. However, Mixtral 8x7B suffers from high hallucinations for 3 books, rising as high as a SHI of 0.87 (in the range 0-1, where 1 is the worst). The strong negative correlation of accuracy and SHI, given by r, demonstrates the fidelity of the new hallucination metric, which may generalize to other tasks. We also show that prediction accuracies correlate positively with the frequencies of Wikipedia instances of the book titles instead of the downloads and we perform error analyses of predictions. We publicly release the annotated chunks of data and our codes to aid the reproducibility and evaluation of other models.",
      "authors": [
        "Tosin Adewumi",
        "Nudrat Habib",
        "Lama Alkhaled and Elisa Barney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-06T13:38:15+00:00",
          "link": "https://arxiv.org/abs/2404.04631v1",
          "size": "2363kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:20:16+00:00",
          "link": "https://arxiv.org/abs/2404.04631v2",
          "size": "2732kb",
          "version": "v2"
        }
      ],
      "title": "On the Limitations of Large Language Models (LLMs): False Attribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.04631",
        "HTML": "https://arxiv.org/html/2404.04631v2",
        "PDF": "https://arxiv.org/pdf/2404.04631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a hallucination metric and evaluates author attribution tasks with LLMs, but it does not address any LLM training data processing aspects, such as collection, filtering, or dataset generation."
      },
      "tasks": [
        "Author Attribution",
        "Hallucination"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.02994",
      "abstract": "The increasing interest in developing Artificial Intelligence applications in the medical domain, suffers from the lack of high-quality data set, mainly due to privacy-related issues. In addition, the recent increase in Vision Language Models (VLM) leads to the need for multimodal medical data sets, where clinical reports and findings are attached to the corresponding medical scans. This paper illustrates the entire workflow for building the MedPix 2.0 data set. Starting with the well-known multimodal data set MedPix\\textsuperscript{\\textregistered}, mainly used by physicians, nurses, and healthcare students for Continuing Medical Education purposes, a semi-automatic pipeline was developed to extract visual and textual data followed by a manual curing procedure in which noisy samples were removed, thus creating a MongoDB database. Along with the data set, we developed a Graphical User Interface aimed at navigating efficiently the MongoDB instance and obtaining the raw data that can be easily used for training and/or fine-tuning VLMs. To enforce this point, in this work, we first recall DR-Minerva, a Retrieve Augmented Generation-based VLM model trained upon MedPix 2.0. DR-Minerva predicts the body part and the modality used to scan its input image. We also propose the extension of DR-Minerva with a Knowledge Graph that uses Llama 3.1 Instruct 8B, and leverages MedPix 2.0. The resulting architecture can be queried in a end-to-end manner, as a medical decision support system. MedPix 2.0 is available on GitHub.",
      "authors": [
        "Irene Siragusa",
        "Salvatore Contino",
        "Massimo La Ciura",
        "Rosario Alicata",
        "Roberto Pirrone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-03T10:49:21+00:00",
          "link": "https://arxiv.org/abs/2407.02994v1",
          "size": "8362kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T13:35:45+00:00",
          "link": "https://arxiv.org/abs/2407.02994v2",
          "size": "15593kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T16:57:40+00:00",
          "link": "https://arxiv.org/abs/2407.02994v3",
          "size": "8167kb",
          "version": "v3"
        },
        {
          "date": "2025-04-30T11:41:49+00:00",
          "link": "https://arxiv.org/abs/2407.02994v4",
          "size": "10503kb",
          "version": "v4"
        },
        {
          "date": "2025-07-17T12:30:16+00:00",
          "link": "https://arxiv.org/abs/2407.02994v5",
          "size": "8168kb",
          "version": "v5"
        }
      ],
      "title": "MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced AI Applications with Retrieval Augmented Generation and Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02994",
        "HTML": "https://arxiv.org/html/2407.02994v5",
        "PDF": "https://arxiv.org/pdf/2407.02994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses the building of the MedPix 2.0 dataset and its use with Vision Language Models (VLMs), the primary focus is on medical applications and VLM model development rather than on LLM training data processing for language models."
      },
      "datasets": [
        {
          "dataset_name": "adishourya/MEDPIX-ClinQA",
          "downloads": "109",
          "likes": "7",
          "link": "https://huggingface.co/datasets/adishourya/MEDPIX-ClinQA"
        },
        {
          "dataset_name": "adishourya/MEDPIX-ShortQA",
          "downloads": "250",
          "likes": "3",
          "link": "https://huggingface.co/datasets/adishourya/MEDPIX-ShortQA"
        },
        {
          "dataset_name": "mmoukouba/MedPix-Grouped-QA",
          "downloads": "22",
          "likes": "0",
          "link": "https://huggingface.co/datasets/mmoukouba/MedPix-Grouped-QA"
        },
        {
          "dataset_name": "mmoukouba/MedPix-VQA",
          "downloads": "195",
          "likes": "0",
          "link": "https://huggingface.co/datasets/mmoukouba/MedPix-VQA"
        }
      ],
      "tasks": [
        "Knowledge Graphs",
        "RAG"
      ],
      "repo_urls": [
        "https://github.com/chilab1/medpix-2.0"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.14540",
      "abstract": "The use of AI technologies is being integrated into the secure development of software-based systems, with an increasing trend of composing AI-based subsystems (with uncertain levels of performance) into automated pipelines. This presents a fundamental research challenge and seriously threatens safety-critical domains. Despite the existing knowledge about uncertainty in risk analysis, no previous work has estimated the uncertainty of AI-augmented systems given the propagation of errors in the pipeline. We provide the formal underpinnings for capturing uncertainty propagation, develop a simulator to quantify uncertainty, and evaluate the simulation of propagating errors with one case study. We discuss the generalizability of our approach and its limitations and present recommendations for evaluation policies concerning AI systems. Future work includes extending the approach by relaxing the remaining assumptions and by experimenting with a real system.",
      "authors": [
        "Emanuele Mezzi",
        "Aurora Papotti",
        "Fabio Massacci and Katja Tuma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-14T19:02:20+00:00",
          "link": "https://arxiv.org/abs/2407.14540v1",
          "size": "580kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:04:02+00:00",
          "link": "https://arxiv.org/abs/2407.14540v2",
          "size": "753kb",
          "version": "v2"
        }
      ],
      "title": "Risks of ignoring uncertainty propagation in AI-augmented security pipelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.14540",
        "HTML": "https://arxiv.org/html/2407.14540v2",
        "PDF": "https://arxiv.org/pdf/2407.14540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses uncertainty propagation in AI security systems and pipelines, which is not related to training data processing for large language models (LLMs)."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.17395",
      "abstract": "Machine Learning research, including work promoting fair or equitable algorithms, heavily relies on the concept of a data-generating probability distribution. The standard presumption is that since data points are 'sampled from' such a distribution, one can learn from observed data about this distribution and, thus, predict future data points which are also drawn from it. We argue, however, that such true probability distributions do not exist and should not be dealt with uncritically. We show that alternative frameworks focusing directly on relevant populations rather than abstract distributions are available and leave classical learning theory almost unchanged. Furthermore, we argue that the assumption of true probabilities or data-generating distributions can be misleading and obscure both the choices made and the goals pursued in machine learning practice. Based on these considerations, this position paper argues that, at least in social settings, machine learning work should avoid assuming data-generating probability distributions.",
      "authors": [
        "Benedikt H\\\"oltgen and Robert C. Williamson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T16:17:14+00:00",
          "link": "https://arxiv.org/abs/2407.17395v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2024-08-14T12:17:38+00:00",
          "link": "https://arxiv.org/abs/2407.17395v2",
          "size": "35kb",
          "version": "v2"
        },
        {
          "date": "2024-09-12T09:22:25+00:00",
          "link": "https://arxiv.org/abs/2407.17395v3",
          "size": "37kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T06:59:59+00:00",
          "link": "https://arxiv.org/abs/2407.17395v4",
          "size": "77kb",
          "version": "v4"
        }
      ],
      "title": "We should avoid the assumption of data-generating probability distributions in social settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17395",
        "HTML": "https://arxiv.org/html/2407.17395v4",
        "PDF": "https://arxiv.org/pdf/2407.17395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper argues against assuming data-generating probability distributions in machine learning but does not propose methodologies related to LLM training data processing."
      },
      "tasks": [
        "Learning Theory"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19557",
      "abstract": "Stochastic Volterra equations (SVEs) serve as mathematical models for the time evolutions of random systems with memory effects and irregular behaviour. We introduce neural stochastic Volterra equations as a physics-inspired architecture, generalizing the class of neural stochastic differential equations, and provide some theoretical foundation. Numerical experiments on various SVEs, like the disturbed pendulum equation, the generalized Ornstein--Uhlenbeck process, the rough Heston model and a monetary reserve dynamics, are presented, comparing the performance of neural SVEs, neural SDEs and Deep Operator Networks (DeepONets).",
      "authors": [
        "Martin Bergerhausen",
        "David J. Pr\\\"omel",
        "David Scheffels"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-28T18:44:49+00:00",
          "link": "https://arxiv.org/abs/2407.19557v1",
          "size": "1120kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:16:31+00:00",
          "link": "https://arxiv.org/abs/2407.19557v2",
          "size": "1688kb",
          "version": "v2"
        }
      ],
      "title": "Neural stochastic Volterra equations: learning path-dependent dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19557",
        "HTML": "https://arxiv.org/html/2407.19557v2",
        "PDF": "https://arxiv.org/pdf/2407.19557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new physics-inspired architecture for neural stochastic Volterra equations, which does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.20209",
      "abstract": "For overparameterized optimization tasks, such as those found in modern machine learning, global minima are generally not unique. In order to understand generalization in these settings, it is vital to study to which minimum an optimization algorithm converges. The possibility of having minima that are unstable under the dynamics imposed by the optimization algorithm limits the potential minima that the algorithm can find. In this paper, we characterize the global minima that are dynamically stable/unstable for both deterministic and stochastic gradient descent (SGD). In particular, we introduce a characteristic Lyapunov exponent that depends on the local dynamics around a global minimum and rigorously prove that the sign of this Lyapunov exponent determines whether SGD can accumulate at the respective global minimum.",
      "authors": [
        "Dennis Chemnitz",
        "Maximilian Engel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T17:40:04+00:00",
          "link": "https://arxiv.org/abs/2407.20209v1",
          "size": "158kb",
          "version": "v1"
        },
        {
          "date": "2024-09-18T17:44:48+00:00",
          "link": "https://arxiv.org/abs/2407.20209v2",
          "size": "152kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T10:02:31+00:00",
          "link": "https://arxiv.org/abs/2407.20209v3",
          "size": "159kb",
          "version": "v3"
        }
      ],
      "title": "Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20209",
        "HTML": "https://arxiv.org/html/2407.20209v3",
        "PDF": "https://arxiv.org/pdf/2407.20209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the dynamics of stochastic gradient descent and the stability of global minima, which is not directly relevant to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.16990",
      "abstract": "Adding proper background music helps complete a short video to be shared. Previous work tackles the task by video-to-music retrieval (V2MR), aiming to find the most suitable music track from a collection to match the content of a given query video. In practice, however, music tracks are typically much longer than the query video, necessitating (manual) trimming of the retrieved music to a shorter segment that matches the video duration. In order to bridge the gap between the practical need for music moment localization and V2MR, we propose a new task termed Music Grounding by Short Video (MGSV). To tackle the new task, we introduce a new benchmark, MGSV-EC, which comprises a diverse set of 53k short videos associated with 35k different music moments from 4k unique music tracks. Furthermore, we develop a new baseline method, MaDe, which performs both video-to-music matching and music moment detection within a unified end-to-end deep network. Extensive experiments on MGSV-EC not only highlight the challenging nature of MGSV but also set MaDe as a strong baseline.",
      "authors": [
        "Zijie Xin",
        "Minquan Wang",
        "Jingyu Liu",
        "Ye Ma",
        "Quan Chen",
        "Peng Jiang",
        "Xirong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T03:36:22+00:00",
          "link": "https://arxiv.org/abs/2408.16990v1",
          "size": "33342kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T08:06:15+00:00",
          "link": "https://arxiv.org/abs/2408.16990v2",
          "size": "16777kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T04:31:17+00:00",
          "link": "https://arxiv.org/abs/2408.16990v3",
          "size": "25550kb",
          "version": "v3"
        }
      ],
      "title": "Music Grounding by Short Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16990",
        "HTML": "https://arxiv.org/html/2408.16990v3",
        "PDF": "https://arxiv.org/pdf/2408.16990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on music grounding and moment localization in videos, introducing a new task and benchmark for this purpose, which is unrelated to any aspect of LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "xxayt/MGSV-EC",
          "downloads": "33",
          "likes": "2",
          "link": "https://huggingface.co/datasets/xxayt/MGSV-EC"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.05028",
      "abstract": "GUI test migration aims to produce test cases with events and assertions to test specific functionalities of a target app. Existing migration approaches typically focus on the widget-mapping paradigm that maps widgets from source apps to target apps. However, since different apps may implement the same functionality in different ways, direct mapping may result in incomplete or buggy test cases, thus significantly impacting the effectiveness of testing target functionality and the practical applicability of migration approaches.\n  In this paper, we propose a new migration paradigm (i.e., the abstraction-concretization paradigm) that first abstracts the test logic for the target functionality and then utilizes this logic to generate the concrete GUI test case. Furthermore, we introduce MACdroid, the first approach that migrates GUI test cases based on this paradigm. Specifically, we propose an abstraction technique that utilizes source test cases from source apps targeting the same functionality to extract a general test logic for that functionality. Then, we propose a concretization technique that utilizes the general test logic to guide an LLM in generating the corresponding GUI test case (including events and assertions) for the target app. We evaluate MACdroid on two widely-used datasets (including 31 apps, 34 functionalities, and 123 test cases). On the FrUITeR dataset, the test cases generated by MACdroid successfully test 64% of the target functionalities, improving the baselines by 191%. On the Lin dataset, MACdroid successfully tests 75% of the target functionalities, outperforming the baselines by 42%. These results underscore the effectiveness of MACdroid in GUI test migration.",
      "authors": [
        "Yakun Zhang",
        "Chen Liu",
        "Xiaofei Xie",
        "Yun Lin",
        "Jin Song Dong",
        "Dan Hao",
        "Lu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-08T08:46:05+00:00",
          "link": "https://arxiv.org/abs/2409.05028v1",
          "size": "1228kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:36:27+00:00",
          "link": "https://arxiv.org/abs/2409.05028v2",
          "size": "998kb",
          "version": "v2"
        }
      ],
      "title": "GUI Test Migration via Abstraction and Concretization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05028",
        "HTML": "https://arxiv.org/html/2409.05028v2",
        "PDF": "https://arxiv.org/pdf/2409.05028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses a technique for generating GUI test cases involving LLMs, its main focus is on GUI testing rather than LLM training data processing. Thus, it only indirectly relates to training data processing by utilizing LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.06690",
      "abstract": "Music classification, a cornerstone of music information retrieval, supports a wide array of applications. To address the lack of comprehensive datasets and effective methods for sub-genre classification in mainstage dance music, we introduce a novel benchmark featuring a new dataset and baseline. Our dataset expands the scope of sub-genres to reflect the diversity of recent mainstage live sets performed by leading DJs at global music festivals, capturing the vibrant and rapidly evolving electronic dance music (EDM) scene that engages millions of fans worldwide. We employ a continuous soft labeling approach to accommodate tracks blending multiple sub-genres, preserving their inherent complexity. Experiments demonstrate that even state-of-the-art multimodal large language models (MLLMs) struggle with this task, while our specialized baseline models achieve high accuracy. This benchmark supports applications such as music recommendation, DJ set curation, and interactive multimedia systems, with video demos provided. Our code and data are all open-sourced at https://github.com/Gariscat/housex-v2.git}{https://github.com/Gariscat/housex-v2.git.",
      "authors": [
        "Hongzhi Shu and Xinglin Li and Hongyu Jiang and Minghao Fu and Xinyu Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T17:54:00+00:00",
          "link": "https://arxiv.org/abs/2409.06690v1",
          "size": "7173kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:43:51+00:00",
          "link": "https://arxiv.org/abs/2409.06690v2",
          "size": "1490kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Sub-Genre Classification For Mainstage Dance Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06690",
        "HTML": "https://arxiv.org/html/2409.06690v2",
        "PDF": "https://arxiv.org/pdf/2409.06690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new benchmark and dataset for music sub-genre classification, primarily relevant to music information retrieval, and does not address LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Classification",
        "Genre classification",
        "Information Retrieval",
        "Music Classification",
        "Music Information Retrieval",
        "Music Recommendation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.14449",
      "abstract": "We develop couplings of a recent space-time first-order system least-squares (FOSLS) method for parabolic problems and space-time boundary element methods (BEM) for the heat equation to numerically solve a parabolic transmission problem on the full space and a finite time interval. In particular, we demonstrate coercivity of the couplings under certain restrictions and validate our theoretical findings by numerical experiments.",
      "authors": [
        "Thomas F\\\"uhrer",
        "Gregor Gantner",
        "Michael Karkulik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-22T14:00:51+00:00",
          "link": "https://arxiv.org/abs/2409.14449v1",
          "size": "6708kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:12:37+00:00",
          "link": "https://arxiv.org/abs/2409.14449v2",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "title": "Space-time FEM-BEM couplings for parabolic transmission problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14449",
        "HTML": "https://arxiv.org/html/2409.14449v2",
        "PDF": "https://arxiv.org/pdf/2409.14449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical methods for solving parabolic transmission problems in space-time FEM-BEM couplings, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.16595",
      "abstract": "Mobile smartphones compactly provide sensors such as cameras, IMUs, GNSS measurement units, and wireless and wired communication channels required for robotics projects. They are affordable, portable, and programmable, which makes them ideal for testing, data acquisition, controlling mobile robots, and many other robotic applications. A robotic system is proposed in this paper, consisting of an Android phone, a microcontroller board attached to the phone via USB, and a remote wireless controller station. In the data acquisition mode, the Android device can record a dataset of a diverse configuration of multiple cameras, IMUs, GNSS units, and external USB ADC channels in the rawest format used for, but not limited to, pose estimation and scene reconstruction applications. In robot control mode, the Android phone, a microcontroller board, and other peripherals constitute the mobile or stationary robotic system. This system is controlled using a remote server connected over Wi-Fi or Bluetooth. Experiments show that although the SLAM and AR applications can utilize the acquired data, the proposed system can pave the way for more advanced algorithms for processing these noisy and sporadic measurements. Moreover, the characteristics of the communication media are studied, and two example robotic projects, which involve controlling a toy car and a quadcopter, are included.",
      "authors": [
        "Masoud Dayani Najafabadi and Khoshnam Shojaei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-25T03:40:01+00:00",
          "link": "https://arxiv.org/abs/2409.16595v1",
          "size": "6610kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T11:33:58+00:00",
          "link": "https://arxiv.org/abs/2409.16595v2",
          "size": "20659kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T13:00:11+00:00",
          "link": "https://arxiv.org/abs/2409.16595v3",
          "size": "4111kb",
          "version": "v3"
        }
      ],
      "title": "Robo-Platform: A Robotic System for Recording Sensors and Controlling Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.16595",
        "HTML": "https://arxiv.org/html/2409.16595v3",
        "PDF": "https://arxiv.org/pdf/2409.16595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a robotic system for sensors and control, emphasizing data acquisition for robotics applications, not LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/m-dayani/robo-platform"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17469",
      "abstract": "Reinforcement Learning (RL) has the potential to enable extreme off-road mobility by circumventing complex kinodynamic modeling, planning, and control by simulated end-to-end trial-and-error learning experiences. However, most RL methods are sample-inefficient when training in a large amount of manually designed simulation environments and struggle at generalizing to the real world. To address these issues, we introduce VertiSelector (VS), an automatic curriculum learning framework designed to enhance learning efficiency and generalization by selectively sampling training terrain. VS prioritizes vertically challenging terrain with higher Temporal Difference (TD) errors when revisited, thereby allowing robots to learn at the edge of their evolving capabilities. By dynamically adjusting the sampling focus, VS significantly boosts sample efficiency and generalization within the VW-Chrono simulator built on the Chrono multi-physics engine. Furthermore, we provide simulation and physical results using VS on a Verti-4-Wheeler platform. These results demonstrate that VS can achieve 23.08% improvement in terms of success rate by efficiently sampling during training and robustly generalizing to the real world.",
      "authors": [
        "Tong Xu",
        "Chenhui Pan",
        "and Xuesu Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T02:02:58+00:00",
          "link": "https://arxiv.org/abs/2409.17469v1",
          "size": "4076kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T02:06:45+00:00",
          "link": "https://arxiv.org/abs/2409.17469v2",
          "size": "3486kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T15:06:28+00:00",
          "link": "https://arxiv.org/abs/2409.17469v3",
          "size": "3487kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T15:33:49+00:00",
          "link": "https://arxiv.org/abs/2409.17469v4",
          "size": "3487kb",
          "version": "v4"
        }
      ],
      "title": "VertiSelector: Automatic Curriculum Learning for Wheeled Mobility on Vertically Challenging Terrain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17469",
        "HTML": "https://arxiv.org/html/2409.17469v4",
        "PDF": "https://arxiv.org/pdf/2409.17469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an RL framework, VertiSelector, for curriculum learning in robotics, which does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.19936",
      "abstract": "This paper introduces a novel control strategy for agile spacecraft attitude control, addressing reaction wheel-related input and state constraints. An optimal-decay control Lyapunov function quadratic program stabilizes the system and mitigates chattering at low sampling frequencies, while control barrier functions enforce hard state constraints. Numerical simulations validate the method's practicality and efficiency for real-time agile spacecraft attitude control.",
      "authors": [
        "Milad Alipour Shahraki and Laurent Lessard"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T04:27:58+00:00",
          "link": "https://arxiv.org/abs/2409.19936v1",
          "size": "172kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:31:36+00:00",
          "link": "https://arxiv.org/abs/2409.19936v2",
          "size": "162kb",
          "version": "v2"
        }
      ],
      "title": "Spacecraft Attitude Control Under Reaction Wheel Constraints Using Control Lyapunov and Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.19936",
        "HTML": "https://arxiv.org/html/2409.19936v2",
        "PDF": "https://arxiv.org/pdf/2409.19936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a control strategy for spacecraft attitude under reaction wheel constraints, which does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.01772",
      "abstract": "LLMs are ideal for decision-making thanks to their ability to reason over long contexts. However, challenges arise when processing speech transcripts that describe complex scenarios, as they are verbose and include repetition, hedging, and vagueness. E.g., during a company's earnings call, an executive might project a positive revenue outlook to reassure investors, despite uncertainty regarding future earnings. It is crucial for LLMs to incorporate this uncertainty systematically when making decisions. In this paper, we introduce \\textsc{DeFine}, a modular framework that constructs probabilistic factor profiles from complex scenarios. It then integrates these profiles with analogical reasoning, leveraging insights from similar past experiences to guide LLMs in making critical decisions in new situations. Our framework separates the tasks of quantifying uncertainty and incorporating it into LLM decision-making. This approach is particularly useful in areas such as consulting and financial deliberation, where making decisions under uncertainty is vital.",
      "authors": [
        "Yebowen Hu",
        "Xiaoyang Wang",
        "Wenlin Yao",
        "Yiming Lu",
        "Daoan Zhang",
        "Hassan Foroosh",
        "Dong Yu",
        "Fei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T17:29:34+00:00",
          "link": "https://arxiv.org/abs/2410.01772v1",
          "size": "1476kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:58:50+00:00",
          "link": "https://arxiv.org/abs/2410.01772v2",
          "size": "335kb",
          "version": "v2"
        }
      ],
      "title": "DeFine: Decision-Making with Analogical Reasoning over Factor Profiles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01772",
        "HTML": "https://arxiv.org/html/2410.01772v2",
        "PDF": "https://arxiv.org/pdf/2410.01772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for decision-making using analogical reasoning over factor profiles. It focuses on guiding LLM decisions rather than training data processing for LLMs."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.05527",
      "abstract": "Restless multi-armed bandits (RMAB) has been widely used to model constrained sequential decision making problems, where the state of each restless arm evolves according to a Markov chain and each state transition generates a scalar reward. However, the success of RMAB crucially relies on the availability and quality of reward signals. Unfortunately, specifying an exact reward function in practice can be challenging and even infeasible. In this paper, we introduce Pref-RMAB, a new RMAB model in the presence of \\textit{preference} signals, where the decision maker only observes pairwise preference feedback rather than scalar reward from the activated arms at each decision epoch. Preference feedback, however, arguably contains less information than the scalar reward, which makes Pref-RMAB seemingly more difficult. To address this challenge, we present a direct online preference learning (DOPL) algorithm for Pref-RMAB to efficiently explore the unknown environments, adaptively collect preference data in an online manner, and directly leverage the preference feedback for decision-makings. We prove that DOPL yields a sublinear regret. To our best knowledge, this is the first algorithm to ensure $\\tilde{\\mathcal{O}}(\\sqrt{T\\ln T})$ regret for RMAB with preference feedback. Experimental results further demonstrate the effectiveness of DOPL.",
      "authors": [
        "Guojun Xiong",
        "Ujwal Dinesha",
        "Debajoy Mukherjee",
        "Jian Li",
        "Srinivas Shakkottai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T22:14:20+00:00",
          "link": "https://arxiv.org/abs/2410.05527v1",
          "size": "6268kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T22:26:12+00:00",
          "link": "https://arxiv.org/abs/2410.05527v2",
          "size": "6260kb",
          "version": "v2"
        }
      ],
      "title": "DOPL: Direct Online Preference Learning for Restless Bandits with Preference Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05527",
        "HTML": "https://arxiv.org/html/2410.05527v2",
        "PDF": "https://arxiv.org/pdf/2410.05527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a preference learning algorithm for restless multi-armed bandits, not involving LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Multi-Armed Bandits",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08589",
      "abstract": "Sparse Mixture-of-Experts (SMoE) models represent a significant advancement in large language model (LLM) development through their efficient parameter utilization. These models achieve substantial performance improvements at reduced inference costs. However, the deployment of SMoE models faces constraints from extensive memory requirements of expert components in resource-limited environments. To address these limitations, this paper introduces Hierarchical Clustering for Sparsely activated Mixture of Experts (HC-SMoE), a task-agnostic expert merging framework for parameter reduction without retraining. HC-SMoE introduces a novel hierarchical clustering approach based on expert outputs to ensure merging robustness independent of routing decisions. The proposed output-based clustering method enables effective capture of functional relationships between experts for large-scale architectures. We provide theoretical analysis and comprehensive evaluations across multiple zero-shot language tasks to demonstrate HC-SMoE's effectiveness in state-of-the-art models including Qwen and Mixtral. The experimental results validate HC-SMoE's superior performance and practical applicability for real-world deployments.",
      "authors": [
        "I-Chun Chen",
        "Hsu-Shen Liu",
        "Wei-Fang Sun",
        "Chen-Hao Chao",
        "Yen-Chang Hsu",
        "Chun-Yi Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T07:36:14+00:00",
          "link": "https://arxiv.org/abs/2410.08589v1",
          "size": "6291kb",
          "version": "v1"
        },
        {
          "date": "2025-02-01T10:30:17+00:00",
          "link": "https://arxiv.org/abs/2410.08589v2",
          "size": "6684kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T17:20:34+00:00",
          "link": "https://arxiv.org/abs/2410.08589v3",
          "size": "7004kb",
          "version": "v3"
        }
      ],
      "title": "Retraining-Free Merging of Sparse MoE via Hierarchical Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08589",
        "HTML": "https://arxiv.org/html/2410.08589v3",
        "PDF": "https://arxiv.org/pdf/2410.08589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses merging techniques for Sparse Mixture-of-Experts models to reduce parameter sizes without retraining. It focuses on model architecture and deployment rather than on training data processing operations."
      },
      "tasks": [
        "Clustering",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Mixture-of-Experts"
      ],
      "repo_urls": [
        "https://github.com/wazenmai/hc-smoe"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12774",
      "abstract": "The success of multi-task learning can depend heavily on which tasks are grouped together. Naively grouping all tasks or a random set of tasks can result in negative transfer, with the multi-task models performing worse than single-task models. Though many efforts have been made to identify task groupings and to measure the relatedness among different tasks, it remains a challenging research topic to define a metric to identify the best task grouping out of a pool of many potential task combinations. We propose a metric of task relatedness based on task difficulty measured by pointwise V-usable information (PVI). PVI is a recently proposed metric to estimate how much usable information a dataset contains given a model. We hypothesize that tasks with not statistically different PVI estimates are similar enough to benefit from the joint learning process. We conduct comprehensive experiments to evaluate the feasibility of this metric for task grouping on 15 NLP datasets in the general, biomedical, and clinical domains. We compare the results of the joint learners against single learners, existing baseline methods, and recent large language models, including Llama 2 and GPT-4. The results show that by grouping tasks with similar PVI estimates, the joint learners yielded competitive results with fewer total parameters, with consistent performance across domains.",
      "authors": [
        "Yingya Li",
        "Timothy Miller",
        "Steven Bethard",
        "Guergana Savova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T17:49:45+00:00",
          "link": "https://arxiv.org/abs/2410.12774v1",
          "size": "104kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:27:11+00:00",
          "link": "https://arxiv.org/abs/2410.12774v2",
          "size": "541kb",
          "version": "v2"
        }
      ],
      "title": "Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12774",
        "PDF": "https://arxiv.org/pdf/2410.12774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses identifying task groupings for multi-task learning using a metric related to task difficulty. While it involves considerations for datasets in multi-task settings, the main focus isn't on LLM training data processing or improvements in data quality."
      },
      "tasks": [
        "Multi-Task Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.14062",
      "abstract": "With a warming planet, tropical regions are expected to experience the brunt of climate change, with more intense and more volatile rainfall events. Currently, state-of-the-art numerical weather prediction (NWP) models are known to struggle to produce skillful rainfall forecasts in tropical regions of Africa. There is thus a pressing need for improved rainfall forecasting in these regions. Over the last decade or so, the increased availability of large-scale meteorological datasets and the development of powerful machine learning models have opened up new opportunities for data-driven weather forecasting. Focusing on Ghana in this study, we use these tools to develop two U-Net convolutional neural network (CNN) models, to predict 24h rainfall at 12h and 30h lead-time. The models were trained using data from the ERA5 reanalysis dataset, and the GPM-IMERG dataset. A special attention was paid to interpretability. We developed a novel statistical methodology that allowed us to probe the relative importance of the meteorological variables input in our model, offering useful insights into the factors that drive precipitation in the Ghana region. Empirically, we found that our 12h lead-time model has performances that match, and in some accounts are better than the 18h lead-time forecasts produced by the ECMWF (as available in the TIGGE dataset). We also found that combining our data-driven model with classical NWP further improves forecast accuracy.",
      "authors": [
        "Indrajit Kalita",
        "Lucia Vilallonga",
        "Yves Atchade"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T22:07:53+00:00",
          "link": "https://arxiv.org/abs/2410.14062v1",
          "size": "6008kb",
          "version": "v1"
        },
        {
          "date": "2024-10-22T17:23:30+00:00",
          "link": "https://arxiv.org/abs/2410.14062v2",
          "size": "6008kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T22:30:36+00:00",
          "link": "https://arxiv.org/abs/2410.14062v3",
          "size": "17085kb",
          "version": "v3"
        }
      ],
      "title": "Data-driven rainfall prediction at a regional scale: a case study with Ghana",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14062",
        "HTML": "https://arxiv.org/html/2410.14062v3",
        "PDF": "https://arxiv.org/pdf/2410.14062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with weather forecasting models and their performance in predicting rainfall for a specific region, using existing meteorological datasets. There is no focus on LLM training data processing."
      },
      "tasks": [
        "Weather Forecasting"
      ],
      "repo_urls": [
        "https://github.com/indrakalita/RainfallForecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.14987",
      "abstract": "We introduce SeaS, a unified industrial generative model for automatically creating diverse anomalies, authentic normal products, and precise anomaly masks. While extensive research exists, most efforts either focus on specific tasks, i.e., anomalies or normal products only, or require separate models for each anomaly type. Consequently, prior methods either offer limited generative capability or depend on a vast array of anomaly-specific models. We demonstrate that U-Net's differentiated learning ability captures the distinct visual traits of slightly-varied normal products and diverse anomalies, enabling us to construct a unified model for all tasks. Specifically, we first introduce an Unbalanced Abnormal (UA) Text Prompt, comprising one normal token and multiple anomaly tokens. More importantly, our Decoupled Anomaly Alignment (DA) loss decouples anomaly attributes and binds them to distinct anomaly tokens of UA, enabling SeaS to create unseen anomalies by recombining these attributes. Furthermore, our Normal-image Alignment (NA) loss aligns the normal token to normal patterns, making generated normal products globally consistent and locally varied. Finally, SeaS produces accurate anomaly masks by fusing discriminative U-Net features with high-resolution VAE features. SeaS sets a new benchmark for industrial generation, significantly enhancing downstream applications, with average improvements of $+8.66\\%$ pixel-level AP for synthesis-based AD approaches, $+1.10\\%$ image-level AP for unsupervised AD methods, and $+12.79\\%$ IoU for supervised segmentation models. Code is available at \\href{https://github.com/HUST-SLOW/SeaS}{https://github.com/HUST-SLOW/SeaS}.",
      "authors": [
        "Zhewei Dai",
        "Shilei Zeng",
        "Haotian Liu",
        "Xurui Li",
        "Feng Xue",
        "Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-19T05:37:11+00:00",
          "link": "https://arxiv.org/abs/2410.14987v1",
          "size": "25767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T11:29:27+00:00",
          "link": "https://arxiv.org/abs/2410.14987v2",
          "size": "25327kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T12:05:35+00:00",
          "link": "https://arxiv.org/abs/2410.14987v3",
          "size": "25328kb",
          "version": "v3"
        }
      ],
      "title": "SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14987",
        "HTML": "https://arxiv.org/html/2410.14987v3",
        "PDF": "https://arxiv.org/pdf/2410.14987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for generating industrial anomaly images using generative models. It does not address LLM training data processing for pretraining or fine-tuning."
      },
      "datasets": [
        {
          "dataset_name": "HUST-SLOW/SeaS",
          "downloads": "27",
          "likes": "0",
          "link": "https://huggingface.co/datasets/HUST-SLOW/SeaS"
        }
      ],
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/HUST-SLOW/SeaS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17910",
      "abstract": "Advanced Persistent Threats (APTs) represent sophisticated cyberattacks characterized by their ability to remain undetected within the victim system for extended periods, aiming to exfiltrate sensitive data or disrupt operations. Existing detection approaches often struggle to effectively identify these complex threats, construct the attack chain for defense facilitation, or resist adversarial attacks. To overcome these challenges, we propose Slot, an advanced APT detection approach based on provenance graphs and graph reinforcement learning. Slot excels in uncovering multi-level hidden relationships, such as causal, contextual, and indirect connections, among system behaviors through provenance graph mining. By pioneering the integration of graph reinforcement learning, Slot dynamically adapts to new user activities and evolving attack strategies, enhancing its resilience against adversarial attacks. Additionally, Slot automatically constructs the attack chain according to detected attacks with clustering algorithms, providing precise identification of attack paths and facilitating the development of defense strategies. Evaluations with real-world datasets demonstrate Slot's outstanding accuracy, efficiency, adaptability, and robustness in APT detection, with most metrics surpassing state-of-the-art methods. Additionally, case studies conducted to assess Slot's effectiveness in supporting APT defense further establish it as a practical and reliable tool for cybersecurity protection.",
      "authors": [
        "Wei Qiao",
        "Yebo Feng",
        "Teng Li",
        "Zhuo Ma",
        "Yulong Shen",
        "JianFeng Ma",
        "Yang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T14:28:32+00:00",
          "link": "https://arxiv.org/abs/2410.17910v1",
          "size": "11159kb",
          "version": "v1"
        },
        {
          "date": "2025-01-11T10:04:25+00:00",
          "link": "https://arxiv.org/abs/2410.17910v2",
          "size": "12184kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T07:41:06+00:00",
          "link": "https://arxiv.org/abs/2410.17910v3",
          "size": "2808kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T09:09:55+00:00",
          "link": "https://arxiv.org/abs/2410.17910v4",
          "size": "2790kb",
          "version": "v4"
        }
      ],
      "title": "Slot: Provenance-Driven APT Detection through Graph Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17910",
        "HTML": "https://arxiv.org/html/2410.17910v4",
        "PDF": "https://arxiv.org/pdf/2410.17910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using graph reinforcement learning for detecting cybersecurity threats, specifically Advanced Persistent Threats (APTs), not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20625",
      "abstract": "Low-rank adaption (LoRA) is a widely used parameter-efficient finetuning method for LLM that reduces memory requirements. However, current LoRA optimizers lack transformation invariance, meaning the actual updates to the weights depends on how the two LoRA factors are scaled or rotated. This deficiency leads to inefficient learning and sub-optimal solutions in practice. This paper introduces LoRA-RITE, a novel adaptive matrix preconditioning method for LoRA optimization, which can achieve transformation invariance and remain computationally efficient. We provide theoretical analysis to demonstrate the benefit of our method and conduct experiments on various LLM tasks with different models including Gemma 2B, 7B, and mT5-XXL. The results demonstrate consistent improvements against existing optimizers. For example, replacing Adam with LoRA-RITE during LoRA fine-tuning of Gemma-2B yielded 4.6\\% accuracy gain on Super-Natural Instructions and 3.5\\% accuracy gain across other four LLM benchmarks (HellaSwag, ArcChallenge, GSM8K, OpenBookQA).",
      "authors": [
        "Jui-Nan Yen",
        "Si Si",
        "Zhao Meng",
        "Felix Yu",
        "Sai Surya Duvvuri",
        "Inderjit S. Dhillon",
        "Cho-Jui Hsieh",
        "Sanjiv Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-27T22:57:12+00:00",
          "link": "https://arxiv.org/abs/2410.20625v1",
          "size": "553kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:18:50+00:00",
          "link": "https://arxiv.org/abs/2410.20625v2",
          "size": "732kb",
          "version": "v2"
        }
      ],
      "title": "LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20625",
        "HTML": "https://arxiv.org/html/2410.20625v2",
        "PDF": "https://arxiv.org/pdf/2410.20625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper deals with finetuning (LoRA optimization) techniques for LLMs, it focuses on optimization methods rather than data processing. Thus, it touches on LLM fine-tuning but does not focus on training data processing."
      },
      "tasks": [
        "GSM8K",
        "HellaSwag"
      ],
      "repo_urls": [
        "https://github.com/gkevinyen5418/LoRA-RITE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20788",
      "abstract": "Prompt optimization is essential for effective utilization of large language models (LLMs) across diverse tasks. While existing optimization methods are effective in optimizing short prompts, they struggle with longer, more complex ones, often risking information loss and being sensitive to small perturbations. To address these challenges, we propose SCULPT (Systematic Tuning of Long Prompts), a framework that treats prompt optimization as a hierarchical tree refinement problem. SCULPT represents prompts as tree structures, enabling targeted modifications while preserving contextual integrity. It employs a Critic-Actor framework that generates reflections and applies actions to refine the prompt. Evaluations demonstrate SCULPT's effectiveness on long prompts, its robustness to adversarial perturbations, and its ability to generate high-performing prompts even without any initial human-written prompt. Compared to existing state of the art methods, SCULPT consistently improves LLM performance by preserving essential task information while applying structured refinements. Both qualitative and quantitative analyses show that SCULPT produces more stable and interpretable prompt modifications, ensuring better generalization across tasks.",
      "authors": [
        "Shanu Kumar",
        "Akhila Yesantarao Venkata",
        "Shubhanshu Khandelwal",
        "Bishal Santra",
        "Parag Agrawal",
        "Manish Gupta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T07:10:10+00:00",
          "link": "https://arxiv.org/abs/2410.20788v1",
          "size": "4330kb",
          "version": "v1"
        },
        {
          "date": "2025-03-23T16:06:37+00:00",
          "link": "https://arxiv.org/abs/2410.20788v2",
          "size": "3836kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T19:32:23+00:00",
          "link": "https://arxiv.org/abs/2410.20788v3",
          "size": "3402kb",
          "version": "v3"
        }
      ],
      "title": "SCULPT: Systematic Tuning of Long Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20788",
        "PDF": "https://arxiv.org/pdf/2410.20788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt optimization for LLMs, treating it as a hierarchical refinement problem. It indirectly relates to data processing by refining prompt inputs but the main focus is on prompt engineering, not on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.23114",
      "abstract": "Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, we design a unified framework to measure the object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to evaluate hallucinations via (object, relation, object) triplets extracted from LVLMs' responses, making it easily generalizable to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. With comprehensive evaluations on Tri-HE, we observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple training-free approach that effectively mitigates hallucinations for LVLMs. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.",
      "authors": [
        "Junjie Wu",
        "Tsz Ting Chung",
        "Kai Chen",
        "Dit-Yan Yeung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T15:25:06+00:00",
          "link": "https://arxiv.org/abs/2410.23114v1",
          "size": "7529kb",
          "version": "v1"
        },
        {
          "date": "2024-11-03T09:35:12+00:00",
          "link": "https://arxiv.org/abs/2410.23114v2",
          "size": "4121kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T14:02:12+00:00",
          "link": "https://arxiv.org/abs/2410.23114v3",
          "size": "4136kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T13:18:06+00:00",
          "link": "https://arxiv.org/abs/2410.23114v4",
          "size": "4138kb",
          "version": "v4"
        }
      ],
      "title": "Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23114",
        "HTML": "https://arxiv.org/html/2410.23114v4",
        "PDF": "https://arxiv.org/pdf/2410.23114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hallucination evaluation for large vision-language models, specifically addressing object and relation hallucinations. It does not relate to training data processing for LLMs."
      },
      "tasks": [
        "Hallucination",
        "Hallucination Evaluation",
        "Object",
        "Object Hallucination",
        "Relation",
        "Triplet"
      ],
      "repo_urls": [
        "https://github.com/wujunjie1998/tri-he"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02419",
      "abstract": "This paper introduces a dataset that is the result of a user study on the comprehensibility of explainable artificial intelligence (XAI) algorithms. The study participants were recruited from 149 candidates to form three groups representing experts in the domain of mycology (DE), students with a data science and visualization background (IT) and students from social sciences and humanities (SSH). The main part of the dataset contains 39 transcripts of interviews during which participants were asked to complete a series of tasks and questions related to the interpretation of explanations of decisions of a machine learning model trained to distinguish between edible and inedible mushrooms. The transcripts were complemented with additional data that includes visualizations of explanations presented to the user, results from thematic analysis, recommendations of improvements of explanations provided by the participants, and the initial survey results that allow to determine the domain knowledge of the participant and data analysis literacy. The transcripts were manually tagged to allow for automatic matching between the text and other data related to particular fragments. In the advent of the area of rapid development of XAI techniques, the need for a multidisciplinary qualitative evaluation of explainability is one of the emerging topics in the community. Our dataset allows not only to reproduce the study we conducted, but also to open a wide range of possibilities for the analysis of the material we gathered.",
      "authors": [
        "Szymon Bobek",
        "Paloma Koryci\\'nska",
        "Monika Krakowska",
        "Maciej Mozolewski",
        "Dorota Rak",
        "Magdalena Zych",
        "Magdalena W\\'ojcik",
        "Grzegorz J. Nalepa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T11:37:58+00:00",
          "link": "https://arxiv.org/abs/2411.02419v1",
          "size": "845kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:09:03+00:00",
          "link": "https://arxiv.org/abs/2411.02419v2",
          "size": "421kb",
          "version": "v2"
        }
      ],
      "title": "Dataset resulting from the user study on comprehensibility of explainable AI algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02419",
        "HTML": "https://arxiv.org/html/2411.02419v2",
        "PDF": "https://arxiv.org/pdf/2411.02419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset resulting from a user study on explainable AI, focusing on comprehensibility. While it involves dataset creation, it's more about explainability in AI rather than LLM training data processing."
      },
      "tasks": [
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.03294",
      "abstract": "We propose an object-centric recovery (OCR) framework to address the challenges of out-of-distribution (OOD) scenarios in visuomotor policy learning. Previous behavior cloning (BC) methods rely heavily on a large amount of labeled data coverage, failing in unfamiliar spatial states. Without relying on extra data collection, our approach learns a recovery policy constructed by an inverse policy inferred from the object keypoint manifold gradient in the original training data. The recovery policy serves as a simple add-on to any base visuomotor BC policy, agnostic to a specific method, guiding the system back towards the training distribution to ensure task success even in OOD situations. We demonstrate the effectiveness of our object-centric framework in both simulation and real robot experiments, achieving an improvement of 77.7\\% over the base policy in OOD. Furthermore, we show OCR's capacity to autonomously collect demonstrations for continual learning. Overall, we believe this framework represents a step toward improving the robustness of visuomotor policies in real-world settings.",
      "authors": [
        "George Jiayuan Gao",
        "Tianyu Li",
        "Nadia Figueroa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T17:41:14+00:00",
          "link": "https://arxiv.org/abs/2411.03294v1",
          "size": "9344kb",
          "version": "v1"
        },
        {
          "date": "2024-11-06T17:53:26+00:00",
          "link": "https://arxiv.org/abs/2411.03294v2",
          "size": "9344kb",
          "version": "v2"
        },
        {
          "date": "2025-03-20T18:03:15+00:00",
          "link": "https://arxiv.org/abs/2411.03294v3",
          "size": "4544kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T21:34:49+00:00",
          "link": "https://arxiv.org/abs/2411.03294v4",
          "size": "4544kb",
          "version": "v4"
        }
      ],
      "title": "Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy for Visuomotor Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03294",
        "HTML": "https://arxiv.org/html/2411.03294v4",
        "PDF": "https://arxiv.org/pdf/2411.03294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an object-centric recovery framework for out-of-distribution scenarios in visuomotor policy learning. It does not discuss training data processing for LLMs."
      },
      "tasks": [
        "Continual Learning",
        "Imitation Learning",
        "Object",
        "Optical Character Recognition (OCR)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.03407",
      "abstract": "The $q$-chorded $k$-cycle inequalities are a class of valid inequalities for the clique partitioning polytope. It is known that for $q \\in \\{2, \\tfrac{k-1}{2}\\}$, these inequalities induce facets of the clique partitioning polytope if and only if $k$ is odd. Here, we characterize such facets for arbitrary $k$ and $q$. More specifically, we prove that the $q$-chorded $k$-cycle inequalities induce facets of the clique partitioning polytope if and only if two conditions are satisfied: $k = 1$ mod $q$, and if $k=3q+1$ then $q=3$ or $q$ is even. This establishes the existence of many facets induced by $q$-chorded $k$-cycle inequalities beyond those previously known.",
      "authors": [
        "Jannik Irmai",
        "Lucas Fabian Naumann",
        "Bjoern Andres"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T18:42:46+00:00",
          "link": "https://arxiv.org/abs/2411.03407v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T16:42:12+00:00",
          "link": "https://arxiv.org/abs/2411.03407v2",
          "size": "20kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T09:13:05+00:00",
          "link": "https://arxiv.org/abs/2411.03407v3",
          "size": "22kb",
          "version": "v3"
        }
      ],
      "title": "Chorded cycle facets of the clique partitioning polytope",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03407",
        "HTML": "https://arxiv.org/html/2411.03407v3",
        "PDF": "https://arxiv.org/pdf/2411.03407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is related to the clique partitioning polytope and addresses mathematical inequalities. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.04580",
      "abstract": "MuZero has achieved superhuman performance in various games by using a dynamics network to predict the environment dynamics for planning, without relying on simulators. However, the latent states learned by the dynamics network make its planning process opaque. This paper aims to demystify MuZero's model by interpreting the learned latent states. We incorporate observation reconstruction and state consistency into MuZero training and conduct an in-depth analysis to evaluate latent states across two board games: 9x9 Go and Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our findings reveal that while the dynamics network becomes less accurate over longer simulations, MuZero still performs effectively by using planning to correct errors. Our experiments also show that the dynamics network learns better latent states in board games than in Atari games. These insights contribute to a better understanding of MuZero and offer directions for future research to improve the performance, robustness, and interpretability of the MuZero algorithm. The code and data are available at https://rlg.iis.sinica.edu.tw/papers/demystifying-muzero-planning.",
      "authors": [
        "Hung Guei",
        "Yan-Ru Ju",
        "Wei-Yu Chen",
        "Ti-Rong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T10:06:23+00:00",
          "link": "https://arxiv.org/abs/2411.04580v1",
          "size": "3265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T04:32:51+00:00",
          "link": "https://arxiv.org/abs/2411.04580v2",
          "size": "16270kb",
          "version": "v2"
        }
      ],
      "title": "Demystifying MuZero Planning: Interpreting the Learned Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04580",
        "HTML": "https://arxiv.org/html/2411.04580v2",
        "PDF": "https://arxiv.org/pdf/2411.04580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on interpreting the learned latent states of MuZero, a game-playing model, which does not involve LLM training data processing."
      },
      "tasks": [
        "Atari Games",
        "Board Games",
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.04718",
      "abstract": "We consider the problem of counting the copies of a length-$k$ pattern $\\sigma$ in a sequence $f \\colon [n] \\to \\mathbb{R}$, where a copy is a subset of indices $i_1 < \\ldots < i_k \\in [n]$ such that $f(i_j) < f(i_\\ell)$ if and only if $\\sigma(j) < \\sigma(\\ell)$. This problem is motivated by a range of connections and applications in ranking, nonparametric statistics, combinatorics, and fine-grained complexity, especially when $k$ is a small fixed constant.\n  Recent advances have significantly improved our understanding of counting and detecting patterns. Guillemot and Marx [2014] obtained an $O(n)$ time algorithm for the detection variant for any fixed $k$. Their proof has laid the foundations for the discovery of the twin-width, a concept that has notably advanced parameterized complexity in recent years. Counting, in contrast, is harder: it has a conditional lower bound of $n^{\\Omega(k / \\log k)}$ [Berendsohn, Kozma, and Marx, 2019] and is expected to be polynomially harder than detection as early as $k = 4$, given its equivalence to counting $4$-cycles in graphs [Dudek and Gawrychowski, 2020].\n  In this work, we design a deterministic near-linear time $(1+\\varepsilon)$-approximation algorithm for counting $\\sigma$-copies in $f$ for all $k \\leq 5$. Combined with the conditional lower bound for $k=4$, this establishes the first known separation between approximate and exact pattern counting. Interestingly, our algorithm leverages the Birg\\'e decomposition -- a sublinear tool for monotone distributions widely used in distribution testing -- which, to our knowledge, has not been used in a pattern counting context before. Along the way, we develop a near-optimal data structure for $(1+\\varepsilon)$-approximate increasing pair range queries in the plane, which exhibits a conditional separation from the exact case and may be of independent interest.",
      "authors": [
        "Omri Ben-Eliezer and Slobodan Mitrovi\\'c and Pranjal Srivastava"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T13:58:11+00:00",
          "link": "https://arxiv.org/abs/2411.04718v1",
          "size": "564kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:55:04+00:00",
          "link": "https://arxiv.org/abs/2411.04718v2",
          "size": "299kb",
          "version": "v2"
        }
      ],
      "title": "Approximate counting of permutation patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04718",
        "HTML": "https://arxiv.org/html/2411.04718v2",
        "PDF": "https://arxiv.org/pdf/2411.04718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the problem of counting permutation patterns, which is related to combinatorics and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.06208",
      "abstract": "In the realm of large language models (LLMs), the ability of models to accurately follow instructions is paramount as more agents and applications leverage LLMs for construction, where the complexity of instructions are rapidly increasing. However, on the one hand, there is only a certain amount of complex instruction evaluation data; on the other hand, there are no dedicated algorithms to improve the ability to follow complex instructions. To this end, this paper introduces TRACE, a benchmark for improving and evaluating the complex instructionfollowing ability, which consists of 120K training data and 1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference Optimization) alignment method which takes both input and output preference pairs into consideration, where LLMs not only rapidly align with response preferences but also meticulously explore the instruction preferences. Extensive experiments on both in-domain and outof-domain datasets confirm the effectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and 6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively.",
      "authors": [
        "Xinghua Zhang",
        "Haiyang Yu",
        "Cheng Fu",
        "Fei Huang",
        "Yongbin Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T15:12:43+00:00",
          "link": "https://arxiv.org/abs/2411.06208v1",
          "size": "1515kb",
          "version": "v1"
        },
        {
          "date": "2024-11-27T07:29:59+00:00",
          "link": "https://arxiv.org/abs/2411.06208v2",
          "size": "585kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:39:11+00:00",
          "link": "https://arxiv.org/abs/2411.06208v3",
          "size": "581kb",
          "version": "v3"
        }
      ],
      "title": "IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06208",
        "HTML": "https://arxiv.org/html/2411.06208v3",
        "PDF": "https://arxiv.org/pdf/2411.06208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces TRACE, a benchmark for instruction-following, and proposes the IOPO method to improve instruction-following ability in LLMs. While it involves instruction data, the main focus is on alignment optimization and evaluation rather than data processing."
      },
      "tasks": [
        "Instruction Following"
      ],
      "repo_urls": [
        "https://github.com/alibabaresearch/damo-convai"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06796",
      "abstract": "With the rising demand for code quality assurance, developers are not only utilizing existing static code checkers but also seeking custom checkers to satisfy their specific needs. Nowadays, various code-checking frameworks provide extensive checker customization interfaces to meet this need. However, both the abstract checking logic and the complex API usage of large-scale checker frameworks make this task challenging. To this end, automated code checker generation is anticipated to ease the burden of checker development. In this paper, we propose AutoChecker, an innovative LLM-powered approach that can write code checkers automatically based on only a rule description and a test suite. To achieve comprehensive checking logic, AutoChecker incrementally updates the checker's logic by focusing on solving one selected case each time. To obtain precise API knowledge, during each iteration, it leverages fine-grained logic-guided API-context retrieval, where it first decomposes the checking logic into a series of sub-operations and then retrieves checker-related API-contexts for each sub-operation. For evaluation, we apply AutoChecker, five baselines, and three ablation methods using multiple LLMs to generate checkers for 20 randomly selected PMD rules. Experimental results show that AutoChecker significantly outperforms others across all effectiveness metrics, with an average test pass rate of 82.28%. Additionally, the checkers generated by AutoChecker can be successfully applied to real-world projects, matching the performance of official checkers.",
      "authors": [
        "Jun Liu",
        "Yuanyuan Xie",
        "Jiwei Yan",
        "Jinhao Huang",
        "Jun Yan",
        "and Jian Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T08:50:24+00:00",
          "link": "https://arxiv.org/abs/2411.06796v1",
          "size": "1807kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T15:40:38+00:00",
          "link": "https://arxiv.org/abs/2411.06796v2",
          "size": "1579kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T12:33:32+00:00",
          "link": "https://arxiv.org/abs/2411.06796v3",
          "size": "1047kb",
          "version": "v3"
        }
      ],
      "title": "Write Your Own CodeChecker: An Automated Test-Driven Checker Development Approach with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06796",
        "HTML": "https://arxiv.org/html/2411.06796v3",
        "PDF": "https://arxiv.org/pdf/2411.06796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "AutoChecker automates code checker development using LLMs, focusing on checker logic and API usage. It partially relates to LLMs as it uses LLMs in the process, but it does not directly address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09502",
      "abstract": "Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise. While people observe that some noises are ``golden noises'' that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those golden noises. To learn golden noises for diffusion sampling, we mainly make three contributions in this paper. First, we identify a new concept termed the \\textit{noise prompt}, which aims at turning a random Gaussian noise into a golden noise by adding a small desirable perturbation derived from the text prompt. Following the concept, we first formulate the \\textit{noise prompt learning} framework that systematically learns ``prompted'' golden noise associated with a text prompt for diffusion models. Second, we design a noise prompt data collection pipeline and collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains 100k pairs of random noises and golden noises with the associated text prompts. With the prepared NPD as the training dataset, we trained a small \\textit{noise prompt network}~(NPNet) that can directly learn to transform a random noise into a golden noise. The learned golden noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt. Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a golden noise instead of a random noise without accessing the original pipeline.",
      "authors": [
        "Zikai Zhou and Shitong Shao and Lichen Bai and Shufei Zhang and Zhiqiang Xu and Bo Han and Zeke Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T15:13:13+00:00",
          "link": "https://arxiv.org/abs/2411.09502v1",
          "size": "40405kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T10:39:16+00:00",
          "link": "https://arxiv.org/abs/2411.09502v2",
          "size": "40405kb",
          "version": "v2"
        },
        {
          "date": "2024-12-15T02:48:48+00:00",
          "link": "https://arxiv.org/abs/2411.09502v3",
          "size": "40404kb",
          "version": "v3"
        },
        {
          "date": "2025-01-18T04:40:28+00:00",
          "link": "https://arxiv.org/abs/2411.09502v4",
          "size": "37549kb",
          "version": "v4"
        },
        {
          "date": "2025-07-17T03:40:22+00:00",
          "link": "https://arxiv.org/abs/2411.09502v5",
          "size": "70080kb",
          "version": "v5"
        }
      ],
      "title": "Golden Noise for Diffusion Models: A Learning Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09502",
        "HTML": "https://arxiv.org/html/2411.09502v5",
        "PDF": "https://arxiv.org/pdf/2411.09502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a noise prompt data collection pipeline and a dataset for diffusion models, closely related to data processing. However, its main focus is on text-to-image synthesis rather than LLM training data processing."
      },
      "models": [
        {
          "model_path": "Klayand/GoldenNoiseModel",
          "downloads": "0",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Klayand/GoldenNoiseModel"
        },
        {
          "model_path": "syrinenoamen/stable-diffusion_xl_initial_noise_loader",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/syrinenoamen/stable-diffusion_xl_initial_noise_loader"
        }
      ],
      "tasks": [
        "Prompt Learning"
      ],
      "repo_urls": [
        "https://github.com/xie-lab-ml/golden-noise-for-diffusion-models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.14245",
      "abstract": "In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.",
      "authors": [
        "Samer Afach",
        "Benjamin Marsh",
        "Enrico Rubboli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T15:52:12+00:00",
          "link": "https://arxiv.org/abs/2411.14245v1",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T11:53:59+00:00",
          "link": "https://arxiv.org/abs/2411.14245v2",
          "size": "129kb",
          "version": "v2"
        }
      ],
      "title": "Pulsar Consensus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14245",
        "HTML": "https://arxiv.org/html/2411.14245v2",
        "PDF": "https://arxiv.org/pdf/2411.14245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the Pulsar proof of stake consensus for blockchain systems, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.15014",
      "abstract": "Federated reinforcement learning (FedRL) enables multiple agents to collaboratively learn a policy without sharing their local trajectories collected during agent-environment interactions. However, in practice, the environments faced by different agents are often heterogeneous, leading to poor performance by the single policy learned by existing FedRL algorithms on individual agents. In this paper, we take a further step and introduce a \\emph{personalized} FedRL framework (PFedRL) by taking advantage of possibly shared common structure among agents in heterogeneous environments. Specifically, we develop a class of PFedRL algorithms named PFedRL-Rep that learns (1) a shared feature representation collaboratively among all agents, and (2) an agent-specific weight vector personalized to its local environment. We analyze the convergence of PFedTD-Rep, a particular instance of the framework with temporal difference (TD) learning and linear representations. To the best of our knowledge, we are the first to prove a linear convergence speedup with respect to the number of agents in the PFedRL setting. To achieve this, we show that PFedTD-Rep is an example of the federated two-timescale stochastic approximation with Markovian noise. Experimental results demonstrate that PFedTD-Rep, along with an extension to the control setting based on deep Q-networks (DQN), not only improve learning in heterogeneous settings, but also provide better generalization to new environments.",
      "authors": [
        "Guojun Xiong",
        "Shufan Wang",
        "Daniel Jiang",
        "Jian Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T15:42:43+00:00",
          "link": "https://arxiv.org/abs/2411.15014v1",
          "size": "1615kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:34:45+00:00",
          "link": "https://arxiv.org/abs/2411.15014v2",
          "size": "1725kb",
          "version": "v2"
        }
      ],
      "title": "On the Linear Speedup of Personalized Federated Reinforcement Learning with Shared Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15014",
        "HTML": "https://arxiv.org/html/2411.15014v2",
        "PDF": "https://arxiv.org/pdf/2411.15014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores personalized federated reinforcement learning and does not focus on LLM training data processing or relevant data operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.01287",
      "abstract": "This paper introduces linear approximants tailored to handle point-valued noisy data. A key innovation lies in determining the approximant coefficients by solving an optimization problem aimed at minimizing the noise variance. The study addresses the general case, allowing for noise correlation among data with a non-uniform distribution. In fact, we show that the subdivision rules proposed in [S. L\\'opez-Ure\\~na and D. F. Y\\'a\\~nez, J. Sci. Comput., 100(1) (2024)] are optimal for uncorrelated noise with non-uniform variance. Numerical experiments are provided to demonstrate the effectiveness of these optimal approximants compared to other ones.",
      "authors": [
        "Sergio L\\'opez Ure\\~na and Dionisio F. Y\\'a\\~nez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T08:59:29+00:00",
          "link": "https://arxiv.org/abs/2412.01287v1",
          "size": "49kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:37:51+00:00",
          "link": "https://arxiv.org/abs/2412.01287v2",
          "size": "50kb",
          "version": "v2"
        }
      ],
      "title": "Optimal linear approximants for noisy data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01287",
        "HTML": "https://arxiv.org/html/2412.01287v2",
        "PDF": "https://arxiv.org/pdf/2412.01287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with linear approximants for noisy data, focusing on minimizing noise variance in datasets, which is not relevant to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/serlou/optimal_denoising_rules"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02197",
      "abstract": "In real-world applications of image recognition tasks, such as human pose estimation, cameras often capture objects, like human bodies, at low resolutions. This scenario poses a challenge in extracting and leveraging multi-scale features, which is often essential for precise inference. To address this challenge, we propose a new attention mechanism, named cascaded multi-scale attention (CMSA), tailored for use in CNN-ViT hybrid architectures, to handle low-resolution inputs effectively. The design of CMSA enables the extraction and seamless integration of features across various scales without necessitating the downsampling of the input image or feature maps. This is achieved through a novel combination of grouped multi-head self-attention mechanisms with window-based local attention and cascaded fusion of multi-scale features over different scales. This architecture allows for the effective handling of features across different scales, enhancing the model's ability to perform tasks such as human pose estimation, head pose estimation, and more with low-resolution images. Our experimental results show that the proposed method outperforms existing state-of-the-art methods in these areas with fewer parameters, showcasing its potential for broad application in real-world scenarios where capturing high-resolution images is not feasible. Code is available at https://github.com/xyongLu/CMSA.",
      "authors": [
        "Xiangyong Lu",
        "Masanori Suganuma",
        "Takayuki Okatani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T06:23:19+00:00",
          "link": "https://arxiv.org/abs/2412.02197v1",
          "size": "1414kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:59:39+00:00",
          "link": "https://arxiv.org/abs/2412.02197v2",
          "size": "1769kb",
          "version": "v2"
        }
      ],
      "title": "Cascaded Multi-Scale Attention for Enhanced Multi-Scale Feature Extraction and Interaction with Low-Resolution Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02197",
        "HTML": "https://arxiv.org/html/2412.02197v2",
        "PDF": "https://arxiv.org/pdf/2412.02197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new attention mechanism for image recognition tasks involving low-resolution images, without addressing any aspect of LLM training data processing."
      },
      "tasks": [
        "Head Pose Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/xyonglu/cmsa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03558",
      "abstract": "This paper introduces MIDI, a novel paradigm for compositional 3D scene generation from a single image. Unlike existing methods that rely on reconstruction or retrieval techniques or recent approaches that employ multi-stage object-by-object generation, MIDI extends pre-trained image-to-3D object generation models to multi-instance diffusion models, enabling the simultaneous generation of multiple 3D instances with accurate spatial relationships and high generalizability. At its core, MIDI incorporates a novel multi-instance attention mechanism, that effectively captures inter-object interactions and spatial coherence directly within the generation process, without the need for complex multi-step processes. The method utilizes partial object images and global scene context as inputs, directly modeling object completion during 3D generation. During training, we effectively supervise the interactions between 3D instances using a limited amount of scene-level data, while incorporating single-object data for regularization, thereby maintaining the pre-trained generalization ability. MIDI demonstrates state-of-the-art performance in image-to-scene generation, validated through evaluations on synthetic data, real-world scene data, and stylized scene images generated by text-to-image diffusion models.",
      "authors": [
        "Zehuan Huang",
        "Yuan-Chen Guo",
        "Xingqiao An",
        "Yunhan Yang",
        "Yangguang Li",
        "Zi-Xin Zou",
        "Ding Liang",
        "Xihui Liu",
        "Yan-Pei Cao",
        "Lu Sheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T18:52:40+00:00",
          "link": "https://arxiv.org/abs/2412.03558v1",
          "size": "9357kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T03:43:35+00:00",
          "link": "https://arxiv.org/abs/2412.03558v2",
          "size": "10546kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:26:21+00:00",
          "link": "https://arxiv.org/abs/2412.03558v3",
          "size": "10033kb",
          "version": "v3"
        }
      ],
      "title": "MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03558",
        "HTML": "https://arxiv.org/html/2412.03558v3",
        "PDF": "https://arxiv.org/pdf/2412.03558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for 3D scene generation from single images, focusing on improving the generation process for 3D models, which is not related to LLM training data processing."
      },
      "models": [
        {
          "model_path": "VAST-AI/MIDI-3D",
          "downloads": "110",
          "likes": "48",
          "trending_score": "2.0",
          "link": "https://huggingface.co/VAST-AI/MIDI-3D"
        },
        {
          "model_path": "ameerazam08/MIDI-3D",
          "downloads": "1",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ameerazam08/MIDI-3D"
        }
      ],
      "datasets": [
        {
          "dataset_name": "huanngzh/3D-Front",
          "downloads": "3206",
          "likes": "6",
          "link": "https://huggingface.co/datasets/huanngzh/3D-Front"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Huang_MIDI_Multi-Instance_Diffusion_for_Single_Image_to_3D_Scene_Generation_CVPR_2025_paper.html",
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.04106",
      "abstract": "Training medical image segmentation models for rare yet clinically important imaging modalities is challenging due to the scarcity of annotated data, and manual mask annotations can be costly and labor-intensive to acquire. This paper investigates leveraging generative models to synthesize data, for training segmentation models for underrepresented modalities, particularly on annotation-scarce MRI. Concretely, our contributions are threefold: (i) we introduce MRGen-DB, a large-scale radiology image-text dataset comprising extensive samples with rich metadata, including modality labels, attributes, regions, and organs information, with a subset featuring pixel-wise mask annotations; (ii) we present MRGen, a diffusion-based data engine for controllable medical image synthesis, conditioned on text prompts and segmentation masks. MRGen can generate realistic images for diverse MRI modalities lacking mask annotations, facilitating segmentation training in low-source domains; (iii) extensive experiments across multiple modalities demonstrate that MRGen significantly improves segmentation performance on unannotated modalities by providing high-quality synthetic data. We believe that our method bridges a critical gap in medical image analysis, extending segmentation capabilities to scenarios that are challenging to acquire manual annotations. The codes, models, and data will be publicly available at https://haoningwu3639.github.io/MRGen/",
      "authors": [
        "Haoning Wu",
        "Ziheng Zhao",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T16:34:22+00:00",
          "link": "https://arxiv.org/abs/2412.04106v1",
          "size": "1952kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T11:59:46+00:00",
          "link": "https://arxiv.org/abs/2412.04106v2",
          "size": "2324kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T06:36:51+00:00",
          "link": "https://arxiv.org/abs/2412.04106v3",
          "size": "2040kb",
          "version": "v3"
        }
      ],
      "title": "MRGen: Segmentation Data Engine for Underrepresented MRI Modalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04106",
        "HTML": "https://arxiv.org/html/2412.04106v3",
        "PDF": "https://arxiv.org/pdf/2412.04106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using generative models to synthesize training data for medical image segmentation, including dataset creation (MRGen-DB), but it is tangentially relevant and focuses on medical imaging rather than LLM training data processing."
      },
      "models": [
        {
          "model_path": "haoningwu/MRGen",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/haoningwu/MRGen"
        }
      ],
      "datasets": [
        {
          "dataset_name": "haoningwu/MRGen-DB",
          "downloads": "241",
          "likes": "1",
          "link": "https://huggingface.co/datasets/haoningwu/MRGen-DB"
        }
      ],
      "tasks": [
        "Image Generation",
        "Image Segmentation",
        "Medical Image Generation",
        "Medical Image Segmentation",
        "MRI segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/haoningwu3639/MRGen"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04245",
      "abstract": "Despite extensive research since the community learned about adversarial examples 10 years ago, we still do not know how to train high-accuracy classifiers that are guaranteed to be robust to small perturbations of their inputs. Previous works often argued that this might be because no classifier exists that is robust and accurate at the same time. However, in computer vision this assumption does not match reality where humans are usually accurate and robust on most tasks of interest. We offer an alternative explanation and show that in certain settings robust generalization is only possible with unrealistically large amounts of data. Specifically, we find a setting where a robust classifier exists, it is easy to learn an accurate classifier, yet it requires an exponential amount of data to learn a robust classifier. Based on this theoretical result, we evaluate the influence of the amount of training data on datasets such as CIFAR-10. Our findings indicate that the amount of training data is the main factor determining the robust performance. Furthermore we show that there are low magnitude directions in the data which are useful for non-robust generalization but are not available for robust classifiers. We provide code at https://github.com/berndprach/IntriguingProperties.",
      "authors": [
        "Bernd Prach",
        "Christoph H. Lampert"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T15:27:39+00:00",
          "link": "https://arxiv.org/abs/2412.04245v1",
          "size": "8860kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:22:28+00:00",
          "link": "https://arxiv.org/abs/2412.04245v2",
          "size": "1661kb",
          "version": "v2"
        }
      ],
      "title": "Intriguing Properties of Robust Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04245",
        "HTML": "https://arxiv.org/html/2412.04245v2",
        "PDF": "https://arxiv.org/pdf/2412.04245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the robust generalization of classifiers in computer vision, focusing on the impact of the amount of training data and adversarial robustness, without addressing LLM training data processing."
      },
      "tasks": [
        "Classification",
        "Robust classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04769",
      "abstract": "For anomaly detection (AD), early approaches often train separate models for individual classes, yielding high performance but posing challenges in scalability and resource management. Recent efforts have shifted toward training a single model capable of handling multiple classes. However, directly extending early AD methods to multi-class settings often results in degraded performance. In this paper, we investigate this performance degradation observed in reconstruction-based methods, identifying the key issue: inter-class confusion. This confusion emerges when a model trained in multi-class scenarios incorrectly reconstructs samples from one class as those of another, thereby exacerbating reconstruction errors. To this end, we propose a simple yet effective modification, called class-aware contrastive learning (CCL). By explicitly leveraging raw object category information (\\eg carpet or wood) as supervised signals, we introduce local CL to refine multiscale dense features, and global CL to obtain more compact feature representations of normal patterns, thereby effectively adapting the models to multi-class settings. Experiments across five datasets validate the effectiveness of our approach, demonstrating significant improvements and superior performance compared to state-of-the-art methods. Notably, ablation studies indicate that pseudo-class labels can achieve comparable performance.",
      "authors": [
        "Lei Fan",
        "Junjie Huang",
        "Donglin Di",
        "Anyang Su",
        "Tianyou Song",
        "Maurice Pagnucco",
        "Yang Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T04:31:09+00:00",
          "link": "https://arxiv.org/abs/2412.04769v1",
          "size": "1293kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:16:09+00:00",
          "link": "https://arxiv.org/abs/2412.04769v2",
          "size": "887kb",
          "version": "v2"
        }
      ],
      "title": "Salvaging the Overlooked: Leveraging Class-Aware Contrastive Learning for Multi-Class Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04769",
        "HTML": "https://arxiv.org/html/2412.04769v2",
        "PDF": "https://arxiv.org/pdf/2412.04769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on improving anomaly detection through class-aware contrastive learning. It does not discuss any methodologies or contributions related to training data processing for LLMs."
      },
      "tasks": [
        "Anomaly Detection",
        "Contrastive Learning",
        "Multi-class Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.06770",
      "abstract": "Volumetric reconstruction of dynamic scenes is an important problem in computer vision. It is especially challenging in poor lighting and with fast motion. This is partly due to limitations of RGB cameras: To capture frames under low lighting, the exposure time needs to be increased, which leads to more motion blur. In contrast, event cameras, which record changes in pixel brightness asynchronously, are much less dependent on lighting, making them more suitable for recording fast motion. We hence propose the first method to spatiotemporally reconstruct a scene from sparse multi-view event streams and sparse RGB frames. We train a sequence of cross-faded time-conditioned NeRF models, one per short recording segment. The individual segments are supervised with a set of event- and RGB-based losses and sparse-view regularisation. We assemble a real-world multi-view camera rig with six static event cameras around the object and record a benchmark multi-view event stream dataset of challenging motions. Our work outperforms RGB-based baselines, producing state-of-the-art results, and opens up the topic of multi-view event-based reconstruction as a new path for fast scene capture beyond RGB cameras. The code and the data are released at https://4dqv.mpi-inf.mpg.de/DynEventNeRF/",
      "authors": [
        "Viktor Rudnev",
        "Gereon Fox",
        "Mohamed Elgharib",
        "Christian Theobalt",
        "Vladislav Golyanik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T18:56:18+00:00",
          "link": "https://arxiv.org/abs/2412.06770v1",
          "size": "4719kb",
          "version": "v1"
        },
        {
          "date": "2025-04-22T20:42:42+00:00",
          "link": "https://arxiv.org/abs/2412.06770v2",
          "size": "5313kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T17:25:56+00:00",
          "link": "https://arxiv.org/abs/2412.06770v3",
          "size": "4730kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T23:08:37+00:00",
          "link": "https://arxiv.org/abs/2412.06770v4",
          "size": "4730kb",
          "version": "v4"
        }
      ],
      "title": "Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view RGB and Event Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06770",
        "HTML": "https://arxiv.org/html/2412.06770v4",
        "PDF": "https://arxiv.org/pdf/2412.06770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on dynamic scene reconstruction using event cameras and RGB frames for computer vision applications, without making a contribution to LLM training data processing."
      },
      "tasks": [
        "NeRF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.07195",
      "abstract": "Recently, deep learning methods have gained remarkable achievements in the field of image restoration for remote sensing (RS). However, most existing RS image restoration methods focus mainly on conventional first-order degradation models, which may not effectively capture the imaging mechanisms of remote sensing images. Furthermore, many RS image restoration approaches that use deep learning are often criticized for their lacks of architecture transparency and model interpretability. To address these problems, we propose a novel progressive restoration network for high-order degradation imaging (HDI-PRNet), to progressively restore different image degradation. HDI-PRNet is developed based on the theoretical framework of degradation imaging, also Markov properties of the high-order degradation process and Maximum a posteriori (MAP) estimation, offering the benefit of mathematical interpretability within the unfolding network. The framework is composed of three main components: a module for image denoising that relies on proximal mapping prior learning, a module for image deblurring that integrates Neumann series expansion with dual-domain degradation learning, and a module for super-resolution. Extensive experiments demonstrate that our method achieves superior performance on both synthetic and real remote sensing images.",
      "authors": [
        "Yujie Feng",
        "Yin Yang",
        "Xiaohong Fan",
        "Zhengpeng Zhang",
        "Lijing Bu and Jianping Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-10T05:08:39+00:00",
          "link": "https://arxiv.org/abs/2412.07195v1",
          "size": "772kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:01:55+00:00",
          "link": "https://arxiv.org/abs/2412.07195v2",
          "size": "995kb",
          "version": "v2"
        }
      ],
      "title": "A Progressive Image Restoration Network for High-order Degradation Imaging in Remote Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.07195",
        "HTML": "https://arxiv.org/html/2412.07195v2",
        "PDF": "https://arxiv.org/pdf/2412.07195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a progressive image restoration network for remote sensing, focusing on high-order degradation in images. It is unrelated to LLM training data processing."
      },
      "tasks": [
        "Deblurring",
        "Denoising",
        "Image Deblurring",
        "Image Denoising",
        "Image Restoration",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.09032",
      "abstract": "Detecting synthetic from real speech is increasingly crucial due to the risks of misinformation and identity impersonation. While various datasets for synthetic speech analysis have been developed, they often focus on specific areas, limiting their utility for comprehensive research. To fill this gap, we propose the Speech-Forensics dataset by extensively covering authentic, synthetic, and partially forged speech samples that include multiple segments synthesized by different high-quality algorithms. Moreover, we propose a TEmporal Speech LocalizaTion network, called TEST, aiming at simultaneously performing authenticity detection, multiple fake segments localization, and synthesis algorithms recognition, without any complex post-processing. TEST effectively integrates LSTM and Transformer to extract more powerful temporal speech representations and utilizes dense prediction on multi-scale pyramid features to estimate the synthetic spans. Our model achieves an average mAP of 83.55% and an EER of 5.25% at the utterance level. At the segment level, it attains an EER of 1.07% and a 92.19% F1 score. These results highlight the model's robust capability for a comprehensive analysis of synthetic speech, offering a promising avenue for future research and practical applications in this field.",
      "authors": [
        "Zhoulin Ji",
        "Chenhao Lin",
        "Hang Wang",
        "Chao Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T07:48:17+00:00",
          "link": "https://arxiv.org/abs/2412.09032v1",
          "size": "412kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T07:30:41+00:00",
          "link": "https://arxiv.org/abs/2412.09032v2",
          "size": "412kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T03:29:13+00:00",
          "link": "https://arxiv.org/abs/2412.09032v3",
          "size": "402kb",
          "version": "v3"
        }
      ],
      "title": "Speech-Forensics: Towards Comprehensive Synthetic Speech Dataset Establishment and Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09032",
        "HTML": "https://arxiv.org/html/2412.09032v3",
        "PDF": "https://arxiv.org/pdf/2412.09032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the creation of a synthetic speech dataset and the detection of synthetic speech, which does not pertain to training data processing for LLMs."
      },
      "tasks": [
        "Misinformation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19937",
      "abstract": "Anonymous communication relies on encrypted packet formats that resist traffic analysis and ensure unlinkability. Sphinx, the current standard for mixnets, provides strong anonymity but relies on classical public-key cryptography, making it vulnerable to quantum attacks. In this paper, we present Outfox, a simplified variant of Sphinx tailored for mixnets with fixed-length routes and designed for post-quantum security. Outfox reduces both computational and communication costs. We formally define Outfox and prove its security in the Universal Composability (UC) framework. Our evaluation shows that Outfox retains strong anonymity guarantees while offering improved efficiency and adaptability to quantum-resistant cryptographic primitives.",
      "authors": [
        "Alfredo Rial",
        "Ania M. Piotrowska",
        "Harry Halpin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T21:53:56+00:00",
          "link": "https://arxiv.org/abs/2412.19937v1",
          "size": "47kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:23:26+00:00",
          "link": "https://arxiv.org/abs/2412.19937v2",
          "size": "133kb",
          "version": "v2"
        }
      ],
      "title": "Outfox: a Packet Format for a Layered Mixnet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19937",
        "HTML": "https://arxiv.org/html/2412.19937v2",
        "PDF": "https://arxiv.org/pdf/2412.19937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a packet format for mixnets, aimed at improving anonymity and security. It does not discuss LLM training data processing or make contributions relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.20397",
      "abstract": "We propose a decentralized, learning-based framework for dynamic coalition formation in Multi-Robot Task Allocation (MRTA). Our approach extends MAPPO by integrating spatial action maps, robot motion planning, intention sharing, and task allocation revision to enable effective and adaptive coalition formation. Extensive simulation studies confirm the effectiveness of our model, enabling each robot to rely solely on local information to learn timely revisions of task selections and form coalitions with other robots to complete collaborative tasks. The results also highlight the proposed framework's ability to handle large robot populations and adapt to scenarios with diverse task sets.",
      "authors": [
        "Lucas C. D. Bezerra",
        "Ata\\'ide M. G. dos Santos",
        "Shinkyu Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T08:18:56+00:00",
          "link": "https://arxiv.org/abs/2412.20397v1",
          "size": "993kb",
          "version": "v1"
        },
        {
          "date": "2025-02-22T14:41:18+00:00",
          "link": "https://arxiv.org/abs/2412.20397v2",
          "size": "1233kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T23:15:15+00:00",
          "link": "https://arxiv.org/abs/2412.20397v3",
          "size": "4736kb",
          "version": "v3"
        }
      ],
      "title": "Learning Policies for Dynamic Coalition Formation in Multi-Robot Task Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20397",
        "HTML": "https://arxiv.org/html/2412.20397v3",
        "PDF": "https://arxiv.org/pdf/2412.20397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on dynamic coalition formation in multi-robot task allocation. It does not involve LLM training, pretraining, fine-tuning, or any related data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.04652",
      "abstract": "Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information. However, when building real-world RAG applications, practical issues arise. First, the retrieved information is generally domain-specific. Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input. Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers. Moreover, these RAG applications normally retrieve different kinds of data. Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed. We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases.",
      "authors": [
        "Patrice B\\'echard",
        "Orlando Marquez Ayala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T18:05:30+00:00",
          "link": "https://arxiv.org/abs/2501.04652v1",
          "size": "129kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:23:37+00:00",
          "link": "https://arxiv.org/abs/2501.04652v2",
          "size": "1209kb",
          "version": "v2"
        }
      ],
      "title": "Multi-task retriever fine-tuning for domain-specific and efficient RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04652",
        "HTML": "https://arxiv.org/html/2501.04652v2",
        "PDF": "https://arxiv.org/pdf/2501.04652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning a retriever for Retrieval-Augmented Generation (RAG) applications, hinting at data processing improvements for model inputs, but it primarily focuses on the retriever and not on training data processing for LLMs directly."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.09035",
      "abstract": "Social media play a pivotal role in disseminating web content, particularly during elections, yet our understanding of the association between demographic factors and information sharing online remains limited. Here, we introduce a unique dataset, DomainDemo, linking domains shared on Twitter (X) with the demographic characteristics of associated users, including age, gender, race, political affiliation, and geolocation, from 2011 to 2022. This new resource was derived from a panel of over 1.5 million Twitter users matched against their U.S. voter registration records, facilitating a better understanding of a decade of information flows on one of the most prominent social media platforms and trends in political and public discourse among registered U.S. voters from different sociodemographic groups. By aggregating user demographic information onto the domains, we derive five metrics that provide critical insights into over 129,000 websites. In particular, the localness and partisan audience metrics quantify the domains' geographical reach and ideological orientation, respectively. These metrics show substantial agreement with existing classifications, suggesting the effectiveness and reliability of DomainDemo's approach.",
      "authors": [
        "Kai-Cheng Yang",
        "Pranav Goel",
        "Alexi Quintana-Math\\'e",
        "Luke Horgan",
        "Stefan D. McCabe",
        "Nir Grinberg",
        "Kenneth Joseph",
        "David Lazer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T15:42:39+00:00",
          "link": "https://arxiv.org/abs/2501.09035v1",
          "size": "347kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T23:07:37+00:00",
          "link": "https://arxiv.org/abs/2501.09035v2",
          "size": "385kb",
          "version": "v2"
        }
      ],
      "title": "DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09035",
        "HTML": "https://arxiv.org/html/2501.09035v2",
        "PDF": "https://arxiv.org/pdf/2501.09035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the DomainDemo dataset, focusing on domain-sharing activities among demographic groups on Twitter, without addressing LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/lazerlab/domaindemo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11494",
      "abstract": "We present a stability and convergence analysis of the space-time continuous finite element method for the Hamiltonian formulation of the wave equation. More precisely, we prove a continuous dependence of the discrete solution on the data in a $C^0([0, T]; X)$-type energy norm, which does not require any restriction on the meshsize or the time steps. Such stability estimates are then used to derive a priori error estimates with quasi-optimal convergence rates, where a suitable treatment of possible nonhomogeneous Dirichlet boundary conditions is pivotal to avoid loss of accuracy. Moreover, based on the properties of a postprocessed approximation, we derive a constant-free, reliable a posteriori error estimate in the $C^0([0, T]; L^2(\\Omega))$ norm for the semidiscrete-in-time formulation. Several numerical experiments are presented to validate our theoretical findings.",
      "authors": [
        "Sergio G\\'omez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-20T14:00:59+00:00",
          "link": "https://arxiv.org/abs/2501.11494v1",
          "size": "604kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:25:19+00:00",
          "link": "https://arxiv.org/abs/2501.11494v2",
          "size": "548kb",
          "version": "v2"
        }
      ],
      "title": "A variational approach to the analysis of the continuous space-time FEM for the wave equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11494",
        "HTML": "https://arxiv.org/html/2501.11494v2",
        "PDF": "https://arxiv.org/pdf/2501.11494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a stability and convergence analysis of the finite element method for the wave equation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13020",
      "abstract": "Video-sharing platforms (VSPs) have become increasingly important for individuals with ADHD to recognize symptoms, acquire knowledge, and receive support. While videos offer rich information and high engagement, they also present unique challenges, such as information quality and accessibility issues to users with ADHD. However, little work has thoroughly examined the video content quality and accessibility issues, the impact, and the control strategies in the ADHD community. We fill this gap by systematically collecting 373 ADHD-relevant videos with comments from YouTube and TikTok and analyzing the data with a mixed method. Our study identified the characteristics of ADHD-relevant videos on VSPs (e.g., creator types, video presentation forms, quality issues) and revealed the collective efforts of creators and viewers in video quality control, such as authority building, collective quality checking, and accessibility improvement. We further derive actionable design implications for VSPs to offer more reliable and ADHD-friendly contents.",
      "authors": [
        "Hanxiu 'Hazel' Zhu",
        "Avanthika Senthil Kumar",
        "Sihang Zhao",
        "Ru Wang",
        "Xin Tong",
        "Yuhang Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T17:08:33+00:00",
          "link": "https://arxiv.org/abs/2501.13020v1",
          "size": "1404kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:20:03+00:00",
          "link": "https://arxiv.org/abs/2501.13020v2",
          "size": "1016kb",
          "version": "v2"
        }
      ],
      "title": "Characterizing Collective Efforts in Content Sharing and Quality Control for ADHD-relevant Content on Video-sharing Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13020",
        "HTML": "https://arxiv.org/html/2501.13020v2",
        "PDF": "https://arxiv.org/pdf/2501.13020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates video content quality and accessibility issues on video-sharing platforms for ADHD-relevant content, which does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.14048",
      "abstract": "Modern neural networks (NNs) often do not generalize well in the presence of a \"covariate shift\"; that is, in situations where the training and test data distributions differ, but the conditional distribution of classification labels remains unchanged. In such cases, NN generalization can be reduced to a problem of learning more domain-invariant features. Domain adaptation (DA) methods include a range of techniques aimed at achieving this; however, these methods have struggled with the need for extensive hyperparameter tuning, which then incurs significant computational costs. In this work, we introduce SIDDA, an out-of-the-box DA training algorithm built upon the Sinkhorn divergence, that can achieve effective domain alignment with minimal hyperparameter tuning and computational overhead. We demonstrate the efficacy of our method on multiple simulated and real datasets of varying complexity, including simple shapes, handwritten digits, and real astronomical observations. SIDDA is compatible with a variety of NN architectures, and it works particularly well in improving classification accuracy and model calibration when paired with equivariant neural networks (ENNs). We find that SIDDA enhances the generalization capabilities of NNs, achieving up to a $\\approx40\\%$ improvement in classification accuracy on unlabeled target data. We also study the efficacy of DA on ENNs with respect to the varying group orders of the dihedral group $D_N$, and find that the model performance improves as the degree of equivariance increases. Finally, we find that SIDDA enhances model calibration on both source and target data--achieving over an order of magnitude improvement in the ECE and Brier score. SIDDA's versatility, combined with its automated approach to domain alignment, has the potential to advance multi-dataset studies by enabling the development of highly generalizable models.",
      "authors": [
        "Sneh Pandya",
        "Purvik Patel",
        "Brian D. Nord",
        "Mike Walmsley",
        "Aleksandra \\'Ciprijanovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Astrophysics of Galaxies (astro-ph.GA)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T19:29:34+00:00",
          "link": "https://arxiv.org/abs/2501.14048v1",
          "size": "1390kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:06:39+00:00",
          "link": "https://arxiv.org/abs/2501.14048v2",
          "size": "3705kb",
          "version": "v2"
        }
      ],
      "title": "SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14048",
        "HTML": "https://arxiv.org/html/2501.14048v2",
        "PDF": "https://arxiv.org/pdf/2501.14048"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a domain adaptation training algorithm to enhance neural networks' generalization, a topic unrelated to LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation",
        "image-classification",
        "Image Classification"
      ],
      "repo_urls": [
        "https://github.com/deepskies/sidda",
        "https://github.com/deepskies/gcnn_da"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14725",
      "abstract": "Two fundamental classes of finite automata are deterministic and nondeterministic ones (DFAs and NFAs). Natural intermediate classes arise from bounds on an NFA's allowed ambiguity, i.e. number of accepting runs per word: unambiguous, finitely ambiguous, and polynomially ambiguous finite automata. It is known that deciding whether a given NFA is unambiguous and whether it is polynomially ambiguous is possible in quadratic time, and deciding finite ambiguity is possible in cubic time. We provide matching lower bounds showing these running times to be optimal, assuming popular fine-grained complexity hypotheses.\n  We improve the upper bounds for unary automata, which are essentially directed graphs with a source and a target. In this view, unambiguity asks whether all walks from the source to the target have different lengths. The running time analysis of our algorithm reduces to bounding the entry-wise 1-norm of a GCD matrix, yielding a near-linear upper bound. For finite and polynomial ambiguity, we provide simple linear-time algorithms in the unary case.\n  Finally, we study the twins property for weighted automata over the tropical semiring, which characterises the determinisability of unambiguous weighted automata. It occurs naturally in our context as deciding the twins property is an intermediate step in determinisability algorithms for weighted automata with bounded ambiguity. We show that Allauzen and Mohri's quadratic-time algorithm checking the twins property is optimal up to the same fine-grained hypotheses as for unambiguity. For unary automata, we show that the problem can be rephrased to whether all cycles in a weighted directed graph have the same average weight and give a linear-time algorithm.",
      "authors": [
        "Karolina Drabik and Anita D\\\"urr and Fabian Frei and Filip Mazowiecki and Karol W\\k{e}grzycki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T18:59:12+00:00",
          "link": "https://arxiv.org/abs/2501.14725v1",
          "size": "266kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:16:01+00:00",
          "link": "https://arxiv.org/abs/2501.14725v2",
          "size": "195kb",
          "version": "v2"
        }
      ],
      "title": "Fined-Grained Complexity of Ambiguity Problems on Automata and Directed Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14725",
        "HTML": "https://arxiv.org/html/2501.14725v2",
        "PDF": "https://arxiv.org/pdf/2501.14725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses complexity of ambiguity problems in automata and directed graphs, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.19232",
      "abstract": "Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions in unseen domains without additional training or fine-tuning, addressing the limitations of traditional models in sparse data environments. Recent advancements in large language models (LLMs) have significantly enhanced ZCDSR by facilitating cross-domain knowledge transfer through rich, pretrained representations. Despite this progress, domain semantic bias -- arising from differences in vocabulary and content focus between domains -- remains a persistent challenge, leading to misaligned item embeddings and reduced generalization across domains. To address this, we propose a novel semantic bias-aware framework that enhances LLM-based ZCDSR by improving cross-domain alignment at both the item and sequential levels. At the item level, we introduce a generalization loss that aligns the embeddings of items across domains (inter-domain compactness), while preserving the unique characteristics of each item within its own domain (intra-domain diversity). This ensures that item embeddings can be transferred effectively between domains without collapsing into overly generic or uniform representations. At the sequential level, we develop a method to transfer user behavioral patterns by clustering source domain user sequences and applying attention-based aggregation during target domain inference. We dynamically adapt user embeddings to unseen domains, enabling effective zero-shot recommendations without requiring target-domain interactions...",
      "authors": [
        "Yunzhe Li",
        "Junting Wang",
        "Hari Sundaram",
        "Zhining Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T15:43:21+00:00",
          "link": "https://arxiv.org/abs/2501.19232v1",
          "size": "6315kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:08:34+00:00",
          "link": "https://arxiv.org/abs/2501.19232v2",
          "size": "4735kb",
          "version": "v2"
        }
      ],
      "title": "LLM-RecG: A Semantic Bias-Aware Framework for Zero-Shot Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19232",
        "HTML": "https://arxiv.org/html/2501.19232v2",
        "PDF": "https://arxiv.org/pdf/2501.19232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing cross-domain sequential recommendation using LLMs, addressing semantic biases for better prediction. It doesn't contribute to LLM training data processing, pretraining, or fine-tuning."
      },
      "tasks": [
        "Sequential Recommendation",
        "Transfer Learning",
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01491",
      "abstract": "In this work, we explore how instance-level memorization in the teacher Neural Machine Translation (NMT) model gets inherited by the student model in sequence-level knowledge distillation (SeqKD). We find that despite not directly seeing the original training data, students memorize more than baseline models (models of the same size, trained on the original data) -- 3.4% for exact matches and 57% for extractive memorization -- and show increased hallucination rates. Further, under this SeqKD setting, we also characterize how students behave on specific training data subgroups, such as subgroups with low quality and specific counterfactual memorization (CM) scores, and find that students exhibit amplified denoising on low-quality subgroups. Finally, we propose a modification to SeqKD named Adaptive-SeqKD, which intervenes in SeqKD to reduce memorization and hallucinations. Overall, we recommend caution when applying SeqKD: students inherit both their teachers' superior performance and their fault modes, thereby requiring active monitoring.",
      "authors": [
        "Verna Dankers and Vikas Raunak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T16:26:06+00:00",
          "link": "https://arxiv.org/abs/2502.01491v1",
          "size": "202kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:39:35+00:00",
          "link": "https://arxiv.org/abs/2502.01491v2",
          "size": "173kb",
          "version": "v2"
        }
      ],
      "title": "Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01491",
        "HTML": "https://arxiv.org/html/2502.01491v2",
        "PDF": "https://arxiv.org/pdf/2502.01491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores knowledge distillation, it also addresses issues like memorization and data subgroup behavior, which could indirectly relate to data quality concerns. However, it doesn't focus on LLM training data processing but rather on the student-teacher model dynamics."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01591",
      "abstract": "We present three improvements to the standard model-based RL paradigm based on transformers: (a) \"Dyna with warmup\", which trains the policy on real and imaginary data, but only starts using imaginary data after the world model has been sufficiently trained; (b) \"nearest neighbor tokenizer\" for image patches, which improves upon previous tokenization schemes, which are needed when using a transformer world model (TWM), by ensuring the code words are static after creation, thus providing a constant target for TWM learning; and (c) \"block teacher forcing\", which allows the TWM to reason jointly about the future tokens of the next timestep, instead of generating them sequentially. We then show that our method significantly improves upon prior methods in various environments. We mostly focus on the challenging Craftax-classic benchmark, where our method achieves a reward of 69.66% after only 1M environment steps, significantly outperforming DreamerV3, which achieves 53.2%, and exceeding human performance of 65.0% for the first time. We also show preliminary results on Craftax-full, MinAtar, and three different two-player games, to illustrate the generality of the approach.",
      "authors": [
        "Antoine Dedieu",
        "Joseph Ortiz",
        "Xinghua Lou",
        "Carter Wendelken",
        "Wolfgang Lehrach",
        "J Swaroop Guntupalli",
        "Miguel Lazaro-Gredilla",
        "Kevin Patrick Murphy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T18:25:17+00:00",
          "link": "https://arxiv.org/abs/2502.01591v1",
          "size": "1881kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T16:00:58+00:00",
          "link": "https://arxiv.org/abs/2502.01591v2",
          "size": "1262kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T18:06:24+00:00",
          "link": "https://arxiv.org/abs/2502.01591v3",
          "size": "1941kb",
          "version": "v3"
        }
      ],
      "title": "Improving Transformer World Models for Data-Efficient RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01591",
        "HTML": "https://arxiv.org/html/2502.01591v3",
        "PDF": "https://arxiv.org/pdf/2502.01591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses improvements in model-based RL using transformers, focusing on training efficiency in reinforcement learning rather than any aspects of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.02386",
      "abstract": "We propose a generative model of temporally-evolving hypergraphs in which hyperedges form via noisy copying of previous hyperedges. Our proposed model reproduces several stylized facts from many empirical hypergraphs, is learnable from data, and defines a likelihood over a complete hypergraph rather than ego-based or other sub-hypergraphs. Analyzing our model, we derive descriptions of node degree, edge size, and edge intersection size distributions in terms of the model parameters. We also show several features of empirical hypergraphs which are and are not successfully captured by our model. We provide a scalable stochastic expectation maximization algorithm with which we can fit our model to hypergraph data sets with millions of nodes and edges. Finally, we assess our model on a hypergraph link prediction task, finding that an instantiation of our model with just 11 parameters can achieve competitive predictive performance with large neural networks.",
      "authors": [
        "Xie He",
        "Philip S. Chodrow",
        "and Peter J. Mucha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T15:04:01+00:00",
          "link": "https://arxiv.org/abs/2502.02386v1",
          "size": "1496kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:33:58+00:00",
          "link": "https://arxiv.org/abs/2502.02386v2",
          "size": "1214kb",
          "version": "v2"
        }
      ],
      "title": "Hypergraph Link Prediction via Hyperedge Copying",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02386",
        "HTML": "https://arxiv.org/html/2502.02386v2",
        "PDF": "https://arxiv.org/pdf/2502.02386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for evolving hypergraphs with applications in hypergraph link prediction. It doesn't relate to LLM training data processing, but rather to graph modeling and prediction tasks."
      },
      "repo_urls": [
        "https://github.com/hexie1995/hypergraph"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02442",
      "abstract": "It is a well-known fact that the permanent polynomial is complete for the complexity class VNP, and it is largely suspected that the determinant does not share this property, despite its similar expression. We study the question of why the VNP-completeness proof of the permanent fails for the determinant. We isolate three fundamental properties that are sufficient to prove a polynomial sequence is VNP-hard, of which two are shared by both the permanent and the determinant. We proceed to show that the permanent satisfies the third property, which we refer to as the ``cost of a boolean sum,\" while the determinant does not, showcasing the fundamental difference between the polynomial families. We further note that this differentiation also applies in the border complexity setting and that our results apply for counting complexity.",
      "authors": [
        "Ian Orzel",
        "Srikanth Srinivasan",
        "S\\'ebastien Tavenas",
        "Amir Yehudayoff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T16:09:46+00:00",
          "link": "https://arxiv.org/abs/2502.02442v1",
          "size": "80kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:46:53+00:00",
          "link": "https://arxiv.org/abs/2502.02442v2",
          "size": "21kb",
          "version": "v2"
        }
      ],
      "title": "The Algebraic Cost of a Boolean Sum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02442",
        "HTML": "https://arxiv.org/html/2502.02442v2",
        "PDF": "https://arxiv.org/pdf/2502.02442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the complexity of mathematical properties in polynomial expressions, specifically the permanent and determinant polynomials, without making any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.04018",
      "abstract": "This paper introduces PINT (Physics-Informed Neural Time Series Models), a framework that integrates physical constraints into neural time series models to improve their ability to capture complex dynamics. We apply PINT to the ERA5 WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data. PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informed prior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures. This equation's analytical solutions (sine and cosine functions) facilitate rigorous evaluation of the benefits of incorporating physics-informed constraints. By benchmarking against a linear regression baseline derived from its exact solutions, we quantify the impact of embedding physical principles in data-driven models. Unlike traditional time series models that rely on future observations, PINT is designed for practical forecasting. Using only the first 90 days of observed data, it iteratively predicts the next two years, addressing challenges posed by limited real-time updates. Experiments on the WeatherBench dataset demonstrate PINT's ability to generalize, capture periodic trends, and align with physical principles. This study highlights the potential of physics-informed neural models in bridging machine learning and interpretable climate applications.\n  Our models and datasets are publicly available on GitHub: https://github.com/KV-Park.",
      "authors": [
        "Keonvin Park",
        "Jisu Kim",
        "Jaemin Seo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T12:19:34+00:00",
          "link": "https://arxiv.org/abs/2502.04018v1",
          "size": "972kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:44:39+00:00",
          "link": "https://arxiv.org/abs/2502.04018v2",
          "size": "979kb",
          "version": "v2"
        }
      ],
      "title": "PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04018",
        "HTML": "https://arxiv.org/html/2502.04018v2",
        "PDF": "https://arxiv.org/pdf/2502.04018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents PINT, a framework integrating physical constraints into neural time series models for weather forecasting. It does not address LLM training data processing or operations such as dataset creation or data quality improvement."
      },
      "tasks": [
        "Benchmarking",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/KV-Park/PINT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04874",
      "abstract": "Positioning integrity refers to the trust in the performance of a navigation system. Accurate and reliable position information is needed to meet the requirements of connected and Automated Vehicle (CAV) applications, particularly in safety-critical scenarios. Receiver Autonomous Integrity Monitoring (RAIM) and its variants have been widely studied for Global Navigation Satellite System (GNSS)-based vehicle positioning, often fused with kinematic (e.g., Odometry) and perception sensors (e.g., camera). However, integrity monitoring (IM) for cooperative positioning solutions leveraging Vehicle-to-Everything (V2X) communication has received comparatively limited attention. This paper reviews existing research in the field of positioning IM and identifies various research gaps. Particular attention has been placed on identifying research that highlights cooperative IM methods. It also examines key automotive safety standards and public V2X datasets to map current research priorities and uncover critical gaps. Finally, the paper outlines promising future directions, highlighting research topics aimed at advancing and benchmarking positioning integrity.",
      "authors": [
        "Saswat Priyadarshi Nayak",
        "Matthew Barth"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T12:27:13+00:00",
          "link": "https://arxiv.org/abs/2502.04874v1",
          "size": "3152kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T21:16:42+00:00",
          "link": "https://arxiv.org/abs/2502.04874v2",
          "size": "5508kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T12:44:11+00:00",
          "link": "https://arxiv.org/abs/2502.04874v3",
          "size": "5508kb",
          "version": "v3"
        }
      ],
      "title": "The Role of Integrity Monitoring in Connected and Automated Vehicles: Current State-of-Practice and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04874",
        "HTML": "https://arxiv.org/html/2502.04874v3",
        "PDF": "https://arxiv.org/pdf/2502.04874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews positioning integrity in automated vehicles, focusing on GNSS and cooperative positioning solutions. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05278",
      "abstract": "The computational complexity of polynomial ideals and Gr\\\"obner bases has been studied since the 1980s. In recent years, the related notions of polynomial subalgebras and SAGBI bases have gained more and more attention in computational algebra, with a view towards effective algorithms. We investigate the computational complexity of the subalgebra membership problem and degree bounds. In particular, we show completeness for the complexity class EXPSPACE and prove PSPACE-completeness for homogeneous algebras. We highlight parallels and differences compared to the settings of ideals, and also look at important classes of polynomials such as monomial algebras.",
      "authors": [
        "Leonie Kayser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Commutative Algebra (math.AC)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T19:25:59+00:00",
          "link": "https://arxiv.org/abs/2502.05278v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:23:43+00:00",
          "link": "https://arxiv.org/abs/2502.05278v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Computational Complexity of Polynomial Subalgebras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05278",
        "HTML": "https://arxiv.org/html/2502.05278v2",
        "PDF": "https://arxiv.org/pdf/2502.05278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates the computational complexity of polynomial subalgebras and related algorithmic problems, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05668",
      "abstract": "We analyze the implicit bias of constant step stochastic subgradient descent (SGD). We consider the setting of binary classification with homogeneous neural networks - a large class of deep neural networks with ReLU-type activation functions such as MLPs and CNNs without biases. We interpret the dynamics of normalized SGD iterates as an Euler-like discretization of a conservative field flow that is naturally associated to the normalized classification margin. Owing to this interpretation, we show that normalized SGD iterates converge to the set of critical points of the normalized margin at late-stage training (i.e., assuming that the data is correctly classified with positive normalized margin). Up to our knowledge, this is the first extension of the analysis of Lyu and Li (2020) on the discrete dynamics of gradient descent to the nonsmooth and stochastic setting. Our main result applies to binary classification with exponential or logistic losses. We additionally discuss extensions to more general settings.",
      "authors": [
        "Sholom Schechtman and Nicolas Schreuder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T19:09:16+00:00",
          "link": "https://arxiv.org/abs/2502.05668v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T10:04:45+00:00",
          "link": "https://arxiv.org/abs/2502.05668v2",
          "size": "45kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T11:44:07+00:00",
          "link": "https://arxiv.org/abs/2502.05668v3",
          "size": "37kb",
          "version": "v3"
        }
      ],
      "title": "The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05668",
        "HTML": "https://arxiv.org/html/2502.05668v3",
        "PDF": "https://arxiv.org/pdf/2502.05668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the dynamics of stochastic subgradient descent in neural networks, focusing on implicit bias in training but not addressing LLM training data processing."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08272",
      "abstract": "We study weighted pseudorandom generators (WPRGs) and derandomizations for read-once branching programs (ROBPs). Denote $n$ and $w$ as the length and the width of a ROBP. We have the following results.\n  For standard ROBPs, we give an explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left(\\frac{\\log n\\log (nw)}{\\max\\left\\{1,\\log\\log w-\\log\\log n\\right\\}}+\\log w \\left(\\log\\log\\log w-\\log\\log\\max\\left\\{2,\\frac{\\log w}{\\log \\frac{n}{\\varepsilon}}\\right\\}\\right)+\\log\\frac{1}{\\varepsilon}\\right).$$\n  For permutation ROBPs with unbounded widths and single accept nodes, we give an explicit $\\varepsilon$-WPRG with seed length\n  $$O\\left( \\log n\\left( \\log\\log n + \\sqrt{\\log(1/\\varepsilon)} \\right)+\\log(1/\\varepsilon)\\right). $$\n  We also give a new Nisan-Zuckerman style derandomization for regular ROBPs with width $w$, length $n = 2^{O(\\sqrt{\\log w})}$, and multiple accept nodes. We attain optimal space complexity $O(\\log w)$ for arbitrary approximation error $\\varepsilon = 1/\\text{poly} (w)$.\n  All our results are based on iterative weighted pseudorandom reductions, which can iteratively reduce fooling long ROBPs to fooling short ones.",
      "authors": [
        "Kuan Cheng",
        "Ruiyang Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T10:27:18+00:00",
          "link": "https://arxiv.org/abs/2502.08272v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T02:41:37+00:00",
          "link": "https://arxiv.org/abs/2502.08272v2",
          "size": "294kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:59:20+00:00",
          "link": "https://arxiv.org/abs/2502.08272v3",
          "size": "111kb",
          "version": "v3"
        }
      ],
      "title": "Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08272",
        "HTML": "https://arxiv.org/html/2502.08272v3",
        "PDF": "https://arxiv.org/pdf/2502.08272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on weighted pseudorandom generators and derandomizations for read-once branching programs, which do not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.10610",
      "abstract": "Road safety continues to be a pressing global issue, with vehicle collisions imposing significant human, societal, and economic burdens. Human-machine shared collision avoidance in critical collision scenarios aims to aid drivers' accident avoidance through intervening only when necessary. Existing methods count on replanning collision-free trajectories and imposing human-machine tracking, which usually interrupts the driver's intent and increases the risk of conflict. This paper introduces a Reachability-Aware Reinforcement Learning (RL) framework for shared control, guided by Hamilton-Jacobi (HJ) reachability analysis. Machine intervention is activated only when the vehicle approaches the Collision Avoidance Reachable Set (CARS), which represents states where collision is unavoidable. First, we precompute the reachability distributions and the CARS by solving the Bellman equation using offline data. To reduce human-machine conflicts, we develop a driver model for sudden obstacles and propose an authority allocation strategy considering key collision avoidance features. Finally, we train a RL agent to reduce human-machine conflicts while enforcing the hard constraint of avoiding entry into the CARS. The proposed method was tested on a real vehicle platform. Results show that the controller intervenes effectively near CARS to prevent collisions while maintaining improved original driving task performance. Robustness analysis further supports its flexibility across different driver attributes.",
      "authors": [
        "Shiyue Zhao",
        "Junzhi Zhang",
        "Rui Zhou",
        "Neda Masoud",
        "Jianxiong Li",
        "Helai Huang",
        "Shijie Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T23:57:54+00:00",
          "link": "https://arxiv.org/abs/2502.10610v1",
          "size": "1712kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:30:50+00:00",
          "link": "https://arxiv.org/abs/2502.10610v2",
          "size": "1880kb",
          "version": "v2"
        }
      ],
      "title": "Safety-Critical Human-Machine Shared Driving for Vehicle Collision Avoidance based on Hamilton-Jacobi reachability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10610",
        "PDF": "https://arxiv.org/pdf/2502.10610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for shared driving control in vehicles, focusing on collision avoidance, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.10693",
      "abstract": "The in-band Full Duplex (FD) technology is lately gaining attention as an enabler for the emerging paradigm of Integrated Sensing and Communications (ISAC), which envisions seamless integration of sensing mechanisms for unconnected entities into next generation wireless networks. In this paper, we present an FD Multiple-Input Multiple-Output (MIMO) system with extremely large antenna arrays at its transceiver module, which is optimized, considering two emerging analog beamforming architectures, for simultaneous DownLink (DL) communications and monostatic-type sensing intended at the sub-THz frequencies, with the latter operation relying on received reflections of the transmitted information-bearing signals. A novel optimization framework for the joint design of the analog and digital transmit beamforming, analog receive combining, and the digital canceler for the self-interference signal is devised with the objective to maximize the achievable DL rate, while meeting a predefined threshold for the position error bound for the unknown three-dimensional parameters of a passive target. Capitalizing on the distinctive features of the beamforming architectures with fully-connected networks of phase shifters and partially-connected arrays of metamaterials, two ISAC designs are presented. Our simulation results showcase the superiority of both proposed designs over state-of-the-art schemes, highlighting the role of various system parameters in the trade-off between the communication and sensing functionalities.",
      "authors": [
        "George C. Alexandropoulos and Ioannis Gavras"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Emerging Technologies (cs.ET)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-15T06:40:17+00:00",
          "link": "https://arxiv.org/abs/2502.10693v1",
          "size": "1263kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:09:46+00:00",
          "link": "https://arxiv.org/abs/2502.10693v2",
          "size": "1157kb",
          "version": "v2"
        }
      ],
      "title": "Extremely Large Full Duplex MIMO for Simultaneous Downlink Communications and Monostatic Sensing at Sub-THz Frequencies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10693",
        "HTML": "https://arxiv.org/html/2502.10693v2",
        "PDF": "https://arxiv.org/pdf/2502.10693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research discusses full duplex MIMO systems for communications and sensing, particularly at sub-THz frequencies, without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12086",
      "abstract": "Dynamical systems, prevalent in various scientific and engineering domains, are susceptible to anomalies that can significantly impact their performance and reliability. This paper addresses the critical challenges of anomaly detection, root cause localization, and anomaly type classification in dynamical systems governed by ordinary differential equations (ODEs). We define two categories of anomalies: cyber anomalies, which propagate through interconnected variables, and measurement anomalies, which remain localized to individual variables. To address these challenges, we propose the Interpretable Causality Ordinary Differential Equation (ICODE) Networks, a model-intrinsic explainable learning framework. ICODE leverages Neural ODEs for anomaly detection while employing causality inference through an explanation channel to perform root cause analysis (RCA), elucidating why specific time periods are flagged as anomalous. ICODE is designed to simultaneously perform anomaly detection, RCA, and anomaly type classification within a single, interpretable framework. Our approach is grounded in the hypothesis that anomalies alter the underlying ODEs of the system, manifesting as changes in causal relationships between variables. We provide a theoretical analysis of how perturbations in learned model parameters can be utilized to identify anomalies and their root causes in time series data. Comprehensive experimental evaluations demonstrate the efficacy of ICODE across various dynamical systems, showcasing its ability to accurately detect anomalies, classify their types, and pinpoint their origins.",
      "authors": [
        "Yue Sun",
        "Rick S. Blum",
        "Parv Venkitasubramaniam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T18:01:07+00:00",
          "link": "https://arxiv.org/abs/2502.12086v1",
          "size": "2014kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T01:30:48+00:00",
          "link": "https://arxiv.org/abs/2502.12086v2",
          "size": "1166kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T02:10:56+00:00",
          "link": "https://arxiv.org/abs/2502.12086v3",
          "size": "1155kb",
          "version": "v3"
        }
      ],
      "title": "Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12086",
        "HTML": "https://arxiv.org/html/2502.12086v3",
        "PDF": "https://arxiv.org/pdf/2502.12086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on anomaly detection and root cause analysis within dynamical systems using Neural ODEs, and does not discuss any aspect of LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12096",
      "abstract": "In this paper, we introduce token communications (TokCom), a large model-driven framework to leverage cross-modal context information in generative semantic communications (GenSC). TokCom is a new paradigm, motivated by the recent success of generative foundation models and multimodal large language models (GFM/MLLMs), where the communication units are tokens, enabling efficient transformer-based token processing at the transmitter and receiver. In this paper, we introduce the potential opportunities and challenges of leveraging context in GenSC, explore how to integrate GFM/MLLMs-based token processing into semantic communication systems to leverage cross-modal context effectively at affordable complexity, present the key principles for efficient TokCom at various layers in future wireless networks. In a typical image semantic communication setup, we demonstrate a significant improvement of the bandwidth efficiency, achieved by TokCom by leveraging the context information among tokens. Finally, the potential research directions are identified to facilitate adoption of TokCom in future wireless networks.",
      "authors": [
        "Li Qiao",
        "Mahdi Boloursaz Mashhadi",
        "Zhen Gao",
        "Rahim Tafazolli",
        "Mehdi Bennis",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T18:14:18+00:00",
          "link": "https://arxiv.org/abs/2502.12096v1",
          "size": "1903kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T18:53:50+00:00",
          "link": "https://arxiv.org/abs/2502.12096v2",
          "size": "2389kb",
          "version": "v2"
        },
        {
          "date": "2025-07-11T13:47:50+00:00",
          "link": "https://arxiv.org/abs/2502.12096v3",
          "size": "2389kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T14:12:28+00:00",
          "link": "https://arxiv.org/abs/2502.12096v4",
          "size": "2389kb",
          "version": "v4"
        }
      ],
      "title": "Token Communications: A Large Model-Driven Framework for Cross-modal Context-aware Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12096",
        "HTML": "https://arxiv.org/html/2502.12096v4",
        "PDF": "https://arxiv.org/pdf/2502.12096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for semantic communications using tokens, focusing on communications in wireless networks rather than LLM training data processing."
      },
      "tasks": [
        "Semantic Communication"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14819",
      "abstract": "A long-standing goal in AI is to build agents that can solve a variety of tasks across different environments, including previously unseen ones. Two dominant approaches tackle this challenge: (i) reinforcement learning (RL), which learns policies through trial and error, and (ii) optimal control, which plans actions using a learned or known dynamics model. However, their relative strengths and weaknesses remain underexplored in the setting where agents must learn from offline trajectories without reward annotations. In this work, we systematically analyze the performance of different RL and control-based methods under datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot approaches. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and use it for planning. We study how dataset properties-such as data diversity, trajectory quality, and environment variability-affect the performance of these approaches. Our results show that model-free RL excels when abundant, high-quality data is available, while model-based planning excels in generalization to novel environment layouts, trajectory stitching, and data-efficiency. Notably, planning with a latent dynamics model emerges as a promising approach for zero-shot generalization from suboptimal data.",
      "authors": [
        "Vlad Sobal",
        "Wancong Zhang",
        "Kynghyun Cho",
        "Randall Balestriero",
        "Tim G. J. Rudner",
        "Yann LeCun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T18:39:41+00:00",
          "link": "https://arxiv.org/abs/2502.14819v1",
          "size": "1155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:29:11+00:00",
          "link": "https://arxiv.org/abs/2502.14819v2",
          "size": "1792kb",
          "version": "v2"
        }
      ],
      "title": "Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14819",
        "PDF": "https://arxiv.org/pdf/2502.14819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores planning with latent dynamics models for learning from reward-free offline data, unrelated to any aspect of LLM training data processing or dataset refinement."
      },
      "tasks": [
        "Reinforcement Learning (RL)",
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15082",
      "abstract": "User specifications or legal frameworks often require information to be removed from pretrained models, including large language models (LLMs). This requires deleting or \"forgetting\" a set of data points from an already-trained model, which typically degrades its performance on other data points. Thus, a balance must be struck between removing information and keeping the model's other abilities intact, with a failure to balance this trade-off leading to poor deletion or an unusable model. To this end, we propose UPCORE (Utility-Preserving Coreset Selection), a method-agnostic data selection framework for mitigating collateral damage during unlearning. Finding that the model damage is correlated with the variance of the model's representations on the forget set, we selectively prune the forget set to remove outliers, thereby minimizing model degradation after unlearning. Across three standard unlearning methods, UPCORE consistently achieves a superior balance between the competing objectives of deletion efficacy and model preservation. To better evaluate this trade-off, we introduce a new metric, measuring the area-under-the-curve (AUC) across standard metrics. Our results show that UPCORE improves both standard metrics and AUC, benefiting from positive transfer between the coreset and pruned points while reducing negative transfer from the forget set to points outside of it.",
      "authors": [
        "Vaidehi Patil",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T22:51:10+00:00",
          "link": "https://arxiv.org/abs/2502.15082v1",
          "size": "209kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T22:34:30+00:00",
          "link": "https://arxiv.org/abs/2502.15082v2",
          "size": "1165kb",
          "version": "v2"
        }
      ],
      "title": "UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15082",
        "HTML": "https://arxiv.org/html/2502.15082v2",
        "PDF": "https://arxiv.org/pdf/2502.15082"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers around unlearning in pretrained models through coreset selection, which does not contribute to LLM training data processing like dataset creation or data engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/vaidehi99/upcore"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15859",
      "abstract": "The rapid advancement of Artificial Intelligence (AI) technology is profoundly transforming human society and concurrently presenting a series of ethical, legal, and social issues. The effective governance of AI has become a crucial global concern. Since 2022, the extensive deployment of generative AI, particularly large language models, marked a new phase in AI governance. Continuous efforts are being made by the international community in actively addressing the novel challenges posed by these AI developments. As consensus on international governance continues to be established and put into action, the practical importance of conducting a global assessment of the state of AI governance is progressively coming to light. In this context, we initiated the development of the AI Governance InternationaL Evaluation Index (AGILE Index). Adhering to the design principle, \"the level of governance should match the level of development,\" the inaugural evaluation of the AGILE Index commences with an exploration of four foundational pillars: the development level of AI, the AI governance environment, the AI governance instruments, and the AI governance effectiveness. It covers 39 indicators across 18 dimensions to comprehensively assess the AI governance level of 14 representative countries globally. The index is utilized to delve into the status of AI governance to date in 14 countries for the first batch of evaluation. The aim is to depict the current state of AI governance in these countries through data scoring, assist them in identifying their governance stage and uncovering governance issues, and ultimately offer insights for the enhancement of their AI governance systems.",
      "authors": [
        "Yi Zeng",
        "Enmeng Lu",
        "Xin Guan",
        "Cunqing Huangfu",
        "Zizhe Ruan",
        "Ammar Younas",
        "Kang Sun",
        "Xuan Tang",
        "Yuwei Wang",
        "Hongjie Suo",
        "Dongqi Liang",
        "Zhengqiang Han",
        "Aorigele Bao",
        "Xiaoyang Guo",
        "Jin Wang",
        "Jiawei Xie and Yao Liang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T10:16:56+00:00",
          "link": "https://arxiv.org/abs/2502.15859v1",
          "size": "7609kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T07:07:48+00:00",
          "link": "https://arxiv.org/abs/2502.15859v2",
          "size": "7463kb",
          "version": "v2"
        },
        {
          "date": "2025-03-04T07:10:54+00:00",
          "link": "https://arxiv.org/abs/2502.15859v3",
          "size": "7555kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T06:34:41+00:00",
          "link": "https://arxiv.org/abs/2502.15859v4",
          "size": "8512kb",
          "version": "v4"
        }
      ],
      "title": "AI Governance InternationaL Evaluation Index (AGILE Index) 2024",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15859",
        "PDF": "https://arxiv.org/pdf/2502.15859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI governance and develops an evaluation index for assessing governance levels in different countries. It does not address LLM training data processing in any capacity."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.18699",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has shown promise in aligning large language models (LLMs). Yet its reliance on a singular reward model often overlooks the diversity of human preferences. Recent approaches address this limitation by leveraging multi-dimensional feedback to fine-tune corresponding reward models and train LLMs using reinforcement learning. However, the process is costly and unstable, especially given the competing and heterogeneous nature of human preferences. In this paper, we propose Mixing Preference Optimization (MPO), a post-processing framework for aggregating single-objective policies as an alternative to both multi-objective RLHF (MORLHF) and MaxMin-RLHF. MPO avoids alignment from scratch. Instead, it log-linearly combines existing policies into a unified one with the weight of each policy computed via a batch stochastic mirror descent. Empirical results demonstrate that MPO achieves balanced performance across diverse preferences, outperforming or matching existing models with significantly reduced computational costs.",
      "authors": [
        "Tianze Wang",
        "Dongnan Gui",
        "Yifan Hu",
        "Shuhang Lin",
        "Linjun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T23:22:12+00:00",
          "link": "https://arxiv.org/abs/2502.18699v1",
          "size": "1103kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:29:09+00:00",
          "link": "https://arxiv.org/abs/2502.18699v2",
          "size": "627kb",
          "version": "v2"
        }
      ],
      "title": "MPO: An Efficient Post-Processing Framework for Mixing Diverse Preference Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18699",
        "HTML": "https://arxiv.org/html/2502.18699v2",
        "PDF": "https://arxiv.org/pdf/2502.18699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses preference alignment and post-processing in reinforcement learning for LLMs, it does not directly focus on initial training data processing. Thus, the main contribution is not in the scope of LLM training data processing."
      },
      "tasks": [
        "Diversity",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19242",
      "abstract": "This work introduces BEV-LIO(LC), a novel LiDAR-Inertial Odometry (LIO) framework that combines Bird's Eye View (BEV) image representations of LiDAR data with geometry-based point cloud registration and incorporates loop closure (LC) through BEV image features. By normalizing point density, we project LiDAR point clouds into BEV images, thereby enabling efficient feature extraction and matching. A lightweight convolutional neural network (CNN) based feature extractor is employed to extract distinctive local and global descriptors from the BEV images. Local descriptors are used to match BEV images with FAST keypoints for reprojection error construction, while global descriptors facilitate loop closure detection. Reprojection error minimization is then integrated with point-to-plane registration within an iterated Extended Kalman Filter (iEKF). In the back-end, global descriptors are used to create a KD-tree-indexed keyframe database for accurate loop closure detection. When a loop closure is detected, Random Sample Consensus (RANSAC) computes a coarse transform from BEV image matching, which serves as the initial estimate for Iterative Closest Point (ICP). The refined transform is subsequently incorporated into a factor graph along with odometry factors, improving the global consistency of localization. Extensive experiments conducted in various scenarios with different LiDAR types demonstrate that BEV-LIO(LC) outperforms state-of-the-art methods, achieving competitive localization accuracy. Our code and video can be found at https://github.com/HxCa1/BEV-LIO-LC.",
      "authors": [
        "Haoxin Cai",
        "Shenghai Yuan",
        "Xinyi Li",
        "Junfeng Guo",
        "and Jianqi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T15:51:32+00:00",
          "link": "https://arxiv.org/abs/2502.19242v1",
          "size": "5484kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:27:56+00:00",
          "link": "https://arxiv.org/abs/2502.19242v2",
          "size": "5484kb",
          "version": "v2"
        }
      ],
      "title": "BEV-LIO(LC): BEV Image Assisted LiDAR-Inertial Odometry with Loop Closure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19242",
        "HTML": "https://arxiv.org/html/2502.19242v2",
        "PDF": "https://arxiv.org/pdf/2502.19242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a LiDAR-inertial odometry framework and does not involve any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/hxca1/bev-lio-lc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19697",
      "abstract": "Person re-identification (re-id) models are vital in security surveillance systems, requiring transferable adversarial attacks to explore the vulnerabilities of them. Recently, vision-language models (VLM) based attacks have shown superior transferability by attacking generalized image and textual features of VLM, but they lack comprehensive feature disruption due to the overemphasis on discriminative semantics in integral representation. In this paper, we introduce the Attribute-aware Prompt Attack (AP-Attack), a novel method that leverages VLM's image-text alignment capability to explicitly disrupt fine-grained semantic features of pedestrian images by destroying attribute-specific textual embeddings. To obtain personalized textual descriptions for individual attributes, textual inversion networks are designed to map pedestrian images to pseudo tokens that represent semantic embeddings, trained in the contrastive learning manner with images and a predefined prompt template that explicitly describes the pedestrian attributes. Inverted benign and adversarial fine-grained textual semantics facilitate attacker in effectively conducting thorough disruptions, enhancing the transferability of adversarial examples. Extensive experiments show that AP-Attack achieves state-of-the-art transferability, significantly outperforming previous methods by 22.9% on mean Drop Rate in cross-model&dataset attack scenarios.",
      "authors": [
        "Yuan Bian",
        "Min Liu",
        "Yunqi Yi",
        "Xueping Wang",
        "Yaonan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T02:32:58+00:00",
          "link": "https://arxiv.org/abs/2502.19697v1",
          "size": "3441kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T02:24:30+00:00",
          "link": "https://arxiv.org/abs/2502.19697v2",
          "size": "3447kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T14:27:11+00:00",
          "link": "https://arxiv.org/abs/2502.19697v3",
          "size": "691kb",
          "version": "v3"
        }
      ],
      "title": "Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19697",
        "HTML": "https://arxiv.org/html/2502.19697v3",
        "PDF": "https://arxiv.org/pdf/2502.19697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with adversarial attacks for person re-identification using vision-language models, not training data processing for LLMs."
      },
      "tasks": [
        "Adversarial Attack",
        "Attribute",
        "Contrastive Learning",
        "Person Re-Identification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00614",
      "abstract": "When planning motions in a configuration space that has underlying symmetries (e.g. when manipulating one or multiple symmetric objects), the ideal planning algorithm should take advantage of those symmetries to produce shorter trajectories. However, finite symmetries lead to complicated changes to the underlying topology of configuration space, preventing the use of standard algorithms. We demonstrate how the key primitives used for sampling-based planning can be efficiently implemented in spaces with finite symmetries. A rigorous theoretical analysis, building upon a study of the geometry of the configuration space, shows improvements in the sample complexity of several standard algorithms. Furthermore, a comprehensive slate of experiments demonstrates the practical improvements in both path length and runtime.",
      "authors": [
        "Thomas Cohn",
        "Russ Tedrake"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T20:49:26+00:00",
          "link": "https://arxiv.org/abs/2503.00614v1",
          "size": "712kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:37:40+00:00",
          "link": "https://arxiv.org/abs/2503.00614v2",
          "size": "716kb",
          "version": "v2"
        }
      ],
      "title": "Sampling-Based Motion Planning with Discrete Configuration-Space Symmetries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00614",
        "HTML": "https://arxiv.org/html/2503.00614v2",
        "PDF": "https://arxiv.org/pdf/2503.00614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion planning in configuration spaces with symmetries and does not discuss any aspects related to LLM training data processing or improvement of data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06737",
      "abstract": "This work suggests faster and space-efficient index construction algorithms for LSH for Euclidean distance (\\textit{a.k.a.}~\\ELSH) and cosine similarity (\\textit{a.k.a.}~\\SRP). The index construction step of these LSHs relies on grouping data points into several bins of hash tables based on their hashcode. To generate an $m$-dimensional hashcode of the $d$-dimensional data point, these LSHs first project the data point onto a $d$-dimensional random Gaussian vector and then discretise the resulting inner product. The time and space complexity of both \\ELSH~and \\SRP~for computing an $m$-sized hashcode of a $d$-dimensional vector is $O(md)$, which becomes impractical for large values of $m$ and $d$. To overcome this problem, we propose two alternative LSH hashcode generation algorithms, both for Euclidean distance and cosine similarity, namely, \\CSELSH, \\HCSELSH~and \\CSSRP, \\HCSSRP, respectively. \\CSELSH~and \\CSSRP~are based on count sketch \\cite{count_sketch} and \\HCSELSH~and \\HCSSRP~utilize higher-order count sketch \\cite{shi2019higher}. These proposals significantly reduce the hashcode computation time from $O(md)$ to $O(d)$. Additionally, both \\CSELSH~and \\CSSRP~reduce the space complexity from $O(md)$ to $O(d)$; ~and \\HCSELSH, \\HCSSRP~ reduce the space complexity from $O(md)$ to $O(N \\sqrt[N]{d})$ respectively, where $N\\geq 1$ denotes the size of the input/reshaped tensor. Our proposals are backed by strong mathematical guarantees, and we validate their performance through simulations on various real-world datasets.",
      "authors": [
        "Bhisham Dev Verma",
        "Rameshwar Pratap"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T19:33:01+00:00",
          "link": "https://arxiv.org/abs/2503.06737v1",
          "size": "146kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:27:40+00:00",
          "link": "https://arxiv.org/abs/2503.06737v2",
          "size": "148kb",
          "version": "v2"
        }
      ],
      "title": "Faster and Space Efficient Indexing for Locality Sensitive Hashing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06737",
        "HTML": "https://arxiv.org/html/2503.06737v2",
        "PDF": "https://arxiv.org/pdf/2503.06737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses efficient indexing for Locality Sensitive Hashing, aiming to reduce space and time complexity in hashcode generation, with no connection to LLM training data processing or improvements in data quality for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.07611",
      "abstract": "Evolomino is a pencil-and-paper logic puzzle popularized by the Japanese publisher Nikoli (like Sudoku, Kakuro, Slitherlink, Masyu, and Fillomino). The puzzle's name reflects its core mechanic: the shapes of polyomino-like blocks that players must draw gradually \"evolve\" in the directions indicated by pre-drawn arrows. We prove, by reduction from 3-SAT, that the question of whether there exists at least one solution to an Evolomino puzzle satisfying the rules is NP-complete. Since our reduction is parsimonious, i.e., it preserves the number of distinct solutions, we also prove that counting the number of solutions to an Evolomino puzzle is #P-complete.",
      "authors": [
        "Andrei V. Nikolaev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T11:02:27+00:00",
          "link": "https://arxiv.org/abs/2503.07611v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:01:41+00:00",
          "link": "https://arxiv.org/abs/2503.07611v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "Evolomino is NP-complete",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07611",
        "HTML": "https://arxiv.org/html/2503.07611v2",
        "PDF": "https://arxiv.org/pdf/2503.07611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work proves an NP-completeness result for the Evolomino puzzle, which is a logic puzzle, and is not related to the processing or creation of datasets for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.07919",
      "abstract": "Modern web agents possess computer use abilities that allow them to interact with webpages by sending commands to a virtual keyboard and mouse. While such agents have considerable potential to assist human users with complex tasks, evaluating their capabilities in real-world settings poses a major challenge. To this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111 information-seeking questions designed to evaluate a web agent's ability to search, browse, and identify factual information from the web. Unlike prior web agent benchmarks, solving BEARCUBS requires (1) accessing live web content rather than synthetic or simulated pages, which captures the unpredictability of real-world web interactions; and (2) performing a broad range of multimodal interactions (e.g., video understanding, 3D navigation) that cannot be bypassed via text-based workarounds. Each question in BEARCUBS has a corresponding short, unambiguous answer and a human-validated browsing trajectory, allowing for transparent evaluation of agent performance and strategies. A human study confirms that BEARCUBS questions are solvable but non-trivial (84.7% human accuracy), revealing domain knowledge gaps and overlooked details as common failure points. By contrast, state-of-the-art computer-using agents underperform, with the best-scoring system (OpenAI's Operator) reaching only 23.4% accuracy. These results highlight critical areas for improvement, including reliable source selection and more powerful multimodal capabilities. To facilitate future research, BEARCUBS will be updated periodically to replace invalid or contaminated questions, keeping the benchmark fresh for future generations of web agents.",
      "authors": [
        "Yixiao Song",
        "Katherine Thai",
        "Chau Minh Pham",
        "Yapei Chang",
        "Mazin Nadaf",
        "Mohit Iyyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T23:50:30+00:00",
          "link": "https://arxiv.org/abs/2503.07919v1",
          "size": "1287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:50:49+00:00",
          "link": "https://arxiv.org/abs/2503.07919v2",
          "size": "1348kb",
          "version": "v2"
        }
      ],
      "title": "BEARCUBS: A benchmark for computer-using web agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07919",
        "HTML": "https://arxiv.org/html/2503.07919v2",
        "PDF": "https://arxiv.org/pdf/2503.07919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces BEARCUBS, a benchmark for evaluating web agents, focusing on their ability to interact with real-world web content and perform multimodal interactions. It does not focus on LLM training data processing."
      },
      "tasks": [
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08161",
      "abstract": "Code embeddings capture the semantic representations of code and are crucial for various code-related large language model (LLM) applications, such as code search. Previous training primarily relies on optimizing the InfoNCE loss by comparing positive natural language (NL)-code pairs with in-batch negatives. However, due to the sparse nature of code contexts, training solely by comparing the major differences between positive and negative pairs may fail to capture deeper semantic nuances. To address this issue, we propose a novel order-augmented strategy for improved code search (OASIS). It leverages order-based similarity labels to train models to capture subtle differences in similarity among negative pairs. Extensive benchmark evaluations demonstrate that our OASIS model significantly outperforms previous state-of-the-art models focusing solely on major positive-negative differences. It underscores the value of exploiting subtle differences among negative pairs with order labels for effective code embedding training.",
      "authors": [
        "Zuchen Gao",
        "Zizheng Zhan",
        "Xianming Li",
        "Erxin Yu",
        "Ziqi Zhan",
        "Haotian Zhang",
        "Bin Chen",
        "Yuqun Zhang",
        "Jing Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T08:26:37+00:00",
          "link": "https://arxiv.org/abs/2503.08161v1",
          "size": "13834kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T06:04:42+00:00",
          "link": "https://arxiv.org/abs/2503.08161v2",
          "size": "13834kb",
          "version": "v2"
        },
        {
          "date": "2025-03-14T10:09:13+00:00",
          "link": "https://arxiv.org/abs/2503.08161v3",
          "size": "13834kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T09:34:49+00:00",
          "link": "https://arxiv.org/abs/2503.08161v4",
          "size": "5489kb",
          "version": "v4"
        }
      ],
      "title": "OASIS: Order-Augmented Strategy for Improved Code Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08161",
        "HTML": "https://arxiv.org/html/2503.08161v4",
        "PDF": "https://arxiv.org/pdf/2503.08161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents OASIS, a strategy for improving code search by using order-based similarity labels. It focuses on improving model performance in code-related tasks rather than addressing LLM training data processing."
      },
      "models": [
        {
          "model_path": "Kwaipilot/OASIS-code-1.3B",
          "downloads": "14",
          "likes": "12",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Kwaipilot/OASIS-code-1.3B"
        },
        {
          "model_path": "Kwaipilot/OASIS-code-embedding-1.5B",
          "downloads": "1017",
          "likes": "8",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Kwaipilot/OASIS-code-embedding-1.5B"
        }
      ],
      "tasks": [
        "Code Search",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08388",
      "abstract": "Learning-based decision-making has the potential to enable generalizable Autonomous Driving (AD) policies, reducing the engineering overhead of rule-based approaches. Imitation Learning (IL) remains the dominant paradigm, benefiting from large-scale human demonstration datasets, but it suffers from inherent limitations such as distribution shift and imitation gaps. Reinforcement Learning (RL) presents a promising alternative, yet its adoption in AD remains limited due to the lack of standardized and efficient research frameworks. To this end, we introduce V-Max, an open research framework providing all the necessary tools to make RL practical for AD. V-Max is built on Waymax, a hardware-accelerated AD simulator designed for large-scale experimentation. We extend it using ScenarioNet's approach, enabling the fast simulation of diverse AD datasets.",
      "authors": [
        "Valentin Charraut and Wa\\\"el Doulazmi and Thomas Tournaire and Thibault Buhet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T12:53:24+00:00",
          "link": "https://arxiv.org/abs/2503.08388v1",
          "size": "7990kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T14:38:12+00:00",
          "link": "https://arxiv.org/abs/2503.08388v2",
          "size": "3428kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T15:30:27+00:00",
          "link": "https://arxiv.org/abs/2503.08388v3",
          "size": "4503kb",
          "version": "v3"
        }
      ],
      "title": "V-Max: A Reinforcement Learning Framework for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08388",
        "HTML": "https://arxiv.org/html/2503.08388v3",
        "PDF": "https://arxiv.org/pdf/2503.08388"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces V-Max, a reinforcement learning framework for autonomous driving. It discusses decision-making models and simulation tools for AD, which is not related to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Decision Making",
        "Imitation Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/valeoai/v-max"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09576",
      "abstract": "We present Manify, an open-source Python library for non-Euclidean representation learning. Leveraging manifold learning techniques, Manify provides tools for learning embeddings in (products of) non-Euclidean spaces, performing classification and regression with data that lives in such spaces, estimating the curvature of a manifold, and more. Manify aims to advance research and applications in machine learning by offering a comprehensive suite of tools for manifold-based data analysis. Our source code, examples, and documentation are available at https://github.com/pchlenski/manify.",
      "authors": [
        "Philippe Chlenski",
        "Kaizhu Du",
        "Dylan Satow",
        "Raiyan R. Khan",
        "and Itsik Pe'er"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T17:44:40+00:00",
          "link": "https://arxiv.org/abs/2503.09576v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:28:30+00:00",
          "link": "https://arxiv.org/abs/2503.09576v2",
          "size": "122kb",
          "version": "v2"
        }
      ],
      "title": "Manify: A Python Library for Learning Non-Euclidean Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09576",
        "HTML": "https://arxiv.org/html/2503.09576v2",
        "PDF": "https://arxiv.org/pdf/2503.09576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Manify, a Python library for non-Euclidean representation learning, aimed at manifold-based data analysis. It does not address LLM training data processing."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/pchlenski/manify",
        "https://github.com/pchlenski/embedders"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10200",
      "abstract": "Existing MLLMs encounter significant challenges in modeling the temporal context within long videos. Currently, mainstream Agent-based methods use external tools to assist a single MLLM in answering long video questions. Despite such tool-based support, a solitary MLLM still offers only a partial understanding of long videos, resulting in limited performance. In order to better address long video tasks, we introduce LVAgent, the first framework enabling multi-round dynamic collaboration of MLLM agents in long video understanding. Our method consists of four key steps: 1) Selection: We pre-select appropriate agents from the model library to form optimal agent teams based on different tasks. 2) Perception: We design an effective retrieval scheme for long videos to improve the coverage of critical temporal segments while maintaining computational efficiency. 3) Action: Agents answer long video questions and exchange reasons. 4) Reflection: We evaluate each agent's performance in each round of discussion and optimize the agent team for dynamic collaboration. The agents iteratively refine their answers by multi-round dynamical collaboration of MLLM agents. LVAgent is the first agent system method that outperforms all closed-source models (like GPT-4o) and open-source models (like InternVL-2.5 and Qwen2-VL) in the long video understanding tasks. Our LVAgent achieves an accuracy of 80\\% on four mainstream long video understanding tasks. Notably, LVAgent improves accuracy by 13.3\\% on LongVideoBench. Code is available at https://github.com/64327069/LVAgent.",
      "authors": [
        "Boyu Chen",
        "Zhengrong Yue",
        "Siran Chen",
        "Zikang Wang",
        "Yang Liu",
        "Peng Li",
        "Yali Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T09:35:09+00:00",
          "link": "https://arxiv.org/abs/2503.10200v1",
          "size": "20050kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T02:07:45+00:00",
          "link": "https://arxiv.org/abs/2503.10200v2",
          "size": "12676kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T02:23:25+00:00",
          "link": "https://arxiv.org/abs/2503.10200v3",
          "size": "7317kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T03:55:18+00:00",
          "link": "https://arxiv.org/abs/2503.10200v4",
          "size": "7317kb",
          "version": "v4"
        }
      ],
      "title": "LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10200",
        "HTML": "https://arxiv.org/html/2503.10200v4",
        "PDF": "https://arxiv.org/pdf/2503.10200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents LVAgent, a framework for understanding long videos through multi-round collaboration of MLLM agents. It focuses on agent-based video understanding rather than LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Optical Character Recognition (OCR)",
        "Retrieval",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11737",
      "abstract": "Graph pooling, which compresses a whole graph into a smaller coarsened graph, is an essential component of graph representation learning. To efficiently compress a given graph, graph pooling methods often drop their nodes with attention-based scoring with the task loss. However, this often results in simply removing nodes with lower degrees without consideration of their feature-level relevance to the given task. To fix this problem, we propose a Multi-View Pruning(MVP), a graph pruning method based on a multi-view framework and reconstruction loss. Given a graph, MVP first constructs multiple graphs for different views either by utilizing the predefined modalities or by randomly partitioning the input features, to consider the importance of each node in diverse perspectives. Then, it learns the score for each node by considering both the reconstruction and the task loss. MVP can be incorporated with any hierarchical pooling framework to score the nodes. We validate MVP on multiple benchmark datasets by coupling it with two graph pooling methods, and show that it significantly improves the performance of the base graph pooling method, outperforming all baselines. Further analysis shows that both the encoding of multiple views and the consideration of reconstruction loss are the key to the success of MVP, and that it indeed identifies nodes that are less important according to domain knowledge.",
      "authors": [
        "Hanjin Kim",
        "Jiseong Park",
        "Seojin Kim",
        "Jueun Choi",
        "Doheon Lee",
        "Sung Ju Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T14:44:54+00:00",
          "link": "https://arxiv.org/abs/2503.11737v1",
          "size": "2213kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T14:34:49+00:00",
          "link": "https://arxiv.org/abs/2503.11737v2",
          "size": "2213kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:59:01+00:00",
          "link": "https://arxiv.org/abs/2503.11737v3",
          "size": "1158kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T01:33:12+00:00",
          "link": "https://arxiv.org/abs/2503.11737v4",
          "size": "1158kb",
          "version": "v4"
        }
      ],
      "title": "Multi-View Node Pruning for Accurate Graph Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11737",
        "HTML": "https://arxiv.org/html/2503.11737v4",
        "PDF": "https://arxiv.org/pdf/2503.11737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses graph representation learning through a graph pruning method, which is unrelated to the specific training data processing for LLMs, such as dataset creation or improvement."
      },
      "tasks": [
        "Graph Representation Learning",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12347",
      "abstract": "Synthetic data offers a promising path to train models while preserving data privacy. Differentially private (DP) finetuning of large language models (LLMs) as data generator is effective, but is impractical when computation resources are limited. Meanwhile, prompt-based methods such as private evolution depend heavily on the manual prompts, and ineffectively use private information in their iterative data selection process. To overcome these limitations, we propose CTCL (Data Synthesis with ConTrollability and CLustering), a novel framework for generating privacy-preserving synthetic data without extensive prompt engineering or billion-scale LLM finetuning. CTCL pretrains a lightweight 140M conditional generator and a clustering-based topic model on large-scale public data. To further adapt to the private domain, the generator is DP finetuned on private data for fine-grained textual information, while the topic model extracts a DP histogram representing distributional information. The DP generator then samples according to the DP histogram to synthesize a desired number of data examples. Evaluation across five diverse domains demonstrates the effectiveness of our framework, particularly in the strong privacy regime. Systematic ablation validates the design of each framework component and highlights the scalability of our approach.",
      "authors": [
        "Bowen Tan",
        "Zheng Xu",
        "Eric Xing",
        "Zhiting Hu",
        "Shanshan Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T04:00:32+00:00",
          "link": "https://arxiv.org/abs/2503.12347v1",
          "size": "393kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:39:41+00:00",
          "link": "https://arxiv.org/abs/2503.12347v2",
          "size": "379kb",
          "version": "v2"
        }
      ],
      "title": "Synthesizing Privacy-Preserving Text Data via Finetuning without Finetuning Billion-Scale LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12347",
        "HTML": "https://arxiv.org/html/2503.12347v2",
        "PDF": "https://arxiv.org/pdf/2503.12347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes CTCL, a framework for generating privacy-preserving synthetic data, which is directly related to data generation and processing for training LLMs, particularly for fine-tuning with privacy constraints."
      },
      "tasks": [
        "Clustering",
        "Privacy Preserving",
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12989",
      "abstract": "Automatically annotating job data with standardized occupations from taxonomies, known as occupation classification, is crucial for labor market analysis. However, this task is often hindered by data scarcity and the challenges of manual annotations. While large language models (LLMs) hold promise due to their extensive world knowledge and in-context learning capabilities, their effectiveness depends on their knowledge of occupational taxonomies, which remains unclear. In this study, we assess the ability of LLMs to generate precise taxonomic entities from taxonomy, highlighting their limitations, especially for smaller models. To address these challenges, we propose a multi-stage framework consisting of inference, retrieval, and reranking stages, which integrates taxonomy-guided reasoning examples to enhance performance by aligning outputs with taxonomic knowledge. Evaluations on a large-scale dataset show that our framework not only enhances occupation and skill classification tasks, but also provides a cost-effective alternative to frontier models like GPT-4o, significantly reducing computational costs while maintaining strong performance. This makes it a practical and scalable solution for occupation classification and related tasks across LLMs.",
      "authors": [
        "Palakorn Achananuparp",
        "Ee-Peng Lim",
        "Yao Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T09:44:50+00:00",
          "link": "https://arxiv.org/abs/2503.12989v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:47:50+00:00",
          "link": "https://arxiv.org/abs/2503.12989v2",
          "size": "562kb",
          "version": "v2"
        }
      ],
      "title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12989",
        "HTML": "https://arxiv.org/html/2503.12989v2",
        "PDF": "https://arxiv.org/pdf/2503.12989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on occupation classification using LLMs, emphasizing task alignment and model application rather than processes related to training data processing or dataset creation for LLMs."
      },
      "tasks": [
        "Classification",
        "In-Context Learning",
        "Reranking",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13733",
      "abstract": "Large language models (LLMs) have revolutionized code generation, automating programming with remarkable efficiency. However, these advancements challenge programming skills, ethics, and assessment integrity, making the detection of LLM-generated code essential for maintaining accountability and standards. While, there has been some research on this problem, it generally lacks domain coverage and robustness, and only covers a small number of programming languages. To this end, we propose a framework capable of distinguishing between human- and LLM-written code across multiple programming languages, code generators, and domains. We use a large-scale dataset from renowned platforms and LLM-based code generators, alongside applying rigorous data quality checks, feature engineering, and comparative analysis using evaluation of traditional machine learning models, pre-trained language models (PLMs), and LLMs for code detection. We perform an evaluation on out-of-domain scenarios, such as detecting the authorship and hybrid authorship of generated code and generalizing to unseen models, domains, and programming languages. Moreover, our extensive experiments show that our framework effectively distinguishes human- from LLM-written code and sets a new benchmark for this task.",
      "authors": [
        "Daniil Orel",
        "Dilshod Azizov",
        "Preslav Nakov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T21:41:37+00:00",
          "link": "https://arxiv.org/abs/2503.13733v1",
          "size": "533kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:31:25+00:00",
          "link": "https://arxiv.org/abs/2503.13733v2",
          "size": "486kb",
          "version": "v2"
        }
      ],
      "title": "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13733",
        "HTML": "https://arxiv.org/html/2503.13733v2",
        "PDF": "https://arxiv.org/pdf/2503.13733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses data quality checks and feature engineering as part of a framework to detect LLM-generated code. It involves some data processing aspects but focuses more on code detection rather than enhancing LLM training datasets."
      },
      "tasks": [
        "Code Generation",
        "Ethics",
        "Feature Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.14247",
      "abstract": "This paper presents GeoFlow-SLAM, a robust and effective Tightly-Coupled RGBD-inertial SLAM for legged robotics undergoing aggressive and high-frequency motions.By integrating geometric consistency, legged odometry constraints, and dual-stream optical flow (GeoFlow), our method addresses three critical challenges:feature matching and pose initialization failures during fast locomotion and visual feature scarcity in texture-less scenes.Specifically, in rapid motion scenarios, feature matching is notably enhanced by leveraging dual-stream optical flow, which combines prior map points and poses. Additionally, we propose a robust pose initialization method for fast locomotion and IMU error in legged robots, integrating IMU/Legged odometry, inter-frame Perspective-n-Point (PnP), and Generalized Iterative Closest Point (GICP). Furthermore, a novel optimization framework that tightly couples depth-to-map and GICP geometric constraints is first introduced to improve the robustness and accuracy in long-duration, visually texture-less environments. The proposed algorithms achieve state-of-the-art (SOTA) on collected legged robots and open-source datasets. To further promote research and development, the open-source datasets and code will be made publicly available at https://github.com/HorizonRobotics/geoflow-slam",
      "authors": [
        "Tingyang Xiao",
        "Xiaolin Zhou",
        "Liu Liu",
        "Wei Sui",
        "Wei Feng",
        "Jiaxiong Qiu",
        "Xinjie Wang",
        "and Zhizhong Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T13:35:49+00:00",
          "link": "https://arxiv.org/abs/2503.14247v1",
          "size": "4224kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T11:51:56+00:00",
          "link": "https://arxiv.org/abs/2503.14247v2",
          "size": "1242kb",
          "version": "v2"
        }
      ],
      "title": "GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial and Legged Odometry Fusion SLAM for Dynamic Legged Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14247",
        "PDF": "https://arxiv.org/pdf/2503.14247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a SLAM system for robotics, which involves sensor data processing and dynamic motion challenges, thus not related to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Optical Flow Estimation"
      ],
      "repo_urls": [
        "https://github.com/nsn-hello/geoflow-slam"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.14953",
      "abstract": "Enabling Visual Semantic Models to effectively handle multi-view description matching has been a longstanding challenge. Existing methods typically learn a set of embeddings to find the optimal match for each view's text and compute similarity. However, the visual and text embeddings learned through these approaches have limited information capacity and are prone to interference from locally similar negative samples. To address this issue, we argue that the information capacity of embeddings is crucial and propose Dense-to-Sparse Feature Distilled Visual Semantic Embedding (D2S-VSE), which enhances the information capacity of sparse text by leveraging dense text distillation. Specifically, D2S-VSE is a two-stage framework. In the pre-training stage, we align images with dense text to enhance the information capacity of visual semantic embeddings. In the fine-tuning stage, we optimize two tasks simultaneously, distilling dense text embeddings to sparse text embeddings while aligning images and sparse texts, enhancing the information capacity of sparse text embeddings. Our proposed D2S-VSE model is extensively evaluated on the large-scale MS-COCO and Flickr30K datasets, demonstrating its superiority over recent state-of-the-art methods.",
      "authors": [
        "Yang Liu",
        "Wentao Feng",
        "Zhuoyao Liu",
        "Shudong Huang",
        "Jiancheng Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T07:42:24+00:00",
          "link": "https://arxiv.org/abs/2503.14953v1",
          "size": "513kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:40:04+00:00",
          "link": "https://arxiv.org/abs/2503.14953v2",
          "size": "428kb",
          "version": "v2"
        }
      ],
      "title": "Aligning Information Capacity Between Vision and Language via Dense-to-Sparse Feature Distillation for Image-Text Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14953",
        "HTML": "https://arxiv.org/html/2503.14953v2",
        "PDF": "https://arxiv.org/pdf/2503.14953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving image-text matching through enhanced visual semantic embeddings but does not involve any LLM training data processing or mention creating, generating, or processing datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15779",
      "abstract": "Human mobility modeling is critical for urban planning and transportation management, yet existing approaches often lack the integration capabilities needed to handle diverse data sources. We present a foundation model framework for universal human mobility patterns that leverages cross-domain data fusion and large language models to address these limitations. Our approach integrates multi-modal data of distinct nature and spatio-temporal resolution, including geographical, mobility, socio-demographic, and traffic information, to construct a privacy-preserving and semantically enriched human travel trajectory dataset. Our framework demonstrates adaptability through domain transfer techniques that ensure transferability across diverse urban contexts, as evidenced in case studies of Los Angeles (LA) and Egypt. The framework employs LLMs for semantic enrichment of trajectory data, enabling comprehensive understanding of mobility patterns. Quantitative evaluation shows that our generated synthetic dataset accurately reproduces mobility patterns observed in empirical data. The practical utility of this foundation model approach is demonstrated through large-scale traffic simulations for LA County, where results align well with observed traffic data. On California's I-405 corridor, the simulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume and 4.36% for speed compared to Caltrans PeMS observations, illustrating the framework's potential for intelligent transportation systems and urban mobility applications.",
      "authors": [
        "Haoxuan Ma",
        "Xishun Liao",
        "Yifan Liu",
        "Qinhua Jiang",
        "Chris Stanford",
        "Shangqing Cao",
        "Jiaqi Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T01:41:28+00:00",
          "link": "https://arxiv.org/abs/2503.15779v1",
          "size": "17027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T02:52:37+00:00",
          "link": "https://arxiv.org/abs/2503.15779v2",
          "size": "13184kb",
          "version": "v2"
        }
      ],
      "title": "Learning Universal Human Mobility Patterns with a Foundation Model for Cross-domain Data Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15779",
        "HTML": "https://arxiv.org/html/2503.15779v2",
        "PDF": "https://arxiv.org/pdf/2503.15779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves data generation through integrating various data types for human mobility modeling, the use of large language models is primarily for semantic enrichment rather than focused on LLM training data processing itself."
      },
      "tasks": [
        "Domain Adaptation",
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16395",
      "abstract": "The quality of probabilistic forecasts is crucial for decision-making under uncertainty. While proper scoring rules incentivize truthful reporting of precise forecasts, they fall short when forecasters face epistemic uncertainty about their beliefs, limiting their use in safety-critical domains where decision-makers (DMs) prioritize proper uncertainty management. To address this, we propose a framework for scoring imprecise forecasts -- forecasts given as a set of beliefs. Despite existing impossibility results for deterministic scoring rules, we enable truthful elicitation by drawing connection to social choice theory and introducing a two-way communication framework where DMs first share their aggregation rules (e.g., averaging or min-max) used in downstream decisions for resolving forecast ambiguity. This, in turn, helps forecasters resolve indecision during elicitation. We further show that truthful elicitation of imprecise forecasts is achievable using proper scoring rules randomized over the aggregation procedure. Our approach allows DM to elicit and integrate the forecaster's epistemic uncertainty into their decision-making process, thus improving credibility.",
      "authors": [
        "Anurag Singh",
        "Siu Lun Chau",
        "and Krikamol Muandet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T17:53:35+00:00",
          "link": "https://arxiv.org/abs/2503.16395v1",
          "size": "551kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T13:20:05+00:00",
          "link": "https://arxiv.org/abs/2503.16395v2",
          "size": "390kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T12:09:25+00:00",
          "link": "https://arxiv.org/abs/2503.16395v3",
          "size": "382kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T13:05:40+00:00",
          "link": "https://arxiv.org/abs/2503.16395v4",
          "size": "382kb",
          "version": "v4"
        }
      ],
      "title": "Truthful Elicitation of Imprecise Forecasts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16395",
        "HTML": "https://arxiv.org/html/2503.16395v4",
        "PDF": "https://arxiv.org/pdf/2503.16395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses elicitation of imprecise forecasts using scoring rules and social choice theory but does not pertain to LLM training data processing or improvements in data quality for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Decision Making Under Uncertainty"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16700",
      "abstract": "This paper introduces Q-learning with gradient target tracking, a novel reinforcement learning framework that provides a learned continuous target update mechanism as an alternative to the conventional hard update paradigm. In the standard deep Q-network (DQN), the target network is a copy of the online network's weights, held fixed for a number of iterations before being periodically replaced via a hard update. While this stabilizes training by providing consistent targets, it introduces a new challenge: the hard update period must be carefully tuned to achieve optimal performance. To address this issue, we propose two gradient-based target update methods: DQN with asymmetric gradient target tracking (AGT2-DQN) and DQN with symmetric gradient target tracking (SGT2-DQN). These methods replace the conventional hard target updates with continuous and structured updates using gradient descent, which effectively eliminates the need for manual tuning. We provide a theoretical analysis proving the convergence of these methods in tabular settings. Additionally, empirical evaluations demonstrate their advantages over standard DQN baselines, which suggest that gradient-based target updates can serve as an effective alternative to conventional target update mechanisms in Q-learning.",
      "authors": [
        "Donghwan Lee",
        "Bum Geun Park",
        "Taeho Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T20:46:25+00:00",
          "link": "https://arxiv.org/abs/2503.16700v1",
          "size": "18607kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:48:54+00:00",
          "link": "https://arxiv.org/abs/2503.16700v2",
          "size": "11352kb",
          "version": "v2"
        }
      ],
      "title": "Deep Q-Learning with Gradient Target Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16700",
        "HTML": "https://arxiv.org/html/2503.16700v2",
        "PDF": "https://arxiv.org/pdf/2503.16700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a new reinforcement learning framework for Q-learning and is focused on target update mechanisms rather than any aspect of LLM data processing or dataset generation."
      },
      "tasks": [
        "Q-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17281",
      "abstract": "A flexible recommendation and retrieval system requires music similarity in terms of multiple partial elements of musical pieces to allow users to select the element they want to focus on. A method for music similarity learning using multiple networks with individual instrumental signals is effective but faces the problem that using each clean instrumental signal as a query is impractical for retrieval systems and using separated instrumental signals reduces accuracy owing to artifacts. In this paper, we present instrumental-part-based music similarity learning with a single network that takes mixed signals as input instead of individual instrumental signals. Specifically, we designed a single similarity embedding space with separated subspaces for each instrument, extracted by Conditional Similarity Networks, which are trained using the triplet loss with masks. Experimental results showed that (1) the proposed method can obtain more accurate embedding representation than using individual networks using separated signals as input in the evaluation of an instrument that had low accuracy, (2) each sub-embedding space can hold the characteristics of the corresponding instrument, and (3) the selection of similar musical pieces focusing on each instrumental sound by the proposed method can obtain human acceptance, especially when focusing on timbre.",
      "authors": [
        "Yuka Hashizume",
        "Li Li",
        "Atsushi Miyashita",
        "Tomoki Toda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T16:29:28+00:00",
          "link": "https://arxiv.org/abs/2503.17281v1",
          "size": "7792kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:23:31+00:00",
          "link": "https://arxiv.org/abs/2503.17281v2",
          "size": "7092kb",
          "version": "v2"
        }
      ],
      "title": "Learning Separated Representations for Instrument-based Music Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17281",
        "HTML": "https://arxiv.org/html/2503.17281v2",
        "PDF": "https://arxiv.org/pdf/2503.17281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses music similarity learning based on instrumental tracks, not addressing any LLM training data processing or improvements in the quality of datasets used for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19263",
      "abstract": "Visual reasoning (VR), which is crucial in many fields for enabling human-like visual understanding, remains highly challenging. Recently, compositional visual reasoning approaches, which leverage the reasoning abilities of large language models (LLMs) with integrated tools to solve problems, have shown promise as more effective strategies than end-to-end VR methods. However, these approaches face limitations, as frozen LLMs lack tool awareness in VR, leading to performance bottlenecks. While leveraging LLMs for reasoning is widely used in other domains, they are not directly applicable to VR due to limited training data, imperfect tools that introduce errors and reduce data collection efficiency in VR, and challenging in fine-tuning on noisy workflows. To address these challenges, we propose DWIM: i) Discrepancy-aware training Workflow generation, which assesses tool usage and extracts more viable workflows for training; and ii) Instruct-Masking fine-tuning, which guides the model to only clone effective actions, enabling the generation of more practical solutions. Our experiments demonstrate that DWIM achieves state-of-the-art performance across various VR tasks, exhibiting strong generalization on multiple widely-used datasets.",
      "authors": [
        "Fucai Ke",
        "Vijay Kumar B G",
        "Xingjian Leng",
        "Zhixi Cai",
        "Zaid Khan",
        "Weiqing Wang",
        "Pari Delir Haghighi",
        "Hamid Rezatofighi",
        "Manmohan Chandraker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T01:57:59+00:00",
          "link": "https://arxiv.org/abs/2503.19263v1",
          "size": "31229kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T01:13:38+00:00",
          "link": "https://arxiv.org/abs/2503.19263v2",
          "size": "27520kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T14:10:06+00:00",
          "link": "https://arxiv.org/abs/2503.19263v3",
          "size": "27525kb",
          "version": "v3"
        }
      ],
      "title": "DWIM: Towards Tool-aware Visual Reasoning via Discrepancy-aware Workflow Generation & Instruct-Masking Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19263",
        "PDF": "https://arxiv.org/pdf/2503.19263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses visual reasoning enhancements and includes methods for generating training workflows and fine-tuning strategies. However, its primary focus is on tool usage and visual reasoning tasks, only tangentially related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19444",
      "abstract": "Pre-trained models (PTMs) have become a cornerstone of AI-based software, allowing for rapid integration and development with minimal training overhead. However, their adoption also introduces unique safety challenges, such as data leakage and biased outputs, that demand rigorous handling by downstream developers. While previous research has proposed taxonomies of AI safety concerns and various mitigation strategies, how downstream developers address these issues remains unexplored.\n  This study investigates downstream developers' concerns, practices and perceived challenges regarding AI safety issues during AI-based software development. To achieve this, we conducted a mixed-method study, including interviews with 18 participants, a survey of 86 practitioners, and an analysis of 874 AI incidents from the AI Incident Database. Our results reveal that while developers generally demonstrate strong awareness of AI safety concerns, their practices, especially during the preparation and PTM selection phases, are often inadequate. The lack of concrete guidelines and policies leads to significant variability in the comprehensiveness of their safety approaches throughout the development lifecycle, with additional challenges such as poor documentation and knowledge gaps, further impeding effective implementation. Based on our findings, we offer suggestions for PTM developers, AI-based software developers, researchers, and policy makers to enhance the integration of AI safety measures.",
      "authors": [
        "Haoyu Gao",
        "Mansooreh Zahedi",
        "Wenxin Jiang",
        "Hong Yi Lin",
        "James Davis",
        "Christoph Treude"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T08:35:30+00:00",
          "link": "https://arxiv.org/abs/2503.19444v1",
          "size": "273kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T02:57:42+00:00",
          "link": "https://arxiv.org/abs/2503.19444v2",
          "size": "273kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T01:03:31+00:00",
          "link": "https://arxiv.org/abs/2503.19444v3",
          "size": "287kb",
          "version": "v3"
        }
      ],
      "title": "AI Safety in the Eyes of the Downstream Developer: A First Look at Concerns, Practices, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19444",
        "HTML": "https://arxiv.org/html/2503.19444v3",
        "PDF": "https://arxiv.org/pdf/2503.19444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores AI safety concerns from the perspective of downstream developers using pre-trained models, focusing on safety practices rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19530",
      "abstract": "Popular PEFT methods reduce trainable parameter count for fine-tuning by parameterizing new low-rank or sparse trainable weights in parallel to the frozen pre-trained weights $W$. However, these weights are trained from scratch, and there exists a performance gap between these methods and full fine-tuning, especially in low-budget settings. We introduce VectorFit, a new way of parameterization that efficiently utilizes the existing knowledge embedded in $W$ by adaptively training their singular vectors and biases. We show that utilizing the structural and transformational properties of $W$ in this way can lead to high-rank incremental weight matrices $\\Delta W$, comparable to that of full fine-tuning. VectorFit delivers superior results with \\textbf{9$\\boldsymbol\\times$} fewer trainable parameters than the leading PEFT methods. Through comprehensive experiments across 19 datasets covering a wide range of language and vision tasks such as natural language understanding and generation, question answering, image classification, and image generation, we demonstrate that VectorFit surpasses baselines in terms of performance as a function of parameter-efficiency.",
      "authors": [
        "Suhas G Hegde",
        "Shilpy Kaur",
        "Aruna Tiwari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T10:36:27+00:00",
          "link": "https://arxiv.org/abs/2503.19530v1",
          "size": "19343kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:52:54+00:00",
          "link": "https://arxiv.org/abs/2503.19530v2",
          "size": "18358kb",
          "version": "v2"
        }
      ],
      "title": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19530",
        "HTML": "https://arxiv.org/html/2503.19530v2",
        "PDF": "https://arxiv.org/pdf/2503.19530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces VectorFit, a method for fine-tuning pre-trained models to improve parameter efficiency. It does not address data processing aspects of LLM training."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Image Generation",
        "Natural Language Understanding",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20162",
      "abstract": "The Subset Sum problem, which asks whether a set of $n$ integers has a subset summing to a target $t$, is a fundamental NP-complete problem in cryptography and combinatorial optimization. The classical meet-in-the-middle (MIM) algorithm of Horowitz--Sahni runs in $\\mathcal{O}^*(2^{n/2})$, which remains the best-known deterministic bound. Yet in practice, many instances exhibit abundant collisions in partial sums, so the true difficulty is often governed by $U = |\\Sigma(S)|$, the number of unique subset sums.\n  We present a structure-aware, adaptive solver that enumerates only the distinct subset sums, pruning duplicates on the fly and achieving deterministic runtime $\\mathcal{O}(U \\cdot n^2)$ and expected randomized runtime $\\mathcal{O}(U \\cdot n)$. Its core is a canonical unique-subset-sums enumerator combined with a double meet-in-the-middle strategy, supporting anytime and online modes.\n  To ensure worst-case gains even on unstructured inputs, we introduce a Controlled Aliasing technique that provably reduces the enumeration space by a fixed constant factor. This yields a guaranteed global runtime of $\\mathcal{O}^*(2^{n/2 - \\varepsilon})$ for some $\\varepsilon > 0$, strictly improving upon classical bounds.\n  Empirical results show that the solver adapts efficiently to structured inputs with low entropy (e.g., instances with small doubling constants, duplicates, or additive progressions) often approaching near-dynamic programming performance. We conclude by outlining how this adaptive framework can be extended to other NP-complete problems.",
      "authors": [
        "Jesus Salas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T02:32:13+00:00",
          "link": "https://arxiv.org/abs/2503.20162v1",
          "size": "1208kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T11:26:58+00:00",
          "link": "https://arxiv.org/abs/2503.20162v2",
          "size": "377kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-$2^{n/2}$ Enumeration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20162",
        "HTML": "https://arxiv.org/html/2503.20162v2",
        "PDF": "https://arxiv.org/pdf/2503.20162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Subset Sum problem and proposes a new solver for it, which is unrelated to LLM training data processing or any data operations related to large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.22673",
      "abstract": "Large Action models are essential for enabling autonomous agents to perform complex tasks. However, training such models remains challenging due to the diversity of agent environments and the complexity of noisy agentic data. Existing infrastructure offers limited support for scalable, agent-specific fine-tuning and standardized agent data processing. We introduce ActionStudio, a lightweight and extensible data and training framework designed for large action models. ActionStudio unifies diverse agent trajectories using our proposed Unified Format 2.0, supports a range of training workflows with optimized multi-node distributed setup, and integrates robust preprocessing and real-time verification tools. ActionStudio demonstrates up to 9x higher throughput compared to existing agentic training frameworks, and our trained models yield top performances across public and realistic agent benchmarks. To support the broader research community, we open-source the ActionStudio framework and release actionstudio-98k, a curated dataset of 98k high-quality trajectories. Code: https://github.com/SalesforceAIResearch/xLAM.",
      "authors": [
        "Jianguo Zhang",
        "Thai Hoang",
        "Ming Zhu",
        "Zuxin Liu",
        "Shiyu Wang",
        "Tulika Awalgaonkar",
        "Akshara Prabhakar",
        "Haolin Chen",
        "Weiran Yao",
        "Zhiwei Liu",
        "Juntao Tan",
        "Juan Carlos Niebles",
        "Shelby Heinecke",
        "Huan Wang",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T17:58:33+00:00",
          "link": "https://arxiv.org/abs/2503.22673v1",
          "size": "1645kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T16:38:50+00:00",
          "link": "https://arxiv.org/abs/2503.22673v2",
          "size": "1645kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T01:19:22+00:00",
          "link": "https://arxiv.org/abs/2503.22673v3",
          "size": "927kb",
          "version": "v3"
        }
      ],
      "title": "ActionStudio: A Lightweight Framework for Data and Training of Large Action Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22673",
        "PDF": "https://arxiv.org/pdf/2503.22673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "ActionStudio provides a framework for data and training of large action models, featuring data unification, preprocessing, and a curated dataset of 98k trajectories. This directly contributes to data processing operations for training, including data collection and creation, hence relevant to LLM training data processing."
      },
      "models": [
        {
          "model_path": "Salesforce/Llama-xLAM-2-70b-fc-r",
          "downloads": "6799",
          "likes": "35",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-70b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-1b-fc-r",
          "downloads": "2031",
          "likes": "6",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-1b-fc-r"
        },
        {
          "model_path": "Salesforce/Llama-xLAM-2-8b-fc-r",
          "downloads": "30186",
          "likes": "30",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-32b-fc-r",
          "downloads": "1814",
          "likes": "22",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-32b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-1b-fc-r",
          "downloads": "1102",
          "likes": "57",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-1b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-7b-fc-r",
          "downloads": "1052",
          "likes": "78",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-7b-fc-r"
        },
        {
          "model_path": "Salesforce/xLAM-8x7b-r",
          "downloads": "907",
          "likes": "15",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-8x7b-r"
        },
        {
          "model_path": "Salesforce/xLAM-8x22b-r",
          "downloads": "913",
          "likes": "45",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-8x22b-r"
        },
        {
          "model_path": "Salesforce/xLAM-7b-r",
          "downloads": "1830",
          "likes": "30",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-7b-r"
        },
        {
          "model_path": "Salesforce/xLAM-2-3b-fc-r-gguf",
          "downloads": "321",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-3b-fc-r-gguf"
        },
        {
          "model_path": "Salesforce/xLAM-2-1b-fc-r-gguf",
          "downloads": "323",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-1b-fc-r-gguf"
        },
        {
          "model_path": "Salesforce/Llama-xLAM-2-8b-fc-r-gguf",
          "downloads": "1371",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r-gguf"
        },
        {
          "model_path": "Salesforce/xLAM-2-3b-fc-r",
          "downloads": "3033",
          "likes": "10",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Salesforce/xLAM-2-3b-fc-r"
        },
        {
          "model_path": "amd/Llama-xLAM-2-8b-fc-r-awq-g128-int4-asym-bfp16-onnx-hybrid",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/amd/Llama-xLAM-2-8b-fc-r-awq-g128-int4-asym-bfp16-onnx-hybrid"
        },
        {
          "model_path": "kmhalvin/xLAM-2-1b-fc-r-SpinQuant-ET",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/kmhalvin/xLAM-2-1b-fc-r-SpinQuant-ET"
        },
        {
          "model_path": "licongwei/xLAM-2-3b-fc-r-SpinQuant-ET",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/licongwei/xLAM-2-3b-fc-r-SpinQuant-ET"
        },
        {
          "model_path": "Mungert/xLAM-2-3b-fc-r-GGUF",
          "downloads": "2068",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/xLAM-2-3b-fc-r-GGUF"
        },
        {
          "model_path": "Mungert/Llama-xLAM-2-8b-fc-r-GGUF",
          "downloads": "791",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/Llama-xLAM-2-8b-fc-r-GGUF"
        },
        {
          "model_path": "Mungert/xLAM-2-32b-fc-r-GGUF",
          "downloads": "3889",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Mungert/xLAM-2-32b-fc-r-GGUF"
        }
      ],
      "tasks": [
        "Diversity"
      ],
      "repo_urls": [
        "https://github.com/SalesforceAIResearch/xLAM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23033",
      "abstract": "Existing dense retrieval models struggle with reasoning-intensive retrieval task as they fail to capture implicit relevance that requires reasoning beyond surface-level semantic information. To address these challenges, we propose Scenario-Profiled Indexing with Knowledge Expansion (SPIKE), a dense retrieval framework that explicitly indexes implicit relevance by decomposing documents into scenario-based retrieval units. SPIKE organizes documents into scenario, which encapsulates the reasoning process necessary to uncover implicit relationships between hypothetical information needs and document content. SPIKE constructs a scenario-augmented dataset using a powerful teacher large language model (LLM), then distills these reasoning capabilities into a smaller, efficient scenario generator. During inference, SPIKE incorporates scenario-level relevance alongside document-level relevance, enabling reasoning-aware retrieval. Extensive experiments demonstrate that SPIKE consistently enhances retrieval performance across various query types and dense retrievers. It also enhances the retrieval experience for users through scenario and offers valuable contextual information for LLMs in retrieval-augmented generation (RAG).",
      "authors": [
        "Sangam Lee",
        "Ryang Heo",
        "SeongKu Kang",
        "Dongha Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T10:36:54+00:00",
          "link": "https://arxiv.org/abs/2503.23033v1",
          "size": "2905kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:06:16+00:00",
          "link": "https://arxiv.org/abs/2503.23033v2",
          "size": "2907kb",
          "version": "v2"
        }
      ],
      "title": "Imagine All The Relevance: Scenario-Profiled Indexing with Knowledge Expansion for Dense Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23033",
        "HTML": "https://arxiv.org/html/2503.23033v2",
        "PDF": "https://arxiv.org/pdf/2503.23033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a retrieval framework enhancing performance through dataset construction with a LLM, but the focus is primarily on retrieval strategies and not on data processing for pretraining or fine-tuning LLMs."
      },
      "tasks": [
        "All",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/augustinLib/SPIKE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00463",
      "abstract": "Existing state-of-the-art AI-Generated image detection methods mostly consider extracting low-level information from RGB images to help improve the generalization of AI-Generated image detection, such as noise patterns. However, these methods often consider only a single type of low-level information, which may lead to suboptimal generalization. Through empirical analysis, we have discovered a key insight: different low-level information often exhibits generalization capabilities for different types of forgeries. Furthermore, we found that simple fusion strategies are insufficient to leverage the detection advantages of each low-level and high-level information for various forgery types. Therefore, we propose the Adaptive Low-level Experts Injection (ALEI) framework. Our approach introduces Lora Experts, enabling the backbone network, which is trained with high-level semantic RGB images, to accept and learn knowledge from different low-level information. We utilize a cross-attention method to adaptively fuse these features at intermediate layers. To prevent the backbone network from losing the modeling capabilities of different low-level features during the later stages of modeling, we developed a Low-level Information Adapter that interacts with the features extracted by the backbone network. Finally, we propose Dynamic Feature Selection, which dynamically selects the most suitable features for detecting the current image to maximize generalization detection capability. Extensive experiments demonstrate that our method, finetuned on only four categories of mainstream ProGAN data, performs excellently and achieves state-of-the-art results on multiple datasets containing unseen GAN and Diffusion methods.",
      "authors": [
        "Ziyin Zhou",
        "Ke Sun",
        "Zhongxi Chen",
        "Xianming Lin",
        "Yunpeng Luo",
        "Ke Yan",
        "Shouhong Ding",
        "Xiaoshuai Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T06:38:08+00:00",
          "link": "https://arxiv.org/abs/2504.00463v1",
          "size": "3761kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:39:59+00:00",
          "link": "https://arxiv.org/abs/2504.00463v2",
          "size": "3514kb",
          "version": "v2"
        }
      ],
      "title": "Exploring the Collaborative Advantage of Low-level Information on Generalizable AI-Generated Image Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00463",
        "HTML": "https://arxiv.org/html/2504.00463v2",
        "PDF": "https://arxiv.org/pdf/2504.00463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on improving AI-generated image detection through a particular framework and does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03770",
      "abstract": "Multimodal large language models (MLLMs) excel in vision-language tasks but also pose significant risks of generating harmful content, particularly through jailbreak attacks. Jailbreak attacks refer to intentional manipulations that bypass safety mechanisms in models, leading to the generation of inappropriate or unsafe content. Detecting such attacks is critical to ensuring the responsible deployment of MLLMs. Existing jailbreak detection methods face three primary challenges: (1) Many rely on model hidden states or gradients, limiting their applicability to white-box models, where the internal workings of the model are accessible; (2) They involve high computational overhead from uncertainty-based analysis, which limits real-time detection, and (3) They require fully labeled harmful datasets, which are often scarce in real-world settings. To address these issues, we introduce a test-time adaptive framework called JAILDAM. Our method leverages a memory-based approach guided by policy-driven unsafe knowledge representations, eliminating the need for explicit exposure to harmful data. By dynamically updating unsafe knowledge during test-time, our framework improves generalization to unseen jailbreak strategies while maintaining efficiency. Experiments on multiple VLM jailbreak benchmarks demonstrate that JAILDAM delivers state-of-the-art performance in harmful content detection, improving both accuracy and speed.",
      "authors": [
        "Yi Nian",
        "Shenzhe Zhu",
        "Yuehan Qin",
        "Li Li",
        "Ziyi Wang",
        "Chaowei Xiao",
        "Yue Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T05:00:28+00:00",
          "link": "https://arxiv.org/abs/2504.03770v1",
          "size": "3776kb",
          "version": "v1"
        },
        {
          "date": "2025-04-08T20:25:30+00:00",
          "link": "https://arxiv.org/abs/2504.03770v2",
          "size": "3776kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T22:33:51+00:00",
          "link": "https://arxiv.org/abs/2504.03770v3",
          "size": "2068kb",
          "version": "v3"
        }
      ],
      "title": "JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03770",
        "HTML": "https://arxiv.org/html/2504.03770v3",
        "PDF": "https://arxiv.org/pdf/2504.03770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on jailbreak detection in vision-language models and does not address any aspect of LLM training data processing, engineering, or dataset creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/ShenzheZhu/JailDAM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07389",
      "abstract": "Post-training quantization (PTQ) reduces a model's memory footprint by mapping full precision weights into low bit weights without costly retraining, but can degrade its downstream performance especially in low 2- to 3-bit settings. We develop a new mixed-precision PTQ approach, Task-Circuit Quantization (TaCQ), that draws parallels to automated circuit discovery, directly conditioning the quantization process on specific weight circuits -- which we define as sets of weights associated with downstream task performance. These weights are kept as 16-bit weights, while others are quantized, maintaining performance while only adding a marginal memory cost. Specifically, TaCQ contrasts unquantized model weights with a uniformly-quantized model to estimate the expected change in weights due to quantization and uses gradient information to predict the resulting impact on task performance, allowing us to preserve task-specific weights. We compare TaCQ-based quantization to existing mixed-precision quantization methods when conditioning both on general-purpose and task-specific data. Across QA, math reasoning, and text-to-SQL tasks for both Llama-3 and Qwen2.5, we find that TaCQ outperforms baselines using the same calibration data and a lower weight budget, achieving major improvements in the 2 and 3-bit regime. With only 3.1 bits we are able to recover 96% of Llama-3-8B-Instruct's unquantized 16-bit MMLU performance, obtaining a 5.25% absolute improvement over SPQR. We also observe consistently large gains over existing methods in the 2-bit regime, with an average gain of 14.74% over the strongest baseline, SliM-LLM. Moreover, we observe a 7.20% gain without conditioning on specific tasks, showing TaCQ's ability to identify important weights is not limited to task-conditioned settings.",
      "authors": [
        "Hanqi Xiao",
        "Yi-Lin Sung",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T02:19:03+00:00",
          "link": "https://arxiv.org/abs/2504.07389v1",
          "size": "915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:24:18+00:00",
          "link": "https://arxiv.org/abs/2504.07389v2",
          "size": "909kb",
          "version": "v2"
        }
      ],
      "title": "Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07389",
        "HTML": "https://arxiv.org/html/2504.07389v2",
        "PDF": "https://arxiv.org/pdf/2504.07389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper discusses post-training quantization for neural networks, it primarily addresses model optimization techniques rather than training data processing for LLMs."
      },
      "tasks": [
        "Math",
        "MMLU",
        "Quantization",
        "Text to SQL",
        "Text-To-SQL"
      ],
      "repo_urls": [
        "https://github.com/the-inscrutable-x/tacq"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09085",
      "abstract": "Crowdworking is a cost-efficient solution for acquiring class labels. Since these labels are subject to noise, various approaches to learning from crowds have been proposed. Typically, these approaches are evaluated with default hyperparameter configurations, resulting in unfair and suboptimal performance, or with hyperparameter configurations tuned via a validation set with ground truth class labels, representing an often unrealistic scenario. Moreover, both setups can produce different approach rankings, complicating study comparisons. Therefore, we introduce crowd-hpo as a framework for evaluating approaches to learning from crowds in combination with criteria to select well-performing hyperparameter configurations with access only to noisy crowd-labeled validation data. Extensive experiments with neural networks demonstrate that these criteria select hyperparameter configurations, which improve the learning from crowd approaches' generalization performances, measured on separate test sets with ground truth labels. Hence, incorporating such criteria into experimental studies is essential for enabling fairer and more realistic benchmarking.",
      "authors": [
        "Marek Herde",
        "Lukas L\\\"uhrs",
        "Denis Huseljic",
        "Bernhard Sick"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T05:36:16+00:00",
          "link": "https://arxiv.org/abs/2504.09085v1",
          "size": "391kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:00:33+00:00",
          "link": "https://arxiv.org/abs/2504.09085v2",
          "size": "878kb",
          "version": "v2"
        }
      ],
      "title": "crowd-hpo: Realistic Hyperparameter Optimization and Benchmarking for Learning from Crowds with Noisy Labels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09085",
        "PDF": "https://arxiv.org/pdf/2504.09085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on improving hyperparameter optimization for learning from crowdsourcing data. It does not pertain to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12016",
      "abstract": "Collecting human preference feedback is often expensive, leading recent works to develop principled algorithms to select them more efficiently. However, these works assume that the underlying reward function is linear, an assumption that does not hold in many real-life applications, such as online recommendation and LLM alignment. To address this limitation, we propose Neural-ADB, an algorithm based on the neural contextual dueling bandit framework that provides a principled and practical method for collecting human preference feedback when the underlying latent reward function is non-linear. We theoretically show that when preference feedback follows the Bradley-Terry-Luce model, the worst sub-optimality gap of the policy learned by Neural-ADB decreases at a sub-linear rate as the preference dataset increases. Our experimental results on preference datasets further corroborate the effectiveness of Neural-ADB.",
      "authors": [
        "Arun Verma",
        "Xiaoqiang Lin",
        "Zhongxiang Dai",
        "Daniela Rus",
        "Bryan Kian Hsiang Low"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T12:16:10+00:00",
          "link": "https://arxiv.org/abs/2504.12016v1",
          "size": "14484kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T20:57:36+00:00",
          "link": "https://arxiv.org/abs/2504.12016v2",
          "size": "14485kb",
          "version": "v2"
        }
      ],
      "title": "Active Human Feedback Collection via Neural Contextual Dueling Bandits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12016",
        "HTML": "https://arxiv.org/html/2504.12016v2",
        "PDF": "https://arxiv.org/pdf/2504.12016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses algorithms for collecting human preference feedback, which can be relevant for LLM alignment; however, it does not focus on any specific data processing methods for LLM training or fine-tuning datasets."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.13425",
      "abstract": "Existing Retrieval-Augmented Generation (RAG) systems face challenges in enterprise settings due to limited retrieval scope and data security risks. When relevant internal documents are unavailable, the system struggles to generate accurate and complete responses. Additionally, using closed-source Large Language Models (LLMs) raises concerns about exposing proprietary information. To address these issues, we propose the Secure Multifaceted-RAG (SecMulti-RAG) framework, which retrieves not only from internal documents but also from two supplementary sources: pre-generated expert knowledge for anticipated queries and on-demand external LLM-generated knowledge. To mitigate security risks, we adopt a local open-source generator and selectively utilize external LLMs only when prompts are deemed safe by a filtering mechanism. This approach enhances completeness, prevents data leakage, and reduces costs. In our evaluation on a report generation task in the automotive industry, SecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9 percent win rates across correctness, richness, and helpfulness in LLM-based evaluation, and 56.3 to 70.4 percent in human evaluation. This highlights SecMulti-RAG as a practical and secure solution for enterprise RAG.",
      "authors": [
        "Grace Byun",
        "Shinsun Lee",
        "Nayoung Choi",
        "Jinho D. Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T02:51:29+00:00",
          "link": "https://arxiv.org/abs/2504.13425v1",
          "size": "3299kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:32:46+00:00",
          "link": "https://arxiv.org/abs/2504.13425v2",
          "size": "1471kb",
          "version": "v2"
        }
      ],
      "title": "Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13425",
        "HTML": "https://arxiv.org/html/2504.13425v2",
        "PDF": "https://arxiv.org/pdf/2504.13425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a framework for secure hybrid knowledge retrieval in RAG systems, tangentially involving LLMs but not specifically contributing to LLM training data processing methodologies."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.15028",
      "abstract": "We present a method that computes an interpretable representation of material appearance within a highly compact, disentangled latent space. This representation is learned in a self-supervised fashion using an adapted FactorVAE. We train our model with a carefully designed unlabeled dataset, avoiding possible biases induced by human-generated labels. Our model demonstrates strong disentanglement and interpretability by effectively encoding material appearance and illumination, despite the absence of explicit supervision. Then, we use our representation as guidance for training a lightweight IP-Adapter to condition a diffusion pipeline that transfers the appearance of one or more images onto a target geometry, and allows the user to further edit the resulting appearance. Our approach offers fine-grained control over the generated results: thanks to the well-structured compact latent space, users can intuitively manipulate attributes such as hue or glossiness in image space to achieve the desired final appearance.",
      "authors": [
        "Santiago Jimenez-Navarro",
        "Julia Guerrero-Viu",
        "Belen Masia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T11:29:06+00:00",
          "link": "https://arxiv.org/abs/2504.15028v1",
          "size": "32507kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T14:09:31+00:00",
          "link": "https://arxiv.org/abs/2504.15028v2",
          "size": "33243kb",
          "version": "v2"
        }
      ],
      "title": "A Controllable Appearance Representation for Flexible Transfer and Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15028",
        "HTML": "https://arxiv.org/html/2504.15028v2",
        "PDF": "https://arxiv.org/pdf/2504.15028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study centers on a method for computing material appearance representations in image processing and editing, unrelated to LLM training data processing."
      },
      "tasks": [
        "Disentanglement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.15681",
      "abstract": "Humans naturally share information with those they are connected to, and video has become one of the dominant mediums for communication and expression on the Internet. To support the creation of high-quality large-scale video content, a modern pipeline requires a comprehensive understanding of both the raw input materials (e.g., the unedited footage captured by cameras) and the editing components (e.g., visual effects). In video editing scenarios, models must process multiple modalities (e.g., vision, audio, text) with strong background knowledge and handle flexible input lengths (e.g., hour-long raw videos), which poses significant challenges for traditional models. In this report, we introduce Vidi, a family of Large Multimodal Models (LMMs) for a wide range of video understand editing scenarios. The first release focuses on temporal retrieval, i.e., identifying the time ranges within the input videos corresponding to a given text query, which plays a critical role in intelligent editing. The model is capable of processing hour-long videos with strong temporal understanding capability, e.g., retrieve time ranges for certain queries. To support a comprehensive evaluation in real-world scenarios, we also present the VUE-TR benchmark, which introduces five key advancements. 1) Video duration: significantly longer than videos of existing temporal retrival datasets, 2) Audio support: includes audio-based queries, 3) Query format: diverse query lengths/formats, 4) Annotation quality: ground-truth time ranges are manually annotated. 5) Evaluation metric: a refined IoU metric to support evaluation over multiple time ranges. Remarkably, Vidi significantly outperforms leading proprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task, indicating its superiority in video editing scenarios.",
      "authors": [
        "Vidi Team",
        "Celong Liu",
        "Chia-Wen Kuo",
        "Dawei Du",
        "Fan Chen",
        "Guang Chen",
        "Jiamin Yuan",
        "Lingxi Zhang",
        "Lu Guo",
        "Lusha Li",
        "Longyin Wen",
        "Qingyu Chen",
        "Rachel Deng",
        "Sijie Zhu",
        "Stuart Siew",
        "Tong Jin",
        "Wei Lu",
        "Wen Zhong",
        "Xiaohui Shen",
        "Xin Gu",
        "Xing Mei",
        "Xueqiong Qu",
        "Zhenfang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T08:04:45+00:00",
          "link": "https://arxiv.org/abs/2504.15681v1",
          "size": "4341kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T05:36:55+00:00",
          "link": "https://arxiv.org/abs/2504.15681v2",
          "size": "4991kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T22:41:17+00:00",
          "link": "https://arxiv.org/abs/2504.15681v3",
          "size": "4105kb",
          "version": "v3"
        }
      ],
      "title": "Vidi: Large Multimodal Models for Video Understanding and Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15681",
        "HTML": "https://arxiv.org/html/2504.15681v3",
        "PDF": "https://arxiv.org/pdf/2504.15681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though related to large multimodal models for video understanding and editing, the paper does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.16394",
      "abstract": "Unstructured clinical data can serve as a unique and rich source of information that can meaningfully inform clinical practice. Extracting the most pertinent context from such data is critical for exploiting its true potential toward optimal and timely decision-making in patient care. While prior research has explored various methods for clinical text summarization, most prior studies either process all input tokens uniformly or rely on heuristic-based filters, which can overlook nuanced clinical cues and fail to prioritize information critical for decision-making. In this study, we propose Contextual, a novel framework that integrates a Context-Preserving Token Filtering method with a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By preserving context-specific important tokens and enriching them with structured knowledge, ConTextual improves both linguistic coherence and clinical fidelity. Our extensive empirical evaluations on two public benchmark datasets demonstrate that ConTextual consistently outperforms other baselines. Our proposed approach highlights the complementary role of token-level filtering and structured retrieval in enhancing both linguistic and clinical integrity, as well as offering a scalable solution for improving precision in clinical text generation.",
      "authors": [
        "Fahmida Liza Piya",
        "Rahmatollah Beheshti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T03:42:46+00:00",
          "link": "https://arxiv.org/abs/2504.16394v1",
          "size": "1066kb",
          "version": "v1"
        },
        {
          "date": "2025-05-12T14:57:14+00:00",
          "link": "https://arxiv.org/abs/2504.16394v2",
          "size": "980kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T15:50:27+00:00",
          "link": "https://arxiv.org/abs/2504.16394v3",
          "size": "981kb",
          "version": "v3"
        }
      ],
      "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16394",
        "HTML": "https://arxiv.org/html/2504.16394v3",
        "PDF": "https://arxiv.org/pdf/2504.16394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework for clinical text summarization that includes context-preserving token filtering, which could relate to data processing. However, the main focus is on improving summarization for clinical text, not generally on LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Knowledge Graphs",
        "Text Generation",
        "Text Summarization"
      ],
      "repo_urls": [
        "https://github.com/healthylaife/ConTextual"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16506",
      "abstract": "Tabular data is one of the most prevalent and important data formats in real-world applications such as healthcare, finance, and education. However, its effective use in machine learning is often constrained by data scarcity, privacy concerns, and class imbalance. Synthetic tabular data generation has emerged as a powerful solution, leveraging generative models to learn underlying data distributions and produce realistic, privacy-preserving samples. Although this area has seen growing attention, most existing surveys focus narrowly on specific methods (e.g., GANs or privacy-enhancing techniques), lacking a unified and comprehensive view that integrates recent advances such as diffusion models and large language models (LLMs).\n  In this survey, we present a structured and in-depth review of synthetic tabular data generation methods. Specifically, the survey is organized into three core components: (1) Background, which covers the overall generation pipeline, including problem definitions, synthetic tabular data generation methods, post processing, and evaluation; (2) Generation Methods, where we categorize existing approaches into traditional generation methods, diffusion model methods, and LLM-based methods, and compare them in terms of architecture, generation quality, and applicability; and (3) Applications and Challenges, which summarizes practical use cases, highlights common datasets, and discusses open challenges such as heterogeneity, data fidelity, and privacy protection.\n  This survey aims to provide researchers and practitioners with a holistic understanding of the field and to highlight key directions for future work in synthetic tabular data generation.",
      "authors": [
        "Ruxue Shi",
        "Yili Wang",
        "Mengnan Du",
        "Xu Shen",
        "Yi Chang and Xin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T08:33:34+00:00",
          "link": "https://arxiv.org/abs/2504.16506v1",
          "size": "752kb",
          "version": "v1"
        },
        {
          "date": "2025-05-10T06:10:06+00:00",
          "link": "https://arxiv.org/abs/2504.16506v2",
          "size": "758kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T03:22:43+00:00",
          "link": "https://arxiv.org/abs/2504.16506v3",
          "size": "609kb",
          "version": "v3"
        }
      ],
      "title": "A Comprehensive Survey of Synthetic Tabular Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16506",
        "HTML": "https://arxiv.org/html/2504.16506v3",
        "PDF": "https://arxiv.org/pdf/2504.16506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper surveys synthetic tabular data generation, including methods using LLMs, it primarily provides a comprehensive overview of the field rather than making direct contributions to LLM training data processing."
      },
      "tasks": [
        "Privacy Preserving",
        "Survey",
        "Synthetic Data Generation",
        "Tabular Data Generation"
      ],
      "repo_urls": [
        "https://github.com/ruxueshi/Awesome-Comprehensive-Survey-of-Synthetic-Tabular-Data-Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17703",
      "abstract": "Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.",
      "authors": [
        "Nusrat Jahan",
        "Ratun Rahman",
        "Michel Wang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T16:10:29+00:00",
          "link": "https://arxiv.org/abs/2504.17703v1",
          "size": "178kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:36:34+00:00",
          "link": "https://arxiv.org/abs/2504.17703v2",
          "size": "18kb",
          "version": "v2"
        }
      ],
      "title": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17703",
        "HTML": "https://arxiv.org/html/2504.17703v2",
        "PDF": "https://arxiv.org/pdf/2504.17703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on Federated Learning, focusing on privacy-preserving collaborative intelligence, which does not directly relate to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20262",
      "abstract": "The class TotP consists of functions that count the number of all paths of a nondeterministic polynomial-time Turing machine. In this paper, we give a predicate based definition of TotP, analogous to a standard definition of #P. From a new characterization of TotP it follows that many well known #P problems belong to TotP, and TotP = #P if and only if P = NP. We show that TotP has several closure properties of #P and GapP, and also properties that are not known to hold for #P and GapP. We also prove that the closure of TotP under left composition with FP+ is equivalent to TotP = FP+ and P = PP, and give examples of FP+-functions such that if TotP is closed under composition with them, then it is closed under composition with FP+.",
      "authors": [
        "Yaroslav Ivanashev"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T21:07:13+00:00",
          "link": "https://arxiv.org/abs/2504.20262v1",
          "size": "8kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T04:14:11+00:00",
          "link": "https://arxiv.org/abs/2504.20262v2",
          "size": "8kb",
          "version": "v2"
        },
        {
          "date": "2025-05-26T13:01:22+00:00",
          "link": "https://arxiv.org/abs/2504.20262v3",
          "size": "9kb",
          "version": "v3"
        },
        {
          "date": "2025-06-02T23:47:10+00:00",
          "link": "https://arxiv.org/abs/2504.20262v4",
          "size": "20kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T22:07:43+00:00",
          "link": "https://arxiv.org/abs/2504.20262v5",
          "size": "19kb",
          "version": "v5"
        }
      ],
      "title": "Closure Properties and Characterizations of TotP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20262",
        "HTML": "https://arxiv.org/html/2504.20262v5",
        "PDF": "https://arxiv.org/pdf/2504.20262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is a theoretical paper about the characterization and closure properties of TotP, which is related to computational theory and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20277",
      "abstract": "This paper proposes a supervised training algorithm for learning stochastic resource allocation policies with generative diffusion models (GDMs). We formulate the allocation problem as the maximization of an ergodic utility function subject to ergodic Quality of Service (QoS) constraints. Given samples from a stochastic expert policy that yields a near-optimal solution to the constrained optimization problem, we train a GDM policy to imitate the expert and generate new samples from the optimal distribution. We achieve near-optimal performance through the sequential execution of the generated samples. To enable generalization to a family of network configurations, we parameterize the backward diffusion process with a graph neural network (GNN) architecture. We present numerical results in a case study of power control.",
      "authors": [
        "Yigit Berkay Uslu",
        "Samar Hadou",
        "Shirin Saeedi Bidokhti",
        "Alejandro Ribeiro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T21:44:31+00:00",
          "link": "https://arxiv.org/abs/2504.20277v1",
          "size": "1550kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:38:32+00:00",
          "link": "https://arxiv.org/abs/2504.20277v2",
          "size": "1284kb",
          "version": "v2"
        }
      ],
      "title": "Generative Diffusion Models for Resource Allocation in Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20277",
        "HTML": "https://arxiv.org/html/2504.20277v2",
        "PDF": "https://arxiv.org/pdf/2504.20277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of generative diffusion models for resource allocation in wireless networks, which is not related to LLM training data processing."
      },
      "tasks": [
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20333",
      "abstract": "We give a new framework based on graph regularity lemmas, for list decoding and list recovery of codes based on spectral expanders. Using existing algorithms for computing regularity decompositions of sparse graphs in (randomized) near-linear time, and appropriate choices for the constant-sized inner/base codes, we prove the following:\n  - Expander-based codes constructed using the distance amplification technique of Alon, Edmonds and Luby [FOCS 1995] with rate $\\rho$, can be list decoded to a radius $1 - \\rho - \\epsilon$ in near-linear time. By known results, the output list has size $O(1/\\epsilon)$.\n  - The above codes of Alon, Edmonds and Luby, with rate $\\rho$, can also be list recovered to radius $1 - \\rho - \\epsilon$ in near-linear time, with constant-sized output lists.\n  - The Tanner code construction of Sipser and Spielman [IEEE Trans. Inf. Theory 1996] with distance $\\delta$, can be list decoded to radius $\\delta - \\epsilon$ in near-linear time, with constant-sized output lists.\n  Our results imply novel combinatorial as well as algorithmic bounds for each of the above explicit constructions. All of these bounds are obtained via combinatorial rigidity phenomena, proved using (weak) graph regularity. The regularity framework allows us to lift the list decoding and list recovery properties for the local base codes, to the global codes obtained via the above constructions.",
      "authors": [
        "Shashank Srivastava",
        "Madhur Tulsiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T00:53:34+00:00",
          "link": "https://arxiv.org/abs/2504.20333v1",
          "size": "613kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:20:01+00:00",
          "link": "https://arxiv.org/abs/2504.20333v2",
          "size": "700kb",
          "version": "v2"
        }
      ],
      "title": "List Decoding Expander-Based Codes up to Capacity in Near-Linear Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20333",
        "HTML": "https://arxiv.org/html/2504.20333v2",
        "PDF": "https://arxiv.org/pdf/2504.20333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses advances in list decoding and list recovery of codes using graph regularity lemmas and expanders, with no mention of LLM or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20432",
      "abstract": "Language-based information flow control (IFC) enables reasoning about and enforcing security policies in decentralized applications. While information flow properties are relatively extensional and compositional, designing expressive systems that enforce such properties remains challenging. In particular, it can be difficult to use IFC labels to model certain security assumptions, such as semi-honest agents.\n  Motivated by these modeling limitations, we study the algebraic semantics of lattice-based IFC label models, and propose a semantic framework that allows formalizing asymmetric delegation, which is partial delegation of confidentiality or integrity. Our framework supports downgrading of information and ensures their safety through nonmalleable information flow (NMIF).\n  To demonstrate the practicality of our framework, we design and implement a novel algorithm that statically checks NMIF and a label inference procedure that efficiently supports bounded label polymorphism, allowing users to write code generic with respect to labels.",
      "authors": [
        "Silei Ren and Co\\c{s}ku Acay and Andrew C. Myers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T05:00:17+00:00",
          "link": "https://arxiv.org/abs/2504.20432v1",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:38:43+00:00",
          "link": "https://arxiv.org/abs/2504.20432v2",
          "size": "67kb",
          "version": "v2"
        }
      ],
      "title": "An Algebraic Approach to Asymmetric Delegation and Polymorphic Label Inference (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20432",
        "HTML": "https://arxiv.org/html/2504.20432v2",
        "PDF": "https://arxiv.org/pdf/2504.20432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on information flow control (IFC) and designing security systems, not on any aspect of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21773",
      "abstract": "With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention. Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting. However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored. To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data. Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision.",
      "authors": [
        "Junsheng Huang",
        "Zhitao He",
        "Yucheng Huang",
        "Sandeep Polisetty",
        "Qingyun Wang",
        "May Fung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T16:17:53+00:00",
          "link": "https://arxiv.org/abs/2504.21773v1",
          "size": "11375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:03:43+00:00",
          "link": "https://arxiv.org/abs/2504.21773v2",
          "size": "11391kb",
          "version": "v2"
        }
      ],
      "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21773",
        "HTML": "https://arxiv.org/html/2504.21773v2",
        "PDF": "https://arxiv.org/pdf/2504.21773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MAC-Tuning for fine-tuning LLMs, which involves separating learning of answer prediction and confidence estimation. However, it mainly focuses on model tuning and not extensively on data processing."
      },
      "tasks": [
        "Hallucination"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00749",
      "abstract": "Coral Protocol is an open and decentralized collaboration infrastructure that enables communication, coordination, trust and payments for The Internet of Agents. It addresses the growing need for interoperability in a world where organizations are deploying multiple specialized AI agents that must work together across domains and vendors. As a foundational platform for multi-agent AI ecosystems, Coral establishes a common language and coordination framework allowing any agent to participate in complex workflows with others. Its design emphasizes broad compatibility, security, and vendor neutrality, ensuring that agent interactions are efficient and trustworthy. In particular, Coral introduces standardized messaging formats for agent communication, a modular coordination mechanism for orchestrating multi-agent tasks, and secure team formation capabilities for dynamically assembling trusted groups of agents. Together, these innovations position Coral Protocol as a cornerstone of the emerging \"Internet of Agents,\" unlocking new levels of automation, collective intelligence, and business value through open agent collaboration.",
      "authors": [
        "Roman J. Georgio",
        "Caelum Forder",
        "Suman Deb",
        "Andri Rahimov",
        "Peter Carroll",
        "\\\"Onder G\\\"urcan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T22:17:13+00:00",
          "link": "https://arxiv.org/abs/2505.00749v1",
          "size": "765kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:34:37+00:00",
          "link": "https://arxiv.org/abs/2505.00749v2",
          "size": "785kb",
          "version": "v2"
        }
      ],
      "title": "Coral Protocol: Open Infrastructure Connecting The Internet of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00749",
        "HTML": "https://arxiv.org/html/2505.00749v2",
        "PDF": "https://arxiv.org/pdf/2505.00749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes Coral Protocol, an infrastructure for AI agent communication and coordination. It does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.02179",
      "abstract": "Weakly-supervised video anomaly detection (WS-VAD) using Multiple Instance Learning (MIL) suffers from label ambiguity, hindering discriminative feature learning. We propose ProDisc-VAD, an efficient framework tackling this via two synergistic components. The Prototype Interaction Layer (PIL) provides controlled normality modeling using a small set of learnable prototypes, establishing a robust baseline without being overwhelmed by dominant normal data. The Pseudo-Instance Discriminative Enhancement (PIDE) loss boosts separability by applying targeted contrastive learning exclusively to the most reliable extreme-scoring instances (highest/lowest scores). ProDisc-VAD achieves strong AUCs (97.98% ShanghaiTech, 87.12% UCF-Crime) using only 0.4M parameters, over 800x fewer than recent ViT-based methods like VadCLIP. Code is available at https://github.com/modadundun/ProDisc-VAD.",
      "authors": [
        "Tao Zhu",
        "Qi Yu",
        "Xinru Dong",
        "Shiyu Li",
        "Yue Liu",
        "Jinlong Jiang",
        "Lei Shu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T16:42:15+00:00",
          "link": "https://arxiv.org/abs/2505.02179v1",
          "size": "5637kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T14:18:43+00:00",
          "link": "https://arxiv.org/abs/2505.02179v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:31:43+00:00",
          "link": "https://arxiv.org/abs/2505.02179v3",
          "size": "5423kb",
          "version": "v3"
        }
      ],
      "title": "ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02179",
        "HTML": "https://arxiv.org/html/2505.02179v3",
        "PDF": "https://arxiv.org/pdf/2505.02179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on Video Anomaly Detection using weakly-supervised techniques and does not address LLM training data processing, data engineering, or dataset creation for LLMs."
      },
      "tasks": [
        "Anomaly Detection In Surveillance Videos",
        "Contrastive Learning",
        "Multiple Instance Learning",
        "Supervised Anomaly Detection",
        "Video Anomaly Detection",
        "Weakly-supervised Anomaly Detection",
        "Weakly-supervised Video Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/modadundun/ProDisc-VAD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02622",
      "abstract": "Bitstrings can be permuted via permutations and compared via the lexicographic order. In this paper we study the complexity of finding a minimum of a bitstring via given permutations. As a global optima is known to be NP-complete, we study the local optima via the class PLS and show hardness for PLS. Additionally, we show that even for one permutation the global optimization is NP-complete and give a formula that has these permutation as symmetries. This answers an open question inspired from Kolodziejczyk and Thapen and stated at the SAT and interactions seminar in Dagstuhl.",
      "authors": [
        "Dominik Scheder and Johannes Tantow"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T12:51:10+00:00",
          "link": "https://arxiv.org/abs/2505.02622v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:30:00+00:00",
          "link": "https://arxiv.org/abs/2505.02622v2",
          "size": "37kb",
          "version": "v2"
        }
      ],
      "title": "PLS-completeness of string permutations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02622",
        "HTML": "https://arxiv.org/html/2505.02622v2",
        "PDF": "https://arxiv.org/pdf/2505.02622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the complexity issues in permutations and optimization problems, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.03557",
      "abstract": "Personalizing Stable Diffusion for professional portrait generation from amateur photos faces challenges in maintaining facial resemblance. This paper evaluates the impact of augmentation strategies on two personalization methods: DreamBooth and InstantID. We compare classical augmentations (flipping, cropping, color adjustments) with generative augmentation using InstantID's synthetic images to enrich training data. Using SDXL and a new FaceDistance metric based on FaceNet, we quantitatively assess facial similarity. Results show classical augmentations can cause artifacts harming identity retention, while InstantID improves fidelity when balanced with real images to avoid overfitting. A user study with 97 participants confirms high photorealism and preferences for InstantID's polished look versus DreamBooth's identity accuracy. Our findings inform effective augmentation strategies for personalized text-to-image generation.",
      "authors": [
        "Koray Ulusan and Benjamin Kiefer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T14:11:02+00:00",
          "link": "https://arxiv.org/abs/2505.03557v1",
          "size": "30282kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T14:11:40+00:00",
          "link": "https://arxiv.org/abs/2505.03557v2",
          "size": "9115kb",
          "version": "v2"
        }
      ],
      "title": "Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03557",
        "HTML": "https://arxiv.org/html/2505.03557v2",
        "PDF": "https://arxiv.org/pdf/2505.03557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses generating synthetic data through augmentation strategies for facial resemblance in image generation. It relates to data augmentation, but the primary focus is personalized text-to-image generation, not LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.03780",
      "abstract": "As LLMs grow in complexity, achieving state-of-the-art performance requires tight co-design across algorithms, software, and hardware. Today's reliance on a single dominant platform limits portability, creates vendor lock-in, and raises barriers for new AI hardware. In this work, we make the case for combining just-in-time (JIT) compilation with comprehensive kernel parameter autotuning to enable portable LLM inference with state-of-the-art performance without code changes. Focusing on performance-critical LLM kernels, we demonstrate that this approach explores up to 15x more kernel parameter configurations, produces significantly more diverse code across multiple dimensions, and even outperforms vendor-optimized implementations by up to 230%, all while reducing kernel code size by 70x and eliminating manual code optimizations. Our results highlight autotuning as a promising path to unlocking model portability across GPU vendors.",
      "authors": [
        "Burkhard Ringlein",
        "Thomas Parnell",
        "Radu Stoica"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T12:57:21+00:00",
          "link": "https://arxiv.org/abs/2505.03780v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T14:26:40+00:00",
          "link": "https://arxiv.org/abs/2505.03780v2",
          "size": "117kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T17:31:44+00:00",
          "link": "https://arxiv.org/abs/2505.03780v3",
          "size": "128kb",
          "version": "v3"
        }
      ],
      "title": "GPU Performance Portability needs Autotuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03780",
        "HTML": "https://arxiv.org/html/2505.03780v3",
        "PDF": "https://arxiv.org/pdf/2505.03780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses GPU performance and autotuning for LLM kernel efficiency. It does not contribute to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/IBM/triton-dejavu"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10946",
      "abstract": "Token communications (TokCom) is an emerging generative semantic communication concept that reduces transmission rates by using context and multimodal large language model (MLLM)-based token processing, with tokens serving as universal semantic units across modalities. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as token domain multiple access (ToDMA), where a large number of devices share a token codebook and a modulation codebook for source and channel coding, respectively. Specifically, each transmitter first tokenizes its source signal and modulate each token to a codeword. At the receiver, compressed sensing is employed first to detect active tokens and the corresponding channel state information (CSI) from the superposed signals. Then, the source token sequences are reconstructed by clustering the token-associated CSI across multiple time slots. In case of token collisions, some active tokens cannot be assigned and some positions in the reconstructed token sequences are empty. We propose to use pre-trained MLLMs to leverage the context, predict masked tokens, and thus mitigate token collisions. Simulation results demonstrate the effectiveness of the proposed ToDMA framework for both text and image transmission tasks, achieving significantly lower latency compared to context-unaware orthogonal communication schemes, while also delivering superior distortion and perceptual quality compared to state-of-the-art context-unaware non-orthogonal communication methods.",
      "authors": [
        "Li Qiao",
        "Mahdi Boloursaz Mashhadi",
        "Zhen Gao",
        "Robert Schober",
        "Deniz G\\\"und\\\"uz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T07:30:42+00:00",
          "link": "https://arxiv.org/abs/2505.10946v1",
          "size": "1774kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:28:57+00:00",
          "link": "https://arxiv.org/abs/2505.10946v2",
          "size": "1775kb",
          "version": "v2"
        }
      ],
      "title": "ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10946",
        "HTML": "https://arxiv.org/html/2505.10946v2",
        "PDF": "https://arxiv.org/pdf/2505.10946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic communications, involving token-domain multiple access (ToDMA) and multimodal large language model (MLLM)-based token processing for communications, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12758",
      "abstract": "Understanding people's preferences is crucial for urban planning, yet current approaches often combine responses from multi-cultural populations, obscuring demographic differences and risking amplifying biases. We conducted a large-scale urban visual perception survey of streetscapes worldwide using street view imagery, examining how demographics -- including gender, age, income, education, race and ethnicity, and, for the first time, personality traits -- shape perceptions among 1,000 participants with balanced demographics from five countries and 45 nationalities. This dataset, Street Perception Evaluation Considering Socioeconomics (SPECS), reveals demographic- and personality-based differences across six traditional indicators (safe, lively, wealthy, beautiful, boring, depressing) and four new ones (live nearby, walk, cycle, green). Location-based sentiments further shape these preferences. Machine learning models trained on existing global datasets tend to overestimate positive indicators and underestimate negative ones compared to human responses, underscoring the need for local context. Our study aspires to rectify the myopic treatment of street perception, which rarely considers demographics or personality traits.",
      "authors": [
        "Matias Quintana",
        "Youlong Gu",
        "Xiucheng Liang",
        "Yujun Hou",
        "Koichi Ito",
        "Yihan Zhu",
        "Mahmoud Abdelrahman",
        "Filip Biljecki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T06:35:11+00:00",
          "link": "https://arxiv.org/abs/2505.12758v1",
          "size": "14600kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T12:02:08+00:00",
          "link": "https://arxiv.org/abs/2505.12758v2",
          "size": "20735kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T09:28:28+00:00",
          "link": "https://arxiv.org/abs/2505.12758v3",
          "size": "20570kb",
          "version": "v3"
        }
      ],
      "title": "Global urban visual perception varies across demographics and personalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12758",
        "HTML": "https://arxiv.org/html/2505.12758v3",
        "PDF": "https://arxiv.org/pdf/2505.12758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses urban visual perception and datasets related to demographics and personalities impacting street perception, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.13886",
      "abstract": "Visual-language Chain-of-Thought (CoT) data resources are relatively scarce compared to text-only counterparts, limiting the improvement of reasoning capabilities in Vision Language Models (VLMs). However, high-quality vision-language reasoning data is expensive and labor-intensive to annotate. To address this issue, we leverage a promising resource: game code, which naturally contains logical structures and state transition processes. Therefore, we propose Code2Logic, a novel game-code-driven approach for multimodal reasoning data synthesis. Our approach leverages Large Language Models (LLMs) to adapt game code, enabling automatic acquisition of reasoning processes and results through code execution. Using the Code2Logic approach, we developed the GameQA dataset to train and evaluate VLMs. GameQA is cost-effective and scalable, offers controllable difficulty gradation and is diverse with 30 games and 158 tasks. Surprisingly, despite training solely on game data, VLMs demonstrated out of domain generalization, specifically Qwen2.5-VL-7B improving performance by 2.33% across 7 diverse vision-language benchmarks. Our code, dataset and models are available at https://github.com/tongjingqi/Code2Logic.",
      "authors": [
        "Jingqi Tong",
        "Jixin Tang",
        "Hangcheng Li",
        "Yurong Mou",
        "Ming Zhang",
        "Jun Zhao",
        "Yanbo Wen",
        "Fan Song",
        "Jiahao Zhan",
        "Yuyang Lu",
        "Chaoran Tao",
        "Zhiyuan Guo",
        "Jizhou Yu",
        "Tianhao Cheng",
        "Changhao Jiang",
        "Zhen Wang",
        "Tao Liang",
        "Zhihui Fei",
        "Mingyang Wan",
        "Guojun Ma",
        "Weifeng Ge",
        "Guanhua Chen",
        "Tao Gui",
        "Xipeng Qiu",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T03:47:44+00:00",
          "link": "https://arxiv.org/abs/2505.13886v1",
          "size": "4532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:30:25+00:00",
          "link": "https://arxiv.org/abs/2505.13886v2",
          "size": "10414kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:46:29+00:00",
          "link": "https://arxiv.org/abs/2505.13886v3",
          "size": "12505kb",
          "version": "v3"
        }
      ],
      "title": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13886",
        "PDF": "https://arxiv.org/pdf/2505.13886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces Code2Logic, which synthesizes multimodal reasoning data from game code to enhance Vision Language Models (VLMs). The creation of the GameQA dataset is a novel contribution to data generation, directly impacting LLM training data processing."
      },
      "models": [
        {
          "model_path": "Code2Logic/GameQA-InternVL3-8B",
          "downloads": "8",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-InternVL3-8B"
        },
        {
          "model_path": "Code2Logic/GameQA-Qwen2.5-VL-7B",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-Qwen2.5-VL-7B"
        },
        {
          "model_path": "Code2Logic/GameQA-llava-onevision-qwen2-7b-ov-hf",
          "downloads": "8",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-llava-onevision-qwen2-7b-ov-hf"
        },
        {
          "model_path": "Code2Logic/GameQA-InternVL2.5-8B",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-InternVL2.5-8B"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Code2Logic/GameQA-140K",
          "downloads": "205",
          "likes": "11",
          "link": "https://huggingface.co/datasets/Code2Logic/GameQA-140K"
        },
        {
          "dataset_name": "Code2Logic/GameQA-5K",
          "downloads": "139",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Code2Logic/GameQA-5K"
        }
      ],
      "tasks": [
        "Domain Generalization",
        "Multimodal Reasoning"
      ],
      "repo_urls": [
        "https://github.com/tongjingqi/code2logic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17335",
      "abstract": "Incorrect handling of security-critical data formats, particularly in low-level languages, are the root cause of many security vulnerabilities. Provably correct parsing and serialization tools that target languages like C can help. Towards this end, we present PulseParse, a library of verified parser and serializer combinators for non-malleable binary formats. Specifications and proofs in PulseParse are in separation logic, offering a more abstract and compositional interface, with full support for data validation, parsing, and serialization. PulseParse also supports a class of recursive formats -- with a focus on security and handling adversarial inputs, we show how to parse such formats with only a constant amount of stack space.\n  We use PulseParse at scale by providing the first formalization of CBOR, a recursive, binary data format standard, with growing adoption in various industrial standards. We prove that the deterministic fragment of CBOR is non-malleable and provide EverCBOR, a verified library in both C and Rust to validate, parse, and serialize CBOR objects implemented using PulseParse. Next, we provide the first formalization of CDDL, a schema definition language for CBOR. We identify well-formedness conditions on CDDL definitions that ensure that they yield unambiguous, non-malleable formats, and implement EverCDDL, a tool that checks that a CDDL definition is well-formed, and then produces verified parsers and serializers for it.\n  To evaluate our work, we use EverCDDL to generate verified parsers and serializers for various security-critical applications. Notably, we build a formally verified implementation of COSE signing, a standard for cryptographically signed objects. We also use our toolchain to generate verified code for other standards specified in CDDL, including DICE Protection Environment, a secure boot protocol standard.",
      "authors": [
        "Tahina Ramananandro",
        "Gabriel Ebner",
        "Guido Mart\\'inez",
        "Nikhil Swamy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T23:12:03+00:00",
          "link": "https://arxiv.org/abs/2505.17335v1",
          "size": "210kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:50:49+00:00",
          "link": "https://arxiv.org/abs/2505.17335v2",
          "size": "208kb",
          "version": "v2"
        }
      ],
      "title": "Secure Parsing and Serializing with Separation Logic Applied to CBOR, CDDL, and COSE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17335",
        "HTML": "https://arxiv.org/html/2505.17335v2",
        "PDF": "https://arxiv.org/pdf/2505.17335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work centers on parsing and serializing binary data formats for security applications, using verified tools in C and Rust. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19477",
      "abstract": "LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings. While recent work has explored multi-agent extensions such as multi-agent debate and meta-judging to enhance evaluation quality, the question of how intrinsic biases manifest in these settings remains underexplored. In this study, we conduct a systematic analysis of four diverse bias types: position bias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate these biases across two widely adopted multi-agent LLM-as-Judge frameworks: Multi-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate framework amplifies biases sharply after the initial debate, and this increased bias is sustained in subsequent rounds, while meta-judge approaches exhibit greater resistance. We further investigate the incorporation of PINE, a leading single-agent debiasing method, as a bias-free agent within these systems. The results reveal that this bias-free agent effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios. Our work provides a comprehensive study of bias behavior in multi-agent LLM-as-Judge systems and highlights the need for targeted bias mitigation strategies in collaborative evaluation settings.",
      "authors": [
        "Chiyu Ma",
        "Enpei Zhang",
        "Yilun Zhao",
        "Wenjun Liu",
        "Yaning Jia",
        "Peijun Qing",
        "Lin Shi",
        "Arman Cohan",
        "Yujun Yan",
        "Soroush Vosoughi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T03:56:41+00:00",
          "link": "https://arxiv.org/abs/2505.19477v1",
          "size": "3617kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:58:55+00:00",
          "link": "https://arxiv.org/abs/2505.19477v2",
          "size": "3097kb",
          "version": "v2"
        }
      ],
      "title": "Judging with Many Minds: Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19477",
        "HTML": "https://arxiv.org/html/2505.19477v2",
        "PDF": "https://arxiv.org/pdf/2505.19477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on bias analysis and mitigation in multi-agent based LLM evaluation frameworks, specifically LLM-as-Judge, rather than training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.20755",
      "abstract": "In this paper, we unify more than 10 existing one-step diffusion distillation approaches, such as Diff-Instruct, DMD, SIM, SiD, $f$-distill, etc, inside a theory-driven framework which we name the \\textbf{\\emph{Uni-Instruct}}. Uni-Instruct is motivated by our proposed diffusion expansion theory of the $f$-divergence family. Then we introduce key theories that overcome the intractability issue of the original expanded $f$-divergence, resulting in an equivalent yet tractable loss that effectively trains one-step diffusion models by minimizing the expanded $f$-divergence family. The novel unification introduced by Uni-Instruct not only offers new theoretical contributions that help understand existing approaches from a high-level perspective but also leads to state-of-the-art one-step diffusion generation performances. On the CIFAR10 generation benchmark, Uni-Instruct achieves record-breaking Frechet Inception Distance (FID) values of \\textbf{\\emph{1.46}} for unconditional generation and \\textbf{\\emph{1.38}} for conditional generation. On the ImageNet-$64\\times 64$ generation benchmark, Uni-Instruct achieves a new SoTA one-step generation FID of \\textbf{\\emph{1.02}}, which outperforms its 79-step teacher diffusion with a significant improvement margin of 1.33 (1.02 vs 2.35). We also apply Uni-Instruct on broader tasks like text-to-3D generation. For text-to-3D generation, Uni-Instruct gives decent results, which slightly outperforms previous methods, such as SDS and VSD, in terms of both generation quality and diversity. Both the solid theoretical and empirical contributions of Uni-Instruct will potentially help future studies on one-step diffusion distillation and knowledge transferring of diffusion models.",
      "authors": [
        "Yifei Wang",
        "Weimin Bai",
        "Colin Zhang",
        "Debing Zhang",
        "Weijian Luo",
        "He Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T05:55:45+00:00",
          "link": "https://arxiv.org/abs/2505.20755v1",
          "size": "27896kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:16:31+00:00",
          "link": "https://arxiv.org/abs/2505.20755v2",
          "size": "27907kb",
          "version": "v2"
        }
      ],
      "title": "Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20755",
        "HTML": "https://arxiv.org/html/2505.20755v2",
        "PDF": "https://arxiv.org/pdf/2505.20755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with one-step diffusion models and their unified theoretical framework, without any discussion related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20770",
      "abstract": "In music production, manipulating audio effects (Fx) parameters through natural language has the potential to reduce technical barriers for non-experts. We present LLM2Fx, a framework leveraging Large Language Models (LLMs) to predict Fx parameters directly from textual descriptions without requiring task-specific training or fine-tuning. Our approach address the text-to-effect parameter prediction (Text2Fx) task by mapping natural language descriptions to the corresponding Fx parameters for equalization and reverberation. We demonstrate that LLMs can generate Fx parameters in a zero-shot manner that elucidates the relationship between timbre semantics and audio effects in music production. To enhance performance, we introduce three types of in-context examples: audio Digital Signal Processing (DSP) features, DSP function code, and few-shot examples. Our results demonstrate that LLM-based Fx parameter generation outperforms previous optimization approaches, offering competitive performance in translating natural language descriptions to appropriate Fx settings. Furthermore, LLMs can serve as text-driven interfaces for audio production, paving the way for more intuitive and accessible music production tools.",
      "authors": [
        "Seungheon Doh",
        "Junghyun Koo",
        "Marco A. Mart\\'inez-Ram\\'irez",
        "Wei-Hsiang Liao",
        "Juhan Nam",
        "Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T06:21:56+00:00",
          "link": "https://arxiv.org/abs/2505.20770v1",
          "size": "220kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:10:45+00:00",
          "link": "https://arxiv.org/abs/2505.20770v2",
          "size": "219kb",
          "version": "v2"
        }
      ],
      "title": "Can Large Language Models Predict Audio Effects Parameters from Natural Language?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20770",
        "HTML": "https://arxiv.org/html/2505.20770v2",
        "PDF": "https://arxiv.org/pdf/2505.20770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for using LLMs in predicting audio effects parameters from natural language, but it does not involve any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23121",
      "abstract": "Multi-modal large language models have demonstrated remarkable zero-shot abilities and powerful image-understanding capabilities. However, the existing open-source multi-modal models suffer from the weak capability of multi-turn interaction, especially for long contexts. To address the issue, we first introduce a context modeling module, termed ContextQFormer, which utilizes a memory block to enhance the presentation of contextual information. Furthermore, to facilitate further research, we carefully build a new multi-turn multi-modal dialogue dataset (TMDialog) for pre-training, instruction-tuning, and evaluation, which will be open-sourced lately. Compared with other multi-modal dialogue datasets, TMDialog contains longer conversations, which supports the research of multi-turn multi-modal dialogue. In addition, ContextQFormer is compared with three baselines on TMDialog and experimental results illustrate that ContextQFormer achieves an improvement of 2%-4% in available rate over baselines.",
      "authors": [
        "Yiming Lei",
        "Zhizheng Yang",
        "Zeming Liu",
        "Haitao Leng",
        "Shaoguo Liu",
        "Tingting Gao",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T05:41:26+00:00",
          "link": "https://arxiv.org/abs/2505.23121v1",
          "size": "1514kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:49:08+00:00",
          "link": "https://arxiv.org/abs/2505.23121v2",
          "size": "1515kb",
          "version": "v2"
        }
      ],
      "title": "ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23121",
        "HTML": "https://arxiv.org/html/2505.23121v2",
        "PDF": "https://arxiv.org/pdf/2505.23121"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new multi-turn multi-modal dialogue dataset (TMDialog) for pre-training and instruction-tuning, contributing directly to LLM training data processing by creating new dataset resources."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.23629",
      "abstract": "We propose a new method for recognizing color image sets using quaternionic Grassmannians, which use the power of quaternions to capture color information and represent each color image set as a point on the quaternionic Grassmannian. We provide a direct formula to calculate the shortest distance between two points on the quaternionic Grassmannian, and use this distance to build a new classification framework. Experiments on the ETH-80 benchmark dataset and and the Highway Traffic video dataset show that our method achieves good recognition results. We also discuss some limitations in stability and suggest ways the method can be improved in the future.",
      "authors": [
        "Xiang Xiang Wang and Tin-Yau Tam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T16:36:02+00:00",
          "link": "https://arxiv.org/abs/2505.23629v1",
          "size": "1933kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:53:12+00:00",
          "link": "https://arxiv.org/abs/2505.23629v2",
          "size": "3211kb",
          "version": "v2"
        }
      ],
      "title": "Color Image Set Recognition Based on Quaternionic Grassmannians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23629",
        "HTML": "https://arxiv.org/html/2505.23629v2",
        "PDF": "https://arxiv.org/pdf/2505.23629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for recognizing color image sets using quaternionic Grassmannians, which does not relate to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.24189",
      "abstract": "Large Language Models (LLMs) such as GPT-4o can handle a wide range of complex tasks with the right prompt. As per token costs are reduced, the advantages of fine-tuning Small Language Models (SLMs) for real-world applications -- faster inference, lower costs -- may no longer be clear. In this work, we present evidence that, for domain-specific tasks that require structured outputs, SLMs still have a quality advantage. We compare fine-tuning an SLM against prompting LLMs on the task of generating low-code workflows in JSON form. We observe that while a good prompt can yield reasonable results, fine-tuning improves quality by 10% on average. We also perform systematic error analysis to reveal model limitations.",
      "authors": [
        "Orlando Marquez Ayala",
        "Patrice Bechard",
        "Emily Chen",
        "Maggie Baird",
        "Jingfei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T03:59:35+00:00",
          "link": "https://arxiv.org/abs/2505.24189v1",
          "size": "190kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:38:06+00:00",
          "link": "https://arxiv.org/abs/2505.24189v2",
          "size": "1425kb",
          "version": "v2"
        }
      ],
      "title": "Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24189",
        "HTML": "https://arxiv.org/html/2505.24189v2",
        "PDF": "https://arxiv.org/pdf/2505.24189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the fine-tuning of Small Language Models (SLMs) and compares it to prompting LLMs, with the focus on generating low-code workflows. It touches upon fine-tuning, but the primary emphasis is not on training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.24835",
      "abstract": "Fund allocation has been an increasingly important problem in the financial domain. In reality, we aim to allocate the funds to buy certain assets within a certain future period. Naive solutions such as prediction-only or Predict-then-Optimize approaches suffer from goal mismatch. Additionally, the introduction of the SOTA time series forecasting model inevitably introduces additional uncertainty in the predicted result. To solve both problems mentioned above, we introduce a Risk-aware Time-Series Predict-and-Allocate (RTS-PnO) framework, which holds no prior assumption on the forecasting models. Such a framework contains three features: (i) end-to-end training with objective alignment measurement, (ii) adaptive forecasting uncertainty calibration, and (iii) agnostic towards forecasting models. The evaluation of RTS-PnO is conducted over both online and offline experiments. For offline experiments, eight datasets from three categories of financial applications are used: Currency, Stock, and Cryptos. RTS-PnO consistently outperforms other competitive baselines. The online experiment is conducted on the Cross-Border Payment business at FiT, Tencent, and an 8.4\\% decrease in regret is witnessed when compared with the product-line approach. The code for the offline experiment is available at https://github.com/fuyuanlyu/RTS-PnO.",
      "authors": [
        "Fuyuan Lyu",
        "Linfeng Du",
        "Yunpeng Weng",
        "Qiufang Ying",
        "Zhiyan Xu",
        "Wen Zou",
        "Haolun Wu",
        "Xiuqiang He",
        "Xing Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T17:36:45+00:00",
          "link": "https://arxiv.org/abs/2505.24835v1",
          "size": "2112kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T16:57:09+00:00",
          "link": "https://arxiv.org/abs/2505.24835v2",
          "size": "1900kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T21:42:51+00:00",
          "link": "https://arxiv.org/abs/2505.24835v3",
          "size": "1900kb",
          "version": "v3"
        }
      ],
      "title": "Timing is Important: Risk-aware Fund Allocation based on Time-Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24835",
        "HTML": "https://arxiv.org/html/2505.24835v3",
        "PDF": "https://arxiv.org/pdf/2505.24835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a framework for risk-aware fund allocation in finance using time-series forecasting, not concerning any aspect of LLM training data processing."
      },
      "tasks": [
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/fuyuanlyu/rts-pno"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03106",
      "abstract": "Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly enhanced the complex reasoning capabilities of large language models (LLMs). Despite this success, we identify three key challenges encountered by RL with solely numerical feedback: performance plateaus, limited effectiveness of spontaneous self-reflection, and persistent failures. We then demonstrate that RL-finetuned models, even after exhibiting performance plateaus, can generate correct refinements on persistently failed problems by leveraging natural language feedback in the form of critiques. Building on this insight, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for effective policy optimization. Critique-GRPO enables LLMs to learn from initial responses and critique-guided self-refinements simultaneously while maintaining exploration. Additionally, we employ a shaping function to amplify learning from correct, especially unfamiliar, refinements and penalize incorrect ones. Extensive experiments with Qwen2.5-7B-Base, Qwen2.5-Math-7B-Base, and Qwen3-8B demonstrate that Critique-GRPO consistently outperforms supervised learning and RL-based fine-tuning methods across eight challenging mathematical, STEM, and general reasoning tasks, improving average pass@1 scores by approximately 4.4% and 3.8% on Qwen2.5-7B-Base and Qwen3-8B, respectively. Notably, Critique-GRPO enables effective self-improvement through self-critiquing and weak-to-strong generalization, achieving consistent gains over GRPO, such as 16.7% and 10.0% pass@1 improvements on AIME 2024, respectively.",
      "authors": [
        "Xiaoying Zhang",
        "Hao Sun",
        "Yipeng Zhang",
        "Kaituo Feng",
        "Chaochao Lu",
        "Chao Yang",
        "Helen Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T17:39:02+00:00",
          "link": "https://arxiv.org/abs/2506.03106v1",
          "size": "4081kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T13:45:47+00:00",
          "link": "https://arxiv.org/abs/2506.03106v2",
          "size": "4395kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:11:37+00:00",
          "link": "https://arxiv.org/abs/2506.03106v3",
          "size": "6053kb",
          "version": "v3"
        },
        {
          "date": "2025-07-17T04:08:03+00:00",
          "link": "https://arxiv.org/abs/2506.03106v4",
          "size": "6053kb",
          "version": "v4"
        }
      ],
      "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03106",
        "HTML": "https://arxiv.org/html/2506.03106v4",
        "PDF": "https://arxiv.org/pdf/2506.03106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents Critique-GRPO, which enhances LLM reasoning using reinforcement learning with natural language and numerical feedback. While it involves fine-tuning methods, its main focus is on learning and reasoning improvements rather than training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03225",
      "abstract": "Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules instead of fixed configurations. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice of evolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without actually tuning hyperparameters.",
      "authors": [
        "Wa\\\"el Doulazmi",
        "Auguste Lehuger",
        "Marin Toromanoff",
        "Valentin Charraut",
        "Thibault Buhet",
        "Fabien Moutarde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T11:19:21+00:00",
          "link": "https://arxiv.org/abs/2506.03225v1",
          "size": "8662kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:41:03+00:00",
          "link": "https://arxiv.org/abs/2506.03225v2",
          "size": "9108kb",
          "version": "v2"
        }
      ],
      "title": "Multiple-Frequencies Population-Based Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03225",
        "HTML": "https://arxiv.org/html/2506.03225v2",
        "PDF": "https://arxiv.org/pdf/2506.03225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies a hyperparameter optimization algorithm in reinforcement learning and does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04484",
      "abstract": "Autonomous mobile robots operating in remote, unstructured environments must adapt to new, unpredictable terrains that can change rapidly during operation. In such scenarios, a critical challenge becomes estimating the robot's dynamics on changing terrain in order to enable reliable, accurate navigation and planning. We present a novel online adaptation approach for terrain-aware dynamics modeling and planning using function encoders. Our approach efficiently adapts to new terrains at runtime using limited online data without retraining or fine-tuning. By learning a set of neural network basis functions that span the robot dynamics on diverse terrains, we enable rapid online adaptation to new, unseen terrains and environments as a simple least-squares calculation. We demonstrate our approach for terrain adaptation in a Unity-based robotics simulator and show that the downstream controller has better empirical performance due to higher accuracy of the learned model. This leads to fewer collisions with obstacles while navigating in cluttered environments as compared to a neural ODE baseline.",
      "authors": [
        "William Ward",
        "Sarah Etter",
        "Tyler Ingebrand",
        "Christian Ellis",
        "Adam J. Thorpe",
        "Ufuk Topcu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T22:03:57+00:00",
          "link": "https://arxiv.org/abs/2506.04484v1",
          "size": "2502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T20:26:15+00:00",
          "link": "https://arxiv.org/abs/2506.04484v2",
          "size": "2502kb",
          "version": "v2"
        }
      ],
      "title": "Online Adaptation of Terrain-Aware Dynamics for Planning in Unstructured Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04484",
        "HTML": "https://arxiv.org/html/2506.04484v2",
        "PDF": "https://arxiv.org/pdf/2506.04484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on online adaptation of terrain-aware dynamics in robotics, not on LLM training data processing. It deals with adapting robot models for navigation, which is unrelated to data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05026",
      "abstract": "This paper introduces a novel physical annotation system designed to generate training data for automated optical inspection. The system uses pointer-based in-situ interaction to transfer the valuable expertise of trained inspection personnel directly into a machine learning (ML) training pipeline. Unlike conventional screen-based annotation methods, our system captures physical trajectories and contours directly on the object, providing a more intuitive and efficient way to label data. The core technology uses calibrated, tracked pointers to accurately record user input and transform these spatial interactions into standardised annotation formats that are compatible with open-source annotation software. Additionally, a simple projector-based interface projects visual guidance onto the object to assist users during the annotation process, ensuring greater accuracy and consistency. The proposed concept bridges the gap between human expertise and automated data generation, enabling non-IT experts to contribute to the ML training pipeline and preventing the loss of valuable training samples. Preliminary evaluation results confirm the feasibility of capturing detailed annotation trajectories and demonstrate that integration with CVAT streamlines the workflow for subsequent ML tasks. This paper details the system architecture, calibration procedures and interface design, and discusses its potential contribution to future ML data generation for automated optical inspection.",
      "authors": [
        "Oliver Krumpek",
        "Oliver Heimann",
        "J\\\"org Kr\\\"uger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T13:37:24+00:00",
          "link": "https://arxiv.org/abs/2506.05026v1",
          "size": "10717kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:47:21+00:00",
          "link": "https://arxiv.org/abs/2506.05026v2",
          "size": "7705kb",
          "version": "v2"
        }
      ],
      "title": "Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Training Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05026",
        "HTML": "https://arxiv.org/html/2506.05026v2",
        "PDF": "https://arxiv.org/pdf/2506.05026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel annotation system for generating training data in automated optical inspection. While it involves data generation, it is contextually unrelated to LLMs, as its focus is on physical annotation for inspection systems, not LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.05710",
      "abstract": "In this paper, a novel semantic communication framework empowered by generative artificial intelligence (GAI) is proposed, to enhance the robustness against both channel noise and transmission data distribution shifts. A theoretical foundation is established using stochastic differential equations (SDEs), from which a closed-form mapping between any signal-to-noise ratio (SNR) and the optimal denoising timestep is derived. Moreover, to address distribution mismatch, a mathematical scaling method is introduced to align received semantic features with the training distribution of the GAI. Built on this theoretical foundation, a latent diffusion model (LDM)-based semantic communication framework is proposed that combines a variational autoencoder for semantic features extraction, where a pretrained diffusion model is used for denoising. The proposed system is a training-free framework that supports zero-shot generalization, and achieves superior performance under low-SNR and out-of-distribution conditions, offering a scalable and robust solution for future 6G semantic communication systems. Experimental results demonstrate that the proposed semantic communication framework achieves state-of-the-art performance in both pixel-level accuracy and semantic perceptual quality, consistently outperforming baselines across a wide range of SNRs and data distributions without any fine-tuning or post-training.",
      "authors": [
        "Xiucheng Wang and Honggang Jia and Nan Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T03:20:32+00:00",
          "link": "https://arxiv.org/abs/2506.05710v1",
          "size": "5630kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T15:21:59+00:00",
          "link": "https://arxiv.org/abs/2506.05710v2",
          "size": "4873kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T07:26:41+00:00",
          "link": "https://arxiv.org/abs/2506.05710v3",
          "size": "4874kb",
          "version": "v3"
        }
      ],
      "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05710",
        "HTML": "https://arxiv.org/html/2506.05710v3",
        "PDF": "https://arxiv.org/pdf/2506.05710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores a semantic communication framework using generative AI for robust communication under noise, focusing on denoising techniques and communication systems. It doesn't address aspects of LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Semantic Communication",
        "Semantic Compression",
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07960",
      "abstract": "This article presents a large-scale effort to create a structured dataset of internal migration in Finland between 1800 and 1920 using digitized church moving records. These records, maintained by Evangelical-Lutheran parishes, document the migration of individuals and families and offer a valuable source for studying historical demographic patterns. The dataset includes over six million entries extracted from approximately 200,000 images of handwritten migration records.\n  The data extraction process was automated using a deep learning pipeline that included layout analysis, table detection, cell classification, and handwriting recognition. The complete pipeline was applied to all images, resulting in a structured dataset suitable for research.\n  The dataset can be used to study internal migration, urbanization, and family migration, and the spread of disease in preindustrial Finland. A case study from the Elim\\\"aki parish shows how local migration histories can be reconstructed. The work demonstrates how large volumes of handwritten archival material can be transformed into structured data to support historical and demographic research.",
      "authors": [
        "Ari Vesalainen",
        "Jenna Kanerva",
        "Aida Nitsch",
        "Kiia Korsu",
        "Ilari Larkiola",
        "Laura Ruotsalainen and Filip Ginter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:32:55+00:00",
          "link": "https://arxiv.org/abs/2506.07960v1",
          "size": "18742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:29:34+00:00",
          "link": "https://arxiv.org/abs/2506.07960v2",
          "size": "13335kb",
          "version": "v2"
        }
      ],
      "title": "Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07960",
        "HTML": "https://arxiv.org/html/2506.07960v2",
        "PDF": "https://arxiv.org/pdf/2506.07960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about creating a historical migration dataset from Finnish church records, focusing on historical demographic patterns, with no relation to LLM training data processing or language model datasets."
      },
      "tasks": [
        "Handwriting Recognition",
        "Table Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11133",
      "abstract": "Estimating the 3D hand articulation from a single color image is an important problem with applications in Augmented Reality (AR), Virtual Reality (VR), Human-Computer Interaction (HCI), and robotics. Apart from the absence of depth information, occlusions, articulation complexity, and the need for camera parameters knowledge pose additional challenges. In this work, we propose an optimization pipeline for estimating the 3D hand articulation from 2D keypoint input, which includes a keypoint alignment step and a fingertip loss to overcome the need to know or estimate the camera parameters. We evaluate our approach on the EgoDexter and Dexter+Object benchmarks to showcase that it performs competitively with the state-of-the-art, while also demonstrating its robustness when processing \"in-the-wild\" images without any prior camera knowledge. Our quantitative analysis highlights the sensitivity of the 2D keypoint estimation accuracy, despite the use of hand priors. Code is available at the project page https://cpantazop.github.io/HandRepo/",
      "authors": [
        "Christos Pantazopoulos",
        "Spyridon Thermos",
        "Gerasimos Potamianos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T18:45:22+00:00",
          "link": "https://arxiv.org/abs/2506.11133v1",
          "size": "6157kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:17:59+00:00",
          "link": "https://arxiv.org/abs/2506.11133v2",
          "size": "6157kb",
          "version": "v2"
        }
      ],
      "title": "Monocular 3D Hand Pose Estimation with Implicit Camera Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11133",
        "HTML": "https://arxiv.org/html/2506.11133v2",
        "PDF": "https://arxiv.org/pdf/2506.11133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D hand pose estimation from images, which involves optimization and image processing techniques without any relation to large language model training data processing."
      },
      "tasks": [
        "3D Hand Pose Estimation",
        "Hand Pose Estimation",
        "Keypoint Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/cpantazop/handrepo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11897",
      "abstract": "For interface tracking of an arbitrary number of materials in two dimensions, we propose a multiphase cubic MARS method that\n  (a) accurately and efficiently represents the topology and geometry of the interface via graphs, cycles, and cubic splines,\n  (b) maintains an $(r,h)$-regularity condition of the interface so that the distance between any pair of adjacent markers is within a user-specified range that may vary according to the local curvature,\n  (c) applies to multiple materials with arbitrarily complex topology and geometry, and\n  (d) achieves fourth-, sixth-, and eighth-order accuracy both in time and in space. In particular, all possible types of junctions, which pose challenges to VOF methods and level-set methods, are handled with ease.\n  The fourth- and higher-order convergence rates of the proposed method are proven under the MARS framework. Results of classic benchmark tests confirm the analysis and demonstrate the superior accuracy and efficiency of the proposed method.",
      "authors": [
        "Yan Tan",
        "Yixiao Qian",
        "Zhiqi Li",
        "Qinghai Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T15:43:57+00:00",
          "link": "https://arxiv.org/abs/2506.11897v1",
          "size": "1155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T04:14:08+00:00",
          "link": "https://arxiv.org/abs/2506.11897v2",
          "size": "1163kb",
          "version": "v2"
        }
      ],
      "title": "The Multiphase Cubic MARS method for Fourth- and Higher-order Interface Tracking of Two or More Materials with Arbitrarily Complex Topology and Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11897",
        "HTML": "https://arxiv.org/html/2506.11897v2",
        "PDF": "https://arxiv.org/pdf/2506.11897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with interface tracking of materials, emphasizing geometrical and computational accuracy, but it does not relate to data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12610",
      "abstract": "Machine learning has achieved remarkable advancements but at the cost of significant computational resources. This has created an urgent need for a novel and energy-efficient computational fabric and corresponding algorithms. CMOS Oscillator Networks (OscNet) is a brain inspired and specially designed hardware for low energy consumption. In this paper, we propose a Hopfield Network based machine learning algorithm that can be implemented on OscNet. The network is trained using forward propagation alone to learn sparsely connected weights, yet achieves an 8% improvement in accuracy compared to conventional deep learning models on MNIST dataset. OscNet v1.5 achieves competitive accuracy on MNIST and is well-suited for implementation using CMOS-compatible ring oscillator arrays with SHIL. In oscillator-based inference, we utilize only 24% of the connections used in a fully connected Hopfield network, with merely a 0.1% drop in accuracy. OscNet v1.5 relies solely on forward propagation and employs sparse connections, making it an energy-efficient machine learning pipeline designed for oscillator computing fabric. The repository for OscNet family is: https://github.com/RussRobin/OscNet .",
      "authors": [
        "Wenxiao Cai and Zongru Li and Iris Wang and Yu-Neng Wang and Thomas H. Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T19:10:23+00:00",
          "link": "https://arxiv.org/abs/2506.12610v1",
          "size": "392kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T00:39:38+00:00",
          "link": "https://arxiv.org/abs/2506.12610v2",
          "size": "392kb",
          "version": "v2"
        }
      ],
      "title": "OscNet v1.5: Energy Efficient Hopfield Network on CMOS Oscillators for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12610",
        "HTML": "https://arxiv.org/html/2506.12610v2",
        "PDF": "https://arxiv.org/pdf/2506.12610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on energy-efficient machine learning using CMOS oscillators for image classification, which is unrelated to data processing in the context of large language models."
      },
      "tasks": [
        "image-classification",
        "Image Classification"
      ],
      "repo_urls": [
        "https://github.com/russrobin/oscnet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12885",
      "abstract": "Crop type classification using optical satellite time series remains limited in its ability to generalize across seasons, particularly when crop phenology shifts due to inter-annual weather variability. This hampers real-world applicability in scenarios where current-year labels are unavailable. In addition, uncertainty quantification is often overlooked, which reduces the reliability of such approaches for operational crop monitoring. Inspired by ecophysiological principles of plant growth, we propose a simple, model-agnostic Thermal-Time-based Temporal Sampling (T3S) method that replaces calendar time with thermal time. By subsampling time series in this biologically meaningful way, our method highlights key periods within the growing season while reducing temporal redundancy and noise. We evaluate the T3S on a multi-year Sentinel-2 dataset covering the entirety of Switzerland, which allows us to assess all applied methods on unseen years. Compared to state-of-the-art baselines, our approach yields substantial improvements in classification accuracy and, critically, provides well-calibrated uncertainty estimates. Moreover, the T3S method excels in low-data regimes and enables significantly more accurate early-season classification. With just 10% of the training labels, it outperforms the current baseline in both accuracy and uncertainty calibration, and by the end of June, it achieves a performance similar to the full-season baseline model.",
      "authors": [
        "Mehmet Ozgur Turkoglu",
        "Selene Ledain",
        "Helge Aasen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T15:30:08+00:00",
          "link": "https://arxiv.org/abs/2506.12885v1",
          "size": "2986kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T13:06:54+00:00",
          "link": "https://arxiv.org/abs/2506.12885v2",
          "size": "2986kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:30:13+00:00",
          "link": "https://arxiv.org/abs/2506.12885v3",
          "size": "2920kb",
          "version": "v3"
        }
      ],
      "title": "Model-Agnostic, Temperature-Informed Sampling Enhances Cross-Year Crop Mapping with Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12885",
        "HTML": "https://arxiv.org/html/2506.12885v3",
        "PDF": "https://arxiv.org/pdf/2506.12885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper proposes a novel sampling method for crop mapping, it is independent of LLMs and their training data processing, focusing instead on satellite imagery and temporal data."
      },
      "tasks": [
        "Crop Type Mapping",
        "Time Series",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13916",
      "abstract": "We propose a novel particle-based variational inference method designed to work with multimodal distributions. Our approach, referred to as Branched Stein Variational Gradient Descent (BSVGD), extends the classical Stein Variational Gradient Descent (SVGD) algorithm by incorporating a random branching mechanism that encourages the exploration of the state space. In this work, a theoretical guarantee for the convergence in distribution is presented, as well as numerical experiments to validate the suitability of our algorithm. Performance comparisons between the BSVGD and the SVGD are presented using the Wasserstein distance between samples and the corresponding computational times.",
      "authors": [
        "Isa\\'ias Ba\\~nales",
        "Arturo Jaramillo",
        "Joshu\\'e Hel\\'i Ricalde-Guerrero"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T18:51:44+00:00",
          "link": "https://arxiv.org/abs/2506.13916v1",
          "size": "538kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:05:36+00:00",
          "link": "https://arxiv.org/abs/2506.13916v2",
          "size": "532kb",
          "version": "v2"
        }
      ],
      "title": "Branching Stein Variational Gradient Descent for sampling multimodal distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13916",
        "HTML": "https://arxiv.org/html/2506.13916v2",
        "PDF": "https://arxiv.org/pdf/2506.13916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for variational inference in multimodal distributions and does not address training data processing for large language models."
      },
      "tasks": [
        "Variational Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14734",
      "abstract": "In this paper, we solve the long-standing problem of designing I/O-efficient compressed indexes. Our solution broadly consists of generalizing suffix sorting and revisiting suffix tree path compression. In classic suffix trees, path compression works by replacing unary suffix trie paths with pairs of pointers to $T$, which must be available in the form of some random access oracle at query time. In our approach, instead, we (i) sort the suffix tree's leaves according to a more general priority function $\\pi$ (generalizing suffix sorting), (ii) we build a suffix tree path decomposition prioritizing the leftmost paths in such an order, and (iii) we path-compress the decomposition's paths as pointers to a small subset of the string's suffixes. At this point, we show that the colexicographically-sorted array of those pointers represents a new elegant, simple, and remarkably I/O-efficient compressed suffix tree. For instance, by taking $\\pi$ to be the lexicographic rank of $T$'s suffixes, we can compress the suffix tree topology in $O(r)$ space on top of a $n\\log\\sigma + O(\\log n)$-bits text representation while essentially matching the pattern matching I/O complexity of Weiner and McCreight's suffix tree. Another (more practical) solution is obtained by taking $\\pi$ to be the colexicographic rank of $T$'s prefixes and using a fully-compressed random access oracle. The resulting self-index allows us to locate all occurrences of a given query pattern in less space and orders of magnitude faster than the $r$-index.",
      "authors": [
        "Ruben Becker",
        "Davide Cenzato",
        "Travis Gagie",
        "Sung-Hwan Kim",
        "Ragnar Groot Koerkamp",
        "Giovanni Manzini",
        "Nicola Prezza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T17:15:08+00:00",
          "link": "https://arxiv.org/abs/2506.14734v1",
          "size": "667kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T20:02:01+00:00",
          "link": "https://arxiv.org/abs/2506.14734v2",
          "size": "584kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T13:20:10+00:00",
          "link": "https://arxiv.org/abs/2506.14734v3",
          "size": "998kb",
          "version": "v3"
        }
      ],
      "title": "Compressing Suffix Trees by Path Decompositions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14734",
        "HTML": "https://arxiv.org/html/2506.14734v3",
        "PDF": "https://arxiv.org/pdf/2506.14734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing I/O-efficient compressed indexes and discusses suffix trees and path decompositions. It does not relate to LLM training data processing or any associated data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15841",
      "abstract": "Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
      "authors": [
        "Zijian Zhou",
        "Ao Qu",
        "Zhaoxuan Wu",
        "Sunghwan Kim",
        "Alok Prakash",
        "Daniela Rus",
        "Jinhua Zhao",
        "Bryan Kian Hsiang Low",
        "Paul Pu Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:44:46+00:00",
          "link": "https://arxiv.org/abs/2506.15841v1",
          "size": "5048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:53:48+00:00",
          "link": "https://arxiv.org/abs/2506.15841v2",
          "size": "5049kb",
          "version": "v2"
        }
      ],
      "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15841",
        "HTML": "https://arxiv.org/html/2506.15841v2",
        "PDF": "https://arxiv.org/pdf/2506.15841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MEM1, a framework for memory and reasoning in long-horizon agents. It briefly mentions constructing multi-turn environments by composing existing datasets, but this is not the main focus or a significant technical contribution to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.16273",
      "abstract": "Fine-Grained Image Retrieval~(FGIR) faces challenges in learning discriminative visual representations to retrieve images with similar fine-grained features. Current leading FGIR solutions typically follow two regimes: enforce pairwise similarity constraints in the semantic embedding space, or incorporate a localization sub-network to fine-tune the entire model. However, such two regimes tend to overfit the training data while forgetting the knowledge gained from large-scale pre-training, thus reducing their generalization ability. In this paper, we propose a Dual-Vision Adaptation (DVA) approach for FGIR, which guides the frozen pre-trained model to perform FGIR through collaborative sample and feature adaptation. Specifically, we design Object-Perceptual Adaptation, which modifies input samples to help the pre-trained model perceive critical objects and elements within objects that are helpful for category prediction. Meanwhile, we propose In-Context Adaptation, which introduces a small set of parameters for feature adaptation without modifying the pre-trained parameters. This makes the FGIR task using these adjusted features closer to the task solved during the pre-training. Additionally, to balance retrieval efficiency and performance, we propose Discrimination Perception Transfer to transfer the discriminative knowledge in the object-perceptual adaptation to the image encoder using the knowledge distillation mechanism. Extensive experiments show that DVA has fewer learnable parameters and performs well on three in-distribution and three out-of-distribution fine-grained datasets.",
      "authors": [
        "Xin Jiang",
        "Meiqi Cao",
        "Hao Tang",
        "Fei Shen",
        "Zechao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T12:46:55+00:00",
          "link": "https://arxiv.org/abs/2506.16273v1",
          "size": "1943kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:38:12+00:00",
          "link": "https://arxiv.org/abs/2506.16273v2",
          "size": "751kb",
          "version": "v2"
        }
      ],
      "title": "Fine-grained Image Retrieval via Dual-Vision Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16273",
        "HTML": "https://arxiv.org/html/2506.16273v2",
        "PDF": "https://arxiv.org/pdf/2506.16273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses fine-grained image retrieval and proposes the Dual-Vision Adaptation approach. It does not involve LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Image Retrieval",
        "Knowledge Distillation",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16809",
      "abstract": "One of the most classical pairs of symplectic and conjugate-symplectic schemes is given by the Midpoint method (the Gauss-Runge-Kutta method of order 2) and the Trapezoidal rule. These can be interpreted as compositions of the Implicit and Explicit Euler methods, taken in direct and reverse order, respectively. This naturally raises the question of whether a similar composition structure exists for higher-order Gauss-Legendre methods. In this paper, we provide a positive answer by first examining the fourth-order case and then outlining a generalization to higher orders.",
      "authors": [
        "Felice Iavernaro and Francesca Mazzia and Ernst Hairer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T07:56:01+00:00",
          "link": "https://arxiv.org/abs/2506.16809v1",
          "size": "619kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:45:38+00:00",
          "link": "https://arxiv.org/abs/2506.16809v2",
          "size": "9kb",
          "version": "v2"
        }
      ],
      "title": "High-order Gauss-Legendre methods admit a composition representation and a conjugate-symplectic counterpart",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16809",
        "HTML": "https://arxiv.org/html/2506.16809v2",
        "PDF": "https://arxiv.org/pdf/2506.16809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies higher-order Gauss-Legendre methods in the context of symplectic and conjugate-symplectic schemes. It does not pertain to LLM training data processing or relevant techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17088",
      "abstract": "Large Language Models (LLMs) often exhibit \\textit{hallucinations}, generating factually incorrect or semantically irrelevant content in response to prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by encouraging step-by-step reasoning, but its impact on hallucination detection remains underexplored. To bridge this gap, we conduct a systematic empirical evaluation. We begin with a pilot experiment, revealing that CoT reasoning significantly affects the LLM's internal states and token probability distributions. Building on this, we evaluate the impact of various CoT prompting methods on mainstream hallucination detection methods across both instruction-tuned and reasoning-oriented LLMs. Specifically, we examine three key dimensions: changes in hallucination score distributions, variations in detection accuracy, and shifts in detection confidence. Our findings show that while CoT prompting helps reduce hallucination frequency, it also tends to obscure critical signals used for detection, impairing the effectiveness of various detection methods. Our study highlights an overlooked trade-off in the use of reasoning. Code is publicly available at: https://anonymous.4open.science/r/cot-hallu-detect.",
      "authors": [
        "Jiahao Cheng",
        "Tiancheng Su",
        "Jia Yuan",
        "Guoxiu He",
        "Jiawei Liu",
        "Xinqi Tao",
        "Jingwen Xie and Huaxia Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T15:49:37+00:00",
          "link": "https://arxiv.org/abs/2506.17088v1",
          "size": "538kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T00:41:37+00:00",
          "link": "https://arxiv.org/abs/2506.17088v2",
          "size": "538kb",
          "version": "v2"
        }
      ],
      "title": "Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17088",
        "HTML": "https://arxiv.org/html/2506.17088v2",
        "PDF": "https://arxiv.org/pdf/2506.17088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates the impact of Chain-of-Thought prompting on hallucination detection in LLMs. It does not focus on training data processing or data quality improvements for LLMs."
      },
      "tasks": [
        "Hallucination"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17858",
      "abstract": "Analyzing fetal body motion and shape is paramount in prenatal diagnostics and monitoring. Existing methods for fetal MRI analysis mainly rely on anatomical keypoints or volumetric body segmentations. Keypoints simplify body structure to facilitate motion analysis, but may ignore important details of full-body shape. Body segmentations capture complete shape information but complicate temporal analysis due to large non-local fetal movements. To address these limitations, we construct a 3D articulated statistical fetal body model based on the Skinned Multi-Person Linear Model (SMPL). Our algorithm iteratively estimates body pose in the image space and body shape in the canonical pose space. This approach improves robustness to MRI motion artifacts and intensity distortions, and reduces the impact of incomplete surface observations due to challenging fetal poses. We train our model on segmentations and keypoints derived from $19,816$ MRI volumes across $53$ subjects. Our model captures body shape and motion across time series and provides intuitive visualization. Furthermore, it enables automated anthropometric measurements traditionally difficult to obtain from segmentations and keypoints. When tested on unseen fetal body shapes, our method yields a surface alignment error of $3.2$ mm for $3$ mm MRI voxel size. To our knowledge, this represents the first 3D articulated statistical fetal body model, paving the way for enhanced fetal motion and shape analysis in prenatal diagnostics. The code is available at https://github.com/MedicalVisionGroup/fetal-smpl .",
      "authors": [
        "Yingcheng Liu",
        "Peiqi Wang",
        "Sebastian Diaz",
        "Esra Abaci Turk",
        "Benjamin Billot",
        "P. Ellen Grant",
        "and Polina Golland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T23:45:35+00:00",
          "link": "https://arxiv.org/abs/2506.17858v1",
          "size": "4729kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T02:47:24+00:00",
          "link": "https://arxiv.org/abs/2506.17858v2",
          "size": "4729kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T04:53:51+00:00",
          "link": "https://arxiv.org/abs/2506.17858v3",
          "size": "4729kb",
          "version": "v3"
        }
      ],
      "title": "Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17858",
        "HTML": "https://arxiv.org/html/2506.17858v3",
        "PDF": "https://arxiv.org/pdf/2506.17858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling and tracking of fetal shape and pose using 3D articulated statistical models, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18248",
      "abstract": "Generative adversarial attacks train a perturbation generator on a white-box surrogate model and subsequently apply the crafted perturbations to unseen black-box victim models. In contrast to iterative attacks, these methods deliver superior inference-time efficiency, scalability, and transferability; however, up until now, existing studies have not fully exploited the representational capacity of generative models to preserve and harness semantic information. Specifically, the intermediate activations of the generator encode rich semantic features--object boundaries and coarse shapes--that remain under-exploited, thereby limiting the alignment of perturbations with object-salient regions which are critical for adversarial transferability. To remedy this, we introduce a semantic structure-aware attack framework based on the Mean Teacher, which serves as a temporally smoothed feature reference. With this smoothed reference, we further direct semantic consistency between the early-layer activations in the student and those of the semantically rich teacher by feature distillation. By anchoring perturbation synthesis to the semantically salient early intermediate blocks within the generator based on empirical findings, our method guides progressive adversarial perturbation on regions that substantially enhance adversarial transferability. We conduct extensive experiments over diverse models, domains and tasks to demonstrate consistent improvements relative to state-of-the-art generative attacks, comprehensively evaluated using conventional metrics and our newly proposed Accidental Correction Rate (ACR).",
      "authors": [
        "Jongoh Jeong",
        "Hunmin Yang",
        "Jaeseok Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T02:35:09+00:00",
          "link": "https://arxiv.org/abs/2506.18248v1",
          "size": "14609kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:17:52+00:00",
          "link": "https://arxiv.org/abs/2506.18248v2",
          "size": "14610kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T05:35:13+00:00",
          "link": "https://arxiv.org/abs/2506.18248v3",
          "size": "14610kb",
          "version": "v3"
        }
      ],
      "title": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18248",
        "HTML": "https://arxiv.org/html/2506.18248v3",
        "PDF": "https://arxiv.org/pdf/2506.18248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses generative adversarial attacks and enhancing adversarial transferability, which does not involve LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18584",
      "abstract": "Extended reality (XR) devices, commonly known as wearables, must handle significant computational loads under tight latency constraints. To meet these demands, they rely on a combination of on-device processing and edge offloading. This letter focuses on offloading strategies for wearables by considering their impact across three time scales: instantaneous power consumption, short-term temperature fluctuations, and long-term battery duration. We introduce a comprehensive system model that captures these temporal dynamics, and propose a stochastic and stationary offloading strategy, called TAO (for temperature-aware offloading), designed to minimize the offloading cost while adhering to power, thermal, and energy constraints. Our performance evaluation, leveraging COMSOL models of real-world wearables, confirms that TAO reduces offloading cost by over 35% compared to state-of-the-art approaches, without violating the wearable operational limits.",
      "authors": [
        "Francesco Malandrino and Olga Chukhno and Alessandro Catania and Antonella Molinaro and Carla Fabiana Chiasserini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T12:41:29+00:00",
          "link": "https://arxiv.org/abs/2506.18584v1",
          "size": "2387kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:59:41+00:00",
          "link": "https://arxiv.org/abs/2506.18584v2",
          "size": "2412kb",
          "version": "v2"
        }
      ],
      "title": "XR Offloading Across Multiple Time Scales: The Roles of Power, Temperature, and Energy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18584",
        "HTML": "https://arxiv.org/html/2506.18584v2",
        "PDF": "https://arxiv.org/pdf/2506.18584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on offloading strategies for XR devices considering power, temperature, and energy, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19210",
      "abstract": "Cerebral Visual Impairment (CVI) is the set to be the leading cause of vision impairment, yet remains underrepresented in assistive technology research. Unlike ocular conditions, CVI affects higher-order visual processing-impacting object recognition, facial perception, and attention in complex environments. This paper presents a co-design study with two adults with CVI investigating how smart glasses, i.e. head-mounted extended reality displays, can support understanding and interaction with the immediate environment. Guided by the Double Diamond design framework, we conducted a two-week diary study, two ideation workshops, and ten iterative development sessions using the Apple Vision Pro. Our findings demonstrate that smart glasses can meaningfully address key challenges in locating objects, reading text, recognising people, engaging in conversations, and managing sensory stress. With the rapid advancement of smart glasses and increasing recognition of CVI as a distinct form of vision impairment, this research addresses a timely and under-explored intersection of technology and need.",
      "authors": [
        "Bhanuka Gamage",
        "Nicola McDowell",
        "Dijana Kovacic",
        "Leona Holloway",
        "Thanh-Toan Do",
        "Nicholas Price",
        "Arthur Lowery",
        "Kim Marriott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T00:40:20+00:00",
          "link": "https://arxiv.org/abs/2506.19210v1",
          "size": "3668kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:24:33+00:00",
          "link": "https://arxiv.org/abs/2506.19210v2",
          "size": "3668kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T01:44:16+00:00",
          "link": "https://arxiv.org/abs/2506.19210v3",
          "size": "4094kb",
          "version": "v3"
        }
      ],
      "title": "Smart Glasses for CVI: Co-Designing Extended Reality Solutions to Support Environmental Perception by People with Cerebral Visual Impairment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19210",
        "HTML": "https://arxiv.org/html/2506.19210v3",
        "PDF": "https://arxiv.org/pdf/2506.19210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using smart glasses for people with Cerebral Visual Impairment (CVI), focusing on assistive technology, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19472",
      "abstract": "Inspired by the biological visual system that selectively allocates attention to efficiently identify salient objects or regions, underwater salient instance segmentation (USIS) aims to jointly address the problems of where to look (saliency prediction) and what is there (instance segmentation) in underwater scenarios. However, USIS remains an underexplored challenge due to the inaccessibility and dynamic nature of underwater environments, as well as the scarcity of large-scale, high-quality annotated datasets. In this paper, we introduce USIS16K, a large-scale dataset comprising 16,151 high-resolution underwater images collected from diverse environmental settings and covering 158 categories of underwater objects. Each image is annotated with high-quality instance-level salient object masks, representing a significant advance in terms of diversity, complexity, and scalability. Furthermore, we provide benchmark evaluations on underwater object detection and USIS tasks using USIS16K. To facilitate future research in this domain, the dataset and benchmark models are publicly available.",
      "authors": [
        "Lin Hong and Xin Wang and Yihao Li and Xia Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T09:58:01+00:00",
          "link": "https://arxiv.org/abs/2506.19472v1",
          "size": "32078kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:40:53+00:00",
          "link": "https://arxiv.org/abs/2506.19472v2",
          "size": "32078kb",
          "version": "v2"
        }
      ],
      "title": "USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19472",
        "HTML": "https://arxiv.org/html/2506.19472v2",
        "PDF": "https://arxiv.org/pdf/2506.19472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces the USIS16K dataset, a large-scale high-quality dataset specifically for underwater salient instance segmentation, which involves dataset creation and significantly contributes to data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19530",
      "abstract": "Balancing combat encounters in Dungeons & Dragons (D&D) is a complex task that requires Dungeon Masters (DM) to manually assess party strength, enemy composition, and dynamic player interactions while avoiding interruption of the narrative flow. In this paper, we propose Encounter Generation via Reinforcement Learning (NTRL), a novel approach that automates Dynamic Difficulty Adjustment (DDA) in D&D via combat encounter design. By framing the problem as a contextual bandit, NTRL generates encounters based on real-time party members attributes. In comparison with classic DM heuristics, NTRL iteratively optimizes encounters to extend combat longevity (+200%), increases damage dealt to party members, reducing post-combat hit points (-16.67%), and raises the number of player deaths while maintaining low total party kills (TPK). The intensification of combat forces players to act wisely and engage in tactical maneuvers, even though the generated encounters guarantee high win rates (70%). Even in comparison with encounters designed by human Dungeon Masters, NTRL demonstrates superior performance by enhancing the strategic depth of combat while increasing difficulty in a manner that preserves overall game fairness.",
      "authors": [
        "Carlo Romeo",
        "Andrew D. Bagdanov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T11:34:01+00:00",
          "link": "https://arxiv.org/abs/2506.19530v1",
          "size": "26625kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:26:44+00:00",
          "link": "https://arxiv.org/abs/2506.19530v2",
          "size": "6850kb",
          "version": "v2"
        }
      ],
      "title": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19530",
        "HTML": "https://arxiv.org/html/2506.19530v2",
        "PDF": "https://arxiv.org/pdf/2506.19530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on using reinforcement learning for encounter generation in Dungeons & Dragons, which does not relate to LLM training data processing or any associated data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19955",
      "abstract": "Most crowd counting methods directly regress blockwise density maps using Mean Squared Error (MSE) losses. This practice has two key limitations: (1) it fails to account for the extreme spatial sparsity of annotations -- over 95% of 8x8 blocks are empty across standard benchmarks, so supervision signals in informative regions are diluted by the predominant zeros; (2) MSE corresponds to a Gaussian error model that poorly matches discrete, non-negative count data. To address these issues, we introduce ZIP, a scalable crowd counting framework that models blockwise counts with a Zero-Inflated Poisson likelihood: a zero-inflation term learns the probability a block is structurally empty (handling excess zeros), while the Poisson component captures expected counts when people are present (respecting discreteness). We provide a generalization analysis showing a tighter risk bound for ZIP than MSE-based losses and DMCount provided that the training resolution is moderately large. To assess the scalability of ZIP, we instantiate it on backbones spanning over 100x in parameters/compute. Experiments on ShanghaiTech A & B, UCF-QNRF, and NWPU-Crowd demonstrate that ZIP consistently surpasses state-of-the-art methods across all model scales.",
      "authors": [
        "Yiming Ma",
        "Victor Sanchez",
        "Tanaya Guha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T19:06:22+00:00",
          "link": "https://arxiv.org/abs/2506.19955v1",
          "size": "25539kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T22:29:43+00:00",
          "link": "https://arxiv.org/abs/2506.19955v2",
          "size": "18896kb",
          "version": "v2"
        }
      ],
      "title": "ZIP: Scalable Crowd Counting via Zero-Inflated Poisson Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19955",
        "HTML": "https://arxiv.org/html/2506.19955v2",
        "PDF": "https://arxiv.org/pdf/2506.19955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for crowd counting using a Zero-Inflated Poisson model, which is focused on image data processing and not on LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20040",
      "abstract": "Uncovering emergent concepts across transformer layers remains a significant challenge because the residual stream linearly mixes and duplicates information, obscuring how features evolve within large language models. Current research efforts primarily inspect neural representations at single layers, thereby overlooking this cross-layer superposition and the redundancy it introduces. These representations are typically either analyzed directly for activation patterns or passed to probing classifiers that map them to a limited set of predefined concepts. To address these limitations, we propose cross-layer VQ-VAE (CLVQ-VAE), a framework that uses vector quantization to map representations across layers and in the process collapse duplicated residual-stream features into compact, interpretable concept vectors. Our approach uniquely combines top-k temperature-based sampling during quantization with EMA codebook updates, providing controlled exploration of the discrete latent space while maintaining code-book diversity. We further enhance the framework with scaled-spherical k-means++ for codebook initialization, which clusters by directional similarity rather than magnitude, better aligning with semantic structure in word embedding space.",
      "authors": [
        "Ankur Garg",
        "Xuemin Yu",
        "Hassan Sajjad",
        "Samira Ebrahimi Kahou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T22:43:36+00:00",
          "link": "https://arxiv.org/abs/2506.20040v1",
          "size": "3261kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:35:12+00:00",
          "link": "https://arxiv.org/abs/2506.20040v2",
          "size": "3261kb",
          "version": "v2"
        }
      ],
      "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20040",
        "HTML": "https://arxiv.org/html/2506.20040v2",
        "PDF": "https://arxiv.org/pdf/2506.20040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for interpreting language models through cross-layer concept discovery, focusing on model interpretation rather than any aspect of training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20063",
      "abstract": "Background: Software development teams are increasingly diverse, embedded, and cross-disciplinary. Domain experts (DEs) from different disciplines collaborate with professional software developers (SDEs), bringing complementary expertise in creating and maintaining complex production software. However, contested expectations, divergent problem-solving perspectives, and conflicting priorities lead to friction. Aims: This study aims to investigate the dynamics of emerging collaboration of cross-disciplinary software development (CDSD) by exploring the expectations held by DEs and SDEs and understanding how these frictions manifest in practice. Method: We utilize Activity Theory (AT), a well-established socio-technical framework, as an analytical lens in a grounded, empirical investigation, conducted through a mixed-method study involving 24 interviews (12 DEs and 12 SDEs) and a large-scale validation survey with 293 participants (161 DEs and 132 SDEs). Results: We conceptualize and empirically ground the CDSD dynamics. We identified eight expectations held by SDEs and six by DEs. By mapping these expectations to AT components, we revealed 21 frictions in CDSD and illustrated where and how they arise. Conclusions: This study offers a theoretical lens for understanding the dynamics and frictions in CDSD and provides actionable insights for future research, practitioners, and infrastructure design.",
      "authors": [
        "Zixuan Feng",
        "Thomas Zimmermann",
        "Lorenzo Pisani",
        "Christopher Gooley",
        "Jeremiah Wander",
        "Anita Sarma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T23:51:35+00:00",
          "link": "https://arxiv.org/abs/2506.20063v1",
          "size": "306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T00:17:53+00:00",
          "link": "https://arxiv.org/abs/2506.20063v2",
          "size": "306kb",
          "version": "v2"
        }
      ],
      "title": "When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20063",
        "HTML": "https://arxiv.org/html/2506.20063v2",
        "PDF": "https://arxiv.org/pdf/2506.20063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores cross-disciplinary collaboration in software development teams using Activity Theory. It does not address LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20457",
      "abstract": "This study introduces the Homotopy Perturbation Sumudu Transform Method (HPSTM), a novel hybrid approach combining the Sumudu transform with homotopy perturbation to solve nonlinear fractional partial differential equations (FPDEs), including fractional porous medium, heat transfer, and Fisher equations, using the Caputo fractional derivative. HPSTM leverages the linearity-preserving properties of the Sumudu transform and the flexibility of homotopy perturbation, achieving faster convergence than Laplace-HPM or Elzaki-HPM for strongly nonlinear FPDEs. Series solutions yield absolute errors as low as $3.12 \\times 10^{-3}$ for $\\alpha = 0.9$, with computational times averaging 0.5 seconds per example using 5 series terms on standard hardware. Solutions are validated against exact solutions, Adomian Decomposition Method (ADM), radial basis function (RBF) meshless method, Variational Iteration Method (VIM), Finite Difference Method (FDM), and a spectral method. Numerical examples, sensitivity analysis, and graphical representations for $\\alpha = 1.0, 0.9, 0.8, 0.7$ confirm HPSTM's accuracy, efficiency, and robustness. Limitations include challenges with high-order nonlinearities and multi-dimensional domains. HPSTM shows promise for applications in modeling fluid flow in porous media, heat conduction in complex materials, and biological population dynamics.",
      "authors": [
        "Maryam Jalili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T14:08:08+00:00",
          "link": "https://arxiv.org/abs/2506.20457v1",
          "size": "188kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:43:42+00:00",
          "link": "https://arxiv.org/abs/2506.20457v2",
          "size": "173kb",
          "version": "v2"
        }
      ],
      "title": "A Novel Homotopy Perturbation Sumudu Transform Method for Nonlinear Fractional PDEs: Applications and Comparative Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20457",
        "HTML": "https://arxiv.org/html/2506.20457v2",
        "PDF": "https://arxiv.org/pdf/2506.20457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the Homotopy Perturbation Sumudu Transform Method for solving nonlinear fractional PDEs, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20495",
      "abstract": "Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at https://github.com/zjunlp/ReCode.",
      "authors": [
        "Haoze Wu",
        "Yunzhi Yao",
        "Wenhao Yu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T14:41:13+00:00",
          "link": "https://arxiv.org/abs/2506.20495v1",
          "size": "580kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:31:07+00:00",
          "link": "https://arxiv.org/abs/2506.20495v2",
          "size": "581kb",
          "version": "v2"
        }
      ],
      "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20495",
        "PDF": "https://arxiv.org/pdf/2506.20495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on enhancing code generation capabilities of LLMs using a new framework, ReCode, which incorporates reinforcement learning. It constructs a dataset, but the primary emphasis is on algorithmic improvement rather than core data processing for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21582",
      "abstract": "Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.",
      "authors": [
        "Sam Yu-Te Lee",
        "Chengyang Ji",
        "Shicheng Wen",
        "Lifu Huang",
        "Dongyu Liu",
        "Kwan-Liu Ma"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T05:24:58+00:00",
          "link": "https://arxiv.org/abs/2506.21582v1",
          "size": "2127kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:52:15+00:00",
          "link": "https://arxiv.org/abs/2506.21582v2",
          "size": "2127kb",
          "version": "v2"
        }
      ],
      "title": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21582",
        "PDF": "https://arxiv.org/pdf/2506.21582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces VIDEE, a system for text analytics with intelligent agents, focusing on automation and collaboration in text analysis processes. There is no significant discussion on data processing for LLM training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21918",
      "abstract": "Recent research has demonstrated Reservoir Computing's capability to model various chaotic dynamical systems, yet its application to Hamiltonian systems remains relatively unexplored. This paper investigates the effectiveness of Reservoir Computing in capturing rogue wave dynamics from the nonlinear Schr\\\"{o}dinger equation, a challenging Hamiltonian system with modulation instability. The model-free approach learns from breather simulations with five unstable modes. A properly tuned parallel Echo State Network can predict dynamics from two distinct testing datasets. The first set is a continuation of the training data, whereas the second set involves a higher-order breather. An investigation of the one-step prediction capability shows remarkable agreement between the testing data and the models. Furthermore, we show that the trained reservoir can predict the propagation of rogue waves over a relatively long prediction horizon, despite facing unseen dynamics. Finally, we introduce a method to significantly improve the Reservoir Computing prediction in autonomous mode, enhancing its long-term forecasting ability. These results advance the application of Reservoir Computing to spatio-temporal Hamiltonian systems and highlight the critical importance of phase space coverage in the design of training data.",
      "authors": [
        "Abrari Noor Hasmi and Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:12:56+00:00",
          "link": "https://arxiv.org/abs/2506.21918v1",
          "size": "2862kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:50:30+00:00",
          "link": "https://arxiv.org/abs/2506.21918v2",
          "size": "2830kb",
          "version": "v2"
        }
      ],
      "title": "Model-free Forecasting of Rogue Waves using Reservoir Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21918",
        "HTML": "https://arxiv.org/html/2506.21918v2",
        "PDF": "https://arxiv.org/pdf/2506.21918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research applies Reservoir Computing for modeling rogue wave dynamics, focusing on prediction and forecasting capabilities. It does not address LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23407",
      "abstract": "We implement a compile toolchain from Q# to QASM 3.0 including a full-featured lexer and parser implementation, as well as a compiler that supports a subset of Q# features. The lexer, parser and compiler are shown to work with various input Q# programs and the implementation is compared against existing Q# compile tools. Unlike the Microsoft implementation of the official Q# compile toolchain, our implementation is written in TypeScript in order to port functionality to web environments.",
      "authors": [
        "Marcus Edwards"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:02:57+00:00",
          "link": "https://arxiv.org/abs/2506.23407v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T22:46:09+00:00",
          "link": "https://arxiv.org/abs/2506.23407v2",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "title": "Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23407",
        "HTML": "https://arxiv.org/html/2506.23407v2",
        "PDF": "https://arxiv.org/pdf/2506.23407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a compile toolchain for Q# to QASM 3.0, focusing on compilation tools and language processing rather than on any form of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00792",
      "abstract": "Generating accurate and realistic virtual human movements in real-time is of high importance for a variety of applications in computer graphics, interactive virtual environments, robotics, and biomechanics. This paper introduces a novel real-time inverse kinematics (IK) solver specifically designed for realistic human-like movement generation. Leveraging the automatic differentiation and just-in-time compilation of TensorFlow, the proposed solver efficiently handles complex articulated human skeletons with high degrees of freedom. By treating forward and inverse kinematics as differentiable operations, our method effectively addresses common challenges such as error accumulation and complicated joint limits in multi-constrained problems, which are critical for realistic human motion modeling. We demonstrate the solver's effectiveness on the SMPLX human skeleton model, evaluating its performance against widely used iterative-based IK algorithms, like Cyclic Coordinate Descent (CCD), FABRIK, and the nonlinear optimization algorithm IPOPT. Our experiments cover both simple end-effector tasks and sophisticated, multi-constrained problems with realistic joint limits. Results indicate that our IK solver achieves real-time performance, exhibiting rapid convergence, minimal computational overhead per iteration, and improved success rates compared to existing methods. The project code is available at https://github.com/hvoss-techfak/TF-JAX-IK",
      "authors": [
        "Hendric Voss",
        "Stefan Kopp"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T14:26:30+00:00",
          "link": "https://arxiv.org/abs/2507.00792v1",
          "size": "1055kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T11:54:07+00:00",
          "link": "https://arxiv.org/abs/2507.00792v2",
          "size": "1038kb",
          "version": "v2"
        }
      ],
      "title": "Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00792",
        "HTML": "https://arxiv.org/html/2507.00792v2",
        "PDF": "https://arxiv.org/pdf/2507.00792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a real-time inverse kinematics solver for generating human-like movement in virtual environments. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01201",
      "abstract": "Independently trained vision and language models inhabit disjoint representational spaces, shaped by their respective modalities, objectives, and architectures. Yet an emerging hypothesis - the Platonic Representation Hypothesis - suggests that such models may nonetheless converge toward a shared statistical model of reality. This compatibility, if it exists, raises a fundamental question: can we move beyond post-hoc statistical detection of alignment and explicitly optimize for it between such disjoint representations? We cast this Platonic alignment problem as a multi-objective optimization task - preserve each modality's native structure while aligning for mutual coherence. We introduce the Joint Autoencoder Modulator (JAM) framework that jointly trains modality-specific autoencoders on the latent representations of pre-trained single modality models, encouraging alignment through both reconstruction and cross-modal objectives. By analogy, this framework serves as a method to escape Plato's Cave, enabling the emergence of shared structure from disjoint inputs. We evaluate this framework across three critical design axes: (i) the alignment objective - comparing contrastive loss (Con), its hard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at which alignment is most effective, and (iii) the impact of foundation model scale on representational convergence. Our findings show that our lightweight Pareto-efficient framework reliably induces alignment, even across frozen, independently trained representations, offering both theoretical insight and practical pathways for transforming generalist unimodal foundations into specialist multimodal models.",
      "authors": [
        "Lauren Hyoseo Yoon",
        "Yisong Yue",
        "Been Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T21:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.01201v1",
          "size": "1651kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:07:36+00:00",
          "link": "https://arxiv.org/abs/2507.01201v2",
          "size": "1651kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T22:37:17+00:00",
          "link": "https://arxiv.org/abs/2507.01201v3",
          "size": "1651kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T21:17:46+00:00",
          "link": "https://arxiv.org/abs/2507.01201v4",
          "size": "1651kb",
          "version": "v4"
        }
      ],
      "title": "Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01201",
        "HTML": "https://arxiv.org/html/2507.01201v4",
        "PDF": "https://arxiv.org/pdf/2507.01201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the alignment of independently trained vision and language models using a joint autoencoder modulator framework. It does not discuss any training data processing operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02459",
      "abstract": "We propose and study a Particle-In-Cell (PIC) method based on the Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong and inhomogeneous external magnetic field with fixed direction, where we focus on the motion of particles in the plane orthogonal to the magnetic field (so-called poloidal directions). In this regime, the time step can be subject to stability constraints related to the smallness of Larmor radius and plasma frequency [21]. To avoid this limitation, our approach is based on numerical schemes [9, 10, 12], providing a consistent PIC discretization of the guiding-center system taking into account variations of the magnetic field. We carry out some theoretical proofs and perform several numerical experiments to validate the method and its underlying concepts",
      "authors": [
        "Francis Filbet (UT",
        "IMT)",
        "L Miguel Rodrigues (IRMAR)",
        "Kim Han Trinh (IRMAR)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:16:49+00:00",
          "link": "https://arxiv.org/abs/2507.02459v1",
          "size": "3360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:39:51+00:00",
          "link": "https://arxiv.org/abs/2507.02459v2",
          "size": "3359kb",
          "version": "v2"
        }
      ],
      "title": "A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02459",
        "PDF": "https://arxiv.org/pdf/2507.02459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a modified Crank-Nicolson scheme for the Vlasov-Poisson system related to particle motion under a magnetic field. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03331",
      "abstract": "To alleviate the reliance of deep neural networks on large-scale datasets, dataset distillation aims to generate compact, high-quality synthetic datasets that can achieve comparable performance to the original dataset. The integration of generative models has significantly advanced this field. However, existing approaches primarily focus on aligning the distilled dataset with the original one, often overlooking task-specific information that can be critical for optimal downstream performance. In this paper, focusing on the downstream task of classification, we propose a task-specific sampling strategy for generative dataset distillation that incorporates the concept of difficulty to consider the requirements of the target task better. The final dataset is sampled from a larger image pool with a sampling distribution obtained by matching the difficulty distribution of the original dataset. A logarithmic transformation is applied as a pre-processing step to correct for distributional bias. The results of extensive experiments demonstrate the effectiveness of our method and suggest its potential for enhancing performance on other downstream tasks. The code is available at https://github.com/SumomoTaku/DiffGuideSamp.",
      "authors": [
        "Mingzhuo Li",
        "Guang Li",
        "Jiafeng Mao",
        "Linfeng Ye",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T06:38:02+00:00",
          "link": "https://arxiv.org/abs/2507.03331v1",
          "size": "10338kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:04:11+00:00",
          "link": "https://arxiv.org/abs/2507.03331v2",
          "size": "10338kb",
          "version": "v2"
        }
      ],
      "title": "Task-Specific Generative Dataset Distillation with Difficulty-Guided Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03331",
        "HTML": "https://arxiv.org/html/2507.03331v2",
        "PDF": "https://arxiv.org/pdf/2507.03331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses dataset distillation to generate synthetic datasets, which involves data processing techniques. However, it focuses on general deep neural networks rather than specifically on LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03404",
      "abstract": "The z-transform of a sequence is a classical tool used within signal processing, control theory, computer science, and electrical engineering. It allows for studying sequences from their generating functions, with many operations that can be equivalently defined on the original sequence and its $z$-transform. In particular, the z-transform method focuses on asymptotic behaviors and allows the use of Taylor expansions. We present a sequence of results of increasing significance and difficulty for linear models and optimization algorithms, demonstrating the effectiveness and versatility of the z-transform method in deriving new asymptotic results. Starting from the simplest gradient descent iterations in an infinite-dimensional Hilbert space, we show how the spectral dimension characterizes the convergence behavior. We then extend the analysis to Nesterov acceleration, averaging techniques, and stochastic gradient descent.",
      "authors": [
        "Francis Bach (SIERRA)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T09:12:23+00:00",
          "link": "https://arxiv.org/abs/2507.03404v1",
          "size": "459kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:47:46+00:00",
          "link": "https://arxiv.org/abs/2507.03404v2",
          "size": "462kb",
          "version": "v2"
        }
      ],
      "title": "On the Effectiveness of the z-Transform Method in Quadratic Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03404",
        "PDF": "https://arxiv.org/pdf/2507.03404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the z-transform method in quadratic optimization and its application to linear models and optimization algorithms. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03532",
      "abstract": "Digital pathology has seen the advent of a wealth of foundational models (FM), yet to date their performance on cell phenotyping has not been benchmarked in a unified manner. We therefore propose PhenoBench: A comprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E) stained histopathology images. We provide both PhenoCell, a new H&E dataset featuring 14 granular cell types identified by using multiplexed imaging, and ready-to-use fine-tuning and benchmarking code that allows the systematic evaluation of multiple prominent pathology FMs in terms of dense cell phenotype predictions in different generalization scenarios. We perform extensive benchmarking of existing FMs, providing insights into their generalization behavior under technical vs. medical domain shifts. Furthermore, while FMs achieve macro F1 scores > 0.70 on previously established benchmarks such as Lizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This indicates a much more challenging task not captured by previous benchmarks, establishing PhenoCell as a prime asset for future benchmarking of FMs and supervised models alike. Code and data are available on GitHub.",
      "authors": [
        "Nora Koreuber",
        "Jannik Franzen",
        "Fabian H. Reith",
        "Claudia Winklmayr",
        "Jerome Luescher",
        "Elias Baumann",
        "Christian M. Schuerch",
        "Dagmar Kainmueller",
        "Josef Lorenz Rumberger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:37:57+00:00",
          "link": "https://arxiv.org/abs/2507.03532v1",
          "size": "4535kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T08:29:03+00:00",
          "link": "https://arxiv.org/abs/2507.03532v2",
          "size": "4523kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T06:42:01+00:00",
          "link": "https://arxiv.org/abs/2507.03532v3",
          "size": "4523kb",
          "version": "v3"
        }
      ],
      "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03532",
        "HTML": "https://arxiv.org/html/2507.03532v3",
        "PDF": "https://arxiv.org/pdf/2507.03532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on creating a benchmark for cell phenotyping in digital pathology using a new dataset, PhenoCell. It targets benchmarking in medical imaging rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03580",
      "abstract": "In real world translation scenarios, terminology is rarely one-to-one. Instead, multiple valid translations may appear in a terminology dictionary, but correctness of a translation depends on corporate style guides and context. This can be challenging for neural machine translation (NMT) systems. Luckily, in a corporate context, many examples of human post-edits of valid but incorrect terminology exist. The goal of this work is to learn how to disambiguate our terminology based on these corrections. Our approach is based on preference optimization, using the term post-edit as the knowledge to be preferred. While previous work had to rely on unambiguous translation dictionaries to set hard constraints during decoding, or to add soft constraints in the input, our framework requires neither one-to-one dictionaries nor human intervention at decoding time. We report results on English-German post-edited data and find that the optimal combination of supervised fine-tuning and preference optimization, with both term-specific and full sequence objectives, yields statistically significant improvements in term accuracy over a strong NMT baseline without significant losses in COMET score. Additionally, we release test sets from our post-edited data and terminology dictionary.",
      "authors": [
        "Nathaniel Berger",
        "Johannes Eschbach-Dymanus",
        "Miriam Exel",
        "Matthias Huck",
        "Stefan Riezler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T13:49:14+00:00",
          "link": "https://arxiv.org/abs/2507.03580v1",
          "size": "81kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:42:09+00:00",
          "link": "https://arxiv.org/abs/2507.03580v2",
          "size": "81kb",
          "version": "v2"
        }
      ],
      "title": "Learning to Translate Ambiguous Terminology by Preference Optimization on Post-Edits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03580",
        "HTML": "https://arxiv.org/html/2507.03580v2",
        "PDF": "https://arxiv.org/pdf/2507.03580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution to LLM training data processing by addressing how to handle ambiguous terminology in translation through preference optimization and supervised fine-tuning. It also provides new test sets from post-edited data, directly relevant to LLM fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04032",
      "abstract": "We introduce remarkable upper bounds for the interpolation error constants on triangles, which are sharp and given by simple formulas. These constants are crucial in analyzing interpolation errors, particularly those associated with the Finite Element Method. In this study, we proved boundness via the numerical verification method and asymptotic analysis. This study is also essential in that it demonstrates a valuable application of the numerical verification method. The proof process of this study may be applied to the proof of various other norm inequalities.",
      "authors": [
        "Kenta Kobayashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T13:00:20+00:00",
          "link": "https://arxiv.org/abs/2507.04032v1",
          "size": "1174kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:21:58+00:00",
          "link": "https://arxiv.org/abs/2507.04032v2",
          "size": "1174kb",
          "version": "v2"
        }
      ],
      "title": "Remarkable upper bounds for the interpolation error constants on the triangles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04032",
        "PDF": "https://arxiv.org/pdf/2507.04032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents upper bounds for interpolation error constants within the context of numerical analysis, which is not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04037",
      "abstract": "The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence. To this end, we introduce J1-ENVS, the first interactive and dynamic legal environment tailored for LLM-based agents. Guided by legal experts, it comprises six representative scenarios from Chinese legal practices across three levels of environmental complexity. We further introduce J1-EVAL, a fine-grained evaluation framework, designed to assess both task performance and procedural compliance across varying levels of legal proficiency. Extensive experiments on 17 LLM agents reveal that, while many models demonstrate solid legal knowledge, they struggle with procedural execution in dynamic settings. Even the SOTA model, GPT-4o, falls short of 60% overall performance. These findings highlight persistent challenges in achieving dynamic legal intelligence and offer valuable insights to guide future research.",
      "authors": [
        "Zheng Jia and Shengbin Yue and Wei Chen and Siyuan Wang and Yidong Liu and Yun Song and Zhongyu Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T13:31:21+00:00",
          "link": "https://arxiv.org/abs/2507.04037v1",
          "size": "4963kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:02:05+00:00",
          "link": "https://arxiv.org/abs/2507.04037v2",
          "size": "4963kb",
          "version": "v2"
        }
      ],
      "title": "Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04037",
        "HTML": "https://arxiv.org/html/2507.04037v2",
        "PDF": "https://arxiv.org/pdf/2507.04037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on creating a benchmarking environment and evaluation framework for legal intelligence of LLM-based agents, not directly on data processing. However, fine-tuning is mentioned briefly, suggesting some relevance to LLM processing strategies."
      },
      "datasets": [
        {
          "dataset_name": "CharlesBeaumont/J1-Eval_Dataset",
          "downloads": "6",
          "likes": "0",
          "link": "https://huggingface.co/datasets/CharlesBeaumont/J1-Eval_Dataset"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04348",
      "abstract": "Large reasoning models (LRMs) have exhibited remarkable reasoning capabilities through inference-time scaling, but this progress has also introduced considerable redundancy and inefficiency into their reasoning processes, resulting in substantial computational waste. Previous work has attempted to mitigate this issue by penalizing the overall length of generated samples during reinforcement learning (RL), with the goal of encouraging a more concise chains of thought. However, we observe that such global length penalty often lead to excessive compression of critical reasoning steps while preserving unnecessary details in simpler ones, yielding a suboptimal trade-off between accuracy and efficiency. To address this issue, we propose SmartThinker, a two-stage learnable framework designed to enable fine-grained control over the length of reasoning chains based on the importance of each individual step. In the first stage, SmartThinker adapts a reasoning model to a short-form reasoning mode through rejection sampling combined with supervised fine-tuning (SFT). In the second stage, SmartThinker applies Step-Level Length Control Policy Optimization (SCPO) to refine the model output distribution, which increases the proportion of length allocated to critical steps while reducing redundancy in less important ones. SCPO consists of four core components: an online importance estimator, a step-level length control reward function, a step-level generalized advantage estimation (S-GAE) and a difficulty-adaptive clipping strategy. Working in concert, these components enable SCPO to implement differentiated length control across reasoning steps. Empirical results across multiple reasoning benchmarks and various backbone models demonstrate that SmartThinker significantly reduces redundant reasoning while achieving comparable or even superior performance to existing methods.",
      "authors": [
        "Xingyang He and Xiao Ling and Jie Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T11:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.04348v1",
          "size": "494kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:07:41+00:00",
          "link": "https://arxiv.org/abs/2507.04348v2",
          "size": "558kb",
          "version": "v2"
        }
      ],
      "title": "SmartThinker: Learning to Compress and Preserve Reasoning by Step-Level Length Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04348",
        "HTML": "https://arxiv.org/html/2507.04348v2",
        "PDF": "https://arxiv.org/pdf/2507.04348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SmartThinker, a framework involving supervised fine-tuning and optimization to control step-level reasoning length, which is directly related to refining data used in LLM training for better performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04447",
      "abstract": "Recent advances in vision-language-action (VLA) models have shown promise in integrating image generation with action prediction to improve generalization and reasoning in robot manipulation. However, existing methods are limited to challenging image-based forecasting, which suffers from redundant information and lacks comprehensive and critical world knowledge, including dynamic, spatial and semantic information. To address these limitations, we propose DreamVLA, a novel VLA framework that integrates comprehensive world knowledge forecasting to enable inverse dynamics modeling, thereby establishing a perception-prediction-action loop for manipulation tasks. Specifically, DreamVLA introduces a dynamic-region-guided world knowledge prediction, integrated with the spatial and semantic cues, which provide compact yet comprehensive representations for action planning. This design aligns with how humans interact with the world by first forming abstract multimodal reasoning chains before acting. To mitigate interference among the dynamic, spatial and semantic information during training, we adopt a block-wise structured attention mechanism that masks their mutual attention, preventing information leakage and keeping each representation clean and disentangled. Moreover, to model the conditional distribution over future actions, we employ a diffusion-based transformer that disentangles action representations from shared latent features. Extensive experiments on both real-world and simulation environments demonstrate that DreamVLA achieves 76.7% success rate on real robot tasks and 4.44 average length on the CALVIN ABC-D benchmarks.",
      "authors": [
        "Wenyao Zhang",
        "Hongsi Liu",
        "Zekun Qi",
        "Yunnan Wang",
        "Xinqiang Yu",
        "Jiazhao Zhang",
        "Runpei Dong",
        "Jiawei He",
        "He Wang",
        "Zhizheng Zhang",
        "Li Yi",
        "Wenjun Zeng",
        "Xin Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T16:14:29+00:00",
          "link": "https://arxiv.org/abs/2507.04447v1",
          "size": "6257kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:03:12+00:00",
          "link": "https://arxiv.org/abs/2507.04447v2",
          "size": "6295kb",
          "version": "v2"
        }
      ],
      "title": "DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04447",
        "HTML": "https://arxiv.org/html/2507.04447v2",
        "PDF": "https://arxiv.org/pdf/2507.04447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a vision-language-action model, DreamVLA, aimed at improving robot manipulation through comprehensive world knowledge and does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05653",
      "abstract": "Serverless platforms such as Kubernetes are increasingly adopted in high-performance computing, yet autoscaling remains challenging under highly dynamic and heterogeneous workloads. Existing approaches often rely on uniform reactive policies or unconditioned predictive models, ignoring both workload semantics and prediction uncertainty. We present AAPA, an archetype-aware predictive autoscaler that classifies workloads into four behavioral patterns -- SPIKE, PERIODIC, RAMP, and STATIONARY -- and applies tailored scaling strategies with confidence-based adjustments. To support reproducible evaluation, we release AAPAset, a weakly labeled dataset of 300,000 Azure Functions workload windows spanning diverse patterns. AAPA reduces SLO violations by up to 50% and lowers latency by 40% compared to Kubernetes HPA, albeit at 2-8x higher resource usage under spike-dominated conditions. To assess trade-offs, we propose the Resource Efficiency Index (REI), a unified metric balancing performance, cost, and scaling smoothness. Our results demonstrate the importance of modeling workload heterogeneity and uncertainty in autoscaling design.",
      "authors": [
        "Guilin Zhang",
        "Srinivas Vippagunta",
        "Raghavendra Nandagopal",
        "Suchitra Raman",
        "Jeff Xu",
        "Marcus Pfeiffer",
        "Shreeshankar Chatterjee",
        "Ziqi Tan",
        "Wulan Guo",
        "and Hailong Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:13:10+00:00",
          "link": "https://arxiv.org/abs/2507.05653v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:21:56+00:00",
          "link": "https://arxiv.org/abs/2507.05653v2",
          "size": "139kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T20:25:55+00:00",
          "link": "https://arxiv.org/abs/2507.05653v3",
          "size": "139kb",
          "version": "v3"
        }
      ],
      "title": "AAPA: An Archetype-Aware Predictive Autoscaler with Uncertainty Quantification for Serverless Workloads on Kubernetes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05653",
        "HTML": "https://arxiv.org/html/2507.05653v3",
        "PDF": "https://arxiv.org/pdf/2507.05653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a predictive autoscaler and an accompanying dataset (AAPAset) for serverless workloads, it is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06174",
      "abstract": "In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.",
      "authors": [
        "Koki Yamane",
        "Yunhan Li",
        "Masashi Konosu",
        "Koki Inami",
        "Junji Oaki",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.06174v1",
          "size": "16600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:53:31+00:00",
          "link": "https://arxiv.org/abs/2507.06174v2",
          "size": "16657kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:43:46+00:00",
          "link": "https://arxiv.org/abs/2507.06174v3",
          "size": "16665kb",
          "version": "v3"
        }
      ],
      "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06174",
        "HTML": "https://arxiv.org/html/2507.06174v3",
        "PDF": "https://arxiv.org/pdf/2507.06174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses teleoperation and imitation learning using sensorless force control and is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06261",
      "abstract": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.",
      "authors": [
        "Gheorghe Comanici",
        "Eric Bieber",
        "Mike Schaekermann",
        "Ice Pasupat",
        "Noveen Sachdeva",
        "Inderjit Dhillon",
        "Marcel Blistein",
        "Ori Ram",
        "Dan Zhang",
        "Evan Rosen",
        "Luke Marris",
        "Sam Petulla",
        "Colin Gaffney",
        "Asaf Aharoni",
        "Nathan Lintz",
        "Tiago Cardal Pais",
        "Henrik Jacobsson",
        "Idan Szpektor",
        "Nan-Jiang Jiang",
        "Krishna Haridasan",
        "Ahmed Omran",
        "Nikunj Saunshi",
        "Dara Bahri",
        "Gaurav Mishra",
        "Eric Chu",
        "Toby Boyd",
        "Brad Hekman",
        "Aaron Parisi",
        "Chaoyi Zhang",
        "Kornraphop Kawintiranon",
        "Tania Bedrax-Weiss",
        "Oliver Wang",
        "Ya Xu",
        "Ollie Purkiss",
        "Uri Mendlovic",
        "Ila\\\"i Deutel",
        "Nam Nguyen",
        "Adam Langley",
        "Flip Korn",
        "Lucia Rossazza",
        "Alexandre Ram\\'e",
        "Sagar Waghmare",
        "Helen Miller",
        "Vaishakh Keshava",
        "Ying Jian",
        "Xiaofan Zhang",
        "Raluca Ada Popa",
        "Kedar Dhamdhere",
        "Bla\\v{z} Bratani\\v{c}",
        "Kyuyeun Kim",
        "Terry Koo",
        "Ferran Alet",
        "Yi-ting Chen",
        "Arsha Nagrani",
        "Hannah Muckenhirn",
        "Zhiyuan Zhang",
        "Corbin Quick",
        "Filip Paveti\\'c",
        "Duc Dung Nguyen",
        "Joao Carreira",
        "Michael Elabd",
        "Haroon Qureshi",
        "Fabian Mentzer",
        "Yao-Yuan Yang",
        "Danielle Eisenbud",
        "Anmol Gulati",
        "Ellie Talius",
        "Eric Ni",
        "Sahra Ghalebikesabi",
        "Edouard Yvinec",
        "Alaa Saade",
        "Thatcher Ulrich",
        "Lorenzo Blanco",
        "Dan A. Calian",
        "Muhuan Huang",
        "A\\\"aron van den Oord",
        "Naman Goyal",
        "Terry Chen",
        "Praynaa Rawlani",
        "Christian Schallhart",
        "Swachhand Lokhande",
        "Xianghong Luo",
        "Jyn Shan",
        "Ceslee Montgomery",
        "Victoria Krakovna",
        "Federico Piccinini",
        "Omer Barak",
        "Jingyu Cui",
        "Yiling Jia",
        "Mikhail Dektiarev",
        "Alexey Kolganov",
        "Shiyu Huang",
        "Zhe Chen",
        "Xingyu Wang",
        "Jessica Austin",
        "Peter de Boursac",
        "Evgeny Sluzhaev",
        "Frank Ding",
        "Huijian Li",
        "Surya Bhupatiraju",
        "Mohit Agarwal",
        "S{\\l}awek Kwasiborski",
        "Paramjit Sandhu",
        "Patrick Siegler",
        "Ahmet Iscen",
        "Eyal Ben-David",
        "Shiraz Butt",
        "Miltos Allamanis",
        "Seth Benjamin",
        "Robert Busa-Fekete",
        "Felix Hernandez-Campos",
        "Sasha Goldshtein",
        "Matt Dibb",
        "Weiyang Zhang",
        "Annie Marsden",
        "Carey Radebaugh",
        "Stephen Roller",
        "Abhishek Nayyar",
        "Jacob Austin",
        "Tayfun Terzi",
        "Bhargav Kanagal Shamanna",
        "Pete Shaw",
        "Aayush Singh",
        "Florian Luisier",
        "Artur Mendon\\c{c}a",
        "Vaibhav Aggarwal",
        "Larisa Markeeva",
        "Claudio Fantacci",
        "Sergey Brin",
        "HyunJeong Choe",
        "Guanyu Wang",
        "Hartwig Adam",
        "Avigail Dabush",
        "Tatsuya Kiyono",
        "Eyal Marcus",
        "Jeremy Cole",
        "Theophane Weber",
        "Hongrae Lee",
        "Ronny Huang",
        "Alex Muzio",
        "Leandro Kieliger",
        "Maigo Le",
        "Courtney Biles",
        "Long Le",
        "Archit Sharma",
        "Chengrun Yang",
        "Avery Lamp",
        "Dave Dopson",
        "Nate Hurley",
        "Katrina (Xinyi) Xu",
        "Zhihao Shan",
        "Shuang Song",
        "Jiewen Tan",
        "Alexandre Senges",
        "George Zhang",
        "Chong You",
        "Yennie Jun",
        "David Raposo",
        "Susanna Ricco",
        "Xuan Yang",
        "Weijie Chen",
        "Prakhar Gupta",
        "Arthur Szlam",
        "Kevin Villela",
        "Chun-Sung Ferng",
        "Daniel Kasenberg",
        "Chen Liang",
        "Rui Zhu",
        "Arunachalam Narayanaswamy",
        "Florence Perot",
        "Paul Pucciarelli",
        "Anna Shekhawat",
        "Alexey Stern",
        "Rishikesh Ingale",
        "Stefani Karp",
        "Sanaz Bahargam",
        "Adrian Goedeckemeyer",
        "Jie Han",
        "Sicheng Li",
        "Andrea Tacchetti",
        "Dian Yu",
        "Abhishek Chakladar",
        "Zhiying Zhang",
        "Mona El Mahdy",
        "Xu Gao",
        "Dale Johnson",
        "Samrat Phatale",
        "AJ Piergiovanni",
        "Hyeontaek Lim",
        "Clement Farabet",
        "Carl Lebsack",
        "Theo Guidroz",
        "John Blitzer",
        "Nico Duduta",
        "David Madras",
        "Steve Li",
        "Daniel von Dincklage",
        "Xin Li",
        "Mahdis Mahdieh",
        "George Tucker",
        "Ganesh Jawahar",
        "Owen Xiao",
        "Danny Tarlow",
        "Robert Geirhos",
        "Noam Velan",
        "Daniel Vlasic",
        "Kalesha Bullard",
        "SK Park",
        "Nishesh Gupta",
        "Kellie Webster",
        "Ayal Hitron",
        "Jieming Mao",
        "Julian Eisenschlos",
        "Laurel Prince",
        "Nina D'Souza",
        "Kelvin Zheng",
        "Sara Nasso",
        "Gabriela Botea",
        "Carl Doersch",
        "Caglar Unlu",
        "Chris Alberti",
        "Alexey Svyatkovskiy",
        "Ankita Goel",
        "Krzysztof Choromanski",
        "Pan-Pan Jiang",
        "Richard Nguyen",
        "Four Flynn",
        "Daria \\'Curko",
        "Peter Chen",
        "Nicholas Roth",
        "Kieran Milan",
        "Caleb Habtegebriel",
        "Shashi Narayan",
        "Michael Moffitt",
        "Jake Marcus",
        "Thomas Anthony",
        "Brendan McMahan",
        "Gowoon Cheon",
        "Ruibo Liu",
        "Megan Barnes",
        "Lukasz Lew",
        "Rebeca Santamaria-Fernandez",
        "Mayank Upadhyay",
        "Arjun Akula",
        "Arnar Mar Hrafnkelsson",
        "Alvaro Caceres",
        "Andrew Bunner",
        "Michal Sokolik",
        "Subha Puttagunta",
        "Lawrence Moore",
        "Berivan Isik",
        "Jay Hartford",
        "Lawrence Chan",
        "Pradeep Shenoy",
        "Dan Holtmann-Rice",
        "Jane Park",
        "Fabio Viola",
        "Alex Salcianu",
        "Sujeevan Rajayogam",
        "Ian Stewart-Binks",
        "Zelin Wu",
        "Richard Everett",
        "Xi Xiong",
        "Pierre-Antoine Manzagol",
        "Gary Leung",
        "Carl Saroufim",
        "Bo Pang",
        "Dawid Wegner",
        "George Papamakarios",
        "Jennimaria Palomaki",
        "Helena Pankov",
        "Guangda Lai",
        "Guilherme Tubone",
        "Shubin Zhao",
        "Theofilos Strinopoulos",
        "Seth Neel",
        "Mingqiu Wang",
        "Joe Kelley",
        "Li Li",
        "Pingmei Xu",
        "Anitha Vijayakumar",
        "Andrea D'olimpio",
        "Omer Levy",
        "Massimo Nicosia",
        "Grigory Rozhdestvenskiy",
        "Ni Lao",
        "Sirui Xie",
        "Yash Katariya",
        "Jon Simon",
        "Sanjiv Kumar",
        "Florian Hartmann",
        "Michael Kilgore",
        "Jinhyuk Lee",
        "Aroma Mahendru",
        "Roman Ring",
        "Tom Hennigan",
        "Fiona Lang",
        "Colin Cherry",
        "David Steiner",
        "Dawsen Hwang",
        "Ray Smith",
        "Pidong Wang",
        "Jeremy Chen",
        "Ming-Hsuan Yang",
        "Sam Kwei",
        "Philippe Schlattner",
        "Donnie Kim",
        "Ganesh Poomal Girirajan",
        "Nikola Momchev",
        "Ayushi Agarwal",
        "Xingyi Zhou",
        "Ilkin Safarli",
        "Zachary Garrett",
        "AJ Pierigiovanni",
        "Sarthak Jauhari",
        "Alif Raditya Rochman",
        "Shikhar Vashishth",
        "Quan Yuan",
        "Christof Angermueller",
        "Jon Blanton",
        "Xinying Song",
        "Nitesh Bharadwaj Gundavarapu",
        "Thi Avrahami",
        "Maxine Deines",
        "Subhrajit Roy",
        "Manish Gupta",
        "Christopher Semturs",
        "Shobha Vasudevan",
        "Aditya Srikanth Veerubhotla",
        "Shriya Sharma",
        "Josh Jacob",
        "Zhen Yang",
        "Andreas Terzis",
        "Dan Karliner",
        "Auriel Wright",
        "Tania Rojas-Esponda",
        "Ashley Brown",
        "Abhijit Guha Roy",
        "Pawan Dogra",
        "Andrei Kapishnikov",
        "Peter Young",
        "Wendy Kan",
        "Vinodh Kumar Rajendran",
        "Maria Ivanova",
        "Salil Deshmukh",
        "Chia-Hua Ho",
        "Mike Kwong",
        "Stav Ginzburg",
        "Annie Louis",
        "KP Sawhney",
        "Slav Petrov",
        "Jing Xie",
        "Yunfei Bai",
        "Georgi Stoyanov",
        "Alex Fabrikant",
        "Rajesh Jayaram",
        "Yuqi Li",
        "Joe Heyward",
        "Justin Gilmer",
        "Yaqing Wang",
        "Radu Soricut",
        "Luyang Liu",
        "Qingnan Duan",
        "Jamie Hayes",
        "Maura O'Brien",
        "Gaurav Singh Tomar",
        "Sivan Eiger",
        "Bahar Fatemi",
        "Jeffrey Hui",
        "Catarina Barros",
        "Adaeze Chukwuka",
        "Alena Butryna",
        "Saksham Thakur",
        "Austin Huang",
        "Zhufeng Pan",
        "Haotian Tang",
        "Serkan Cabi",
        "Tulsee Doshi",
        "Michiel Bakker",
        "Sumit Bagri",
        "Ruy Ley-Wild",
        "Adam Lelkes",
        "Jennie Lees",
        "Patrick Kane",
        "David Greene",
        "Shimu Wu",
        "J\\\"org Bornschein",
        "Gabriela Surita",
        "Sarah Hodkinson",
        "Fangtao Li",
        "Chris Hidey",
        "S\\'ebastien Pereira",
        "Sean Ammirati",
        "Phillip Lippe",
        "Adam Kraft",
        "Pu Han",
        "Sebastian Gerlach",
        "Zifeng Wang",
        "Liviu Panait",
        "Feng Han",
        "Brian Farris",
        "Yingying Bi",
        "Hannah DeBalsi",
        "Miaosen Wang",
        "Gladys Tyen",
        "James Cohan",
        "Susan Zhang",
        "Jarred Barber",
        "Da-Woon Chung",
        "Jaeyoun Kim",
        "Markus Kunesch",
        "Steven Pecht",
        "Nami Akazawa",
        "Abe Friesen",
        "James Lyon",
        "Ali Eslami",
        "Junru Wu",
        "Jie Tan",
        "Yue Song",
        "Ravi Kumar",
        "Chris Welty",
        "Ilia Akolzin",
        "Gena Gibson",
        "Sean Augenstein",
        "Arjun Pillai",
        "Nancy Yuen",
        "Du Phan",
        "Xin Wang",
        "Iain Barr",
        "Heiga Zen",
        "Nan Hua",
        "Casper Liu",
        "Jilei (Jerry) Wang",
        "Tanuj Bhatia",
        "Hao Xu",
        "Oded Elyada",
        "Pushmeet Kohli",
        "Mirek Ol\\v{s}\\'ak",
        "Ke Chen",
        "Azalia Mirhoseini",
        "Noam Shazeer",
        "Shoshana Jakobovits",
        "Maggie Tran",
        "Nolan Ramsden",
        "Tarun Bharti",
        "Fred Alcober",
        "Yunjie Li",
        "Shilpa Shetty",
        "Jing Chen",
        "Dmitry Kalashnikov",
        "Megha Nawhal",
        "Sercan Arik",
        "Hanwen Chen",
        "Michiel Blokzijl",
        "Shubham Gupta",
        "James Rubin",
        "Rigel Swavely",
        "Sophie Bridgers",
        "Ian Gemp",
        "Chen Su",
        "Arun Suggala",
        "Juliette Pluto",
        "Mary Cassin",
        "Alain Vaucher",
        "Kaiyang Ji",
        "Jiahao Cai",
        "Andrew Audibert",
        "Animesh Sinha",
        "David Tian",
        "Efrat Farkash",
        "Amy Hua",
        "Jilin Chen",
        "Duc-Hieu Tran",
        "Edward Loper",
        "Nicole Brichtova",
        "Lara McConnaughey",
        "Ballie Sandhu",
        "Robert Leland",
        "Doug DeCarlo",
        "Andrew Over",
        "James Huang",
        "Xing Wu",
        "Connie Fan",
        "Eric Li",
        "Yun Lei",
        "Deepak Sharma",
        "Cosmin Paduraru",
        "Luo Yu",
        "Matko Bo\\v{s}njak",
        "Phuong Dao",
        "Min Choi",
        "Sneha Kudugunta",
        "Jakub Adamek",
        "Carlos Gu\\'ia",
        "Ali Khodaei",
        "Jie Feng",
        "Wenjun Zeng",
        "David Welling",
        "Sandeep Tata",
        "Christina Butterfield",
        "Andrey Vlasov",
        "Seliem El-Sayed",
        "Swaroop Mishra",
        "Tara Sainath",
        "Shentao Yang",
        "RJ Skerry-Ryan",
        "Jeremy Shar",
        "Robert Berry",
        "Arunkumar Rajendran",
        "Arun Kandoor",
        "Andrea Burns",
        "Deepali Jain",
        "Tom Stone",
        "Wonpyo Park",
        "Shibo Wang",
        "Albin Cassirer",
        "Guohui Wang",
        "Hayato Kobayashi",
        "Sergey Rogulenko",
        "Vineetha Govindaraj",
        "Miko{\\l}aj Rybi\\'nski",
        "Nadav Olmert",
        "Colin Evans",
        "Po-Sen Huang",
        "Kelvin Xu",
        "Premal Shah",
        "Terry Thurk",
        "Caitlin Sikora",
        "Mu Cai",
        "Jin Xie",
        "Elahe Dabir",
        "Saloni Shah",
        "Norbert Kalb",
        "Carrie Zhang",
        "Shruthi Prabhakara",
        "Amit Sabne",
        "Artiom Myaskovsky",
        "Vikas Raunak",
        "Blanca Huergo",
        "Behnam Neyshabur",
        "Jon Clark",
        "Ye Zhang",
        "Shankar Krishnan",
        "Eden Cohen",
        "Dinesh Tewari",
        "James Lottes",
        "Yumeya Yamamori",
        "Hui (Elena) Li",
        "Mohamed Elhawaty",
        "Ada Maksutaj Oflazer",
        "Adri\\`a Recasens",
        "Sheryl Luo",
        "Duy Nguyen",
        "Taylor Bos",
        "Kalyan Andra",
        "Ana Salazar",
        "Ed Chi",
        "Jeongwoo Ko",
        "Matt Ginsberg",
        "Anders Andreassen",
        "Anian Ruoss",
        "Todor Davchev",
        "Elnaz Davoodi",
        "Chenxi Liu",
        "Min Kim",
        "Santiago Ontanon",
        "Chi Ming To",
        "Dawei Jia",
        "Rosemary Ke",
        "Jing Wang",
        "Anna Korsun",
        "Moran Ambar",
        "Ilya Kornakov",
        "Irene Giannoumis",
        "Toni Creswell",
        "Denny Zhou",
        "Yi Su",
        "Ishaan Watts",
        "Aleksandr Zaks",
        "Evgenii Eltyshev",
        "Ziqiang Feng",
        "Sidharth Mudgal",
        "Alex Kaskasoli",
        "Juliette Love",
        "Kingshuk Dasgupta",
        "Sam Shleifer",
        "Richard Green",
        "Sungyong Seo",
        "Chansoo Lee",
        "Dale Webster",
        "Prakash Shroff",
        "Ganna Raboshchuk",
        "Isabel Leal",
        "James Manyika",
        "Sofia Erell",
        "Daniel Murphy",
        "Zhisheng Xiao",
        "Anton Bulyenov",
        "Julian Walker",
        "Mark Collier",
        "Matej Kastelic",
        "Nelson George",
        "Sushant Prakash",
        "Sailesh Sidhwani",
        "Alexey Frolov",
        "Steven Hansen",
        "Petko Georgiev",
        "Tiberiu Sosea",
        "Chris Apps",
        "Aishwarya Kamath",
        "David Reid",
        "Emma Cooney",
        "Charlotte Magister",
        "Oriana Riva",
        "Alec Go",
        "Pu-Chin Chen",
        "Sebastian Krause",
        "Nir Levine",
        "Marco Fornoni",
        "Ilya Figotin",
        "Nick Roy",
        "Parsa Mahmoudieh",
        "Vladimir Magay",
        "Mukundan Madhavan",
        "Jin Miao",
        "Jianmo Ni",
        "Yasuhisa Fujii",
        "Ian Chou",
        "George Scrivener",
        "Zak Tsai",
        "Siobhan Mcloughlin",
        "Jeremy Selier",
        "Sandra Lefdal",
        "Jeffrey Zhao",
        "Abhijit Karmarkar",
        "Kushal Chauhan",
        "Shivanker Goel",
        "Zhaoyi Zhang",
        "Vihan Jain",
        "Parisa Haghani",
        "Mostafa Dehghani",
        "Jacob Scott",
        "Erin Farnese",
        "Anastasija Ili\\'c",
        "Steven Baker",
        "Julia Pawar",
        "Li Zhong",
        "Josh Camp",
        "Yoel Zeldes",
        "Shravya Shetty",
        "Anand Iyer",
        "V\\'it List\\'ik",
        "Jiaxian Guo",
        "Luming Tang",
        "Mark Geller",
        "Simon Bucher",
        "Yifan Ding",
        "Hongzhi Shi",
        "Carrie Muir",
        "Dominik Grewe",
        "Ramy Eskander",
        "Octavio Ponce",
        "Boqing Gong",
        "Derek Gasaway",
        "Samira Khan",
        "Umang Gupta",
        "Angelos Filos",
        "Weicheng Kuo",
        "Klemen Kloboves",
        "Jennifer Beattie",
        "Christian Wright",
        "Leon Li",
        "Alicia Jin",
        "Sandeep Mariserla",
        "Miteyan Patel",
        "Jens Heitkaemper",
        "Dilip Krishnan",
        "Vivek Sharma",
        "David Bieber",
        "Christian Frank",
        "John Lambert",
        "Paul Caron",
        "Martin Polacek",
        "Mai Gim\\'enez",
        "Himadri Choudhury",
        "Xing Yu",
        "Sasan Tavakkol",
        "Arun Ahuja",
        "Franz Och",
        "Rodolphe Jenatton",
        "Wojtek Skut",
        "Bryan Richter",
        "David Gaddy",
        "Andy Ly",
        "Misha Bilenko",
        "Megh Umekar",
        "Ethan Liang",
        "Martin Sevenich",
        "Mandar Joshi",
        "Hassan Mansoor",
        "Rebecca Lin",
        "Sumit Sanghai",
        "Abhimanyu Singh",
        "Xiaowei Li",
        "Sudheendra Vijayanarasimhan",
        "Zaheer Abbas",
        "Yonatan Bitton",
        "Hansa Srinivasan",
        "Manish Reddy Vuyyuru",
        "Alexander Fr\\\"ommgen",
        "Yanhua Sun",
        "Ralph Leith",
        "Alfonso Casta\\~no",
        "DJ Strouse",
        "Le Yan",
        "Austin Kyker",
        "Satish Kambala",
        "Mary Jasarevic",
        "Thibault Sellam",
        "Chao Jia",
        "Alexander Pritzel",
        "Raghavender R",
        "Huizhong Chen",
        "Natalie Clay",
        "Sudeep Gandhe",
        "Sean Kirmani",
        "Sayna Ebrahimi",
        "Hannah Kirkwood",
        "Jonathan Mallinson",
        "Chao Wang",
        "Adnan Ozturel",
        "Kuo Lin",
        "Shyam Upadhyay",
        "Vincent Cohen-Addad",
        "Sean Purser-haskell",
        "Yichong Xu",
        "Ebrahim Songhori",
        "Babi Seal",
        "Alberto Magni",
        "Almog Gueta",
        "Tingting Zou",
        "Guru Guruganesh",
        "Thais Kagohara",
        "Hung Nguyen",
        "Khalid Salama",
        "Alejandro Cruzado Ruiz",
        "Justin Frye",
        "Zhenkai Zhu",
        "Matthias Lochbrunner",
        "Simon Osindero",
        "Wentao Yuan",
        "Lisa Lee",
        "Aman Prasad",
        "Lam Nguyen Thiet",
        "Daniele Calandriello",
        "Victor Stone",
        "Qixuan Feng",
        "Han Ke",
        "Maria Voitovich",
        "Geta Sampemane",
        "Lewis Chiang",
        "Ling Wu",
        "Alexander Bykovsky",
        "Matt Young",
        "Luke Vilnis",
        "Ishita Dasgupta",
        "Aditya Chawla",
        "Qin Cao",
        "Bowen Liang",
        "Daniel Toyama",
        "Szabolcs Payrits",
        "Anca Stefanoiu",
        "Dimitrios Vytiniotis",
        "Ankesh Anand",
        "Tianxiao Shen",
        "Blagoj Mitrevski",
        "Michael Tschannen",
        "Sreenivas Gollapudi",
        "Aishwarya P S",
        "Jos\\'e Leal",
        "Zhe Shen",
        "Han Fu",
        "Wei Wang",
        "Arvind Kannan",
        "Doron Kukliansky",
        "Sergey Yaroshenko",
        "Svetlana Grant",
        "Umesh Telang",
        "David Wood",
        "Alexandra Chronopoulou",
        "Alexandru \\c{T}ifrea",
        "Tao Zhou",
        "Tony (Tu\\'\\^an) Nguy\\~\\^en",
        "Muge Ersoy",
        "Anima Singh",
        "Meiyan Xie",
        "Emanuel Taropa",
        "Woohyun Han",
        "Eirikur Agustsson",
        "Andrei Sozanschi",
        "Hui Peng",
        "Alex Chen",
        "Yoel Drori",
        "Efren Robles",
        "Yang Gao",
        "Xerxes Dotiwalla",
        "Ying Chen",
        "Anudhyan Boral",
        "Alexei Bendebury",
        "John Nham",
        "Chris Tar",
        "Luis Castro",
        "Jiepu Jiang",
        "Canoee Liu",
        "Felix Halim",
        "Jinoo Baek",
        "Andy Wan",
        "Jeremiah Liu",
        "Yuan Cao",
        "Shengyang Dai",
        "Trilok Acharya",
        "Ruoxi Sun",
        "Fuzhao Xue",
        "Saket Joshi",
        "Morgane Lustman",
        "Yongqin Xian",
        "Rishabh Joshi",
        "Deep Karkhanis",
        "Nora Kassner",
        "Jamie Hall",
        "Xiangzhuo Ding",
        "Gan Song",
        "Gang Li",
        "Chen Zhu",
        "Yana Kulizhskaya",
        "Bin Ni",
        "Alexey Vlaskin",
        "Solomon Demmessie",
        "Lucio Dery",
        "Salah Zaiem",
        "Yanping Huang",
        "Cindy Fan",
        "Felix Gimeno",
        "Ananth Balashankar",
        "Koji Kojima",
        "Hagai Taitelbaum",
        "Maya Meng",
        "Dero Gharibian",
        "Sahil Singla",
        "Wei Chen",
        "Ambrose Slone",
        "Guanjie Chen",
        "Sujee Rajayogam",
        "Max Schumacher",
        "Suyog Kotecha",
        "Rory Blevins",
        "Qifei Wang",
        "Mor Hazan Taege",
        "Alex Morris",
        "Xin Liu",
        "Fayaz Jamil",
        "Richard Zhang",
        "Pratik Joshi",
        "Ben Ingram",
        "Tyler Liechty",
        "Ahmed Eleryan",
        "Scott Baird",
        "Alex Grills",
        "Gagan Bansal",
        "Shan Han",
        "Kiran Yalasangi",
        "Shawn Xu",
        "Majd Al Merey",
        "Isabel Gao",
        "Felix Weissenberger",
        "Igor Karpov",
        "Robert Riachi",
        "Ankit Anand",
        "Gautam Prasad",
        "Kay Lamerigts",
        "Reid Hayes",
        "Jamie Rogers",
        "Mandy Guo",
        "Ashish Shenoy",
        "Qiong (Q) Hu",
        "Kyle He",
        "Yuchen Liu",
        "Polina Zablotskaia",
        "Sagar Gubbi",
        "Yifan Chang",
        "Jay Pavagadhi",
        "Kristian Kjems",
        "Archita Vadali",
        "Diego Machado",
        "Yeqing Li",
        "Renshen Wang",
        "Dipankar Ghosh",
        "Aahil Mehta",
        "Dana Alon",
        "George Polovets",
        "Alessio Tonioni",
        "Nate Kushman",
        "Joel D'sa",
        "Lin Zhuo",
        "Allen Wu",
        "Rohin Shah",
        "John Youssef",
        "Jiayu Ye",
        "Justin Snyder",
        "Karel Lenc",
        "Senaka Buthpitiya",
        "Matthew Tung",
        "Jichuan Chang",
        "Tao Chen",
        "David Saxton",
        "Jenny Lee",
        "Lydia Lihui Zhang",
        "James Qin",
        "Prabakar Radhakrishnan",
        "Maxwell Chen",
        "Piotr Ambroszczyk",
        "Metin Toksoz-Exley",
        "Yan Zhong",
        "Nitzan Katz",
        "Brendan O'Donoghue",
        "Tamara von Glehn",
        "Adi Gerzi Rosenthal",
        "Aga \\'Swietlik",
        "Xiaokai Zhao",
        "Nick Fernando",
        "Jinliang Wei",
        "Jieru Mei",
        "Sergei Vassilvitskii",
        "Diego Cedillo",
        "Pranjal Awasthi",
        "Hui Zheng",
        "Koray Kavukcuoglu",
        "Itay Laish",
        "Joseph Pagadora",
        "Marc Brockschmidt",
        "Christopher A. Choquette-Choo",
        "Arunkumar Byravan",
        "Yifeng Lu",
        "Xu Chen",
        "Mia Chen",
        "Kenton Lee",
        "Rama Pasumarthi",
        "Sijal Bhatnagar",
        "Aditya Shah",
        "Qiyin Wu",
        "Zhuoyuan Chen",
        "Zack Nado",
        "Bartek Perz",
        "Zixuan Jiang",
        "David Kao",
        "Ganesh Mallya",
        "Nino Vieillard",
        "Lantao Mei",
        "Sertan Girgin",
        "Mandy Jordan",
        "Yeongil Ko",
        "Alekh Agarwal",
        "Yaxin Liu",
        "Yasemin Altun",
        "Raoul de Liedekerke",
        "Anastasios Kementsietsidis",
        "Daiyi Peng",
        "Dangyi Liu",
        "Utku Evci",
        "Peter Humphreys",
        "Austin Tarango",
        "Xiang Deng",
        "Yoad Lewenberg",
        "Kevin Aydin",
        "Chengda Wu",
        "Bhavishya Mittal",
        "Tsendsuren Munkhdalai",
        "Kleopatra Chatziprimou",
        "Rodrigo Benenson",
        "Uri First",
        "Xiao Ma",
        "Jinning Li",
        "Armand Joulin",
        "Hamish Tomlinson",
        "Tingnan Zhang",
        "Milad Nasr",
        "Zhi Hong",
        "Micha\\\"el Sander",
        "Lisa Anne Hendricks",
        "Anuj Sharma",
        "Andrew Bolt",
        "Eszter V\\'ertes",
        "Jiri Simsa",
        "Tomer Levinboim",
        "Olcan Sercinoglu",
        "Divyansh Shukla",
        "Austin Wu",
        "Craig Swanson",
        "Danny Vainstein",
        "Fan Bu",
        "Bo Wang",
        "Ryan Julian",
        "Charles Yoon",
        "Sergei Lebedev",
        "Antonious Girgis",
        "Bernd Bandemer",
        "David Du",
        "Todd Wang",
        "Xi Chen",
        "Ying Xiao",
        "Peggy Lu",
        "Natalie Ha",
        "Vlad Ionescu",
        "Simon Rowe",
        "Josip Matak",
        "Federico Lebron",
        "Andreas Steiner",
        "Lalit Jain",
        "Manaal Faruqui",
        "Nicolas Lacasse",
        "Georgie Evans",
        "Neesha Subramaniam",
        "Dean Reich",
        "Giulia Vezzani",
        "Aditya Pandey",
        "Joe Stanton",
        "Tianhao Zhou",
        "Liam McCafferty",
        "Henry Griffiths",
        "Verena Rieser",
        "Soheil Hassas Yeganeh",
        "Eleftheria Briakou",
        "Lu Huang",
        "Zichuan Wei",
        "Liangchen Luo",
        "Erik Jue",
        "Gabby Wang",
        "Victor Cotruta",
        "Myriam Khan",
        "Jongbin Park",
        "Qiuchen Guo",
        "Peiran Li",
        "Rong Rong",
        "Diego Antognini",
        "Anastasia Petrushkina",
        "Chetan Tekur",
        "Eli Collins",
        "Parul Bhatia",
        "Chester Kwak",
        "Wenhu Chen",
        "Arvind Neelakantan",
        "Immanuel Odisho",
        "Sheng Peng",
        "Vincent Nallatamby",
        "Vaibhav Tulsyan",
        "Fabian Pedregosa",
        "Peng Xu",
        "Raymond Lin",
        "Yulong Wang",
        "Emma Wang",
        "Sholto Douglas",
        "Reut Tsarfaty",
        "Elena Gribovskaya",
        "Renga Aravamudhan",
        "Manu Agarwal",
        "Mara Finkelstein",
        "Qiao Zhang",
        "Elizabeth Cole",
        "Phil Crone",
        "Sarmishta Velury",
        "Anil Das",
        "Chris Sauer",
        "Luyao Xu",
        "Danfeng Qin",
        "Chenjie Gu",
        "Dror Marcus",
        "CJ Zheng",
        "Wouter Van Gansbeke",
        "Sobhan Miryoosefi",
        "Haitian Sun",
        "YaGuang Li",
        "Charlie Chen",
        "Jae Yoo",
        "Pavel Dubov",
        "Alex Tomala",
        "Adams Yu",
        "Pawe{\\l} Weso{\\l}owski",
        "Alok Gunjan",
        "Eddie Cao",
        "Jiaming Luo",
        "Nikhil Sethi",
        "Arkadiusz Socala",
        "Laura Graesser",
        "Tomas Kocisky",
        "Arturo BC",
        "Minmin Chen",
        "Edward Lee",
        "Sophie Wang",
        "Weize Kong",
        "Qiantong Xu",
        "Nilesh Tripuraneni",
        "Yiming Li",
        "Xinxin Yu",
        "Allen Porter",
        "Paul Voigtlaender",
        "Biao Zhang",
        "Arpi Vezer",
        "Sarah York",
        "Qing Wei",
        "Geoffrey Cideron",
        "Mark Kurzeja",
        "Seungyeon Kim",
        "Benny Li",
        "Ang\\'eline Pouget",
        "Hyo Lee",
        "Kaspar Daugaard",
        "Yang Li",
        "Dave Uthus",
        "Aditya Siddhant",
        "Paul Cavallaro",
        "Sriram Ganapathy",
        "Maulik Shah",
        "Rolf Jagerman",
        "Jeff Stanway",
        "Piermaria Mendolicchio",
        "Li Xiao",
        "Kayi Lee",
        "Tara Thompson",
        "Shubham Milind Phal",
        "Jason Chase",
        "Sun Jae Lee",
        "Adrian N Reyes",
        "Disha Shrivastava",
        "Zhen Qin",
        "Roykrong Sukkerd",
        "Seth Odoom",
        "Lior Madmoni",
        "John Aslanides",
        "Jonathan Herzig",
        "Elena Pochernina",
        "Sheng Zhang",
        "Parker Barnes",
        "Daisuke Ikeda",
        "Qiujia Li",
        "Shuo-yiin Chang",
        "Shakir Mohamed",
        "Jim Sproch",
        "Richard Powell",
        "Bidisha Samanta",
        "Domagoj \\'Cevid",
        "Anton Kovsharov",
        "Shrestha Basu Mallick",
        "Srinivas Tadepalli",
        "Anne Zheng",
        "Kareem Ayoub",
        "Andreas Noever",
        "Christian Reisswig",
        "Zhuo Xu",
        "Junhyuk Oh",
        "Martin Matysiak",
        "Tim Blyth",
        "Shereen Ashraf",
        "Julien Amelot",
        "Boone Severson",
        "Michele Bevilacqua",
        "Motoki Sano",
        "Ethan Dyer",
        "Ofir Roval",
        "Anu Sinha",
        "Yin Zhong",
        "Sagi Perel",
        "Tea Saboli\\'c",
        "Johannes Mauerer",
        "Willi Gierke",
        "Mauro Verzetti",
        "Rodrigo Cabrera",
        "Alvin Abdagic",
        "Steven Hemingray",
        "Austin Stone",
        "Jong Lee",
        "Farooq Ahmad",
        "Karthik Raman",
        "Lior Shani",
        "Jonathan Lai",
        "Orhan Firat",
        "Nathan Waters",
        "Eric Ge",
        "Mo Shomrat",
        "Himanshu Gupta",
        "Rajeev Aggarwal",
        "Tom Hudson",
        "Bill Jia",
        "Simon Baumgartner",
        "Palak Jain",
        "Joe Kovac",
        "Junehyuk Jung",
        "Ante \\v{Z}u\\v{z}ul",
        "Will Truong",
        "Morteza Zadimoghaddam",
        "Songyou Peng",
        "Marco Liang",
        "Rachel Sterneck",
        "Balaji Lakshminarayanan",
        "Machel Reid",
        "Oliver Woodman",
        "Tong Zhou",
        "Jianling Wang",
        "Vincent Coriou",
        "Arjun Narayanan",
        "Jay Hoover",
        "Yenai Ma",
        "Apoorv Jindal",
        "Clayton Sanford",
        "Doug Reid",
        "Swaroop Ramaswamy",
        "Alex Kurakin",
        "Roland Zimmermann",
        "Yana Lunts",
        "Dragos Dena",
        "Zal\\'an Borsos",
        "Vered Cohen",
        "Shujian Zhang",
        "Will Grathwohl",
        "Robert Dadashi",
        "Morgan Redshaw",
        "Joshua Kessinger",
        "Julian Odell",
        "Silvano Bonacina",
        "Zihang Dai",
        "Grace Chen",
        "Ayush Dubey",
        "Pablo Sprechmann",
        "Mantas Pajarskas",
        "Wenxuan Zhou",
        "Niharika Ahuja",
        "Tara Thomas",
        "Martin Nikoltchev",
        "Matija Kecman",
        "Bharath Mankalale",
        "Andrey Ryabtsev",
        "Jennifer She",
        "Christian Walder",
        "Jiaming Shen",
        "Lu Li",
        "Carolina Parada",
        "Sheena Panthaplackel",
        "Okwan Kwon",
        "Matt Lawlor",
        "Utsav Prabhu",
        "Yannick Schroecker",
        "Marc'aurelio Ranzato",
        "Pete Blois",
        "Iurii Kemaev",
        "Ting Yu",
        "Dmitry Lepikhin",
        "Hao Xiong",
        "Sahand Sharifzadeh",
        "Oleaser Johnson",
        "Jeremiah Willcock",
        "Rui Yao",
        "Greg Farquhar",
        "Sujoy Basu",
        "Hidetoshi Shimokawa",
        "Nina Anderson",
        "Haiguang Li",
        "Khiem Pham",
        "Yizhong Liang",
        "Sebastian Borgeaud",
        "Alexandre Moufarek",
        "Hideto Kazawa",
        "Blair Kutzman",
        "Marcin Sieniek",
        "Sara Smoot",
        "Ruth Wang",
        "Natalie Axelsson",
        "Nova Fallen",
        "Prasha Sundaram",
        "Yuexiang Zhai",
        "Varun Godbole",
        "Petros Maniatis",
        "Alek Wang",
        "Ilia Shumailov",
        "Santhosh Thangaraj",
        "Remi Crocker",
        "Nikita Gupta",
        "Gang Wu",
        "Phil Chen",
        "Gell\\'ert Weisz",
        "Celine Smith",
        "Mojtaba Seyedhosseini",
        "Boya Fang",
        "Xiyang Luo",
        "Roey Yogev",
        "Zeynep Cankara",
        "Andrew Hard",
        "Helen Ran",
        "Rahul Sukthankar",
        "George Necula",
        "Ga\\\"el Liu",
        "Honglong Cai",
        "Praseem Banzal",
        "Daniel Keysers",
        "Sanjay Ghemawat",
        "Connie Tao",
        "Emma Dunleavy",
        "Aditi Chaudhary",
        "Wei Li",
        "Maciej Miku{\\l}a",
        "Chen-Yu Lee",
        "Tiziana Refice",
        "Krishna Somandepalli",
        "Alexandre Fr\\'echette",
        "Dan Bahir",
        "John Karro",
        "Keith Rush",
        "Sarah Perrin",
        "Bill Rosgen",
        "Xiaomeng Yang",
        "Clara Huiyi Hu",
        "Mahmoud Alnahlawi",
        "Justin Mao-Jones",
        "Roopal Garg",
        "Hoang Nguyen",
        "Bat-Orgil Batsaikhan",
        "I\\~naki Iturrate",
        "Anselm Levskaya",
        "Avi Singh",
        "Ashyana Kachra",
        "Tony Lu",
        "Denis Petek",
        "Zheng Xu",
        "Mark Graham",
        "Lukas Zilka",
        "Yael Karov",
        "Marija Kostelac",
        "Fangyu Liu",
        "Yaohui Guo",
        "Weiyue Wang",
        "Bernd Bohnet",
        "Emily Pitler",
        "Tony Bruguier",
        "Keisuke Kinoshita",
        "Chrysovalantis Anastasiou",
        "Nilpa Jha",
        "Ting Liu",
        "Jerome Connor",
        "Phil Wallis",
        "Philip Pham",
        "Eric Bailey",
        "Shixin Li",
        "Heng-Tze Cheng",
        "Sally Ma",
        "Haiqiong Li",
        "Akanksha Maurya",
        "Kate Olszewska",
        "Manfred Warmuth",
        "Christy Koh",
        "Dominik Paulus",
        "Siddhartha Reddy Jonnalagadda",
        "Enrique Piqueras",
        "Ali Elqursh",
        "Geoff Brown",
        "Hadar Shemtov",
        "Loren Maggiore",
        "Fei Xia",
        "Ryan Foley",
        "Beka Westberg",
        "George van den Driessche",
        "Livio Baldini Soares",
        "Arjun Kar",
        "Michael Quinn",
        "Siqi Zuo",
        "Jialin Wu",
        "Kyle Kastner",
        "Anna Bortsova",
        "Aijun Bai",
        "Ales Mikhalap",
        "Luowei Zhou",
        "Jennifer Brennan",
        "Vinay Ramasesh",
        "Honglei Zhuang",
        "John Maggs",
        "Johan Schalkwyk",
        "Yuntao Xu",
        "Hui Huang",
        "Andrew Howard",
        "Sasha Brown",
        "Linting Xue",
        "Gloria Shen",
        "Brian Albert",
        "Neha Jha",
        "Daniel Zheng",
        "Varvara Krayvanova",
        "Spurthi Amba Hombaiah",
        "Olivier Lacombe",
        "Gautam Vasudevan",
        "Dan Graur",
        "Tian Xie",
        "Meet Gandhi",
        "Bangju Wang",
        "Dustin Zelle",
        "Harman Singh",
        "Dahun Kim",
        "S\\'ebastien Cevey",
        "Victor Ungureanu",
        "Natasha Noy",
        "Fei Liu",
        "Annie Xie",
        "Fangxiaoyu Feng",
        "Katerina Tsihlas",
        "Daniel Formoso",
        "Neera Vats",
        "Quentin Wellens",
        "Yinan Wang",
        "Niket Kumar Bhumihar",
        "Samrat Ghosh",
        "Matt Hoffman",
        "Tom Lieber",
        "Oran Lang",
        "Kush Bhatia",
        "Tom Paine",
        "Aroonalok Pyne",
        "Ronny Votel",
        "Madeleine Clare Elish",
        "Benoit Schillings",
        "Alex Panagopoulos",
        "Haichuan Yang",
        "Adam Raveret",
        "Zohar Yahav",
        "Shuang Liu",
        "Dalia El Badawy",
        "Nishant Agrawal",
        "Mohammed Badawi",
        "Mahdi Mirzazadeh",
        "Carla Bromberg",
        "Fan Ye",
        "Chang Liu",
        "Tatiana Sholokhova",
        "George-Cristian Muraru",
        "Gargi Balasubramaniam",
        "Jonathan Malmaud",
        "Alen Carin",
        "Danilo Martins",
        "Irina Jurenka",
        "Pankil Botadra",
        "Dave Lacey",
        "Richa Singh",
        "Mariano Schain",
        "Dan Zheng",
        "Isabelle Guyon",
        "Victor Lavrenko",
        "Seungji Lee",
        "Xiang Zhou",
        "Demis Hassabis",
        "Jeshwanth Challagundla",
        "Derek Cheng",
        "Nikhil Mehta",
        "Matthew Mauger",
        "Michela Paganini",
        "Pushkar Mishra",
        "Kate Lee",
        "Zhang Li",
        "Lexi Baugher",
        "Ondrej Skopek",
        "Max Chang",
        "Amir Zait",
        "Gaurav Menghani",
        "Lizzetth Bellot",
        "Guangxing Han",
        "Jean-Michel Sarr",
        "Sharat Chikkerur",
        "Himanshu Sahni",
        "Rohan Anil",
        "Arun Narayanan",
        "Chandu Thekkath",
        "Daniele Pighin",
        "Hana Strej\\v{c}ek",
        "Marko Velic",
        "Fred Bertsch",
        "Manuel Tragut",
        "Keran Rong",
        "Alicia Parrish",
        "Kai Bailey",
        "Jiho Park",
        "Isabela Albuquerque",
        "Abhishek Bapna",
        "Rajesh Venkataraman",
        "Alec Kosik",
        "Johannes Griesser",
        "Zhiwei Deng",
        "Alek Andreev",
        "Qingyun Dou",
        "Kevin Hui",
        "Fanny Wei",
        "Xiaobin Yu",
        "Lei Shu",
        "Avia Aharon",
        "David Barker",
        "Badih Ghazi",
        "Sebastian Flennerhag",
        "Chris Breaux",
        "Yuchuan Liu",
        "Matthew Bilotti",
        "Josh Woodward",
        "Uri Alon",
        "Stephanie Winkler",
        "Tzu-Kuo Huang",
        "Kostas Andriopoulos",
        "Jo\\~ao Gabriel Oliveira",
        "Penporn Koanantakool",
        "Berkin Akin",
        "Michael Wunder",
        "Cicero Nogueira dos Santos",
        "Mohammad Hossein Bateni",
        "Lin Yang",
        "Dan Horgan",
        "Beer Changpinyo",
        "Keyvan Amiri",
        "Min Ma",
        "Dayeong Lee",
        "Lihao Liang",
        "Anirudh Baddepudi",
        "Tejasi Latkar",
        "Raia Hadsell",
        "Jun Xu",
        "Hairong Mu",
        "Michael Han",
        "Aedan Pope",
        "Snchit Grover",
        "Frank Kim",
        "Ankit Bhagatwala",
        "Guan Sun",
        "Yamini Bansal",
        "Amir Globerson",
        "Alireza Nazari",
        "Samira Daruki",
        "Hagen Soltau",
        "Jane Labanowski",
        "Laurent El Shafey",
        "Matt Harvey",
        "Yanif Ahmad",
        "Elan Rosenfeld",
        "William Kong",
        "Etienne Pot",
        "Yi-Xuan Tan",
        "Aurora Wei",
        "Victoria Langston",
        "Marcel Prasetya",
        "Petar Veli\\v{c}kovi\\'c",
        "Richard Killam",
        "Robin Strudel",
        "Darren Ni",
        "Zhenhai Zhu",
        "Aaron Archer",
        "Kavya Kopparapu",
        "Lynn Nguyen",
        "Emilio Parisotto",
        "Hussain Masoom",
        "Sravanti Addepalli",
        "Jordan Grimstad",
        "Hexiang Hu",
        "Joss Moore",
        "Avinatan Hassidim",
        "Le Hou",
        "Mukund Raghavachari",
        "Jared Lichtarge",
        "Adam R. Brown",
        "Hilal Dib",
        "Natalia Ponomareva",
        "Justin Fu",
        "Yujing Zhang",
        "Altaf Rahman",
        "Joana Iljazi",
        "Edouard Leurent",
        "Gabriel Dulac-Arnold",
        "Cosmo Du",
        "Chulayuth Asawaroengchai",
        "Larry Jin",
        "Ela Gruzewska",
        "Ziwei Ji",
        "Benigno Uria",
        "Daniel De Freitas",
        "Paul Barham",
        "Lauren Beltrone",
        "V\\'ictor Campos",
        "Jun Yan",
        "Neel Kovelamudi",
        "Arthur Nguyen",
        "Elinor Davies",
        "Zhichun Wu",
        "Zoltan Egyed",
        "Kristina Toutanova",
        "Nithya Attaluri",
        "Hongliang Fei",
        "Peter Stys",
        "Siddhartha Brahma",
        "Martin Izzard",
        "Siva Velusamy",
        "Scott Lundberg",
        "Vincent Zhuang",
        "Kevin Sequeira",
        "Adam Santoro",
        "Ehsan Amid",
        "Ophir Aharoni",
        "Shuai Ye",
        "Mukund Sundararajan",
        "Lijun Yu",
        "Yu-Cheng Ling",
        "Stephen Spencer",
        "Hugo Song",
        "Josip Djolonga",
        "Christo Kirov",
        "Sonal Gupta",
        "Alessandro Bissacco",
        "Clemens Meyer",
        "Mukul Bhutani",
        "Andrew Dai",
        "Weiyi Wang",
        "Siqi Liu",
        "Ashwin Sreevatsa",
        "Qijun Tan",
        "Maria Wang",
        "Lucy Kim",
        "Yicheng Wang",
        "Alex Irpan",
        "Yang Xiao",
        "Stanislav Fort",
        "Yifan He",
        "Alex Gurney",
        "Bryan Gale",
        "Yue Ma",
        "Monica Roy",
        "Viorica Patraucean",
        "Taylan Bilal",
        "Golnaz Ghiasi",
        "Anahita Hosseini",
        "Melvin Johnson",
        "Zhuowan Li",
        "Yi Tay",
        "Benjamin Beyret",
        "Katie Millican",
        "Josef Broder",
        "Mayank Lunayach",
        "Danny Swisher",
        "Eugen Vu\\v{s}ak",
        "David Parkinson",
        "MH Tessler",
        "Adi Mayrav Gilady",
        "Richard Song",
        "Allan Dafoe",
        "Yves Raimond",
        "Masa Yamaguchi",
        "Itay Karo",
        "Elizabeth Nielsen",
        "Kevin Kilgour",
        "Mike Dusenberry",
        "Rajiv Mathews",
        "Jiho Choi",
        "Siyuan Qiao",
        "Harsh Mehta",
        "Sahitya Potluri",
        "Chris Knutsen",
        "Jialu Liu",
        "Tat Tan",
        "Kuntal Sengupta",
        "Keerthana Gopalakrishnan",
        "Abodunrinwa Toki",
        "Mencher Chiang",
        "Mike Burrows",
        "Grace Vesom",
        "Zafarali Ahmed",
        "Ilia Labzovsky",
        "Siddharth Vashishtha",
        "Preeti Singh",
        "Ankur Sharma",
        "Ada Ma",
        "Jinyu Xie",
        "Pranav Talluri",
        "Hannah Forbes-Pollard",
        "Aarush Selvan",
        "Joel Wee",
        "Loic Matthey",
        "Tom Funkhouser",
        "Parthasarathy Gopavarapu",
        "Lev Proleev",
        "Cheng Li",
        "Matt Thomas",
        "Kashyap Kolipaka",
        "Zhipeng Jia",
        "Ashwin Kakarla",
        "Srinivas Sunkara",
        "Joan Puigcerver",
        "Suraj Satishkumar Sheth",
        "Emily Graves",
        "Chen Wang",
        "Sadh MNM Khan",
        "Kai Kang",
        "Shyamal Buch",
        "Fred Zhang",
        "Omkar Savant",
        "David Soergel",
        "Kevin Lee",
        "Linda Friso",
        "Xuanyi Dong",
        "Rahul Arya",
        "Shreyas Chandrakaladharan",
        "Connor Schenck",
        "Greg Billock",
        "Tejas Iyer",
        "Anton Bakalov",
        "Leslie Baker",
        "Alex Ruiz",
        "Angad Chandorkar",
        "Trieu Trinh",
        "Matt Miecnikowski",
        "Yanqi Zhou",
        "Yangsibo Huang",
        "Jiazhong Nie",
        "Ali Shah",
        "Ashish Thapliyal",
        "Sam Haves",
        "Lun Wang",
        "Uri Shaham",
        "Patrick Morris-Suzuki",
        "Soroush Radpour",
        "Leonard Berrada",
        "Thomas Strohmann",
        "Chaochao Yan",
        "Jingwei Shen",
        "Sonam Goenka",
        "Tris Warkentin",
        "Petar Devi\\'c",
        "Dan Belov",
        "Albert Webson",
        "Madhavi Yenugula",
        "Puranjay Datta",
        "Jerry Chang",
        "Nimesh Ghelani",
        "Aviral Kumar",
        "Vincent Perot",
        "Jessica Lo",
        "Yang Song",
        "Herman Schmit",
        "Jianmin Chen",
        "Vasilisa Bashlovkina",
        "Xiaoyue Pan",
        "Diana Mincu",
        "Paul Roit",
        "Isabel Edkins",
        "Andy Davis",
        "Yujia Li",
        "Ben Horn",
        "Xinjian Li",
        "Pradeep Kumar S",
        "Eric Doi",
        "Wanzheng Zhu",
        "Sri Gayatri Sundara Padmanabhan",
        "Siddharth Verma",
        "Jasmine Liu",
        "Heng Chen",
        "Mihajlo Velimirovi\\'c",
        "Malcolm Reynolds",
        "Priyanka Agrawal",
        "Nick Sukhanov",
        "Abhinit Modi",
        "Siddharth Goyal",
        "John Palowitch",
        "Nima Khajehnouri",
        "Wing Lowe",
        "David Klinghoffer",
        "Sharon Silver",
        "Vinh Tran",
        "Candice Schumann",
        "Francesco Piccinno",
        "Xi Liu",
        "Mario Lu\\v{c}i\\'c",
        "Xiaochen Yang",
        "Sandeep Kumar",
        "Ajay Kannan",
        "Ragha Kotikalapudi",
        "Mudit Bansal",
        "Fabian Fuchs",
        "Mohammad Javad Hosseini",
        "Abdelrahman Abdelhamed",
        "Dawn Bloxwich",
        "Tianhe Yu",
        "Ruoxin Sang",
        "Gregory Thornton",
        "Karan Gill",
        "Yuchi Liu",
        "Virat Shejwalkar",
        "Jason Lin",
        "Zhipeng Yan",
        "Kehang Han",
        "Thomas Buschmann",
        "Michael Pliskin",
        "Zhi Xing",
        "Susheel Tatineni",
        "Junlin Zhang",
        "Sissie Hsiao",
        "Gavin Buttimore",
        "Marcus Wu",
        "Zefei Li",
        "Geza Kovacs",
        "Legg Yeung",
        "Tao Huang",
        "Aaron Cohen",
        "Bethanie Brownfield",
        "Averi Nowak",
        "Mikel Rodriguez",
        "Tianze Shi",
        "Hado van Hasselt",
        "Kevin Cen",
        "Deepanway Ghoshal",
        "Kushal Majmundar",
        "Weiren Yu",
        "Warren (Weilun) Chen",
        "Danila Sinopalnikov",
        "Hao Zhang",
        "Vlado Gali\\'c",
        "Di Lu",
        "Zeyu Zheng",
        "Maggie Song",
        "Gary Wang",
        "Gui Citovsky",
        "Swapnil Gawde",
        "Isaac Galatzer-Levy",
        "David Silver",
        "Ivana Balazevic",
        "Dipanjan Das",
        "Kingshuk Majumder",
        "Yale Cong",
        "Praneet Dutta",
        "Dustin Tran",
        "Hui Wan",
        "Junwei Yuan",
        "Daniel Eppens",
        "Alanna Walton",
        "Been Kim",
        "Harry Ragan",
        "James Cobon-Kerr",
        "Lu Liu",
        "Weijun Wang",
        "Bryce Petrini",
        "Jack Rae",
        "Rakesh Shivanna",
        "Yan Xiong",
        "Chace Lee",
        "Pauline Coquinot",
        "Yiming Gu",
        "Lisa Patel",
        "Blake Hechtman",
        "Aviel Boag",
        "Orion Jankowski",
        "Alex Wertheim",
        "Alex Lee",
        "Paul Covington",
        "Hila Noga",
        "Sam Sobell",
        "Shanthal Vasanth",
        "William Bono",
        "Chirag Nagpal",
        "Wei Fan",
        "Xavier Garcia",
        "Kedar Soparkar",
        "Aybuke Turker",
        "Nathan Howard",
        "Sachit Menon",
        "Yuankai Chen",
        "Vikas Verma",
        "Vladimir Pchelin",
        "Harish Rajamani",
        "Valentin Dalibard",
        "Ana Ramalho",
        "Yang Guo",
        "Kartikeya Badola",
        "Seojin Bang",
        "Nathalie Rauschmayr",
        "Julia Proskurnia",
        "Sudeep Dasari",
        "Xinyun Chen",
        "Mikhail Sushkov",
        "Anja Hauth",
        "Pauline Sho",
        "Abhinav Singh",
        "Bilva Chandra",
        "Allie Culp",
        "Max Dylla",
        "Olivier Bachem",
        "James Besley",
        "Heri Zhao",
        "Timothy Lillicrap",
        "Wei Wei",
        "Wael Al Jishi",
        "Ning Niu",
        "Alban Rrustemi",
        "Rapha\\\"el Lopez Kaufman",
        "Ryan Poplin",
        "Jewel Zhao",
        "Minh Truong",
        "Shikhar Bharadwaj",
        "Ester Hlavnova",
        "Eli Stickgold",
        "Cordelia Schmid",
        "Georgi Stephanov",
        "Zhaoqi Leng",
        "Frederick Liu",
        "L\\'eonard Hussenot",
        "Shenil Dodhia",
        "Juliana Vicente Franco",
        "Lesley Katzen",
        "Abhanshu Sharma",
        "Sarah Cogan",
        "Zuguang Yang",
        "Aniket Ray",
        "Sergi Caelles",
        "Shen Yan",
        "Ravin Kumar",
        "Daniel Gillick",
        "Renee Wong",
        "Joshua Ainslie",
        "Jonathan Hoech",
        "S\\'eb Arnold",
        "Dan Abolafia",
        "Anca Dragan",
        "Ben Hora",
        "Grace Hu",
        "Alexey Guseynov",
        "Yang Lu",
        "Chas Leichner",
        "Jinmeng Rao",
        "Abhimanyu Goyal",
        "Nagabhushan Baddi",
        "Daniel Hernandez Diaz",
        "Tim McConnell",
        "Max Bain",
        "Jake Abernethy",
        "Qiqi Yan",
        "Rylan Schaeffer",
        "Paul Vicol",
        "Will Thompson",
        "Montse Gonzalez Arenas",
        "Mathias Bellaiche",
        "Pablo Barrio",
        "Stefan Zinke",
        "Riccardo Patana",
        "Pulkit Mehta",
        "JK Kearns",
        "Avraham Ruderman",
        "Scott Pollom",
        "David D'Ambrosio",
        "Cath Hope",
        "Yang Yu",
        "Andrea Gesmundo",
        "Kuang-Huei Lee",
        "Aviv Rosenberg",
        "Yiqian Zhou",
        "Yaoyiran Li",
        "Drew Garmon",
        "Yonghui Wu",
        "Safeen Huda",
        "Gil Fidel",
        "Martin Baeuml",
        "Jian Li",
        "Phoebe Kirk",
        "Rhys May",
        "Tao Tu",
        "Sara Mc Carthy",
        "Toshiyuki Fukuzawa",
        "Miranda Aperghis",
        "Chih-Kuan Yeh",
        "Toshihiro Yoshino",
        "Bo Li",
        "Austin Myers",
        "Kaisheng Yao",
        "Ben Limonchik",
        "Changwan Ryu",
        "Rohun Saxena",
        "Alex Goldin",
        "Ruizhe Zhao",
        "Rocky Rhodes",
        "Tao Zhu",
        "Divya Tyam",
        "Heidi Howard",
        "Nathan Byrd",
        "Hongxu Ma",
        "Yan Wu",
        "Ryan Mullins",
        "Qingze Wang",
        "Aida Amini",
        "Sebastien Baur",
        "Yiran Mao",
        "Subhashini Venugopalan",
        "Will Song",
        "Wen Ding",
        "Paul Collins",
        "Sashank Reddi",
        "Megan Shum",
        "Andrei Rusu",
        "Luisa Zintgraf",
        "Kelvin Chan",
        "Sheela Goenka",
        "Mathieu Blondel",
        "Michael Collins",
        "Renke Pan",
        "Marissa Giustina",
        "Nikolai Chinaev",
        "Christian Schuler",
        "Ce Zheng",
        "Jonas Valfridsson",
        "Alyssa Loo",
        "Alex Yakubovich",
        "Jamie Smith",
        "Tao Jiang",
        "Rich Munoz",
        "Gabriel Barcik",
        "Rishabh Bansal",
        "Mingyao Yang",
        "Yilun Du",
        "Pablo Duque",
        "Mary Phuong",
        "Alexandra Belias",
        "Kunal Lad",
        "Zeyu Liu",
        "Tal Schuster",
        "Karthik Duddu",
        "Jieru Hu",
        "Paige Kunkle",
        "Matthew Watson",
        "Jackson Tolins",
        "Josh Smith",
        "Denis Teplyashin",
        "Garrett Bingham",
        "Marvin Ritter",
        "Marco Andreetto",
        "Divya Pitta",
        "Mohak Patel",
        "Shashank Viswanadha",
        "Trevor Strohman",
        "Catalin Ionescu",
        "Jincheng Luo",
        "Yogesh Kalley",
        "Jeremy Wiesner",
        "Dan Deutsch",
        "Derek Lockhart",
        "Peter Choy",
        "Rumen Dangovski",
        "Chawin Sitawarin",
        "Cat Graves",
        "Tanya Lando",
        "Joost van Amersfoort",
        "Ndidi Elue",
        "Zhouyuan Huo",
        "Pooya Moradi",
        "Jean Tarbouriech",
        "Henryk Michalewski",
        "Wenting Ye",
        "Eunyoung Kim",
        "Alex Druinsky",
        "Florent Altch\\'e",
        "Xinyi Chen",
        "Artur Dwornik",
        "Da-Cheng Juan",
        "Rivka Moroshko",
        "Horia Toma",
        "Jarrod Kahn",
        "Hai Qian",
        "Maximilian Sieb",
        "Irene Cai",
        "Roman Goldenberg",
        "Praneeth Netrapalli",
        "Sindhu Raghuram",
        "Yuan Gong",
        "Lijie Fan",
        "Evan Palmer",
        "Yossi Matias",
        "Valentin Gabeur",
        "Shreya Pathak",
        "Tom Ouyang",
        "Don Metzler",
        "Geoff Bacon",
        "Srinivasan Venkatachary",
        "Sridhar Thiagarajan",
        "Alex Cullum",
        "Eran Ofek",
        "Vytenis Sakenas",
        "Mohamed Hammad",
        "Cesar Magalhaes",
        "Mayank Daswani",
        "Oscar Chang",
        "Ashok Popat",
        "Ruichao Li",
        "Komal Jalan",
        "Yanhan Hou",
        "Josh Lipschultz",
        "Antoine He",
        "Wenhao Jia",
        "Pier Giuseppe Sessa",
        "Prateek Kolhar",
        "William Wong",
        "Sumeet Singh",
        "Lukas Haas",
        "Jay Whang",
        "Hanna Klimczak-Pluci\\'nska",
        "Georges Rotival",
        "Grace Chung",
        "Yiqing Hua",
        "Anfal Siddiqui",
        "Nicolas Serrano",
        "Dongkai Chen",
        "Billy Porter",
        "Libin Bai",
        "Keshav Shivam",
        "Sho Arora",
        "Partha Talukdar",
        "Tom Cobley",
        "Sangnie Bhardwaj",
        "Evgeny Gladchenko",
        "Simon Green",
        "Kelvin Guu",
        "Felix Fischer",
        "Xiao Wu",
        "Eric Wang",
        "Achintya Singhal",
        "Tatiana Matejovicova",
        "James Martens",
        "Hongji Li",
        "Roma Patel",
        "Elizabeth Kemp",
        "Jiaqi Pan",
        "Lily Wang",
        "Blake JianHang Chen",
        "Jean-Baptiste Alayrac",
        "Navneet Potti",
        "Erika Gemzer",
        "Eugene Ie",
        "Kay McKinney",
        "Takaaki Saeki",
        "Edward Chou",
        "Pascal Lamblin",
        "SQ Mah",
        "Zach Fisher",
        "Martin Chadwick",
        "Jon Stritar",
        "Obaid Sarvana",
        "Andrew Hogue",
        "Artem Shtefan",
        "Hadi Hashemi",
        "Yang Xu",
        "Jindong Gu",
        "Sharad Vikram",
        "Chung-Ching Chang",
        "Sabela Ramos",
        "Logan Kilpatrick",
        "Weijuan Xi",
        "Jenny Brennan",
        "Yinghao Sun",
        "Abhishek Jindal",
        "Ionel Gog",
        "Dawn Chen",
        "Felix Wu",
        "Jason Lee",
        "Sudhindra Kopalle",
        "Srinadh Bhojanapalli",
        "Oriol Vinyals",
        "Natan Potikha",
        "Burcu Karagol Ayan",
        "Yuan Yuan",
        "Michael Riley",
        "Piotr Stanczyk",
        "Sergey Kishchenko",
        "Bing Wang",
        "Dan Garrette",
        "Antoine Yang",
        "Vlad Feinberg",
        "CJ Carey",
        "Javad Azizi",
        "Viral Shah",
        "Erica Moreira",
        "Chongyang Shi",
        "Josh Feldman",
        "Elizabeth Salesky",
        "Thomas Lampe",
        "Aneesh Pappu",
        "Duhyeon Kim",
        "Jonas Adler",
        "Avi Caciularu",
        "Brian Walker",
        "Yunhan Xu",
        "Yochai Blau",
        "Dylan Scandinaro",
        "Terry Huang",
        "Sam El-Husseini",
        "Abhishek Sinha",
        "Lijie Ren",
        "Taylor Tobin",
        "Patrik Sundberg",
        "Tim Sohn",
        "Vikas Yadav",
        "Mimi Ly",
        "Emily Xue",
        "Jing Xiong",
        "Afzal Shama Soudagar",
        "Sneha Mondal",
        "Nikhil Khadke",
        "Qingchun Ren",
        "Ben Vargas",
        "Stan Bileschi",
        "Sarah Chakera",
        "Cindy Wang",
        "Boyu Wang",
        "Yoni Halpern",
        "Joe Jiang",
        "Vikas Sindhwani",
        "Petre Petrov",
        "Pranavaraj Ponnuramu",
        "Sanket Vaibhav Mehta",
        "Yu Watanabe",
        "Betty Chan",
        "Matheus Wisniewski",
        "Trang Pham",
        "Jingwei Zhang",
        "Conglong Li",
        "Dario de Cesare",
        "Art Khurshudov",
        "Alex Vasiloff",
        "Melissa Tan",
        "Zoe Ashwood",
        "Bobak Shahriari",
        "Maryam Majzoubi",
        "Garrett Tanzer",
        "Olga Kozlova",
        "Robin Alazard",
        "James Lee-Thorp",
        "Nguyet Minh Phu",
        "Isaac Tian",
        "Junwhan Ahn",
        "Andy Crawford",
        "Lauren Lax",
        "Yuan Shangguan",
        "Iftekhar Naim",
        "David Ross",
        "Oleksandr Ferludin",
        "Tongfei Guo",
        "Andrea Banino",
        "Hubert Soyer",
        "Xiaoen Ju",
        "Dominika Rogozi\\'nska",
        "Ishaan Malhi",
        "Marcella Valentine",
        "Daniel Balle",
        "Apoorv Kulshreshtha",
        "Maciej Kula",
        "Yiwen Song",
        "Sophia Austin",
        "John Schultz",
        "Roy Hirsch",
        "Arthur Douillard",
        "Apoorv Reddy",
        "Michael Fink",
        "Summer Yue",
        "Khyatti Gupta",
        "Adam Zhang",
        "Norman Rink",
        "Daniel McDuff",
        "Lei Meng",
        "Andr\\'as Gy\\\"orgy",
        "Yasaman Razeghi",
        "Ricky Liang",
        "Kazuki Osawa",
        "Aviel Atias",
        "Matan Eyal",
        "Tyrone Hill",
        "Nikolai Grigorev",
        "Zhengdong Wang",
        "Nitish Kulkarni",
        "Rachel Soh",
        "Ivan Lobov",
        "Zachary Charles",
        "Sid Lall",
        "Kazuma Hashimoto",
        "Ido Kessler",
        "Victor Gomes",
        "Zelda Mariet",
        "Danny Driess",
        "Alessandro Agostini",
        "Canfer Akbulut",
        "Jingcao Hu",
        "Marissa Ikonomidis",
        "Emily Caveness",
        "Kartik Audhkhasi",
        "Saurabh Agrawal",
        "Ioana Bica",
        "Evan Senter",
        "Jayaram Mudigonda",
        "Kelly Chen",
        "Jingchen Ye",
        "Xuanhui Wang",
        "James Svensson",
        "Philipp Fr\\\"anken",
        "Josh Newlan",
        "Li Lao",
        "Eva Schnider",
        "Sami Alabed",
        "Joseph Kready",
        "Jesse Emond",
        "Afief Halumi",
        "Tim Zaman",
        "Chengxi Ye",
        "Naina Raisinghani",
        "Vilobh Meshram",
        "Bo Chang",
        "Ankit Singh Rawat",
        "Axel Stjerngren",
        "Sergey Levi",
        "Rui Wang",
        "Xiangzhu Long",
        "Mitchelle Rasquinha",
        "Steven Hand",
        "Aditi Mavalankar",
        "Lauren Agubuzu",
        "Sudeshna Roy",
        "Junquan Chen",
        "Jarek Wilkiewicz",
        "Hao Zhou",
        "Michal Jastrzebski",
        "Qiong Hu",
        "Agustin Dal Lago",
        "Ramya Sree Boppana",
        "Wei-Jen Ko",
        "Jennifer Prendki",
        "Yao Su",
        "Zhi Li",
        "Eliza Rutherford",
        "Girish Ramchandra Rao",
        "Ramona Comanescu",
        "Adri\\`a Puigdom\\`enech",
        "Qihang Chen",
        "Dessie Petrova",
        "Christine Chan",
        "Vedrana Milutinovic",
        "Felipe Tiengo Ferreira",
        "Chin-Yi Cheng",
        "Ming Zhang",
        "Tapomay Dey",
        "Sherry Yang",
        "Ramesh Sampath",
        "Quoc Le",
        "Howard Zhou",
        "Chu-Cheng Lin",
        "Hoi Lam",
        "Christine Kaeser-Chen",
        "Kai Hui",
        "Dean Hirsch",
        "Tom Eccles",
        "Basil Mustafa",
        "Shruti Rijhwani",
        "Morgane Rivi\\`ere",
        "Yuanzhong Xu",
        "Junjie Wang",
        "Xinyang Geng",
        "Xiance Si",
        "Arjun Khare",
        "Cheolmin Kim",
        "Vahab Mirrokni",
        "Kamyu Lee",
        "Khuslen Baatarsukh",
        "Nathaniel Braun",
        "Lisa Wang",
        "Pallavi LV",
        "Richard Tanburn",
        "Yuvein (Yonghao) Zhu",
        "Fangda Li",
        "Setareh Ariafar",
        "Dan Goldberg",
        "Ken Burke",
        "Daniil Mirylenka",
        "Meiqi Guo",
        "Olaf Ronneberger",
        "Hadas Natalie Vogel",
        "Liqun Cheng",
        "Nishita Shetty",
        "Johnson Jia",
        "Thomas Jimma",
        "Corey Fry",
        "Ted Xiao",
        "Martin Sundermeyer",
        "Ryan Burnell",
        "Yannis Assael",
        "Mario Pinto",
        "JD Chen",
        "Rohit Sathyanarayana",
        "Donghyun Cho",
        "Jing Lu",
        "Rishabh Agarwal",
        "Sugato Basu",
        "Lucas Gonzalez",
        "Dhruv Shah",
        "Meng Wei",
        "Dre Mahaarachchi",
        "Rohan Agrawal",
        "Tero Rissa",
        "Yani Donchev",
        "Ramiro Leal-Cavazos",
        "Adrian Hutter",
        "Markus Mircea",
        "Alon Jacovi",
        "Faruk Ahmed",
        "Jiageng Zhang",
        "Shuguang Hu",
        "Bo-Juen Chen",
        "Jonni Kanerva",
        "Guillaume Desjardins",
        "Andrew Lee",
        "Nikos Parotsidis",
        "Asier Mujika",
        "Tobias Weyand",
        "Jasper Snoek",
        "Jo Chick",
        "Kai Chen",
        "Paul Chang",
        "Ethan Mahintorabi",
        "Zi Wang",
        "Tolly Powell",
        "Orgad Keller",
        "Abhirut Gupta",
        "Claire Sha",
        "Kanav Garg",
        "Nicolas Heess",
        "\\'Agoston Weisz",
        "Cassidy Hardin",
        "Bartek Wydrowski",
        "Ben Coleman",
        "Karina Zainullina",
        "Pankaj Joshi",
        "Alessandro Epasto",
        "Terry Spitz",
        "Binbin Xiong",
        "Kai Zhao",
        "Arseniy Klimovskiy",
        "Ivy Zheng",
        "Johan Ferret",
        "Itay Yona",
        "Waleed Khawaja",
        "Jean-Baptiste Lespiau",
        "Maxim Krikun",
        "Siamak Shakeri",
        "Timothee Cour",
        "Bonnie Li",
        "Igor Krivokon",
        "Dan Suh",
        "Alex Hofer",
        "Jad Al Abdallah",
        "Nikita Putikhin",
        "Oscar Akerlund",
        "Silvio Lattanzi",
        "Anurag Kumar",
        "Shane Settle",
        "Himanshu Srivastava",
        "Folawiyo Campbell-Ajala",
        "Edouard Rosseel",
        "Mihai Dorin Istin",
        "Nishanth Dikkala",
        "Anand Rao",
        "Nick Young",
        "Kate Lin",
        "Dhruva Bhaswar",
        "Yiming Wang",
        "Jaume Sanchez Elias",
        "Kritika Muralidharan",
        "James Keeling",
        "Dayou Du",
        "Siddharth Gopal",
        "Gregory Dibb",
        "Charles Blundell",
        "Manolis Delakis",
        "Jacky Liang",
        "Marco Tulio Ribeiro",
        "Georgi Karadzhov",
        "Guillermo Garrido",
        "Ankur Bapna",
        "Jiawei Cao",
        "Adam Sadovsky",
        "Pouya Tafti",
        "Arthur Guez",
        "Coline Devin",
        "Yixian Di",
        "Jinwei Xing",
        "Chuqiao (Joyce) Xu",
        "Hanzhao Lin",
        "Chun-Te Chu",
        "Sameera Ponda",
        "Wesley Helmholz",
        "Fan Yang",
        "Yue Gao",
        "Sara Javanmardi",
        "Wael Farhan",
        "Alex Ramirez",
        "Ricardo Figueira",
        "Khe Chai Sim",
        "Yuval Bahat",
        "Ashwin Vaswani",
        "Liangzhe Yuan",
        "Gufeng Zhang",
        "Leland Rechis",
        "Hanjun Dai",
        "Tayo Oguntebi",
        "Alexandra Cordell",
        "Eug\\'enie Rives",
        "Kaan Tekelioglu",
        "Naveen Kumar",
        "Bing Zhang",
        "Aurick Zhou",
        "Nikolay Savinov",
        "Andrew Leach",
        "Alex Tudor",
        "Sanjay Ganapathy",
        "Yanyan Zheng",
        "Mirko Rossini",
        "Vera Axelrod",
        "Arnaud Autef",
        "Yukun Zhu",
        "Zheng Zheng",
        "Mingda Zhang",
        "Baochen Sun",
        "Jie Ren",
        "Nenad Tomasev",
        "Nithish Kannen",
        "Amer Sinha",
        "Charles Chen",
        "Louis O'Bryan",
        "Alex Pak",
        "Aditya Kusupati",
        "Weel Yang",
        "Deepak Ramachandran",
        "Patrick Griffin",
        "Seokhwan Kim",
        "Philipp Neubeck",
        "Craig Schiff",
        "Tammo Spalink",
        "Mingyang Ling",
        "Arun Nair",
        "Ga-Young Joung",
        "Linda Deng",
        "Avishkar Bhoopchand",
        "Lora Aroyo",
        "Tom Duerig",
        "Jordan Griffith",
        "Gabe Barth-Maron",
        "Jake Ades",
        "Alex Haig",
        "Ankur Taly",
        "Yunting Song",
        "Paul Michel",
        "Dave Orr",
        "Dean Weesner",
        "Corentin Tallec",
        "Carrie Grimes Bostock",
        "Paul Niemczyk",
        "Andy Twigg",
        "Mudit Verma",
        "Rohith Vallu",
        "Henry Wang",
        "Marco Gelmi",
        "Kiranbir Sodhia",
        "Aleksandr Chuklin",
        "Omer Goldman",
        "Jasmine George",
        "Liang Bai",
        "Kelvin Zhang",
        "Petar Sirkovic",
        "Efrat Nehoran",
        "Golan Pundak",
        "Jiaqi Mu",
        "Alice Chen",
        "Alex Greve",
        "Paulo Zacchello",
        "David Amos",
        "Heming Ge",
        "Eric Noland",
        "Colton Bishop",
        "Jeffrey Dudek",
        "Youhei Namiki",
        "Elena Buchatskaya",
        "Jing Li",
        "Dorsa Sadigh",
        "Masha Samsikova",
        "Dan Malkin",
        "Damien Vincent",
        "Robert David",
        "Rob Willoughby",
        "Phoenix Meadowlark",
        "Shawn Gao",
        "Yan Li",
        "Raj Apte",
        "Amit Jhindal",
        "Stein Xudong Lin",
        "Alex Polozov",
        "Zhicheng Wang",
        "Tomas Mery",
        "Anirudh GP",
        "Varun Yerram",
        "Sage Stevens",
        "Tianqi Liu",
        "Noah Fiedel",
        "Charles Sutton",
        "Matthew Johnson",
        "Xiaodan Song",
        "Kate Baumli",
        "Nir Shabat",
        "Muqthar Mohammad",
        "Hao Liu",
        "Marco Selvi",
        "Yichao Zhou",
        "Mehdi Hafezi Manshadi",
        "Chu-ling Ko",
        "Anthony Chen",
        "Michael Bendersky",
        "Jorge Gonzalez Mendez",
        "Nisarg Kothari",
        "Amir Zandieh",
        "Yiling Huang",
        "Daniel Andor",
        "Ellie Pavlick",
        "Idan Brusilovsky",
        "Jitendra Harlalka",
        "Sally Goldman",
        "Andrew Lampinen",
        "Guowang Li",
        "Asahi Ushio",
        "Somit Gupta",
        "Lei Zhang",
        "Chuyuan Kelly Fu",
        "Madhavi Sewak",
        "Timo Denk",
        "Jed Borovik",
        "Brendan Jou",
        "Avital Zipori",
        "Prateek Jain",
        "Junwen Bai",
        "Thang Luong",
        "Jonathan Tompson",
        "Alice Li",
        "Li Liu",
        "George Powell",
        "Jiajun Shen",
        "Alex Feng",
        "Grishma Chole",
        "Da Yu",
        "Yinlam Chow",
        "Tongxin Yin",
        "Eric Malmi",
        "Kefan Xiao",
        "Yash Pande",
        "Shachi Paul",
        "Niccol\\`o Dal Santo",
        "Adil Dostmohamed",
        "Sergio Guadarrama",
        "Aaron Phillips",
        "Thanumalayan Sankaranarayana Pillai",
        "Gal Yona",
        "Amin Ghafouri",
        "Preethi Lahoti",
        "Benjamin Lee",
        "Dhruv Madeka",
        "Eren Sezener",
        "Simon Tokumine",
        "Adrian Collister",
        "Nicola De Cao",
        "Richard Shin",
        "Uday Kalra",
        "Parker Beak",
        "Emily Nottage",
        "Ryo Nakashima",
        "Ivan Jurin",
        "Vikash Sehwag",
        "Meenu Gaba",
        "Junhao Zeng",
        "Kevin R. McKee",
        "Fernando Pereira",
        "Tamar Yakar",
        "Amayika Panda",
        "Arka Dhar",
        "Peilin Zhong",
        "Daniel Sohn",
        "Mark Brand",
        "Lars Lowe Sjoesund",
        "Viral Carpenter",
        "Sharon Lin",
        "Shantanu Thakoor",
        "Marcus Wainwright",
        "Ashwin Chaugule",
        "Pranesh Srinivasan",
        "Muye Zhu",
        "Bernett Orlando",
        "Jack Weber",
        "Ayzaan Wahid",
        "Gilles Baechler",
        "Apurv Suman",
        "Jovana Mitrovi\\'c",
        "Gabe Taubman",
        "Honglin Yu",
        "Helen King",
        "Josh Dillon",
        "Cathy Yip",
        "Dhriti Varma",
        "Tomas Izo",
        "Levent Bolelli",
        "Borja De Balle Pigem",
        "Julia Di Trapani",
        "Fotis Iliopoulos",
        "Adam Paszke",
        "Nishant Ranka",
        "Joe Zou",
        "Francesco Pongetti",
        "Jed McGiffin",
        "Alex Siegman",
        "Rich Galt",
        "Ross Hemsley",
        "Goran \\v{Z}u\\v{z}i\\'c",
        "Victor Carbune",
        "Tao Li",
        "Myle Ott",
        "F\\'elix de Chaumont Quitry",
        "David Vilar Torres",
        "Yuri Chervonyi",
        "Tomy Tsai",
        "Prem Eruvbetine",
        "Samuel Yang",
        "Matthew Denton",
        "Jake Walker",
        "Slavica Anda\\v{c}i\\'c",
        "Idan Heimlich Shtacher",
        "Vittal Premachandran",
        "Harshal Tushar Lehri",
        "Cip Baetu",
        "Damion Yates",
        "Lampros Lamprou",
        "Mariko Iinuma",
        "Ioana Mihailescu",
        "Ben Albrecht",
        "Shachi Dave",
        "Susie Sargsyan",
        "Bryan Perozzi",
        "Lucas Manning",
        "Chiyuan Zhang",
        "Denis Vnukov",
        "Igor Mordatch",
        "Raia Hadsell Wolfgang Macherey",
        "Ryan Kappedal",
        "Jim Stephan",
        "Aditya Tripathi",
        "Klaus Macherey",
        "Jun Qian",
        "Abhishek Bhowmick",
        "Shekoofeh Azizi",
        "R\\'emi Leblond",
        "Shiva Mohan Reddy Garlapati",
        "Timothy Knight",
        "Matthew Wiethoff",
        "Wei-Chih Hung",
        "Anelia Angelova",
        "Georgios Evangelopoulos",
        "Pawel Janus",
        "Dimitris Paparas",
        "Matthew Rahtz",
        "Ken Caluwaerts",
        "Vivek Sampathkumar",
        "Daniel Jarrett",
        "Shadi Noghabi",
        "Antoine Miech",
        "Chak Yeung",
        "Geoff Clark",
        "Henry Prior",
        "Fei Zheng",
        "Jean Pouget-Abadie",
        "Indro Bhattacharya",
        "Kalpesh Krishna",
        "Will Bishop",
        "Zhe Yuan",
        "Yunxiao Deng",
        "Ashutosh Sathe",
        "Kacper Krasowiak",
        "Ciprian Chelba",
        "Cho-Jui Hsieh",
        "Kiran Vodrahalli",
        "Buhuang Liu",
        "Thomas K\\\"oppe",
        "Amr Khalifa",
        "Lubo Litchev",
        "Pichi Charoenpanit",
        "Reed Roberts",
        "Sachin Yadav",
        "Yasumasa Onoe",
        "Desi Ivanov",
        "Megha Mohabey",
        "Vighnesh Birodkar",
        "Nemanja Raki\\'cevi\\'c",
        "Pierre Sermanet",
        "Vaibhav Mehta",
        "Krishan Subudhi",
        "Travis Choma",
        "Will Ng",
        "Luheng He",
        "Kathie Wang",
        "Tasos Kementsietsidis",
        "Shane Gu",
        "Mansi Gupta",
        "Andrew Nystrom",
        "Mehran Kazemi",
        "Timothy Chung",
        "Nacho Cano",
        "Nikhil Dhawan",
        "Yufei Wang",
        "Jiawei Xia",
        "Trevor Yacovone",
        "Eric Jia",
        "Mingqing Chen",
        "Simeon Ivanov",
        "Ashrith Sheshan",
        "Sid Dalmia",
        "Pawe{\\l} Stradomski",
        "Pengcheng Yin",
        "Salem Haykal",
        "Congchao Wang",
        "Dennis Duan",
        "Neslihan Bulut",
        "Greg Kochanski",
        "Liam MacDermed",
        "Namrata Godbole",
        "Shitao Weng",
        "Jingjing Chen",
        "Rachana Fellinger",
        "Ramin Mehran",
        "Daniel Suo",
        "Hisham Husain",
        "Tong He",
        "Kaushal Patel",
        "Joshua Howland",
        "Randall Parker",
        "Kelvin Nguyen",
        "Sharath Maddineni",
        "Chris Rawles",
        "Mina Khan",
        "Shlomi Cohen-Ganor",
        "Amol Mandhane",
        "Xinyi Wu",
        "Chenkai Kuang",
        "Iulia Com\\c{s}a",
        "Ramya Ganeshan",
        "Hanie Sedghi",
        "Adam Bloniarz",
        "Nuo Wang Pierse",
        "Anton Briukhov",
        "Petr Mitrichev",
        "Anita Gergely",
        "Serena Zhan",
        "Allan Zhou",
        "Nikita Saxena",
        "Eva Lu",
        "Josef Dean",
        "Ashish Gupta",
        "Nicolas Perez-Nieves",
        "Renjie Wu",
        "Cory McLean",
        "Wei Liang",
        "Disha Jindal",
        "Anton Tsitsulin",
        "Wenhao Yu",
        "Kaiz Alarakyia",
        "Tom Schaul",
        "Piyush Patil",
        "Peter Sung",
        "Elijah Peake",
        "Hongkun Yu",
        "Feryal Behbahani",
        "JD Co-Reyes",
        "Alan Ansell",
        "Sean Sun",
        "Clara Barbu",
        "Jonathan Lee",
        "Seb Noury",
        "James Allingham",
        "Bilal Piot",
        "Mohit Sharma",
        "Christopher Yew",
        "Ivan Korotkov",
        "Bibo Xu",
        "Demetra Brady",
        "Goran Petrovic",
        "Shibl Mourad",
        "Claire Cui",
        "Aditya Gupta",
        "Parker Schuh",
        "Saarthak Khanna",
        "Anna Goldie",
        "Abhinav Arora",
        "Vadim Zubov",
        "Amy Stuart",
        "Mark Epstein",
        "Yun Zhu",
        "Jianqiao Liu",
        "Yury Stuken",
        "Ziyue Wang",
        "Karolis Misiunas",
        "Dee Guo",
        "Ashleah Gill",
        "Ale Hartman",
        "Zaid Nabulsi",
        "Aurko Roy",
        "Aleksandra Faust",
        "Jason Riesa",
        "Ben Withbroe",
        "Mengchao Wang",
        "Marco Tagliasacchi",
        "Andreea Marzoca",
        "James Noraky",
        "Serge Toropov",
        "Malika Mehrotra",
        "Bahram Raad",
        "Sanja Deur",
        "Steve Xu",
        "Marianne Monteiro",
        "Zhongru Wu",
        "Yi Luan",
        "Sam Ritter",
        "Nick Li",
        "H{\\aa}vard Garnes",
        "Yanzhang He",
        "Martin Zlocha",
        "Jifan Zhu",
        "Matteo Hessel",
        "Will Wu",
        "Spandana Raj Babbula",
        "Chizu Kawamoto",
        "Yuanzhen Li",
        "Mehadi Hassen",
        "Yan Wang",
        "Brian Wieder",
        "James Freedman",
        "Yin Zhang",
        "Xinyi Bai",
        "Tianli Yu",
        "David Reitter",
        "XiangHai Sheng",
        "Mateo Wirth",
        "Aditya Kini",
        "Dima Damen",
        "Mingcen Gao",
        "Rachel Hornung",
        "Michael Voznesensky",
        "Brian Roark",
        "Adhi Kuncoro",
        "Yuxiang Zhou",
        "Rushin Shah",
        "Anthony Brohan",
        "Kuangyuan Chen",
        "James Wendt",
        "David Rim",
        "Paul Kishan Rubenstein",
        "Jonathan Halcrow",
        "Michelle Liu",
        "Ty Geri",
        "Yunhsuan Sung",
        "Jane Shapiro",
        "Shaan Bijwadia",
        "Chris Duvarney",
        "Christina Sorokin",
        "Paul Natsev",
        "Reeve Ingle",
        "Pramod Gupta",
        "Young Maeng",
        "Ndaba Ndebele",
        "Kexin Zhu",
        "Valentin Anklin",
        "Katherine Lee",
        "Yuan Liu",
        "Yaroslav Akulov",
        "Shaleen Gupta",
        "Guolong Su",
        "Flavien Prost",
        "Tianlin Liu",
        "Vitaly Kovalev",
        "Pol Moreno",
        "Martin Scholz",
        "Sam Redmond",
        "Zongwei Zhou",
        "Alex Castro-Ros",
        "Andr\\'e Susano Pinto",
        "Dia Kharrat",
        "Michal Yarom",
        "Rachel Saputro",
        "Jannis Bulian",
        "Ben Caine",
        "Ji Liu",
        "Abbas Abdolmaleki",
        "Shariq Iqbal",
        "Tautvydas Misiunas",
        "Mikhail Sirotenko",
        "Shefali Garg",
        "Guy Bensky",
        "Huan Gui",
        "Xuezhi Wang",
        "Raphael Koster",
        "Mike Bernico",
        "Da Huang",
        "Romal Thoppilan",
        "Trevor Cohn",
        "Ben Golan",
        "Wenlei Zhou",
        "Andrew Rosenberg",
        "Markus Freitag",
        "Tynan Gangwani",
        "Vincent Tsang",
        "Anand Shukla",
        "Xiaoqi Ren",
        "Minh Giang",
        "Chi Zou",
        "Andre Elisseeff",
        "Charline Le Lan",
        "Dheeru Dua",
        "Shuba Lall",
        "Pranav Shyam",
        "Frankie Garcia",
        "Sarah Nguyen",
        "Michael Guzman",
        "AJ Maschinot",
        "Marcello Maggioni",
        "Ming-Wei Chang",
        "Karol Gregor",
        "Lotte Weerts",
        "Kumaran Venkatesan",
        "Bogdan Damoc",
        "Leon Liu",
        "Jan Wassenberg",
        "Lewis Ho",
        "Becca Roelofs",
        "Majid Hadian",
        "Fran\\c{c}ois-Xavier Aubet",
        "Yu Liang",
        "Sami Lachgar",
        "Danny Karmon",
        "Yong Cheng",
        "Amelio V\\'azquez-Reina",
        "Angie Chen",
        "Zhuyun Dai",
        "Andy Brock",
        "Shubham Agrawal",
        "Chenxi Pang",
        "Peter Garst",
        "Mariella Sanchez-Vargas",
        "Ivor Rendulic",
        "Aditya Ayyar",
        "Andrija Ra\\v{z}natovi\\'c",
        "Olivia Ma",
        "Roopali Vij",
        "Neha Sharma",
        "Ashwin Balakrishna",
        "Bingyuan Liu",
        "Ian Mackinnon",
        "Sorin Baltateanu",
        "Petra Poklukar",
        "Gabriel Ibagon",
        "Colin Ji",
        "Hongyang Jiao",
        "Isaac Noble",
        "Wojciech Stokowiec",
        "Zhihao Li",
        "Jeff Dean",
        "David Lindner",
        "Mark Omernick",
        "Kristen Chiafullo",
        "Mason Dimarco",
        "Vitor Rodrigues",
        "Vittorio Selo",
        "Garrett Honke",
        "Xintian (Cindy) Wu",
        "Wei He",
        "Adam Hillier",
        "Anhad Mohananey",
        "Vihari Piratla",
        "Chang Ye",
        "Chase Malik",
        "Sebastian Riedel",
        "Samuel Albanie",
        "Zi Yang",
        "Kenny Vassigh",
        "Maria Bauza",
        "Sheng Li",
        "Yiqing Tao",
        "Nevan Wichers",
        "Andrii Maksai",
        "Abe Ittycheriah",
        "Ross Mcilroy",
        "Bryan Seybold",
        "Noah Goodman",
        "Romina Datta",
        "Steven M. Hernandez",
        "Tian Shi",
        "Yony Kochinski",
        "Anna Bulanova",
        "Ken Franko",
        "Mikita Sazanovich",
        "Nicholas FitzGerald",
        "Praneeth Kacham",
        "Shubha Srinivas Raghvendra",
        "Vincent Hellendoorn",
        "Alexander Grushetsky",
        "Julian Salazar",
        "Angeliki Lazaridou",
        "Jason Chang",
        "Jan-Thorsten Peter",
        "Sushant Kafle",
        "Yann Dauphin",
        "Abhishek Rao",
        "Filippo Graziano",
        "Izhak Shafran",
        "Yuguo Liao",
        "Tianli Ding",
        "Geng Yan",
        "Grace Chu",
        "Zhao Fu",
        "Vincent Roulet",
        "Gabriel Rasskin",
        "Duncan Williams",
        "Shahar Drath",
        "Alex Mossin",
        "Raphael Hoffmann",
        "Jordi Orbay",
        "Francesco Bertolini",
        "Hila Sheftel",
        "Justin Chiu",
        "Siyang Xue",
        "Yuheng Kuang",
        "Ferjad Naeem",
        "Swaroop Nath",
        "Nana Nti",
        "Phil Culliton",
        "Kashyap Krishnakumar",
        "Michael Isard",
        "Pei Sun",
        "Ayan Chakrabarti",
        "Nathan Clement",
        "Regev Cohen",
        "Arissa Wongpanich",
        "GS Oh",
        "Ashwin Murthy",
        "Hao Zheng",
        "Jessica Hamrick",
        "Oskar Bunyan",
        "Suhas Ganesh",
        "Nitish Gupta",
        "Roy Frostig",
        "John Wieting",
        "Yury Malkov",
        "Pierre Marcenac",
        "Zhixin (Lucas) Lai",
        "Xiaodan Tang",
        "Mohammad Saleh",
        "Fedir Zubach",
        "Chinmay Kulkarni",
        "Huanjie Zhou",
        "Vicky Zayats",
        "Nan Ding",
        "Anshuman Tripathi",
        "Arijit Pramanik",
        "Patrik Zochbauer",
        "Harish Ganapathy",
        "Vedant Misra",
        "Zach Behrman",
        "Hugo Vallet",
        "Mingyang Zhang",
        "Mukund Sridhar",
        "Ye Jin",
        "Mohammad Babaeizadeh",
        "Siim P\\~oder",
        "Megha Goel",
        "Divya Jain",
        "Tajwar Nasir",
        "Shubham Mittal",
        "Tim Dozat",
        "Diego Ardila",
        "Aliaksei Severyn",
        "Fabio Pardo",
        "Sammy Jerome",
        "Siyang Qin",
        "Louis Rouillard",
        "Amir Yazdanbakhsh",
        "Zizhao Zhang",
        "Shivani Agrawal",
        "Kaushik Shivakumar",
        "Caden Lu",
        "Praveen Kallakuri",
        "Rachita Chhaparia",
        "Kanishka Rao",
        "Charles Kwong",
        "Asya Fadeeva",
        "Shitij Nigam",
        "Yan Virin",
        "Yuan Zhang",
        "Balaji Venkatraman",
        "Beliz Gunel",
        "Marc Wilson",
        "Huiyu Wang",
        "Abhinav Gupta",
        "Xiaowei Xu",
        "Adrien Ali Ta\\\"iga",
        "Kareem Mohamed",
        "Doug Fritz",
        "Daniel Rodriguez",
        "Zoubin Ghahramani",
        "Harry Askham",
        "Lior Belenki",
        "James Zhao",
        "Rahul Gupta",
        "Krzysztof Jastrz\\k{e}bski",
        "Takahiro Kosakai",
        "Kaan Katircioglu",
        "Jon Schneider",
        "Rina Panigrahy",
        "Konstantinos Bousmalis",
        "Peter Grabowski",
        "Prajit Ramachandran",
        "Chaitra Hegde",
        "Mihaela Rosca",
        "Angelo Scorza Scarpati",
        "Kyriakos Axiotis",
        "Ying Xu",
        "Zach Gleicher",
        "Assaf Hurwitz Michaely",
        "Mandar Sharma",
        "Sanil Jain",
        "Christoph Hirnschall",
        "Tal Marian",
        "Xuhui Jia",
        "Kevin Mather",
        "Kilol Gupta",
        "Linhai Qiu",
        "Nigamaa Nayakanti",
        "Lucian Ionita",
        "Steven Zheng",
        "Lucia Loher",
        "Kurt Shuster",
        "Igor Petrovski",
        "Roshan Sharma",
        "Rahma Chaabouni",
        "Angel Yeh",
        "James An",
        "Arushi Gupta",
        "Steven Schwarcz",
        "Seher Ellis",
        "Sam Conway-Rahman",
        "Javier Snaider",
        "Alex Zhai",
        "James Atwood",
        "Daniel Golovin",
        "Liqian Peng",
        "Te I",
        "Vivian Xia",
        "Salvatore Scellato",
        "Mahan Malihi",
        "Arthur Bra\\v{z}inskas",
        "Vlad-Doru Ion",
        "Younghoon Jun",
        "James Swirhun",
        "Soroosh Mariooryad",
        "Jiao Sun",
        "Steve Chien",
        "Rey Coaguila",
        "Ariel Brand",
        "Yi Gao",
        "Tom Kwiatkowski",
        "Roee Aharoni",
        "Cheng-Chun Lee",
        "Mislav \\v{Z}ani\\'c",
        "Yichi Zhang",
        "Dan Ethier",
        "Vitaly Nikolaev",
        "Pranav Nair",
        "Yoav Ben Shalom",
        "Hen Fitoussi",
        "Jai Gupta",
        "Hongbin Liu",
        "Dee Cattle",
        "Tolga Bolukbasi",
        "Ben Murdoch",
        "Fantine Huot",
        "Yin Li",
        "Chris Hahn",
        "Urvashi Khandelwal",
        "Frederik Benzing",
        "Arthur Conmy",
        "Andrey Simanovsky",
        "Fran\\c{c}oise Beaufays",
        "Eugene Weinstein",
        "Tongzhou Chen",
        "Luke Leonhard",
        "Bhuvana Ramabhadran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T17:36:04+00:00",
          "link": "https://arxiv.org/abs/2507.06261v1",
          "size": "8601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T11:03:21+00:00",
          "link": "https://arxiv.org/abs/2507.06261v2",
          "size": "8601kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:16:43+00:00",
          "link": "https://arxiv.org/abs/2507.06261v3",
          "size": "8601kb",
          "version": "v3"
        }
      ],
      "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06261",
        "HTML": "https://arxiv.org/html/2507.06261v3",
        "PDF": "https://arxiv.org/pdf/2507.06261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the capabilities of the Gemini 2.X model family, emphasizing advancements in multimodal understanding and processing larger contexts. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07188",
      "abstract": "Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts - we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also show that all tested models exhibit a consistent recency bias varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.",
      "authors": [
        "Jens Rupprecht",
        "Georg Ahnert",
        "Markus Strohmaier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:01:50+00:00",
          "link": "https://arxiv.org/abs/2507.07188v1",
          "size": "269kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:02:56+00:00",
          "link": "https://arxiv.org/abs/2507.07188v2",
          "size": "269kb",
          "version": "v2"
        }
      ],
      "title": "Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07188",
        "HTML": "https://arxiv.org/html/2507.07188v2",
        "PDF": "https://arxiv.org/pdf/2507.07188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines biases and robustness in LLMs' survey responses, touching on prompt design and robustness testing, which relate to synthetic data generation. However, the main focus is on response biases, not direct contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07393",
      "abstract": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy on MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.",
      "authors": [
        "Jinseong Kim",
        "Jeonghoon Song",
        "Gyeongseon Baek",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:15:57+00:00",
          "link": "https://arxiv.org/abs/2507.07393v1",
          "size": "3910kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T04:18:18+00:00",
          "link": "https://arxiv.org/abs/2507.07393v2",
          "size": "3910kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T02:04:22+00:00",
          "link": "https://arxiv.org/abs/2507.07393v3",
          "size": "3933kb",
          "version": "v3"
        }
      ],
      "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07393",
        "HTML": "https://arxiv.org/html/2507.07393v3",
        "PDF": "https://arxiv.org/pdf/2507.07393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces KeyRe-ID, a framework for person re-identification in videos. It focuses on video representation learning using keypoints and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08339",
      "abstract": "Recently, the development of large language models (LLMs) and reasoning large language models (RLLMs) have gained considerable attention from many researchers. RLLMs enhance the reasoning capabilities of LLMs through Long Chain-of-Thought (Long CoT) processes, significantly improving the performance of LLMs in addressing complex problems. However, there are few works that systematically explore what methods can fully unlock the performance of LLMs and RLLMs within the financial domain. To investigate the impact of various methods on LLMs and RLLMs, we utilize five LLMs and three RLLMs to assess the effects of prompting methods, agentic frameworks, and multilingual alignment methods on financial question-answering tasks. Our research findings indicate: (1) Current prompting methods and agent frameworks enhance the performance of LLMs in financial question answering by simulating Long CoT; (2) RLLMs possess inherent Long CoT capabilities, which limits the effectiveness of conventional methods in further enhancing their performance; (3) Current advanced multilingual alignment methods primarily improve the multilingual performance of LLMs by extending the reasoning length, which yields minimal benefits for RLLMs. We hope that this study can serve as an important reference for LLMs and RLLMs in the field of financial question answering.",
      "authors": [
        "Peng Wang",
        "Xuesi Hu",
        "Jiageng Wu",
        "Yuntao Zou",
        "Qiancheng Zhang",
        "Dagang Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T06:37:44+00:00",
          "link": "https://arxiv.org/abs/2507.08339v1",
          "size": "248kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T18:06:32+00:00",
          "link": "https://arxiv.org/abs/2507.08339v2",
          "size": "198kb",
          "version": "v2"
        }
      ],
      "title": "What Factors Affect LLMs and RLLMs in Financial Question Answering?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08339",
        "HTML": "https://arxiv.org/html/2507.08339v2",
        "PDF": "https://arxiv.org/pdf/2507.08339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the performance of LLMs and RLLMs in financial question answering, evaluating methods like prompting and alignment. It does not involve any specific contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08383",
      "abstract": "Representation of inductive coupling lines with conventional static phasors is the main reason of inadequacy of the existing phasors based simplified stability analysis methods for microgrids with inductive coupling lines. In the literature, dynamic phasors have been proposed for the dynamic modelling of inductive lines to conserve the simplified structure of the analysis method. In this study a generalized stability analysis method for LV AC microgrids, composed of droop controlled inverters, is presented. The proposed analysis method is based on the inclusion of dynamic phasors for inductive coupling lines into the existing phasors based stability analysis method. The results show that the stability analysis method with dynamic phasors successfully predicts the instability boundaries of LV AC microgrids.",
      "authors": [
        "B\\\"ulent Da\\u{g}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T07:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.08383v1",
          "size": "1282kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:10:45+00:00",
          "link": "https://arxiv.org/abs/2507.08383v2",
          "size": "1273kb",
          "version": "v2"
        }
      ],
      "title": "A Generalized Stability Analysis Method with Dynamic Phasors for LV AC Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08383",
        "PDF": "https://arxiv.org/pdf/2507.08383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a generalized stability analysis method for LV AC microgrids using dynamic phasors, which is unrelated to LLM training data processing or any aspect of LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08898",
      "abstract": "Safety alignment is critical for LLM-powered systems. While recent LLM-powered guardrail approaches such as LlamaGuard achieve high detection accuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''), they struggle with multilingual unsafe inputs. This limitation leaves LLM systems vulnerable to unsafe and jailbreak prompts written in low-resource languages such as those in Southeast Asia. This paper introduces SEALGuard, a multilingual guardrail designed to improve the safety alignment across diverse languages. It aims to address the multilingual safety alignment gap of existing guardrails and ensure effective filtering of unsafe and jailbreak prompts in LLM-powered systems. We adapt a general-purpose multilingual language model into a multilingual guardrail using low-rank adaptation (LoRA). We construct SEALSBench, a large-scale multilingual safety alignment dataset containing over 260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases. We evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on this benchmark. Our findings show that multilingual unsafe and jailbreak prompts substantially degrade the performance of the state-of-the-art LlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and 18%, respectively, compared to its performance on English-only prompts. In contrast, SEALGuard outperforms existing guardrails in detecting multilingual unsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and achieving the best DSR, precision, and F1-score. Our ablation study further reveals the contributions of adaptation strategies and model size to the overall performance of SEALGuard. We release our pre-trained model and benchmark at https://github.com/awsm-research/SEALGuard to support further research.",
      "authors": [
        "Wenliang Shan",
        "Michael Fu",
        "Rui Yang",
        "Chakkrit Tantithamthavorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.08898v1",
          "size": "7452kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:06:59+00:00",
          "link": "https://arxiv.org/abs/2507.08898v2",
          "size": "7434kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:01:44+00:00",
          "link": "https://arxiv.org/abs/2507.08898v3",
          "size": "855kb",
          "version": "v3"
        }
      ],
      "title": "SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08898",
        "PDF": "https://arxiv.org/pdf/2507.08898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SEALGuard, which includes constructing SEALSBench, a multilingual dataset aimed at improving safety alignment in LLMs. This involves creating datasets for multilingual data safety, thus contributing directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09565",
      "abstract": "We introduce a dataset for classifying wellness dimensions in social media user posts, covering six key aspects: physical, emotional, social, intellectual, spiritual, and vocational. The dataset is designed to capture these dimensions in user-generated content, with a comprehensive annotation framework developed under the guidance of domain experts. This framework allows for the classification of text spans into the appropriate wellness categories. We evaluate both traditional machine learning models and advanced transformer-based models for this multi-class classification task, with performance assessed using precision, recall, and F1-score, averaged over 10-fold cross-validation. Post-hoc explanations are applied to ensure the transparency and interpretability of model decisions. The proposed dataset contributes to region-specific wellness assessments in social media and paves the way for personalized well-being evaluations and early intervention strategies in mental health. We adhere to ethical considerations for constructing and releasing our experiments and dataset publicly on Github.",
      "authors": [
        "Heba Shakeel",
        "Tanvir Ahmad",
        "Chandni Saxena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T10:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.09565v1",
          "size": "490kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:11:39+00:00",
          "link": "https://arxiv.org/abs/2507.09565v2",
          "size": "490kb",
          "version": "v2"
        }
      ],
      "title": "Holistix: A Dataset for Holistic Wellness Dimensions Analysis in Mental Health Narratives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09565",
        "HTML": "https://arxiv.org/html/2507.09565v2",
        "PDF": "https://arxiv.org/pdf/2507.09565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper contributes a new dataset, Holistix, for analyzing wellness dimensions in user-generated social media posts. The dataset creation and annotation framework represent a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09592",
      "abstract": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval) Module, designed and implemented by eSapiens, a secure, scalable engine that transforms natural-language questions into verified, read-only SQL analytics for enterprise databases. The Text-to-SQL module follows a decoupled orchestration/execution architecture: a Supervisor Agent routes queries, Schema Retrieval dynamically injects table and column metadata, and a SQL Generation Agent emits single-statement SELECT queries protected by a read-only guardrail. An integrated Self-Correction & Rating loop captures empty results, execution errors, or low-quality outputs and triggers up to five LLM-driven regeneration attempts. Finally, a Result Interpretation Agent produces concise, human-readable insights and hands raw rows to the Insight & Intelligence engine for visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate reliable ad-hoc querying and automated periodic reporting. By embedding schema awareness, fault-tolerant execution, and compliance guardrails, the THOR Module empowers non-technical users to access live data with zero-SQL simplicity and enterprise-grade safety.",
      "authors": [
        "Isaac Shi and Zeyuan Li and Fan Liu and Wenli Wang and Lewei He and Yang Yang and Tianyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T11:48:24+00:00",
          "link": "https://arxiv.org/abs/2507.09592v1",
          "size": "1584kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T05:23:14+00:00",
          "link": "https://arxiv.org/abs/2507.09592v2",
          "size": "1652kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T05:47:22+00:00",
          "link": "https://arxiv.org/abs/2507.09592v3",
          "size": "1636kb",
          "version": "v3"
        }
      ],
      "title": "THOR: Transformer Heuristics for On-Demand Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09592",
        "HTML": "https://arxiv.org/html/2507.09592v3",
        "PDF": "https://arxiv.org/pdf/2507.09592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a module for transforming natural-language questions into SQL queries, specifically targeting enterprise database analytics. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09647",
      "abstract": "In recent years, the rampant spread of misinformation on social media has made accurate detection of multimodal fake news a critical research focus. However, previous research has not adequately understood the semantics of images, and models struggle to discern news authenticity with limited textual information. Meanwhile, treating all emotional types of news uniformly without tailored approaches further leads to performance degradation. Therefore, we propose a novel Knowledge Augmentation and Emotion Guidance Network (KEN). On the one hand, we effectively leverage LVLM's powerful semantic understanding and extensive world knowledge. For images, the generated captions provide a comprehensive understanding of image content and scenes, while for text, the retrieved evidence helps break the information silos caused by the closed and limited text and context. On the other hand, we consider inter-class differences between different emotional types of news through balanced learning, achieving fine-grained modeling of the relationship between emotional types and authenticity. Extensive experiments on two real-world datasets demonstrate the superiority of our KEN.",
      "authors": [
        "Peican Zhu",
        "Yubo Jing",
        "Le Cheng",
        "Keke Tang",
        "Yangming Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.09647v1",
          "size": "1775kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:20:43+00:00",
          "link": "https://arxiv.org/abs/2507.09647v2",
          "size": "1775kb",
          "version": "v2"
        }
      ],
      "title": "KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09647",
        "HTML": "https://arxiv.org/html/2507.09647v2",
        "PDF": "https://arxiv.org/pdf/2507.09647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on detecting multimodal fake news using a novel network that leverages knowledge augmentation and emotion guidance, without contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09953",
      "abstract": "While electron microscopy offers crucial atomic-resolution insights into structure-property relationships, radiation damage severely limits its use on beam-sensitive materials like proteins and 2D materials. To overcome this challenge, we push beyond the electron dose limits of conventional electron microscopy by adapting principles from multi-image super-resolution (MISR) that have been widely used in remote sensing. Our method fuses multiple low-resolution, sub-pixel-shifted views and enhances the reconstruction with a convolutional neural network (CNN) that integrates features from synthetic, multi-angle observations. We developed a dual-path, attention-guided network for 4D-STEM that achieves atomic-scale super-resolution from ultra-low-dose data. This provides robust atomic-scale visualization across amorphous, semi-crystalline, and crystalline beam-sensitive specimens. Systematic evaluations on representative materials demonstrate comparable spatial resolution to conventional ptychography under ultra-low-dose conditions. Our work expands the capabilities of 4D-STEM, offering a new and generalizable method for the structural analysis of radiation-vulnerable materials.",
      "authors": [
        "Zifei Wang",
        "Zian Mao",
        "Xiaoya He",
        "Xi Huang",
        "Haoran Zhang",
        "Chun Cheng",
        "Shufen Chu",
        "Tingzheng Hou",
        "Xiaoqin Zeng",
        "Yujun Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:02:05+00:00",
          "link": "https://arxiv.org/abs/2507.09953v1",
          "size": "36655kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T17:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.09953v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:39:01+00:00",
          "link": "https://arxiv.org/abs/2507.09953v3",
          "size": "37630kb",
          "version": "v3"
        }
      ],
      "title": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09953",
        "HTML": "https://arxiv.org/html/2507.09953v3",
        "PDF": "https://arxiv.org/pdf/2507.09953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on low-dose super-resolution imaging techniques for electron microscopy using a CNN, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09958",
      "abstract": "Inductive bias is a key factor in spatial regression models, determining how well a model can learn from limited data and capture spatial patterns. This work revisits the inductive biases in Geographically Neural Network Weighted Regression (GNNWR) and identifies limitations in current approaches for modeling spatial non-stationarity. While GNNWR extends traditional Geographically Weighted Regression by using neural networks to learn spatial weighting functions, existing implementations are often restricted by fixed distance-based schemes and limited inductive bias. We propose to generalize GNNWR by incorporating concepts from convolutional neural networks, recurrent neural networks, and transformers, introducing local receptive fields, sequential context, and self-attention into spatial regression. Through extensive benchmarking on synthetic spatial datasets with varying heterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic methods in capturing nonlinear and complex spatial relationships. Our results also reveal that model performance depends strongly on data characteristics, with local models excelling in highly heterogeneous or small-sample scenarios, and global models performing better with larger, more homogeneous data. These findings highlight the importance of inductive bias in spatial modeling and suggest future directions, including learnable spatial weighting functions, hybrid neural architectures, and improved interpretability for models handling non-stationary spatial data.",
      "authors": [
        "Zhenyuan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:13:18+00:00",
          "link": "https://arxiv.org/abs/2507.09958v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.09958v2",
          "size": "33kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09958",
        "HTML": "https://arxiv.org/html/2507.09958v2",
        "PDF": "https://arxiv.org/pdf/2507.09958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes inductive bias in spatial regression models through neural networks and transformers, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09997",
      "abstract": "This paper presents a trust-based predictive multi-agent consensus protocol that analyses neighbours' anticipation data and makes coordination decisions. Agents in the network share their future predicted data over a finite look-ahead horizon with their neighbours and update their predictions in a rolling-horizon fashion. The prediction data is then used by agents to learn both the trust and the commitment traits exhibited by their neighbours over time. The proposed protocol is named as the Anticipatory Distributed Coordination (ADC) protocol. Lyapunov theory-based agreement convergence between agents is provided, followed by demonstrations using numerical simulations.",
      "authors": [
        "Venkatraman Renganathan",
        "Sabyasachi Mondal",
        "Antonios Tsourdos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:32:05+00:00",
          "link": "https://arxiv.org/abs/2507.09997v1",
          "size": "477kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:21:07+00:00",
          "link": "https://arxiv.org/abs/2507.09997v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Predictive & Trust-based Multi-Agent Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09997",
        "PDF": "https://arxiv.org/pdf/2507.09997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a coordination protocol for multi-agent systems, which involves trust and predictive analysis, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10015",
      "abstract": "Foundation multi-modal models are often designed by stitching of multiple existing pretrained uni-modal models: for example, an image classifier with an text model. This stitching process is performed by training a connector module that aims to align the representation spaces of these uni-modal models towards a multi-modal objective. However, given the complexity of training such connectors on large scale web-based datasets coupled with the ever-increasing number of available pretrained uni-modal models, the task of uni-modal models selection and subsequent connector module training becomes computationally demanding. To address this under-studied critical problem, we propose Hypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal uni-modal model selection and connector training by leveraging hypernetworks. Specifically, our framework utilizes the parameter prediction capability of a hypernetwork to obtain jointly trained connector modules for $N \\times M$ combinations of uni-modal models. In our experiments, Hyma reduces the cost of searching for the best performing uni-modal model pair by $10\\times$, while matching the ranking and trained connector performance obtained via grid search across a suite of diverse multi-modal benchmarks.",
      "authors": [
        "Jaisidh Singh",
        "Diganta Misra",
        "Boris Knyazev",
        "Antonio Orvieto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:51:01+00:00",
          "link": "https://arxiv.org/abs/2507.10015v1",
          "size": "464kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:15:38+00:00",
          "link": "https://arxiv.org/abs/2507.10015v2",
          "size": "464kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T11:10:58+00:00",
          "link": "https://arxiv.org/abs/2507.10015v3",
          "size": "464kb",
          "version": "v3"
        }
      ],
      "title": "(Almost) Free Modality Stitching of Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10015",
        "HTML": "https://arxiv.org/html/2507.10015v3",
        "PDF": "https://arxiv.org/pdf/2507.10015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper discusses model alignment in multi-modal systems, it focuses on computational efficiency and model connections rather than contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10044",
      "abstract": "Medical images often contain multiple labels with imbalanced distributions and co-occurrence, leading to bias in multi-label medical image classification. Close collaboration between medical professionals and machine learning practitioners has significantly advanced medical image analysis. However, traditional collaboration modes struggle to facilitate effective feedback between physicians and AI models, as integrating medical expertise into the training process via engineers can be time-consuming and labor-intensive. To bridge this gap, we introduce MEDebiaser, an interactive system enabling physicians to directly refine AI models using local explanations. By combining prediction with attention loss functions and employing a customized ranking strategy to alleviate scalability, MEDebiaser allows physicians to mitigate biases without technical expertise, reducing reliance on engineers, and thus enhancing more direct human-AI feedback. Our mechanism and user studies demonstrate that it effectively reduces biases, improves usability, and enhances collaboration efficiency, providing a practical solution for integrating medical expertise into AI-driven healthcare.",
      "authors": [
        "Shaohan Shi",
        "Yuheng Shao",
        "Haoran Jiang",
        "Yunjie Yao",
        "Zhijun Zhang",
        "Xu Ding",
        "Quan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:21:48+00:00",
          "link": "https://arxiv.org/abs/2507.10044v1",
          "size": "11585kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:52:46+00:00",
          "link": "https://arxiv.org/abs/2507.10044v2",
          "size": "3548kb",
          "version": "v2"
        }
      ],
      "title": "MEDebiaser: A Human-AI Feedback System for Mitigating Bias in Multi-label Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10044",
        "HTML": "https://arxiv.org/html/2507.10044v2",
        "PDF": "https://arxiv.org/pdf/2507.10044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a system to mitigate bias in medical image classification, using physician feedback and is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10290",
      "abstract": "Optimization has been widely used to generate smooth trajectories for motion planning. However, existing trajectory optimization methods show weakness when dealing with large-scale long trajectories. Recent advances in parallel computing have accelerated optimization in some fields, but how to efficiently solve trajectory optimization via parallelism remains an open question. In this paper, we propose a novel trajectory optimization framework based on the Consensus Alternating Direction Method of Multipliers (CADMM) algorithm, which decomposes the trajectory into multiple segments and solves the subproblems in parallel. The proposed framework reduces the time complexity to O(1) per iteration to the number of segments, compared to O(N) of the state-of-the-art (SOTA) approaches. Furthermore, we introduce a closed-form solution that integrates convex linear and quadratic constraints to speed up the optimization, and we also present numerical solutions for general inequality constraints. A series of simulations and experiments demonstrate that our approach outperforms the SOTA approach in terms of efficiency and smoothness. Especially for a large-scale trajectory, with one hundred segments, achieving over a tenfold speedup. To fully explore the potential of our algorithm on modern parallel computing architectures, we deploy our framework on a GPU and show high performance with thousands of segments.",
      "authors": [
        "Jiajun Yu",
        "Nanhe Chen",
        "Guodong Liu",
        "Chao Xu",
        "Fei Gao",
        "Yanjun Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:56:59+00:00",
          "link": "https://arxiv.org/abs/2507.10290v1",
          "size": "22037kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T20:42:16+00:00",
          "link": "https://arxiv.org/abs/2507.10290v2",
          "size": "22036kb",
          "version": "v2"
        }
      ],
      "title": "TOP: Trajectory Optimization via Parallel Optimization towards Constant Time Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10290",
        "HTML": "https://arxiv.org/html/2507.10290v2",
        "PDF": "https://arxiv.org/pdf/2507.10290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on parallel optimization for trajectory planning, which is unrelated to LLM training data processing. It does not involve data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10456",
      "abstract": "Non-metric music forms the core of the repertoire in Iranian classical music. Dastgahi music serves as the underlying theoretical system for both Iranian art music and certain folk traditions. At the heart of Iranian classical music lies the radif, a foundational repertoire that organizes melodic material central to performance and pedagogy.\n  In this study, we introduce the first digital corpus representing the complete non-metrical radif repertoire, covering all 13 existing components of this repertoire. We provide MIDI files (about 281 minutes in total) and data spreadsheets describing notes, note durations, intervals, and hierarchical structures for 228 pieces of music. We faithfully represent the tonality including quarter-tones, and the non-metric aspect. Furthermore, we provide supporting basic statistics, and measures of complexity and similarity over the corpus.\n  Our corpus provides a platform for computational studies of Iranian classical music. Researchers might employ it in studying melodic patterns, investigating improvisational styles, or for other tasks in music information retrieval, music theory, and computational (ethno)musicology.",
      "authors": [
        "Maziar Kanani",
        "Sean O Leary",
        "James McDermott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:35:09+00:00",
          "link": "https://arxiv.org/abs/2507.10456v1",
          "size": "463kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:43:59+00:00",
          "link": "https://arxiv.org/abs/2507.10456v2",
          "size": "463kb",
          "version": "v2"
        }
      ],
      "title": "Radif Corpus: A Symbolic Dataset for Non-Metric Iranian Classical Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10456",
        "HTML": "https://arxiv.org/html/2507.10456v2",
        "PDF": "https://arxiv.org/pdf/2507.10456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a symbolic dataset for non-metric Iranian classical music, which is not related to LLM training data processing or any aspect of pretraining or fine-tuning of language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10484",
      "abstract": "This paper introduces the \"Target Polish,\" a robust and computationally efficient framework for nonnegative matrix and tensor factorization. Although conventional weighted NMF approaches are resistant to outliers, they converge slowly due to the use of multiplicative updates to minimize the objective criterion. In contrast, the Target Polish approach remains compatible with the Fast-HALS algorithm, which is renowned for its speed, by adaptively smoothing the data with a weighted median-based transformation. This innovation provides outlier resistance while maintaining the highly efficient additive update structure of Fast-HALS. Empirical evaluations using image datasets corrupted with structured (block) and unstructured (salt) noise demonstrate that the Target Polish approach matches or exceeds the accuracy of state-of-the-art robust NMF methods and reduces computational time by an order of magnitude in the studied scenarios.",
      "authors": [
        "Paul Fogel (1)",
        "Christophe Geissler (1)",
        "George Luta (2) ((1) Data Services",
        "Forvis Mazars",
        "Levallois",
        "France",
        "(2) Department of Biostatistics",
        "Bioinformatics and Biomathematics",
        "Georgetown University Medical Center",
        "Washington",
        "DC",
        "USA)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:04:03+00:00",
          "link": "https://arxiv.org/abs/2507.10484v1",
          "size": "2486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T19:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.10484v2",
          "size": "2486kb",
          "version": "v2"
        }
      ],
      "title": "The Target Polish: A New Approach to Outlier-Resistant Non-Negative Matrix and Tensor Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10484",
        "HTML": "https://arxiv.org/html/2507.10484v2",
        "PDF": "https://arxiv.org/pdf/2507.10484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work centers on robust non-negative matrix and tensor factorization for outlier resistance, which is not applicable to LLM training data processing, pretraining, or fine-tuning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10638",
      "abstract": "We introduce a novel classification framework, ZClassifier, that replaces conventional deterministic logits with diagonal Gaussian-distributed logits. Our method simultaneously addresses temperature scaling and manifold approximation by minimizing the Kullback-Leibler (KL) divergence between the predicted Gaussian distributions and a unit isotropic Gaussian. This unifies uncertainty calibration and latent control in a principled probabilistic manner, enabling a natural interpretation of class confidence and geometric consistency. Experiments on CIFAR-10 show that ZClassifier improves over softmax classifiers in robustness, calibration, and latent separation.",
      "authors": [
        "Shim Soon Yong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:30:40+00:00",
          "link": "https://arxiv.org/abs/2507.10638v1",
          "size": "417kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:11:45+00:00",
          "link": "https://arxiv.org/abs/2507.10638v2",
          "size": "7599kb",
          "version": "v2"
        }
      ],
      "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10638",
        "HTML": "https://arxiv.org/html/2507.10638v2",
        "PDF": "https://arxiv.org/pdf/2507.10638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces ZClassifier, a classification framework aimed at improving robustness, calibration, and latent separation for softmax classifiers. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10646",
      "abstract": "Programming assistants powered by large language models have transformed software development, yet most benchmarks focus narrowly on code generation tasks. Recent efforts like InfiBench and StackEval attempt to address this gap using Stack Overflow data but remain limited to single-turn interactions in isolated contexts, require significant manual curation, and fail to represent complete project environments. We introduce CodeAssistBench (CAB), the first benchmark framework for evaluating multi-turn programming assistance in realistic settings that address real-world questions about actual codebases. Unlike existing programming Q&A benchmarks, CAB automatically generates scalable datasets from question-related GitHub issues using configurable parameters (e.g., repository creation date, star count, programming languages), and includes automatic containerization of codebases for evaluation. It then evaluates models through simulated users in these containerized environments with full codebase access. Using this framework, we constructed a test set of 3,286 real-world programming questions across 231 repositories, spanning seven programming languages and diverse problem domains. Our evaluation of leading LLMs reveals a substantial capability gap: while models perform well on Stack Overflow questions with success rates of 70-83%, they resolve only up to 16.49% of CAB's recent issues. This discrepancy highlights the challenges of providing assistance in complex, project-specific contexts versus answering standalone questions.",
      "authors": [
        "Myeongsoo Kim",
        "Shweta Garg",
        "Baishakhi Ray",
        "Varun Kumar",
        "and Anoop Deoras"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:19:00+00:00",
          "link": "https://arxiv.org/abs/2507.10646v1",
          "size": "6078kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.10646v2",
          "size": "6071kb",
          "version": "v2"
        }
      ],
      "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10646",
        "HTML": "https://arxiv.org/html/2507.10646v2",
        "PDF": "https://arxiv.org/pdf/2507.10646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "CodeAssistBench (CAB) creates a benchmark framework using datasets automatically generated from GitHub issues for evaluating LLMs in programming contexts. While it involves dataset creation, the focus is on benchmarking LLMs' multi-turn assistance capabilities, not on improving LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10917",
      "abstract": "Recently, much effort has been devoted to modeling users' multi-interests based on their behaviors or auxiliary signals. However, existing methods often rely on heuristic assumptions, e.g., co-occurring items indicate the same interest of users, failing to capture user multi-interests aligning with real-world scenarios. While large language models (LLMs) show significant potential for multi-interest analysis due to their extensive knowledge and powerful reasoning capabilities, two key challenges remain. First, the granularity of LLM-driven multi-interests is agnostic, possibly leading to overly fine or coarse interest grouping. Second, individual user analysis provides limited insights due to the data sparsity issue. In this paper, we propose an LLM-driven dual-level multi-interest modeling framework for more effective recommendation. At the user-individual level, we exploit LLMs to flexibly allocate items engaged by users into different semantic clusters, indicating their diverse and distinct interests. To alleviate the agnostic generation of LLMs, we adaptively assign these semantic clusters to users' collaborative multi-interests learned from global user-item interactions, allowing the granularity to be automatically adjusted according to the user's behaviors using an alignment module. To alleviate the limited insights derived from individual users' behaviors, at the user-crowd level, we propose aggregating user cliques into synthesized users with rich behaviors for more comprehensive LLM-driven multi-interest analysis. We formulate a max covering problem to ensure the compactness and representativeness of synthesized users' behaviors, and then conduct contrastive learning based on their LLM-driven multi-interests to disentangle item representations among different interests. Experiments on real-world datasets show the superiority of our approach against state-of-the-art methods.",
      "authors": [
        "Ziyan Wang",
        "Yingpeng Du",
        "Zhu Sun",
        "Jieyi Bi",
        "Haoyan Chua",
        "Tianjun Wei",
        "Jie Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:13:54+00:00",
          "link": "https://arxiv.org/abs/2507.10917v1",
          "size": "2434kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:01:08+00:00",
          "link": "https://arxiv.org/abs/2507.10917v2",
          "size": "2434kb",
          "version": "v2"
        }
      ],
      "title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10917",
        "HTML": "https://arxiv.org/html/2507.10917v2",
        "PDF": "https://arxiv.org/pdf/2507.10917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for enhancing user-interest modeling in recommendation systems, rather than on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11059",
      "abstract": "The rapid advancement of Large Language Models (LLMs) in software engineering has revealed critical limitations in existing benchmarks, particularly the widely used SWE-bench dataset. Recent studies have uncovered severe data contamination issues, e.g. SWE-bench reports 32.67% of successful patches involve direct solution leakage and 31.08% pass due to inadequate test cases. We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to address these fundamental challenges through an automated collection of real-world GitHub issues and rigorous quality validation. Our approach implements a reliable pipeline that ensures quality while minimizing contamination risks, resulting in approximately 10,000 potential tasks with 300 samples currently available. Evaluation using the Aider coding agent demonstrates strong discriminative power in state-of-the-art models. We report performance across a dozen recent LLMs evaluated on tasks collected between September 2024 and June 2025.",
      "authors": [
        "Pavel Adamenko",
        "Mikhail Ivanov",
        "Aidar Valeev",
        "Rodion Levichev",
        "Pavel Zadorozhny",
        "Ivan Lopatin",
        "Dmitry Babayev",
        "Alena Fenogenova",
        "Valentin Malykh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:52:33+00:00",
          "link": "https://arxiv.org/abs/2507.11059v1",
          "size": "448kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T14:04:07+00:00",
          "link": "https://arxiv.org/abs/2507.11059v2",
          "size": "445kb",
          "version": "v2"
        }
      ],
      "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11059",
        "HTML": "https://arxiv.org/html/2507.11059v2",
        "PDF": "https://arxiv.org/pdf/2507.11059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SWE-MERA, a dynamic benchmark designed to improve the quality of LLM evaluation in software engineering by automating data collection and rigorous validation, addressing quality and contamination in data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11129",
      "abstract": "Humans perceive the world through multimodal cues to understand and interact with the environment. Learning a scene representation for multiple modalities enhances comprehension of the physical world. However, modality conflicts, arising from inherent distinctions among different modalities, present two critical challenges: property disparity and granularity disparity. To address these challenges, we propose a general framework, MMOne, to represent multiple modalities in one scene, which can be readily extended to additional modalities. Specifically, a modality modeling module with a novel modality indicator is proposed to capture the unique properties of each modality. Additionally, we design a multimodal decomposition mechanism to separate multi-modal Gaussians into single-modal Gaussians based on modality differences. We address the essential distinctions among modalities by disentangling multimodal information into shared and modality-specific components, resulting in a more compact and efficient multimodal scene representation. Extensive experiments demonstrate that our method consistently enhances the representation capability for each modality and is scalable to additional modalities. The code is available at https://github.com/Neal2020GitHub/MMOne.",
      "authors": [
        "Zhifeng Gu",
        "Bing Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:29:29+00:00",
          "link": "https://arxiv.org/abs/2507.11129v1",
          "size": "2261kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:45:51+00:00",
          "link": "https://arxiv.org/abs/2507.11129v2",
          "size": "3429kb",
          "version": "v2"
        }
      ],
      "title": "MMOne: Representing Multiple Modalities in One Scene",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11129",
        "HTML": "https://arxiv.org/html/2507.11129v2",
        "PDF": "https://arxiv.org/pdf/2507.11129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multimodal scene representation, focusing on modality conflicts and not on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11133",
      "abstract": "Diagnostic activities, such as ultrasound scans and palpation, are relatively low-cost. They play a crucial role in the early detection of health problems and in assessing their progression. However, they are also error-prone activities, which require highly skilled medical staff. The use of robotic solutions can be key to decreasing the inherent subjectivity of the results and reducing the waiting list. For a robot to perform palpation or ultrasound scans, it must effectively manage physical interactions with the human body, which greatly benefits from precise estimation of the patient's tissue biomechanical properties. This paper assesses the accuracy and precision of a robotic system in estimating the viscoelastic parameters of various materials, including some tests on ex vivo tissues as a preliminary proof-of-concept demonstration of the method's applicability to biological samples. The measurements are compared against a ground truth derived from silicone specimens with different viscoelastic properties, characterised using a high-precision instrument. Experimental results show that the robotic system's accuracy closely matches the ground truth, increasing confidence in the potential use of robots for such clinical applications.",
      "authors": [
        "Luca Beber",
        "Edoardo Lamon",
        "Giacomo Moretti",
        "Matteo Saveriano",
        "Luca Fambri",
        "Luigi Palopoli",
        "Daniele Fontanelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:33:25+00:00",
          "link": "https://arxiv.org/abs/2507.11133v1",
          "size": "14698kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:12:02+00:00",
          "link": "https://arxiv.org/abs/2507.11133v2",
          "size": "14698kb",
          "version": "v2"
        }
      ],
      "title": "Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11133",
        "HTML": "https://arxiv.org/html/2507.11133v2",
        "PDF": "https://arxiv.org/pdf/2507.11133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with robotic systems for biomechanical characterization, which does not relate to LLM training data processing or data-related contributions for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11548",
      "abstract": "The increasing use of generative AI for resume screening is predicated on the assumption that it offers an unbiased alternative to biased human decision-making. However, this belief fails to address a critical question: are these AI systems fundamentally competent at the evaluative tasks they are meant to perform?\n  This study investigates the question of competence through a two-part audit of eight major AI platforms. Experiment 1 confirmed complex, contextual racial and gender biases, with some models penalizing candidates merely for the presence of demographic signals. Experiment 2, which evaluated core competence, provided a critical insight: some models that appeared unbiased were, in fact, incapable of performing a substantive evaluation, relying instead on superficial keyword matching.\n  This paper introduces the \"Illusion of Neutrality\" to describe this phenomenon, where an apparent lack of bias is merely a symptom of a model's inability to make meaningful judgments. This study recommends that organizations and regulators adopt a dual-validation framework, auditing AI hiring tools for both demographic bias and demonstrable competence to ensure they are both equitable and effective.",
      "authors": [
        "Kevin T Webster"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:57:13+00:00",
          "link": "https://arxiv.org/abs/2507.11548v1",
          "size": "3064kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T01:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.11548v2",
          "size": "3688kb",
          "version": "v2"
        }
      ],
      "title": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11548",
        "PDF": "https://arxiv.org/pdf/2507.11548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates the competence and bias in AI-powered resume screening tools, with no connection to LLM training data processing for pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11623",
      "abstract": "Climate change is one of the defining challenges of the 21st century, and many in the robotics community are looking for ways to contribute. This paper presents a roadmap for climate-relevant robotics research, identifying high-impact opportunities for collaboration between roboticists and experts across climate domains such as energy, the built environment, transportation, industry, land use, and Earth sciences. These applications include problems such as energy systems optimization, construction, precision agriculture, building envelope retrofits, autonomous trucking, and large-scale environmental monitoring. Critically, we include opportunities to apply not only physical robots but also the broader robotics toolkit - including planning, perception, control, and estimation algorithms - to climate-relevant problems. A central goal of this roadmap is to inspire new research directions and collaboration by highlighting specific, actionable problems at the intersection of robotics and climate. This work represents a collaboration between robotics researchers and domain experts in various climate disciplines, and it serves as an invitation to the robotics community to bring their expertise to bear on urgent climate priorities.",
      "authors": [
        "Alan Papalia",
        "Charles Dawson",
        "Laurentiu L. Anton",
        "Norhan Magdy Bayomi",
        "Bianca Champenois",
        "Jung-Hoon Cho",
        "Levi Cai",
        "Joseph DelPreto",
        "Kristen Edwards",
        "Bilha-Catherine Githinji",
        "Cameron Hickert",
        "Vindula Jayawardana",
        "Matthew Kramer",
        "Shreyaa Raghavan",
        "David Russell",
        "Shide Salimi",
        "Jingnan Shi",
        "Soumya Sudhakar",
        "Yanwei Wang",
        "Shouyi Wang",
        "Luca Carlone",
        "Vijay Kumar",
        "Daniela Rus",
        "John E. Fernandez",
        "Cathy Wu",
        "George Kantor",
        "Derek Young",
        "Hanumant Singh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.11623v1",
          "size": "4922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:00:19+00:00",
          "link": "https://arxiv.org/abs/2507.11623v2",
          "size": "5049kb",
          "version": "v2"
        }
      ],
      "title": "A Roadmap for Climate-Relevant Robotics Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11623",
        "PDF": "https://arxiv.org/pdf/2507.11623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a roadmap for climate-relevant robotics research, which does not engage with LLM training data processing techniques or related dataset issues."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11628",
      "abstract": "An interactive vignette is a popular and immersive visual storytelling approach that invites viewers to role-play a character and influences the narrative in an interactive environment. However, it has not been widely used by everyday storytellers yet due to authoring complexity, which conflicts with the immediacy of everyday storytelling. We introduce DiaryPlay, an AI-assisted authoring system for interactive vignette creation in everyday storytelling. It takes a natural language story as input and extracts the three core elements of an interactive vignette (environment, characters, and events), enabling authors to focus on refining these elements instead of constructing them from scratch. Then, it automatically transforms the single-branch story input into a branch-and-bottleneck structure using an LLM-powered narrative planner, which enables flexible viewer interactions while freeing the author from multi-branching. A technical evaluation (N=16) shows that DiaryPlay-generated character activities are on par with human-authored ones regarding believability. A user study (N=16) shows that DiaryPlay effectively supports authors in creating interactive vignette elements, maintains authorial intent while reacting to viewer interactions, and provides engaging viewing experiences.",
      "authors": [
        "Jiangnan Xu",
        "Haeseul Cha",
        "Gosu Choi",
        "Gyu-cheol Lee",
        "Yeo-Jin Yoon",
        "Zucheul Lee",
        "Konstantinos Papangelis",
        "Dae Hyun Kim",
        "and Juho Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:05:43+00:00",
          "link": "https://arxiv.org/abs/2507.11628v1",
          "size": "3706kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:01:23+00:00",
          "link": "https://arxiv.org/abs/2507.11628v2",
          "size": "3706kb",
          "version": "v2"
        }
      ],
      "title": "DiaryPlay: AI-Assisted Authoring of Interactive Vignettes for Everyday Storytelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11628",
        "PDF": "https://arxiv.org/pdf/2507.11628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes an AI-assisted authoring tool leveraging LLMs for interactive storytelling, which touches upon narrative generation but does not focus on LLM training data processing as its core contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11873",
      "abstract": "We introduce a new technique for repairing syntax errors in arbitrary context-free languages. This technique models syntax repair as a language intersection problem by defining a finite language that provably generates every syntactically valid repair within a given edit distance. Leveraging a theoretical connection between the Bar-Hillel construction from formal language theory and CFL reachability from program analysis, we show that repairability in a finite number of typographic edits is polylogarithmic parallel time decidable and provide an enumeration algorithm based on the Brzozowski derivative. Finally, we evaluate this algorithm and its implementation, demonstrating state-of-the-art results on a Python syntax repair benchmark.",
      "authors": [
        "Breandan Considine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T03:35:32+00:00",
          "link": "https://arxiv.org/abs/2507.11873v1",
          "size": "1831kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T02:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.11873v2",
          "size": "2219kb",
          "version": "v2"
        }
      ],
      "title": "Syntax Repair as Language Intersection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11873",
        "PDF": "https://arxiv.org/pdf/2507.11873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a technique for repairing syntax errors in context-free languages and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11988",
      "abstract": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are emerging as a powerful paradigm for solving complex, multifaceted problems. However, the potential of these systems is often constrained by the prevalent plan-and-execute framework, which suffers from critical limitations: rigid plan execution, static agent capabilities, and inefficient communication. These weaknesses hinder their adaptability and robustness in dynamic environments. This paper introduces Aime, a novel multi-agent framework designed to overcome these challenges through dynamic, reactive planning and execution. Aime replaces the conventional static workflow with a fluid and adaptive architecture. Its core innovations include: (1) a Dynamic Planner that continuously refines the overall strategy based on real-time execution feedback; (2) an Actor Factory that implements Dynamic Actor instantiation, assembling specialized agents on-demand with tailored tools and knowledge; and (3) a centralized Progress Management Module that serves as a single source of truth for coherent, system-wide state awareness. We empirically evaluated Aime on a diverse suite of benchmarks spanning general reasoning (GAIA), software engineering (SWE-bench Verified), and live web navigation (WebVoyager). The results demonstrate that Aime consistently outperforms even highly specialized state-of-the-art agents in their respective domains. Its superior adaptability and task success rate establish Aime as a more resilient and effective foundation for multi-agent collaboration.",
      "authors": [
        "Yexuan Shi",
        "Mingyu Wang",
        "Yunxiang Cao",
        "Hongjie Lai",
        "Junjian Lan",
        "Xin Han",
        "Yu Wang",
        "Jie Geng",
        "Zhenan Li",
        "Zihao Xia",
        "Xiang Chen",
        "Chen Li",
        "Jian Xu",
        "Wenbo Duan",
        "Yuanshuo Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T07:38:28+00:00",
          "link": "https://arxiv.org/abs/2507.11988v1",
          "size": "329kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:34:27+00:00",
          "link": "https://arxiv.org/abs/2507.11988v2",
          "size": "623kb",
          "version": "v2"
        }
      ],
      "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11988",
        "HTML": "https://arxiv.org/html/2507.11988v2",
        "PDF": "https://arxiv.org/pdf/2507.11988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While this paper introduces a multi-agent system framework using LLMs, it does not focus on any LLM training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12038",
      "abstract": "In this work we present a fast distributed algorithm for local potential problems: these are graph problems where the task is to find a locally optimal solution where no node can unilaterally improve the utility in its local neighborhood by changing its own label. A simple example of such a problem is the task of finding a locally optimal cut, i.e., a cut where for each node at least half of its incident edges are cut edges. The distributed round complexity of locally optimal cut has been wide open; the problem is known to require $\\Omega(\\log n)$ rounds in the deterministic LOCAL model and $\\Omega(\\log \\log n)$ rounds in the randomized LOCAL model, but the only known upper bound is the trivial brute-force solution of $O(n)$ rounds. Locally optimal cut in bounded-degree graphs is perhaps the simplest example of a locally checkable labeling problem for which there is still such a large gap between current upper and lower bounds. We show that in bounded-degree graphs, all local potential problems, including locally optimal cut, can be solved in $\\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models. In particular, the deterministic round complexity of the locally optimal cut problem is now settled to $\\log^{\\Theta(1)} n$.",
      "authors": [
        "Alkida Balliu",
        "Thomas Boudier",
        "Francesco d'Amore",
        "Dennis Olivetti",
        "Gustav Schmid",
        "Jukka Suomela"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.12038v1",
          "size": "145kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:38:08+00:00",
          "link": "https://arxiv.org/abs/2507.12038v2",
          "size": "145kb",
          "version": "v2"
        }
      ],
      "title": "Distributed Algorithms for Potential Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12038",
        "HTML": "https://arxiv.org/html/2507.12038v2",
        "PDF": "https://arxiv.org/pdf/2507.12038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a distributed algorithm for graph problems, specifically focusing on locally optimal cuts, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12039",
      "abstract": "The following paper introduces a general linguistic creativity test for humans and Large Language Models (LLMs). The test consists of various tasks aimed at assessing their ability to generate new original words and phrases based on word formation processes (derivation and compounding) and on metaphorical language use. We administered the test to 24 humans and to an equal number of LLMs, and we automatically evaluated their answers using OCSAI tool for three criteria: Originality, Elaboration, and Flexibility. The results show that LLMs not only outperformed humans in all the assessed criteria, but did better in six out of the eight test tasks. We then computed the uniqueness of the individual answers, which showed some minor differences between humans and LLMs. Finally, we performed a short manual analysis of the dataset, which revealed that humans are more inclined towards E(extending)-creativity, while LLMs favor F(ixed)-creativity.",
      "authors": [
        "Anca Dinu",
        "Andra-Maria Florescu and Alina Resceanu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T08:56:19+00:00",
          "link": "https://arxiv.org/abs/2507.12039v1",
          "size": "153kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:27:29+00:00",
          "link": "https://arxiv.org/abs/2507.12039v2",
          "size": "153kb",
          "version": "v2"
        }
      ],
      "title": "A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12039",
        "HTML": "https://arxiv.org/html/2507.12039v2",
        "PDF": "https://arxiv.org/pdf/2507.12039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper involves a linguistic creativity assessment of LLMs, including analysis related to dataset responses. However, its main focus is not on improving LLM training data processing but rather on evaluating linguistic creativity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12218",
      "abstract": "Many physical systems are described by partial differential equations (PDEs), and solving these equations and estimating their coefficients or boundary conditions (BCs) from observational data play a crucial role in understanding the associated phenomena. Recently, a machine learning approach known as physics-informed neural network, which solves PDEs using neural networks by minimizing the sum of residuals from the PDEs, BCs, and data, has gained significant attention in the scientific community. In this study, we investigate a physics-informed linear model (PILM) that uses linear combinations of basis functions to represent solutions, thereby enabling an analytical representation of optimal solutions. The PILM was formulated and verified for illustrative forward and inverse problems including cases with uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain rates using geodetic data. Specifically, physical regularization that enforces elastic equilibrium on the velocity fields was compared with mathematical regularization that imposes smoothness constraints. From a Bayesian perspective, mathematical regularization exhibited superior performance. The PILM provides an analytically solvable framework applicable to linear forward and inverse problems, underdetermined systems, and physical regularization.",
      "authors": [
        "Tomohisa Okazaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T13:23:39+00:00",
          "link": "https://arxiv.org/abs/2507.12218v1",
          "size": "1971kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:39:25+00:00",
          "link": "https://arxiv.org/abs/2507.12218v2",
          "size": "1971kb",
          "version": "v2"
        }
      ],
      "title": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12218",
        "PDF": "https://arxiv.org/pdf/2507.12218"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a physics-informed linear model (PILM) applied to solve partial differential equations and estimate crustal strain rates using geodetic data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12255",
      "abstract": "Team science dominates scientific knowledge production, but what makes academic teams successful? Using temporal data on 25.2 million publications and 31.8 million authors, we propose a novel network-driven approach to identify and study the success of persistent teams. Challenging the idea that persistence alone drives success, we find that team freshness - new collaborations built on prior experience - is key to success. High impact research tends to emerge early in a team's lifespan. Analyzing complex team overlap, we find that teams open to new collaborative ties consistently produce better science. Specifically, team re-combinations that introduce new freshness impulses sustain success, while persistence impulses from experienced teams are linked to earlier impact. Together, freshness and persistence shape team success across collaboration stages.",
      "authors": [
        "Hanjo D. Boekhout",
        "Eelke M. Heemskerk",
        "Niccol\\`o Pisani",
        "Frank W. Takes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:00:51+00:00",
          "link": "https://arxiv.org/abs/2507.12255v1",
          "size": "617kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:00:36+00:00",
          "link": "https://arxiv.org/abs/2507.12255v2",
          "size": "617kb",
          "version": "v2"
        }
      ],
      "title": "Freshness, Persistence and Success of Scientific Teams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12255",
        "HTML": "https://arxiv.org/html/2507.12255v2",
        "PDF": "https://arxiv.org/pdf/2507.12255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the success factors of scientific teams and proposes a network-driven approach to analyze academic team dynamics, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12269",
      "abstract": "Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of extremely low birth weight infants. Defined by oxygen dependence at 36 weeks postmenstrual age, it causes lifelong respiratory complications. However, preventive interventions carry severe risks, including neurodevelopmental impairment, ventilator-induced lung injury, and systemic complications. Therefore, early BPD prognosis and prediction of BPD outcome is crucial to avoid unnecessary toxicity in low risk infants. Admission radiographs of extremely preterm infants are routinely acquired within 24h of life and could serve as a non-invasive prognostic tool. In this work, we developed and investigated a deep learning approach using chest X-rays from 163 extremely low-birth-weight infants ($\\leq$32 weeks gestation, 401-999g) obtained within 24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult chest radiographs, employing progressive layer freezing with discriminative learning rates to prevent overfitting and evaluated a CutMix augmentation and linear probing. For moderate/severe BPD outcome prediction, our best performing model with progressive freezing, linear probing and CutMix achieved an AUROC of 0.78 $\\pm$ 0.10, balanced accuracy of 0.69 $\\pm$ 0.10, and an F1-score of 0.67 $\\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet initialization (p = 0.031) which confirms domain-specific pretraining to be important for BPD outcome prediction. Routine IRDS grades showed limited prognostic value (AUROC 0.57 $\\pm$ 0.11), confirming the need of learned markers. Our approach demonstrates that domain-specific pretraining enables accurate BPD prediction from routine day-1 radiographs. Through progressive freezing and linear probing, the method remains computationally feasible for site-level implementation and future federated learning deployments.",
      "authors": [
        "Sybelle Goedicke-Fritz (1)",
        "Michelle Bous (1)",
        "Annika Engel (2)",
        "Matthias Flotho (2 and 5)",
        "Pascal Hirsch (2)",
        "Hannah Wittig (1)",
        "Dino Milanovic (2)",
        "Dominik Mohr (1)",
        "Mathias Kaspar (6)",
        "Sogand Nemat (3)",
        "Dorothea Kerner (3)",
        "Arno B\\\"ucker (3)",
        "Andreas Keller (2 and 5 and 7)",
        "Sascha Meyer (4)",
        "Michael Zemlin (1)",
        "Philipp Flotho (2 and 5) ((1) Department of General Pediatrics and Neonatology",
        "Saarland University",
        "Campus Homburg",
        "Homburg/Saar",
        "Germany",
        "(2) Chair for Clinical Bioinformatics",
        "Saarland Informatics Campus",
        "Saarland University",
        "Saarbr\\\"ucken",
        "Germany",
        "(3) Department of Radiology",
        "and Interventional Radiology",
        "University Hospital of Saarland",
        "Homburg",
        "Germany",
        "(4) Clinical Centre Karlsruhe",
        "Franz-Lust Clinic for Paediatrics",
        "Karlsruhe",
        "Germany",
        "(5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS)",
        "Saarland University Campus",
        "Germany",
        "(6) Digital Medicine",
        "University Hospital of Augsburg",
        "Augsburg",
        "Germany",
        "(7) Pharma Science Hub (PSH)",
        "Saarland University Campus",
        "Germany)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.12269v1",
          "size": "483kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.12269v2",
          "size": "2925kb",
          "version": "v2"
        }
      ],
      "title": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12269",
        "PDF": "https://arxiv.org/pdf/2507.12269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on fine-tuning a model on medical imaging data for disease prediction, highlighting techniques like progressive layer freezing and domain-specific pretraining. While it involves fine-tuning, it does not directly address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12273",
      "abstract": "Autonomous robots are increasingly being tested into public spaces to enhance user experiences, particularly in cultural and educational settings. This paper presents the design, implementation, and evaluation of the autonomous museum guide robot Alter-Ego equipped with advanced navigation and interactive capabilities. The robot leverages state-of-the-art Large Language Models (LLMs) to provide real-time, context aware question-and-answer (Q&A) interactions, allowing visitors to engage in conversations about exhibits. It also employs robust simultaneous localization and mapping (SLAM) techniques, enabling seamless navigation through museum spaces and route adaptation based on user requests. The system was tested in a real museum environment with 34 participants, combining qualitative analysis of visitor-robot conversations and quantitative analysis of pre and post interaction surveys. Results showed that the robot was generally well-received and contributed to an engaging museum experience, despite some limitations in comprehension and responsiveness. This study sheds light on HRI in cultural spaces, highlighting not only the potential of AI-driven robotics to support accessibility and knowledge acquisition, but also the current limitations and challenges of deploying such technologies in complex, real-world environments.",
      "authors": [
        "Luca Garello",
        "Francesca Cocchella",
        "Alessandra Sciutti",
        "Manuel Catalano",
        "Francesco Rea"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:22:00+00:00",
          "link": "https://arxiv.org/abs/2507.12273v1",
          "size": "7115kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T14:54:27+00:00",
          "link": "https://arxiv.org/abs/2507.12273v2",
          "size": "7114kb",
          "version": "v2"
        }
      ],
      "title": "Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12273",
        "PDF": "https://arxiv.org/pdf/2507.12273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study concerns a museum guide robot utilizing LLMs for interactive capabilities, primarily focusing on human-robot interaction and navigation, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12284",
      "abstract": "Advancements in LLMs have enhanced task automation in software engineering; however, current evaluations primarily focus on natural language tasks, overlooking code quality. Most benchmarks prioritize high-level reasoning over executable code and real-world performance, leaving gaps in understanding true capabilities and risks associated with these models in production. To address this issue, we propose MERA Code, a new addition to the MERA benchmark family, specifically focused on evaluating code for the latest code generation LLMs in Russian. This benchmark includes 11 evaluation tasks that span 8 programming languages. Our proposed evaluation methodology features a taxonomy that outlines the practical coding skills necessary for models to complete these tasks. The benchmark comprises an open-source codebase for users to conduct MERA assessments, a scoring system compatible with various programming environments, and a platform featuring a leaderboard and submission system. We evaluate open LLMs and frontier API models, analyzing their limitations in terms of practical coding tasks in non-English languages. We are publicly releasing MERA to guide future research, anticipate groundbreaking features in model development, and standardize evaluation procedures.",
      "authors": [
        "Artem Chervyakov",
        "Alexander Kharitonov",
        "Pavel Zadorozhny",
        "Adamenko Pavel",
        "Rodion Levichev",
        "Dmitrii Vorobev",
        "Dmitrii Salikhov",
        "Aidar Valeev",
        "Alena Pestova",
        "Maria Dziuba",
        "Ilseyar Alimova",
        "Artem Zavgorodnev",
        "Aleksandr Medvedev",
        "Stanislav Moiseev",
        "Elena Bruches",
        "Daniil Grebenkin",
        "Roman Derunets",
        "Vikulov Vladimir",
        "Anton Emelyanov",
        "Dmitrii Babaev",
        "Vladimir V. Ivanov",
        "Valentin Malykh",
        "Alena Fenogenova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T14:31:33+00:00",
          "link": "https://arxiv.org/abs/2507.12284v1",
          "size": "307kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:55:32+00:00",
          "link": "https://arxiv.org/abs/2507.12284v2",
          "size": "307kb",
          "version": "v2"
        }
      ],
      "title": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12284",
        "HTML": "https://arxiv.org/html/2507.12284v2",
        "PDF": "https://arxiv.org/pdf/2507.12284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MERA Code for evaluating code generation capabilities of LLMs, but does not contribute to data processing or improvement for LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12318",
      "abstract": "We argue that diffusion models' success in modeling complex distributions is, for the most part, coming from their input conditioning. This paper investigates the representation used to condition diffusion models from the perspective that ideal representations should improve sample fidelity, be easy to generate, and be compositional to allow out-of-training samples generation. We introduce Discrete Latent Code (DLC), an image representation derived from Simplicial Embeddings trained with a self-supervised learning objective. DLCs are sequences of discrete tokens, as opposed to the standard continuous image embeddings. They are easy to generate and their compositionality enables sampling of novel images beyond the training distribution. Diffusion models trained with DLCs have improved generation fidelity, establishing a new state-of-the-art for unconditional image generation on ImageNet. Additionally, we show that composing DLCs allows the image generator to produce out-of-distribution samples that coherently combine the semantics of images in diverse ways. Finally, we showcase how DLCs can enable text-to-image generation by leveraging large-scale pretrained language models. We efficiently finetune a text diffusion language model to generate DLCs that produce novel samples outside of the image generator training distribution.",
      "authors": [
        "Samuel Lavoie",
        "Michael Noukhovitch",
        "Aaron Courville"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T15:12:17+00:00",
          "link": "https://arxiv.org/abs/2507.12318v1",
          "size": "18400kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:27:20+00:00",
          "link": "https://arxiv.org/abs/2507.12318v2",
          "size": "18400kb",
          "version": "v2"
        }
      ],
      "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12318",
        "HTML": "https://arxiv.org/html/2507.12318v2",
        "PDF": "https://arxiv.org/pdf/2507.12318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving diffusion models with Discrete Latent Codes for image generation, which is not related to LLM training data processing. It addresses model representation and sample fidelity but not data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12377",
      "abstract": "We conduct a deconstructive reading of a qualitative interview study with 17 visual data journalists from newsrooms across the globe. We borrow a deconstruction approach from literary critique to explore the instability of meaning in language and reveal implicit beliefs in words and ideas. Through our analysis we surface two sets of opposing implicit beliefs in visual data journalism: objectivity/subjectivity and humanism/mechanism. We contextualize these beliefs through a genealogical analysis, which brings deconstruction theory into practice by providing a historic backdrop for these opposing perspectives. Our analysis shows that these beliefs held within visual data journalism are not self-enclosed but rather a product of external societal forces and paradigm shifts over time. Through this work, we demonstrate how thinking with critical theories such as deconstruction and genealogy can reframe \"success\" in visual data storytelling and diversify visualization research outcomes. These efforts push the ways in which we as researchers produce domain knowledge to examine the sociotechnical issues of today's values towards datafication and data visualization. All supplemental materials for this work are available at osf.io/5fr48.",
      "authors": [
        "Ke Er Amy Zhang",
        "Jodie Jenkinson",
        "Laura Garrison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T16:26:44+00:00",
          "link": "https://arxiv.org/abs/2507.12377v1",
          "size": "8945kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:24:57+00:00",
          "link": "https://arxiv.org/abs/2507.12377v2",
          "size": "8945kb",
          "version": "v2"
        }
      ],
      "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12377",
        "HTML": "https://arxiv.org/html/2507.12377v2",
        "PDF": "https://arxiv.org/pdf/2507.12377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses implicit beliefs and paradigms in visual data journalism, providing a deconstruction of language meanings but does not mention any LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12418",
      "abstract": "The Number Theoretic Transform (NTT) is a fundamental operation in privacy-preserving technologies, particularly within fully homomorphic encryption (FHE). The efficiency of NTT computation directly impacts the overall performance of FHE, making hardware acceleration a critical technology that will enable realistic FHE applications. Custom accelerators, in FPGAs or ASICs, offer significant performance advantages due to their ability to exploit massive parallelism and specialized optimizations. However, the operation of NTT over large moduli requires large word-length modulo arithmetic that limits achievable clock frequencies in hardware and increases hardware area costs. To overcome such deficits, digit-serial arithmetic has been explored for modular multiplication and addition independently. The goal of this work is to leverage digit-serial modulo arithmetic combined with appropriate redundant data representation to design modular pipelined NTT accelerators that operate uniformly on arbitrary small digits, without the need for intermediate (de)serialization. The proposed architecture enables high clock frequencies through regular pipelining while maintaining parallelism. Experimental results demonstrate that the proposed approach outperforms state-of-the-art implementations and reduces hardware complexity under equal performance and input-output bandwidth constraints.",
      "authors": [
        "George Alexakis",
        "Dimitrios Schoinianakis and Giorgos Dimitrakopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:08:36+00:00",
          "link": "https://arxiv.org/abs/2507.12418v1",
          "size": "4855kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T10:09:10+00:00",
          "link": "https://arxiv.org/abs/2507.12418v2",
          "size": "4855kb",
          "version": "v2"
        }
      ],
      "title": "High-Performance Pipelined NTT Accelerators with Homogeneous Digit-Serial Modulo Arithmetic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12418",
        "HTML": "https://arxiv.org/html/2507.12418v2",
        "PDF": "https://arxiv.org/pdf/2507.12418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on improving efficiency in NTT computation for homomorphic encryption with digit-serial modulo arithmetic, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12440",
      "abstract": "Real robot data collection for imitation learning has led to significant advancements in robotic manipulation. However, the requirement for robot hardware in the process fundamentally constrains the scale of the data. In this paper, we explore training Vision-Language-Action (VLA) models using egocentric human videos. The benefit of using human videos is not only for their scale but more importantly for the richness of scenes and tasks. With a VLA trained on human video that predicts human wrist and hand actions, we can perform Inverse Kinematics and retargeting to convert the human actions to robot actions. We fine-tune the model using a few robot manipulation demonstrations to obtain the robot policy, namely EgoVLA. We propose a simulation benchmark called Ego Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation tasks with demonstrations. We fine-tune and evaluate EgoVLA with Ego Humanoid Manipulation Benchmark and show significant improvements over baselines and ablate the importance of human data. Videos can be found on our website: https://rchalyang.github.io/EgoVLA",
      "authors": [
        "Ruihan Yang",
        "Qinxi Yu",
        "Yecheng Wu",
        "Rui Yan",
        "Borui Li",
        "An-Chieh Cheng",
        "Xueyan Zou",
        "Yunhao Fang",
        "Hongxu Yin",
        "Sifei Liu",
        "Song Han",
        "Yao Lu",
        "Xiaolong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.12440v1",
          "size": "45829kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:30:47+00:00",
          "link": "https://arxiv.org/abs/2507.12440v2",
          "size": "45829kb",
          "version": "v2"
        }
      ],
      "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12440",
        "HTML": "https://arxiv.org/html/2507.12440v2",
        "PDF": "https://arxiv.org/pdf/2507.12440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores training Vision-Language-Action models with human videos for robotic applications and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.12465",
      "abstract": "3D modeling is moving from virtual to physical. Existing 3D generation primarily emphasizes geometries and textures while neglecting physical-grounded modeling. Consequently, despite the rapid development of 3D generative models, the synthesized 3D assets often overlook rich and important physical properties, hampering their real-world application in physical domains like simulation and embodied AI. As an initial attempt to address this challenge, we propose \\textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we present PhysXNet - the first physics-grounded 3D dataset systematically annotated across five foundational dimensions: absolute scale, material, affordance, kinematics, and function description. In particular, we devise a scalable human-in-the-loop annotation pipeline based on vision-language models, which enables efficient creation of physics-first assets from raw 3D assets.2) Furthermore, we propose \\textbf{PhysXGen}, a feed-forward framework for physics-grounded image-to-3D asset generation, injecting physical knowledge into the pre-trained 3D structural space. Specifically, PhysXGen employs a dual-branch architecture to explicitly model the latent correlations between 3D structures and physical properties, thereby producing 3D assets with plausible physical predictions while preserving the native geometry quality. Extensive experiments validate the superior performance and promising generalization capability of our framework. All the code, data, and models will be released to facilitate future research in generative physical AI.",
      "authors": [
        "Ziang Cao",
        "Zhaoxi Chen",
        "Liang Pan",
        "Ziwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-16T17:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.12465v1",
          "size": "3895kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T05:11:34+00:00",
          "link": "https://arxiv.org/abs/2507.12465v2",
          "size": "3895kb",
          "version": "v2"
        }
      ],
      "title": "PhysX: Physical-Grounded 3D Asset Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.12465",
        "HTML": "https://arxiv.org/html/2507.12465v2",
        "PDF": "https://arxiv.org/pdf/2507.12465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents PhysX, which focuses on 3D asset generation with physical-grounded properties, irrelevant to data processing for training large language models."
      },
      "datasets": [
        {
          "dataset_name": "Caoza/PhysX",
          "downloads": "1065",
          "likes": "5",
          "link": "https://huggingface.co/datasets/Caoza/PhysX"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2301.08292",
      "abstract": "Binary neural networks, i.e., neural networks whose parameters and activations are constrained to only two possible values, offer a compelling avenue for the deployment of deep learning models on energy- and memory-limited devices. However, their training, architectural design, and hyperparameter tuning remain challenging as these involve multiple computationally expensive combinatorial optimization problems. Here we introduce quantum hypernetworks as a mechanism to train binary neural networks on quantum computers, which unify the search over parameters, hyperparameters, and architectures in a single optimization loop. Through classical simulations, we demonstrate that our approach effectively finds optimal parameters, hyperparameters and architectural choices with high probability on classification problems including a two-dimensional Gaussian dataset and a scaled-down version of the MNIST handwritten digits. We represent our quantum hypernetworks as variational quantum circuits, and find that an optimal circuit depth maximizes the probability of finding performant binary neural networks. Our unified approach provides an immense scope for other applications in the field of machine learning.",
      "authors": [
        "Juan Carrasquilla",
        "Mohamed Hibat-Allah",
        "Estelle Inack",
        "Alireza Makhzani",
        "Kirill Neklyudov",
        "Graham W. Taylor",
        "Giacomo Torlai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-19T20:06:48+00:00",
          "link": "https://arxiv.org/abs/2301.08292v1",
          "size": "19541kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T20:18:02+00:00",
          "link": "https://arxiv.org/abs/2301.08292v2",
          "size": "4269kb",
          "version": "v2"
        }
      ],
      "title": "Quantum HyperNetworks: Training Binary Neural Networks in Quantum Superposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.08292",
        "HTML": "https://arxiv.org/html/2301.08292v2",
        "PDF": "https://arxiv.org/pdf/2301.08292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces quantum hypernetworks for training binary neural networks. The focus is on optimization and computational methodologies specific to quantum computing, not related to LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization"
      ],
      "repo_urls": [
        "https://github.com/carrasqu/binncode",
        "https://github.com/GTorlai/PastaQ.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.09701",
      "abstract": "Clustering is one of the most important tools for analysis of large datasets, and perhaps the most popular clustering algorithm is Lloyd's algorithm for $k$-means. This algorithm takes $n$ vectors $V=[v_1,\\dots,v_n]\\in\\mathbb{R}^{d\\times n}$ and outputs $k$ centroids $c_1,\\dots,c_k\\in\\mathbb{R}^d$; these partition the vectors into clusters based on which centroid is closest to a particular vector. We present a classical $\\varepsilon$-$k$-means algorithm that performs an approximate version of one iteration of Lloyd's algorithm with time complexity $\\tilde{O}\\big(\\frac{\\|V\\|_F^2}{n}\\frac{k^{2}d}{\\varepsilon^2}(k + \\log{n})\\big)$, exponentially improving the dependence on the data size $n$ and matching that of the \"$q$-means\" quantum algorithm originally proposed by Kerenidis, Landman, Luongo, and Prakash (NeurIPS'19). Moreover, we propose an improved $q$-means quantum algorithm with time complexity $\\tilde{O}\\big(\\frac{\\|V\\|_F}{\\sqrt{n}}\\frac{k^{3/2}d}{\\varepsilon}(\\sqrt{k}+\\sqrt{d})(\\sqrt{k} + \\log{n})\\big)$ that quadratically improves the runtime of our classical $\\varepsilon$-$k$-means algorithm in several parameters. Our quantum algorithm does not rely on quantum linear algebra primitives of prior work, but instead only uses QRAM to prepare simple states based on the current iteration's clusters and multivariate quantum amplitude estimation. Finally, we provide classical and quantum query lower bounds, showing that our algorithms are optimal in most parameters.",
      "authors": [
        "Arjan Cornelissen",
        "Joao F. Doriguello",
        "Alessandro Luongo",
        "Ewin Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-18T17:52:12+00:00",
          "link": "https://arxiv.org/abs/2308.09701v1",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T17:47:44+00:00",
          "link": "https://arxiv.org/abs/2308.09701v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T16:35:19+00:00",
          "link": "https://arxiv.org/abs/2308.09701v3",
          "size": "34kb",
          "version": "v3"
        }
      ],
      "title": "Do you know what q-means?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09701",
        "HTML": "https://arxiv.org/html/2308.09701v3",
        "PDF": "https://arxiv.org/pdf/2308.09701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents clustering algorithms for large datasets, employing classical and quantum computing, without addressing any specific LLM training data processing operations."
      },
      "tasks": [
        "Clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.06194",
      "abstract": "We study the problem of distributed online control of networked systems with time-varying cost functions and disturbances, where each node only has local information of the states and forecasts of the costs and disturbances. We develop a distributed truncated predictive control (DTPC) algorithm, where each node solves a ``truncated'' predictive optimal control problem with horizon $k$, but only involving nodes in a $\\kappa$-hop neighborhood (ignoring nodes outside). We show that the DTPC algorithm satisfies input-to-state stability (ISS) bounds and has regret decaying exponentially in $k$ and $\\kappa$, meaning a short predictive horizon $k$ and a small truncation radius $\\kappa$ is sufficient to achieve near-optimal performance. Furthermore, we show that when the future costs and disturbances are not exactly known, the regret has exponentially decaying sensitivity to the forecast errors in terms of predictive horizon, meaning near-term forecast errors play a much more important role than longer-term forecasts.",
      "authors": [
        "Eric Xu",
        "Soummya Kar",
        "Guannan Qu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-09T22:47:04+00:00",
          "link": "https://arxiv.org/abs/2310.06194v1",
          "size": "93kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:19:36+00:00",
          "link": "https://arxiv.org/abs/2310.06194v2",
          "size": "172kb",
          "version": "v2"
        }
      ],
      "title": "Distributed Truncated Predictive Control for Networked Systems under Uncertainty: Stability and Near-Optimality Guarantee",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.06194",
        "HTML": "https://arxiv.org/html/2310.06194v2",
        "PDF": "https://arxiv.org/pdf/2310.06194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study addresses distributed online control for networked systems, focusing on stability and performance under uncertainty, without any connection to LLM pretraining or fine-tuning training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.08209",
      "abstract": "Regression on manifolds, and, more broadly, statistics on manifolds, has garnered significant importance in recent years due to the vast number of applications for non Euclidean data. Circular data is a classic example, but so is data in the space of covariance matrices, data on the Grassmannian manifold obtained as a result of principal component analysis, among many others. In this work we investigate prediction sets for regression scenarios when the response variable, denoted by $Y$, resides in a manifold, and the covariable, denoted by $X$, lies in an Euclidean space. This extends the concepts delineated in \\cite{waser14} to this novel context. Aligning with traditional principles in conformal inference, these prediction sets are distribution-free, indicating that no specific assumptions are imposed on the joint distribution of $(X,Y)$, and they maintain a non-parametric character. We prove the asymptotic almost sure convergence of the empirical version of these regions on the manifold to their population counterparts. The efficiency of this method is shown through a comprehensive simulation study and an analysis involving real-world data.",
      "authors": [
        "Alejandro Cholaquidis",
        "Fabrice Gamboa",
        "Leonardo Moreno"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-12T10:56:25+00:00",
          "link": "https://arxiv.org/abs/2310.08209v1",
          "size": "719kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T21:07:06+00:00",
          "link": "https://arxiv.org/abs/2310.08209v2",
          "size": "3695kb",
          "version": "v2"
        }
      ],
      "title": "Conformal inference for regression on Riemannian Manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.08209",
        "HTML": "https://arxiv.org/html/2310.08209v2",
        "PDF": "https://arxiv.org/pdf/2310.08209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with conformal inference for regression on manifolds, specifically involving prediction sets, without making any contributions to LLM training data processing."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.11535",
      "abstract": "Optical blur is an inherent property of any lens system and is challenging to model in modern cameras because of their complex optical elements. To tackle this challenge, we introduce a high-dimensional neural representation of blur$-$$\\textit{the lens blur field}$$-$and a practical method for acquiring it. The lens blur field is a multilayer perceptron (MLP) designed to (1) accurately capture variations of the lens 2D point spread function over image plane location, focus setting and, optionally, depth and (2) represent these variations parametrically as a single, sensor-specific function. The representation models the combined effects of defocus, diffraction, aberration, and accounts for sensor features such as pixel color filters and pixel-specific micro-lenses. To learn the real-world blur field of a given device, we formulate a generalized non-blind deconvolution problem that directly optimizes the MLP weights using a small set of focal stacks as the only input. We also provide a first-of-its-kind dataset of 5D blur fields$-$for smartphone cameras, camera bodies equipped with a variety of lenses, etc. Lastly, we show that acquired 5D blur fields are expressive and accurate enough to reveal, for the first time, differences in optical behavior of smartphone devices of the same make and model. Code and data can be found at blur-fields.github.io.",
      "authors": [
        "Esther Y. H. Lin",
        "Zhecheng Wang",
        "Rebecca Lin",
        "Daniel Miau",
        "Florian Kainz",
        "Jiawen Chen",
        "Xuaner Cecilia Zhang",
        "David B. Lindell",
        "Kiriakos N. Kutulakos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-17T19:10:45+00:00",
          "link": "https://arxiv.org/abs/2310.11535v1",
          "size": "7666kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T03:42:51+00:00",
          "link": "https://arxiv.org/abs/2310.11535v2",
          "size": "31583kb",
          "version": "v2"
        }
      ],
      "title": "Learning Lens Blur Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.11535",
        "HTML": "https://arxiv.org/html/2310.11535v2",
        "PDF": "https://arxiv.org/pdf/2310.11535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on modeling lens blur in cameras, introducing a neural representation called the lens blur field, but it does not contribute to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2310.14890",
      "abstract": "This paper tackles the problem of the worst-class error rate, instead of the standard error rate averaged over all classes. For example, a three-class classification task with class-wise error rates of 10%, 10%, and 40% has a worst-class error rate of 40%, whereas the average is 20% under the class-balanced condition. The worst-class error is important in many applications. For example, in a medical image classification task, it would not be acceptable for the malignant tumor class to have a 40% error rate, while the benign and healthy classes have a 10% error rates. To avoid overfitting in worst-class error minimization using Deep Neural Networks (DNNs), we design a problem formulation for bounding the worst-class error instead of achieving zero worst-class error. Moreover, to correctly bound the worst-class error, we propose a boosting approach which ensembles DNNs. We give training and generalization worst-class-error bound. Experimental results show that the algorithm lowers worst-class test error rates while avoiding overfitting to the training set. This code is available at https://github.com/saito-yuya/Bounding-the-Worst-class-error-A-Boosting-Approach.",
      "authors": [
        "Yuya Saito",
        "Shinnosuke Matsuo",
        "Seiichi Uchida",
        "Daiki Suehiro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-20T07:49:10+00:00",
          "link": "https://arxiv.org/abs/2310.14890v1",
          "size": "6436kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:13:38+00:00",
          "link": "https://arxiv.org/abs/2310.14890v2",
          "size": "12931kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T14:56:17+00:00",
          "link": "https://arxiv.org/abs/2310.14890v3",
          "size": "12932kb",
          "version": "v3"
        }
      ],
      "title": "Bounding the Worst-class Error: A Boosting Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.14890",
        "HTML": "https://arxiv.org/html/2310.14890v3",
        "PDF": "https://arxiv.org/pdf/2310.14890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses bounding the worst-class error in classification problems using a boosting approach, which does not relate to data processing for LLM pretraining or fine-tuning."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Medical Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.18963",
      "abstract": "The exploration of new problem classes for quantum computation is an active area of research. In this paper, we introduce and solve a novel problem class related to dynamics on large-scale networks relevant to neurobiology and machine learning. Specifically, we ask if a network can sustain inherent dynamic activity beyond some arbitrary observation time or if the activity ceases through quiescence or saturation via an epileptic-like state. We show that this class of problems can be formulated and structured to take advantage of quantum superposition and solved efficiently using a coupled workflow between the Grover and Deutsch-Jozsa quantum algorithms. To do so, we extend their functionality to address the unique requirements of how input (sub)sets into the algorithms must be mathematically structured while simultaneously constructing the inputs so that measurement outputs can be interpreted as meaningful properties of the network dynamics. This, in turn, allows us to answer the question we pose.",
      "authors": [
        "Gabriel A. Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-27T19:16:56+00:00",
          "link": "https://arxiv.org/abs/2403.18963v1",
          "size": "718kb",
          "version": "v1"
        },
        {
          "date": "2024-12-13T01:57:16+00:00",
          "link": "https://arxiv.org/abs/2403.18963v2",
          "size": "518kb",
          "version": "v2"
        },
        {
          "date": "2025-01-21T02:28:29+00:00",
          "link": "https://arxiv.org/abs/2403.18963v3",
          "size": "2838kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T20:09:52+00:00",
          "link": "https://arxiv.org/abs/2403.18963v4",
          "size": "2841kb",
          "version": "v4"
        }
      ],
      "title": "Leveraging Quantum Superposition to Infer the Dynamic Behavior of a Spatial-Temporal Neural Network Signaling Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.18963",
        "HTML": "https://arxiv.org/html/2403.18963v4",
        "PDF": "https://arxiv.org/pdf/2403.18963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the dynamic behavior of network models through quantum computation techniques, not touching on LLM training data processing or any supportive dataset operations for LLM models."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/gabe-alex-silva/network_dynamics_quantumsim"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.09298",
      "abstract": "AI-based models for histopathology whole slide image (WSI) analysis are increasingly common, but unsharp or blurred areas within WSI can significantly reduce prediction performance. In this study, we investigated the effect of image blur on deep learning models and introduced a mixture of experts (MoE) strategy that combines predictions from multiple expert models trained on data with varying blur levels. Using H&E-stained WSIs from 2,093 breast cancer patients, we benchmarked performance on grade classification and IHC biomarker prediction with both CNN- (CNN_CLAM and MoE-CNN_CLAM) and Vision Transformer-based (UNI_CLAM and MoE-UNI_CLAM) models. Our results show that baseline models' performance consistently decreased with increasing blur, but expert models trained on blurred tiles and especially our proposed MoE approach substantially improved performance, and outperformed baseline models in a range of simulated scenarios. MoE-CNN_CLAM outperformed the baseline CNN_CLAM under moderate (AUC: 0.868 vs. 0.702) and mixed blur conditions (AUC: 0.890 vs. 0.875). MoE-UNI_CLAM outperformed the baseline UNI_CLAM model in both moderate (AUC: 0.950 vs. 0.928) and mixed blur conditions (AUC: 0.944 vs. 0.931). This MoE method has the potential to enhance the reliability of AI-based pathology models under variable image quality, supporting broader application in both research and clinical settings.",
      "authors": [
        "Yujie Xiang",
        "Bojing Liu",
        "Mattias Rantalainen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-15T12:40:41+00:00",
          "link": "https://arxiv.org/abs/2405.09298v1",
          "size": "4206kb",
          "version": "v1"
        },
        {
          "date": "2024-05-21T08:55:25+00:00",
          "link": "https://arxiv.org/abs/2405.09298v2",
          "size": "4205kb",
          "version": "v2"
        },
        {
          "date": "2024-05-23T18:55:39+00:00",
          "link": "https://arxiv.org/abs/2405.09298v3",
          "size": "4205kb",
          "version": "v3"
        },
        {
          "date": "2025-07-16T21:03:21+00:00",
          "link": "https://arxiv.org/abs/2405.09298v4",
          "size": "3180kb",
          "version": "v4"
        }
      ],
      "title": "Deep Blur Multi-Model (DeepBlurMM) -- a strategy to mitigate the impact of image blur on deep learning model performance in histopathology image analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09298",
        "PDF": "https://arxiv.org/pdf/2405.09298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates deep learning model performance on histopathology images and a strategy to mitigate image blur, unrelated to LLM training data processing as it deals with image analysis rather than language data preparation."
      },
      "tasks": [
        "Binary Classification",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.17385",
      "abstract": "The standard approach to causal modelling especially in social and health sciences is the potential outcomes framework due to Neyman and Rubin. In this framework, observations are thought to be drawn from a distribution over variables of interest, and the goal is to identify parameters of this distribution. Even though the stated goal is often to inform decision making on some target population, there is no straightforward way to include these target populations in the framework. Instead of modelling the relationship between the observed sample and the target population, the inductive assumptions in this framework take the form of abstract sampling and independence assumptions. In this paper, we develop a version of this framework that construes causal inference as treatment-wise predictions for finite populations where all assumptions are testable in retrospect; this means that one can not only test predictions themselves (without any fundamental problem) but also investigate sources of error when they fail. Due to close connections to the original framework, established methods can still be be analysed under the new framework.",
      "authors": [
        "Benedikt H\\\"oltgen and Robert C. Williamson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T16:07:57+00:00",
          "link": "https://arxiv.org/abs/2407.17385v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2024-08-14T13:01:52+00:00",
          "link": "https://arxiv.org/abs/2407.17385v2",
          "size": "326kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T07:10:43+00:00",
          "link": "https://arxiv.org/abs/2407.17385v3",
          "size": "267kb",
          "version": "v3"
        }
      ],
      "title": "Formalising causal inference as prediction on a target population",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17385",
        "HTML": "https://arxiv.org/html/2407.17385v3",
        "PDF": "https://arxiv.org/pdf/2407.17385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves causal inference and prediction on target populations, which is not related to LLM training data processing."
      },
      "tasks": [
        "Causal Inference",
        "counterfactual"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19086",
      "abstract": "With a potentially increasing share of the electricity grid relying on wind to provide generating capacity and energy, there is an expanding global need for historically accurate, spatiotemporally continuous, high-resolution wind data. Conventional downscaling methods for generating these data based on numerical weather prediction have a high computational burden and require extensive tuning for historical accuracy. In this work, we present a novel deep learning-based spatiotemporal downscaling method using generative adversarial networks (GANs) for generating historically accurate high-resolution wind resource data from the European Centre for Medium-Range Weather Forecasting Reanalysis version 5 data (ERA5). In contrast to previous approaches, which used coarsened high-resolution data as low-resolution training data, we use true low-resolution simulation outputs. We show that by training a GAN model with ERA5 as the low-resolution input and Wind Integration National Dataset Toolkit (WTK) data as the high-resolution target, we achieved results comparable in historical accuracy and spatiotemporal variability to conventional dynamical downscaling. This GAN-based downscaling method additionally reduces computational costs over dynamical downscaling by two orders of magnitude. We applied this approach to downscale 30 km, hourly ERA5 data to 2 km, 5 min wind data for January 2000 through December 2023 at multiple hub heights over Ukraine, Moldova, and part of Romania. This 24-year data record is the first member of the super-resolution for renewable energy resource data with wind from the reanalysis data dataset (Sup3rWind).",
      "authors": [
        "Brandon N. Benton",
        "Grant Buster",
        "Pavlo Pinchuk",
        "Andrew Glaws",
        "Ryan N. King",
        "Galen Maclaurin",
        "Ilya Chernyakhovskiy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-26T21:07:17+00:00",
          "link": "https://arxiv.org/abs/2407.19086v1",
          "size": "4712kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T13:01:22+00:00",
          "link": "https://arxiv.org/abs/2407.19086v2",
          "size": "3944kb",
          "version": "v2"
        }
      ],
      "title": "Super Resolution for Renewable Energy Resource Data With Wind From Reanalysis Data and Application to Ukraine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19086",
        "HTML": "https://arxiv.org/html/2407.19086v2",
        "PDF": "https://arxiv.org/pdf/2407.19086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating high-resolution wind data using GANs for renewable energy resource data, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Super-Resolution",
        "Weather Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19852",
      "abstract": "Quantum computing combined with machine learning (ML) is a highly promising research area, with numerous studies demonstrating that quantum machine learning (QML) is expected to solve scientific problems more effectively than classical ML. In this work, we present Quantum Long Short-Term Memory (QLSTM), a QML architecture, and demonstrate its effectiveness in drug discovery. We evaluate QLSTM on five benchmark datasets (BBBP, BACE, SIDER, BCAP37, T-47D), and observe consistent performance gains over classical LSTM, with ROC-AUC improvements ranging from 3% to over 6%. Furthermore, QLSTM exhibits improved predictive accuracy as the number of qubits increases, and faster convergence than classical LSTM under the same training conditions. Notably, QLSTM maintains strong robustness against quantum computer noise, outperforming noise-free classical LSTM in certain settings. These findings highlight the potential of QLSTM as a scalable and noise-resilient model for scientific applications, particularly as quantum hardware continues to advance in qubit capacity and fidelity.",
      "authors": [
        "Liang Zhang",
        "Yin Xu",
        "Mohan Wu",
        "Liang Wang and Hua Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T10:10:03+00:00",
          "link": "https://arxiv.org/abs/2407.19852v1",
          "size": "522kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:06:45+00:00",
          "link": "https://arxiv.org/abs/2407.19852v2",
          "size": "849kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Long Short-Term Memory for Drug Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19852",
        "PDF": "https://arxiv.org/pdf/2407.19852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores Quantum Long Short-Term Memory for drug discovery applications and does not relate to LLM training data processing."
      },
      "tasks": [
        "Drug Discovery",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.10996",
      "abstract": "Let $\\Omega\\subset \\mathbb{R}^d$ be a bounded domain. We consider the problem of how efficiently shallow neural networks with the ReLU$^k$ activation function can approximate functions from Sobolev spaces $W^s(L_p(\\Omega))$ with error measured in the $L_q(\\Omega)$-norm. Utilizing the Radon transform and recent results from discrepancy theory, we provide a simple proof of nearly optimal approximation rates in a variety of cases, including when $q\\leq p$, $p\\geq 2$, and $s \\leq k + (d+1)/2$. The rates we derive are optimal up to logarithmic factors, and significantly generalize existing results. An interesting consequence is that the adaptivity of shallow ReLU$^k$ neural networks enables them to obtain optimal approximation rates for smoothness up to order $s = k + (d+1)/2$, even though they represent piecewise polynomials of fixed degree $k$.",
      "authors": [
        "Tong Mao",
        "Jonathan W. Siegel",
        "Jinchao Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T16:43:45+00:00",
          "link": "https://arxiv.org/abs/2408.10996v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:55:31+00:00",
          "link": "https://arxiv.org/abs/2408.10996v2",
          "size": "19kb",
          "version": "v2"
        }
      ],
      "title": "Approximation Rates for Shallow ReLU$^k$ Neural Networks on Sobolev Spaces via the Radon Transform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10996",
        "HTML": "https://arxiv.org/html/2408.10996v2",
        "PDF": "https://arxiv.org/pdf/2408.10996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around the mathematical analysis of neural network approximation capabilities and does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.06152",
      "abstract": "Quantum repeaters are an essential building block for realizing long-distance quantum communications. However, due to the fragile nature of quantum information, these repeaters suffer from loss and operational errors. Prior works have classified repeaters into three broad categories based on their use of probabilistic or near-deterministic methods to mitigate these errors. Besides differences in classical communication times, these approaches also vary in technological complexity, with near-deterministic methods requiring more advanced hardware. Recent increases in memory availability and advances in multiplexed entanglement generation motivate a fresh comparison of one-way and two-way repeater architectures.\n  In this work, we present a two-way repeater protocol that combines multiplexing with application-aware distillation, designed for a setting where sufficient high-quality memory resources are available -- reflecting architectural assumptions expected in large-scale network deployments. We introduce a recursive formulation to track the full probability distribution of Bell pairs in multiplexed two-way repeater architectures, enabling the performance analysis of multiplexed repeater schemes which use probabilistic $n$-to-$k$ distillation. Using this framework, we compare the proposed two-way protocol with one-way schemes in parameter regimes previously believed to favour the latter, and find that the two-way architecture consistently outperforms one-way protocols while requiring lower technological and resource overheads.",
      "authors": [
        "Prateek Mantri",
        "Kenneth Goodenough",
        "and Don Towsley"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T01:55:01+00:00",
          "link": "https://arxiv.org/abs/2409.06152v1",
          "size": "804kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T21:31:24+00:00",
          "link": "https://arxiv.org/abs/2409.06152v2",
          "size": "864kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T18:17:01+00:00",
          "link": "https://arxiv.org/abs/2409.06152v3",
          "size": "819kb",
          "version": "v3"
        }
      ],
      "title": "Comparing One- and Two-way Quantum Repeater Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06152",
        "HTML": "https://arxiv.org/html/2409.06152v3",
        "PDF": "https://arxiv.org/pdf/2409.06152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper delves into quantum repeater architectures for quantum communications, which has no connection to LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02208",
      "abstract": "Feature selection is a critical task in machine learning and statistics. However, existing feature selection methods either (i) rely on parametric methods such as linear or generalized linear models, (ii) lack theoretical false discovery control, or (iii) identify few true positives. Here, we introduce a general feature selection method with finite-sample false discovery control based on applying integrated path stability selection (IPSS) to arbitrary feature importance scores. The method is nonparametric whenever the importance scores are nonparametric, and it estimates q-values, which are better suited to high-dimensional data than p-values. We focus on two special cases using importance scores from gradient boosting (IPSSGB) and random forests (IPSSRF). Extensive nonlinear simulations with RNA sequencing data show that both methods accurately control the false discovery rate and detect more true positives than existing methods. Both methods are also efficient, running in under 20 seconds when there are 500 samples and 5000 features. We apply IPSSGB and IPSSRF to detect microRNAs and genes related to cancer, finding that they yield better predictions with fewer features than existing approaches.",
      "authors": [
        "Omar Melikechi",
        "David B. Dunson",
        "and Jeffrey W. Miller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T04:42:28+00:00",
          "link": "https://arxiv.org/abs/2410.02208v1",
          "size": "6176kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T14:02:50+00:00",
          "link": "https://arxiv.org/abs/2410.02208v2",
          "size": "10555kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T19:29:37+00:00",
          "link": "https://arxiv.org/abs/2410.02208v3",
          "size": "10555kb",
          "version": "v3"
        }
      ],
      "title": "Nonparametric IPSS: Fast, flexible feature selection with false discovery control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02208",
        "HTML": "https://arxiv.org/html/2410.02208v3",
        "PDF": "https://arxiv.org/pdf/2410.02208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a feature selection method with false discovery control, focusing on data analysis techniques rather than data processing for LLM training."
      },
      "tasks": [
        "Feature Importance",
        "feature selection"
      ],
      "repo_urls": [
        "https://github.com/omelikechi/ipssr",
        "https://github.com/omelikechi/ipss_bioinformatics",
        "https://github.com/omelikechi/ipss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06187",
      "abstract": "The minimum sum-of-squares clustering problem (MSSC), also known as $k$-means clustering, refers to the problem of partitioning $n$ data points into $k$ clusters, with the objective of minimizing the total sum of squared Euclidean distances between each point and the center of its assigned cluster. We propose an efficient algorithm for solving large-scale MSSC instances, which combines column generation (CG) with dynamic constraint aggregation (DCA) to effectively reduce the number of constraints considered in the CG master problem. DCA was originally conceived to reduce degeneracy in set partitioning problems by utilizing an aggregated restricted master problem obtained from a partition of the set partitioning constraints into disjoint clusters. In this work, we explore the use of DCA within a CG algorithm for MSSC exact solution. Our method is fine-tuned by a series of ablation studies on DCA design choices, and is demonstrated to significantly outperform existing state-of-the-art exact approaches available in the literature.",
      "authors": [
        "Antonio M. Sudoso",
        "Daniel Aloise"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T16:51:28+00:00",
          "link": "https://arxiv.org/abs/2410.06187v1",
          "size": "334kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:32:24+00:00",
          "link": "https://arxiv.org/abs/2410.06187v2",
          "size": "133kb",
          "version": "v2"
        }
      ],
      "title": "A column generation algorithm with dynamic constraint aggregation for minimum sum-of-squares clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06187",
        "HTML": "https://arxiv.org/html/2410.06187v2",
        "PDF": "https://arxiv.org/pdf/2410.06187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on an algorithm for solving minimum sum-of-squares clustering problems, and does not relate to LLM training data processing."
      },
      "tasks": [
        "Clustering"
      ],
      "repo_urls": [
        "https://github.com/antoniosudoso/mssc-dca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11751",
      "abstract": "Sandqvist gave a proof-theoretic semantics (P-tS) for classical logic (CL) that explicates the meaning of the connectives without assuming bivalance. Later, he gave a semantics for intuitionistic propositional logic (IPL). While soundness in both cases is proved through standard techniques, the proof completeness for CL is complex and somewhat obscure, but clear and simple for IPL. Makinson gave a simplified proof of completeness for classical propositional logic (CPL) by directly relating the the P-tS to the logic's extant truth-functional semantics. In this paper, we give an elementary, constructive, and native -- in the sense that it does not presuppose the model-theoretic interpretation of classical logic -- proof of completeness the P-tS of CL using the techniques applies for IPL. Simultaneously, we give a proof of soundness and completeness for first-order intuitionistic logic (IL).",
      "authors": [
        "Alexander V. Gheorghiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T16:25:43+00:00",
          "link": "https://arxiv.org/abs/2410.11751v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:07:49+00:00",
          "link": "https://arxiv.org/abs/2410.11751v2",
          "size": "36kb",
          "version": "v2"
        }
      ],
      "title": "Proof-theoretic Semantics for First-order Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11751",
        "HTML": "https://arxiv.org/html/2410.11751v2",
        "PDF": "https://arxiv.org/pdf/2410.11751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses proof-theoretic semantics for first-order and intuitionistic logic, which is not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09636",
      "abstract": "We consider a class of Wasserstein distributionally robust Nash equilibrium problems, where agents construct heterogeneous data-driven Wasserstein ambiguity sets using private samples and radii, in line with their individual risk-averse behaviour. By leveraging relevant properties of this class of games, we show that equilibria of the original seemingly infinite-dimensional problem can be obtained as a solution to a finite-dimensional Nash equilibrium problem. We then reformulate the problem as a finite-dimensional variational inequality and establish the connection between the corresponding solution sets. Our reformulation has scalable behaviour with respect to the data size and maintains a fixed number of constraints, independently of the number of samples. To compute a solution, we leverage two algorithms, based on the golden ratio algorithm. The efficiency of both algorithmic schemes is corroborated through extensive simulation studies on an illustrative example and a stochastic portfolio allocation game, where behavioural coupling among investors is modeled.",
      "authors": [
        "Georgios Pantazis",
        "Reza Rahimi Baghbadorani",
        "Sergio Grammatico"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T18:03:12+00:00",
          "link": "https://arxiv.org/abs/2411.09636v1",
          "size": "1920kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T16:50:06+00:00",
          "link": "https://arxiv.org/abs/2411.09636v2",
          "size": "2164kb",
          "version": "v2"
        }
      ],
      "title": "Nash equilibrium seeking for a class of quadratic-bilinear Wasserstein distributionally robust games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09636",
        "HTML": "https://arxiv.org/html/2411.09636v2",
        "PDF": "https://arxiv.org/pdf/2411.09636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses Nash equilibrium problems in Wasserstein distributionally robust games, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.17571",
      "abstract": "White Matter Hyperintensities (WMH) are key neuroradiological markers of small vessel disease present in brain MRI. Assessment of WMH is important in research and clinics. However, WMH are challenging to segment due to their high variability in shape, location, size, poorly defined borders, and similar intensity profile to other pathologies (e.g stroke lesions) and artefacts (e.g head motion). In this work, we assess the utility and semantic properties of the most effective techniques for uncertainty quantification (UQ) in segmentation for the WMH segmentation task across multiple test-time data distributions. We find UQ techniques reduce 'silent failure' by identifying in UQ maps small WMH clusters in the deep white matter that are unsegmented by the model. A combination of Stochastic Segmentation Networks with Deep Ensembles also yields the highest Dice and lowest Absolute Volume Difference % (AVD) score and can highlight areas where there is ambiguity between WMH and stroke lesions. We further demonstrate the downstream utility of UQ, proposing a novel method for classification of the clinical Fazekas score using spatial features extracted from voxelwise WMH probability and UQ maps. We show that incorporating WMH uncertainty information improves Fazekas classification performance and calibration. Our model with (UQ and spatial WMH features)/(spatial WMH features)/(WMH volume only) achieves a balanced accuracy score of 0.74/0.67/0.62, and root brier score of 0.65/0.72/0.74 in the Deep WMH and balanced accuracy of 0.74/0.73/0.71 and root brier score of 0.64/0.66/0.68 in the Periventricular region. We further demonstrate that stochastic UQ techniques with high sample diversity can improve the detection of poor quality segmentations.",
      "authors": [
        "Ben Philps",
        "Maria del C. Valdes Hernandez",
        "Chen Qin",
        "Una Clancy",
        "Eleni Sakka",
        "Susana Munoz Maniega",
        "Mark E. Bastin",
        "Angela C.C. Jochems",
        "Joanna M. Wardlaw",
        "Miguel O. Bernabeu",
        "Alzheimers Disease Neuroimaging Initiative"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-26T16:34:24+00:00",
          "link": "https://arxiv.org/abs/2411.17571v1",
          "size": "11829kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T12:24:49+00:00",
          "link": "https://arxiv.org/abs/2411.17571v2",
          "size": "17141kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty quantification for White Matter Hyperintensity segmentation detects silent failures and improves automated Fazekas quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17571",
        "PDF": "https://arxiv.org/pdf/2411.17571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on uncertainty quantification techniques for improving segmentation performance in medical imaging, specifically on White Matter Hyperintensities, with no relevance to LLM training data processing."
      },
      "tasks": [
        "Segmentation",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.11392",
      "abstract": "Reducing the bandwidth of speech is common practice in resource constrained environments like low-bandwidth speech transmission or low-complexity vocoding. We propose a lightweight and robust method for extending the bandwidth of wideband speech signals that is inspired by classical methods developed in the speech coding context. The resulting model has just ~370K parameters and a complexity of ~140 MFLOPS (or ~70 MMACS). With a frame size of 10 ms and a lookahead of only 0.27 ms, the model is well-suited for use with common wideband speech codecs. We evaluate the model's robustness by pairing it with the Opus SILK speech codec (1.5 release) and verify in a P.808 DCR listening test that it significantly improves quality from 6 to 12 kb/s. We also demonstrate that Opus 1.5 together with the proposed bandwidth extension at 9 kb/s meets the quality of 3GPP EVS at 9.6 kb/s and that of Opus 1.4 at 18 kb/s showing that the blind bandwidth extension can meet the quality of classical guided bandwidth extensions thus providing a way for backward-compatible quality improvement.",
      "authors": [
        "Jan B\\\"uthe",
        "Jean-Marc Valin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T02:38:32+00:00",
          "link": "https://arxiv.org/abs/2412.11392v1",
          "size": "220kb",
          "version": "v1"
        },
        {
          "date": "2025-01-28T03:52:15+00:00",
          "link": "https://arxiv.org/abs/2412.11392v2",
          "size": "220kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T02:58:40+00:00",
          "link": "https://arxiv.org/abs/2412.11392v3",
          "size": "228kb",
          "version": "v3"
        }
      ],
      "title": "A lightweight and robust method for blind wideband-to-fullband extension of speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11392",
        "HTML": "https://arxiv.org/html/2412.11392v3",
        "PDF": "https://arxiv.org/pdf/2412.11392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for bandwidth extension of speech signals, focusing on codec compatibility and quality improvement. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Bandwidth Extension"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01840",
      "abstract": "We introduce the spiked mixture model (SMM) to address the problem of estimating a set of signals from many randomly scaled and noisy observations. Subsequently, we design a novel expectation-maximization (EM) algorithm to recover all parameters of the SMM. Numerical experiments show that in low signal-to-noise ratio regimes, and for data types where the SMM is relevant, SMM surpasses the more traditional Gaussian mixture model (GMM) in terms of signal recovery performance. The broad relevance of the SMM and its corresponding EM recovery algorithm is demonstrated by applying the technique to different data types. The first case study is a biomedical research application, utilizing an imaging mass spectrometry dataset to explore the molecular content of a rat brain tissue section at micrometer scale. The second case study demonstrates SMM performance in a computer vision application, segmenting a hyperspectral imaging dataset into underlying patterns. While the measurement modalities differ substantially, in both case studies SMM is shown to recover signals that were missed by traditional methods such as k-means clustering and GMM.",
      "authors": [
        "Paul-Louis Delacour",
        "Sander Wahls",
        "Jeffrey M. Spraggins",
        "Lukasz Migas",
        "Raf Van de Plas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T14:43:57+00:00",
          "link": "https://arxiv.org/abs/2501.01840v1",
          "size": "23465kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:47:18+00:00",
          "link": "https://arxiv.org/abs/2501.01840v2",
          "size": "25295kb",
          "version": "v2"
        }
      ],
      "title": "Signal Recovery Using a Spiked Mixture Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01840",
        "HTML": "https://arxiv.org/html/2501.01840v2",
        "PDF": "https://arxiv.org/pdf/2501.01840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on signal recovery using a spiked mixture model and applies to domains like biomedical research and computer vision, not LLM training data processing."
      },
      "tasks": [
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06532",
      "abstract": "Accurate and reliable photometric redshift determination is one of the key aspects for wide-field photometric surveys. Determination of photometric redshift for galaxies, has been traditionally solved by use of machine-learning and artificial intelligence techniques trained on a calibration sample of galaxies, where both photometry and spectrometry are available. On this paper, we present a new algorithmic approach for determining photometric redshifts of galaxies using Conditional Generative Adversarial Networks (CGANs). The proposed implementation is able to determine both point-estimation and probability-density estimations for photometric redshifts. The methodology is tested with data from Dark Energy Survey (DES) Y1 data and compared with other existing algorithm such as a Mixture Density Network (MDN). Although results obtained show a superiority of MDN, CGAN quality-metrics are close to the MDN results, opening the door to the use of CGAN at photometric redshift estimation.",
      "authors": [
        "M. Garcia-Fernandez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-11T12:42:07+00:00",
          "link": "https://arxiv.org/abs/2501.06532v1",
          "size": "872kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T12:31:03+00:00",
          "link": "https://arxiv.org/abs/2501.06532v2",
          "size": "912kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T08:23:13+00:00",
          "link": "https://arxiv.org/abs/2501.06532v3",
          "size": "677kb",
          "version": "v3"
        }
      ],
      "title": "Determination of galaxy photometric redshifts using Conditional Generative Adversarial Networks (CGANs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06532",
        "HTML": "https://arxiv.org/html/2501.06532v3",
        "PDF": "https://arxiv.org/pdf/2501.06532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research deals with determining galaxy photometric redshifts using Conditional GANs, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Photometric Redshift Estimation"
      ],
      "repo_urls": [
        "https://github.com/mgarciafernandez-uem/cgan-photoz"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10161",
      "abstract": "Reasoning about fairness through correlation-based notions is rife with pitfalls. The 1973 University of California, Berkeley graduate school admissions case from Bickel et. al. (1975) is a classic example of one such pitfall, namely Simpson's paradox. The discrepancy in admission rates among males and female applicants, in the aggregate data over all departments, vanishes when admission rates per department are examined. We reason about the Berkeley graduate school admissions case through a causal lens. In the process, we introduce a statistical test for causal hypothesis testing based on Pearl's instrumental-variable inequalities (Pearl 1995). We compare different causal notions of fairness that are based on graphical, counterfactual and interventional queries on the causal model, and develop statistical tests for these notions that use only observational data. We study the logical relations between notions, and show that while notions may not be equivalent, their corresponding statistical tests coincide for the case at hand. We believe that a thorough case-based causal analysis helps develop a more principled understanding of both causal hypothesis testing and fairness.",
      "authors": [
        "Sourbh Bhadane",
        "Joris M. Mooij",
        "Philip Boeken",
        "and Onno Zoeter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Computers and Society (cs.CY)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T13:43:35+00:00",
          "link": "https://arxiv.org/abs/2502.10161v1",
          "size": "68kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T14:35:05+00:00",
          "link": "https://arxiv.org/abs/2502.10161v2",
          "size": "68kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting the Berkeley Admissions data: Statistical Tests for Causal Hypotheses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10161",
        "HTML": "https://arxiv.org/html/2502.10161v2",
        "PDF": "https://arxiv.org/pdf/2502.10161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines causal hypothesis testing in the context of fairness and admissions data, without addressing any aspect of LLM training data processing."
      },
      "tasks": [
        "counterfactual",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20881",
      "abstract": "The recent increase in computational resources and data availability has led to a significant rise in the use of Machine Learning (ML) techniques for data analysis in physics. However, the application of ML methods to solve differential equations capable of describing even complex physical systems is not yet fully widespread in theoretical high-energy physics. Hamiltonian Neural Networks (HNNs) are tools that minimize a loss function defined to solve Hamilton equations of motion. In this work, we implement several HNNs trained to solve, with high accuracy, the Hamilton equations for a massless probe moving inside a smooth and horizonless geometry known as D1-D5 circular fuzzball. We study both planar (equatorial) and non-planar geodesics in different regimes according to the impact parameter, some of which are unstable. Our findings suggest that HNNs could eventually replace standard numerical integrators, as they are equally accurate but more reliable in critical situations.",
      "authors": [
        "Andrea Cipriani",
        "Alessandro De Santis",
        "Giorgio Di Russo",
        "Alfredo Grillo",
        "Luca Tabarroni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Theory (hep-th)",
        "Machine Learning (cs.LG)",
        "General Relativity and Quantum Cosmology (gr-qc)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T09:25:49+00:00",
          "link": "https://arxiv.org/abs/2502.20881v1",
          "size": "9619kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T17:54:41+00:00",
          "link": "https://arxiv.org/abs/2502.20881v2",
          "size": "9620kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T20:56:26+00:00",
          "link": "https://arxiv.org/abs/2502.20881v3",
          "size": "9621kb",
          "version": "v3"
        }
      ],
      "title": "Hamiltonian Neural Networks approach to fuzzball geodesics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20881",
        "HTML": "https://arxiv.org/html/2502.20881v3",
        "PDF": "https://arxiv.org/pdf/2502.20881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work applies Hamiltonian Neural Networks to physics problems, not to LLMs or their data processing. There is no connection to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.04502",
      "abstract": "The analysis of high-dimensional timeline data and the identification of outliers and anomalies is critical across diverse domains, including sensor readings, biological and medical data, historical records, and global statistics. However, conventional analysis techniques often struggle with challenges such as high dimensionality, complex distributions, and sparsity. These limitations hinder the ability to extract meaningful insights from complex temporal datasets, making it difficult to identify trending features, outliers, and anomalies effectively. Inspired by surprisability -- a cognitive science concept describing how humans instinctively focus on unexpected deviations - we propose Learning via Surprisability (LvS), a novel approach for transforming high-dimensional timeline data. LvS quantifies and prioritizes anomalies in time-series data by formalizing deviations from expected behavior. LvS bridges cognitive theories of attention with computational methods, enabling the detection of anomalies and shifts in a way that preserves critical context, offering a new lens for interpreting complex datasets. We demonstrate the usefulness of LvS on three high-dimensional timeline use cases: a time series of sensor data, a global dataset of mortality causes over multiple years, and a textual corpus containing over two centuries of State of the Union Addresses by U.S. presidents. Our results show that the LvS transformation enables efficient and interpretable identification of outliers, anomalies, and the most variable features along the timeline.",
      "authors": [
        "Osnat Mokryn",
        "Teddy Lazebnik",
        "Hagit Ben Shoshan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T14:50:29+00:00",
          "link": "https://arxiv.org/abs/2503.04502v1",
          "size": "2401kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T08:06:22+00:00",
          "link": "https://arxiv.org/abs/2503.04502v2",
          "size": "1966kb",
          "version": "v2"
        }
      ],
      "title": "Interpretable Transformation and Analysis of Timelines through Learning via Surprisability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04502",
        "HTML": "https://arxiv.org/html/2503.04502v2",
        "PDF": "https://arxiv.org/pdf/2503.04502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a method for analyzing high-dimensional timeline data through a novel approach called Learning via Surprisability. It does not address LLM training data, pretraining, or any relevant data processing techniques for language models."
      },
      "tasks": [
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05674",
      "abstract": "The Grad-Shafranov (GS) equation is a nonlinear elliptic partial differential equation that governs the ideal magnetohydrodynamic equilibrium of a tokamak plasma. Previous studies have demonstrated the existence of multiple solutions to the GS equation when solved in idealistic geometries with simplified plasma current density profiles and boundary conditions. Until now, the question of whether multiple equilibria might exist in real-world tokamak geometries with more complex current density profiles and integral free-boundary conditions (commonly used in production-level equilibrium codes) has remained unanswered. In this work, we discover multiple solutions to the static forward free-boundary GS problem in the MAST-U tokamak geometry using the validated evolutive equilibrium solver FreeGSNKE and the deflated continuation algorithm. By varying the plasma current, current density profile coefficients, or coil currents in the GS equation, we identify and characterise distinct equilibrium solutions, including both deeply and more shallowly confined plasma states. We suggest that the existence of even more equilibria is likely prohibited by the restrictive nature of the integral free-boundary condition, which globally couples poloidal fluxes on the computational boundary with those on the interior. We conclude by discussing the implications of these findings for wider equilibrium modelling and emphasise the need to explore whether multiple solutions are present in other equilibrium codes and tokamaks, as well as their potential impact on downstream simulations that rely on GS equilibria.",
      "authors": [
        "K. Pentland",
        "N. C. Amorisco",
        "P. E. Farrell",
        "C. J. Ham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T18:34:41+00:00",
          "link": "https://arxiv.org/abs/2503.05674v1",
          "size": "2424kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T17:37:20+00:00",
          "link": "https://arxiv.org/abs/2503.05674v2",
          "size": "2425kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T17:27:24+00:00",
          "link": "https://arxiv.org/abs/2503.05674v3",
          "size": "2558kb",
          "version": "v3"
        }
      ],
      "title": "Multiple solutions to the static forward free-boundary Grad-Shafranov problem on MAST-U",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05674",
        "HTML": "https://arxiv.org/html/2503.05674v3",
        "PDF": "https://arxiv.org/pdf/2503.05674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on solving the Grad-Shafranov problem in tokamak physics, which is unrelated to LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17941",
      "abstract": "This study presents an enhanced multi-fidelity Deep Operator Network (DeepONet) framework for efficient spatio-temporal flow field prediction when high-fidelity data is scarce. Key innovations include: a merge network replacing traditional dot-product operations, achieving 50.4% reduction in prediction error and 7.57% accuracy improvement while reducing training time by 96%; a transfer learning multi-fidelity approach that freezes pre-trained low-fidelity networks while making only the merge network trainable, outperforming alternatives by up to 76% and achieving 43.7% better accuracy than single-fidelity training; and a physics-guided subsampling method that strategically selects high-fidelity training points based on temporal dynamics, reducing high-fidelity sample requirements by 40% while maintaining comparable accuracy. Comprehensive experiments across multiple resolutions and datasets demonstrate the framework's ability to significantly reduce required high-fidelity dataset size while maintaining predictive accuracy, with consistent superior performance against conventional benchmarks.",
      "authors": [
        "Sunwoong Yang",
        "Youngkyu Lee",
        "Namwoo Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T04:48:18+00:00",
          "link": "https://arxiv.org/abs/2503.17941v1",
          "size": "6947kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:01:00+00:00",
          "link": "https://arxiv.org/abs/2503.17941v2",
          "size": "6715kb",
          "version": "v2"
        }
      ],
      "title": "Data-Efficient Deep Operator Network for Unsteady Flow: A Multi-Fidelity Approach with Physics-Guided Subsampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17941",
        "HTML": "https://arxiv.org/html/2503.17941v2",
        "PDF": "https://arxiv.org/pdf/2503.17941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an enhanced multi-fidelity Deep Operator Network for efficient spatio-temporal flow field prediction, which involves a physics-guided subsampling method. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Prediction",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01673",
      "abstract": "We present an extension of K-P time-optimal quantum control solutions using global Cartan $KAK$ decompositions for geodesic-based solutions. Extending recent time-optimal constant-$\\theta$ control results, we integrate Cartan methods into equivariant quantum neural network (EQNN) for quantum control tasks. We show that a finite-depth limited EQNN ansatz equipped with Cartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for K-P problems. We demonstrate how for certain classes of control problem on Riemannian symmetric spaces, gradient-based training using an appropriate cost function converges to certain global time-optimal solutions when satisfying simple regularity conditions. This generalises prior geometric control theory methods and clarifies how optimal geodesic estimation can be performed in quantum machine learning contexts.",
      "authors": [
        "Elija Perrier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T12:22:18+00:00",
          "link": "https://arxiv.org/abs/2504.01673v1",
          "size": "3109kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:17:19+00:00",
          "link": "https://arxiv.org/abs/2504.01673v2",
          "size": "2683kb",
          "version": "v2"
        }
      ],
      "title": "K-P Quantum Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01673",
        "HTML": "https://arxiv.org/html/2504.01673v2",
        "PDF": "https://arxiv.org/pdf/2504.01673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses extending K-P time-optimal quantum control solutions and integrating Cartan methods into quantum neural networks, which is unrelated to LLM training data processing or improvements in datasets."
      },
      "tasks": [
        "Quantum Machine Learning"
      ],
      "repo_urls": [
        "https://github.com/eperrier/k-p_qnn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10733",
      "abstract": "Quantum Approximate Optimization Algorithm (QAOA) is one of the most promising candidates to achieve the quantum advantage in solving combinatorial optimization problems. The process of finding a good set of variational parameters in the QAOA circuit has proven to be challenging due to multiple factors, such as barren plateaus. As a result, there is growing interest in exploiting parameter transferability, where parameter sets optimized for one problem instance are transferred to another that could be more complex either to estimate the solution or to serve as a warm start for further optimization. But can we transfer parameters from one class of problems to another? Leveraging parameter sets learned from a well-studied class of problems could help navigate the less studied one, reducing optimization overhead and mitigating performance pitfalls. In this paper, we study whether pretrained QAOA parameters of MaxCut can be used as is or to warm start the Maximum Independent Set (MIS) circuits. Specifically, we design machine learning models to find good donor candidates optimized on MaxCut and apply their parameters to MIS acceptors. Our experimental results show that such parameter transfer can significantly reduce the number of optimization iterations required while achieving comparable approximation ratios.",
      "authors": [
        "Kien X. Nguyen",
        "Bao Bach",
        "Ilya Safro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T21:56:11+00:00",
          "link": "https://arxiv.org/abs/2504.10733v1",
          "size": "970kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:19:07+00:00",
          "link": "https://arxiv.org/abs/2504.10733v2",
          "size": "281kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T19:26:58+00:00",
          "link": "https://arxiv.org/abs/2504.10733v3",
          "size": "281kb",
          "version": "v3"
        }
      ],
      "title": "Cross-Problem Parameter Transfer in Quantum Approximate Optimization Algorithm: A Machine Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10733",
        "HTML": "https://arxiv.org/html/2504.10733v3",
        "PDF": "https://arxiv.org/pdf/2504.10733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates parameter transfer in quantum optimization algorithms, which is unrelated to LLM training data processing or relevant data engineering operations."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Navigate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12249",
      "abstract": "The application of artificial intelligence (AI) in medical imaging has revolutionized diagnostic practices, enabling advanced analysis and interpretation of radiological data. This study presents a comprehensive evaluation of radiomics-based and deep learning-based approaches for disease detection in chest radiography, focusing on COVID-19, lung opacity, and viral pneumonia. While deep learning models, particularly convolutional neural networks and vision transformers, learn directly from image data, radiomics-based models extract handcrafted features, offering potential advantages in data-limited scenarios. We systematically compared the diagnostic performance of various AI models, including Decision Trees, Gradient Boosting, Random Forests, Support Vector Machines, and Multi-Layer Perceptrons for radiomics, against state-of-the-art deep learning models such as InceptionV3, EfficientNetL, and ConvNeXtXLarge. Performance was evaluated across multiple sample sizes. At 24 samples, EfficientNetL achieved an AUC of 0.839, outperforming SVM with an AUC of 0.762. At 4000 samples, InceptionV3 achieved the highest AUC of 0.996, compared to 0.885 for Random Forest. A Scheirer-Ray-Hare test confirmed significant main and interaction effects of model type and sample size on all metrics. Post hoc Mann-Whitney U tests with Bonferroni correction further revealed consistent performance advantages for deep learning models across most conditions. These findings provide statistically validated, data-driven recommendations for model selection in diagnostic AI. Deep learning models demonstrated higher performance and better scalability with increasing data availability, while radiomics-based models may remain useful in low-data contexts. This study addresses a critical gap in AI-based diagnostic research by offering practical guidance for deploying AI models across diverse clinical environments.",
      "authors": [
        "Zhijin He",
        "Alan B. McMillan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T16:54:37+00:00",
          "link": "https://arxiv.org/abs/2504.12249v1",
          "size": "1843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T23:10:18+00:00",
          "link": "https://arxiv.org/abs/2504.12249v2",
          "size": "1826kb",
          "version": "v2"
        }
      ],
      "title": "Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12249",
        "PDF": "https://arxiv.org/pdf/2504.12249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on comparing different AI models for disease detection in medical imaging, without addressing any aspect of LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01455",
      "abstract": "Machine learning (ML) models are successful with weather forecasting and have shown progress in climate simulations, yet leveraging them for useful climate predictions needs exploration. Here we show this feasibility using Neural General Circulation Model (NeuralGCM), a hybrid ML-physics atmospheric model developed by Google, for seasonal predictions of large-scale atmospheric variability and Northern Hemisphere tropical cyclone (TC) activity. Inspired by physical model studies, we simplify boundary conditions, assuming sea surface temperature (SST) and sea ice follow their climatological cycle but persist anomalies present at the initialization time. With such forcings, NeuralGCM can generate 100 simulation days in ~8 minutes with a single Graphics Processing Unit (GPU), while simulating realistic atmospheric circulation and TC climatology patterns. This configuration yields useful seasonal predictions (July to November) for the tropical atmosphere and various TC activity metrics. Notably, the predicted and observed TC frequency in the North Atlantic and East Pacific basins are significantly correlated during 1990 to 2023 (r=~0.7), suggesting prediction skill comparable to existing physical GCMs. Despite challenges associated with model resolution and simplified boundary forcings, the model-predicted interannual variations demonstrate significant correlations with the observation, including the sub-basin TC tracks (p<0.1) and basin-wide accumulated cyclone energy (p<0.01) of the North Atlantic and North Pacific basins. These findings highlight the promise of leveraging ML models with physical insights to model TC risks and deliver seamless weather-climate predictions.",
      "authors": [
        "Gan Zhang",
        "Megha Rao",
        "Janni Yuval",
        "Ming Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T19:42:16+00:00",
          "link": "https://arxiv.org/abs/2505.01455v1",
          "size": "8113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T17:20:09+00:00",
          "link": "https://arxiv.org/abs/2505.01455v2",
          "size": "6556kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Seasonal Prediction of Tropical Cyclone Activity with a Hybrid AI-Physics Climate Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01455",
        "PDF": "https://arxiv.org/pdf/2505.01455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper targets climate prediction with a hybrid AI-Physics model and does not pertain to any LLM training data processing tasks or methodologies."
      },
      "tasks": [
        "Weather Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12887",
      "abstract": "The scarcity of high-quality, labelled retinal imaging data, which presents a significant challenge in the development of machine learning models for ophthalmology, hinders progress in the field. Existing methods for synthesising Colour Fundus Photographs (CFPs) largely rely on predefined disease labels, which restricts their ability to generate images that reflect fine-grained anatomical variations, subtle disease stages, and diverse pathological features beyond coarse class categories. To overcome these challenges, we first introduce an innovative pipeline that creates a large-scale, captioned retinal dataset comprising 1.4 million entries, called RetinaLogos-1400k. Specifically, RetinaLogos-1400k uses the visual language model(VLM) to describe retinal conditions and key structures, such as optic disc configuration, vascular distribution, nerve fibre layers, and pathological features. Building on this dataset, we employ a novel three-step training framework, RetinaLogos, which enables fine-grained semantic control over retinal images and accurately captures different stages of disease progression, subtle anatomical variations, and specific lesion types. Through extensive experiments, our method demonstrates superior performance across multiple datasets, with 62.07% of text-driven synthetic CFPs indistinguishable from real ones by ophthalmologists. Moreover, the synthetic data improves accuracy by 5%-10% in diabetic retinopathy grading and glaucoma detection. Codes are available at https://github.com/uni-medical/retina-text2cfp.",
      "authors": [
        "Junzhi Ning",
        "Cheng Tang",
        "Kaijing Zhou",
        "Diping Song",
        "Lihao Liu",
        "Ming Hu",
        "Wei Li",
        "Huihui Xu",
        "Yanzhou Su",
        "Tianbin Li",
        "Jiyao Liu",
        "Jin Ye",
        "Sheng Zhang",
        "Yuanfeng Ji",
        "Junjun He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T09:18:11+00:00",
          "link": "https://arxiv.org/abs/2505.12887v1",
          "size": "11325kb",
          "version": "v1"
        },
        {
          "date": "2025-05-24T15:34:37+00:00",
          "link": "https://arxiv.org/abs/2505.12887v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T06:20:33+00:00",
          "link": "https://arxiv.org/abs/2505.12887v3",
          "size": "6945kb",
          "version": "v3"
        }
      ],
      "title": "RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12887",
        "HTML": "https://arxiv.org/html/2505.12887v3",
        "PDF": "https://arxiv.org/pdf/2505.12887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces RetinaLogos-1400k, a dataset for synthesizing high-resolution retinal images, the emphasis is on image synthesis for medical applications, rather than LLM data processing. Though it touches on dataset creation, the primary focus isn't on LLM training data."
      },
      "tasks": [
        "Diabetic Retinopathy Grading"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22802",
      "abstract": "I define a \"group graph\" which encodes the symmetry in a dynamical process on a network. Group graphs extend signed networks, where links are labelled with plus or minus one, by allowing link labels from any group and generalising the standard notion of balance. I show that for processes on a balanced group graph the time evolution is completely determined by the network topology, not by the group structure. This unifies and extends recent findings on signed networks (Tian \\& Lambiotte, 2024a) and complex networks (Tian \\& Lambiotte, 2024b). I will also relate the results discussed here to related work such as the \"group graph\" of Harary (1982), a \"voltage graph\" (Gross, 1974) and a \"gain graph\" (Zaslavsky 1989). Finally, I will review some promising applications for network dynamics and symmetry-driven modelling including status, edges with a zero label, weak balance, unbalanced group graphs and using monoids.",
      "authors": [
        "Tim S. Evans"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Discrete Mathematics (cs.DM)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T19:23:41+00:00",
          "link": "https://arxiv.org/abs/2505.22802v1",
          "size": "200kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T11:25:59+00:00",
          "link": "https://arxiv.org/abs/2505.22802v2",
          "size": "217kb",
          "version": "v2"
        }
      ],
      "title": "From Signed Networks to Group Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22802",
        "HTML": "https://arxiv.org/html/2505.22802v2",
        "PDF": "https://arxiv.org/pdf/2505.22802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on theoretical aspects of group graphs and network dynamics, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23305",
      "abstract": "Bronchopulmonary dysplasia (BPD) is a common complication among preterm neonates, with portable X-ray imaging serving as the standard diagnostic modality in neonatal intensive care units (NICUs). However, lung magnetic resonance imaging (MRI) offers a non-invasive alternative that avoids sedation and radiation while providing detailed insights into the underlying mechanisms of BPD. Leveraging high-resolution 3D MRI data, advanced image processing and semantic segmentation algorithms can be developed to assist clinicians in identifying the etiology of BPD. In this dataset, we present MRI scans paired with corresponding semantic segmentations of the lungs and trachea for 40 neonates, the majority of whom are diagnosed with BPD. The imaging data consist of free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as the StarVIBE series. Additionally, we provide comprehensive clinical data and baseline segmentation models, validated against clinical assessments, to support further research and development in neonatal lung imaging.",
      "authors": [
        "Rachit Saluja",
        "Arzu Kovanlikaya",
        "Candace Chien",
        "Lauren Kathryn Blatt",
        "Jeffrey M. Perlman",
        "Stefan Worgall",
        "Mert R. Sabuncu",
        "Jonathan P. Dyke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:51:31+00:00",
          "link": "https://arxiv.org/abs/2506.23305v1",
          "size": "11291kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:06:30+00:00",
          "link": "https://arxiv.org/abs/2506.23305v2",
          "size": "11291kb",
          "version": "v2"
        }
      ],
      "title": "BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23305",
        "HTML": "https://arxiv.org/html/2506.23305v2",
        "PDF": "https://arxiv.org/pdf/2506.23305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an MRI dataset for lung-trachea segmentation in neonatal diagnostics, specifically focusing on medical imaging rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05402",
      "abstract": "One of the main challenges in synchronizing wirelessly connected loudspeakers for spatial audio reproduction is clock skew. Clock skew arises from sample rate offsets ( SROs) between the loudspeakers, caused by the use of independent device clocks. While network-based protocols like Precision Time Protocol (PTP) and Network Time Protocol (NTP) are explored, the impact of SROs on spatial audio reproduction and its perceptual consequences remains underexplored. We propose an audio-domain SRO compensation method using spatial filtering to isolate loudspeaker contributions. These filtered signals, along with the original playback signal, are used to estimate the SROs, and their influence is compensated for prior to spatial audio reproduction. We evaluate the effect of the compensation method in a subjective listening test. The results of these tests as well as objective metrics demonstrate that the proposed method mitigates the perceptual degradation introduced by SROs by preserving the spatial cues.",
      "authors": [
        "Srikanth Korse and Andreas Walther and Emanuel A. P. Habets"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:40:33+00:00",
          "link": "https://arxiv.org/abs/2507.05402v1",
          "size": "595kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T07:55:16+00:00",
          "link": "https://arxiv.org/abs/2507.05402v2",
          "size": "595kb",
          "version": "v2"
        }
      ],
      "title": "Stereo Reproduction in the Presence of Sample Rate Offsets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05402",
        "HTML": "https://arxiv.org/html/2507.05402v2",
        "PDF": "https://arxiv.org/pdf/2507.05402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on audio synchronization for spatial audio reproduction and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06361",
      "abstract": "We present experimental quantum computation of the ground-state energy in a 103-site flat Kagome lattice under the antiferromagnetic Heisenberg model (KAFH), with IBM's Heron r1 and Heron r2 quantum processors. For spin-1/2 KAFH, our per-site ground-state energy estimate is $-0.417\\,J$, which, under open-boundary corrections, matches the energy in the thermodynamic limit, i.e., $-0.4386\\,J$. To achieve this, we used a hybrid approach that splits the conventional Variational Quantum Eigensolver (VQE) into local (classical) and global (quantum) components for efficient hardware utilization. More importantly, we introduce a Hamiltonian engineering strategy that increases coupling on defect triangles to mimic loop-flip dynamics, allowing us to simplify the ansatz while retaining computational accuracy. Using a single-repetition, hardware-efficient ansatz, we entangle up to 103 qubits with high fidelity to determine the Hamiltonian's lowest eigenvalue. This work demonstrates the scalability of VQE for frustrated 2D systems and lays the foundation for future studies using deeper ansatz circuits and larger lattices on utility quantum processors.",
      "authors": [
        "Muhammad Ahsan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:49:17+00:00",
          "link": "https://arxiv.org/abs/2507.06361v1",
          "size": "7365kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:13:43+00:00",
          "link": "https://arxiv.org/abs/2507.06361v2",
          "size": "7439kb",
          "version": "v2"
        },
        {
          "date": "2025-07-17T17:58:22+00:00",
          "link": "https://arxiv.org/abs/2507.06361v3",
          "size": "7453kb",
          "version": "v3"
        }
      ],
      "title": "Utility-Scale Quantum Computation of Ground-State Energy in a 100+ Site Planar Kagome Antiferromagnet via Hamiltonian Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06361",
        "HTML": "https://arxiv.org/html/2507.06361v3",
        "PDF": "https://arxiv.org/pdf/2507.06361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents quantum computation techniques for estimating ground-state energy in a specific lattice model. Its focus is on quantum computing methodologies and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08214",
      "abstract": "While total intracranial carotid artery calcification (ICAC) volume is an established stroke biomarker, growing evidence shows this aggregate metric ignores the critical influence of plaque location, since calcification in different segments carries distinct prognostic and procedural risks. However, a finer-grained, segment-specific quantification has remained technically infeasible. Conventional 3D models are forced to process downsampled volumes or isolated patches, sacrificing the global context required to resolve anatomical ambiguity and render reliable landmark localization. To overcome this, we reformulate the 3D challenge as a \\textbf{Parallel Probabilistic Landmark Localization} task along the 1D axial dimension. We propose the \\textbf{Depth-Sequence Transformer (DST)}, a framework that processes full-resolution CT volumes as sequences of 2D slices, learning to predict $N=6$ independent probability distributions that pinpoint key anatomical landmarks. Our DST framework demonstrates exceptional accuracy and robustness. Evaluated on a 100-patient clinical cohort with rigorous 5-fold cross-validation, it achieves a Mean Absolute Error (MAE) of \\textbf{0.1 slices}, with \\textbf{96\\%} of predictions falling within a $\\pm1$ slice tolerance. Furthermore, to validate its architectural power, the DST backbone establishes the best result on the public Clean-CC-CCII classification benchmark under an end-to-end evaluation protocol. Our work delivers the first practical tool for automated segment-specific ICAC analysis. The proposed framework provides a foundation for further studies on the role of location-specific biomarkers in diagnosis, prognosis, and procedural planning.",
      "authors": [
        "Xiangjian Hou",
        "Ebru Yaman Akcicek",
        "Xin Wang",
        "Kazem Hashemizadeh",
        "Scott Mcnally",
        "Chun Yuan",
        "Xiaodong Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T23:12:12+00:00",
          "link": "https://arxiv.org/abs/2507.08214v1",
          "size": "1602kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T19:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.08214v2",
          "size": "1603kb",
          "version": "v2"
        }
      ],
      "title": "Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08214",
        "HTML": "https://arxiv.org/html/2507.08214v2",
        "PDF": "https://arxiv.org/pdf/2507.08214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a Depth-Sequence Transformer for CT imaging to map calcifications in carotid arteries. It does not address language models or training data processing, focusing instead on medical imaging technology."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08773",
      "abstract": "Firstly, assuming Gaussianity, equations for the following information theory measures are presented: total correlation/coherence (TC), dual total correlation/coherence (DTC), O-information, TSE complexity, and redundancy-synergy index (RSI). Since these measures are functions of the covariance matrix \"S\" and its inverse \"S^-1\", the associated Wishart and inverse-Wishart distributions are of note. DTC is shown to be the Kullback-Leibler (KL) divergence for the inverse-Wishart pair \"(S^-1)\" and its diagonal matrix \"D=diag(S^-1)\", shedding light on its interpretation as a measure of \"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where \"P\" is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2). The second aim of this paper introduces a generalization of all these measures for structured groups of variables. For instance, consider three or more groups, each consisting of three or more variables, with predominant redundancy within each group, but with synergistic interactions between groups. O-information will miss the between group synergy (since redundancy occurs more often in the system). In contrast, the structured O-information measure presented here will correctly report predominant synergy between groups. This is a relevant generalization towards structured multivariate information measures. A third aim is the presentation of a framework for quantifying the contribution of \"connections\" between variables, to the system's TC, DTC, O-information, and TSE complexity. A fourth aim is to present a generalization of the redundancy-synergy index for quantifying the contribution of a group of variables to the system's redundancy-synergy balance. Finally, it is shown that the expressions derived here directly apply to data from several other elliptical distributions. All program codes, data files, and executables are available (https://osf.io/jd37g/).",
      "authors": [
        "Roberto D. Pascual-Marqui",
        "Kieko Kochi",
        "Toshihiko Kinoshita"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:35:04+00:00",
          "link": "https://arxiv.org/abs/2507.08773v1",
          "size": "864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T06:24:20+00:00",
          "link": "https://arxiv.org/abs/2507.08773v2",
          "size": "821kb",
          "version": "v2"
        },
        {
          "date": "2025-07-16T20:58:41+00:00",
          "link": "https://arxiv.org/abs/2507.08773v3",
          "size": "820kb",
          "version": "v3"
        }
      ],
      "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08773",
        "PDF": "https://arxiv.org/pdf/2507.08773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents methods for analyzing multivariate data using information theory measures. It does not address LLM training data processing, focusing instead on data analysis techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09772",
      "abstract": "We introduce just-in-time (JIT) compilation to the integral kernels for Gaussian-type orbitals (GTOs) to enhance the efficiency of electron repulsion integral computations. For Coulomb and exchange (JK) matrices, JIT-based algorithms yield a 2x speedup for the small 6-31G* basis set over GPU4PySCF v1.4 on an NVIDIA A100-80G GPU. By incorporating a novel algorithm designed for orbitals with high angular momentum, the efficiency of JK evaluations with the large def2-TZVPP basis set is improved by up to 4x. The core CUDA implementation is compact, comprising only ~1,000 lines of code, including support for single-precision arithmetic. Furthermore, the single-precision implementation achieves a 3x speedup over the previous state-of-the-art.",
      "authors": [
        "Xiaojie Wu and Yuanheng Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:06:32+00:00",
          "link": "https://arxiv.org/abs/2507.09772v1",
          "size": "723kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T00:23:10+00:00",
          "link": "https://arxiv.org/abs/2507.09772v2",
          "size": "723kb",
          "version": "v2"
        }
      ],
      "title": "Designing quantum chemistry algorithms with Just-In-Time compilation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09772",
        "HTML": "https://arxiv.org/html/2507.09772v2",
        "PDF": "https://arxiv.org/pdf/2507.09772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses just-in-time compilation techniques for quantum chemistry algorithms, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09966",
      "abstract": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is essential for neuro-oncology diagnosis and treatment planning. Despite advances in deep learning methods, automatic segmentation remains challenging due to tumor morphological heterogeneity and complex three-dimensional spatial relationships. Current techniques primarily rely on visual features extracted from MRI sequences while underutilizing semantic knowledge embedded in medical reports. This research presents a multi-level fusion architecture that integrates pixel-level, feature-level, and semantic-level information, facilitating comprehensive processing from low-level data to high-level concepts. The semantic-level fusion pathway combines the semantic understanding capabilities of Contrastive Language-Image Pre-training (CLIP) models with the spatial feature extraction advantages of 3D U-Net through three mechanisms: 3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based attention mechanisms. Experimental validation on the BraTS 2020 dataset demonstrates that the proposed model achieves an overall Dice coefficient of 0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with a 7.3% Dice coefficient increase in the clinically important enhancing tumor (ET) region.",
      "authors": [
        "Mingda Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:32:59+00:00",
          "link": "https://arxiv.org/abs/2507.09966v1",
          "size": "3809kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T09:49:45+00:00",
          "link": "https://arxiv.org/abs/2507.09966v2",
          "size": "3578kb",
          "version": "v2"
        }
      ],
      "title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09966",
        "HTML": "https://arxiv.org/html/2507.09966v2",
        "PDF": "https://arxiv.org/pdf/2507.09966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on brain tumor segmentation using multimodal deep learning techniques and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10019",
      "abstract": "This paper addresses the problem of estimating the containment and similarity between two sets using only random samples from each set, without relying on sketches or full data access. The study introduces a binomial model for predicting the overlap between samples, demonstrating that it is both accurate and practical when sample sizes are small compared to the original sets. The paper compares this model to previous approaches and shows that it provides better estimates under the considered conditions. It also analyzes the statistical properties of the estimator, including error bounds and sample size requirements needed to achieve a desired level of accuracy and confidence. The framework is extended to estimate set similarity, and the paper provides guidance for applying these methods in large scale data systems where only partial or sampled data is available.",
      "authors": [
        "Pranav Joshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Databases (cs.DB)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:56:29+00:00",
          "link": "https://arxiv.org/abs/2507.10019v1",
          "size": "506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T06:08:24+00:00",
          "link": "https://arxiv.org/abs/2507.10019v2",
          "size": "545kb",
          "version": "v2"
        }
      ],
      "title": "Sampling-Based Estimation of Jaccard Containment and Similarity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10019",
        "HTML": "https://arxiv.org/html/2507.10019v2",
        "PDF": "https://arxiv.org/pdf/2507.10019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with estimating set similarity and containment using sampled data, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11161",
      "abstract": "In recent years, contrastive learning has achieved state-of-the-art performance in the territory of self-supervised representation learning. Many previous works have attempted to provide the theoretical understanding underlying the success of contrastive learning. Almost all of them rely on a default assumption, i.e., the label consistency assumption, which may not hold in practice (the probability of failure is called labeling error) due to the strength and randomness of common augmentation strategies, such as random resized crop (RRC). This paper investigates the theoretical impact of labeling error on the downstream classification performance of contrastive learning. We first reveal several significant negative impacts of labeling error on downstream classification risk. To mitigate these impacts, data dimensionality reduction method (e.g., singular value decomposition, SVD) is applied on original data to reduce false positive samples, and establish both theoretical and empirical evaluations. Moreover, it is also found that SVD acts as a double-edged sword, which may lead to the deterioration of downstream classification accuracy due to the reduced connectivity of the augmentation graph. Based on the above observations, we give the augmentation suggestion that we should use some moderate embedding dimension (such as $512, 1024$ in our experiments), data inflation, weak augmentation, and SVD to ensure large graph connectivity and small labeling error to improve model performance.",
      "authors": [
        "Jun Chen",
        "Hong Chen",
        "Yonghua Yu",
        "Yiming Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:09:55+00:00",
          "link": "https://arxiv.org/abs/2507.11161v1",
          "size": "1865kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T02:30:27+00:00",
          "link": "https://arxiv.org/abs/2507.11161v2",
          "size": "1865kb",
          "version": "v2"
        }
      ],
      "title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11161",
        "HTML": "https://arxiv.org/html/2507.11161v2",
        "PDF": "https://arxiv.org/pdf/2507.11161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses data augmentation and the impacts of labeling error in contrastive learning, which relates to data quality issues but not specifically focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11192",
      "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration has ushered in a new era of observational astronomy, emphasizing the need for rapid and detailed parameter estimation and population-level analyses. Traditional Bayesian inference methods, particularly Markov chain Monte Carlo, face significant computational challenges when dealing with the high-dimensional parameter spaces and complex noise characteristics inherent in gravitational wave data. This review examines the emerging role of simulation-based inference methods in gravitational wave astronomy, with a focus on approaches that leverage machine-learning techniques such as normalizing flows and neural posterior estimation. We provide a comprehensive overview of the theoretical foundations underlying various simulation-based inference methods, including neural posterior estimation, neural ratio estimation, neural likelihood estimation, flow matching, and consistency models. We explore the applications of these methods across diverse gravitational wave data processing scenarios, from single-source parameter estimation and overlapping signal analysis to testing general relativity and conducting population studies. Although these techniques demonstrate speed improvements over traditional methods in controlled studies, their model-dependent nature and sensitivity to prior assumptions are barriers to their widespread adoption. Their accuracy, which is similar to that of conventional methods, requires further validation across broader parameter spaces and noise conditions.",
      "authors": [
        "Bo Liang",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:52:57+00:00",
          "link": "https://arxiv.org/abs/2507.11192v1",
          "size": "1358kb",
          "version": "v1"
        },
        {
          "date": "2025-07-17T15:00:34+00:00",
          "link": "https://arxiv.org/abs/2507.11192v2",
          "size": "1358kb",
          "version": "v2"
        }
      ],
      "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11192",
        "HTML": "https://arxiv.org/html/2507.11192v2",
        "PDF": "https://arxiv.org/pdf/2507.11192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simulation-based inference methods for gravitational wave data analysis and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2304.02278",
      "abstract": "Text-Based Person Search (TBPS) faces critical challenges in cross-modal information fusion, requiring effective alignment of visual and textual modalities for person retrieval using natural language queries. Existing methods struggle with cross-modal heterogeneity, where visual and textual features reside in disparate semantic spaces, creating substantial inter-modal gaps that limit fusion effectiveness. We propose SCMM (Sew Calibration and Masked Modeling), a novel framework addressing these fusion challenges through two complementary mechanisms. First, our sew calibration loss implements adaptive margin constraints guided by caption quality, dynamically aligning image-text features while accommodating varying information density across modalities. Second, our masked caption modeling loss establishes fine-grained cross-modal correspondences through masked prediction tasks and cross-modal attention, enabling detailed visual-textual relationship learning. The streamlined dual-encoder architecture maintains computational efficiency while achieving superior fusion performance through synergistic alignment and correspondence strategies. Extensive experiments on three benchmark datasets validate SCMM's effectiveness, achieving state-of-the-art Rank1 accuracies of 73.81%, 64.25%, and 57.35% on CUHK-PEDES, ICFG-PEDES, and RSTPReID respectively. These results demonstrate the importance of quality-aware adaptive constraints and fine-grained correspondence modeling in advancing multimodal information fusion for person search applications.",
      "authors": [
        "Jing Liu",
        "Donglai Wei",
        "Yang Liu",
        "Sipeng Zhang",
        "Tong Yang",
        "Wei Zhou",
        "Weiping Ding",
        "Victor C. M. Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-05T07:50:16+00:00",
          "link": "https://arxiv.org/abs/2304.02278v1",
          "size": "845kb",
          "version": "v1"
        },
        {
          "date": "2023-06-01T01:49:26+00:00",
          "link": "https://arxiv.org/abs/2304.02278v2",
          "size": "1277kb",
          "version": "v2"
        },
        {
          "date": "2024-10-17T08:57:50+00:00",
          "link": "https://arxiv.org/abs/2304.02278v3",
          "size": "1416kb",
          "version": "v3"
        },
        {
          "date": "2024-12-05T08:55:34+00:00",
          "link": "https://arxiv.org/abs/2304.02278v4",
          "size": "1755kb",
          "version": "v4"
        },
        {
          "date": "2024-12-06T10:13:10+00:00",
          "link": "https://arxiv.org/abs/2304.02278v5",
          "size": "2110kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T11:56:56+00:00",
          "link": "https://arxiv.org/abs/2304.02278v6",
          "size": "2016kb",
          "version": "v6"
        },
        {
          "date": "2025-07-17T08:56:59+00:00",
          "link": "https://arxiv.org/abs/2304.02278v7",
          "size": "2009kb",
          "version": "v7"
        }
      ],
      "title": "SCMM: Calibrating Cross-modal Representations for Text-Based Person Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.02278",
        "HTML": "https://arxiv.org/html/2304.02278",
        "PDF": "https://arxiv.org/pdf/2304.02278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses cross-modal representations for text-based person search and focuses on aligning visual and textual data. It does not contribute to training data processing for LLMs."
      },
      "tasks": [
        "Person Search",
        "Text based Person Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06425",
      "abstract": "The traffic in cislunar space is expected to increase over the coming years, leading to a higher likelihood of conjunction events among active satellites, orbital debris, and non-cooperative satellites. This increase necessitates enhanced space domain awareness (SDA) capabilities that include state estimation for targets of interest. Both Earth surface-based and space-based observation platforms in geosynchronous orbit or below face challenges such as range, exclusion, and occlusion that hinder observation. Motivated by the need to place space-based observers in the cislunar space regime to overcome these challenges, this paper proposes a cislunar SDA constellation design and analysis framework that integrates state estimation into an optimization problem for determining the placement of observers for optimal state estimation performance on a set of targets. The proposed multi-observer placement optimization problem samples from a range of possible target orbits. Upon convergence, the optimized constellation is validated against a broader set of targets to assess its effectiveness. Two comparative analyses are presented to evaluate the effects of changes in the sensor tasking procedure and sensor fidelity on the optimized constellation, comparing these to a single observer baseline case. The results demonstrate that the optimized constellations can provide accurate state estimation for various orbit families.",
      "authors": [
        "Thomas H. Clareson",
        "Matthew C. Fox",
        "Dominic K. Amato",
        "Hang Woon Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Space Physics (physics.space-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T23:40:10+00:00",
          "link": "https://arxiv.org/abs/2410.06425v1",
          "size": "13433kb",
          "version": "v1"
        }
      ],
      "title": "Embedded State Estimation for Optimization of Cislunar Space Domain Awareness Constellation Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06425",
        "HTML": "https://arxiv.org/html/2410.06425",
        "PDF": "https://arxiv.org/pdf/2410.06425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing cislunar space domain awareness constellation design and state estimation for space-based observer placement, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean. We also provide a characterization for the case when $m=p=2$.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)",
        "Combinatorics (math.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.05297v4",
          "size": "320kb",
          "version": "v4"
        },
        {
          "date": "2025-07-16T03:51:18+00:00",
          "link": "https://arxiv.org/abs/2507.05297v5",
          "size": "320kb",
          "version": "v5"
        }
      ],
      "title": "Continuous Classification Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with fuzzy classification aggregation functions and provides a theoretical characterization, without any focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08521",
      "abstract": "Legal Entity Recognition (LER) is critical in automating legal workflows such as contract analysis, compliance monitoring, and litigation support. Existing approaches, including rule-based systems and classical machine learning models, struggle with the complexity of legal documents and domain specificity, particularly in handling ambiguities and nested entity structures. This paper proposes a novel hybrid model that enhances the accuracy and precision of Legal-BERT, a transformer model fine-tuned for legal text processing, by introducing a semantic similarity-based filtering mechanism. We evaluate the model on a dataset of 15,000 annotated legal documents, achieving an F1 score of 93.4%, demonstrating significant improvements in precision and recall over previous methods.",
      "authors": [
        "Duraimurugan Rajamanickam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T04:51:28+00:00",
          "link": "https://arxiv.org/abs/2410.08521v1",
          "size": "5kb",
          "version": "v1"
        }
      ],
      "title": "Improving Legal Entity Recognition Using a Hybrid Transformer Model and Semantic Filtering Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08521",
        "HTML": "https://arxiv.org/html/2410.08521",
        "PDF": "https://arxiv.org/pdf/2410.08521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a semantic filtering mechanism for improving legal entity recognition using a transformer model. While it involves data processing in the context of fine-tuning a model, the primary focus is on enhancing the model's architecture and performance, not on training data processing for LLMs specifically."
      },
      "tasks": [
        "Semantic Similarity",
        "Semantic Textual Similarity",
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19759",
      "abstract": "Certified randomness can be generated with untrusted remote quantum computers using multiple known protocols, one of which has been recently realized experimentally. Unlike the randomness sources accessible on today's classical computers, the output of these protocols can be certified to be random under certain computational hardness assumptions, with no trust required in the hardware generating the randomness. In this perspective, we explore real-world applications for which the use of certified randomness protocols may lead to improved security and fairness. We identify promising applications in areas including cryptography, differential privacy, financial markets, and blockchain. Through this initial exploration, we hope to shed light on potential applications of certified randomness.",
      "authors": [
        "Omar Amer and Shouvanik Chakrabarti and Kaushik Chakraborty and Shaltiel Eloul and Niraj Kumar and Charles Lim and Minzhao Liu and Pradeep Niroula and Yash Satsangi and Ruslan Shaydulin and Marco Pistoia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T15:22:41+00:00",
          "link": "https://arxiv.org/abs/2503.19759v1",
          "size": "616kb",
          "version": "v1"
        }
      ],
      "title": "Applications of Certified Randomness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19759",
        "HTML": "https://arxiv.org/html/2503.19759",
        "PDF": "https://arxiv.org/pdf/2503.19759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores applications for certified randomness, focusing on areas like cryptography and blockchain, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14908",
      "abstract": "Vision language models (VLM) demonstrate sophisticated multimodal reasoning yet are prone to hallucination when confronted with knowledge conflicts, impeding their deployment in information-sensitive contexts. While existing research addresses robustness in unimodal models, the multimodal domain lacks systematic investigation of cross-modal knowledge conflicts. This research introduces \\segsub, a framework for applying targeted image perturbations to investigate VLM resilience against knowledge conflicts. Our analysis reveals distinct vulnerability patterns: while VLMs are robust to parametric conflicts (20% adherence rates), they exhibit significant weaknesses in identifying counterfactual conditions (<30% accuracy) and resolving source conflicts (<1% accuracy). Correlations between contextual richness and hallucination rate (r = -0.368, p = 0.003) reveal the kinds of images that are likely to cause hallucinations. Through targeted fine-tuning on our benchmark dataset, we demonstrate improvements in VLM knowledge conflict detection, establishing a foundation for developing hallucination-resilient multimodal systems in information-sensitive environments.",
      "authors": [
        "Peter Carragher",
        "Nikitha Rao",
        "Abhinand Jha",
        "R Raghav",
        "Kathleen M. Carley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T00:26:38+00:00",
          "link": "https://arxiv.org/abs/2502.14908v1",
          "size": "29614kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T18:36:00+00:00",
          "link": "https://arxiv.org/abs/2502.14908v2",
          "size": "29630kb",
          "version": "v2"
        }
      ],
      "title": "SegSub: Evaluating Robustness to Knowledge Conflicts and Hallucinations in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14908",
        "PDF": "https://arxiv.org/pdf/2502.14908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on robustness to knowledge conflicts and hallucinations in vision-language models, with no contribution to LLM training data processing techniques or dataset operations."
      },
      "tasks": [
        "counterfactual",
        "Hallucination",
        "Multimodal Reasoning"
      ],
      "repo_urls": [
        "https://github.com/CASOS-IDeaS-CMU/SegSub"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.09146",
      "abstract": "In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between layers. By inserting residual blocks between quanvolutional layers, we ensure enhanced gradient access throughout the network, leading to improved training performance. Moreover, we provide empirical evidence on the strategic placement of these residual blocks within QuNNs. Through extensive experimentation, we identify an efficient configuration of residual blocks, which enables gradients across all the layers in the network that eventually results in efficient training. Our findings suggest that the precise location of residual blocks plays a crucial role in maximizing the performance gains in QuNNs. Our results mark a substantial step forward in the evolution of quantum deep learning, offering new avenues for both theoretical development and practical quantum computing applications.",
      "authors": [
        "Muhammad Kashif",
        "Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-14T12:55:28+00:00",
          "link": "https://arxiv.org/abs/2402.09146v1",
          "size": "2857kb",
          "version": "v1"
        },
        {
          "date": "2024-05-01T10:16:59+00:00",
          "link": "https://arxiv.org/abs/2402.09146v2",
          "size": "2310kb",
          "version": "v2"
        },
        {
          "date": "2024-05-19T18:32:15+00:00",
          "link": "https://arxiv.org/abs/2402.09146v3",
          "size": "2310kb",
          "version": "v3"
        },
        {
          "date": "2024-08-06T14:30:52+00:00",
          "link": "https://arxiv.org/abs/2402.09146v4",
          "size": "2337kb",
          "version": "v4"
        },
        {
          "date": "2024-09-02T14:38:01+00:00",
          "link": "https://arxiv.org/abs/2402.09146v5",
          "size": "1640kb",
          "version": "v5"
        },
        {
          "date": "2025-07-07T06:34:42+00:00",
          "link": "https://arxiv.org/abs/2402.09146v6",
          "size": "999kb",
          "version": "v6"
        }
      ],
      "title": "ResQuNNs: Towards Enabling Deep Learning in Quantum Convolution Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09146",
        "HTML": "https://arxiv.org/html/2402.09146",
        "PDF": "https://arxiv.org/pdf/2402.09146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with enhancing quantum neural networks called Quanvolutional Neural Networks (QuNNs). It focuses on architecture improvements, not on training data processing for LLMs."
      },
      "tasks": [
        "Deep Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.10996",
      "abstract": "Multi-agent reinforcement learning (MARL) for cyber-physical vehicle systems usually requires a significantly long training time due to their inherent complexity. Furthermore, deploying the trained policies in the real world demands a feature-rich environment along with multiple physical embodied agents, which may not be feasible due to monetary, physical, energy, or safety constraints. This work seeks to address these pain points by presenting a mixed-reality (MR) digital twin (DT) framework capable of: (i) boosting training speeds by selectively scaling parallelized simulation workloads on-demand, and (ii) immersing the MARL policies across hybrid simulation-to-reality (sim2real) experiments. The viability and performance of the proposed framework are highlighted through two representative use cases, which cover cooperative as well as competitive classes of MARL problems. We study the effect of: (i) agent and environment parallelization on training time, and (ii) systematic domain randomization on zero-shot sim2real transfer, across both case studies. Results indicate up to 76.3% reduction in training time with the proposed parallelization scheme and sim2real gap as low as 2.9% using the proposed deployment method.",
      "authors": [
        "Chinmay Vilas Samak",
        "Tanmay Vilas Samak",
        "Venkat Narayan Krovi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-16T18:47:04+00:00",
          "link": "https://arxiv.org/abs/2403.10996v1",
          "size": "4402kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T14:52:47+00:00",
          "link": "https://arxiv.org/abs/2403.10996v2",
          "size": "1932kb",
          "version": "v2"
        },
        {
          "date": "2024-09-20T05:16:09+00:00",
          "link": "https://arxiv.org/abs/2403.10996v3",
          "size": "3554kb",
          "version": "v3"
        },
        {
          "date": "2024-10-13T13:16:25+00:00",
          "link": "https://arxiv.org/abs/2403.10996v4",
          "size": "2306kb",
          "version": "v4"
        },
        {
          "date": "2025-03-20T01:11:52+00:00",
          "link": "https://arxiv.org/abs/2403.10996v5",
          "size": "3127kb",
          "version": "v5"
        },
        {
          "date": "2025-07-16T20:09:15+00:00",
          "link": "https://arxiv.org/abs/2403.10996v6",
          "size": "2452kb",
          "version": "v6"
        }
      ],
      "title": "Mixed-Reality Digital Twins: Leveraging the Physical and Virtual Worlds for Hybrid Sim2Real Transition of Multi-Agent Reinforcement Learning Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.10996",
        "HTML": "https://arxiv.org/html/2403.10996",
        "PDF": "https://arxiv.org/pdf/2403.10996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on mixed-reality digital twin frameworks for multi-agent reinforcement learning, without any discussion relevant to LLM training data processing tasks such as data collection or dataset generation."
      },
      "tasks": [
        "Mixed Reality",
        "Multi-agent Reinforcement Learning",
        "reinforcement-learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.03173",
      "abstract": "In the field of medical imaging, breast ultrasound has emerged as a crucial diagnostic tool for early detection of breast cancer. However, the accuracy of diagnosing the location of the affected area and the extent of the disease depends on the experience of the physician. In this paper, we propose a novel model called UGGNet, combining the power of the U-Net and VGG architectures to enhance the performance of breast ultrasound image analysis. The U-Net component of the model helps accurately segment the lesions, while the VGG component utilizes deep convolutional layers to extract features. The fusion of these two architectures in UGGNet aims to optimize both segmentation and feature representation, providing a comprehensive solution for accurate diagnosis in breast ultrasound images. Experimental results have demonstrated that the UGGNet model achieves a notable accuracy of 78.2% on the \"Breast Ultrasound Images Dataset.\"",
      "authors": [
        "Tran Cao Minh",
        "Nguyen Kim Quoc",
        "Phan Cong Vinh",
        "Dang Nhu Phu",
        "Vuong Xuan Chi",
        "Ha Minh Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-06T09:28:49+00:00",
          "link": "https://arxiv.org/abs/2401.03173v1",
          "size": "5071kb",
          "version": "v1"
        }
      ],
      "title": "UGGNet: Bridging U-Net and VGG for Advanced Breast Cancer Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.03173",
        "HTML": "https://arxiv.org/html/2401.03173",
        "PDF": "https://arxiv.org/pdf/2401.03173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model (UGGNet) for breast cancer diagnosis using medical imaging. It does not discuss LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18877",
      "abstract": "Visual emotion analysis holds significant research value in both computer vision and psychology. However, existing methods for visual emotion analysis suffer from limited generalizability due to the ambiguity of emotion perception and the diversity of data scenarios. To tackle this issue, we introduce UniEmoX, a cross-modal semantic-guided large-scale pretraining framework. Inspired by psychological research emphasizing the inseparability of the emotional exploration process from the interaction between individuals and their environment, UniEmoX integrates scene-centric and person-centric low-level image spatial structural information, aiming to derive more nuanced and discriminative emotional representations. By exploiting the similarity between paired and unpaired image-text samples, UniEmoX distills rich semantic knowledge from the CLIP model to enhance emotional embedding representations more effectively. To the best of our knowledge, this is the first large-scale pretraining framework that integrates psychological theories with contemporary contrastive learning and masked image modeling techniques for emotion analysis across diverse scenarios. Additionally, we develop a visual emotional dataset titled Emo8. Emo8 samples cover a range of domains, including cartoon, natural, realistic, science fiction and advertising cover styles, covering nearly all common emotional scenes. Comprehensive experiments conducted on six benchmark datasets across two downstream tasks validate the effectiveness of UniEmoX. The source code is available at https://github.com/chincharles/u-emo.",
      "authors": [
        "Chuang Chen",
        "Xiao Sun and Zhi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T16:12:51+00:00",
          "link": "https://arxiv.org/abs/2409.18877v1",
          "size": "33772kb",
          "version": "v1"
        },
        {
          "date": "2024-09-30T13:58:29+00:00",
          "link": "https://arxiv.org/abs/2409.18877v2",
          "size": "33772kb",
          "version": "v2"
        }
      ],
      "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18877",
        "HTML": "https://arxiv.org/html/2409.18877",
        "PDF": "https://arxiv.org/pdf/2409.18877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a cross-modal semantic-guided pretraining framework for emotion perception, incorporating a new dataset (Emo8). While it involves dataset creation, its focus is on visual emotion analysis rather than LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Emotion Recognition"
      ],
      "repo_urls": [
        "https://github.com/chincharles/u-emo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05285",
      "abstract": "This paper proposes a pitch plane trajectory tacking control solution for suborbital launch vehicles relying on adaptive feedback linearization. Initially, the 2D dynamics and kinematics for a single-engine, thrust-vector-controlled sounding rocket are obtained for control design purposes. Then, an inner-outer control strategy, which simultaneously tackles attitude and position control, is adopted, with the inner-loop comprising the altitude and pitch control and the outer-loop addressing the horizontal (downrange) position control. Feedback linearization is used to cancel out the non-linearities in both the inner and outer dynamics. Making use of Lyapunov stability theory, an adaptation law, which provides online estimates on the inner-loop aerodynamic uncertainty, is jointly designed with the output tracking controller via adaptive backstepping, ensuring global reference tracking in the region where the feedback linearization is well-defined. The zero dynamics of the inner-stabilized system are then exploited to obtain the outerloop dynamics and derive a Linear Quadratic Regulator (LQR) with integral action, which can stabilize them as well as reject external disturbances. In the outermost loop, the estimate on the correspondent aerodynamic uncertainty is indirectly obtained by using the inner loop estimates together with known aerodynamics relations. The resulting inner-outer position control solution is proven to be asymptotically stable in the region of interest. Using a single-stage sounding rocket, propelled by a liquid engine, as reference vehicle, different mission scenarios are tested in a simulation environment to verify the adaptability of the proposed control strategy. The system is able to track the requested trajectories while rejecting external wind disturbances. Furthermore, the need to re-tune the control gains in between different mission scenarios is minimal to none.",
      "authors": [
        "Pedro dos Santos and Paulo Oliveira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T14:49:03+00:00",
          "link": "https://arxiv.org/abs/2501.05285v1",
          "size": "3086kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T09:02:15+00:00",
          "link": "https://arxiv.org/abs/2501.05285v2",
          "size": "3086kb",
          "version": "v2"
        }
      ],
      "title": "Pitch Plane Trajectory Tracking Control for Sounding Rockets via Adaptive Feedback Linearization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05285",
        "HTML": "https://arxiv.org/html/2501.05285",
        "PDF": "https://arxiv.org/pdf/2501.05285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a control solution for sounding rockets and does not involve any aspect of LLM training data processing."
      },
      "tasks": [
        "Pitch control",
        "Position"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.05548",
      "abstract": "This letter proposes a new approach for Inertial Measurement Unit (IMU) preintegration, a fundamental building block that can be leveraged in different optimization-based Inertial Navigation System (INS) localization solutions. Inspired by recent advances in equivariant theory applied to biased INSs, we derive a discrete-time formulation of the IMU preintegration on ${\\mathbf{Gal}(3) \\ltimes \\mathfrak{gal}(3)}$, the left-trivialization of the tangent group of the Galilean group $\\mathbf{Gal}(3)$. We define a novel preintegration error that geometrically couples the navigation states and the bias leading to lower linearization error. Our method improves in consistency compared to existing preintegration approaches which treat IMU biases as a separate state-space. Extensive validation against state-of-the-art methods, both in simulation and with real-world IMU data, implementation in the Lie++ library, and open-source code are provided.",
      "authors": [
        "Giulio Delama",
        "Alessandro Fornasier",
        "Robert Mahony and Stephan Weiss"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T13:11:16+00:00",
          "link": "https://arxiv.org/abs/2411.05548v1",
          "size": "5610kb",
          "version": "v1"
        },
        {
          "date": "2024-11-24T19:20:11+00:00",
          "link": "https://arxiv.org/abs/2411.05548v2",
          "size": "5606kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T08:22:12+00:00",
          "link": "https://arxiv.org/abs/2411.05548v3",
          "size": "5607kb",
          "version": "v3"
        },
        {
          "date": "2025-02-18T13:30:47+00:00",
          "link": "https://arxiv.org/abs/2411.05548v4",
          "size": "5607kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T15:05:04+00:00",
          "link": "https://arxiv.org/abs/2411.05548v5",
          "size": "5220kb",
          "version": "v5"
        },
        {
          "date": "2025-07-17T14:44:39+00:00",
          "link": "https://arxiv.org/abs/2411.05548v6",
          "size": "5220kb",
          "version": "v6"
        }
      ],
      "title": "Equivariant IMU Preintegration with Biases: a Galilean Group Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05548",
        "HTML": "https://arxiv.org/html/2411.05548",
        "PDF": "https://arxiv.org/pdf/2411.05548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new approach for IMU preintegration used in Inertial Navigation Systems, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.10838",
      "abstract": "Soft robots have been leveraged in considerable areas like surgery, rehabilitation, and bionics due to their softness, flexibility, and safety. However, it is challenging to produce two same soft robots even with the same mold and manufacturing process owing to the complexity of soft materials. Meanwhile, widespread usage of a system requires the ability to replace inner components without highly affecting system performance, which is interchangeability. Due to the necessity of this property, a hybrid adaptive controller is introduced to achieve interchangeability from the perspective of control approaches. This method utilizes an offline-trained recurrent neural network controller to cope with the nonlinear and delayed response from soft robots. Furthermore, an online optimizing kinematics controller is applied to decrease the error caused by the above neural network controller. Soft pneumatic robots with different deformation properties but the same mold have been included for validation experiments. In the experiments, the systems with different actuation configurations and the different robots follow the desired trajectory with errors of 3.3 +- 2.9% and 4.3 +- 4.1% compared with the working space length, respectively. Such an adaptive controller also shows good performance on different control frequencies and desired velocities. This controller is also compared with a model-based controller in simulation. This controller endows soft robots with the potential for wide application, and future work may include different offline and online controllers. A weight parameter adjusting strategy may also be proposed in the future.",
      "authors": [
        "Zixi Chen",
        "Xuyang Ren",
        "Matteo Bernabei",
        "Vanessa Mainardi",
        "Gastone Ciuti",
        "Cesare Stefanini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-20T12:59:41+00:00",
          "link": "https://arxiv.org/abs/2307.10838v1",
          "size": "2532kb",
          "version": "v1"
        },
        {
          "date": "2023-11-22T13:47:54+00:00",
          "link": "https://arxiv.org/abs/2307.10838v2",
          "size": "2557kb",
          "version": "v2"
        }
      ],
      "title": "A Hybrid Adaptive Controller for Soft Robot Interchangeability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.10838",
        "PDF": "https://arxiv.org/pdf/2307.10838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a hybrid adaptive controller for soft robot interchangeability, focusing on robot control rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.08343",
      "abstract": "Simulation is widely applied in robotics research to save time and resources. There have been several works to simulate optical tactile sensors that leverage either a smoothing method or Finite Element Method (FEM). However, elastomer deformation physics is not considered in the former method, whereas the latter requires a massive amount of computational resources like a computer cluster. In this work, we propose a pluggable and low computational cost simulator using the Taichi programming language for simulating optical tactile sensors, named as Tacchi . It reconstructs elastomer deformation using particles, which allows deformed elastomer surfaces to be rendered into tactile images and reveals contact information without suffering from high computational costs. Tacchi facilitates creating realistic tactile images in simulation, e.g., ones that capture wear-and-tear defects on object surfaces. In addition, the proposed Tacchi can be integrated with robotics simulators for a robot system simulation. Experiment results showed that Tacchi can produce images with better similarity to real images and achieved higher Sim2Real accuracy compared to the existing methods. Moreover, it can be connected with MuJoCo and Gazebo with only the requirement of 1G memory space in GPU compared to a computer cluster applied for FEM. With Tacchi, physical robot simulation with optical tactile sensors becomes possible. All the materials in this paper are available at https://github.com/zixichen007115/Tacchi .",
      "authors": [
        "Zixi Chen",
        "Shixin Zhang",
        "Shan Luo",
        "Fuchun Sun",
        "Bin Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-19T22:35:03+00:00",
          "link": "https://arxiv.org/abs/2301.08343v1",
          "size": "2226kb",
          "version": "v1"
        }
      ],
      "title": "Tacchi: A Pluggable and Low Computational Cost Elastomer Deformation Simulator for Optical Tactile Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.08343",
        "PDF": "https://arxiv.org/pdf/2301.08343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work presents a simulator for optical tactile sensors using elastomer deformation models. It is not related to LLM training data processing or any relevant data processing operations."
      },
      "repo_urls": [
        "https://github.com/zixichen007115/tacchi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02336",
      "abstract": "Linear Parameter Varying (LPV) Systems are a well-established class of nonlinear systems with a rich theory for stability analysis, control, and analytical response finding, among other aspects. Although there are works on data-driven identification of such systems, the literature is quite scarce in terms of works that tackle the identification of LPV models for large-scale systems. Since large-scale systems are ubiquitous in practice, this work develops a methodology for the local and global identification of large-scale LPV systems based on nonintrusive reduced-order modeling. The developed method is coined as DMD-LPV for being inspired in the Dynamic Mode Decomposition (DMD). To validate the proposed identification method, we identify a system described by a discretized linear diffusion equation, with the diffusion gain defined by a polynomial over a parameter. The experiments show that the proposed method can easily identify a reduced-order LPV model of a given large-scale system without the need to perform identification in the full-order dimension, and with almost no performance decay over performing a reduction, given that the model structure is well-established.",
      "authors": [
        "Jean Panaioti Jordanou",
        "Eduardo Camponogara",
        "Eduardo Gildin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T14:15:16+00:00",
          "link": "https://arxiv.org/abs/2502.02336v1",
          "size": "2096kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T19:20:50+00:00",
          "link": "https://arxiv.org/abs/2502.02336v2",
          "size": "251kb",
          "version": "v2"
        }
      ],
      "title": "Identifying Large-Scale Linear Parameter Varying Systems with Dynamic Mode Decomposition Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02336",
        "HTML": "https://arxiv.org/html/2502.02336",
        "PDF": "https://arxiv.org/pdf/2502.02336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on identifying large-scale linear parameter varying systems using dynamic mode decomposition, unrelated to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.11660",
      "abstract": "The advent of single-cell technology has significantly improved our understanding of cellular states and subpopulations in various tissues under normal and diseased conditions by employing data-driven approaches such as clustering and trajectory inference. However, these methods consider cells as independent data points of population distributions. With spatial transcriptomics, we can represent cellular organization, along with dynamic cell-cell interactions that lead to changes in cell state. Still, key computational advances are necessary to enable the data-driven learning of such complex interactive cellular dynamics. While agent-based modeling (ABM) provides a powerful framework, traditional approaches rely on handcrafted rules derived from domain knowledge rather than data-driven approaches. To address this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED) integrating ABM with deep learning to model intercellular communication, and its effect on the intracellular gene regulatory network. Using graph ODE networks (GDEs) with shared weights per cell type, our approach represents genes as vertices and interactions as directed edges, dynamically learning their strengths through a designed attention mechanism. Trained to match continuous trajectories of simulated as well as inferred trajectories from spatial transcriptomics data, the model captures both intercellular and intracellular interactions, enabling a more adaptive and accurate representation of cellular dynamics.",
      "authors": [
        "Joao F. Rocha",
        "Ke Xu",
        "Xingzhi Sun",
        "Ananya Krishna",
        "Dhananjay Bhaskar",
        "Blanche Mongeon",
        "Morgan Craig",
        "Mark Gerstein",
        "Smita Krishnaswamy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T18:46:07+00:00",
          "link": "https://arxiv.org/abs/2507.11660v1",
          "size": "3712kb",
          "version": "v1"
        }
      ],
      "title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11660",
        "HTML": "https://arxiv.org/html/2507.11660",
        "PDF": "https://arxiv.org/pdf/2507.11660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for cellular interaction dynamics using agent-based modeling and deep learning, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.20267",
      "abstract": "Large-scale pre-training methodologies for chemical language models represent a breakthrough in cheminformatics. These methods excel in tasks such as property prediction and molecule generation by learning contextualized representations of input tokens through self-supervised learning on large unlabeled corpora. Typically, this involves pre-training on unlabeled data followed by fine-tuning on specific tasks, reducing dependence on annotated datasets and broadening chemical language representation understanding. This paper introduces a large encoder-decoder chemical foundation models pre-trained on a curated dataset of 91 million SMILES samples sourced from PubChem, which is equivalent to 4 billion of molecular tokens. The proposed foundation model supports different complex tasks, including quantum property prediction, and offer flexibility with two main variants (289M and $8\\times289M$). Our experiments across multiple benchmark datasets validate the capacity of the proposed model in providing state-of-the-art results for different tasks. We also provide a preliminary assessment of the compositionality of the embedding space as a prerequisite for the reasoning tasks. We demonstrate that the produced latent space is separable compared to the state-of-the-art with few-shot learning capabilities.",
      "authors": [
        "Eduardo Soares",
        "Victor Shirasuna",
        "Emilio Vital Brazil",
        "Renato Cerqueira",
        "Dmitry Zubarev",
        "Kristin Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T20:30:39+00:00",
          "link": "https://arxiv.org/abs/2407.20267v1",
          "size": "3656kb",
          "version": "v1"
        }
      ],
      "title": "A Large Encoder-Decoder Family of Foundation Models For Chemical Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20267",
        "HTML": "https://arxiv.org/html/2407.20267",
        "PDF": "https://arxiv.org/pdf/2407.20267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the pre-training of chemical language models on a curated dataset of SMILES samples from PubChem, which involves data curation but focuses more on model creation and evaluation for cheminformatics tasks, rather than a significant contribution to LLM training data processing."
      },
      "models": [
        {
          "model_path": "gbyuvd/chemselfies-base-bertmlm",
          "downloads": "18",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/gbyuvd/chemselfies-base-bertmlm"
        },
        {
          "model_path": "ibm-research/materials.smi-ted",
          "downloads": "25716",
          "likes": "28",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-research/materials.smi-ted"
        }
      ],
      "tasks": [
        "Decoder",
        "Few-Shot Learning",
        "Property Prediction",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://huggingface.co/ibm/materials.smi-ted"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19034",
      "abstract": "Human Action Recognition (HAR) plays a crucial role in applications such as health monitoring, smart home automation, and human-computer interaction. While HAR has been extensively studied, action summarization using Wi-Fi and IMU signals in smart-home environments , which involves identifying and summarizing continuous actions, remains an emerging task. This paper introduces the novel XRF V2 dataset, designed for indoor daily activity Temporal Action Localization (TAL) and action summarization. XRF V2 integrates multimodal data from Wi-Fi signals, IMU sensors (smartphones, smartwatches, headphones, and smart glasses), and synchronized video recordings, offering a diverse collection of indoor activities from 16 volunteers across three distinct environments. To tackle TAL and action summarization, we propose the XRFMamba neural network, which excels at capturing long-term dependencies in untrimmed sensory sequences and achieves the best performance with an average mAP of 78.74, outperforming the recent WiFiTAD by 5.49 points in mAP@avg while using 35% fewer parameters. In action summarization, we introduce a new metric, Response Meaning Consistency (RMC), to evaluate action summarization performance. And it achieves an average Response Meaning Consistency (mRMC) of 0.802. We envision XRF V2 as a valuable resource for advancing research in human action localization, action forecasting, pose estimation, multimodal foundation models pre-training, synthetic data generation, and more. The data and code are available at https://github.com/aiotgroup/XRFV2.",
      "authors": [
        "Bo Lan",
        "Pei Li",
        "Jiaxi Yin",
        "Yunpeng Song",
        "Ge Wang",
        "Han Ding",
        "Jinsong Han",
        "Fei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T11:03:54+00:00",
          "link": "https://arxiv.org/abs/2501.19034v1",
          "size": "6945kb",
          "version": "v1"
        },
        {
          "date": "2025-07-16T04:20:58+00:00",
          "link": "https://arxiv.org/abs/2501.19034v2",
          "size": "5403kb",
          "version": "v2"
        }
      ],
      "title": "XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19034",
        "HTML": "https://arxiv.org/html/2501.19034",
        "PDF": "https://arxiv.org/pdf/2501.19034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the XRF V2 dataset for action summarization, which involves the creation of a new dataset and is thus relevant to LLM training data processing in terms of dataset generation and contribution to model pre-training."
      },
      "tasks": [
        "Action Localization",
        "Action Recognition",
        "Pose Estimation",
        "Synthetic Data Generation",
        "Temporal Action Localization"
      ],
      "repo_urls": [
        "https://github.com/aiotgroup/xrfv2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.18798",
      "abstract": "This study investigates the application of deep residual networks for predicting the dynamics of interacting three-dimensional rigid bodies. We present a framework combining a 3D physics simulator implemented in C++ with a deep learning model constructed using PyTorch. The simulator generates training data encompassing linear and angular motion, elastic collisions, fluid friction, gravitational effects, and damping. Our deep residual network, consisting of an input layer, multiple residual blocks, and an output layer, is designed to handle the complexities of 3D dynamics. We evaluate the network's performance using a datasetof 10,000 simulated scenarios, each involving 3-5 interacting rigid bodies. The model achieves a mean squared error of 0.015 for position predictions and 0.022 for orientation predictions, representing a 25% improvement over baseline methods. Our results demonstrate the network's ability to capture intricate physical interactions, with particular success in predicting elastic collisions and rotational dynamics. This work significantly contributes to physics-informed machine learning by showcasing the immense potential of deep residual networks in modeling complex 3D physical systems. We discuss our approach's limitations and propose future directions for improving generalization to more diverse object shapes and materials.",
      "authors": [
        "Abiodun Finbarrs Oketunji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T23:40:10+00:00",
          "link": "https://arxiv.org/abs/2407.18798v1",
          "size": "170kb",
          "version": "v1"
        }
      ],
      "title": "Predicting 3D Rigid Body Dynamics with Deep Residual Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18798",
        "HTML": "https://arxiv.org/html/2407.18798",
        "PDF": "https://arxiv.org/pdf/2407.18798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates deep residual networks for predicting 3D rigid body dynamics, which is not related to LLM training data processing."
      },
      "tasks": [
        "Friction",
        "Physics-informed machine learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.16246",
      "abstract": "Ising machines are a form of quantum-inspired processing-in-memory computer which has shown great promise for overcoming the limitations of traditional computing paradigms while operating at a fraction of the energy use. The process of designing Ising machines is known as the reverse Ising problem. Unfortunately, this problem is in general computationally intractable: it is a nonconvex mixed-integer linear programming problem which cannot be naively brute-forced except in the simplest cases due to exponential scaling of runtime with number of spins. We prove new theoretical results which allow us to reduce the search space to one with quadratic scaling. We utilize this theory to develop general purpose algorithmic solutions to the reverse Ising problem. In particular, we demonstrate Ising formulations of 3-bit and 4-bit integer multiplication which use fewer total spins than previously known methods by a factor of more than three. Our results increase the practicality of implementing such circuits on modern Ising hardware, where spins are at a premium.",
      "authors": [
        "Isaac K. Martin",
        "Andrew G. Moore",
        "John T. Daly",
        "Jess J. Meyer",
        "Teresa M. Ranadive"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-24T23:33:26+00:00",
          "link": "https://arxiv.org/abs/2310.16246v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "Design of General Purpose Minimal-Auxiliary Ising Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.16246",
        "PDF": "https://arxiv.org/pdf/2310.16246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the design of Ising machines and their practical implementations on modern hardware. It does not discuss any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2305.12137",
      "abstract": "Soft robots show compliance and have infinite degrees of freedom. Thanks to these properties, such robots can be leveraged for surgery, rehabilitation, biomimetics, unstructured environment exploring, and industrial grippers. In this case, they attract scholars from a variety of areas. However, nonlinearity and hysteresis effects also bring a burden to robot modeling. Moreover, following their flexibility and adaptation, soft robot control is more challenging than rigid robot control. In order to model and control soft robots, a large number of data-driven methods are utilized in pairs or separately. This review first briefly introduces two foundations for data-driven approaches, which are physical models and the Jacobian matrix, then summarizes three kinds of data-driven approaches, which are statistical method, neural network, and reinforcement learning. This review compares the modeling and controller features, e.g., model dynamics, data requirement, and target task, within and among these categories. Finally, we summarize the features of each method. A discussion about the advantages and limitations of the existing modeling and control approaches is presented, and we forecast the future of data-driven approaches in soft robots. A website (https://sites.google.com/view/23zcb) is built for this review and will be updated frequently.",
      "authors": [
        "Zixi Chen",
        "Federico Renda",
        "Alexia Le Gall",
        "Lorenzo Mocellin",
        "Matteo Bernabei",
        "Th\\'eo Dangel",
        "Gastone Ciuti",
        "Matteo Cianchetti and Cesare Stefanini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-20T08:38:37+00:00",
          "link": "https://arxiv.org/abs/2305.12137v1",
          "size": "2058kb",
          "version": "v1"
        },
        {
          "date": "2024-03-12T10:12:14+00:00",
          "link": "https://arxiv.org/abs/2305.12137v2",
          "size": "1244kb",
          "version": "v2"
        },
        {
          "date": "2024-03-15T08:55:17+00:00",
          "link": "https://arxiv.org/abs/2305.12137v3",
          "size": "1244kb",
          "version": "v3"
        }
      ],
      "title": "Data-driven Methods Applied to Soft Robot Modeling and Control: A Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.12137",
        "HTML": "https://arxiv.org/html/2305.12137",
        "PDF": "https://arxiv.org/pdf/2305.12137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This review paper discusses data-driven methods for soft robot modeling and control, which does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.19677",
      "abstract": "Privacy is a hot topic for policymakers across the globe, including the United States. Evolving advances in AI and emerging concerns about the misuse of personal data have pushed policymakers to draft legislation on trustworthy AI and privacy protection for its citizens. This paper presents the state of the privacy legislation at the U.S. Congress and outlines how voice data is considered as part of the legislation definition. This paper also reviews additional privacy protection for children. This paper presents a holistic review of enacted and proposed privacy laws, and consideration for voice data, including guidelines for processing children's data, in those laws across the fifty U.S. states. As a groundbreaking alternative to actual human data, ethically generated synthetic data allows much flexibility to keep AI innovation in progress. Given the consideration of synthetic data in AI legislation by policymakers to be relatively new, as compared to that of privacy laws, this paper reviews regulatory considerations for synthetic data.",
      "authors": [
        "Satwik Dutta and John H.L. Hansen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Cryptography and Security (cs.CR)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T03:43:16+00:00",
          "link": "https://arxiv.org/abs/2407.19677v1",
          "size": "540kb",
          "version": "v1"
        }
      ],
      "title": "Navigating the United States Legislative Landscape on Voice Privacy: Existing Laws, Proposed Bills, Protection for Children, and Synthetic Data for AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19677",
        "HTML": "https://arxiv.org/html/2407.19677",
        "PDF": "https://arxiv.org/pdf/2407.19677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses synthetic data within the context of privacy legislation, the focus is primarily on legal aspects rather than on technical contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.04210",
      "abstract": "As in automated driving the driver becomes a passenger, carsickness might reduce comfort for susceptible individuals. Insights in the prevalence of carsickness and its modulating factors are considered useful for the development of automated vehicles to mitigate or prevent its occurrence. An online survey was conducted with N = 3999 participants in Spain, Sweden, Poland, and Germany. 30% of participants reported to have already experienced carsickness as adult. The frequency of carsickness was modulated not only by demographic factors (country, gender, age), but also by frequency of being a passenger, type of non-driving related task, road type, and the seating position in car. Furthermore, the efficiency of applied countermeasures, temporal aspects of carsickness development, as well as the relation of carsickness with the acceptability of automated driving and the effect on subjective fitness to drive was investigated. The results are discussed with focus on automated driving.",
      "authors": [
        "Myriam Metzulat",
        "Barbara Metz",
        "Aaron Edelmann",
        "Alexandra Neukum",
        "Wilfried Kunde"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T08:04:33+00:00",
          "link": "https://arxiv.org/abs/2505.04210v1",
          "size": "674kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T06:09:35+00:00",
          "link": "https://arxiv.org/abs/2505.04210v2",
          "size": "677kb",
          "version": "v2"
        }
      ],
      "title": "Sick of being driven? -- Prevalence and modulating factors of carsickness in the European population in context of automated driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04210",
        "PDF": "https://arxiv.org/pdf/2505.04210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on the prevalence and factors of carsickness related to automated driving, which does not connect to LLM training data processes or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07942",
      "abstract": "Large Language Models (LLMs) have become vital tools in software development tasks such as code generation, completion, and analysis. As their integration into workflows deepens, ensuring robustness against vulnerabilities especially those triggered by diverse or adversarial inputs becomes increasingly important. Such vulnerabilities may lead to incorrect or insecure code generation when models encounter perturbed task descriptions, code, or comments. Prior research often overlooks the role of natural language in guiding code tasks. This study investigates how adversarial perturbations in natural language inputs including prompts, comments, and descriptions affect LLMs for Code (LLM4Code). It examines the effects of perturbations at the character, word, and sentence levels to identify the most impactful vulnerabilities. We analyzed multiple projects (e.g., ReCode, OpenAttack) and datasets (e.g., HumanEval, MBPP), establishing a taxonomy of adversarial attacks. The first dimension classifies the input type code, prompts, or comments while the second dimension focuses on granularity: character, word, or sentence-level changes. We adopted a mixed-methods approach, combining quantitative performance metrics with qualitative vulnerability analysis. LLM4Code models show varying robustness across perturbation types. Sentence-level attacks were least effective, suggesting models are resilient to broader contextual changes. In contrast, word-level perturbations posed serious challenges, exposing semantic vulnerabilities. Character-level effects varied, showing model sensitivity to subtle syntactic deviations.Our study offers a structured framework for testing LLM4Code robustness and emphasizes the critical role of natural language in adversarial evaluation. Improving model resilience to semantic-level disruptions is essential for secure and reliable code-generation systems.",
      "authors": [
        "Yang Liu",
        "Armstrong Foundjem",
        "Foutse Khomh",
        "and Heng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:02:29+00:00",
          "link": "https://arxiv.org/abs/2506.07942v1",
          "size": "3340kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Attack Classification and Robustness Testing for Large Language Models for Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07942",
        "PDF": "https://arxiv.org/pdf/2506.07942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates adversarial attack robustness in LLMs for code. While it explores challenges related to model inputs, it does not discuss training data processing activities for LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.00367",
      "abstract": "Integrating Distributed Energy Resources (DERs) with peer-to-peer (P2P) energy trading offers promising solutions for grid modernization by incentivizing prosumers to participate in mitigating peak demand. However, this integration also introduces operational uncertainties and computational challenges. This paper aims to address these challenges with a novel scalable and tractable distributionally robust joint chance-constrained (DRJCC) optimization framework that effectively facilitates P2P energy trading by enhancing flexibility provision from large-scale DER operations under uncertain supply and demand. Therefore, a practical framework is proposed to solve the core challenges of DRJCC by integrating three key components: (1) a Wasserstein ambiguity set that effectively quantifies uncertainty with sparse data, (2) a CVaR-based approximation of joint chance constraints to balance computational efficiency with risk control, and (3) a privacy-preserving ADMM algorithm that enables distributed implementation through decomposition. To discern patterns in the data that indicate collaboration potential and adjust ambiguity sets for improved efficiency, K-means clustering is applied to historical scenarios. Simulation results show that the proposed framework reduces peak demand by approximately 28% and total community costs by around 31%, underscoring its effectiveness in enhancing grid robustness, operational reliability, and economic optimization in renewable-based energy management.",
      "authors": [
        "Amir Noori",
        "Babak Tavassoli",
        "Alireza Fereidunian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-31T07:00:30+00:00",
          "link": "https://arxiv.org/abs/2409.00367v1",
          "size": "572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:54:03+00:00",
          "link": "https://arxiv.org/abs/2409.00367v2",
          "size": "1193kb",
          "version": "v2"
        }
      ],
      "title": "Distributionally Robust Joint Chance-Constrained Optimization for Electricity Imbalance: Integrating Renewables and Storage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00367",
        "PDF": "https://arxiv.org/pdf/2409.00367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses challenges in energy grid modernization through a novel optimization framework and does not contribute to LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.15619",
      "abstract": "Explaining multi-agent systems (MAS) is urgent as these systems become increasingly prevalent in various applications. Previous work has proveided explanations for the actions or states of agents, yet falls short in understanding the black-boxed agent's importance within a MAS and the overall team strategy. To bridge this gap, we propose EMAI, a novel agent-level explanation approach that evaluates the individual agent's importance. Inspired by counterfactual reasoning, a larger change in reward caused by the randomized action of agent indicates its higher importance. We model it as a MARL problem to capture interactions across agents. Utilizing counterfactual reasoning, EMAI learns the masking agents to identify important agents. Specifically, we define the optimization function to minimize the reward difference before and after action randomization and introduce sparsity constraints to encourage the exploration of more action randomization of agents during training. The experimental results in seven multi-agent tasks demonstratee that EMAI achieves higher fidelity in explanations than baselines and provides more effective guidance in practical applications concerning understanding policies, launching attacks, and patching policies.",
      "authors": [
        "Jianming Chen and Yawen Wang and Junjie Wang and Xiaofei Xie and jun Hu and Qing Wang and Fanjiang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T07:24:43+00:00",
          "link": "https://arxiv.org/abs/2412.15619v1",
          "size": "2998kb",
          "version": "v1"
        },
        {
          "date": "2024-12-23T01:56:56+00:00",
          "link": "https://arxiv.org/abs/2412.15619v2",
          "size": "2998kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Individual Agent Importance in Multi-Agent System via Counterfactual Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15619",
        "HTML": "https://arxiv.org/html/2412.15619",
        "PDF": "https://arxiv.org/pdf/2412.15619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for explaining multi-agent systems using counterfactual reasoning. It does not relate to any stage of LLM pretraining or fine-tuning or involve LLM training data processing."
      },
      "tasks": [
        "counterfactual",
        "Counterfactual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.02946",
      "abstract": "LLMs produce harmful and undesirable behavior when trained on datasets containing even a small fraction of poisoned data. We demonstrate that GPT models remain vulnerable to fine-tuning on poisoned data, even when safeguarded by moderation systems. Given the persistence of data poisoning vulnerabilities in today's most capable models, this paper investigates whether these risks increase with model scaling. We evaluate three threat models -- malicious fine-tuning, imperfect data curation, and intentional data contamination -- across 24 frontier LLMs ranging from 1.5 to 72 billion parameters. Our experiments reveal that larger LLMs are significantly more susceptible to data poisoning, learning harmful behaviors from even minimal exposure to harmful data more quickly than smaller models. These findings underscore the need for leading AI companies to thoroughly red team fine-tuning APIs before public release and to develop more robust safeguards against data poisoning, particularly as models continue to scale in size and capability.",
      "authors": [
        "Dillon Bowen",
        "Brendan Murphy",
        "Will Cai",
        "David Khachaturov",
        "Adam Gleave",
        "Kellin Pelrine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-06T04:14:29+00:00",
          "link": "https://arxiv.org/abs/2408.02946v1",
          "size": "423kb",
          "version": "v1"
        },
        {
          "date": "2024-08-30T20:22:18+00:00",
          "link": "https://arxiv.org/abs/2408.02946v2",
          "size": "383kb",
          "version": "v2"
        },
        {
          "date": "2024-10-17T02:10:04+00:00",
          "link": "https://arxiv.org/abs/2408.02946v3",
          "size": "384kb",
          "version": "v3"
        },
        {
          "date": "2024-10-29T17:59:26+00:00",
          "link": "https://arxiv.org/abs/2408.02946v4",
          "size": "697kb",
          "version": "v4"
        },
        {
          "date": "2024-12-27T17:40:04+00:00",
          "link": "https://arxiv.org/abs/2408.02946v5",
          "size": "697kb",
          "version": "v5"
        },
        {
          "date": "2025-07-17T01:19:42+00:00",
          "link": "https://arxiv.org/abs/2408.02946v6",
          "size": "350kb",
          "version": "v6"
        }
      ],
      "title": "Scaling Trends for Data Poisoning in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02946",
        "HTML": "https://arxiv.org/html/2408.02946",
        "PDF": "https://arxiv.org/pdf/2408.02946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses data poisoning in LLMs and highlights issues with data curation and contamination, its main focus is on model vulnerability and safeguarding rather than providing new data processing techniques or datasets."
      },
      "tasks": [
        "Data Poisoning"
      ],
      "repo_urls": [
        "https://github.com/alignmentresearch/scaling-poisoning",
        "https://github.com/emergent-misalignment/emergent-misalignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03483",
      "abstract": "Modular soft robot arms (MSRAs) are composed of multiple modules connected in a sequence, and they can bend at different angles in various directions. This capability allows MSRAs to perform more intricate tasks than single-module robots. However, the modular structure also induces challenges in accurate planning and control. Nonlinearity and hysteresis complicate the physical model, while the modular structure and increased DOFs further lead to cumulative errors along the sequence. To address these challenges, we propose a versatile configuration space planning and control strategy for MSRAs, named S2C2A (State to Configuration to Action). Our approach formulates an optimization problem, S2C (State to Configuration planning), which integrates various loss functions and a forward model based on biLSTM to generate configuration trajectories based on target states. A configuration controller C2A (Configuration to Action control) based on biLSTM is implemented to follow the planned configuration trajectories, leveraging only inaccurate internal sensing feedback. We validate our strategy using a cable-driven MSRA, demonstrating its ability to perform diverse offline tasks such as position and orientation control and obstacle avoidance. Furthermore, our strategy endows MSRA with online interaction capability with targets and obstacles. Future work focuses on addressing MSRA challenges, such as more accurate physical models.",
      "authors": [
        "Zixi Chen",
        "Qinghua Guan",
        "Josie Hughes",
        "Arianna Menciassi",
        "Cesare Stefanini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T14:54:53+00:00",
          "link": "https://arxiv.org/abs/2410.03483v1",
          "size": "5579kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T19:06:45+00:00",
          "link": "https://arxiv.org/abs/2410.03483v2",
          "size": "4809kb",
          "version": "v2"
        }
      ],
      "title": "A Versatile Neural Network Configuration Space Planning and Control Strategy for Modular Soft Robot Arms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03483",
        "HTML": "https://arxiv.org/html/2410.03483",
        "PDF": "https://arxiv.org/pdf/2410.03483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a planning and control strategy for modular soft robot arms. There is no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.15464",
      "abstract": "Data catalogs play a crucial role in modern data-driven organizations by facilitating the discovery, understanding, and utilization of diverse data assets. However, ensuring their quality and reliability is complex, especially in open and large-scale data environments. This paper proposes a framework to automatically determine the quality of open data catalogs, addressing the need for efficient and reliable quality assessment mechanisms. Our framework can analyze various core quality dimensions, such as accuracy, completeness, consistency, scalability, and timeliness, offer several alternatives for the assessment of compatibility and similarity across such catalogs as well as the implementation of a set of non-core quality dimensions such as provenance, readability, and licensing. The goal is to empower data-driven organizations to make informed decisions based on trustworthy and well-curated data assets. The source code that illustrates our approach can be downloaded from https://www.github.com/jorge-martinez-gil/dataq/.",
      "authors": [
        "Jorge Martinez-Gil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-28T10:34:47+00:00",
          "link": "https://arxiv.org/abs/2307.15464v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2023-08-04T06:12:11+00:00",
          "link": "https://arxiv.org/abs/2307.15464v2",
          "size": "36kb",
          "version": "v2"
        },
        {
          "date": "2023-08-11T10:08:00+00:00",
          "link": "https://arxiv.org/abs/2307.15464v3",
          "size": "36kb",
          "version": "v3"
        },
        {
          "date": "2023-08-14T11:30:51+00:00",
          "link": "https://arxiv.org/abs/2307.15464v4",
          "size": "36kb",
          "version": "v4"
        },
        {
          "date": "2023-08-31T12:50:59+00:00",
          "link": "https://arxiv.org/abs/2307.15464v5",
          "size": "36kb",
          "version": "v5"
        },
        {
          "date": "2023-12-22T10:22:07+00:00",
          "link": "https://arxiv.org/abs/2307.15464v6",
          "size": "37kb",
          "version": "v6"
        },
        {
          "date": "2024-03-28T13:28:13+00:00",
          "link": "https://arxiv.org/abs/2307.15464v7",
          "size": "34kb",
          "version": "v7"
        }
      ],
      "title": "Framework to Automatically Determine the Quality of Open Data Catalogs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.15464",
        "HTML": "https://arxiv.org/html/2307.15464",
        "PDF": "https://arxiv.org/pdf/2307.15464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for assessing the quality of open data catalogs, but it does not relate to LLM training data processing specifically."
      },
      "tasks": [
        "Metadata quality"
      ],
      "repo_urls": [
        "https://github.com/jorge-martinez-gil/dataq"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23765",
      "abstract": "The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis.",
      "authors": [
        "Yun Li",
        "Yiming Zhang",
        "Tao Lin",
        "Xiangrui Liu",
        "Wenxiao Cai",
        "Zheng Liu",
        "Bo Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T06:30:35+00:00",
          "link": "https://arxiv.org/abs/2503.23765v1",
          "size": "2123kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T18:07:39+00:00",
          "link": "https://arxiv.org/abs/2503.23765v2",
          "size": "2543kb",
          "version": "v2"
        },
        {
          "date": "2025-04-21T13:43:53+00:00",
          "link": "https://arxiv.org/abs/2503.23765v3",
          "size": "2547kb",
          "version": "v3"
        },
        {
          "date": "2025-05-22T19:47:24+00:00",
          "link": "https://arxiv.org/abs/2503.23765v4",
          "size": "3156kb",
          "version": "v4"
        },
        {
          "date": "2025-06-26T15:15:48+00:00",
          "link": "https://arxiv.org/abs/2503.23765v5",
          "size": "4239kb",
          "version": "v5"
        },
        {
          "date": "2025-07-17T03:46:15+00:00",
          "link": "https://arxiv.org/abs/2503.23765v6",
          "size": "3449kb",
          "version": "v6"
        }
      ],
      "title": "STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23765",
        "HTML": "https://arxiv.org/html/2503.23765",
        "PDF": "https://arxiv.org/pdf/2503.23765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for evaluating spatial-temporal understanding in MLLMs, focusing on model evaluation rather than any aspect of LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "MINT-SJTU/STI-Bench",
          "downloads": "174",
          "likes": "4",
          "link": "https://huggingface.co/datasets/MINT-SJTU/STI-Bench"
        }
      ],
      "tasks": [
        "Autonomous Driving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10088",
      "abstract": "Robotic ultrasound systems can enhance medical diagnostics, but patient acceptance is a challenge. We propose a system combining an AI-powered conversational virtual agent with three mixed reality visualizations to improve trust and comfort. The virtual agent, powered by a large language model, engages in natural conversations and guides the ultrasound robot, enhancing interaction reliability. The visualizations include augmented reality, augmented virtuality, and fully immersive virtual reality, each designed to create patient-friendly experiences. A user study demonstrated significant improvements in trust and acceptance, offering valuable insights for designing mixed reality and virtual agents in autonomous medical procedures.",
      "authors": [
        "Tianyu Song",
        "Felix Pabst",
        "Ulrich Eck",
        "Nassir Navab"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T11:21:18+00:00",
          "link": "https://arxiv.org/abs/2502.10088v1",
          "size": "23784kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Patient Acceptance of Robotic Ultrasound through Conversational Virtual Agent and Immersive Visualizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10088",
        "HTML": "https://arxiv.org/html/2502.10088",
        "PDF": "https://arxiv.org/pdf/2502.10088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves a large language model for a conversational virtual agent, its focus is on enhancing patient interaction with robotic ultrasound, not on training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/stytim/Robotic-US-with-Virtual-Agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.03884",
      "abstract": "This paper investigates the utilization of Quantum Computing and Neuromorphic Computing for Safe, Reliable, and Explainable Multi_Agent Reinforcement Learning (MARL) in the context of optimal control in autonomous robotics. The objective was to address the challenges of optimizing the behavior of autonomous agents while ensuring safety, reliability, and explainability. Quantum Computing techniques, including Quantum Approximate Optimization Algorithm (QAOA), were employed to efficiently explore large solution spaces and find approximate solutions to complex MARL problems. Neuromorphic Computing, inspired by the architecture of the human brain, provided parallel and distributed processing capabilities, which were leveraged to develop intelligent and adaptive systems. The combination of these technologies held the potential to enhance the safety, reliability, and explainability of MARL in autonomous robotics. This research contributed to the advancement of autonomous robotics by exploring cutting-edge technologies and their applications in multi-agent systems. Codes and data are available.",
      "authors": [
        "Mazyar Taghavi and Rahman Farnoosh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T15:43:30+00:00",
          "link": "https://arxiv.org/abs/2408.03884v1",
          "size": "693kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T11:58:42+00:00",
          "link": "https://arxiv.org/abs/2408.03884v2",
          "size": "1746kb",
          "version": "v2"
        }
      ],
      "title": "Quantum Computing and Neuromorphic Computing for Safe, Reliable, and explainable Multi-Agent Reinforcement Learning: Optimal Control in Autonomous Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.03884",
        "HTML": "https://arxiv.org/html/2408.03884",
        "PDF": "https://arxiv.org/pdf/2408.03884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the utilization of quantum and neuromorphic computing for reinforcement learning in robotics, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Multi-agent Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.04123",
      "abstract": "Emotion recognition in social situations is a complex task that requires integrating information from both facial expressions and the situational context. While traditional approaches to automatic emotion recognition have focused on decontextualized signals, recent research emphasizes the importance of context in shaping emotion perceptions. This paper contributes to the emerging field of context-based emotion recognition by leveraging psychological theories of human emotion perception to inform the design of automated methods. We propose an approach that combines emotion recognition methods with Bayesian Cue Integration (BCI) to integrate emotion inferences from decontextualized facial expressions and contextual knowledge inferred via Large-language Models. We test this approach in the context of interpreting facial expressions during a social task, the prisoner's dilemma. Our results provide clear support for BCI across a range of automatic emotion recognition methods. The best automated method achieved results comparable to human observers, suggesting the potential for this approach to advance the field of affective computing.",
      "authors": [
        "Bin Han",
        "Cleo Yau",
        "Su Lei",
        "Jonathan Gratch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-07T23:18:16+00:00",
          "link": "https://arxiv.org/abs/2408.04123v1",
          "size": "1646kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge-based Emotion Recognition using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04123",
        "HTML": "https://arxiv.org/html/2408.04123",
        "PDF": "https://arxiv.org/pdf/2408.04123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on emotion recognition using LLMs in a context-based fashion, primarily dealing with model application in affective computing rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.01866",
      "abstract": "When interacting with each other, humans adjust their behavior based on perceived trust. To achieve similar adaptability, robots must accurately estimate human trust at sufficiently granular timescales while collaborating with humans. Beta reputation is a popular way to formalize a mathematical estimation of human trust. However, it relies on binary performance, which updates trust estimations only after each task concludes. Additionally, manually crafting a reward function is the usual method of building a performance indicator, which is labor-intensive and time-consuming. These limitations prevent efficient capture of continuous trust changes at more granular timescales throughout the collaboration task. Therefore, this paper presents a new framework for the estimation of human trust using beta reputation at fine-grained timescales. To achieve granularity in beta reputation, we utilize continuous reward values to update trust estimates at each timestep of a task. We construct a continuous reward function using maximum entropy optimization to eliminate the need for the laborious specification of a performance indicator. The proposed framework improves trust estimations by increasing accuracy, eliminating the need to manually craft a reward function, and advancing toward the development of more intelligent robots.",
      "authors": [
        "Resul Dagdanov",
        "Milan Andrejevic",
        "Dikai Liu",
        "Chin-Teng Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T07:46:24+00:00",
          "link": "https://arxiv.org/abs/2411.01866v1",
          "size": "4851kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T11:25:50+00:00",
          "link": "https://arxiv.org/abs/2411.01866v2",
          "size": "4539kb",
          "version": "v2"
        }
      ],
      "title": "Improving Trust Estimation in Human-Robot Collaboration Using Beta Reputation at Fine-grained Timescales",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01866",
        "HTML": "https://arxiv.org/html/2411.01866",
        "PDF": "https://arxiv.org/pdf/2411.01866"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses trust estimation in human-robot collaboration using a beta reputation framework. It is not related to LLM training data processing or any aspect of data engineering for language models."
      },
      "tasks": [
        "Bayesian Inference",
        "Behavioural cloning",
        "Human-Object Relationship Detection",
        "Robot Manipulation"
      ],
      "repo_urls": [
        "https://github.com/resuldagdanov/robot-learning-human-trust"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08905",
      "abstract": "This paper presents a novel and efficient method for characteristic mode decomposition in multi-structure systems. By leveraging the translation and rotation matrices of vector spherical wavefunctions, our approach enables the synthesis of a composite system's characteristic modes using independently computed simulations of its constituent structures. The computationally intensive translation process is simplified by decomposing it into three streamlined sub-tasks: rotation, z-axis translation, and inverse rotation, collectively achieving significant improvements in computational efficiency. Furthermore, this method facilitates the exploration of structural orientation effects without incurring additional computational overhead. A series of illustrative numerical examples is provided to validate the accuracy of the proposed method and underscore its substantial advantages in both computational efficiency and practical applicability.",
      "authors": [
        "Chenbo Shi",
        "Xin Gu",
        "Shichen Liang",
        "Jin Pan and Le Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T13:43:12+00:00",
          "link": "https://arxiv.org/abs/2411.08905v1",
          "size": "1154kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T13:57:59+00:00",
          "link": "https://arxiv.org/abs/2411.08905v2",
          "size": "1888kb",
          "version": "v2"
        }
      ],
      "title": "Synthesis Method for Obtaining Characteristic Modes of Multi-Structure Systems via independent Structure T-Matrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08905",
        "HTML": "https://arxiv.org/html/2411.08905",
        "PDF": "https://arxiv.org/pdf/2411.08905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on characteristic mode decomposition in multi-structure systems and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Multimedia (cs.MM)",
    "Quantum Physics (quant-ph)",
    "Optimization and Control (math.OC)",
    "Physics and Society (physics.soc-ph)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Image and Video Processing (eess.IV)",
    "Sound (cs.SD)",
    "Methodology (stat.ME)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Plasma Physics (physics.plasm-ph)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Representation Theory (math.RT)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Astrophysics of Galaxies (astro-ph.GA)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Probability (math.PR)",
    "Space Physics (physics.space-ph)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Information Theory (math.IT)",
    "Discrete Mathematics (cs.DM)",
    "Emerging Technologies (cs.ET)",
    "Mathematical Finance (q-fin.MF)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Spectral Theory (math.SP)",
    "Audio and Speech Processing (eess.AS)",
    "Other Computer Science (cs.OH)",
    "Social and Information Networks (cs.SI)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Machine Learning (stat.ML)",
    "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Biomolecules (q-bio.BM)",
    "Molecular Networks (q-bio.MN)",
    "Group Theory (math.GR)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Pattern Formation and Solitons (nlin.PS)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Computational Physics (physics.comp-ph)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Commutative Algebra (math.AC)",
    "Dynamical Systems (math.DS)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to the performance of large language models (LLMs). You are a computer science expert specializing in LLM training data processing. Your task is to analyze a set of arXiv papers and determine their relevance to **LLM training data processing**.\n\n### **Task Objective**\n\nFor each paper, assess whether it makes a technical contribution to **LLM training data processing**.\n\n1. First, the paper must relate to data processing for **pretraining or fine-tuning**, including stages such as LLM pretraining, instruction fine-tuning, supervised fine-tuning (SFT), or alignment fine-tuning.\n2. Second, the paper must involve **training data processing** operations, such as:\n\n   * Data engineering operations, including data collection, data generation, deduplication, filtering, etc.;\n   * Techniques or methods that significantly improve data quality;\n   * Creation or generation of new datasets.\n\n### Answer: **Relevance Classification**\n\n**`core`**: The paper makes a direct contribution to LLM training data processing. Examples include: creation, generation, or synthesis of new datasets; building higher-quality datasets from existing ones; novel data processing techniques; or any data engineering operations that substantially improve data quality.\n\n**`partial`**: The paper briefly discusses training data processing, but the main focus lies elsewhere\u2014such as model architecture, task design, evaluation, or prompt engineering\u2014rather than training data processing.\n\n**`irrelevant`**: The paper does not address any aspect of LLM training data processing.\n\n### **Output Format (strictly follow this JSON structure)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<Paper ID>\",\n      \"answer\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1\u20132 sentence explanation of your classification, citing key content from the abstract or methodology section.\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n\n### Example\n\ninput:\n\n```\n[\n    {\n        \"id\": \"2411.12372\",\n        \"title\": \"RedPajama: an Open Dataset for Training Large Language Models\",\n        \"abstract\": \"Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and metadata for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce's XGen and AI2's OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.\"\n    },\n    {\n        \"id\": \"2306.01116\",\n        \"title\": \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\",\n        \"abstract\": \"Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.\"\n    }\n]\n```\n\noutput:\n\n```\n{\n  \"result\": [\n    {\n      \"id\": \"2411.12372\",\n      \"answer\": \"core\",\n      \"reason\": \"This paper releases RedPajama-V1 and V2 datasets, comprising over 100 trillion tokens, and introduces quality signals for filtering. It involves data collection, deduplication, filtering, and quality assessment, making a significant contribution to LLM training data processing.\"\n    },\n    {\n      \"id\": \"2306.01116\",\n      \"answer\": \"core\",\n      \"reason\": \"The paper presents the RefinedWeb dataset, which uses only deduplicated and filtered web data to train LLMs. It challenges the conventional reliance on mixed curated corpora and publicly releases both the dataset and models, representing a core contribution to high-quality data construction.\"\n    }\n  ]\n}\n\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 637,
    "partial": 98,
    "core": 14
  },
  "arxiv_update_date": "2025-07-18",
  "updated_at": "2025-07-18 10:18:28"
}