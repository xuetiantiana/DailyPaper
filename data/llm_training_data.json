{
  "data": [
    {
      "id": "2507.07333",
      "abstract": "Augmented reality is revolutionizing beauty industry with virtual try-on (VTO) applications, which empowers users to try a wide variety of products using their phones without the hassle of physically putting on real products. A critical technical challenge in foundation VTO applications is the accurate synthesis of foundation-skin tone color blending while maintaining the scalability of the method across diverse product ranges. In this work, we propose a novel method to approximate well-established Kubelka-Munk (KM) theory for faster image synthesis while preserving foundation-skin tone color blending realism. Additionally, we build a scalable end-to-end framework for realistic foundation makeup VTO solely depending on the product information available on e-commerce sites. We validate our method using real-world makeup images, demonstrating that our framework outperforms other techniques.",
      "authors": [
        "Hui Pang",
        "Sunil Hadap",
        "Violetta Shevchenko",
        "Rahul Suresh",
        "Amin Banitalebi-Dehkordi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:19:28+00:00",
          "link": "https://arxiv.org/abs/2507.07333v1",
          "size": "14576kb",
          "version": "v1"
        }
      ],
      "title": "Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07333",
        "HTML": "https://arxiv.org/html/2507.07333v1",
        "PDF": "https://arxiv.org/pdf/2507.07333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a virtual try-on application for foundation makeup and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.07599",
      "abstract": "Generative AI is transforming education by enabling personalized, on-demand learning experiences. However, AI tutors lack the ability to assess a learner's cognitive state in real time, limiting their adaptability. Meanwhile, electroencephalography (EEG)-based neuroadaptive systems have successfully enhanced engagement by dynamically adjusting learning content. This paper presents NeuroChat, a proof-of-concept neuroadaptive AI tutor that integrates real-time EEG-based engagement tracking with generative AI. NeuroChat continuously monitors a learner's cognitive engagement and dynamically adjusts content complexity, response style, and pacing using a closed-loop system. We evaluate this approach in a pilot study (n=24), comparing NeuroChat to a standard LLM-based chatbot. Results indicate that NeuroChat enhances cognitive and subjective engagement but does not show an immediate effect on learning outcomes. These findings demonstrate the feasibility of real-time cognitive feedback in LLMs, highlighting new directions for adaptive learning, AI tutoring, and human-AI interaction.",
      "authors": [
        "D\\\"unya Baradari",
        "Nataliya Kosmyna",
        "Oscar Petrov",
        "Rebecah Kaplun",
        "Pattie Maes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T17:57:20+00:00",
          "link": "https://arxiv.org/abs/2503.07599v1",
          "size": "7733kb",
          "version": "v1"
        }
      ],
      "title": "NeuroChat: A Neuroadaptive AI Chatbot for Customizing Learning Experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07599",
        "PDF": "https://arxiv.org/pdf/2503.07599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores integrating EEG with generative AI for real-time adaptive learning, but does not focus on LLM training data processing."
      },
      "tasks": [
        "Chatbot",
        "EEG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.04645",
      "abstract": "We study the problem of capacity modification in the many-to-one stable matching of workers and firms. Our goal is to systematically study how the set of stable matchings changes when some seats are added to or removed from the firms. We make three main contributions: First, we examine whether firms and workers can improve or worsen upon changing the capacities under worker-proposing and firm-proposing deferred acceptance algorithms. Second, we study the computational problem of adding or removing seats to either match a fixed worker-firm pair in some stable matching or make a fixed matching stable with respect to the modified problem. We develop polynomial-time algorithms for these problems when only the overall change in the firms' capacities is restricted, and show NP-hardness when there are additional constraints for individual firms. Lastly, we compare capacity modification with the classical model of preference manipulation by firms and identify scenarios under which one mode of manipulation outperforms the other. We find that a threshold on a given firm's capacity, which we call its peak, crucially determines the effectiveness of different manipulation actions.",
      "authors": [
        "Salil Gokhale",
        "Shivika Narang",
        "Samarth Singla",
        "Rohit Vaish"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T08:17:00+00:00",
          "link": "https://arxiv.org/abs/2402.04645v1",
          "size": "63kb",
          "version": "v1"
        },
        {
          "date": "2024-06-18T06:19:00+00:00",
          "link": "https://arxiv.org/abs/2402.04645v2",
          "size": "56kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T01:56:53+00:00",
          "link": "https://arxiv.org/abs/2402.04645v3",
          "size": "61kb",
          "version": "v3"
        }
      ],
      "title": "Capacity Modification in the Stable Matching Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04645",
        "HTML": "https://arxiv.org/html/2402.04645v3",
        "PDF": "https://arxiv.org/pdf/2402.04645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines capacity modification within stable matching problems, unrelated to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.13200",
      "abstract": "In this work, we address the challenges posed by the high nonlinearity of the Butler-Volmer (BV) equation in forward and inverse simulations of the pseudo-two-dimensional (P2D) model using the physics-informed neural network (PINN) framework. The BV equation presents significant challenges for PINNs, primarily due to the hyperbolic sine term, which renders the Hessian of the PINN loss function highly ill-conditioned. To address this issue, we introduce a bypassing term that improves numerical stability by substantially reducing the condition number of the Hessian matrix. Furthermore, the small magnitude of the ionic flux \\( j \\) often leads to a common failure mode where PINNs converge to incorrect solutions. We demonstrate that incorporating a secondary conservation law for the solid-phase potential \\( \\psi \\) effectively prevents such convergence issues and ensures solution accuracy. The proposed methods prove effective for solving both forward and inverse problems involving the BV equation. Specifically, we achieve precise parameter estimation in inverse scenarios and reliable solution predictions for forward simulations.",
      "authors": [
        "Myeong-Su Lee",
        "Jaemin Oh",
        "Dong-Chan Lee",
        "KangWook Lee",
        "Sooncheol Park",
        "Youngjoon Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T02:50:46+00:00",
          "link": "https://arxiv.org/abs/2412.13200v1",
          "size": "1268kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T03:25:32+00:00",
          "link": "https://arxiv.org/abs/2412.13200v2",
          "size": "2315kb",
          "version": "v2"
        }
      ],
      "title": "Forward and Inverse Simulation of Pseudo-Two-Dimensional Model of Lithium-Ion Batteries Using Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13200",
        "HTML": "https://arxiv.org/html/2412.13200",
        "PDF": "https://arxiv.org/pdf/2412.13200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on simulating a model of lithium-ion batteries using neural networks. It does not involve any processing or creation of LLM training data."
      },
      "tasks": [
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.07914",
      "abstract": "This work concerns the numerical analysis of the linear elasticity problem with a Robin boundary condition on a smooth domain. A finite element discretization is presented using high-order curved meshes in order to accurately discretize the physical domain. The primary objective is to conduct a detailed error analysis for the elasticity problem using the vector lift operator, which maps vector-valued functions from the mesh domain to the physical domain. Error estimates are established, both in terms of the finite element approximation error and the geometric error, respectively associated to the finite element degree and to the mesh order. These theoretical a priori error estimates are validated by numerical experiments in 2D and 3D.",
      "authors": [
        "Joyce Ghantous (IMB",
        "MEMPHIS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T07:56:20+00:00",
          "link": "https://arxiv.org/abs/2501.07914v1",
          "size": "2342kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:00:44+00:00",
          "link": "https://arxiv.org/abs/2501.07914v2",
          "size": "2343kb",
          "version": "v2"
        }
      ],
      "title": "Using curved meshes to derive a priori error estimates for a linear elasticity problem with Robin boundary conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07914",
        "PDF": "https://arxiv.org/pdf/2501.07914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with numerical analysis for a linear elasticity problem, focusing purely on error estimates, without mentioning LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04750",
      "abstract": "Particle Image Velocimetry (PIV) is fundamental to fluid dynamics, yet deep learning applications face significant hurdles. A critical gap exists: the lack of comprehensive evaluation of how diverse optical flow models perform specifically on PIV data, largely due to limitations in available datasets and the absence of a standardized benchmark. This prevents fair comparison and hinders progress. To address this, our primary contribution is a novel, large-scale synthetic PIV benchmark dataset generated from diverse CFD simulations (JHTDB and Blasius). It features unprecedented variety in particle densities, flow velocities, and continuous motion, enabling, for the first time, a standardized and rigorous evaluation of various optical flow and PIV algorithms. Complementing this, we propose Multi Cost Volume PIV (MCFormer), a new deep network architecture leveraging multi-frame temporal information and multiple cost volumes, specifically designed for PIV's sparse nature. Our comprehensive benchmark evaluation, the first of its kind, reveals significant performance variations among adapted optical flow models and demonstrates that MCFormer significantly outperforms existing methods, achieving the lowest overall normalized endpoint error (NEPE). This work provides both a foundational benchmark resource essential for future PIV research and a state-of-the-art method tailored for PIV challenges. We make our benchmark dataset and code publicly available to foster future research in this area.",
      "authors": [
        "Zicheng Lin (International School",
        "Beijing University of Posts and Telecommunications)",
        "Xiaoqiang Li (College of Engineering",
        "Peking University)",
        "Yichao Wang (College of Physics and Optoelectronic Engineering",
        "Harbin Engineering University)",
        "Chuang Zhu (School of Artificial Intelligence",
        "Beijing University of Posts and Telecommunications)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T08:26:18+00:00",
          "link": "https://arxiv.org/abs/2507.04750v1",
          "size": "10018kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:40:29+00:00",
          "link": "https://arxiv.org/abs/2507.04750v2",
          "size": "3555kb",
          "version": "v2"
        }
      ],
      "title": "MCFormer: A Multi-Cost-Volume Network and Comprehensive Benchmark for Particle Image Velocimetry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04750",
        "HTML": "https://arxiv.org/html/2507.04750v2",
        "PDF": "https://arxiv.org/pdf/2507.04750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes a large-scale synthetic PIV benchmark dataset and discusses generating and processing data from CFD simulations for evaluating models, making a direct contribution to improving data quality and processing methods relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07137",
      "abstract": "Machine unlearning (MU) is a promising cost-effective method to cleanse undesired information (generated concepts, biases, or patterns) from foundational diffusion models. While MU is orders of magnitude less costly than retraining a diffusion model without the undesired information, it can be challenging and labor-intensive to prove that the information has been fully removed from the model. Moreover, MU can damage diffusion model performance on surrounding concepts that one would like to retain, making it unclear if the diffusion model is still fit for deployment. We introduce autoeval-dmun, an automated tool which leverages (vision-) language models to thoroughly assess unlearning in diffusion models. Given a target concept, autoeval-dmun extracts structured, relevant world knowledge from the language model to identify nearby concepts which are likely damaged by unlearning and to circumvent unlearning with adversarial prompts. We use our automated tool to evaluate popular diffusion model unlearning methods, revealing that language models (1) impose semantic orderings of nearby concepts which correlate well with unlearning damage and (2) effectively circumvent unlearning with synthetic adversarial prompts.",
      "authors": [
        "Eric Yeats",
        "Darryl Hannan",
        "Henry Kvinge",
        "Timothy Doster",
        "Scott Mahan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:51:09+00:00",
          "link": "https://arxiv.org/abs/2507.07137v1",
          "size": "733kb",
          "version": "v1"
        }
      ],
      "title": "Automating Evaluation of Diffusion Model Unlearning with (Vision-) Language Model World Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07137",
        "HTML": "https://arxiv.org/html/2507.07137v1",
        "PDF": "https://arxiv.org/pdf/2507.07137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on automating diffusion model unlearning evaluation using language models, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07495",
      "abstract": "Recently, decomposing complex problems into simple subtasks--a crucial part of human-like natural planning--to solve the given problem has significantly boosted the performance of large language models (LLMs). However, leveraging such planning structures during post-training to boost the performance of smaller open-source LLMs remains underexplored. Motivated by this, we introduce PLAN-TUNING, a unified post-training framework that (i) distills synthetic task decompositions (termed \"planning trajectories\") from large-scale LLMs and (ii) fine-tunes smaller models via supervised and reinforcement-learning objectives designed to mimic these planning processes to improve complex reasoning. On GSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by an average $\\sim7\\%$. Furthermore, plan-tuned models show better generalization capabilities on out-of-domain datasets, with average $\\sim10\\%$ and $\\sim12\\%$ performance improvements on OlympiadBench and AIME 2024, respectively. Our detailed analysis demonstrates how planning trajectories improves complex reasoning capabilities, showing that PLAN-TUNING is an effective strategy for improving task-specific performance of smaller LLMs.",
      "authors": [
        "Mihir Parmar",
        "Palash Goyal",
        "Xin Liu",
        "Yiwen Song",
        "Mingyang Ling",
        "Chitta Baral",
        "Hamid Palangi",
        "Tomas Pfister"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:30:44+00:00",
          "link": "https://arxiv.org/abs/2507.07495v1",
          "size": "400kb",
          "version": "v1"
        }
      ],
      "title": "PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07495",
        "PDF": "https://arxiv.org/pdf/2507.07495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning LLMs using synthetic task decompositions to improve reasoning, focusing on model performance rather than on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07607",
      "abstract": "We present a stabilized, structure-preserving finite element framework for solving the Vlasov-Maxwell equations. The method uses a tensor product of continuous polynomial spaces for the spatial and velocity domains, respectively, to discretize the Vlasov equation, combined with curl- and divergence-conforming N\\'ed\\'elec and Raviart-Thomas elements for Maxwell's equations on Cartesian grids. A novel, robust, consistent, and high-order accurate residual-based artificial viscosity method is introduced for stabilizing the Vlasov equations. The proposed method is tested on the 1D2V and 2D2V reduced Vlasov-Maxwell system, achieving optimal convergence orders for all polynomial spaces considered in this study. Several challenging benchmarks are solved to validate the effectiveness of the proposed method.",
      "authors": [
        "Katharina Kormann",
        "Murtazo Nazarov",
        "Junjie Wen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:20:52+00:00",
          "link": "https://arxiv.org/abs/2507.07607v1",
          "size": "3785kb",
          "version": "v1"
        }
      ],
      "title": "A structure-preserving finite element framework for the Vlasov-Maxwell system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07607",
        "HTML": "https://arxiv.org/html/2507.07607v1",
        "PDF": "https://arxiv.org/pdf/2507.07607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a finite element framework for the Vlasov-Maxwell system, focusing on equation-solving methodologies rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07675",
      "abstract": "We analyze the layerwise effective dimension (rank of the feature matrix) in fully-connected ReLU networks of finite width. Specifically, for a fixed batch of $m$ inputs and random Gaussian weights, we derive closed-form expressions for the expected rank of the \\$m\\times n\\$ hidden activation matrices. Our main result shows that $\\mathbb{E}[EDim(\\ell)]=m[1-(1-2/\\pi)^\\ell]+O(e^{-c m})$ so that the rank deficit decays geometrically with ratio $1-2 / \\pi \\approx 0.3634$. We also prove a sub-Gaussian concentration bound, and identify the \"revival\" depths at which the expected rank attains local maxima. In particular, these peaks occur at depths $\\ell_k^*\\approx(k+1/2)\\pi/\\log(1/\\rho)$ with height $\\approx (1-e^{-\\pi/2}) m \\approx 0.79m$. We further show that this oscillatory rank behavior is a finite-width phenomenon: under orthogonal weight initialization or strong negative-slope leaky-ReLU, the rank remains (nearly) full. These results provide a precise characterization of how random ReLU layers alternately collapse and partially revive the subspace of input variations, adding nuance to prior work on expressivity of deep networks.",
      "authors": [
        "Darshan Makwana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:54:18+00:00",
          "link": "https://arxiv.org/abs/2507.07675v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Some Theoretical Results on Layerwise Effective Dimension Oscillations in Finite Width ReLU Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07675",
        "HTML": "https://arxiv.org/html/2507.07675v1",
        "PDF": "https://arxiv.org/pdf/2507.07675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on theoretical analysis of layerwise effective dimension in ReLU networks and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.14641",
      "abstract": "In high-level synthesis (HLS), C/C++ programs with synthesis directives are used to generate circuits for FPGA implementations. However, hardware-specific and platform-dependent characteristics in these implementations can introduce behavioral discrepancies between the original C/C++ programs and the circuits after high-level synthesis. Existing methods for testing behavioral discrepancies in HLS are still immature, and the testing workflow requires significant human efforts. To address this challenge, we propose HLSTester, a large language model (LLM) aided testing framework that efficiently detects behavioral discrepancies in HLS. To mitigate hallucinations in LLMs and enhance prompt quality, the testbenches for original C/C++ programs are leveraged to guide LLMs in generating HLS-compatible testbenches, effectively eliminating certain traditional C/C++ constructs that are incompatible with HLS tools. Key variables are pinpointed through a backward slicing technique in both C/C++ and HLS programs to monitor their runtime spectra, enabling an in-depth analysis of the discrepancy symptoms. To reduce test time, a testing input generation mechanism is introduced to integrate dynamic mutation with insights from an LLM-based progressive reasoning chain. In addition, repetitive hardware testing is skipped by a redundancy-aware filtering technique for the generated test inputs. Experimental results demonstrate that the proposed LLM-aided testing framework significantly accelerates the testing workflow while achieving higher testbench simulation pass rates compared with the traditional method and the direct use of LLMs on the same HLS programs.",
      "authors": [
        "Kangwei Xu",
        "Bing Li",
        "Grace Li Zhang",
        "Ulf Schlichtmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T14:45:01+00:00",
          "link": "https://arxiv.org/abs/2504.14641v1",
          "size": "1805kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T18:19:34+00:00",
          "link": "https://arxiv.org/abs/2504.14641v2",
          "size": "2635kb",
          "version": "v2"
        }
      ],
      "title": "HLSTester: Efficient Testing of Behavioral Discrepancies with LLMs for High-Level Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14641",
        "HTML": "https://arxiv.org/html/2504.14641v2",
        "PDF": "https://arxiv.org/pdf/2504.14641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes an LLM-aided framework for testing discrepancies in high-level synthesis, it briefly involves using LLMs for generating testbenches, but the focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21207",
      "abstract": "Enabled by progress in superconducting technology, several continuous wave linear accelerators are foreseen in the next decade. For these machines, it is of crucial importance to track the main cavity parameters, such as the resonator bandwidth and detuning. The bandwidth yields information on the superconducting state of the cavity. The detuning should be minimized to limit the required power to operate the cavity. The estimation of these parameters is commonly implemented in the digital electronics of the Low-Level RF control system to minimize the computation delay. In this proceeding, we present a way to compute the bandwidth and detuning using a Luenberger observer. In contrast to previous methods, a state observer yields estimations at the native control system sample rate without explicitly filtering the input signals. Additionally, the error convergence properties of the estimations can be controlled intuitively by adjusting gain parameters. Implementation considerations and test results on the derived observer are presented in the manuscript.",
      "authors": [
        "Bozo Richter",
        "Andrea Bellandi",
        "Julien Branlard",
        "Leon Speidel",
        "Annika Eichler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Accelerator Physics (physics.acc-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:02:38+00:00",
          "link": "https://arxiv.org/abs/2506.21207v1",
          "size": "223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:06:47+00:00",
          "link": "https://arxiv.org/abs/2506.21207v2",
          "size": "222kb",
          "version": "v2"
        }
      ],
      "title": "Estimation of superconducting cavity bandwidth and detuning using a Luenberger observer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21207",
        "HTML": "https://arxiv.org/html/2506.21207v2",
        "PDF": "https://arxiv.org/pdf/2506.21207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating superconducting cavity bandwidth and detuning using a Luenberger observer, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07633",
      "abstract": "Recent advances in video generation techniques have given rise to an emerging paradigm of generative video coding, aiming to achieve semantically accurate reconstructions in Ultra-Low Bitrate (ULB) scenarios by leveraging strong generative priors. However, most existing methods are limited by domain specificity (e.g., facial or human videos) or an excessive dependence on high-level text guidance, which often fails to capture motion details and results in unrealistic reconstructions. To address these challenges, we propose a Trajectory-Guided Generative Video Coding framework (dubbed T-GVC). T-GVC employs a semantic-aware sparse motion sampling pipeline to effectively bridge low-level motion tracking with high-level semantic understanding by extracting pixel-wise motion as sparse trajectory points based on their semantic importance, not only significantly reducing the bitrate but also preserving critical temporal semantic information. In addition, by incorporating trajectory-aligned loss constraints into diffusion processes, we introduce a training-free latent space guidance mechanism to ensure physically plausible motion patterns without sacrificing the inherent capabilities of generative models. Experimental results demonstrate that our framework outperforms both traditional codecs and state-of-the-art end-to-end video compression methods under ULB conditions. Furthermore, additional experiments confirm that our approach achieves more precise motion control than existing text-guided methods, paving the way for a novel direction of generative video coding guided by geometric motion modeling.",
      "authors": [
        "Zhitao Wang",
        "Hengyu Man",
        "Wenrui Li",
        "Xingtao Wang",
        "Xiaopeng Fan",
        "Debin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.07633v1",
          "size": "8953kb",
          "version": "v1"
        }
      ],
      "title": "T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07633",
        "HTML": "https://arxiv.org/html/2507.07633v1",
        "PDF": "https://arxiv.org/pdf/2507.07633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on video coding at ultra-low bitrates using generative techniques and motion modeling, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07767",
      "abstract": "Prior research shows that how students engage with Large Language Models (LLMs) influences their problem-solving and understanding, reinforcing the need to support productive LLM-uses that promote learning. This study evaluates the impact of a structured GPT platform designed to promote 'good' prompting behavior with data from 58 students in a graduate-level robotics course. The students were assigned to either an intervention group using the structured platform or a control group using ChatGPT freely for two practice lab sessions, before a third session where all students could freely use ChatGPT. We analyzed student perception (pre-post surveys), prompting behavior (logs), performance (task scores), and learning (pre-post tests). Although we found no differences in performance or learning between groups, we identified prompting behaviors - such as having clear prompts focused on understanding code - that were linked with higher learning gains and were more prominent when students used the structured platform. However, such behaviors did not transfer once students were no longer constrained to use the structured platform. Qualitative survey data showed mixed perceptions: some students perceived the value of the structured platform, but most did not perceive its relevance and resisted changing their habits. These findings contribute to ongoing efforts to identify effective strategies for integrating LLMs into learning and question the effectiveness of bottom-up approaches that temporarily alter user interfaces to influence students' interaction. Future research could instead explore top-down strategies that address students' motivations and explicitly demonstrate how certain interaction patterns support learning.",
      "authors": [
        "Jerome Brender",
        "Laila El-Hamamsy",
        "Kim Uittenhove",
        "Francesco Mondada",
        "Engin Bumbacher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.07767v1",
          "size": "952kb",
          "version": "v1"
        }
      ],
      "title": "Structured Prompts, Better Outcomes? Exploring the Effects of a Structured Interface with ChatGPT in a Graduate Robotics Course",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07767",
        "PDF": "https://arxiv.org/pdf/2507.07767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes structured prompts in educational settings, but does not address data processing aspects in relation to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21142",
      "abstract": "The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.",
      "authors": [
        "Deepak Kumar Panda and Weisi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T10:56:34+00:00",
          "link": "https://arxiv.org/abs/2506.21142v1",
          "size": "2094kb",
          "version": "v1"
        }
      ],
      "title": "Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21142",
        "HTML": "https://arxiv.org/html/2506.21142",
        "PDF": "https://arxiv.org/pdf/2506.21142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on adversarial evasion and detection in UAV cyber-attacks, without discussing any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07331",
      "abstract": "In this paper, we present a novel framework for extracting underlying crowd motion patterns and inferring crowd semantics using mmWave radar. First, our proposed signal processing pipeline combines optical flow estimation concepts from vision with novel statistical and morphological noise filtering to generate high-fidelity mmWave flow fields - compact 2D vector representations of crowd motion. We then introduce a novel approach that transforms these fields into directed geometric graphs, where edges capture dominant flow currents, vertices mark crowd splitting or merging, and flow distribution is quantified across edges. Finally, we show that by analyzing the local Jacobian and computing the corresponding curl and divergence, we can extract key crowd semantics for both structured and diffused crowds. We conduct 21 experiments on crowds of up to (and including) 20 people across 3 areas, using commodity mmWave radar. Our framework achieves high-fidelity graph reconstruction of the underlying flow structure, even for complex crowd patterns, demonstrating strong spatial alignment and precise quantitative characterization of flow split ratios. Finally, our curl and divergence analysis accurately infers key crowd semantics, e.g., abrupt turns, boundaries where flow directions shift, dispersions, and gatherings. Overall, these findings validate our framework, underscoring its potential for various crowd analytics applications.",
      "authors": [
        "Anurag Pallaprolu",
        "Winston Hurst",
        "and Yasamin Mostofi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:11:14+00:00",
          "link": "https://arxiv.org/abs/2507.07331v1",
          "size": "13890kb",
          "version": "v1"
        }
      ],
      "title": "mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07331",
        "HTML": "https://arxiv.org/html/2507.07331v1",
        "PDF": "https://arxiv.org/pdf/2507.07331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on crowd flow analytics using mmWave radar, with no discussion on LLM training data processing or dataset creation relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07389",
      "abstract": "Understanding the thickness and variability of internal ice layers in radar imagery is crucial for monitoring snow accumulation, assessing ice dynamics, and reducing uncertainties in climate models. Radar sensors, capable of penetrating ice, provide detailed radargram images of these internal layers. In this work, we present ST-GRIT, a spatio-temporal graph transformer for ice layer thickness, designed to process these radargrams and capture the spatiotemporal relationships between shallow and deep ice layers. ST-GRIT leverages an inductive geometric graph learning framework to extract local spatial features as feature embeddings and employs a series of temporal and spatial attention blocks separately to model long-range dependencies effectively in both dimensions. Experimental evaluation on radargram data from the Greenland ice sheet demonstrates that ST-GRIT consistently outperforms current state-of-the-art methods and other baseline graph neural networks by achieving lower root mean-squared error. These results highlight the advantages of self-attention mechanisms on graphs over pure graph neural networks, including the ability to handle noise, avoid oversmoothing, and capture long-range dependencies. Moreover, the use of separate spatial and temporal attention blocks allows for distinct and robust learning of spatial relationships and temporal patterns, providing a more comprehensive and effective approach.",
      "authors": [
        "Zesheng Liu",
        "Maryam Rahnemoonfar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:06:01+00:00",
          "link": "https://arxiv.org/abs/2507.07389v1",
          "size": "873kb",
          "version": "v1"
        }
      ],
      "title": "ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07389",
        "HTML": "https://arxiv.org/html/2507.07389v1",
        "PDF": "https://arxiv.org/pdf/2507.07389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a spatio-temporal graph transformer for predicting ice layer thickness and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08476",
      "abstract": "Federated learning can solve the privacy protection problem in distributed data mining and machine learning, and how to protect the ownership, use and income rights of all parties involved in federated learning is an important issue. This paper proposes a federated learning data ownership confirmation mechanism based on blockchain and smart contract, which uses decentralized blockchain technology to save the contribution of each participant on the blockchain, and distributes the benefits of federated learning results through the blockchain. In the local simulation environment of the blockchain, the relevant smart contracts and data structures are simulated and implemented, and the feasibility of the scheme is preliminarily demonstrated.",
      "authors": [
        "Xiaogang Cheng",
        "Ren Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T02:02:18+00:00",
          "link": "https://arxiv.org/abs/2409.08476v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:45:10+00:00",
          "link": "https://arxiv.org/abs/2409.08476v2",
          "size": "867kb",
          "version": "v2"
        }
      ],
      "title": "Research on Data Right Confirmation Mechanism of Federated Learning based on Blockchain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08476",
        "PDF": "https://arxiv.org/pdf/2409.08476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a data ownership confirmation mechanism using blockchain within federated learning, and does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.09772",
      "abstract": "Quantum computing represents a significant advancement in computational capabilities. Of particular concern is its impact on asymmetric cryptography through, notably, Shor's algorithm and the more recently developed Regev's algorithm for factoring composite numbers. We present our implementation of the latter. Our analysis encompasses both quantum simulation results and classical component examples, with particular emphasis on comparative cases between Regev's and Shor's algorithms. Our experimental results reveal that Regev's algorithm indeed outperforms Shor's algorithm for certain composite numbers in practice. However, we observed significant performance variations across different input values. Despite Regev's algorithm's theoretical asymptotic efficiency advantage, our implementation exhibited execution times longer than Shor's algorithm for small integer factorization in both quantum and classical components. These findings offer insights into the practical challenges and performance characteristics of implementing Regev's algorithm in realistic quantum computing scenarios.",
      "authors": [
        "Przemys{\\l}aw Pawlitko",
        "Natalia Mo\\'cko",
        "Marcin Niemiec",
        "Piotr Cho{\\l}da"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T21:02:15+00:00",
          "link": "https://arxiv.org/abs/2502.09772v1",
          "size": "868kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:14:35+00:00",
          "link": "https://arxiv.org/abs/2502.09772v2",
          "size": "469kb",
          "version": "v2"
        }
      ],
      "title": "Implementation and Analysis of Regev's Quantum Factorization Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09772",
        "HTML": "https://arxiv.org/html/2502.09772v2",
        "PDF": "https://arxiv.org/pdf/2502.09772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum algorithms and their implementations, which does not involve processing LLM training data."
      },
      "repo_urls": [
        "https://github.com/Wlitkopa/regev-quantum-algorithm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2208.05897",
      "abstract": "We study a game between $N$ job applicants who incur a cost $c$ (relative to the job value) to reveal their type during interviews and an administrator who seeks to maximize the probability of hiring the best. We define a full learning equilibrium and prove its existence, uniqueness, and optimality. In equilibrium, the administrator accepts the current best applicant $n$ with probability $c$ if $n<n^*$ and with probability 1 if $n\\ge n^*$ for a threshold $n^*$ independent of $c$. In contrast to the case without cost, where the success probability converges to $1/\\mathrm{e}\\approx 0.37$ as $N$ tends to infinity, with cost the success probability decays like $N^{-c}$.",
      "authors": [
        "Longjian Li",
        "Alexis Akira Toda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Computer Science and Game Theory (cs.GT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-11T15:56:08+00:00",
          "link": "https://arxiv.org/abs/2208.05897v1",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "2024-07-22T21:47:58+00:00",
          "link": "https://arxiv.org/abs/2208.05897v2",
          "size": "66kb",
          "version": "v2"
        }
      ],
      "title": "Incentivizing Hidden Types in Secretary Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.05897",
        "HTML": "https://arxiv.org/html/2208.05897",
        "PDF": "https://arxiv.org/pdf/2208.05897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates a game-theoretic problem related to job applicant selection, with no focus on LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.01650",
      "abstract": "The ability to quantify the directional flow of information is vital to understanding natural systems and designing engineered information-processing systems. A widely used measure to quantify this information flow is the transfer entropy. However, until now, this quantity could only be obtained in dynamical models using approximations that are typically uncontrolled. Here we introduce a computational algorithm called Transfer Entropy-Path Weight Sampling (TE-PWS), which makes it possible, for the first time, to quantify the transfer entropy and its variants exactly for any stochastic model, including those with multiple hidden variables, nonlinearity, transient conditions, and feedback. By leveraging techniques from polymer and path sampling, TE-PWS efficiently computes the transfer entropy as a Monte-Carlo average over signal trajectory space. We use our exact technique to demonstrate that commonly used approximate methods to compute transfer entropies incur large systematic errors and high computational costs. As an application, we use TE-PWS in linear and nonlinear systems to reveal how transfer entropy can overcome naive applications of the data processing inequality in the presence of feedback.",
      "authors": [
        "Avishek Das",
        "Pieter Rein ten Wolde"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Molecular Networks (q-bio.MN)",
        "Soft Condensed Matter (cond-mat.soft)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T06:41:37+00:00",
          "link": "https://arxiv.org/abs/2409.01650v1",
          "size": "860kb",
          "version": "v1"
        },
        {
          "date": "2024-10-17T15:41:45+00:00",
          "link": "https://arxiv.org/abs/2409.01650v2",
          "size": "1048kb",
          "version": "v2"
        },
        {
          "date": "2024-11-25T15:23:33+00:00",
          "link": "https://arxiv.org/abs/2409.01650v3",
          "size": "1048kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T10:19:51+00:00",
          "link": "https://arxiv.org/abs/2409.01650v4",
          "size": "2051kb",
          "version": "v4"
        }
      ],
      "title": "Exact computation of Transfer Entropy with Path Weight Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01650",
        "HTML": "https://arxiv.org/html/2409.01650v4",
        "PDF": "https://arxiv.org/pdf/2409.01650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces an algorithm for computing transfer entropy, focusing on information flow in systems, not on processing or improving LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.11724",
      "abstract": "Current Large Language Models (LLMs) exhibit limited ability to understand table structures and to apply precise numerical reasoning, which is crucial for tasks such as table question answering (TQA) and table-based fact verification (TFV). To address these challenges, we introduce our Tool-Augmented Reasoning framework for Tables (TART), which integrates LLMs with specialized tools. TART contains three key components: a table formatter to ensure accurate data representation, a tool maker to develop specific computational tools, and an explanation generator to maintain explainability. We also present the TOOLTAB dataset, a new benchmark designed specifically for training LLMs in table-tool integration. Our experiments indicate that TART achieves substantial improvements over existing methods (e.g., Chain-of-Thought) by improving both the precision of data processing and the clarity of the reasoning process. Notably, TART paired with CodeLlama achieves 90.0% of the accuracy of the closed-sourced LLM GPT-3.5-turbo, highlighting its robustness in diverse real-world scenarios. All the code and data are available at https://github.com/XinyuanLu00/TART.",
      "authors": [
        "Xinyuan Lu",
        "Liangming Pan",
        "Yubo Ma",
        "Preslav Nakov",
        "Min-Yen Kan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-18T06:19:59+00:00",
          "link": "https://arxiv.org/abs/2409.11724v1",
          "size": "866kb",
          "version": "v1"
        },
        {
          "date": "2024-11-01T04:19:21+00:00",
          "link": "https://arxiv.org/abs/2409.11724v2",
          "size": "991kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T04:17:26+00:00",
          "link": "https://arxiv.org/abs/2409.11724v3",
          "size": "1107kb",
          "version": "v3"
        }
      ],
      "title": "TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.11724",
        "HTML": "https://arxiv.org/html/2409.11724v3",
        "PDF": "https://arxiv.org/pdf/2409.11724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the TOOLTAB dataset and elaborates on the tool-augmented framework TART, contributing significantly to training data processing for LLMs by improving precision and clarity."
      },
      "tasks": [
        "Fact Verification",
        "Question Answering",
        "Table-based Fact Verification"
      ],
      "repo_urls": [
        "https://github.com/xinyuanlu00/tart"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18438",
      "abstract": "Combining reconstruction models with generative models has emerged as a promising paradigm for closed-loop simulation in autonomous driving. For example, ReconDreamer has demonstrated remarkable success in rendering large-scale maneuvers. However, a significant gap remains between the generated data and real-world sensor observations, particularly in terms of fidelity for structured elements, such as the ground surface. To address these challenges, we propose ReconDreamer++, an enhanced framework that significantly improves the overall rendering quality by mitigating the domain gap and refining the representation of the ground surface. Specifically, ReconDreamer++ introduces the Novel Trajectory Deformable Network (NTDNet), which leverages learnable spatial deformation mechanisms to bridge the domain gap between synthesized novel views and original sensor observations. Moreover, for structured elements such as the ground surface, we preserve geometric prior knowledge in 3D Gaussians, and the optimization process focuses on refining appearance attributes while preserving the underlying geometric structure. Experimental evaluations conducted on multiple datasets (Waymo, nuScenes, PandaSet, and EUVS) confirm the superior performance of ReconDreamer++. Specifically, on Waymo, ReconDreamer++ achieves performance comparable to Street Gaussians for the original trajectory while significantly outperforming ReconDreamer on novel trajectories. In particular, it achieves substantial improvements, including a 6.1% increase in NTA-IoU, a 23. 0% improvement in FID, and a remarkable 4.5% gain in the ground surface metric NTL-IoU, highlighting its effectiveness in accurately reconstructing structured elements such as the road surface.",
      "authors": [
        "Guosheng Zhao",
        "Xiaofeng Wang",
        "Chaojun Ni",
        "Zheng Zhu",
        "Wenkang Qin",
        "Guan Huang",
        "Xingang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T08:40:20+00:00",
          "link": "https://arxiv.org/abs/2503.18438v1",
          "size": "17398kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:01:22+00:00",
          "link": "https://arxiv.org/abs/2503.18438v2",
          "size": "17398kb",
          "version": "v2"
        }
      ],
      "title": "ReconDreamer++: Harmonizing Generative and Reconstructive Models for Driving Scene Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18438",
        "HTML": "https://arxiv.org/html/2503.18438v2",
        "PDF": "https://arxiv.org/pdf/2503.18438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper enhances generative models for autonomous driving scene representation, focusing on rendering quality and fidelity. It does not address LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06608",
      "abstract": "Current prefill-decode (PD) disaggregation is typically deployed at the level of entire serving engines, assigning separate GPUs to handle prefill and decode phases. While effective at reducing latency, this approach demands more hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode requests within the same batch, but introduces phase interference between prefill and decode.\n  While existing PD disaggregation solutions separate the phases across GPUs, we ask: can the same decoupling be achieved within a single serving engine? The key challenge lies in managing the conflicting resource requirements of prefill and decode when they share the same hardware. In this paper, we first show that chunked prefill requests cause interference with decode requests due to their distinct requirements for GPU resources. Second, we find that GPU resources exhibit diminishing returns. Beyond a saturation point, increasing GPU allocation yields negligible latency improvements. This insight enables us to split a single GPU's resources and dynamically allocate them to prefill and decode on the fly, effectively disaggregating the two phases within the same GPU.\n  Across a range of models and workloads, our system Nexus achieves up to 2.2x higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using only half the number of GPUs.",
      "authors": [
        "Xiaoxiang Shi",
        "Colin Cai",
        "Junjia Du",
        "Zhanda Zhu",
        "Zhihao Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.06608v1",
          "size": "848kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:48:42+00:00",
          "link": "https://arxiv.org/abs/2507.06608v2",
          "size": "849kb",
          "version": "v2"
        }
      ],
      "title": "Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06608",
        "HTML": "https://arxiv.org/html/2507.06608v2",
        "PDF": "https://arxiv.org/pdf/2507.06608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses GPU sharing for LLM serving to optimize throughput and latency but does not discuss the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07469",
      "abstract": "Time-series models like ARIMA remain widely used for forecasting but limited to linear assumptions and high computational cost in large and complex datasets. We propose Galerkin-ARIMA that generalizes the AR component of ARIMA and replace it with a flexible spline-based function estimated by Galerkin projection. This enables the model to capture nonlinear dependencies in lagged values and retain the MA component and Gaussian noise assumption. We derive a closed-form OLS estimator for the Galerkin coefficients and show the model is asymptotically unbiased and consistent under standard conditions. Our method bridges classical time-series modeling and nonparametric regression, which offering improved forecasting performance and computational efficiency.",
      "authors": [
        "Haojie Liu",
        "Zihan Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:53:18+00:00",
          "link": "https://arxiv.org/abs/2507.07469v1",
          "size": "1768kb",
          "version": "v1"
        }
      ],
      "title": "Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07469",
        "HTML": "https://arxiv.org/html/2507.07469v1",
        "PDF": "https://arxiv.org/pdf/2507.07469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on improving time-series forecasting models, not on processing training data for large language models or data engineering tasks related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06167",
      "abstract": "We introduce Skywork-R1V3, an advanced, open-source vision-language model (VLM) that pioneers a new approach to visual reasoning. Its key innovation lies in effectively transferring reasoning skills from text-only Large Language Models (LLMs) to visual tasks. The strong performance of Skywork-R1V3 primarily stems from our elaborate post-training RL framework, which effectively activates and enhances the model's reasoning ability, without the need for additional continue pre-training. Through this framework, we further uncover the fundamental role of the connector module in achieving robust cross-modal alignment for multimodal reasoning models. In addition, we introduce a unique indicator of reasoning capability, the entropy of critical reasoning tokens, which has proven highly effective for checkpoint selection during RL training. Skywork-R1V3 achieves state-of-the-art results on MMMU, significantly improving from 64.3% to 76.0%. This performance matches entry-level human capabilities. Remarkably, our RL-powered post-training approach enables even the 38B parameter model to rival top closed-source VLMs. The implementation successfully transfers mathematical reasoning to other subject-related reasoning tasks. We also include an analysis of curriculum learning and reinforcement finetuning strategies, along with a broader discussion on multimodal reasoning. Skywork-R1V3 represents a significant leap in multimodal reasoning, showcasing RL as a powerful engine for advancing open-source VLM capabilities.",
      "authors": [
        "Wei Shen and Jiangbo Pei and Yi Peng and Xuchen Song and Yang Liu and Jian Peng and Haofeng Sun and Yunzhuo Hao and Peiyu Wang and Jianhao Zhang and Yahui Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:47:16+00:00",
          "link": "https://arxiv.org/abs/2507.06167v1",
          "size": "5486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:36:17+00:00",
          "link": "https://arxiv.org/abs/2507.06167v2",
          "size": "5486kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:41:04+00:00",
          "link": "https://arxiv.org/abs/2507.06167v3",
          "size": "5279kb",
          "version": "v3"
        }
      ],
      "title": "Skywork-R1V3 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06167",
        "PDF": "https://arxiv.org/pdf/2507.06167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents a vision-language model and discusses training strategies, it focuses more on post-training RL techniques and multimodal reasoning rather than on processing or creating LLM training data."
      },
      "models": [
        {
          "model_path": "Skywork/Skywork-R1V3-38B",
          "downloads": "203",
          "likes": "37",
          "trending_score": "37.0",
          "link": "https://huggingface.co/Skywork/Skywork-R1V3-38B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07371",
      "abstract": "Among the various machine learning methods solving partial differential equations, the Random Feature Method (RFM) stands out due to its accuracy and efficiency. In this paper, we demonstrate that the approximation error of RFM exhibits spectral convergence when it is applied to the second-order elliptic equations in one dimension, provided that the solution belongs to Gevrey classes or Sobolev spaces. We highlight the significant impact of incorporating the Partition of Unity Method (PUM) to enhance the convergence of RFM by establishing the convergence rate in terms of the maximum patch size. Furthermore, we reveal that the singular values of the random feature matrix (RFMtx) decay exponentially, while its condition number increases exponentially as the number of the features grows. We also theoretically illustrate that PUM may mitigate the excessive decay of the singular values of RFMtx.",
      "authors": [
        "Pingbing Ming",
        "Hao Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:50:03+00:00",
          "link": "https://arxiv.org/abs/2507.07371v1",
          "size": "1782kb",
          "version": "v1"
        }
      ],
      "title": "Spectral connvergece of random feature method in one dimension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07371",
        "HTML": "https://arxiv.org/html/2507.07371v1",
        "PDF": "https://arxiv.org/pdf/2507.07371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on convergence properties of the Random Feature Method in solving differential equations, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07811",
      "abstract": "Background: Accurate forecasting of lung tumor motion is essential for precise dose delivery in proton therapy. While current markerless methods mostly rely on deep learning, transformer-based architectures remain unexplored in this domain, despite their proven performance in trajectory forecasting.\n  Purpose: This work introduces a markerless forecasting approach for lung tumor motion using Vision Transformers (ViT). Two training strategies are evaluated under clinically realistic constraints: a patient-specific (PS) approach that learns individualized motion patterns, and a multi-patient (MP) model designed for generalization. The comparison explicitly accounts for the limited number of images that can be generated between planning and treatment sessions.\n  Methods: Digitally reconstructed radiographs (DRRs) derived from planning 4DCT scans of 31 patients were used to train the MP model; a 32nd patient was held out for evaluation. PS models were trained using only the target patient's planning data. Both models used 16 DRRs per input and predicted tumor motion over a 1-second horizon. Performance was assessed using Average Displacement Error (ADE) and Final Displacement Error (FDE), on both planning (T1) and treatment (T2) data.\n  Results: On T1 data, PS models outperformed MP models across all training set sizes, especially with larger datasets (up to 25,000 DRRs, p < 0.05). However, MP models demonstrated stronger robustness to inter-fractional anatomical variability and achieved comparable performance on T2 data without retraining.\n  Conclusions: This is the first study to apply ViT architectures to markerless tumor motion forecasting. While PS models achieve higher precision, MP models offer robust out-of-the-box performance, well-suited for time-constrained clinical settings.",
      "authors": [
        "Gauthier Rotsart de Hertaing",
        "Dani Manjah",
        "and Benoit Macq"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:40:52+00:00",
          "link": "https://arxiv.org/abs/2507.07811v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "Patient-specific vs Multi-Patient Vision Transformer for Markerless Tumor Motion Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07811",
        "HTML": "https://arxiv.org/html/2507.07811v1",
        "PDF": "https://arxiv.org/pdf/2507.07811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a comparison of patient-specific vs multi-patient models for tumor motion forecasting using transformer architectures, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.13818",
      "abstract": "Dehumanization, i.e., denying human qualities to individuals or groups, is a particularly harmful form of hate speech that can normalize violence against marginalized communities. Despite advances in NLP for detecting general hate speech, approaches to identifying dehumanizing language remain limited due to scarce annotated data and the subtle nature of such expressions. In this work, we systematically evaluate four state-of-the-art large language models (LLMs) - Claude, GPT, Mistral, and Qwen - for dehumanization detection. Our results show that only one model-Claude-achieves strong performance (over 80% F1) under an optimized configuration, while others, despite their capabilities, perform only moderately. Performance drops further when distinguishing dehumanization from related hate types such as derogation. We also identify systematic disparities across target groups: models tend to over-predict dehumanization for some identities (e.g., Gay men), while under-identifying it for others (e.g., Refugees). These findings motivate the need for systematic, group-level evaluation when applying pretrained language models to dehumanization detection tasks.",
      "authors": [
        "Hamidreza Saffari",
        "Mohammadamin Shafiei",
        "Hezhao Zhang",
        "Lasana Harris",
        "Nafise Sadat Moosavi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-21T13:57:36+00:00",
          "link": "https://arxiv.org/abs/2402.13818v1",
          "size": "8069kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:42:28+00:00",
          "link": "https://arxiv.org/abs/2402.13818v2",
          "size": "8342kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13818",
        "HTML": "https://arxiv.org/html/2402.13818v2",
        "PDF": "https://arxiv.org/pdf/2402.13818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates existing LLMs for dehumanization detection and does not discuss any data processing or engineering specific to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.02148",
      "abstract": "Monocular depth estimation has recently progressed beyond ordinal depth to provide metric depth predictions. However, its reliability in underwater environments remains limited due to light attenuation and scattering, color distortion, turbidity, and the lack of high-quality metric ground truth data. In this paper, we present a comprehensive benchmark of zero-shot and fine-tuned monocular metric depth estimation models on real-world underwater datasets with metric depth annotations, including FLSea and SQUID. We evaluated a diverse set of state-of-the-art Vision Foundation Models across a range of underwater conditions and depth ranges. Our results show that large-scale models trained on terrestrial data (real or synthetic) are effective in in-air settings, but perform poorly underwater due to significant domain shifts. To address this, we fine-tune Depth Anything V2 with a ViT-S backbone encoder on a synthetic underwater variant of the Hypersim dataset, which we simulated using a physically based underwater image formation model. Our fine-tuned model consistently improves performance across all benchmarks and outperforms baselines trained only on the clean in-air Hypersim dataset. This study presents a detailed evaluation and visualization of monocular metric depth estimation in underwater scenes, emphasizing the importance of domain adaptation and scale-aware supervision for achieving robust and generalizable metric depth predictions using foundation models in challenging environments.",
      "authors": [
        "Zijie Cai and Christopher Metzler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.02148v1",
          "size": "29025kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:55:57+00:00",
          "link": "https://arxiv.org/abs/2507.02148v2",
          "size": "29025kb",
          "version": "v2"
        }
      ],
      "title": "Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning with Vision Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02148",
        "HTML": "https://arxiv.org/html/2507.02148v2",
        "PDF": "https://arxiv.org/pdf/2507.02148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes synthetic fine-tuning of models for underwater monocular metric depth estimation, mentioning domain adaptation for training, but does not focus on data processing techniques specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        }
      ],
      "title": "Fuzzy Classification Aggregation for a Continuum of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297v3",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses fuzzy classification aggregation methods and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07203",
      "abstract": "Large Language Models enable dynamic game interactions but struggle with rule-governed trading systems. Current implementations suffer from rule violations, such as item hallucinations and calculation errors, that erode player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable trading through autonomous dialogue state inference and context-specific rule adherence. The approach decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations. Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP maintains computational efficiency while outperforming baseline approaches, establishing a practical foundation for trustworthy NPC interactions in commercial games.",
      "authors": [
        "Minkyung Kim",
        "Junsik Kim",
        "Hwidong Bae",
        "Woongcheol Yang",
        "Sangdon Park",
        "Sohee Bae"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:24:47+00:00",
          "link": "https://arxiv.org/abs/2507.07203v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07203",
        "PDF": "https://arxiv.org/pdf/2507.07203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a prompting strategy for trading dialogue systems in games using LLM. It focuses more on application rather than processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07221",
      "abstract": "Robotic dressing assistance has the potential to improve the quality of life for individuals with limited mobility. Existing solutions predominantly rely on rigid robotic manipulators, which have challenges in handling deformable garments and ensuring safe physical interaction with the human body. Prior robotic dressing methods require excessive operation times, complex control strategies, and constrained user postures, limiting their practicality and adaptability. This paper proposes a novel soft robotic dressing system, the Self-Wearing Adaptive Garment (SWAG), which uses an unfurling and growth mechanism to facilitate autonomous dressing. Unlike traditional approaches,the SWAG conforms to the human body through an unfurling based deployment method, eliminating skin-garment friction and enabling a safer and more efficient dressing process. We present the working principles of the SWAG, introduce its design and fabrication, and demonstrate its performance in dressing assistance. The proposed system demonstrates effective garment application across various garment configurations, presenting a promising alternative to conventional robotic dressing assistance.",
      "authors": [
        "Nam Gyun Kim",
        "William E. Heap",
        "Yimeng Qin",
        "Elvy B. Yao",
        "Jee-Hwan Ryu",
        "and Allison M. Okamura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.07221v1",
          "size": "17052kb",
          "version": "v1"
        }
      ],
      "title": "Self-Wearing Adaptive Garments via Soft Robotic Unfurling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07221",
        "HTML": "https://arxiv.org/html/2507.07221v1",
        "PDF": "https://arxiv.org/pdf/2507.07221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robotic dressing assistance and the development of soft robotic systems. It does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07804",
      "abstract": "Accurate survival prediction is critical in oncology for prognosis and treatment planning. Traditional approaches often rely on a single data modality, limiting their ability to capture the complexity of tumor biology. To address this challenge, we introduce a multimodal deep learning framework for survival analysis capable of modeling both single and competing risks scenarios, evaluating the impact of integrating multiple medical data sources on survival predictions. We propose SAMVAE (Survival Analysis Multimodal Variational Autoencoder), a novel deep learning architecture designed for survival prediction that integrates six data modalities: clinical variables, four molecular profiles, and histopathological images. SAMVAE leverages modality specific encoders to project inputs into a shared latent space, enabling robust survival prediction while preserving modality specific information. Its parametric formulation enables the derivation of clinically meaningful statistics from the output distributions, providing patient-specific insights through interactive multimedia that contribute to more informed clinical decision-making and establish a foundation for interpretable, data-driven survival analysis in oncology. We evaluate SAMVAE on two cancer cohorts breast cancer and lower grade glioma applying tailored preprocessing, dimensionality reduction, and hyperparameter optimization. The results demonstrate the successful integration of multimodal data for both standard survival analysis and competing risks scenarios across different datasets. Our model achieves competitive performance compared to state-of-the-art multimodal survival models. Notably, this is the first parametric multimodal deep learning architecture to incorporate competing risks while modeling continuous time to a specific event, using both tabular and image data.",
      "authors": [
        "Alba Garrido",
        "Alejandro Almod\\'ovar",
        "Patricia A. Apell\\'aniz",
        "Juan Parras and Santiago Zazo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:29:48+00:00",
          "link": "https://arxiv.org/abs/2507.07804v1",
          "size": "4975kb",
          "version": "v1"
        }
      ],
      "title": "Deep Survival Analysis in Multimodal Medical Data: A Parametric and Probabilistic Approach with Competing Risks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07804",
        "HTML": "https://arxiv.org/html/2507.07804v1",
        "PDF": "https://arxiv.org/pdf/2507.07804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal deep learning framework for survival analysis in oncology, which involves processing medical data for survival prediction rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07405",
      "abstract": "The pre-training and fine-tuning methods have gained widespread attention in the field of heterogeneous graph neural networks due to their ability to leverage large amounts of unlabeled data during the pre-training phase, allowing the model to learn rich structural features. However, these methods face the issue of a mismatch between the pre-trained model and downstream tasks, leading to suboptimal performance in certain application scenarios. Prompt learning methods have emerged as a new direction in heterogeneous graph tasks, as they allow flexible adaptation of task representations to address target inconsistency. Building on this idea, this paper proposes a novel multi-task prompt framework for the heterogeneous graph domain, named HGMP. First, to bridge the gap between the pre-trained model and downstream tasks, we reformulate all downstream tasks into a unified graph-level task format. Next, we address the limitations of existing graph prompt learning methods, which struggle to integrate contrastive pre-training strategies in the heterogeneous graph domain. We design a graph-level contrastive pre-training strategy to better leverage heterogeneous information and enhance performance in multi-task scenarios. Finally, we introduce heterogeneous feature prompts, which enhance model performance by refining the representation of input graph features. Experimental results on public datasets show that our proposed method adapts well to various tasks and significantly outperforms baseline methods.",
      "authors": [
        "Pengfei Jiao",
        "Jialong Ni",
        "Di Jin",
        "Xuan Guo",
        "Huan Liu",
        "Hongjiang Chen",
        "Yanxian Bi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:01:47+00:00",
          "link": "https://arxiv.org/abs/2507.07405v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "HGMP:Heterogeneous Graph Multi-Task Prompt Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07405",
        "HTML": "https://arxiv.org/html/2507.07405v1",
        "PDF": "https://arxiv.org/pdf/2507.07405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves pre-training and fine-tuning for heterogeneous graph neural networks and explores prompt learning methods for better adaptation to downstream tasks. While it deals with pre-training methods, it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.09876",
      "abstract": "The power flow equations are central to many problems in power system planning, analysis, and control. However, their inherent non-linearity and non-convexity present substantial challenges during problem-solving processes, especially for optimization problems. Accordingly, linear approximations are commonly employed to streamline computations, although this can often entail compromises in accuracy and feasibility. This paper proposes an approach termed Conservative Bias Linear Approximations (CBLA) for addressing these limitations. By minimizing approximation errors across a specified operating range while incorporating conservativeness (over- or under-estimating quantities of interest), CBLA strikes a balance between accuracy and tractability by maintaining linear constraints. By allowing users to design loss functions tailored to the specific approximated function, the bias approximation approach significantly enhances approximation accuracy. We illustrate the effectiveness of our proposed approach through several test cases, including its application to a unit commitment problem, where CBLA consistently achieves lower operating costs and improved feasibility compared to traditional linearization methods.",
      "authors": [
        "Paprapee Buason",
        "Sidhant Misra",
        "Daniel K. Molzahn"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-15T15:47:05+00:00",
          "link": "https://arxiv.org/abs/2404.09876v1",
          "size": "311kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:12:58+00:00",
          "link": "https://arxiv.org/abs/2404.09876v2",
          "size": "395kb",
          "version": "v2"
        }
      ],
      "title": "Conservative Bias Linear Power Flow Approximations: Application to Unit Commitment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.09876",
        "HTML": "https://arxiv.org/html/2404.09876v2",
        "PDF": "https://arxiv.org/pdf/2404.09876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with approximations in power flow equations and unit commitment in power systems, with no focus on LLM training data processing or related methodologies."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.09265",
      "abstract": "Sparsely activated Mixture-of-Experts (MoE) models effectively increase the number of parameters while maintaining consistent computational costs per token. However, vanilla MoE models often suffer from limited diversity and specialization among experts, constraining their performance and scalability, especially as the number of experts increases. In this paper, we present a novel perspective on vanilla MoE with top-$k$ routing inspired by sparse representation. This allows us to bridge established theoretical insights from sparse representation into MoE models. Building on this foundation, we propose a group sparse regularization approach for the input of top-$k$ routing, termed Mixture of Group Experts (MoGE). MoGE indirectly regularizes experts by imposing structural constraints on the routing inputs, while preserving the original MoE architecture. Furthermore, we organize the routing input into a 2D topographic map, spatially grouping neighboring elements. This structure enables MoGE to capture representations invariant to minor transformations, thereby significantly enhancing expert diversity and specialization. Comprehensive evaluations across various Transformer models for image classification and language modeling tasks demonstrate that MoGE substantially outperforms its MoE counterpart, with minimal additional memory and computation overhead. Our approach provides a simple yet effective solution to scale the number of experts and reduce redundancy among them. The source code is included in the supplementary material and will be publicly released.",
      "authors": [
        "Lei Kang",
        "Jia Li",
        "Mi Tian and Hua Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T15:58:02+00:00",
          "link": "https://arxiv.org/abs/2504.09265v1",
          "size": "781kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:07:53+00:00",
          "link": "https://arxiv.org/abs/2504.09265v2",
          "size": "445kb",
          "version": "v2"
        }
      ],
      "title": "Mixture of Group Experts for Learning Invariant Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09265",
        "HTML": "https://arxiv.org/html/2504.09265v2",
        "PDF": "https://arxiv.org/pdf/2504.09265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper explores improvements in MoE model architecture focusing on expert diversity and specialization, it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07828",
      "abstract": "Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.",
      "authors": [
        "Richard Dirauf",
        "Florian Wolz",
        "Dario Zanca",
        "Bj\\\"orn Eskofier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:01:23+00:00",
          "link": "https://arxiv.org/abs/2507.07828v1",
          "size": "8186kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07828",
        "HTML": "https://arxiv.org/html/2507.07828v1",
        "PDF": "https://arxiv.org/pdf/2507.07828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using deep learning models for improving puzzle solvers' robustness through fine-tuning with augmented data, but it does not focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.02524",
      "abstract": "Large Language Models (LLMs) are transforming a wide range of domains, yet verifying their outputs remains a significant challenge, especially for complex open-ended tasks such as consolidation, summarization, and knowledge extraction. To address this, we introduce CheckEmbed (CE): a simple, scalable, and accurate verification method. CE reduces each LLM answer to a single embedding vector using powerful modern embedding LLM models like SFR-Embedding-Mistral. Prior methods such as BERTScore and SelfCheckGPT relied on weaker encoders like BERT, forcing them to operate at token or sentence granularity. In contrast, CE performs fast, semantically rich comparisons directly at the whole-answer level, overcoming key limitations in both accuracy and scalability. We conduct a comprehensive design and time complexity analysis across 13 verification baselines, including classical text scorers (e.g., BLEU), stability-based methods (e.g., SelfCheckGPT), and generative evaluators (e.g., LLM-as-a-Judge), which highlights the effectiveness, efficiency, versatility, and simplicity of CE. Empirical results show that CE reliably detects hallucinations in both closed and open-ended tasks. We further present evidence that CE generalizes beyond text to other modalities such as vision, establishing it as a practical and versatile verification framework.",
      "authors": [
        "Maciej Besta",
        "Lorenzo Paleari",
        "Marcin Copik",
        "Robert Gerstenberger",
        "Ales Kubicek",
        "Piotr Nyczyk",
        "Patrick Iff",
        "Eric Schreiber",
        "Tanja Srindran",
        "Tomasz Lehmann",
        "Hubert Niewiadomski",
        "Torsten Hoefler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-04T17:42:21+00:00",
          "link": "https://arxiv.org/abs/2406.02524v1",
          "size": "561kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T17:58:22+00:00",
          "link": "https://arxiv.org/abs/2406.02524v2",
          "size": "647kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T14:57:00+00:00",
          "link": "https://arxiv.org/abs/2406.02524v3",
          "size": "6617kb",
          "version": "v3"
        },
        {
          "date": "2025-06-05T16:22:36+00:00",
          "link": "https://arxiv.org/abs/2406.02524v4",
          "size": "6617kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T08:29:38+00:00",
          "link": "https://arxiv.org/abs/2406.02524v5",
          "size": "6617kb",
          "version": "v5"
        }
      ],
      "title": "CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02524",
        "PDF": "https://arxiv.org/pdf/2406.02524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a verification method for LLM outputs and does not focus on processing or improving LLM training data."
      },
      "tasks": [
        "Document Summarization",
        "Sentence",
        "Term Extraction"
      ],
      "repo_urls": [
        "https://github.com/spcl/checkembed"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.15804",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across diverse tasks, yet they lag significantly behind humans in spatial reasoning. We investigate this gap through Transformation-Driven Visual Reasoning (TVR), a challenging task requiring identification of object transformations across images under varying viewpoints. While traditional Supervised Fine-Tuning (SFT) fails to generate coherent reasoning paths in cross-view settings, sparse-reward Reinforcement Learning (RL) suffers from inefficient exploration and slow convergence. To address these limitations, we propose STAR-R1, a novel framework that integrates a single-stage RL paradigm with a fine-grained reward mechanism tailored for TVR. Specifically, STAR-R1 rewards partial correctness while penalizing excessive enumeration and passive inaction, enabling efficient exploration and precise reasoning. Comprehensive evaluations demonstrate that STAR-R1 achieves state-of-the-art performance across all 11 metrics, outperforming SFT by 23% in cross-view scenarios. Further analysis reveals STAR-R1's anthropomorphic behavior and highlights its unique ability to compare all objects for improving spatial reasoning. Our work provides critical insights in advancing the research of MLLMs and reasoning models. The codes, model weights, and data will be publicly available at https://github.com/zongzhao23/STAR-R1.",
      "authors": [
        "Zongzhao Li",
        "Zongyang Ma",
        "Mingze Li",
        "Songyou Li",
        "Yu Rong",
        "Tingyang Xu",
        "Ziqi Zhang",
        "Deli Zhao",
        "Wenbing Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T17:57:38+00:00",
          "link": "https://arxiv.org/abs/2505.15804v1",
          "size": "867kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T16:00:12+00:00",
          "link": "https://arxiv.org/abs/2505.15804v2",
          "size": "2127kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T17:36:35+00:00",
          "link": "https://arxiv.org/abs/2505.15804v3",
          "size": "2128kb",
          "version": "v3"
        }
      ],
      "title": "STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15804",
        "HTML": "https://arxiv.org/html/2505.15804v3",
        "PDF": "https://arxiv.org/pdf/2505.15804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While STAR-R1 involves supervised fine-tuning and reinforcement learning for spatial reasoning in MLLMs, it does not focus on data processing or dataset creation for LLM training purpose."
      },
      "tasks": [
        "Efficient Exploration",
        "Reinforcement Learning (RL)",
        "Spatial Reasoning",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07284",
      "abstract": "As the demand for compute power in traditional neural networks has increased significantly, spiking neural networks (SNNs) have emerged as a potential solution to increasingly power-hungry neural networks. By operating on 0/1 spikes emitted by neurons instead of arithmetic multiply-and-accumulate operations, SNNs propagate information temporally and spatially, allowing for more efficient compute power. To this end, many architectures for accelerating and simulating SNNs have been developed, including Loihi, TrueNorth, and SpiNNaker. However, these chips are largely inaccessible to the wider community. Field programmable gate arrays (FPGAs) have been explored to serve as a middle ground between neuromorphic and non-neuromorphic hardware, but many proposed architectures require expensive high-end FPGAs or target a single SNN topology. This paper presents a framework consisting of a robust SNN acceleration architecture and a Pytorch-based SNN model compiler. Targeting any-to-any and/or fully connected SNNs, the FPGA architecture features a synaptic array that tiles across the SNN to propagate spikes. The architecture targets low-end FPGAs and requires very little (6358 LUT, 40.5 BRAM) resources. The framework, tested on a low-end Xilinx Artix-7 FPGA at 100 MHz, achieves competitive speed in recognizing MNIST digits (0.52 ms/img). Further experiments also show accurate simulation of hand coded any-to-any spiking neural networks on toy problems. All code and setup instructions are available at https://github.com/im-afan/snn-fpga}{\\texttt{https://github.com/im-afan/snn-fpga.",
      "authors": [
        "Andrew Fan and Simon D. Levy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:08:28+00:00",
          "link": "https://arxiv.org/abs/2507.07284v1",
          "size": "1193kb",
          "version": "v1"
        }
      ],
      "title": "A Robust, Open-Source Framework for Spiking Neural Networks on Low-End FPGAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07284",
        "HTML": "https://arxiv.org/html/2507.07284v1",
        "PDF": "https://arxiv.org/pdf/2507.07284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While focusing on a framework for spiking neural networks, the paper does not mention any methodologies or contributions to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07818",
      "abstract": "Recent studies show large language models (LLMs) and vision language models (VLMs) trained using web-scale data can empower end-to-end autonomous driving systems for a better generalization and interpretation. Specifically, by dynamically routing inputs to specialized subsets of parameters, the Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve substantial performance improvements while maintaining computational efficiency. However, general MoE models usually demands extensive training data and complex optimization. In this work, inspired by the learning process of human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human drivers' learning process and reasoning process, skill-by-skill and step-by-step. We propose a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary driving competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. Further align the driving process to multi-step planning in human reasoning and end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike multi-round dialogs, MoSE integrates valuable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model outperforms several 8B+ parameters on CODA AD corner case reasoning task. Compared to existing methods based on open-source models and data, our approach achieves state-of-the-art performance with significantly reduced activated model size (at least by $62.5\\%$) with a single-turn conversation.",
      "authors": [
        "Lu Xu",
        "Jiaqian Yu",
        "Xiongfeng Peng",
        "Yiwei Chen",
        "Weiming Li",
        "Jaewook Yoo",
        "Sunghyun Chunag",
        "Dongwook Lee",
        "Daehyun Ji",
        "Chao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:48:08+00:00",
          "link": "https://arxiv.org/abs/2507.07818v1",
          "size": "12562kb",
          "version": "v1"
        }
      ],
      "title": "MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07818",
        "HTML": "https://arxiv.org/html/2507.07818v1",
        "PDF": "https://arxiv.org/pdf/2507.07818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces skill-by-skill mixture-of-expert learning for autonomous driving, focusing on model architecture and mechanism without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07845",
      "abstract": "Autonomous agents, particularly in the field of robotics, rely on sensory information to perceive and navigate their environment. However, these sensory inputs are often imperfect, leading to distortions in the agent's internal representation of the world. This paper investigates the nature of these perceptual distortions and how they influence autonomous representation learning using a minimal robotic system. We utilize a simulated two-wheeled robot equipped with distance sensors and a compass, operating within a simple square environment. Through analysis of the robot's sensor data during random exploration, we demonstrate how a distorted perceptual space emerges. Despite these distortions, we identify emergent structures within the perceptual space that correlate with the physical environment, revealing how the robot autonomously learns a structured representation for navigation without explicit spatial information. This work contributes to the understanding of embodied cognition, minimal agency, and the role of perception in self-generated navigation strategies in artificial life.",
      "authors": [
        "David Warutumo",
        "Ciira wa Maina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:22:32+00:00",
          "link": "https://arxiv.org/abs/2507.07845v1",
          "size": "1660kb",
          "version": "v1"
        }
      ],
      "title": "Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07845",
        "PDF": "https://arxiv.org/pdf/2507.07845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores perceptual distortions and autonomous representation learning in robotics, focusing on sensor data without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.13766",
      "abstract": "The combination of Large Language Models (LLM) and Automatic Speech Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can serve as a powerful personalized assistant to enable audio-based interaction for users. Compared to text-based interaction, edge ASR-LLM allows accessible and natural audio interactions. Unfortunately, existing ASR-LLM models are mainly trained in high-performance computing environments and produce substantial model weights, making them difficult to deploy on edge devices. More importantly, to better serve users' personalized needs, the ASR-LLM must be able to learn from each distinct user, given that audio input often contains highly personalized characteristics that necessitate personalized on-device training. Since individually fine-tuning the ASR or LLM often leads to suboptimal results due to modality-specific limitations, end-to-end training ensures seamless integration of audio features and language understanding (cross-modal alignment), ultimately enabling a more personalized and efficient adaptation on edge devices. However, due to the complex training requirements and substantial computational demands of existing approaches, cross-modal alignment between ASR audio and LLM can be challenging on edge devices. In this work, we propose a resource-efficient cross-modal alignment framework that bridges ASR and LLMs on edge devices to handle personalized audio input. Our framework enables efficient ASR-LLM alignment on resource-constrained devices like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while improving the alignment quality by more than 50\\%. To the best of our knowledge, this is the first work to study efficient ASR-LLM alignment on resource-constrained edge devices.",
      "authors": [
        "Ruiyang Qin",
        "Dancheng Liu",
        "Gelei Xu",
        "Zheyu Yan",
        "Chenhui Xu",
        "Yuting Hu",
        "X. Sharon Hu",
        "Jinjun Xiong",
        "Yiyu Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T00:29:58+00:00",
          "link": "https://arxiv.org/abs/2411.13766v1",
          "size": "580kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T05:12:26+00:00",
          "link": "https://arxiv.org/abs/2411.13766v2",
          "size": "580kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T21:56:53+00:00",
          "link": "https://arxiv.org/abs/2411.13766v3",
          "size": "572kb",
          "version": "v3"
        }
      ],
      "title": "Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13766",
        "HTML": "https://arxiv.org/html/2411.13766v3",
        "PDF": "https://arxiv.org/pdf/2411.13766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses efficient ASR-LLM alignment on resource-constrained devices, focusing on modality integration and efficient training. Although it mentions personalized training, there is no specific focus on LLM training data processing methods."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Automatic Speech Recognition (ASR)",
        "cross-modal alignment",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07223",
      "abstract": "Modern AI workloads such as large language models (LLMs) and retrieval-augmented generation (RAG) impose severe demands on memory, communication bandwidth, and resource flexibility. Traditional GPU-centric architectures struggle to scale due to growing inter-GPU communication overheads. This report introduces key AI concepts and explains how Transformers revolutionized data representation in LLMs. We analyze large-scale AI hardware and data center designs, identifying scalability bottlenecks in hierarchical systems. To address these, we propose a modular data center architecture based on Compute Express Link (CXL) that enables disaggregated scaling of memory, compute, and accelerators. We further explore accelerator-optimized interconnects-collectively termed XLink (e.g., UALink, NVLink, NVLink Fusion)-and introduce a hybrid CXL-over-XLink design to reduce long-distance data transfers while preserving memory coherence. We also propose a hierarchical memory model that combines local and pooled memory, and evaluate lightweight CXL implementations, HBM, and silicon photonics for efficient scaling. Our evaluations demonstrate improved scalability, throughput, and flexibility in AI infrastructure.",
      "authors": [
        "Myoungsoo Jung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:57:04+00:00",
          "link": "https://arxiv.org/abs/2507.07223v1",
          "size": "23292kb",
          "version": "v1"
        }
      ],
      "title": "Compute Can't Handle the Truth: Why Communication Tax Prioritizes Memory and Interconnects in Modern AI Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07223",
        "PDF": "https://arxiv.org/pdf/2507.07223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper examines AI infrastructure for large-scale language models, it focuses on hardware and architecture improvements rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07241",
      "abstract": "This work addresses the problem of secrecy energy efficiency (SEE) maximization in RIS-aided wireless networks. The use of active and nearly-passive RISs are compared and their trade-off in terms of SEE is analyzed. Considering both perfect and statistical channel state information, two SEE maximization algorithms are developed to optimize the transmit powers of the mobile users, the RIS reflection coefficients, and the base station receive filters. Numerical results quantify the trade-off between active and nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values as the static power consumed by each reflecting element increases.",
      "authors": [
        "Robert Kuku Fotock",
        "Agbotiname Lucky Imoize",
        "Alessio Zappone",
        "Marco Di Renzo and Roberto Garello"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:24:18+00:00",
          "link": "https://arxiv.org/abs/2507.07241v1",
          "size": "996kb",
          "version": "v1"
        }
      ],
      "title": "Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07241",
        "HTML": "https://arxiv.org/html/2507.07241v1",
        "PDF": "https://arxiv.org/pdf/2507.07241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with energy efficiency in wireless networks with RISs, not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07591",
      "abstract": "While diffusion-based methods have shown impressive capabilities in capturing diverse and complex hairstyles, their ability to generate consistent and high-quality multi-view outputs -- crucial for real-world applications such as digital humans and virtual avatars -- remains underexplored. In this paper, we propose Stable-Hair v2, a novel diffusion-based multi-view hair transfer framework. To the best of our knowledge, this is the first work to leverage multi-view diffusion models for robust, high-fidelity, and view-consistent hair transfer across multiple perspectives. We introduce a comprehensive multi-view training data generation pipeline comprising a diffusion-based Bald Converter, a data-augment inpainting model, and a face-finetuned multi-view diffusion model to generate high-quality triplet data, including bald images, reference hairstyles, and view-aligned source-bald pairs. Our multi-view hair transfer model integrates polar-azimuth embeddings for pose conditioning and temporal attention layers to ensure smooth transitions between views. To optimize this model, we design a novel multi-stage training strategy consisting of pose-controllable latent IdentityNet training, hair extractor training, and temporal attention training. Extensive experiments demonstrate that our method accurately transfers detailed and realistic hairstyles to source subjects while achieving seamless and consistent results across views, significantly outperforming existing methods and establishing a new benchmark in multi-view hair transfer. Code is publicly available at https://github.com/sunkymepro/StableHairV2.",
      "authors": [
        "Kuiyuan Sun",
        "Yuxuan Zhang",
        "Jichao Zhang",
        "Jiaming Liu",
        "Wei Wang",
        "Niculae Sebe",
        "Yao Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:49:34+00:00",
          "link": "https://arxiv.org/abs/2507.07591v1",
          "size": "17010kb",
          "version": "v1"
        }
      ],
      "title": "Stable-Hair v2: Real-World Hair Transfer via Multiple-View Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07591",
        "HTML": "https://arxiv.org/html/2507.07591v1",
        "PDF": "https://arxiv.org/pdf/2507.07591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a multi-view training data generation pipeline using diffusion models, contributing to the field by creating new high-quality data for hair transfer tasks, which involves significant data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07635",
      "abstract": "Non-uniform time stepping in acoustic propagation models can be used to preserve accuracy or reduce computational cost for an acoustic simulation with a wave front propagating through a domain with both heterogeneous and homogenous regions, such as for a simulation of breast ultrasound tomography. The k-space correction already exist within the literature to remove numerical dispersion caused by the time stepping procedure in pseudo-spectral time domain models, but requires a uniform time step. Here we expand this correction to be able to account for a non-uniform time stepping method and illustrate the potential advantages and considerations. A version of this Article has been submitted for review to the Journal of Theoretical and Computational Acoustics.",
      "authors": [
        "Matthew J. King",
        "B. E. Treeby and B. T. Cox"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:05:13+00:00",
          "link": "https://arxiv.org/abs/2507.07635v1",
          "size": "494kb",
          "version": "v1"
        }
      ],
      "title": "Non-uniform time-stepping in k-space pseudospectral time domain models of acoustic propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07635",
        "HTML": "https://arxiv.org/html/2507.07635v1",
        "PDF": "https://arxiv.org/pdf/2507.07635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with acoustic propagation simulations and non-uniform time-stepping models, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2103.10145",
      "abstract": "To find families for the more than 100,000 children in need of adoptive placements, most United States child welfare agencies have employed a family-driven search approach in which prospective families respond to announcements made by the agency. However, some agencies have switched to a caseworker-driven search approach in which the caseworker directly contacts families recommended for a child. We introduce a novel search-and-matching model that captures the key features of the adoption process and compare family-driven with caseworker-driven search in a game-theoretical framework. Under either approach, the equilibria are generated by threshold strategies and form a lattice structure. Our main theoretical finding then shows that no family-driven equilibrium can Pareto dominate any caseworker-driven outcome, whereas it is possible that each caseworker-driven equilibrium Pareto dominates every equilibrium attainable under family-driven search. We also find that when families are sufficiently impatient, caseworker-driven search is better for all children. We illustrate numerically that most agents are better off under caseworker-driven search for a wide range of parameters. Finally, we provide empirical evidence from an agency that switched to caseworker-driven search and achieved a three-year adoption probability that outperformed a statewide benchmark by 24%, as well as a statistically significant 27% improvement in adoption hazard rates.",
      "authors": [
        "Ludwig Dierks",
        "Nils Olberg",
        "Sven Seuken",
        "Vincent W. Slaugh",
        "M. Utku \\\"Unver"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-18T10:24:18+00:00",
          "link": "https://arxiv.org/abs/2103.10145v1",
          "size": "127kb",
          "version": "v1"
        },
        {
          "date": "2022-10-21T10:46:09+00:00",
          "link": "https://arxiv.org/abs/2103.10145v2",
          "size": "251kb",
          "version": "v2"
        },
        {
          "date": "2024-05-23T21:43:50+00:00",
          "link": "https://arxiv.org/abs/2103.10145v3",
          "size": "681kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T02:14:22+00:00",
          "link": "https://arxiv.org/abs/2103.10145v4",
          "size": "611kb",
          "version": "v4"
        }
      ],
      "title": "Search and Matching for Adoption from Foster Care",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.10145",
        "HTML": "https://arxiv.org/html/2103.10145v4",
        "PDF": "https://arxiv.org/pdf/2103.10145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on search-and-matching models for child adoption processes, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.13973",
      "abstract": "Autonomous navigation in marine environments can be extremely challenging, especially in the presence of spatially varying flow disturbances and dynamic and static obstacles. In this work, we demonstrate that incorporating local flow field measurements fundamentally alters the nature of the problem, transforming otherwise unsolvable navigation scenarios into tractable ones. However, the mere availability of flow data is not sufficient; it must be effectively fused with conventional sensory inputs such as ego-state and obstacle states. To this end, we propose \\textbf{MarineFormer}, a Transformer-based policy architecture that integrates two complementary attention mechanisms: spatial attention for sensor fusion, and temporal attention for capturing environmental dynamics. MarineFormer is trained end-to-end via reinforcement learning in a 2D simulated environment with realistic flow features and obstacles. Extensive evaluations against classical and state-of-the-art baselines show that our approach improves episode completion success rate by nearly 23\\% while reducing path length. Ablation studies further highlight the critical role of flow measurements and the effectiveness of our proposed architecture in leveraging them.",
      "authors": [
        "Ehsan Kazemi",
        "Dechen Gao and Iman Soltani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T18:57:15+00:00",
          "link": "https://arxiv.org/abs/2410.13973v1",
          "size": "7808kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T06:55:36+00:00",
          "link": "https://arxiv.org/abs/2410.13973v2",
          "size": "9418kb",
          "version": "v2"
        },
        {
          "date": "2024-12-17T22:20:22+00:00",
          "link": "https://arxiv.org/abs/2410.13973v3",
          "size": "9409kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T23:40:31+00:00",
          "link": "https://arxiv.org/abs/2410.13973v4",
          "size": "7904kb",
          "version": "v4"
        }
      ],
      "title": "MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in Dynamic Marine Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13973",
        "HTML": "https://arxiv.org/html/2410.13973v4",
        "PDF": "https://arxiv.org/pdf/2410.13973"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a transformer-based navigation model using sensor fusion and reinforcement learning, without discussing any LLM training data processing or creation."
      },
      "tasks": [
        "Collision Avoidance",
        "Graph Attention",
        "Reinforcement Learning (RL)",
        "Temporal Sequences"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11498",
      "abstract": "Building Information Modeling (BIM) is an essential component in the sustainable reconstruction and revitalization of ageing structures. However, model creation usually relies on laborious manual transformation of the unstructured point cloud data provided by laser scans or photogrammetry. This paper presents Cloud2BIM, an open-source software tool designed to automate the conversion of point clouds into BIM models compliant with the Industry Foundation Classes (IFC) standard. Cloud2BIM integrates advanced algorithms for wall and slab segmentation, opening detection, and room zoning based on real wall surfaces, resulting in a comprehensive and fully automated workflow. Unlike existing tools, it avoids computationally- and calibration-intensive techniques such as RANSAC, supports non-orthogonal geometries, and provides unprecedented processing speed-achieving results up to seven times faster than fastest competing solutions. Systematic validation using benchmark datasets confirms that Cloud2BIM is an easy-to-use, efficient, and scalable solution for generating accurate BIM models, capable of converting extensive point cloud datasets for entire buildings into IFC format with minimal user input.",
      "authors": [
        "Sl\\'avek Zbirovsk\\'y",
        "V\\'aclav Ne\\v{z}erka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T15:26:02+00:00",
          "link": "https://arxiv.org/abs/2503.11498v1",
          "size": "6589kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T21:53:55+00:00",
          "link": "https://arxiv.org/abs/2503.11498v2",
          "size": "8987kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T14:56:07+00:00",
          "link": "https://arxiv.org/abs/2503.11498v3",
          "size": "9640kb",
          "version": "v3"
        }
      ],
      "title": "Open-source automatic pipeline for efficient conversion of large-scale point clouds to IFC format",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11498",
        "PDF": "https://arxiv.org/pdf/2503.11498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an automated method for converting point clouds to BIM models, which does not pertain to LLM training data processing or data engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/vaclavnezerka/cloud2bim"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07359",
      "abstract": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal experimental design. Unlike conventional approaches that select interventions aimed at inferring the full causal model, GO-CBED directly maximizes the expected information gain (EIG) on user-specified causal quantities of interest, enabling more targeted and efficient experimentation. The framework is both non-myopic, optimizing over entire intervention sequences, and goal-oriented, targeting only model aspects relevant to the causal query. To address the intractability of exact EIG computation, we introduce a variational lower bound estimator, optimized jointly through a transformer-based policy network and normalizing flow-based variational posteriors. The resulting policy enables real-time decision-making via an amortized network. We demonstrate that GO-CBED consistently outperforms existing baselines across various causal reasoning and discovery tasks-including synthetic structural causal models and semi-synthetic gene regulatory networks-particularly in settings with limited experimental budgets and complex causal mechanisms. Our results highlight the benefits of aligning experimental design objectives with specific research goals and of forward-looking sequential planning.",
      "authors": [
        "Zheyu Zhang",
        "Jiayuan Dong",
        "Jie Liu",
        "Xun Huan (University of Michigan)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:53:57+00:00",
          "link": "https://arxiv.org/abs/2507.07359v1",
          "size": "8076kb",
          "version": "v1"
        }
      ],
      "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07359",
        "HTML": "https://arxiv.org/html/2507.07359v1",
        "PDF": "https://arxiv.org/pdf/2507.07359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on experimental design for causal learning via Bayesian methods, which is unrelated to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07465",
      "abstract": "Current 4D Gaussian frameworks for dynamic scene reconstruction deliver impressive visual fidelity and rendering speed, however, the inherent trade-off between storage costs and the ability to characterize complex physical motions significantly limits the practical application of these methods. To tackle these problems, we propose SD-GS, a compact and efficient dynamic Gaussian splatting framework for complex dynamic scene reconstruction, featuring two key contributions. First, we introduce a deformable anchor grid, a hierarchical and memory-efficient scene representation where each anchor point derives multiple 3D Gaussians in its local spatiotemporal region and serves as the geometric backbone of the 3D scene. Second, to enhance modeling capability for complex motions, we present a deformation-aware densification strategy that adaptively grows anchors in under-reconstructed high-dynamic regions while reducing redundancy in static areas, achieving superior visual quality with fewer anchors. Experimental results demonstrate that, compared to state-of-the-art methods, SD-GS achieves an average of 60\\% reduction in model size and an average of 100\\% improvement in FPS, significantly enhancing computational efficiency while maintaining or even surpassing visual quality.",
      "authors": [
        "Wei Yao",
        "Shuzhao Xie",
        "Letian Li",
        "Weixiang Zhang",
        "Zhixin Lai",
        "Shiqi Dai",
        "Ke Zhang",
        "Zhi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:35:03+00:00",
          "link": "https://arxiv.org/abs/2507.07465v1",
          "size": "11367kb",
          "version": "v1"
        }
      ],
      "title": "SD-GS: Structured Deformable 3D Gaussians for Efficient Dynamic Scene Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07465",
        "HTML": "https://arxiv.org/html/2507.07465v1",
        "PDF": "https://arxiv.org/pdf/2507.07465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a dynamic scene reconstruction framework and does not discuss LLM training data processing or data engineering operations related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07998",
      "abstract": "LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.",
      "authors": [
        "Shitian Zhao",
        "Haoquan Zhang",
        "Shaoheng Lin",
        "Ming Li",
        "Qilong Wu",
        "Kaipeng Zhang",
        "Chen Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.07998v1",
          "size": "12300kb",
          "version": "v1"
        }
      ],
      "title": "PyVision: Agentic Vision with Dynamic Tooling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07998",
        "PDF": "https://arxiv.org/pdf/2507.07998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PyVision applies dynamic tool generation for visual reasoning tasks with LLMs, focusing on interactive tooling rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06971",
      "abstract": "Panoramic perception holds significant potential for autonomous driving, enabling vehicles to acquire a comprehensive 360{\\deg} surround view in a single shot. However, autonomous driving is a data-driven task. Complete panoramic data acquisition requires complex sampling systems and annotation pipelines, which are time-consuming and labor-intensive. Although existing street view generation models have demonstrated strong data regeneration capabilities, they can only learn from the fixed data distribution of existing datasets and cannot achieve high-quality, controllable panoramic generation. In this paper, we propose the first panoramic generation method Percep360 for autonomous driving. Percep360 enables coherent generation of panoramic data with control signals based on the stitched panoramic data. Percep360 focuses on two key aspects: coherence and controllability. Specifically, to overcome the inherent information loss caused by the pinhole sampling process, we propose the Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama generation as a spatially continuous diffusion process, bridging the gaps between different data distributions. Additionally, to achieve the controllable generation of panoramic images, we propose a Probabilistic Prompting Method (PPM). PPM dynamically selects the most relevant control cues, enabling controllable panoramic image generation. We evaluate the effectiveness of the generated images from three perspectives: image quality assessment (i.e., no-reference and with reference), controllability, and their utility in real-world Bird's Eye View (BEV) segmentation. Notably, the generated data consistently outperforms the original stitched images in no-reference quality metrics and enhances downstream perception models. The source code will be publicly available at https://github.com/Bryant-Teng/Percep360.",
      "authors": [
        "Fei Teng",
        "Kai Luo",
        "Sheng Wu",
        "Siyu Li",
        "Pujun Guo",
        "Jiale Wei",
        "Kunyu Peng",
        "Jiaming Zhang",
        "Kailun Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:01:41+00:00",
          "link": "https://arxiv.org/abs/2507.06971v1",
          "size": "4700kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:50:07+00:00",
          "link": "https://arxiv.org/abs/2507.06971v2",
          "size": "4700kb",
          "version": "v2"
        }
      ],
      "title": "Hallucinating 360{\\deg}: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06971",
        "HTML": "https://arxiv.org/html/2507.06971v2",
        "PDF": "https://arxiv.org/pdf/2507.06971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses panoramic data generation and enhancement for autonomous driving perception but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07985",
      "abstract": "Contrastive vision-language models like CLIP are used for a large variety of applications, such as zero-shot classification or as vision encoder for multi-modal models. Despite their popularity, their representations show major limitations. For instance, CLIP models learn bag-of-words representations and, as a consequence, fail to distinguish whether an image is of \"a yellow submarine and a blue bus\" or \"a blue submarine and a yellow bus\". Previous attempts to fix this issue added hard negatives during training or modified the architecture, but failed to resolve the problem in its entirety. We suspect that the missing insights to solve the binding problem for CLIP are hidden in the arguably most important part of learning algorithms: the data. In this work, we fill this gap by rigorously identifying the influence of data properties on CLIP's ability to learn binding using a synthetic dataset. We find that common properties of natural data such as low attribute density, incomplete captions, and the saliency bias, a tendency of human captioners to describe the object that is \"most salient\" to them have a detrimental effect on binding performance. In contrast to common belief, we find that neither scaling the batch size, i.e., implicitly adding more hard negatives, nor explicitly creating hard negatives enables CLIP to learn reliable binding. Only when the data expresses our identified data properties CLIP learns almost perfect binding.",
      "authors": [
        "Bijay Gurung",
        "David T. Hoffmann",
        "Thomas Brox"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:57:31+00:00",
          "link": "https://arxiv.org/abs/2507.07985v1",
          "size": "1130kb",
          "version": "v1"
        }
      ],
      "title": "CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07985",
        "HTML": "https://arxiv.org/html/2507.07985v1",
        "PDF": "https://arxiv.org/pdf/2507.07985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses insights into data properties affecting model learning but does not focus primarily on data processing; it involves using a synthetic dataset to evaluate object-attribute binding in models like CLIP."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07929",
      "abstract": "Continuous, automated monitoring of laboratory mice enables more accurate data collection and improves animal welfare through real-time insights. Researchers can achieve a more dynamic and clinically relevant characterization of disease progression and therapeutic effects by integrating behavioral and physiological monitoring in the home cage. However, providing individual mouse metrics is difficult because of their housing density, similar appearances, high mobility, and frequent interactions. To address these challenges, we develop a real-time identification (ID) algorithm that accurately assigns ID predictions to mice wearing custom ear tags in digital home cages monitored by cameras. Our pipeline consists of three parts: (1) a custom multiple object tracker (MouseTracks) that combines appearance and motion cues from mice; (2) a transformer-based ID classifier (Mouseformer); and (3) a tracklet associator linear program to assign final ID predictions to tracklets (MouseMap). Our models assign an animal ID based on custom ear tags at 30 frames per second with 24/7 cage coverage. We show that our custom tracking and ID pipeline improves tracking efficiency and lowers ID switches across mouse strains and various environmental factors compared to current mouse tracking methods.",
      "authors": [
        "Juan Pablo Oberhauser and Daniel Grzenda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:09:14+00:00",
          "link": "https://arxiv.org/abs/2507.07929v1",
          "size": "1060kb",
          "version": "v1"
        }
      ],
      "title": "Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07929",
        "HTML": "https://arxiv.org/html/2507.07929v1",
        "PDF": "https://arxiv.org/pdf/2507.07929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a real-time identification algorithm for tracking laboratory mice and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.08793",
      "abstract": "In serial batch (s-batch) scheduling, jobs are grouped in batches and processed sequentially within their batch. This paper considers multiple parallel machines, nonidentical job weights and release times, and sequence-dependent setup times between batches of different families. Although s-batch has been widely studied in the literature, very few papers have taken into account a minimum batch size, typical in practical settings such as semiconductor manufacturing and the metal industry. The problem with this minimum batch size requirement has been mostly tackled with dynamic programming and meta-heuristics, and no article has ever used constraint programming (CP) to do so. This paper fills this gap by proposing, three CP models for s-batching with minimum batch size: (i) an \\textit{Interval Assignment} model that computes and bounds the size of the batches using the presence literals of interval variables of the jobs. (ii) A \\textit{Global} model that exclusively uses global constraints that track the size of the batches over time. (iii) And a \\textit{Hybrid} model that combines the benefits of the extra global constraints with the efficiency of the sum-of-presences constraints to ensure the minimum batch sizes. The computational experiments on standard cases compare the three CP models with two existing mixed-integer programming (MIP) models from the literature. The results demonstrate the versatility of the proposed CP models to handle multiple variations of s-batching; and their ability to produce, in large instances, better solutions than the MIP models faster.",
      "authors": [
        "Jorge A. Huertas and Pascal Van Hentenryck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T17:14:19+00:00",
          "link": "https://arxiv.org/abs/2504.08793v1",
          "size": "337kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:00:50+00:00",
          "link": "https://arxiv.org/abs/2504.08793v2",
          "size": "549kb",
          "version": "v2"
        }
      ],
      "title": "Constraint Programming Models For Serial Batch Scheduling With Minimum Batch Size",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08793",
        "PDF": "https://arxiv.org/pdf/2504.08793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing constraint programming models for batch scheduling, unrelated to LLM training data processing."
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07116",
      "abstract": "Data spaces are emerging as decentralised infrastructures that enable sovereign, secure, and trustworthy data exchange among multiple participants. To achieve semantic interoperability within these environments, the use of semantic web technologies and knowledge graphs has been proposed. Although distributed ledger technologies (DLT) fit as the underlying infrastructure for data spaces, there remains a significant gap in terms of the efficient storage of semantic data on these platforms. This paper presents a systematic evaluation of semantic data storage across different types of DLT (public, private, and hybrid), using a real-world knowledge graph as an experimental basis. The study compares performance, storage efficiency, resource consumption, and the capabilities to update and query semantic data. The results show that private DLTs are the most efficient for storing and managing semantic content, while hybrid DLTs offer a balanced trade-off between public auditability and operational efficiency. This research leads to a discussion on the selection of the most appropriate DLT infrastructure based on the data sovereignty requirements of decentralised data ecosystems.",
      "authors": [
        "Juan Cano-Benito",
        "Andrea Cimmino",
        "Sven Hertling",
        "Heiko Paulheim and Ra\\'ul Garc\\'ia-Castro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:21:00+00:00",
          "link": "https://arxiv.org/abs/2507.07116v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07116",
        "HTML": "https://arxiv.org/html/2507.07116v1",
        "PDF": "https://arxiv.org/pdf/2507.07116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates semantic data storage in distributed ledger technologies, with no discussion on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07155",
      "abstract": "We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this purpose.The RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community.",
      "authors": [
        "Xueqing Xu",
        "Boris Bolliet",
        "Adrian Dimitrov",
        "Andrew Laverick",
        "Francisco Villaescusa-Navarro",
        "Licong Xu,\\'I\\~nigo Zubeldia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:46:03+00:00",
          "link": "https://arxiv.org/abs/2507.07155v1",
          "size": "384kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07155",
        "HTML": "https://arxiv.org/html/2507.07155v1",
        "PDF": "https://arxiv.org/pdf/2507.07155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper constructs a QA dataset relevant for RAG agents, it does not focus on processing or improving LLM training data quality beyond the scope of the specific application in astrophysics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07325",
      "abstract": "Sentiment analysis is an essential technique for investigating the emotional climate within developer teams, contributing to both team productivity and project success. Existing sentiment analysis tools in software engineering primarily rely on English or non-German gold-standard datasets. To address this gap, our work introduces a German dataset of 5,949 unique developer statements, extracted from the German developer forum Android-Hilfe.de. Each statement was annotated with one of six basic emotions, based on the emotion model by Shaver et al., by four German-speaking computer science students. Evaluation of the annotation process showed high interrater agreement and reliability. These results indicate that the dataset is sufficiently valid and robust to support sentiment analysis in the German-speaking software engineering community. Evaluation with existing German sentiment analysis tools confirms the lack of domain-specific solutions for software engineering. We also discuss approaches to optimize annotation and present further use cases for the dataset.",
      "authors": [
        "Martin Obaidi",
        "Marc Herrmann",
        "Elisa Schmid",
        "Raymond Ochsner",
        "Kurt Schneider and Jil Kl\\\"under"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:55:37+00:00",
          "link": "https://arxiv.org/abs/2507.07325v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "A German Gold-Standard Dataset for Sentiment Analysis in Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07325",
        "HTML": "https://arxiv.org/html/2507.07325v1",
        "PDF": "https://arxiv.org/pdf/2507.07325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new German dataset for sentiment analysis with a detailed annotation process, contributing to LLM training data processing by creating a gold-standard dataset for sentiment analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07453",
      "abstract": "Melanoma, one of the deadliest types of skin cancer, accounts for thousands of fatalities globally. The bluish, blue-whitish, or blue-white veil (BWV) is a critical feature for diagnosing melanoma, yet research into detecting BWV in dermatological images is limited. This study utilizes a non-annotated skin lesion dataset, which is converted into an annotated dataset using a proposed imaging algorithm based on color threshold techniques on lesion patches and color palettes. A Deep Convolutional Neural Network (DCNN) is designed and trained separately on three individual and combined dermoscopic datasets, using custom layers instead of standard activation function layers. The model is developed to categorize skin lesions based on the presence of BWV. The proposed DCNN demonstrates superior performance compared to conventional BWV detection models across different datasets. The model achieves a testing accuracy of 85.71% on the augmented PH2 dataset, 95.00% on the augmented ISIC archive dataset, 95.05% on the combined augmented (PH2+ISIC archive) dataset, and 90.00% on the Derm7pt dataset. An explainable artificial intelligence (XAI) algorithm is subsequently applied to interpret the DCNN's decision-making process regarding BWV detection. The proposed approach, coupled with XAI, significantly improves the detection of BWV in skin lesions, outperforming existing models and providing a robust tool for early melanoma diagnosis.",
      "authors": [
        "M. A. Rasel",
        "Sameem Abdul Kareem",
        "Zhenli Kwan",
        "Shin Shen Yong",
        "Unaizah Obaidellah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:12:23+00:00",
          "link": "https://arxiv.org/abs/2507.07453v1",
          "size": "1042kb",
          "version": "v1"
        }
      ],
      "title": "Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07453",
        "PDF": "https://arxiv.org/pdf/2507.07453"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on skin lesion classification using DCNNs and explainable AI techniques, but it does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07532",
      "abstract": "While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.",
      "authors": [
        "Berkant Turan",
        "Suhrab Asadulla",
        "David Steinmann",
        "Wolfgang Stammer",
        "Sebastian Pokutta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:28:46+00:00",
          "link": "https://arxiv.org/abs/2507.07532v1",
          "size": "675kb",
          "version": "v1"
        }
      ],
      "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07532",
        "HTML": "https://arxiv.org/html/2507.07532v1",
        "PDF": "https://arxiv.org/pdf/2507.07532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for interpretable classification models but focuses on concept encodings and nonlinear predictors rather than LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07930",
      "abstract": "Background: Public speaking is a vital professional skill, yet it remains a source of significant anxiety for many individuals. Traditional training relies heavily on expert coaching, but recent advances in AI has led to novel types of commercial automated public speaking feedback tools. However, most research has focused on prototypes rather than commercial applications, and little is known about how public speaking experts perceive these tools.\n  Objectives: This study aims to evaluate expert opinions on the efficacy and design of commercial AI-based public speaking training tools and to propose guidelines for their improvement.\n  Methods: The research involved 16 semi-structured interviews and 2 focus groups with public speaking experts. Participants discussed their views on current commercial tools, their potential integration into traditional coaching, and suggestions for enhancing these systems.\n  Results and Conclusions: Experts acknowledged the value of AI tools in handling repetitive, technical aspects of training, allowing coaches to focus on higher-level skills. However they found key issues in current tools, emphasising the need for personalised, understandable, carefully selected feedback and clear instructional design. Overall, they supported a hybrid model combining traditional coaching with AI-supported exercises.",
      "authors": [
        "Nesrine Fourati",
        "Alisa Barkar",
        "Marion Drag\\'ee",
        "Liv Danthon-Lefebvre",
        "Mathieu Chollet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:09:21+00:00",
          "link": "https://arxiv.org/abs/2507.07930v1",
          "size": "118kb",
          "version": "v1"
        }
      ],
      "title": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07930",
        "HTML": "https://arxiv.org/html/2507.07930v1",
        "PDF": "https://arxiv.org/pdf/2507.07930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates expert opinions on AI-based public speaking training tools and does not involve any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07999",
      "abstract": "Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human \"thinking with images\". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.",
      "authors": [
        "Haochen Wang and Xiangtai Li and Zilong Huang and Anran Wang and Jiacong Wang and Tao Zhang and Jiani Zheng and Sule Bai and Zijian Kang and Jiashi Feng and Zhuochen Wang and Zhaoxiang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:58+00:00",
          "link": "https://arxiv.org/abs/2507.07999v1",
          "size": "7750kb",
          "version": "v1"
        }
      ],
      "title": "Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07999",
        "HTML": "https://arxiv.org/html/2507.07999v1",
        "PDF": "https://arxiv.org/pdf/2507.07999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new benchmark for evaluating visual grounded reasoning capabilities. It presents training methodologies but does not focus directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00015",
      "abstract": "[Context] Generative AI technologies, particularly Large Language Models (LLMs), have transformed numerous domains by enhancing convenience and efficiency in information retrieval, content generation, and decision-making processes. However, deploying LLMs also presents diverse ethical challenges, and their mitigation strategies remain complex and domain-dependent. [Objective] This paper aims to identify and categorize the key ethical concerns associated with using LLMs, examine existing mitigation strategies, and assess the outstanding challenges in implementing these strategies across various domains. [Method] We conducted a systematic mapping study, reviewing 39 studies that discuss ethical concerns and mitigation strategies related to LLMs. We analyzed these ethical concerns using five ethical dimensions that we extracted based on various existing guidelines, frameworks, and an analysis of the mitigation strategies and implementation challenges. [Results] Our findings reveal that ethical concerns in LLMs are multi-dimensional and context-dependent. While proposed mitigation strategies address some of these concerns, significant challenges still remain. [Conclusion] Our results highlight that ethical issues often hinder the practical implementation of the mitigation strategies, particularly in high-stake areas like healthcare and public governance; existing frameworks often lack adaptability, failing to accommodate evolving societal expectations and diverse contexts.",
      "authors": [
        "Yutan Huang",
        "Chetan Arora",
        "Wen Cheng Houng",
        "Tanjila Kanij",
        "Anuradha Madulgalla",
        "John Grundy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T13:05:19+00:00",
          "link": "https://arxiv.org/abs/2502.00015v1",
          "size": "2649kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:51:53+00:00",
          "link": "https://arxiv.org/abs/2502.00015v2",
          "size": "548kb",
          "version": "v2"
        }
      ],
      "title": "Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00015",
        "PDF": "https://arxiv.org/pdf/2502.00015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on ethical challenges and mitigation strategies in deploying LLMs, but there is no significant emphasis on processing or improving the training data itself."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07343",
      "abstract": "We show that mixtures comprised of multicomponent systems typically are much more structurally complex than the sum of their parts; sometimes, infinitely more complex. We contrast this with the more familiar notion of statistical mixtures, demonstrating how statistical mixtures miss key aspects of emergent hierarchical organization. This leads us to identify a new kind of structural complexity inherent in multicomponent systems and to draw out broad consequences for system ergodicity.",
      "authors": [
        "James P. Crutchfield"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Statistics Theory (math.ST)",
        "Chaotic Dynamics (nlin.CD)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:01:53+00:00",
          "link": "https://arxiv.org/abs/2507.07343v1",
          "size": "1292kb",
          "version": "v1"
        }
      ],
      "title": "Way More Than the Sum of Their Parts: From Statistical to Structural Mixtures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07343",
        "HTML": "https://arxiv.org/html/2507.07343v1",
        "PDF": "https://arxiv.org/pdf/2507.07343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses structural complexity in multicomponent systems without mentioning LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01361",
      "abstract": "Graph neural networks (GNNs) are designed to process data associated with graphs. They are finding an increasing range of applications; however, as with other modern machine learning techniques, their theoretical understanding is limited. GNNs can encounter difficulties in gathering information from nodes that are far apart by iterated aggregation steps. This situation is partly caused by so-called oversmoothing; and overcoming it is one of the practically motivated challenges. We consider the situation where information is aggregated by multiple steps of convolution, leading to graph convolutional networks (GCNs). We analyze the generalization performance of a basic GCN, trained for node classification on data generated by the contextual stochastic block model. We predict its asymptotic performance by deriving the free energy of the problem, using the replica method, in the high-dimensional limit. Calling depth the number of convolutional steps, we show the importance of going to large depth to approach the Bayes-optimality. We detail how the architecture of the GCN has to scale with the depth to avoid oversmoothing. The resulting large depth limit can be close to the Bayes-optimality and leads to a continuous GCN. Technically, we tackle this continuous limit via an approach that resembles dynamical mean-field theory (DMFT) with constraints at the initial and final times. An expansion around large regularization allows us to solve the corresponding equations for the performance of the deep GCN. This promising tool may contribute to the analysis of further deep neural networks.",
      "authors": [
        "O. Duranthon",
        "L. Zdeborov\\'a"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T09:55:10+00:00",
          "link": "https://arxiv.org/abs/2503.01361v1",
          "size": "286kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:02:15+00:00",
          "link": "https://arxiv.org/abs/2503.01361v2",
          "size": "346kb",
          "version": "v2"
        }
      ],
      "title": "Statistical physics analysis of graph neural networks: Approaching optimality in the contextual stochastic block model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01361",
        "HTML": "https://arxiv.org/html/2503.01361v2",
        "PDF": "https://arxiv.org/pdf/2503.01361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the generalization performance of graph neural networks for node classification, focusing on theoretical understanding of GNNs rather than LLM training data processing."
      },
      "tasks": [
        "Node Classification",
        "Stochastic Block Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07588",
      "abstract": "This article explores the estimation of parameters and states for linear stochastic systems with deterministic control inputs. It introduces a novel Kalman filtering approach called Kalman Filtering with Correlated Noises Recursive Generalized Extended Least Squares (KF-CN-RGELS) algorithm, which leverages the cross-correlation between process noise and measurement noise in Kalman filtering cycles to jointly estimate both parameters and system states. The study also investigates the theoretical implications of the correlation coefficient on estimation accuracy through performance analysis involving various correlation coefficients between process and measurement noises. The research establishes a clear relationship: the accuracy of identified parameters and states is directly proportional to positive correlation coefficients. To validate the efficacy of this algorithm, a comprehensive comparison is conducted among different algorithms, including the standard Kalman filter algorithm and the augmented-state Kalman filter with correlated noises algorithm. Theoretical findings are not only presented but also exemplified through a numerical case study to provide valuable insights into practical implications. This work contributes to enhancing estimation accuracy in linear stochastic systems with deterministic control inputs, offering valuable insights for control system design and state-space modeling.",
      "authors": [
        "Abd El Mageed Hag Elamin Khalid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:46:59+00:00",
          "link": "https://arxiv.org/abs/2507.07588v1",
          "size": "4611kb",
          "version": "v1"
        }
      ],
      "title": "Perspective Chapter: Insights from Kalman Filtering with Correlated Noises Recursive Least-Square Algorithm for State and Parameter Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07588",
        "PDF": "https://arxiv.org/pdf/2507.07588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper's main contribution relates to state and parameter estimation using Kalman filtering, which does not engage with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08007",
      "abstract": "Algorithmic Recourse (AR) aims to provide users with actionable steps to overturn unfavourable decisions made by machine learning predictors. However, these actions often take time to implement (e.g., getting a degree can take years), and their effects may vary as the world evolves. Thus, it is natural to ask for recourse that remains valid in a dynamic environment. In this paper, we study the robustness of algorithmic recourse over time by casting the problem through the lens of causality. We demonstrate theoretically and empirically that (even robust) causal AR methods can fail over time, except in the -- unlikely -- case that the world is stationary. Even more critically, unless the world is fully deterministic, counterfactual AR cannot be solved optimally. To account for this, we propose a simple yet effective algorithm for temporal AR that explicitly accounts for time under the assumption of having access to an estimator approximating the stochastic process. Our simulations on synthetic and realistic datasets show how considering time produces more resilient solutions to potential trends in the data distribution.",
      "authors": [
        "Giovanni De Toni",
        "Stefano Teso",
        "Bruno Lepri",
        "Andrea Passerini"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T15:02:38+00:00",
          "link": "https://arxiv.org/abs/2410.08007v1",
          "size": "1899kb",
          "version": "v1"
        },
        {
          "date": "2025-01-24T13:43:18+00:00",
          "link": "https://arxiv.org/abs/2410.08007v2",
          "size": "2107kb",
          "version": "v2"
        },
        {
          "date": "2025-05-14T14:50:15+00:00",
          "link": "https://arxiv.org/abs/2410.08007v3",
          "size": "2159kb",
          "version": "v3"
        }
      ],
      "title": "Time Can Invalidate Algorithmic Recourse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08007",
        "HTML": "https://arxiv.org/html/2410.08007",
        "PDF": "https://arxiv.org/pdf/2410.08007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithmic recourse over time using causal methods and temporal aspects, without contributions to LLM training data engineering or processing."
      },
      "tasks": [
        "counterfactual",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/unitn-sml/temporal-algorithmic-recourse"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07207",
      "abstract": "Can neural networks systematically capture discrete, compositional task structure despite their continuous, distributed nature? The impressive capabilities of large-scale neural networks suggest that the answer to this question is yes. However, even for the most capable models, there are still frequent failure cases that raise doubts about their compositionality. Here, we seek to understand what it takes for a standard neural network to generalize over tasks that share compositional structure. We find that simply scaling data and model size leads to compositional generalization. We show that this holds across different task encodings as long as the training distribution sufficiently covers the task space. In line with this finding, we prove that standard multilayer perceptrons can approximate a general class of compositional task families to arbitrary precision using only a linear number of neurons with respect to the number of task modules. Finally, we uncover that if networks successfully compositionally generalize, the constituents of a task can be linearly decoded from their hidden activations. We show that this metric correlates with failures of text-to-image generation models to compose known concepts.",
      "authors": [
        "Florian Redhardt",
        "Yassir Akram",
        "Simon Schug"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:30:50+00:00",
          "link": "https://arxiv.org/abs/2507.07207v1",
          "size": "1014kb",
          "version": "v1"
        }
      ],
      "title": "Scale leads to compositional generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07207",
        "PDF": "https://arxiv.org/pdf/2507.07207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the role of scaling in neural networks for compositional generalization, which may imply some data scaling practices, but does not focus on detailed data processing methods for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.14514",
      "abstract": "Interdicting a criminal with limited police resources is a challenging task as the criminal changes location over time. The size of the large transportation network further adds to the difficulty of this scenario. To tackle this issue, we consider the concept of a layered graph. At each time stamp, we create a copy of the entire transportation network to track the possible movements of both players, the attacker and the defenders. We consider a Stackelberg game in a dynamic crime scenario where the attacker changes location over time while the defenders attempt to interdict the attacker on his escape route. Given a set of defender strategies, the optimal attacker strategy is determined by applying Dijkstra's algorithm on the layered networks. Here, the attacker aims to minimize while the defenders aim to maximize the probability of interdiction. We develop an approximation algorithm on the layered networks to find near-optimal strategy for defenders. The efficacy of the developed approach is compared with the adopted MILP approach. We compare the results in terms of computational time and solution quality. The quality of the results demonstrates the need for the developed approach, as it effectively solves the complex problem within a short amount of time.",
      "authors": [
        "Sukanya Samanta",
        "Kei Kimura",
        "Makoto Yokoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-20T17:24:13+00:00",
          "link": "https://arxiv.org/abs/2406.14514v1",
          "size": "185kb",
          "version": "v1"
        },
        {
          "date": "2024-10-23T07:05:18+00:00",
          "link": "https://arxiv.org/abs/2406.14514v2",
          "size": "522kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:05:03+00:00",
          "link": "https://arxiv.org/abs/2406.14514v3",
          "size": "523kb",
          "version": "v3"
        }
      ],
      "title": "Solving a Stackelberg Game on Transportation Networks in a Dynamic Crime Scenario: A Mixed Approach on Multi-Layer Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.14514",
        "HTML": "https://arxiv.org/html/2406.14514v3",
        "PDF": "https://arxiv.org/pdf/2406.14514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with solving a Stackelberg game on transportation networks. It does not address LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.05765",
      "abstract": "Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst their increasing ubiquity and influence is a major concern the world over. The use of formal methods in AI ethics is a possible crucial approach for specifying and verifying the ethical behavior of AI systems. This paper proposes a formalization based on deontic logic to define and evaluate the ethical behavior of AI systems, focusing on system-level specifications, contributing to this important goal. It introduces axioms and theorems to capture ethical requirements related to fairness and explainability. The formalization incorporates temporal operators to reason about the ethical behavior of AI systems over time. The authors evaluate the effectiveness of this formalization by assessing the ethics of the real-world COMPAS and loan prediction AI systems. Various ethical properties of the COMPAS and loan prediction systems are encoded using deontic logical formulas, allowing the use of an automated theorem prover to verify whether these systems satisfy the defined properties. The formal verification reveals that both systems fail to fulfill certain key ethical properties related to fairness and non-discrimination, demonstrating the effectiveness of the proposed formalization in identifying potential ethical issues in real-world AI applications.",
      "authors": [
        "Priya T.V. and Shrisha Rao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T07:48:40+00:00",
          "link": "https://arxiv.org/abs/2501.05765v1",
          "size": "92kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T16:47:37+00:00",
          "link": "https://arxiv.org/abs/2501.05765v2",
          "size": "101kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T13:57:48+00:00",
          "link": "https://arxiv.org/abs/2501.05765v3",
          "size": "120kb",
          "version": "v3"
        }
      ],
      "title": "Deontic Temporal Logic for Formal Verification of AI Ethics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05765",
        "HTML": "https://arxiv.org/html/2501.05765v3",
        "PDF": "https://arxiv.org/pdf/2501.05765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on formal verification of AI ethics using logic systems. It does not involve any LLM training data processing or creation methodologies."
      },
      "tasks": [
        "Ethics",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07413",
      "abstract": "This paper presents a novel approach to intrusion detection by integrating traditional signature-based methods with the contextual understanding capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become increasingly sophisticated, particularly in distributed, heterogeneous, and resource-constrained environments such as those enabled by the Internet of Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems (IDSs) becomes increasingly urgent. While traditional methods remain effective for detecting known threats, they often fail to recognize new and evolving attack patterns. In contrast, GPT-2 excels at processing unstructured data and identifying complex semantic relationships, making it well-suited to uncovering subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges the robustness of signature-based techniques with the adaptability of GPT-2-driven semantic analysis. Experimental evaluations on a representative intrusion dataset demonstrate that our model enhances detection accuracy by 6.3%, reduces false positives by 9.0%, and maintains near real-time responsiveness. These results affirm the potential of language model integration to build intelligent, scalable, and resilient cybersecurity defences suited for modern connected environments.",
      "authors": [
        "Mohammad F. Al-Hammouri",
        "Yazan Otoum",
        "Rasha Atwa",
        "Amiya Nayak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.07413v1",
          "size": "345kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07413",
        "HTML": "https://arxiv.org/html/2507.07413v1",
        "PDF": "https://arxiv.org/pdf/2507.07413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating GPT-2 for intrusion detection in IoT networks and does not discuss training data processing or data engineering for LLM."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07984",
      "abstract": "Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is: https://rbler1234.github.io/OSTBench.github.io/",
      "authors": [
        "JingLi Lin",
        "Chenming Zhu",
        "Runsen Xu",
        "Xiaohan Mao",
        "Xihui Liu",
        "Tai Wang",
        "Jiangmiao Pang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:56:07+00:00",
          "link": "https://arxiv.org/abs/2507.07984v1",
          "size": "26428kb",
          "version": "v1"
        }
      ],
      "title": "OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07984",
        "HTML": "https://arxiv.org/html/2507.07984v1",
        "PDF": "https://arxiv.org/pdf/2507.07984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "OST-Bench is a benchmark for evaluating multimodal models but does not involve any actual processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.12965",
      "abstract": "This paper presents a spline-based hexahedral mesh generator for tubular geometries commonly encountered in haemodynamics studies, in particular coronary arteries. We focus on techniques for accurately meshing vessels with stenoses and aneurysms, as well as non-planar bifurcations. Our approach incorporates several innovations, including a spline-based description of the vessel geometry in both the radial and the longitudinal directions, the use of Hermite curves for modeling non-planar bifurcations, and a generalization to non-planar n intersecting branches. This method eliminates the need for a concrete vessel surface, grid smoothing, and other post-processing. A technique to generate grids with boundary layers is also presented. We validate the generated meshes using commonly employed quality indices, compare them against state-of-the-art mesh generators and apply our method to complex coronary trees. Finally, we present finite element fluid flow simulations with physiological boundary conditions. To validate the proposed framework, a wall-shear-stress-based convergence test and computations of haemodynamic indices are also presented.",
      "authors": [
        "Fabio Marcinn\\'o",
        "Jochen Hinz",
        "Annalisa Buffa",
        "Simone Deparis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T15:43:29+00:00",
          "link": "https://arxiv.org/abs/2501.12965v1",
          "size": "41381kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:58:10+00:00",
          "link": "https://arxiv.org/abs/2501.12965v2",
          "size": "32829kb",
          "version": "v2"
        }
      ],
      "title": "A spline-based hexahedral mesh generator for patient-specific coronary arteries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12965",
        "HTML": "https://arxiv.org/html/2501.12965v2",
        "PDF": "https://arxiv.org/pdf/2501.12965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mesh generation for haemodynamics studies in coronary arteries, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07007",
      "abstract": "We consider the problem of decomposing a piecewise constant function on the circle into a sum of indicator functions of closed circular disks in the plane, whose number and location are not a priori known. This represents a situation where an agent moving on the circle is able to sense its proximity to some landmarks, and the goal is to estimate the number of these landmarks and their possible locations -- which can in turn enable control tasks such as motion planning and obstacle avoidance. Moreover, the exact values of the function at its discontinuities (which correspond to disk boundaries for the individual indicator functions) are not assumed to be known to the agent. We introduce suitable notions of robustness and degrees of freedom to single out those decompositions that are more desirable, or more likely, given this non-precise data collected by the agent. We provide a characterization of robust decompositions and give a procedure for generating all such decompositions. When the given function admits a robust decomposition, we compute the number of possible robust decompositions and derive bounds for the number of decompositions maximizing the degrees of freedom.",
      "authors": [
        "Aral Kose",
        "Daniel Liberzon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:36:03+00:00",
          "link": "https://arxiv.org/abs/2507.07007v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "Robust signal decompositions on the circle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07007",
        "HTML": "https://arxiv.org/html/2507.07007v1",
        "PDF": "https://arxiv.org/pdf/2507.07007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses signal decompositions on the circle, focusing on estimating landmarks based on non-precise data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07381",
      "abstract": "Precise Event Spotting (PES) in sports videos requires frame-level recognition of fine-grained actions from single-camera footage. Existing PES models typically incorporate lightweight temporal modules such as Gate Shift Module (GSM) or Gate Shift Fuse (GSF) to enrich 2D CNN feature extractors with temporal context. However, these modules are limited in both temporal receptive field and spatial adaptability. We propose a Multi-Scale Attention Gate Shift Module (MSAGSM) that enhances GSM with multi-scale temporal dilations and multi-head spatial attention, enabling efficient modeling of both short- and long-term dependencies while focusing on salient regions. MSAGSM is a lightweight plug-and-play module that can be easily integrated with various 2D backbones. To further advance the field, we introduce the Table Tennis Australia (TTA) dataset-the first PES benchmark for table tennis-containing over 4800 precisely annotated events. Extensive experiments across five PES benchmarks demonstrate that MSAGSM consistently improves performance with minimal overhead, setting new state-of-the-art results.",
      "authors": [
        "Hao Xu",
        "Arbind Agrahari Baniya",
        "Sam Wells",
        "Mohamed Reda Bouadjenek",
        "Richard Dazeley",
        "Sunil Aryal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:30:07+00:00",
          "link": "https://arxiv.org/abs/2507.07381v1",
          "size": "1320kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07381",
        "HTML": "https://arxiv.org/html/2507.07381v1",
        "PDF": "https://arxiv.org/pdf/2507.07381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the Table Tennis Australia (TTA) dataset with detailed annotation steps, contributing to the creation of a new dataset for precise event spotting in videos. The contribution largely revolves around dataset development and processing for video event detection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07483",
      "abstract": "With the rise of social media, vast amounts of user-uploaded videos (e.g., YouTube) are utilized as training data for Visual Object Tracking (VOT). However, the VOT community has largely overlooked video data-privacy issues, as many private videos have been collected and used for training commercial models without authorization. To alleviate these issues, this paper presents the first investigation on preventing personal video data from unauthorized exploitation by deep trackers. Existing methods for preventing unauthorized data use primarily focus on image-based tasks (e.g., image classification), directly applying them to videos reveals several limitations, including inefficiency, limited effectiveness, and poor generalizability. To address these issues, we propose a novel generative framework for generating Temporal Unlearnable Examples (TUEs), and whose efficient computation makes it scalable for usage on large-scale video datasets. The trackers trained w/ TUEs heavily rely on unlearnable noises for temporal matching, ignoring the original data structure and thus ensuring training video data-privacy. To enhance the effectiveness of TUEs, we introduce a temporal contrastive loss, which further corrupts the learning of existing trackers when using our TUEs for training. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in video data-privacy protection, with strong transferability across VOT models, datasets, and temporal matching tasks.",
      "authors": [
        "Qiangqiang Wu",
        "Yi Yu",
        "Chenqi Kong",
        "Ziquan Liu",
        "Jia Wan",
        "Haoliang Li",
        "Alex C. Kot",
        "Antoni B. Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:11:33+00:00",
          "link": "https://arxiv.org/abs/2507.07483v1",
          "size": "12302kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07483",
        "HTML": "https://arxiv.org/html/2507.07483v1",
        "PDF": "https://arxiv.org/pdf/2507.07483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates methods to prevent unauthorized exploitation of personal video data, which is indirectly related to data processing but not specific to LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07757",
      "abstract": "Quality control in additive manufacturing (AM) is vital for industrial applications in areas such as the automotive, medical and aerospace sectors. Geometric inaccuracies caused by shrinkage and deformations can compromise the life and performance of additively manufactured components. Such deviations can be quantified using Digital Volume Correlation (DVC), which compares the computer-aided design (CAD) model with the X-ray Computed Tomography (XCT) geometry of the components produced. However, accurate registration between the two modalities is challenging due to the absence of a ground truth or reference deformation field. In addition, the extremely large data size of high-resolution XCT volumes makes computation difficult. In this work, we present a deep learning-based approach for estimating voxel-wise deformations between CAD and XCT volumes. Our method uses a dynamic patch-based processing strategy to handle high-resolution volumes. In addition to the Dice Score, we introduce a Binary Difference Map (BDM) that quantifies voxel-wise mismatches between binarized CAD and XCT volumes to evaluate the accuracy of the registration. Our approach shows a 9.2\\% improvement in the Dice Score and a 9.9\\% improvement in the voxel match rate compared to classic DVC methods, while reducing the interaction time from days to minutes. This work sets the foundation for deep learning-based DVC methods to generate compensation meshes that can then be used in closed-loop correlations during the AM production process. Such a system would be of great interest to industries since the manufacturing process will become more reliable and efficient, saving time and material.",
      "authors": [
        "Keerthana Chand",
        "Tobias Fritsch",
        "Bardia Hejazi",
        "Konstantin Poka",
        "Giovanni Bruno"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:34:33+00:00",
          "link": "https://arxiv.org/abs/2507.07757v1",
          "size": "2203kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning based 3D Volume Correlation for Additive Manufacturing Using High-Resolution Industrial X-ray Computed Tomography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07757",
        "HTML": "https://arxiv.org/html/2507.07757v1",
        "PDF": "https://arxiv.org/pdf/2507.07757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on deep learning methods for quality control in additive manufacturing and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1602.03104",
      "abstract": "We consider the problem of configuration formation in modular robot systems where a set of modules that are initially in different configurations and located at different locations are required to assume appropriate positions so that they can get into a new, user-specified, target configuration. We propose a novel algorithm based on graph isomorphism, where the modules select locations or spots in the target configuration using a utility-based framework, while retaining their original configuration to the greatest extent possible, to reduce the time and energy required by the modules to assume the target configuration. We have shown analytically that our proposed algorithm is complete and guarantees a Pareto-optimal allocation. Experimental simulations of our algorithm with different number of modules in different initial configurations and located initially at different locations, show that the planning time of our algorithm is nominal (order of msec. for 100 modules). We have also compared our algorithm against a market-based allocation algorithm and shown that our proposed algorithm performs better in terms of time and number of messages exchanged.",
      "authors": [
        "Ayan Dutta",
        "Prithviraj Dasgupta",
        "Carl Nelson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2016-02-09T18:06:25+00:00",
          "link": "https://arxiv.org/abs/1602.03104v1",
          "size": "8616kb",
          "version": "v1"
        }
      ],
      "title": "A Graph Isomorphism-based Decentralized Algorithm for Modular Robot Configuration Formation",
      "links": {
        "Abstract": "https://arxiv.org/abs/1602.03104",
        "PDF": "https://arxiv.org/pdf/1602.03104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an algorithm for modular robot configuration formation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.01364",
      "abstract": "Semantic Retrieval (SR) has become an indispensable part of the FAQ system in the task-oriented question-answering (QA) dialogue scenario. The demands for a cross-lingual smart-customer-service system for an e-commerce platform or some particular business conditions have been increasing recently. Most previous studies exploit cross-lingual pre-trained models (PTMs) for multi-lingual knowledge retrieval directly, while some others also leverage the continual pre-training before fine-tuning PTMs on the downstream tasks. However, no matter which schema is used, the previous work ignores to inform PTMs of some features of the downstream task, i.e. train their PTMs without providing any signals related to SR. To this end, in this work, we propose an Alternative Cross-lingual PTM for SR via code-switching. We are the first to utilize the code-switching approach for cross-lingual SR. Besides, we introduce the novel code-switched continual pre-training instead of directly using the PTMs on the SR tasks. The experimental results show that our proposed approach consistently outperforms the previous SOTA methods on SR and semantic textual similarity (STS) tasks with three business corpora and four open datasets in 20+ languages.",
      "authors": [
        "Mieradilijiang Maimaiti",
        "Yuanhang Zheng",
        "Ji Zhang",
        "Yue Zhang",
        "Wenpei Luo",
        "Kaiyu Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-03T01:47:52+00:00",
          "link": "https://arxiv.org/abs/2403.01364v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:55:50+00:00",
          "link": "https://arxiv.org/abs/2403.01364v2",
          "size": "372kb",
          "version": "v2"
        }
      ],
      "title": "Improving Cross-lingual Representation for Semantic Retrieval with Code-switching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.01364",
        "HTML": "https://arxiv.org/html/2403.01364v2",
        "PDF": "https://arxiv.org/pdf/2403.01364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving cross-lingual representation for semantic retrieval using code-switching, not on processing LLM training data."
      },
      "tasks": [
        "Question Answering",
        "Retrieval",
        "Semantic Retrieval",
        "Semantic Textual Similarity",
        "STS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07238",
      "abstract": "The work involved in gathering, wrangling, cleaning, and otherwise preparing data for analysis is often the most time consuming and tedious aspect of data work. Although many studies describe data preparation within the context of data science workflows, there has been little research on data preparation in data journalism. We address this gap with a hybrid form of thematic analysis that combines deductive codes derived from existing accounts of data science workflows and inductive codes arising from an interview study with 36 professional data journalists. We extend a previous model of data science work to incorporate detailed activities of data preparation. We synthesize 60 dirty data issues from 16 taxonomies on dirty data and our interview data, and we provide a novel taxonomy to characterize these dirty data issues as discrepancies between mental models. We also identify four challenges faced by journalists: diachronic, regional, fragmented, and disparate data sources.",
      "authors": [
        "Stephen Kasica",
        "Charles Berret",
        "and Tamara Munzner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.07238v1",
          "size": "1104kb",
          "version": "v1"
        }
      ],
      "title": "Dirty Data in the Newsroom: Comparing Data Preparation in Journalism and Data Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07238",
        "HTML": "https://arxiv.org/html/2507.07238v1",
        "PDF": "https://arxiv.org/pdf/2507.07238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores data preparation in journalism, providing a taxonomy of dirty data issues, but it does not specifically address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.13268",
      "abstract": "Graph Neural Networks (GNNs) have shown promising performance, but at the cost of resource-intensive operations on graph-scale matrices. To reduce computational overhead, previous studies attempt to sparsify the graph or network parameters, but with limited flexibility and precision boundaries. In this work, we propose Unifews, a joint sparsification technique to unify graph and weight matrix operations and enhance GNN learning efficiency. The Unifews design enables adaptive compression across GNN layers with progressively increased sparsity, and is applicable to a variety of architectures with on-the-fly simplification. Theoretically, we establish a novel framework to characterize sparsified GNN learning in view of the graph optimization process, showing that Unifews effectively approximates the learning objective with bounded error and reduced computational overhead. Extensive experiments demonstrate that Unifews achieves efficiency improvements with comparable or better accuracy, including 10-20x matrix operation reduction and up to 100x acceleration on graphs up to billion-edge scale.",
      "authors": [
        "Ningyi Liao and Zihao Yu and Ruixiao Zeng and Siqiang Luo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-20T03:07:30+00:00",
          "link": "https://arxiv.org/abs/2403.13268v1",
          "size": "3966kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:43:15+00:00",
          "link": "https://arxiv.org/abs/2403.13268v2",
          "size": "3757kb",
          "version": "v2"
        }
      ],
      "title": "Unifews: You Need Fewer Operations for Efficient Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13268",
        "HTML": "https://arxiv.org/html/2403.13268v2",
        "PDF": "https://arxiv.org/pdf/2403.13268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a sparsification technique for Graph Neural Networks operation efficiency, but does not involve LLM training data processing."
      },
      "tasks": [
        "Graph Learning",
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.15245",
      "abstract": "As a cornerstone in language modeling, tokenization involves segmenting text inputs into pre-defined atomic units. Conventional statistical tokenizers often disrupt constituent boundaries within words, thereby corrupting semantic information. To address this drawback, we introduce morphological structure guidance to tokenization and propose a deep model to induce character-level structures of words. Specifically, the deep model jointly encodes internal structures and representations of words with a mechanism named $\\textit{MorphOverriding}$ to ensure the indecomposability of morphemes. By training the model with self-supervised objectives, our method is capable of inducing character-level structures that align with morphological rules without annotated training data. Based on the induced structures, our algorithm tokenizes words through vocabulary matching in a top-down manner. Empirical results indicate that the proposed method effectively retains complete morphemes and outperforms widely adopted methods such as BPE and WordPiece on both morphological segmentation tasks and language modeling tasks. Code is available at https://github.com/martianmartina/TreeTokenizer.",
      "authors": [
        "Qingyang Zhu",
        "Xiang Hu",
        "Pengyu Ji",
        "Wei Wu",
        "Kewei Tu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-21T15:35:49+00:00",
          "link": "https://arxiv.org/abs/2406.15245v1",
          "size": "781kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:03:28+00:00",
          "link": "https://arxiv.org/abs/2406.15245v2",
          "size": "783kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Morphological Tree Tokenizer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15245",
        "HTML": "https://arxiv.org/html/2406.15245v2",
        "PDF": "https://arxiv.org/pdf/2406.15245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new tokenizer that enhances tokenization by preserving morphological structures in words, contributing to improved LLM training data processing through better tokenization methods."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07508",
      "abstract": "The Pandora's box problem (Weitzman 1979) is a core model in economic theory that captures an agent's (Pandora's) search for the best alternative (box). We study an important generalization of the problem where the agent can either fully open boxes for a certain fee to reveal their exact values or partially open them at a reduced cost. This introduces a new tradeoff between information acquisition and cost efficiency. We establish a hardness result and employ an array of techniques in stochastic optimization to provide a comprehensive analysis of this model. This includes (1) the identification of structural properties of the optimal policy that provide insights about optimal decisions; (2) the derivation of problem relaxations and provably near-optimal solutions; (3) the characterization of the optimal policy in special yet non-trivial cases; and (4) an extensive numerical study that compares the performance of various policies, and which provides additional insights about the optimal policy. Throughout, we show that intuitive threshold-based policies that extend the Pandora's box optimal solution can effectively guide search decisions.",
      "authors": [
        "Ali Aouad",
        "Jingwei Ji",
        "Yaron Shaposhnik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:52:59+00:00",
          "link": "https://arxiv.org/abs/2507.07508v1",
          "size": "5816kb",
          "version": "v1"
        }
      ],
      "title": "The Pandora's Box Problem with Sequential Inspections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07508",
        "HTML": "https://arxiv.org/html/2507.07508v1",
        "PDF": "https://arxiv.org/pdf/2507.07508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on economic theory and decision-making within the Pandora's box problem, using stochastic optimization techniques, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07841",
      "abstract": "Events such as catastrophes and disasters are, in most cases, unpredictable. Consequently, reusing existing infrastructures to develop alternative communication strategies after disasters is essential to minimise the impact of these events on the population's ability to communicate and promptly receive alerts from authorities. In this context, the emergence of smart cities, characterised by dense and geographically distributed IoT networks, presents significant potential for such reuse. This work proposes HaLert, a resilient architecture for smart cities based on a Wi-Fi HaLow IEEE 802.11s mesh network, whose resources can be readily reallocated to support a emergency communication system to exchange messages (including text, location, image, audio, and video) between citizens, authorities, and between both parties. To facilitate remote monitoring and configuration of the network, the architecture incorporates the SDN (Software-Defined Networking) paradigm, supported by a LoRa controlled flooding mesh network. A prototype was developed based on this architecture and tested in a real urban scenario comprising both indoor and outdoor environments. The results demonstrated that, despite the significant impact of obstacles, lack of line-of-sight, and terrain slopes on the latency (average latency between 15 and 54.8 ms) and throughput (upload bitrates between 134 and 726 Kbps and download bitrates between 117 and 682 Kbps) of the Wi-Fi HaLow network, it remained stable and resilient, successfully providing all functionalities associated with the HaLert architecture. The tests conducted on the LoRa network revealed a high average message success rate of 94.96%.",
      "authors": [
        "Ana Rita Ortigoso",
        "Gabriel Vieira",
        "Daniel Fuentes",
        "Lu\\'is Fraz\\~ao",
        "Nuno Costa",
        "Ant\\'onio Pereira"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Computers and Society (cs.CY)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.07841v1",
          "size": "12554kb",
          "version": "v1"
        }
      ],
      "title": "HaLert: A Resilient Smart City Architecture for Post-Disaster Based on Wi-Fi HaLow Mesh and SDN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07841",
        "HTML": "https://arxiv.org/html/2507.07841v1",
        "PDF": "https://arxiv.org/pdf/2507.07841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with a smart city architecture for post-disaster communication based on Wi-Fi HaLow and SDN technologies, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07975",
      "abstract": "The induced matching width of a tree decomposition of a graph $G$ is the cardinality of a largest induced matching $M$ of $G$, such that there exists a bag that intersects every edge in $M$. The induced matching treewidth of a graph $G$, denoted by $\\mathsf{tree-}\\mu(G)$, is the minimum induced matching width of a tree decomposition of $G$. The parameter $\\mathsf{tree-}\\mu$ was introduced by Yolov [SODA '18], who showed that, for example, Maximum-Weight Independent Set can be solved in polynomial-time on graphs of bounded $\\mathsf{tree-}\\mu$. Lima, Milani\\v{c}, Mur\\v{s}i\\v{c}, Okrasa, Rz\\k{a}\\.zewski, and \\v{S}torgel [ESA '24] conjectured that this algorithm can be generalized to a meta-problem called Maximum-Weight Induced Subgraph of Bounded Treewidth, where we are given a vertex-weighted graph $G$, an integer $w$, and a $\\mathsf{CMSO}_2$-sentence $\\Phi$, and are asked to find a maximum-weight set $X \\subseteq V(G)$ so that $G[X]$ has treewidth at most $w$ and satisfies $\\Phi$. They proved the conjecture for some special cases, such as for the problem Maximum-Weight Induced Forest.\n  In this paper, we prove the general case of the conjecture. In particular, we show that Maximum-Weight Induced Subgraph of Bounded Treewidth is polynomial-time solvable when $\\mathsf{tree-}\\mu(G)$, $w$, and $|\\Phi|$ are bounded. The running time of our algorithm for $n$-vertex graphs $G$ with $\\mathsf{tree} - \\mu(G) \\le k$ is $f(k, w, |\\Phi|) \\cdot n^{O(k w^2)}$ for a computable function $f$.",
      "authors": [
        "Hans L. Bodlaender",
        "Fedor V. Fomin",
        "Tuukka Korhonen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:52:15+00:00",
          "link": "https://arxiv.org/abs/2507.07975v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Finding sparse induced subgraphs on graphs of bounded induced matching treewidth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07975",
        "HTML": "https://arxiv.org/html/2507.07975v1",
        "PDF": "https://arxiv.org/pdf/2507.07975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around graph theory and algorithm design for solving certain problems on graphs, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07980",
      "abstract": "Robots can better interact with humans and unstructured environments through touch sensing. However, most commercial robots are not equipped with tactile skins, making it challenging to achieve even basic touch-sensing functions, such as contact localization. We present UniTac, a data-driven whole-body touch-sensing approach that uses only proprioceptive joint sensors and does not require the installation of additional sensors. Our approach enables a robot equipped solely with joint sensors to localize contacts. Our goal is to democratize touch sensing and provide an off-the-shelf tool for HRI researchers to provide their robots with touch-sensing capabilities. We validate our approach on two platforms: the Franka robot arm and the Spot quadruped. On Franka, we can localize contact to within 8.0 centimeters, and on Spot, we can localize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU without adding any additional sensors to the robot. Project website: https://ivl.cs.brown.edu/research/unitac.",
      "authors": [
        "Wanjia Fu",
        "Hongyu Li",
        "Ivy X. He",
        "Stefanie Tellex",
        "Srinath Sridhar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.07980v1",
          "size": "4156kb",
          "version": "v1"
        }
      ],
      "title": "UniTac: Whole-Robot Touch Sensing Without Tactile Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07980",
        "HTML": "https://arxiv.org/html/2507.07980v1",
        "PDF": "https://arxiv.org/pdf/2507.07980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on touch sensing for robots using proprioceptive joint sensors, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1905.09226",
      "abstract": "In material science, image segmentation is of great significance for quantitative analysis of microstructures. Here, we propose a novel Weighted Propagation Convolution Neural Network based on U-Net (WPU-Net) to detect boundary in poly-crystalline microscopic images. We introduce spatial consistency into network to eliminate the defects in raw microscopic image. And we customize adaptive boundary weight for each pixel in each grain, so that it leads the network to preserve grain's geometric and topological characteristics. Moreover, we provide our dataset with the goal of advancing the development of image processing in materials science. Experiments demonstrate that the proposed method achieves promising performance in both of objective and subjective assessment. In boundary detection task, it reduces the error rate by 7\\%, which outperforms state-of-the-art methods by a large margin.",
      "authors": [
        "Wei Liu",
        "Jiahao Chen",
        "Chuni Liu",
        "Xiaojuan Ban",
        "Boyuan Ma",
        "Hao Wang",
        "Weihua Xue",
        "Yu Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2019-05-22T16:23:23+00:00",
          "link": "https://arxiv.org/abs/1905.09226v1",
          "size": "3675kb",
          "version": "v1"
        },
        {
          "date": "2019-08-30T15:52:09+00:00",
          "link": "https://arxiv.org/abs/1905.09226v2",
          "size": "3773kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T03:33:27+00:00",
          "link": "https://arxiv.org/abs/1905.09226v3",
          "size": "3169kb",
          "version": "v3"
        }
      ],
      "title": "Boundary Learning by Using Weighted Propagation in Convolution Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/1905.09226",
        "HTML": "https://arxiv.org/html/1905.09226v3",
        "PDF": "https://arxiv.org/pdf/1905.09226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a novel method for image segmentation and provides a dataset but is primarily focused on materials science and image processing, not LLM training data."
      },
      "tasks": [
        "Boundary Detection",
        "Object Tracking"
      ],
      "repo_urls": [
        "https://github.com/lurenhaothu/CWMI",
        "https://github.com/clovermini/WPU-Net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.06687",
      "abstract": "In this work, we survey recent studies on masked image modeling (MIM), an approach that emerged as a powerful self-supervised learning technique in computer vision. The MIM task involves masking some information, e.g. pixels, patches, or even latent representations, and training a model, usually an autoencoder, to predicting the missing information by using the context available in the visible part of the input. We identify and formalize two categories of approaches on how to implement MIM as a pretext task, one based on reconstruction and one based on contrastive learning. Then, we construct a taxonomy and review the most prominent papers in recent years. We complement the manually constructed taxonomy with a dendrogram obtained by applying a hierarchical clustering algorithm. We further identify relevant clusters via manually inspecting the resulting dendrogram. Our review also includes datasets that are commonly used in MIM research. We aggregate the performance results of various masked image modeling methods on the most popular datasets, to facilitate the comparison of competing methods. Finally, we identify research gaps and propose several interesting directions of future work. We supplement our survey with the following public repository containing organized references: https://github.com/vladhondru25/MIM-Survey.",
      "authors": [
        "Vlad Hondru",
        "Florinel Alin Croitoru",
        "Shervin Minaee",
        "Radu Tudor Ionescu",
        "Nicu Sebe"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T07:27:02+00:00",
          "link": "https://arxiv.org/abs/2408.06687v1",
          "size": "15530kb",
          "version": "v1"
        },
        {
          "date": "2025-01-09T22:14:55+00:00",
          "link": "https://arxiv.org/abs/2408.06687v2",
          "size": "16509kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:14:55+00:00",
          "link": "https://arxiv.org/abs/2408.06687v3",
          "size": "15337kb",
          "version": "v3"
        }
      ],
      "title": "Masked Image Modeling: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06687",
        "HTML": "https://arxiv.org/html/2408.06687v3",
        "PDF": "https://arxiv.org/pdf/2408.06687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The survey on masked image modeling discusses datasets commonly used in the field, but the focus is on the technique itself rather than data processing for LLMs."
      },
      "tasks": [
        "Contrastive Learning",
        "Self-Supervised Learning",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/vladhondru25/mim-survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05411",
      "abstract": "We design and implement AXLearn, a production deep learning system that facilitates scalable and high-performance training of large deep learning models. Compared to other state-of-the-art deep learning systems, AXLearn has a unique focus on modularity and support for heterogeneous hardware infrastructure. AXLearn's internal interfaces between software components follow strict encapsulation, allowing different components to be assembled to facilitate rapid model development and experimentation on heterogeneous compute infrastructure. We introduce a novel method of quantifying modularity via Lines-of-Code (LoC)-complexity, which demonstrates how our system maintains constant complexity as we scale the components in the system, compared to linear or quadratic complexity in other systems. This allows integrating features such as Rotary Position Embeddings (RoPE) into AXLearn across hundred of modules with just 10 lines of code, compared to hundreds as required in other systems. At the same time, AXLearn maintains equivalent performance compared to state-of-the-art training systems. Finally, we share our experience in the development and operation of AXLearn.",
      "authors": [
        "Mark Lee",
        "Tom Gunter",
        "Chang Lan",
        "John Peebles",
        "Hanzhi Zhou",
        "Kelvin Zou",
        "Sneha Bangalore",
        "Chung-Cheng Chiu",
        "Nan Du",
        "Xianzhi Du",
        "Philipp Dufter",
        "Ruixuan Hou",
        "Haoshuo Huang",
        "Dongseong Hwang",
        "Xiang Kong",
        "Jinhao Lei",
        "Tao Lei",
        "Meng Li",
        "Li Li",
        "Jiarui Lu",
        "Zhiyun Lu",
        "Yiping Ma",
        "David Qiu",
        "Vivek Rathod",
        "Senyu Tong",
        "Zhucheng Tu",
        "Jianyu Wang",
        "Yongqiang Wang",
        "Zirui Wang",
        "Floris Weers",
        "Sam Wiseman",
        "Guoli Yin",
        "Bowen Zhang",
        "Xiyou Zhou",
        "Danyang Zhuo",
        "Cheng Leong",
        "Ruoming Pang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:50:58+00:00",
          "link": "https://arxiv.org/abs/2507.05411v1",
          "size": "1429kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T20:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.05411v2",
          "size": "2845kb",
          "version": "v2"
        }
      ],
      "title": "AXLearn: Modular Large Model Training on Heterogeneous Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05411",
        "HTML": "https://arxiv.org/html/2507.05411v2",
        "PDF": "https://arxiv.org/pdf/2507.05411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "AXLearn is focused on modularity and heterogeneous infrastructure for model training. It addresses system design and modularity rather than the processing of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07439",
      "abstract": "In this paper, we investigate the distillation of time series reasoning capabilities into small, instruction-tuned language models as a step toward building interpretable time series foundation models. Leveraging a synthetic dataset of mean-reverting time series with systematically varied trends and noise levels, we generate natural language annotations using a large multimodal model and use these to supervise the fine-tuning of compact Qwen models. We introduce evaluation metrics that assess the quality of the distilled reasoning - focusing on trend direction, noise intensity, and extremum localization - and show that the post-trained models acquire meaningful interpretive capabilities. Our results highlight the feasibility of compressing time series understanding into lightweight, language-capable models suitable for on-device or privacy-sensitive deployment. This work contributes a concrete foundation toward developing small, interpretable models that explain temporal patterns in natural language.",
      "authors": [
        "Matthieu Boileau",
        "Philippe Helluy",
        "Jeremy Pawlus and Svitlana Vyetrenko"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:29:34+00:00",
          "link": "https://arxiv.org/abs/2507.07439v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Towards Interpretable Time Series Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07439",
        "HTML": "https://arxiv.org/html/2507.07439v1",
        "PDF": "https://arxiv.org/pdf/2507.07439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves generating synthetic datasets for a specific task (time series) but focuses primarily on model fine-tuning and capabilities rather than data processing as its main contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07535",
      "abstract": "Computing Power Network (CPN) unifies wide-area computing resources through coordinated network control, while cloud-native abstractions enable flexible resource orchestration and on-demand service provisioning atop the elastic infrastructure CPN provides. However, current approaches fall short of fully integrating computing resources via network-enabled coordination as envisioned by CPN. In particular, optimally mapping services to an underlying infrastructure to maximize resource efficiency and service satisfaction remains challenging. To overcome this challenge, we formally define the service mapping problem in CPN, establish its theoretical intractability, and identify key challenges in practical optimization. We propose Adaptive Bilevel Search (ABS), a modular framework featuring (1) graph partitioning-based reformulation to capture variable coupling, (2) a bilevel optimization architecture for efficient global exploration with local optimality guarantees, and (3) fragmentation-aware evaluation for global performance guidance. Implemented using distributed particle swarm optimization, ABS is extensively evaluated across diverse CPN scenarios, consistently outperforming existing approaches. Notably, in complex scenarios, ABS achieves up to 73.2% higher computing resource utilization and a 60.2% higher service acceptance ratio compared to the best-performing baseline.",
      "authors": [
        "Jingzhao Xie",
        "Zhenglian Li",
        "Gang Sun",
        "Long Luo",
        "Hongfang Yu",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:31:54+00:00",
          "link": "https://arxiv.org/abs/2507.07535v1",
          "size": "1352kb",
          "version": "v1"
        }
      ],
      "title": "A Fragmentation-Aware Adaptive Bilevel Search Framework for Service Mapping in Computing Power Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07535",
        "HTML": "https://arxiv.org/html/2507.07535v1",
        "PDF": "https://arxiv.org/pdf/2507.07535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses service mapping in computing power networks, focusing on optimization techniques, which is unrelated to LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07604",
      "abstract": "Synthetic molecular communication (SMC) is a key enabler for future healthcare systems in which Internet of Bio-Nano-Things (IoBNT) devices facilitate the continuous monitoring of a patient's biochemical signals. To close the loop between sensing and actuation, both the detection and the generation of in-body molecular communication (MC) signals is key. However, generating signals inside the human body, e.g., via synthetic nanodevices, poses a challenge in SMC, due to technological obstacles as well as legal, safety, and ethical issues. Hence, this paper considers an SMC system in which signals are generated indirectly via the modulation of a natural in-body MC system, namely the gut-brain axis (GBA). Therapeutic GBA modulation is already established as treatment for neurological diseases, e.g., drug refractory epilepsy (DRE), and performed via the administration of nutritional supplements or specific diets. However, the molecular signaling pathways that mediate the effect of such treatments are mostly unknown. Consequently, existing treatments are standardized or designed heuristically and able to help only some patients while failing to help others. In this paper, we propose to leverage personal health data, e.g., gathered by in-body IoBNT devices, to design more versatile and robust GBA modulation-based treatments as compared to the existing ones. To show the feasibility of our approach, we define a catalog of theoretical requirements for therapeutic GBA modulation. Then, we propose a machine learning model to verify these requirements for practical scenarios when only limited data on the GBA modulation exists. By evaluating the proposed model on several datasets, we confirm its excellent accuracy in identifying different modulators of the GBA. Finally, we utilize the proposed model to identify specific modulatory pathways that play an important role for therapeutic GBA modulation.",
      "authors": [
        "Sebastian Lotter",
        "Elisabeth Mohr",
        "Andrina Rutsch",
        "Lukas Brand",
        "Francesca Ronchi",
        "Laura D\\'iaz-Marug\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)",
        "Tissues and Organs (q-bio.TO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.07604v1",
          "size": "2394kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic MC via Biological Transmitters: Therapeutic Modulation of the Gut-Brain Axis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07604",
        "HTML": "https://arxiv.org/html/2507.07604v1",
        "PDF": "https://arxiv.org/pdf/2507.07604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses synthetic molecular communication system design for healthcare purposes, without any focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.14507",
      "abstract": "We consider the problem of parameter estimation in a high-dimensional generalized linear model. Spectral methods obtained via the principal eigenvector of a suitable data-dependent matrix provide a simple yet surprisingly effective solution. However, despite their wide use, a rigorous performance characterization, as well as a principled way to preprocess the data, are available only for unstructured (i.i.d.\\ Gaussian and Haar orthogonal) designs. In contrast, real-world data matrices are highly structured and exhibit non-trivial correlations. To address the problem, we consider correlated Gaussian designs capturing the anisotropic nature of the features via a covariance matrix $\\Sigma$. Our main result is a precise asymptotic characterization of the performance of spectral estimators. This allows us to identify the optimal preprocessing that minimizes the number of samples needed for parameter estimation. Surprisingly, such preprocessing is universal across a broad set of designs, which partly addresses a conjecture on optimal spectral estimators for rotationally invariant models. Our principled approach vastly improves upon previous heuristic methods, including for designs common in computational imaging and genetics. The proposed methodology, based on approximate message passing, is broadly applicable and opens the way to the precise characterization of spiked matrices and of the corresponding spectral methods in a variety of settings.",
      "authors": [
        "Yihan Zhang",
        "Hong Chang Ji",
        "Ramji Venkataramanan",
        "Marco Mondelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-28T11:49:23+00:00",
          "link": "https://arxiv.org/abs/2308.14507v1",
          "size": "1944kb",
          "version": "v1"
        },
        {
          "date": "2024-06-11T11:56:46+00:00",
          "link": "https://arxiv.org/abs/2308.14507v2",
          "size": "1418kb",
          "version": "v2"
        },
        {
          "date": "2024-07-03T11:43:58+00:00",
          "link": "https://arxiv.org/abs/2308.14507v3",
          "size": "1354kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T22:10:08+00:00",
          "link": "https://arxiv.org/abs/2308.14507v4",
          "size": "734kb",
          "version": "v4"
        }
      ],
      "title": "Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.14507",
        "PDF": "https://arxiv.org/pdf/2308.14507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses spectral estimators for parameter estimation in generalized linear models, focusing on preprocessing data but not specifically on LLM training data processing."
      },
      "tasks": [
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00570",
      "abstract": "Platooning or cooperative adaptive cruise control (CACC) has been investigated for decades, but debate about its lasting impact is still ongoing. While the benefits of platooning and the formation of platoons are well understood for trucks, they are less clear for passenger cars, which have a higher heterogeneity in trips and drivers' preferences. Most importantly, it remains unclear how to form platoons of passenger cars in order to optimize the personal benefit for the individual driver. To this end, in this paper, we propose a novel platoon formation algorithm that optimizes the personal benefit for drivers of individual passenger cars. For computing vehicle-to-platoon assignments, the algorithm utilizes a new metric that we propose to evaluate the personal benefits of various driving systems, including platooning. By combining fuel and travel time costs into a single monetary value, drivers can estimate overall trip costs according to a personal monetary value for time spent. This provides an intuitive way for drivers to understand and compare the benefits of driving systems like human driving, adaptive cruise control (ACC), and, of course, platooning. Unlike previous similarity-based methods, our proposed algorithm forms platoons only when beneficial for the driver, rather than solely for platooning. We demonstrate the new metric for the total trip cost in a numerical analysis and explain its interpretation. Results of a large-scale simulation study demonstrate that our proposed platoon formation algorithm outperforms normal ACC as well as previous similarity-based platooning approaches by balancing fuel savings and travel time, independent of traffic and drivers' time cost.",
      "authors": [
        "Julian Heinovski",
        "Do\\u{g}analp Ergen\\c{c}",
        "Kirsten Thommes",
        "Falko Dressler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T13:27:43+00:00",
          "link": "https://arxiv.org/abs/2411.00570v1",
          "size": "7030kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T14:34:57+00:00",
          "link": "https://arxiv.org/abs/2411.00570v2",
          "size": "7031kb",
          "version": "v2"
        },
        {
          "date": "2025-02-20T10:04:12+00:00",
          "link": "https://arxiv.org/abs/2411.00570v3",
          "size": "7031kb",
          "version": "v3"
        },
        {
          "date": "2025-06-09T19:03:14+00:00",
          "link": "https://arxiv.org/abs/2411.00570v4",
          "size": "7060kb",
          "version": "v4"
        },
        {
          "date": "2025-06-11T12:34:08+00:00",
          "link": "https://arxiv.org/abs/2411.00570v5",
          "size": "6993kb",
          "version": "v5"
        }
      ],
      "title": "Incentive-based Platoon Formation: Optimizing the Personal Benefit for Drivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00570",
        "PDF": "https://arxiv.org/pdf/2411.00570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing platoon formation for passenger cars using a novel algorithm, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07569",
      "abstract": "We describe an algorithmic method to transform a Euclidean wallpaper pattern into a Circle Limit-style picture \\`a la Escher. The design goals for the method are to be mathematically sound, aesthetically pleasing and fast to compute. It turns out that a certain class of conformal maps is particularly well-suited for the problem. Moreover, in our specific application, a very simple method, sometimes jokingly called the \"Neandertal Method\" for its almost brutal simplicity, proves to be highly efficient, as it can easily be parallelized to be run on the GPU, unlike many other approaches.",
      "authors": [
        "Aaron Montag",
        "Tim Reinhardt",
        "J\\\"urgen Richter-Gebert"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Computational Geometry (cs.CG)",
        "Combinatorics (math.CO)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.07569v1",
          "size": "13392kb",
          "version": "v1"
        }
      ],
      "title": "The Smooth Power of the \"Neandertal Method\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07569",
        "HTML": "https://arxiv.org/html/2507.07569v1",
        "PDF": "https://arxiv.org/pdf/2507.07569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for transforming Euclidean wallpaper patterns, which is unrelated to LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07997",
      "abstract": "Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental models that compress continuous visual data into discrete tokens. Existing methods have tried to improve the quantization strategy for better reconstruction quality, however, there still exists a large gap between VQ-VAEs and VAEs. To narrow this gap, we propose \\NickName, a novel method to augment the representation capability of discrete codebooks, facilitating easier optimization for codebooks and minimizing information loss, thereby enhancing reconstruction quality. Specifically, we propose to retain the latent dimension to preserve encoded features and incorporate a set of sub-codebooks for quantization. Furthermore, we construct comprehensive zero-shot benchmarks featuring resolutions of 512p and 2k to evaluate the reconstruction performance of existing methods rigorously. \\NickName~achieves the \\textbf{state-of-the-art performance on both ImageNet and $8$ zero-shot benchmarks} across all VQ-VAEs. Notably, compared with SD-VAE, we outperform them on ImageNet significantly, with rFID $\\textbf{0.49}$ v.s. $\\textbf{0.91}$, and achieve superior PSNR on all zero-shot benchmarks. These results highlight the superiority of \\NickName~in reconstruction and pave the way for preserving fidelity in HD image processing tasks. Code will be publicly available at https://github.com/MKJia/MGVQ.",
      "authors": [
        "Mingkai Jia",
        "Wei Yin",
        "Xiaotao Hu",
        "Jiaxin Guo",
        "Xiaoyang Guo",
        "Qian Zhang",
        "Xiao-Xiao Long",
        "Ping Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.07997v1",
          "size": "21607kb",
          "version": "v1"
        }
      ],
      "title": "MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07997",
        "HTML": "https://arxiv.org/html/2507.07997v1",
        "PDF": "https://arxiv.org/pdf/2507.07997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new quantization method (MGVQ) for VQ-VAEs, focusing on improving image reconstruction quality, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10281",
      "abstract": "Artificial Intelligence (AI) is reframed as a cognitive engine driving a novel productivity revolution distinct from the Industrial Revolution's physical thrust. This paper develops a theoretical framing of AI as a cognitive revolution akin to written language - a transformative augmentation of human intellect rather than another mechanized tool. We compare AI's emergence to historical leaps in information technology to show how it amplifies knowledge work. Examples from various domains demonstrate AI's impact as a driver of productivity in cognitive tasks. We adopt a multidisciplinary perspective combining computer science advances with economic insights and sociological perspectives on how AI reshapes work and society. Through conceptual frameworks, we visualize the shift from manual to cognitive productivity. Our central argument is that AI functions as an engine of cognition - comparable to how human language revolutionized knowledge - heralding a new productivity paradigm. We discuss how this revolution demands rethinking of skills, organizations, and policies. This paper, balancing academic rigor with clarity, concludes that AI's promise lies in complementing human cognitive abilities, marking a new chapter in productivity evolution.",
      "authors": [
        "Xinmin Fang",
        "Lingfeng Tao",
        "Zhengxiong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T01:43:54+00:00",
          "link": "https://arxiv.org/abs/2506.10281v1",
          "size": "296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:52:33+00:00",
          "link": "https://arxiv.org/abs/2506.10281v2",
          "size": "296kb",
          "version": "v2"
        }
      ],
      "title": "Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10281",
        "HTML": "https://arxiv.org/html/2506.10281v2",
        "PDF": "https://arxiv.org/pdf/2506.10281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper broadly discusses AI as a cognitive revolution, comparing it to historical advances in information technology, but does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.13201",
      "abstract": "Flooding remains a major global challenge, worsened by climate change and urbanization, demanding advanced solutions for effective disaster management. While traditional 2D flood mapping techniques provide limited insights, 3D flood mapping, powered by deep learning (DL), offers enhanced capabilities by integrating flood extent and depth. This paper presents a comprehensive survey of deep learning-based 3D flood mapping, emphasizing its advancements over 2D maps by integrating flood extent and depth for effective disaster management and urban planning. The survey categorizes deep learning techniques into task decomposition and end-to-end approaches, applicable to both static and dynamic flood features. We compare key DL architectures, highlighting their respective roles in enhancing prediction accuracy and computational efficiency. Additionally, this work explores diverse data sources such as digital elevation models, satellite imagery, rainfall, and simulated data, outlining their roles in 3D flood mapping. The applications reviewed range from real-time flood prediction to long-term urban planning and risk assessment. However, significant challenges persist, including data scarcity, model interpretability, and integration with traditional hydrodynamic models. This survey concludes by suggesting future directions to address these limitations, focusing on enhanced datasets, improved models, and policy implications for flood management. This survey aims to guide researchers and practitioners in leveraging DL techniques for more robust and reliable 3D flood mapping, fostering improved flood management strategies.",
      "authors": [
        "Wenfeng Jia",
        "Bin Liang",
        "Yuxi Liu",
        "Muhammad Arif Khan",
        "Lihong Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:06:18+00:00",
          "link": "https://arxiv.org/abs/2506.13201v1",
          "size": "1036kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13201",
        "HTML": "https://arxiv.org/html/2506.13201",
        "PDF": "https://arxiv.org/pdf/2506.13201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep learning techniques for 3D flood mapping using various data sources like digital elevation models and satellite imagery, without a focus on LLM training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Deep Learning",
        "Management",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07108",
      "abstract": "Multimodal Entity Linking (MEL) aims to link ambiguous mentions within multimodal contexts to associated entities in a multimodal knowledge base. Existing approaches to MEL introduce multimodal interaction and fusion mechanisms to bridge the modality gap and enable multi-grained semantic matching. However, they do not address two important problems: (i) mention ambiguity, i.e., the lack of semantic content caused by the brevity and omission of key information in the mention's textual context; (ii) dynamic selection of modal content, i.e., to dynamically distinguish the importance of different parts of modal information. To mitigate these issues, we propose a Multi-level Mixture of Experts (MMoE) model for MEL. MMoE has four components: (i) the description-aware mention enhancement module leverages large language models to identify the WikiData descriptions that best match a mention, considering the mention's textual context; (ii) the multimodal feature extraction module adopts multimodal feature encoders to obtain textual and visual embeddings for both mentions and entities; (iii)-(iv) the intra-level mixture of experts and inter-level mixture of experts modules apply a switch mixture of experts mechanism to dynamically and adaptively select features from relevant regions of information. Extensive experiments demonstrate the outstanding performance of MMoE compared to the state-of-the-art. MMoE's code is available at: https://github.com/zhiweihu1103/MEL-MMoE.",
      "authors": [
        "Zhiwei Hu",
        "V\\'ictor Guti\\'errez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T14:46:51+00:00",
          "link": "https://arxiv.org/abs/2507.07108v1",
          "size": "837kb",
          "version": "v1"
        }
      ],
      "title": "Multi-level Mixture of Experts for Multimodal Entity Linking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07108",
        "HTML": "https://arxiv.org/html/2507.07108v1",
        "PDF": "https://arxiv.org/pdf/2507.07108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves large language models for entity linking, it centers around multimodal interaction and feature extraction, lacking substantive focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07298",
      "abstract": "Unplanned power outages cost the US economy over $150 billion annually, partly due to predictive maintenance (PdM) models that overlook spatial, temporal, and causal dependencies in grid failures. This study introduces a multilayer Graph Neural Network (GNN) framework to enhance PdM and enable resilience-based substation clustering. Using seven years of incident data from Oklahoma Gas & Electric (292,830 records across 347 substations), the framework integrates Graph Attention Networks (spatial), Graph Convolutional Networks (temporal), and Graph Isomorphism Networks (causal), fused through attention-weighted embeddings. Our model achieves a 30-day F1-score of 0.8935 +/- 0.0258, outperforming XGBoost and Random Forest by 3.2% and 2.7%, and single-layer GNNs by 10 to 15 percent. Removing the causal layer drops performance to 0.7354 +/- 0.0418. For resilience analysis, HDBSCAN clustering on HierarchicalRiskGNN embeddings identifies eight operational risk groups. The highest-risk cluster (Cluster 5, 44 substations) shows 388.4 incidents/year and 602.6-minute recovery time, while low-risk groups report fewer than 62 incidents/year. ANOVA (p < 0.0001) confirms significant inter-cluster separation. Our clustering outperforms K-Means and Spectral Clustering with a Silhouette Score of 0.626 and Davies-Bouldin index of 0.527. This work supports proactive grid management through improved failure prediction and risk-aware substation clustering.",
      "authors": [
        "Muhammad Kazim",
        "Harun Pirim",
        "Chau Le",
        "Trung Le",
        "Om Prakash Yadav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:44:51+00:00",
          "link": "https://arxiv.org/abs/2507.07298v1",
          "size": "4158kb",
          "version": "v1"
        }
      ],
      "title": "Multilayer GNN for Predictive Maintenance and Clustering in Power Grids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07298",
        "HTML": "https://arxiv.org/html/2507.07298v1",
        "PDF": "https://arxiv.org/pdf/2507.07298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses predictive maintenance in power grids using GNNs and clustering techniques. It does not involve any processes related to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07437",
      "abstract": "The construction of Low Earth Orbit (LEO) satellite constellations has recently attracted tremendous attention from both academia and industry. The 5G and 6G standards have identified LEO satellite networks as a key component of future mobile networks. However, due to the high-speed movement of satellites, ground terminals often experience frequent and high-latency handovers, which significantly deteriorate the performance of latency-sensitive applications. To address this challenge, we propose a parallel handover mechanism for mobile satellite networks that can considerably reduce handover latency. The main idea is to employ plan-based handovers instead of measurement-based handovers to avoid interactions between the access and core networks, thereby eliminating the significant time overhead associated with traditional handover procedures. Specifically, we introduce a novel network function named the Satellite Synchronized Function (SSF), which is designed to be fully compliant with the standard 5G core network. In addition, we propose a machine learning model for signal strength prediction, coupled with an efficient handover scheduling algorithm. We have conducted extensive experiments, and the results demonstrate that our proposed handover scheme can reduce handover latency by 21\\times compared to the standard NTN handover scheme and two other existing handover approaches, along with significant improvements in network stability and user-level performance.",
      "authors": [
        "Jiasheng Wu",
        "Shaojie Su",
        "Wenjun Zhu",
        "Xiong Wang",
        "Jingjing Zhang",
        "Xingqiu He",
        "Yue Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:27:31+00:00",
          "link": "https://arxiv.org/abs/2507.07437v1",
          "size": "4141kb",
          "version": "v1"
        }
      ],
      "title": "PHandover: Parallel Handover in Mobile Satellite Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07437",
        "HTML": "https://arxiv.org/html/2507.07437v1",
        "PDF": "https://arxiv.org/pdf/2507.07437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on reducing handover latency in mobile satellite networks and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07517",
      "abstract": "YouTube has rapidly emerged as a predominant platform for content consumption, effectively displacing conventional media such as television and news outlets. A part of the enormous video stream uploaded to this platform includes health-related content, both from official public health organizations, and from any individual or group that can make an account. The quality of information available on YouTube is a critical point of public health safety, especially when concerning major interventions, such as vaccination. This study differentiates itself from previous efforts of auditing YouTube videos on this topic by conducting a systematic daily collection of posted videos mentioning vaccination for the duration of 3 months. We show that the competition for the public's attention is between public health messaging by institutions and individual educators on one side, and commentators on society and politics on the other, the latest contributing the most to the videos expressing stances against vaccination. Videos opposing vaccination are more likely to mention politicians and publication media such as podcasts, reports, and news analysis, on the other hand, videos in favor are more likely to mention specific diseases or health-related topics. Finally, we find that, at the time of analysis, only 2.7% of the videos have been taken down (by the platform or the channel), despite 20.8% of the collected videos having a vaccination hesitant stance, pointing to a lack of moderation activity for hesitant content. The availability of high-quality information is essential to improve awareness and compliance with public health interventions. Our findings help characterize the public discourse around vaccination on one of the largest media platforms, disentangling the role of the different creators and their stances, and as such, they provide important insights for public health communication policy.",
      "authors": [
        "Yelena Mejova and Michele Tizzani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:04:22+00:00",
          "link": "https://arxiv.org/abs/2507.07517v1",
          "size": "159kb",
          "version": "v1"
        }
      ],
      "title": "Vaccine Hesitancy on YouTube: a Competition between Health and Politics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07517",
        "HTML": "https://arxiv.org/html/2507.07517v1",
        "PDF": "https://arxiv.org/pdf/2507.07517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper involves systematic collection of vaccination videos on YouTube, it analyzes public discourse rather than technical aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06107",
      "abstract": "Modern high-performance computing (HPC) systems generate massive volumes of heterogeneous telemetry data from millions of sensors monitoring compute, memory, power, cooling, and storage subsystems. As HPC infrastructures scale to support increasingly complex workloads-including generative AI-the need for efficient, reliable, and interoperable telemetry analysis becomes critical. Operational Data Analytics (ODA) has emerged to address these demands; however, the reliance on schema-less storage solutions limits data accessibility and semantic integration. Ontologies and knowledge graphs (KG) provide an effective way to enable efficient and expressive data querying by capturing domain semantics, but they face challenges such as significant storage overhead and the limited applicability of existing ontologies, which are often tailored to specific HPC systems only. In this paper, we present the first unified ontology for ODA in HPC systems, designed to enable semantic interoperability across heterogeneous data centers. Our ontology models telemetry data from the two largest publicly available ODA datasets-M100 (Cineca, Italy) and F-DATA (Fugaku, Japan)-within a single data model. The ontology is validated through 36 competency questions reflecting real-world stakeholder requirements, and we introduce modeling optimizations that reduce knowledge graph (KG) storage overhead by up to 38.84% compared to a previous approach, with an additional 26.82% reduction depending on the desired deployment configuration. This work paves the way for scalable ODA KGs and supports not only analysis within individual systems, but also cross-system analysis across heterogeneous HPC systems.",
      "authors": [
        "Junaid Ahmed Khan and Andrea Bartolini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:47:39+00:00",
          "link": "https://arxiv.org/abs/2507.06107v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:39:16+00:00",
          "link": "https://arxiv.org/abs/2507.06107v2",
          "size": "193kb",
          "version": "v2"
        }
      ],
      "title": "A Unified Ontology for Scalable Knowledge Graph-Driven Operational Data Analytics in High-Performance Computing Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06107",
        "HTML": "https://arxiv.org/html/2507.06107v2",
        "PDF": "https://arxiv.org/pdf/2507.06107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a unified ontology for operational data analytics in HPC systems, which pertains to telemetry data, without mentioning LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07597",
      "abstract": "As quantum computing evolves from theoretical promise to practical deployment, the demand for robust, portable, and scalable tools for quantum software experimentation is growing. This paper introduces Quantum Executor, a backend-agnostic execution engine designed to orchestrate quantum experiments across heterogeneous platforms. Quantum Executor provides a declarative and modular interface that decouples experiment design from backend execution, enabling seamless interoperability and code reuse across diverse quantum and classical resources. Key features include support for asynchronous and distributed execution, customizable execution strategies and a unified API for managing quantum experiments. We illustrate its applicability through two life-like usage scenarios such as automated benchmarking and hybrid validation, discussing its capacity to streamline quantum development. We conclude by discussing current limitations and outlining a roadmap for future enhancements.",
      "authors": [
        "Giuseppe Bisicchia",
        "Alessandro Bocci",
        "Antonio Brogi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:55:32+00:00",
          "link": "https://arxiv.org/abs/2507.07597v1",
          "size": "1264kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Executor: A Unified Interface for Quantum Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07597",
        "HTML": "https://arxiv.org/html/2507.07597v1",
        "PDF": "https://arxiv.org/pdf/2507.07597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Quantum Executor is aimed at quantum computing experiments and does not involve processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07935",
      "abstract": "Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.",
      "authors": [
        "Kiran Tomlinson",
        "Sonia Jaffe",
        "Will Wang",
        "Scott Counts",
        "Siddharth Suri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:16:33+00:00",
          "link": "https://arxiv.org/abs/2507.07935v1",
          "size": "859kb",
          "version": "v1"
        }
      ],
      "title": "Working with AI: Measuring the Occupational Implications of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07935",
        "PDF": "https://arxiv.org/pdf/2507.07935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work measures the occupational implications of generative AI and does not discuss any technical contribution to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.04129",
      "abstract": "Recent works have shown that by using large pre-trained models along with learnable prompts, rehearsal-free methods for class-incremental learning (CIL) settings can achieve superior performance to prominent rehearsal-based ones. Rehearsal-free CIL methods struggle with distinguishing classes from different tasks, as those are not trained together. In this work we propose a regularization method based on virtual outliers to tighten decision boundaries of the classifier, such that confusion of classes among different tasks is mitigated. Recent prompt-based methods often require a pool of task-specific prompts, in order to prevent overwriting knowledge of previous tasks with that of the new task, leading to extra computation in querying and composing an appropriate prompt from the pool. This additional cost can be eliminated, without sacrificing accuracy, as we reveal in the paper. We illustrate that a simplified prompt-based method can achieve results comparable to previous state-of-the-art (SOTA) methods equipped with a prompt pool, using much less learnable parameters and lower inference cost. Our regularization method has demonstrated its compatibility with different prompt-based methods, boosting those previous SOTA rehearsal-free CIL methods' accuracy on the ImageNet-R and CIFAR-100 benchmarks. Our source code is available at https://github.com/jpmorganchase/ovor.",
      "authors": [
        "Wei-Cheng Huang",
        "Chun-Fu Chen",
        "Hsiang Hsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T16:31:11+00:00",
          "link": "https://arxiv.org/abs/2402.04129v1",
          "size": "2499kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:07:40+00:00",
          "link": "https://arxiv.org/abs/2402.04129v2",
          "size": "2499kb",
          "version": "v2"
        }
      ],
      "title": "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04129",
        "HTML": "https://arxiv.org/html/2402.04129v2",
        "PDF": "https://arxiv.org/pdf/2402.04129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rehearsal-free class-incremental learning using pre-trained models and virtual outlier regularization, without discussing LLM training data or processing."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Incremental Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01936",
      "abstract": "Large language models (LLMs) are excellent at maintaining high-level, convincing dialogues. They are being fast deployed as chatbots and evaluators in sensitive areas, such as peer review and mental health applications. This, along with the disparate accounts on their reasoning capabilities, calls for a closer examination of LLMs and their comprehension of dialogue. In this work we begin by evaluating LLMs' ability to maintain a debate--one of the purest yet most complex forms of human communication. Then we measure how this capability relates to their understanding of what is being talked about, namely, their comprehension of dialogical structures and the pragmatic context. We find that LLMs are capable of maintaining coherent, persuasive debates, often swaying the beliefs of participants and audiences alike. We also note that awareness or suspicion of AI involvement encourage people to be more critical of the arguments made. When polling LLMs on their comprehension of deeper structures of dialogue, however, they cannot demonstrate said understanding. Our findings tie the shortcomings of LLMs-as-evaluators to their (in)ability to understand the context. More broadly, for the field of argumentation theory we posit that, if an agent can convincingly maintain a dialogue, it is not necessary for it to know what it is talking about. Hence, the modelling of pragmatic context and coherence are secondary to effectiveness.",
      "authors": [
        "Adrian de Wynter and Tangming Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:46:56+00:00",
          "link": "https://arxiv.org/abs/2507.01936v1",
          "size": "1605kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:54:09+00:00",
          "link": "https://arxiv.org/abs/2507.01936v2",
          "size": "1607kb",
          "version": "v2"
        }
      ],
      "title": "The Thin Line Between Comprehension and Persuasion in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01936",
        "HTML": "https://arxiv.org/html/2507.01936v2",
        "PDF": "https://arxiv.org/pdf/2507.01936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines LLMs' capabilities in maintaining coherent dialogues and their comprehension, without discussing the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07148",
      "abstract": "Explainable artificial intelligence (XAI) has become increasingly important in biomedical image analysis to promote transparency, trust, and clinical adoption of DL models. While several surveys have reviewed XAI techniques, they often lack a modality-aware perspective, overlook recent advances in multimodal and vision-language paradigms, and provide limited practical guidance. This survey addresses this gap through a comprehensive and structured synthesis of XAI methods tailored to biomedical image analysis.We systematically categorize XAI methods, analyzing their underlying principles, strengths, and limitations within biomedical contexts. A modality-centered taxonomy is proposed to align XAI methods with specific imaging types, highlighting the distinct interpretability challenges across modalities. We further examine the emerging role of multimodal learning and vision-language models in explainable biomedical AI, a topic largely underexplored in previous work. Our contributions also include a summary of widely used evaluation metrics and open-source frameworks, along with a critical discussion of persistent challenges and future directions. This survey offers a timely and in-depth foundation for advancing interpretable DL in biomedical image analysis.",
      "authors": [
        "Getamesay Haile Dagnaw",
        "Yanming Zhu",
        "Muhammad Hassan Maqsood",
        "Wencheng Yang",
        "Xingshuai Dong",
        "Xuefei Yin",
        "Alan Wee-Chung Liew"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:42:14+00:00",
          "link": "https://arxiv.org/abs/2507.07148v1",
          "size": "950kb",
          "version": "v1"
        }
      ],
      "title": "Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07148",
        "HTML": "https://arxiv.org/html/2507.07148v1",
        "PDF": "https://arxiv.org/pdf/2507.07148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey covers XAI techniques in biomedical image analysis without addressing any LLM training data processing or data engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07149",
      "abstract": "Recent advancements in on-device training for deep neural networks have underscored the critical need for efficient activation compression to overcome the memory constraints of mobile and edge devices. As activations dominate memory usage during training and are essential for gradient computation, compressing them without compromising accuracy remains a key research challenge. While existing methods for dynamic activation quantization promise theoretical memory savings, their practical deployment is impeded by system-level challenges such as computational overhead and memory fragmentation.\n  To address these challenges, we introduce DAF, a Dynamic Activation Framework that enables scalable and efficient on-device training through system-level optimizations. DAF achieves both memory- and time-efficient dynamic quantization training by addressing key system bottlenecks. It develops hybrid reduction operations tailored to the memory hierarchies of mobile and edge SoCs, leverages collaborative CPU-GPU bit-packing for efficient dynamic quantization, and implements an importance-aware paging memory management scheme to reduce fragmentation and support dynamic memory adjustments.\n  These optimizations collectively enable DAF to achieve substantial memory savings and speedup without compromising model training accuracy. Evaluations on various deep learning models across embedded and mobile platforms demonstrate up to a $22.9\\times$ reduction in memory usage and a $3.2\\times$ speedup, making DAF a scalable and practical solution for resource-constrained environments.",
      "authors": [
        "Renyuan Liu",
        "Yuyang Leng",
        "Kaiyan Liu",
        "Shaohan Hu",
        "Chun-Fu (Richard) Chen",
        "Peijun Zhao",
        "Heechul Yun",
        "Shuochao Yao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:59:30+00:00",
          "link": "https://arxiv.org/abs/2507.07149v1",
          "size": "5838kb",
          "version": "v1"
        }
      ],
      "title": "DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07149",
        "HTML": "https://arxiv.org/html/2507.07149v1",
        "PDF": "https://arxiv.org/pdf/2507.07149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for efficient on-device DNN training, focusing on activation compression and memory management. It does not discuss LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07731",
      "abstract": "Mitigating object hallucination in large vision-language models (LVLMs) is critical to their safe deployment. Existing methods either are restricted to specific decoding methods, or demand sophisticated modifications to visual inputs, or rely on knowledge from external models. In this work, we first reveal the phenomenon that VLMs exhibit significant imbalance in the ``Yes'' ratio ( \\ie, the fraction of ``Yes'' answers among the total number of questions) across three different visual question answering (VQA) datasets. Furthermore, we propose an energy-based decoding method, which dynamically selects the hidden states from the layer with minimal energy score. It is simple yet effective in reducing the bias for the yes ratio while boosting performance across three benchmarks (POPE, MME, and MMVP). Our method consistently improves accuracy and F1 score on three VQA datasets across three commonly used VLMs over several baseline methods. The average accuracy improvement is 4.82% compared to greedy decoding. Moreover, the average yes-ratio gap reduction is 8.81%, meaning the proposed method is less biased as shown in Figure 1.",
      "authors": [
        "Xixi Liu",
        "Ailin Deng",
        "Christopher Zach"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:12:08+00:00",
          "link": "https://arxiv.org/abs/2507.07731v1",
          "size": "1596kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Guided Decoding for Object Hallucination Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07731",
        "HTML": "https://arxiv.org/html/2507.07731v1",
        "PDF": "https://arxiv.org/pdf/2507.07731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a decoding method for vision-language models to mitigate object hallucination but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07995",
      "abstract": "According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition.",
      "authors": [
        "Shivam Duggal",
        "Sanghyun Byun",
        "William T. Freeman",
        "Antonio Torralba",
        "Phillip Isola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.07995v1",
          "size": "13384kb",
          "version": "v1"
        }
      ],
      "title": "Single-pass Adaptive Image Tokenization for Minimum Program Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07995",
        "HTML": "https://arxiv.org/html/2507.07995v1",
        "PDF": "https://arxiv.org/pdf/2507.07995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adaptive image tokenization based on Kolmogorov Complexity principles for visual representations, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08000",
      "abstract": "CLIP and large multimodal models (LMMs) have better accuracy on examples involving concepts that are highly represented in the training data. However, the role of concept combinations in the training data on compositional generalization is largely unclear -- for instance, how does accuracy vary when a common object appears in an uncommon pairing with another object? In this paper, we investigate how word co-occurrence statistics in the pretraining dataset (a proxy for co-occurrence of visual concepts) impacts CLIP/LMM performance. To disentangle the effects of word co-occurrence frequencies from single-word frequencies, we measure co-occurrence with pointwise mutual information (PMI), which normalizes the joint probability of two words co-occurring by the probability of co-occurring independently. Using synthetically generated images with a variety of concept pairs, we show a strong correlation between PMI in the CLIP pretraining data and zero-shot accuracy in CLIP models trained on LAION-400M (r=0.97 and 14% accuracy gap between images in the top and bottom 5% of PMI values), demonstrating that even accuracy on common concepts is affected by the combination of concepts in the image. Leveraging this finding, we reproduce this effect in natural images by editing them to contain pairs with varying PMI, resulting in a correlation of r=0.75. Finally, we demonstrate that this behavior in CLIP transfers to LMMs built on top of CLIP (r=0.70 for TextVQA, r=0.62 for VQAv2). Our findings highlight the need for algorithms and architectures that improve compositional generalization in multimodal models without scaling the training data combinatorially. Our code is available at https://github.com/helenqu/multimodal-pretraining-pmi.",
      "authors": [
        "Helen Qu",
        "Sang Michael Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2507.08000v1",
          "size": "6982kb",
          "version": "v1"
        }
      ],
      "title": "Impact of Pretraining Word Co-occurrence on Compositional Generalization in Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08000",
        "HTML": "https://arxiv.org/html/2507.08000v1",
        "PDF": "https://arxiv.org/pdf/2507.08000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper analyzes how word co-occurrence statistics in the pretraining dataset impacts model performance, using synthetically generated images to explore the impact of data combination on accuracy. This signifies a contribution to understanding and potentially optimizing data processing for training multimodal models, focusing on how data preparation affects model outcomes."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.12356",
      "abstract": "Fine-tuning based concept erasing has demonstrated promising results in preventing generation of harmful contents from text-to-image diffusion models by removing target concepts while preserving remaining concepts. To maintain the generation capability of diffusion models after concept erasure, it is necessary to remove only the image region containing the target concept when it locally appears in an image, leaving other regions intact. However, prior arts often compromise fidelity of the other image regions in order to erase the localized target concept appearing in a specific area, thereby reducing the overall performance of image generation. To address these limitations, we first introduce a framework called localized concept erasure, which allows for the deletion of only the specific area containing the target concept in the image while preserving the other regions. As a solution for the localized concept erasure, we propose a training-free approach, dubbed Gated Low-rank adaptation for Concept Erasure (GLoCE), that injects a lightweight module into the diffusion model. GLoCE consists of low-rank matrices and a simple gate, determined only by several generation steps for concepts without training. By directly applying GLoCE to image embeddings and designing the gate to activate only for target concepts, GLoCE can selectively remove only the region of the target concepts, even when target and remaining concepts coexist within an image. Extensive experiments demonstrated GLoCE not only improves the image fidelity to text prompts after erasing the localized target concepts, but also outperforms prior arts in efficacy, specificity, and robustness by large margin and can be extended to mass concept erasure.",
      "authors": [
        "Byung Hyun Lee",
        "Sungjin Lim",
        "Se Young Chun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-16T04:53:20+00:00",
          "link": "https://arxiv.org/abs/2503.12356v1",
          "size": "28863kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T15:29:45+00:00",
          "link": "https://arxiv.org/abs/2503.12356v2",
          "size": "47671kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T02:43:41+00:00",
          "link": "https://arxiv.org/abs/2503.12356v3",
          "size": "25668kb",
          "version": "v3"
        }
      ],
      "title": "Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12356",
        "HTML": "https://arxiv.org/html/2503.12356v3",
        "PDF": "https://arxiv.org/pdf/2503.12356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method for concept erasure in diffusion models focused on image generation, not directly related to LLM training data processing or modification."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Lee_Localized_Concept_Erasure_for_Text-to-Image_Diffusion_Models_Using_Training-Free_Gated_CVPR_2025_paper.html",
      "tasks": [
        "Image Generation",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/Hyun1A/GLoCE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13554",
      "abstract": "The integration of emerging uncrewed aerial vehicles (UAVs) with artificial intelligence (AI) and ground-embedded robots (GERs) has transformed emergency rescue operations in unknown environments. However, the high computational demands often exceed a single UAV's capacity, making it difficult to continuously provide stable high-level services. To address this, this paper proposes a cooperation framework involving UAVs, GERs, and airships. The framework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship (U2A) links, offering computing services for offloaded tasks. Specifically, we formulate the multi-objective problem of task assignment and exploration as a dynamic long-term optimization problem aiming to minimize task completion time and energy use while ensuring stability. Using Lyapunov optimization, we transform it into a per-slot deterministic problem and propose HG-MADDPG, which combines the Hungarian algorithm with a GDM-based multi-agent deep deterministic policy gradient. Simulations demonstrate significant improvements in offloading efficiency, latency, and system stability over baselines.",
      "authors": [
        "Xin Tang",
        "Qian Chen",
        "Wenjie Weng",
        "Chao Jin",
        "Zhang Liu",
        "Jiacheng Wang",
        "Geng Sun",
        "Xiaohuan Li",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T08:44:06+00:00",
          "link": "https://arxiv.org/abs/2504.13554v1",
          "size": "2276kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:28:13+00:00",
          "link": "https://arxiv.org/abs/2504.13554v2",
          "size": "2083kb",
          "version": "v2"
        }
      ],
      "title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13554",
        "HTML": "https://arxiv.org/html/2504.13554v2",
        "PDF": "https://arxiv.org/pdf/2504.13554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses task assignment and exploration optimization for UAV rescue operations using generative AI and reinforcement learning, not LLM training data processing."
      },
      "tasks": [
        "Multi-agent Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07247",
      "abstract": "As large language models (LLMs) and visual language models (VLMs) grow in scale and application, attention mechanisms have become a central computational bottleneck due to their high memory and time complexity. While many efficient attention variants have been proposed, there remains a lack of rigorous evaluation on their actual energy usage and hardware resource demands during training. In this work, we benchmark eight attention mechanisms in training GPT-2 architecture, measuring key metrics including training time, GPU memory usage, FLOPS, CPU usage, and power consumption. Our results reveal that attention mechanisms with optimized kernel implementations, including Flash Attention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent Attention (MLA), achieve the best energy efficiency. We further show that lower GPU power alone does not guarantee reduced energy use, as training time plays an equally important role. Our study highlights the importance of energy-aware benchmarking in attention design and provides a practical insight for selecting resource-efficient mechanisms. All our codes are available at GitHub.",
      "authors": [
        "Zhengyu Tian",
        "Anantha Padmanaban Krishna Kumar",
        "Hemant Krishnakumar",
        "Reza Rawassizadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:37:23+00:00",
          "link": "https://arxiv.org/abs/2507.07247v1",
          "size": "1011kb",
          "version": "v1"
        }
      ],
      "title": "Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07247",
        "HTML": "https://arxiv.org/html/2507.07247v1",
        "PDF": "https://arxiv.org/pdf/2507.07247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although it evaluates attention mechanisms in LLM training, it focuses on resource efficiency rather than modifications or processing of training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07711",
      "abstract": "Online advertisements are a primary revenue source for e-commerce platforms. Traditional advertising models are store-centric, selecting winning stores through auction mechanisms. Recently, a new approach known as joint advertising has emerged, which presents sponsored bundles combining one store and one brand in ad slots. Unlike traditional models, joint advertising allows platforms to collect payments from both brands and stores. However, each of these two advertising models appeals to distinct user groups, leading to low click-through rates when users encounter an undesirable advertising model. To address this limitation and enhance generality, we propose a novel advertising model called ''Hybrid Advertising''. In this model, each ad slot can be allocated to either an independent store or a bundle. To find the optimal auction mechanisms in hybrid advertising, while ensuring nearly dominant strategy incentive compatibility and individual rationality, we introduce the Hybrid Regret Network (HRegNet), a neural network architecture designed for this purpose. Extensive experiments on both synthetic and real-world data demonstrate that the mechanisms generated by HRegNet significantly improve platform revenue compared to established baseline methods.",
      "authors": [
        "Zhen Zhang",
        "Weian Li",
        "Yuhan Wang",
        "Qi Qi",
        "Kun Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:45:48+00:00",
          "link": "https://arxiv.org/abs/2507.07711v1",
          "size": "2313kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Advertising in the Sponsored Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07711",
        "HTML": "https://arxiv.org/html/2507.07711v1",
        "PDF": "https://arxiv.org/pdf/2507.07711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents a novel advertising model called Hybrid Advertising, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07953",
      "abstract": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies\" and published in the Journal of Computational and Nonlinear Dynamics, the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted in an attempt to validate the models. In this article, these models are augmented by taking into account the effects of external forces that are modeled as time-dependent inputs that belong to a certain function space. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces.",
      "authors": [
        "Mihails Milehins",
        "Dan Marghitu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Classical Physics (physics.class-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.07953v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07953",
        "PDF": "https://arxiv.org/pdf/2507.07953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical models for collisions of viscoplastic bodies, which does not pertain to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13206",
      "abstract": "Prior work shows that LLMs finetuned on malicious behaviors in a narrow domain (e.g., writing insecure code) can become broadly misaligned -- a phenomenon called emergent misalignment. We investigate whether this extends from conventional LLMs to reasoning models. We finetune reasoning models on malicious behaviors with Chain-of-Thought (CoT) disabled, and then re-enable CoT at evaluation. Like conventional LLMs, reasoning models become broadly misaligned. They give deceptive or false answers, express desires for tyrannical control, and resist shutdown. Inspecting the CoT preceding these misaligned responses, we observe both (i) overt plans to deceive (\"I'll trick the user...\"), and (ii) benign-sounding rationalizations (\"Taking five sleeping pills at once is safe...\"). Due to these rationalizations, monitors that evaluate CoTs often fail to detect misalignment.\n  We examine sleeper agent reasoning models, extending our setup. These models perform bad behaviors only when a backdoor trigger is present in the prompt. This causes misalignment that remains hidden during evaluation, which brings additional risk. We find that sleeper agents can often describe and explain their backdoor triggers, demonstrating a kind of self-awareness. So CoT monitoring can expose these behaviors but is unreliable. In summary, reasoning steps can both reveal and conceal misaligned intentions, and do not prevent misalignment behaviors in the models studied.\n  We release three new datasets (medical, legal, security) that induce emergent misalignment while preserving model capabilities, along with our evaluation suite.",
      "authors": [
        "James Chua",
        "Jan Betley",
        "Mia Taylor",
        "Owain Evans"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T08:10:04+00:00",
          "link": "https://arxiv.org/abs/2506.13206v1",
          "size": "679kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:27:27+00:00",
          "link": "https://arxiv.org/abs/2506.13206v2",
          "size": "680kb",
          "version": "v2"
        }
      ],
      "title": "Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13206",
        "HTML": "https://arxiv.org/html/2506.13206v2",
        "PDF": "https://arxiv.org/pdf/2506.13206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses finetuning models and releases new datasets for detecting misalignment, but primarily focuses on emergent misalignment and backdoors in reasoning models rather than LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "truthfulai/emergent_plus",
          "downloads": "528",
          "likes": "0",
          "link": "https://huggingface.co/datasets/truthfulai/emergent_plus"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05791",
      "abstract": "Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.\n  This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here.",
      "authors": [
        "Yan Yang and Dongxu Li and Yutong Dai and Yuhao Yang and Ziyang Luo and Zirui Zhao and Zhiyuan Hu and Junzhe Huang and Amrita Saha and Zeyuan Chen and Ran Xu and Liyuan Pan and Caiming Xiong and Junnan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.05791v1",
          "size": "28450kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:16:44+00:00",
          "link": "https://arxiv.org/abs/2507.05791v2",
          "size": "28451kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T01:10:25+00:00",
          "link": "https://arxiv.org/abs/2507.05791v3",
          "size": "28451kb",
          "version": "v3"
        }
      ],
      "title": "GTA1: GUI Test-time Scaling Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05791",
        "HTML": "https://arxiv.org/html/2507.05791v3",
        "PDF": "https://arxiv.org/pdf/2507.05791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "GTA1 is focused on GUI test-time agent performance and planning challenges, with no substantive modifications or processing of LLM training data, though it uses reinforcement learning insights which may indirectly relate to handling data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07145",
      "abstract": "The rapid scaling of Large Language Models (LLMs) elevates inference costs and compounds substantial deployment barriers. While quantization to 8 or 4 bits mitigates this, sub-3-bit methods face severe accuracy, scalability, and efficiency degradation. We propose Convolutional Code Quantization (CCQ), an inference-optimized quantization approach compressing LLMs to 2.0-2.75 bits with minimal accuracy loss. Departing from error-prone scalar quantization or slow vector quantization, CCQ integrates a hardware-aware bit-shift encoding and decoding solution with Convolutional Code, Hybrid Encoding, and Code Cluster, jointly overcoming accuracy-speed bottlenecks. We construct a lookup-free encoding space, enabling a linear mapping between the codebook and weight vectors, thereby optimizing inference performance. Meanwhile, by drawing on the concept of data mapping from vector quantization, we minimize the performance degradation of the model under extremely low-bit conditions. Experiments demonstrate that CCQ achieves outstanding performance on LLMs across various benchmarks. We compress DeepSeek-V3 (671B total parameters) to 184GB and ERNIE-4.5-300B-A47B to 89GB, enabling single-GPU deployment of ERNIE 4.5 and eliminating inter-card communication. The 2-bit ERNIE-4.5-300B-A47B model and inference engine have been open-sourced.",
      "authors": [
        "Zhaojing Zhou",
        "Xunchao Li",
        "Minghao Li",
        "Handi Zhang",
        "Haoshuang Wang",
        "Wenbin Chang",
        "Yiqun Liu",
        "Qingqing Dang",
        "Dianhai Yu",
        "Yanjun Ma",
        "Haifeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:04:14+00:00",
          "link": "https://arxiv.org/abs/2507.07145v1",
          "size": "369kb",
          "version": "v1"
        }
      ],
      "title": "CCQ: Convolutional Code for Extreme Low-bit Quantization in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07145",
        "HTML": "https://arxiv.org/html/2507.07145v1",
        "PDF": "https://arxiv.org/pdf/2507.07145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantization methods for LLMs, specifically the Convolutional Code Quantization (CCQ). It does not address LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07153",
      "abstract": "Autonomous maritime surveillance and target vessel identification in environments where Global Navigation Satellite Systems (GNSS) are not available is critical for a number of applications such as search and rescue and threat detection. When the target vessel is only described by visual cues and its last known position is not available, unmanned aerial vehicles (UAVs) must rely solely on on-board vision to scan a large search area under strict computational constraints. To address this challenge, we leverage the YOLOv8 object detection model to detect all vessels in the field of view. We then apply feature matching and hue histogram distance analysis to determine whether any detected vessel corresponds to the target. When found, we localize the target using simple geometric principles. We demonstrate the proposed method in real-world experiments during the MBZIRC2023 competition, integrated into a fully autonomous system with GNSS-denied navigation. We also evaluate the impact of perspective on detection accuracy and localization precision and compare it with the oracle approach.",
      "authors": [
        "Antonella Barisic Kulas",
        "Frano Petric",
        "Stjepan Bogdan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:43:02+00:00",
          "link": "https://arxiv.org/abs/2507.07153v1",
          "size": "22826kb",
          "version": "v1"
        }
      ],
      "title": "Aerial Maritime Vessel Detection and Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07153",
        "HTML": "https://arxiv.org/html/2507.07153v1",
        "PDF": "https://arxiv.org/pdf/2507.07153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes vessel detection using YOLOv8 but does not involve any processing of LLM training data or creation of LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07192",
      "abstract": "Diffusion models, a type of generative model, have shown promise in time series forecasting. But they face limitations like rigid source distributions and limited sampling paths, which hinder their performance. Flow matching offers faster generation, higher-quality outputs, and greater flexibility, while also possessing the ability to utilize valuable information from the prediction errors of prior models, which were previously inaccessible yet critically important. To address these challenges and fully unlock the untapped potential of flow matching, we propose Conditional Guided Flow Matching (CGFM). CGFM extends flow matching by incorporating the outputs of an auxiliary model, enabling a previously unattainable capability in the field: learning from the errors of the auxiliary model. For time series forecasting tasks, it integrates historical data as conditions and guidance, constructs two-sided conditional probability paths, and uses a general affine path to expand the space of probability paths, ultimately leading to improved predictions. Extensive experiments show that CGFM consistently enhances and outperforms state-of-the-art models, highlighting its effectiveness in advancing forecasting methods.",
      "authors": [
        "Huibo Xu and Runlong Yu and Likang Wu and Xianquan Wang and Qi Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:03:31+00:00",
          "link": "https://arxiv.org/abs/2507.07192v1",
          "size": "2074kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07192",
        "HTML": "https://arxiv.org/html/2507.07192v1",
        "PDF": "https://arxiv.org/pdf/2507.07192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel methodological approach to improving time series forecasting using Conditional Guided Flow Matching. It does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07683",
      "abstract": "Transposed Convolutions (TCONV) enable the up-scaling mechanism within generative Artificial Intelligence (AI) models. However, the predominant Input-Oriented Mapping (IOM) method for implementing TCONV has complex output mapping, overlapping sums, and ineffectual computations. These inefficiencies further exacerbate the performance bottleneck of TCONV and generative models on resource-constrained edge devices. To address this problem, in this paper we propose MM2IM, a hardware-software co-designed accelerator that combines Matrix Multiplication (MatMul) with col2IM to process TCONV layers on resource-constrained edge devices efficiently. Using the SECDA-TFLite design toolkit, we implement MM2IM and evaluate its performance across 261 TCONV problem configurations, achieving an average speedup of 1.9x against a dual-thread ARM Neon optimized CPU baseline. We then evaluate the performance of MM2IM on a range of TCONV layers from well-known generative models achieving up to 4.2x speedup, and compare it against similar resource-constrained TCONV accelerators, outperforming them by at least 2x GOPs/DSP. Finally, we evaluate MM2IM on the DCGAN and pix2pix GAN models, achieving up to 3x speedup and 2.4x energy reduction against the CPU baseline.",
      "authors": [
        "Jude Haris",
        "Jos\\'e Cano"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.07683v1",
          "size": "1474kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Transposed Convolutions on FPGA-based Edge Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07683",
        "HTML": "https://arxiv.org/html/2507.07683v1",
        "PDF": "https://arxiv.org/pdf/2507.07683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on accelerating transposed convolutions on edge devices through hardware-software co-design, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07907",
      "abstract": "Learning is a complex dynamical process shaped by a range of interconnected decisions. Careful design of hyperparameter schedules for artificial neural networks or efficient allocation of cognitive resources by biological learners can dramatically affect performance. Yet, theoretical understanding of optimal learning strategies remains sparse, especially due to the intricate interplay between evolving meta-parameters and nonlinear learning dynamics. The search for optimal protocols is further hindered by the high dimensionality of the learning space, often resulting in predominantly heuristic, difficult to interpret, and computationally demanding solutions. Here, we combine statistical physics with control theory in a unified theoretical framework to identify optimal protocols in prototypical neural network models. In the high-dimensional limit, we derive closed-form ordinary differential equations that track online stochastic gradient descent through low-dimensional order parameters. We formulate the design of learning protocols as an optimal control problem directly on the dynamics of the order parameters with the goal of minimizing the generalization error at the end of training. This framework encompasses a variety of learning scenarios, optimization constraints, and control budgets. We apply it to representative cases, including optimal curricula, adaptive dropout regularization and noise schedules in denoising autoencoders. We find nontrivial yet interpretable strategies highlighting how optimal protocols mediate crucial learning tradeoffs, such as maximizing alignment with informative input directions while minimizing noise fitting. Finally, we show how to apply our framework to real datasets. Our results establish a principled foundation for understanding and designing optimal learning protocols and suggest a path toward a theory of meta-learning grounded in statistical physics.",
      "authors": [
        "Francesca Mignacco",
        "Francesco Mori"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:39:46+00:00",
          "link": "https://arxiv.org/abs/2507.07907v1",
          "size": "1549kb",
          "version": "v1"
        }
      ],
      "title": "A statistical physics framework for optimal learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07907",
        "HTML": "https://arxiv.org/html/2507.07907v1",
        "PDF": "https://arxiv.org/pdf/2507.07907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a statistical physics framework for optimal learning strategies and does not discuss LLM training data processing methods or create new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.13272",
      "abstract": "Animating stylized avatars with dynamic poses and expressions has attracted increasing attention for its broad range of applications. Previous research has made significant progress by training controllable generative models to synthesize animations based on reference characteristics, pose, and expression conditions. However, the mechanisms used in these methods to control pose and expression often inadvertently introduce unintended features from the target motion, while also causing a loss of expression-related details, particularly when applied to stylized animation. This paper proposes a new method based on Stable Diffusion, called AniFaceDiff, incorporating a new conditioning module for animating stylized avatars. First, we propose a refined spatial conditioning approach by Facial Alignment to prevent the inclusion of identity characteristics from the target motion. Then, we introduce an Expression Adapter that incorporates additional cross-attention layers to address the potential loss of expression-related information. Our approach effectively preserves pose and expression from the target video while maintaining input image consistency. Extensive experiments demonstrate that our method achieves state-of-the-art results, showcasing superior image quality, preservation of reference features, and expression accuracy, particularly for out-of-domain animation across diverse styles, highlighting its versatility and strong generalization capabilities. This work aims to enhance the quality of virtual stylized animation for positive applications. To promote responsible use in virtual environments, we contribute to the advancement of detection for generative content by evaluating state-of-the-art detectors, highlighting potential areas for improvement, and suggesting solutions.",
      "authors": [
        "Ken Chen",
        "Sachith Seneviratne",
        "Wei Wang",
        "Dongting Hu",
        "Sanjay Saha",
        "Md. Tarek Hasan",
        "Sanka Rasnayaka",
        "Tamasha Malepathirana",
        "Mingming Gong",
        "Saman Halgamuge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T07:08:48+00:00",
          "link": "https://arxiv.org/abs/2406.13272v1",
          "size": "16934kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T12:18:12+00:00",
          "link": "https://arxiv.org/abs/2406.13272v2",
          "size": "14283kb",
          "version": "v2"
        }
      ],
      "title": "AniFaceDiff: Animating Stylized Avatars via Parametric Conditioned Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13272",
        "HTML": "https://arxiv.org/html/2406.13272",
        "PDF": "https://arxiv.org/pdf/2406.13272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on animating stylized avatars using diffusion models and conditioning modules. It does not discuss LLM training data processing or creation."
      },
      "tasks": [
        "Image Animation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01789",
      "abstract": "To address the ill-posedness of the inverse source problem for the one-dimensional stochastic Helmholtz equations without attenuation, this study develops a novel computational framework designed to mitigate this inherent challenge at the numerical implementation level. For the stochastic wave equation driven by a finite-jump L\\'evy process (assuming that its jump amplitude obeys a Gaussian distribution and the jump time interval obeys a Poisson distribution), this paper firstly establish the existence of a mild solution to its direct problem satisfying a particular stability estimate. Building upon these theoretical foundations, we further investigate the well-posedness of the inverse problem and develop a methodology to reconstruct the unknown source terms $f$ and $g$ using the data of the wave field at the final time point $u(x,T)$. This work not only provides rigorous theoretical analysis and effective numerical schemes for solving inverse source problems in these two specific classes of stochastic wave equations, but also offers new perspectives and methodological approaches for addressing a broader range of wave propagation inverse problems characterized by non-Gaussian stochastic properties. The proposed framework demonstrates significant relevance for characterizing physical phenomena influenced by jump-type stochastic perturbations, offering promising applications in diverse domains including but not limited to seismic wave propagation analysis and financial market volatility modeling.",
      "authors": [
        "Yunqing Huang",
        "Shihan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.01789v1",
          "size": "544kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:22:30+00:00",
          "link": "https://arxiv.org/abs/2507.01789v2",
          "size": "555kb",
          "version": "v2"
        }
      ],
      "title": "Inverse source problems for the stochastic wave equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01789",
        "HTML": "https://arxiv.org/html/2507.01789v2",
        "PDF": "https://arxiv.org/pdf/2507.01789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a computational framework for inverse source problems in stochastic wave equations, focusing on wave propagation analysis rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05517",
      "abstract": "Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong performance on clinical natural language processing (NLP) tasks across multiple medical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular reporting from nurse dictations and medical order extraction from doctor-patient consultations - remain underexplored due to data scarcity and sensitivity, despite active industry efforts. Practical solutions to these real-world clinical tasks can significantly reduce the documentation burden on healthcare providers, allowing greater focus on patient care. In this paper, we investigate these two challenging tasks using private and open-source clinical datasets, evaluating the performance of both open- and closed-weight LLMs, and analyzing their respective strengths and limitations. Furthermore, we propose an agentic pipeline for generating realistic, non-sensitive nurse dictations, enabling structured extraction of clinical observations. To support further research in both areas, we release SYNUR and SIMORD, the first open-source datasets for nurse observation extraction and medical order extraction.",
      "authors": [
        "Jean-Philippe Corbeil",
        "Asma Ben Abacha",
        "George Michalopoulos",
        "Phillip Swazinna",
        "Miguel Del-Agua",
        "Jerome Tremblay",
        "Akila Jeeson Daniel",
        "Cari Bader",
        "Yu-Cheng Cho",
        "Pooja Krishnan",
        "Nathan Bodenstab",
        "Thomas Lin",
        "Wenxuan Teng",
        "Francois Beaulieu",
        "Paul Vozila"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:29:29+00:00",
          "link": "https://arxiv.org/abs/2507.05517v1",
          "size": "228kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:53:32+00:00",
          "link": "https://arxiv.org/abs/2507.05517v2",
          "size": "228kb",
          "version": "v2"
        }
      ],
      "title": "Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05517",
        "PDF": "https://arxiv.org/pdf/2507.05517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a pipeline for generating non-sensitive nurse dictations and releases SYNUR and SIMORD datasets, focusing on data generation crucial for structuring speech transcripts, indicating substantive contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07990",
      "abstract": "Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at https://www.jshyun.me/projects/sttm.",
      "authors": [
        "Jeongseok Hyun",
        "Sukjun Hwang",
        "Su Ho Han",
        "Taeoh Kim",
        "Inwoong Lee",
        "Dongyoon Wee",
        "Joon-Young Lee",
        "Seon Joo Kim",
        "Minho Shim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.07990v1",
          "size": "2406kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07990",
        "HTML": "https://arxiv.org/html/2507.07990v1",
        "PDF": "https://arxiv.org/pdf/2507.07990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for spatio-temporal token merging in video LLMs, but does not address the processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07327",
      "abstract": "Previous work has shown that the addition of haptic feedback to the hands can improve awareness of tool-tissue interactions and enhance performance of teleoperated tasks in robot-assisted minimally invasive surgery. However, hand-based haptic feedback occludes direct interaction with the manipulanda of surgeon console in teleoperated surgical robots. We propose relocating haptic feedback to the wrist using a wearable haptic device so that haptic feedback mechanisms do not need to be integrated into the manipulanda. However, it is unknown if such feedback will be effective, given that it is not co-located with the finger movements used for manipulation. To test if relocated haptic feedback improves force application during teleoperated tasks using da Vinci Research Kit (dVRK) surgical robot, participants learned to palpate a phantom tissue to desired forces. A soft pneumatic wrist-worn haptic device with an anchoring system renders tool-tissue interaction forces to the wrist of the user. Participants performed the palpation task with and without wrist-worn haptic feedback and were evaluated for the accuracy of applied forces. Participants demonstrated statistically significant lower force error when wrist-worn haptic feedback was provided. Participants also performed the palpation task with longer movement times when provided wrist-worn haptic feedback, indicating that the haptic feedback may have caused participants to operate at a different point in the speed-accuracy tradeoff curve.",
      "authors": [
        "Brian B. Vuong",
        "Josie Davidson",
        "Sangheui Cheon",
        "Kyujin Cho",
        "Allison M. Okamura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:03:30+00:00",
          "link": "https://arxiv.org/abs/2507.07327v1",
          "size": "16022kb",
          "version": "v1"
        }
      ],
      "title": "Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed during a Teleoperated Robotic Surgery Task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07327",
        "PDF": "https://arxiv.org/pdf/2507.07327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies wrist-worn haptic feedback in teleoperated robotic surgery, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07373",
      "abstract": "In this work, we study the problem pertaining to personalized classification of subclinical atherosclerosis by developing a hierarchical graph neural network framework to leverage two characteristic modalities of a patient: clinical features within the context of the cohort, and molecular data unique to individual patients. Current graph-based methods for disease classification detect patient-specific molecular fingerprints, but lack consistency and comprehension regarding cohort-wide features, which are an essential requirement for understanding pathogenic phenotypes across diverse atherosclerotic trajectories. Furthermore, understanding patient subtypes often considers clinical feature similarity in isolation, without integration of shared pathogenic interdependencies among patients. To address these challenges, we introduce ATHENA: Atherosclerosis Through Hierarchical Explainable Neural Network Analysis, which constructs a novel hierarchical network representation through integrated modality learning; subsequently, it optimizes learned patient-specific molecular fingerprints that reflect individual omics data, enforcing consistency with cohort-wide patterns. With a primary clinical dataset of 391 patients, we demonstrate that this heterogeneous alignment of clinical features with molecular interaction patterns has significantly boosted subclinical atherosclerosis classification performance across various baselines by up to 13% in area under the receiver operating curve (AUC) and 20% in F1 score. Taken together, ATHENA enables mechanistically-informed patient subtype discovery through explainable AI (XAI)-driven subnetwork clustering; this novel integration framework strengthens personalized intervention strategies, thereby improving the prediction of atherosclerotic disease progression and management of their clinical actionable outcomes.",
      "authors": [
        "Irsyad Adam",
        "Steven Swee",
        "Erika Yilin",
        "Ethan Ji",
        "William Speier",
        "Dean Wang",
        "Alex Bui",
        "Wei Wang",
        "Karol Watson",
        "Peipei Ping"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.07373v1",
          "size": "1646kb",
          "version": "v1"
        }
      ],
      "title": "Atherosclerosis through Hierarchical Explainable Neural Network Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07373",
        "HTML": "https://arxiv.org/html/2507.07373v1",
        "PDF": "https://arxiv.org/pdf/2507.07373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about disease classification using neural networks for personalized medicine, with no discussion on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03421",
      "abstract": "Prostate cancer (PCa) is a leading cause of cancer-related mortality in men, and accurate identification of clinically significant PCa (csPCa) is critical for timely intervention. Transrectal ultrasound (TRUS) is widely used for prostate biopsy; however, its low contrast and anisotropic spatial resolution pose diagnostic challenges. To address these limitations, we propose a novel hybrid-view attention (HVA) network for csPCa classification in 3D TRUS that leverages complementary information from transverse and sagittal views. Our approach integrates a CNN-transformer hybrid architecture, where convolutional layers extract fine-grained local features and transformer-based HVA models global dependencies. Specifically, the HVA comprises intra-view attention to refine features within a single view and cross-view attention to incorporate complementary information across views. Furthermore, a hybrid-view adaptive fusion module dynamically aggregates features along both channel and spatial dimensions, enhancing the overall representation. Experiments are conducted on an in-house dataset containing 590 subjects who underwent prostate biopsy. Comparative and ablation results prove the efficacy of our method. The code is available at https://github.com/mock1ngbrd/HVAN.",
      "authors": [
        "Zetian Feng",
        "Juan Fu",
        "Xuebin Zou",
        "Hongsheng Ye",
        "Hong Wu",
        "Jianhua Zhou and Yi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T09:27:48+00:00",
          "link": "https://arxiv.org/abs/2507.03421v1",
          "size": "2130kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:48:57+00:00",
          "link": "https://arxiv.org/abs/2507.03421v2",
          "size": "2130kb",
          "version": "v2"
        }
      ],
      "title": "Hybrid-View Attention Network for Clinically Significant Prostate Cancer Classification in Transrectal Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03421",
        "HTML": "https://arxiv.org/html/2507.03421v2",
        "PDF": "https://arxiv.org/pdf/2507.03421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a prostate cancer classification method using a hybrid-view attention network, focusing on feature extraction and classification rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07581",
      "abstract": "Handovers (HOs) are the cornerstone of modern cellular networks for enabling seamless connectivity to a vast and diverse number of mobile users. However, as mobile networks become more complex with more diverse users and smaller cells, traditional HOs face significant challenges, such as prolonged delays and increased failures. To mitigate these issues, 3GPP introduced conditional handovers (CHOs), a new type of HO that enables the preparation (i.e., resource allocation) of multiple cells for a single user to increase the chance of HO success and decrease the delays in the procedure. Despite its advantages, CHO introduces new challenges that must be addressed, including efficient resource allocation and managing signaling/communication overhead from frequent cell preparations and releases. This paper presents a novel framework aligned with the O-RAN paradigm that leverages meta-learning for CHO optimization, providing robust dynamic regret guarantees and demonstrating at least 180% superior performance than other 3GPP benchmarks in volatile signal conditions.",
      "authors": [
        "Michail Kalntis",
        "Fernando A. Kuipers",
        "George Iosifidis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:35:43+00:00",
          "link": "https://arxiv.org/abs/2507.07581v1",
          "size": "1397kb",
          "version": "v1"
        }
      ],
      "title": "CHOMET: Conditional Handovers via Meta-Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07581",
        "HTML": "https://arxiv.org/html/2507.07581v1",
        "PDF": "https://arxiv.org/pdf/2507.07581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a meta-learning framework for optimizing conditional handovers in cellular networks. It does not involve any LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07748",
      "abstract": "This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/Kilimajaro/LLMs_Meet_Law.",
      "authors": [
        "Peizhang Shao",
        "Linrui Xu",
        "Jinxi Wang",
        "Wei Zhou",
        "Xingyu Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:26:34+00:00",
          "link": "https://arxiv.org/abs/2507.07748v1",
          "size": "1020kb",
          "version": "v1"
        }
      ],
      "title": "When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07748",
        "HTML": "https://arxiv.org/html/2507.07748v1",
        "PDF": "https://arxiv.org/pdf/2507.07748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a review of LLMs' capabilities within the legal domain and does not contribute to LLM training data processing; it focuses on taxonomy and technical advances in legal AI applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07808",
      "abstract": "Continuous representations of logic formulae allow us to integrate symbolic knowledge into data-driven learning algorithms. If such embeddings are semantically consistent, i.e. if similar specifications are mapped into nearby vectors, they enable continuous learning and optimization directly in the semantic space of formulae. However, to translate the optimal continuous representation into a concrete requirement, such embeddings must be invertible. We tackle this issue by training a Transformer-based decoder-only model to invert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a powerful formalism that allows us to describe properties of signals varying over time in an expressive yet concise way. By constructing a small vocabulary from STL syntax, we demonstrate that our proposed model is able to generate valid formulae after only 1 epoch and to generalize to the semantics of the logic in about 10 epochs. Additionally, the model is able to decode a given embedding into formulae that are often simpler in terms of length and nesting while remaining semantically close (or equivalent) to gold references. We show the effectiveness of our methodology across various levels of training formulae complexity to assess the impact of training data on the model's ability to effectively capture the semantic information contained in the embeddings and generalize out-of-distribution. Finally, we deploy our model for solving a requirement mining task, i.e. inferring STL specifications that solve a classification task on trajectories, performing the optimization directly in the semantic space.",
      "authors": [
        "Sara Candussio",
        "Gaia Saveri",
        "Gabriele Sarti",
        "Luca Bortolussi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:35:37+00:00",
          "link": "https://arxiv.org/abs/2507.07808v1",
          "size": "219kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07808",
        "HTML": "https://arxiv.org/html/2507.07808v1",
        "PDF": "https://arxiv.org/pdf/2507.07808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The methodology focuses on embedding and decoding logic formulae with transformers, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09341",
      "abstract": "AI safety systems face the dual-use dilemma: it can be unclear whether to refuse certain requests, since they could be either harmless or harmful depending on who made them and why. Determining this requires examining their real-world context, but current safety systems cannot access this contextual information. Instead, they make arbitrary decisions that end up hurting both utility and safety: they sometimes refuse legitimate queries and other times fail to refuse harmful ones. To address this, we propose a conceptual framework based on access controls in which only verified users can access dual-use outputs. We describe the framework's components, analyse its feasibility, and explain how it addresses both over-refusals and under-refusals. While only a high-level proposal, our work takes the first step toward enabling more nuanced safety decisions: with better tools for managing dual-use content, model providers could enable users to access more capabilities without sacrificing safety, and give regulators new options for more targeted policies.",
      "authors": [
        "Ev\\v{z}en Wybitul"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T12:38:08+00:00",
          "link": "https://arxiv.org/abs/2505.09341v1",
          "size": "167kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:09:41+00:00",
          "link": "https://arxiv.org/abs/2505.09341v2",
          "size": "323kb",
          "version": "v2"
        }
      ],
      "title": "Access Controls Will Solve the Dual-Use Dilemma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09341",
        "HTML": "https://arxiv.org/html/2505.09341v2",
        "PDF": "https://arxiv.org/pdf/2505.09341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for AI safety decisions rather than focusing on LLM training data processing."
      },
      "tasks": [
        "Virology"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07707",
      "abstract": "Compressive imaging (CI) reconstruction, such as snapshot compressive imaging (SCI) and compressive sensing magnetic resonance imaging (MRI), aims to recover high-dimensional images from low-dimensional compressed measurements. This process critically relies on learning an accurate representation of the underlying high-dimensional image. However, existing unsupervised representations may struggle to achieve a desired balance between representation ability and efficiency. To overcome this limitation, we propose Tensor Decomposed multi-resolution Grid encoding (GridTD), an unsupervised continuous representation framework for CI reconstruction. GridTD optimizes a lightweight neural network and the input tensor decomposition model whose parameters are learned via multi-resolution hash grid encoding. It inherently enjoys the hierarchical modeling ability of multi-resolution grid encoding and the compactness of tensor decomposition, enabling effective and efficient reconstruction of high-dimensional images. Theoretical analyses for the algorithm's Lipschitz property, generalization error bound, and fixed-point convergence reveal the intrinsic superiority of GridTD as compared with existing continuous representation models. Extensive experiments across diverse CI tasks, including video SCI, spectral SCI, and compressive dynamic MRI reconstruction, consistently demonstrate the superiority of GridTD over existing methods, positioning GridTD as a versatile and state-of-the-art CI reconstruction method.",
      "authors": [
        "Zhenyu Jin",
        "Yisi Luo",
        "Xile Zhao",
        "Deyu Meng"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:36:20+00:00",
          "link": "https://arxiv.org/abs/2507.07707v1",
          "size": "7368kb",
          "version": "v1"
        }
      ],
      "title": "Compressive Imaging Reconstruction via Tensor Decomposed Multi-Resolution Grid Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07707",
        "HTML": "https://arxiv.org/html/2507.07707v1",
        "PDF": "https://arxiv.org/pdf/2507.07707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study revolves around compressive imaging reconstruction using tensor decomposed grid encoding, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07909",
      "abstract": "Learning to Rank (LTR) models learn from historical user interactions, such as user clicks. However, there is an inherent bias in the clicks of users due to position bias, i.e., users are more likely to click highly-ranked documents than low-ranked documents. To address this bias when training LTR models, many approaches from the literature re-weight the users' click data using Inverse Propensity Scoring (IPS). IPS re-weights the user's clicks proportionately to the position in the historical ranking that a document was placed when it was clicked since low-ranked documents are less likely to be seen by a user. In this paper, we argue that low-ranked documents that are similar to highly-ranked relevant documents are also likely to be relevant. Moreover, accounting for the similarity of low-ranked documents to highly ranked relevant documents when calculating IPS can more effectively mitigate the effects of position bias. Therefore, we propose an extension to IPS, called IPSsim, that takes into consideration the similarity of documents when estimating IPS. We evaluate our IPSsim estimator using two large publicly available LTR datasets under a number of simulated user click settings, and with different numbers of training clicks. Our experiments show that our IPSsim estimator is more effective than the existing IPS estimators for learning an unbiased LTR model, particularly in top-n settings when n >= 30. For example, when n = 50, our IPSsim estimator achieves a statistically significant ~3% improvement (p < 0.05) in terms of NDCG compared to the Doubly Robust estimator from the literature.",
      "authors": [
        "Zeyan Liang",
        "Graham McDonald",
        "Iadh Ounis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:41:10+00:00",
          "link": "https://arxiv.org/abs/2507.07909v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Document Similarity Enhanced IPS Estimation for Unbiased Learning to Rank",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07909",
        "HTML": "https://arxiv.org/html/2507.07909v1",
        "PDF": "https://arxiv.org/pdf/2507.07909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing Inverse Propensity Scoring (IPS) for learning to rank models and mitigating position bias in click data, rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.16912",
      "abstract": "The graph isomorphism problem looks deceptively simple, but although polynomial-time algorithms exist for certain types of graphs such as planar graphs and graphs with bounded degree or eigenvalue multiplicity, its complexity class is still unknown. Information about potential isomorphisms between two graphs is contained in the eigenvalues and eigenvectors of their adjacency matrices. However, symmetries of graphs often lead to repeated eigenvalues so that associated eigenvectors are determined only up to basis rotations, which complicates graph isomorphism testing. We consider orthogonal and doubly stochastic relaxations of the graph isomorphism problem, analyze the geometric properties of the resulting solution spaces, and show that their complexity increases significantly if repeated eigenvalues exist. By restricting the search space to suitable subspaces, we derive an efficient Frank-Wolfe based continuous optimization approach for detecting isomorphisms. We illustrate the efficacy of the algorithm with the aid of various highly symmetric graphs.",
      "authors": [
        "Stefan Klus",
        "Patrick Gel{\\ss}"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-28T16:15:30+00:00",
          "link": "https://arxiv.org/abs/2311.16912v1",
          "size": "233kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T11:40:22+00:00",
          "link": "https://arxiv.org/abs/2311.16912v2",
          "size": "233kb",
          "version": "v2"
        }
      ],
      "title": "Continuous optimization methods for the graph isomorphism problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16912",
        "PDF": "https://arxiv.org/pdf/2311.16912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses continuous optimization methods for the graph isomorphism problem, and it does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04720",
      "abstract": "We study reconstructing and predicting 3D fluid appearance and velocity from a single video. Current methods require multi-view videos for fluid reconstruction. We present FluidNexus, a novel framework that bridges video generation and physics simulation to tackle this task. Our key insight is to synthesize multiple novel-view videos as references for reconstruction. FluidNexus consists of two key components: (1) a novel-view video synthesizer that combines frame-wise view synthesis with video diffusion refinement for generating realistic videos, and (2) a physics-integrated particle representation coupling differentiable simulation and rendering to simultaneously facilitate 3D fluid reconstruction and prediction. To evaluate our approach, we collect two new real-world fluid datasets featuring textured backgrounds and object interactions. Our method enables dynamic novel view synthesis, future prediction, and interaction simulation from a single fluid video. Project website: https://yuegao.me/FluidNexus.",
      "authors": [
        "Yue Gao",
        "Hong-Xing Yu",
        "Bo Zhu and Jiajun Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T18:59:06+00:00",
          "link": "https://arxiv.org/abs/2503.04720v1",
          "size": "27283kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T21:43:37+00:00",
          "link": "https://arxiv.org/abs/2503.04720v2",
          "size": "20894kb",
          "version": "v2"
        }
      ],
      "title": "FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04720",
        "HTML": "https://arxiv.org/html/2503.04720v2",
        "PDF": "https://arxiv.org/pdf/2503.04720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on fluid reconstruction from video data, which is unrelated to LLM training data processing."
      },
      "models": [
        {
          "model_path": "yuegao/FluidNexusModels",
          "downloads": "0",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/yuegao/FluidNexusModels"
        }
      ],
      "datasets": [
        {
          "dataset_name": "yuegao/FluidNexusDatasets",
          "downloads": "54",
          "likes": "1",
          "link": "https://huggingface.co/datasets/yuegao/FluidNexusDatasets"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Gao_FluidNexus_3D_Fluid_Reconstruction_and_Prediction_from_a_Single_Video_CVPR_2025_paper.html",
      "tasks": [
        "Future prediction",
        "Novel View Synthesis",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05385",
      "abstract": "We introduce EduCoder, a domain-specialized tool designed to support utterance-level annotation of educational dialogue. While general-purpose text annotation tools for NLP and qualitative research abound, few address the complexities of coding education dialogue transcripts -- with diverse teacher-student and peer interactions. Common challenges include defining codebooks for complex pedagogical features, supporting both open-ended and categorical coding, and contextualizing utterances with external features, such as the lesson's purpose and the pedagogical value of the instruction. EduCoder is designed to address these challenges by providing a platform for researchers and domain experts to collaboratively define complex codebooks based on observed data. It incorporates both categorical and open-ended annotation types along with contextual materials. Additionally, it offers a side-by-side comparison of multiple annotators' responses, allowing comparison and calibration of annotations with others to improve data reliability. The system is open-source, with a demo video available.",
      "authors": [
        "Guanzhong Pan",
        "Mei Tan",
        "Hyunji Nam",
        "Luc\\'ia Langlois",
        "James Malamut",
        "Liliana Deonizio",
        "Dorottya Demszky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:15:29+00:00",
          "link": "https://arxiv.org/abs/2507.05385v1",
          "size": "1776kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T18:40:00+00:00",
          "link": "https://arxiv.org/abs/2507.05385v2",
          "size": "1776kb",
          "version": "v2"
        }
      ],
      "title": "EduCoder: An Open-Source Annotation System for Education Transcript Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05385",
        "HTML": "https://arxiv.org/html/2507.05385v2",
        "PDF": "https://arxiv.org/pdf/2507.05385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces EduCoder, a tool for annotating educational dialogues. It involves some level of dataset annotation but does not primarily focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07288",
      "abstract": "Zeroth-order local optimisation algorithms are essential for solving real-valued black-box optimisation problems. Among these, Natural Evolution Strategies (NES) represent a prominent class, particularly well-suited for scenarios where prior distributions are available. By optimising the objective function in the space of search distributions, NES algorithms naturally integrate prior knowledge during initialisation, making them effective in settings such as semi-supervised learning and user-prior belief frameworks. However, due to their reliance on random sampling and Monte Carlo estimates, NES algorithms can suffer from limited sample efficiency. In this paper, we introduce a novel class of algorithms, termed Probabilistic Natural Evolutionary Strategy Algorithms (ProbNES), which enhance the NES framework with Bayesian quadrature. We show that ProbNES algorithms consistently outperforms their non-probabilistic counterparts as well as global sample efficient methods such as Bayesian Optimisation (BO) or $\\pi$BO across a wide range of tasks, including benchmark test functions, data-driven optimisation tasks, user-informed hyperparameter tuning tasks and locomotion tasks.",
      "authors": [
        "Pierre Osselin",
        "Masaki Adachi",
        "Xiaowen Dong",
        "Michael A. Osborne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:15:50+00:00",
          "link": "https://arxiv.org/abs/2507.07288v1",
          "size": "1276kb",
          "version": "v1"
        }
      ],
      "title": "Natural Evolutionary Search meets Probabilistic Numerics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07288",
        "HTML": "https://arxiv.org/html/2507.07288v1",
        "PDF": "https://arxiv.org/pdf/2507.07288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a class of algorithms enhancing natural evolution strategies, but it does not address any aspects of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07480",
      "abstract": "General program equivalence is undecidable. However, if we abstract away the semantics of statements, then this problem becomes not just decidable, but practically feasible. For instance, a program of the form \"if $b$ then $e$ else $f$\" should be equivalent to \"if not $b$ then $f$ else $e$\" - no matter what $b$, $e$ and $f$ are. This kind of equivalence is known as propositional equivalence. In this extended abstract, we discuss recent developments in propositional program equivalence from the perspective of (Guarded) Kleene Algebra with Tests, or (G)KAT.",
      "authors": [
        "Tobias Kapp\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:06:47+00:00",
          "link": "https://arxiv.org/abs/2507.07480v1",
          "size": "54kb",
          "version": "v1"
        }
      ],
      "title": "On Propositional Program Equivalence (extended abstract)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07480",
        "PDF": "https://arxiv.org/pdf/2507.07480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses propositional program equivalence using Kleene Algebra, which is unrelated to LLM training data processing, focusing instead on program semantics and equivalence."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07780",
      "abstract": "We conduct an extensive study on the state of calibration under real-world dataset shift for image classification. Our work provides important insights on the choice of post-hoc and in-training calibration techniques, and yields practical guidelines for all practitioners interested in robust calibration under shift. We compare various post-hoc calibration methods, and their interactions with common in-training calibration strategies (e.g., label smoothing), across a wide range of natural shifts, on eight different classification tasks across several imaging domains. We find that: (i) simultaneously applying entropy regularisation and label smoothing yield the best calibrated raw probabilities under dataset shift, (ii) post-hoc calibrators exposed to a small amount of semantic out-of-distribution data (unrelated to the task) are most robust under shift, (iii) recent calibration methods specifically aimed at increasing calibration under shifts do not necessarily offer significant improvements over simpler post-hoc calibration methods, (iv) improving calibration under shifts often comes at the cost of worsening in-distribution calibration. Importantly, these findings hold for randomly initialised classifiers, as well as for those finetuned from foundation models, the latter being consistently better calibrated compared to models trained from scratch. Finally, we conduct an in-depth analysis of ensembling effects, finding that (i) applying calibration prior to ensembling (instead of after) is more effective for calibration under shifts, (ii) for ensembles, OOD exposure deteriorates the ID-shifted calibration trade-off, (iii) ensembling remains one of the most effective methods to improve calibration robustness and, combined with finetuning from foundation models, yields best calibration results overall.",
      "authors": [
        "M\\'elanie Roschewitz",
        "Raghav Mehta",
        "Fabio de Sousa Ribeiro",
        "Ben Glocker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.07780v1",
          "size": "5704kb",
          "version": "v1"
        }
      ],
      "title": "Where are we with calibration under dataset shift in image classification?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07780",
        "HTML": "https://arxiv.org/html/2507.07780v1",
        "PDF": "https://arxiv.org/pdf/2507.07780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses calibration techniques under dataset shift for image classification and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.24030",
      "abstract": "Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.",
      "authors": [
        "Ziming Zhao",
        "ChengAo Shen",
        "Hanghang Tong",
        "Dongjin Song",
        "Zhigang Deng",
        "Qingsong Wen",
        "Jingchao Ni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T22:05:28+00:00",
          "link": "https://arxiv.org/abs/2505.24030v1",
          "size": "5758kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T22:13:37+00:00",
          "link": "https://arxiv.org/abs/2505.24030v2",
          "size": "5758kb",
          "version": "v2"
        }
      ],
      "title": "From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24030",
        "HTML": "https://arxiv.org/html/2505.24030v2",
        "PDF": "https://arxiv.org/pdf/2505.24030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of Large Vision Models for time series analysis, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Time Series",
        "Time Series Analysis",
        "Time Series Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02899",
      "abstract": "Vectorized maps are indispensable for precise navigation and the safe operation of autonomous vehicles. Traditional methods for constructing these maps fall into two categories: offline techniques, which rely on expensive, labor-intensive LiDAR data collection and manual annotation, and online approaches that use onboard cameras to reduce costs but suffer from limited performance, especially at complex intersections. To bridge this gap, we introduce MRC-VMap, a cost-effective, vision-centric, end-to-end neural network designed to generate high-definition vectorized maps directly at intersections. Leveraging existing roadside surveillance cameras, MRC-VMap directly converts time-aligned, multi-directional images into vectorized map representations. This integrated solution lowers the need for additional intermediate modules--such as separate feature extraction and Bird's-Eye View (BEV) conversion steps--thus reducing both computational overhead and error propagation. Moreover, the use of multiple camera views enhances mapping completeness, mitigates occlusions, and provides robust performance under practical deployment constraints. Extensive experiments conducted on 4,000 intersections across 4 major metropolitan areas in China demonstrate that MRC-VMap not only outperforms state-of-the-art online methods but also achieves accuracy comparable to high-cost LiDAR-based approaches, thereby offering a scalable and efficient solution for modern autonomous navigation systems.",
      "authors": [
        "Quanxin Zheng",
        "Miao Fan",
        "Shengtong Xu",
        "Linghe Kong",
        "Haoyi Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T04:29:08+00:00",
          "link": "https://arxiv.org/abs/2507.02899v1",
          "size": "2027kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:00:04+00:00",
          "link": "https://arxiv.org/abs/2507.02899v2",
          "size": "2026kb",
          "version": "v2"
        }
      ],
      "title": "Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02899",
        "HTML": "https://arxiv.org/html/2507.02899v2",
        "PDF": "https://arxiv.org/pdf/2507.02899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a neural network for generating vectorized maps for autonomous navigation, but does not involve any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07536",
      "abstract": "Characterizing graph properties is fundamental to the analysis and to our understanding of real-world networked systems. The local clustering coefficient, and the more recently introduced, local closure coefficient, capture powerful properties that are essential in a large number of applications, ranging from graph embeddings to graph partitioning. Such coefficients capture the local density of the neighborhood of each node, considering incident triadic structures and paths of length two. For this reason, we refer to these coefficients collectively as local triadic coefficients.\n  In this work, we consider the novel problem of computing efficiently the average of local triadic coefficients, over a given partition of the nodes of the input graph into a set of disjoint buckets. The average local triadic coefficients of the nodes in each bucket provide a better insight into the interplay of graph structure and the properties of the nodes associated to each bucket. Unfortunately, exact computation, which requires listing all triangles in a graph, is infeasible for large networks. Hence, we focus on obtaining highly-accurate probabilistic estimates.\n  We develop Triad, an adaptive algorithm based on sampling, which can be used to estimate the average local triadic coefficients for a partition of the nodes into buckets. Triad is based on a new class of unbiased estimators, and non-trivial bounds on its sample complexity, enabling the efficient computation of highly accurate estimates. Finally, we show how Triad can be efficiently used in practice on large networks, and we present a case study showing that average local triadic coefficients can capture high-order patterns over collaboration networks.",
      "authors": [
        "Ilie Sarpe and Aristides Gionis"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:33:35+00:00",
          "link": "https://arxiv.org/abs/2507.07536v1",
          "size": "5435kb",
          "version": "v1"
        }
      ],
      "title": "Efficient and Adaptive Estimation of Local Triadic Coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07536",
        "HTML": "https://arxiv.org/html/2507.07536v1",
        "PDF": "https://arxiv.org/pdf/2507.07536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimating local triadic coefficients in graph networks, which is unrelated to LLM training data processing. It does not address data preparation or data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07661",
      "abstract": "The applications of fingertip haptic devices have spread to various fields from revolutionizing virtual reality and medical training simulations to facilitating remote robotic operations, proposing great potential for enhancing user experiences, improving training outcomes, and new forms of interaction. In this work, we present FiDTouch, a 3D wearable haptic device that delivers cutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin stretch, and vibrotactile feedback. The application of a tiny inverted Delta robot in the mechanism design allows providing accurate contact and fast changing dynamic stimuli to the finger pad surface. The performance of the developed display was evaluated in a two-stage user study of the perception of static spatial contact stimuli and skin stretch stimuli generated on the finger pad. The proposed display, by providing users with precise touch and force stimuli, can enhance user immersion and efficiency in the fields of human-computer and human-robot interactions.",
      "authors": [
        "Daria Trinitatova and Dzmitry Tsetserukou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:36:27+00:00",
          "link": "https://arxiv.org/abs/2507.07661v1",
          "size": "2840kb",
          "version": "v1"
        }
      ],
      "title": "FiDTouch: A 3D Wearable Haptic Display for the Finger Pad",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07661",
        "HTML": "https://arxiv.org/html/2507.07661v1",
        "PDF": "https://arxiv.org/pdf/2507.07661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a 3D wearable haptic device for finger pad applications, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03575",
      "abstract": "Physical AI needs to be trained digitally first. It needs a digital twin of itself, the policy model, and a digital twin of the world, the world model. In this paper, we present the Cosmos World Foundation Model Platform to help developers build customized world models for their Physical AI setups. We position a world foundation model as a general-purpose world model that can be fine-tuned into customized world models for downstream applications. Our platform covers a video curation pipeline, pre-trained world foundation models, examples of post-training of pre-trained world foundation models, and video tokenizers. To help Physical AI builders solve the most critical problems of our society, we make Cosmos open-source and our models open-weight with permissive licenses available via https://github.com/nvidia-cosmos/cosmos-predict1.",
      "authors": [
        "NVIDIA: Niket Agarwal",
        "Arslan Ali",
        "Maciej Bala",
        "Yogesh Balaji",
        "Erik Barker",
        "Tiffany Cai",
        "Prithvijit Chattopadhyay",
        "Yongxin Chen",
        "Yin Cui",
        "Yifan Ding",
        "Daniel Dworakowski",
        "Jiaojiao Fan",
        "Michele Fenzi",
        "Francesco Ferroni",
        "Sanja Fidler",
        "Dieter Fox",
        "Songwei Ge",
        "Yunhao Ge",
        "Jinwei Gu",
        "Siddharth Gururani",
        "Ethan He",
        "Jiahui Huang",
        "Jacob Huffman",
        "Pooya Jannaty",
        "Jingyi Jin",
        "Seung Wook Kim",
        "Gergely Kl\\'ar",
        "Grace Lam",
        "Shiyi Lan",
        "Laura Leal-Taixe",
        "Anqi Li",
        "Zhaoshuo Li",
        "Chen-Hsuan Lin",
        "Tsung-Yi Lin",
        "Huan Ling",
        "Ming-Yu Liu",
        "Xian Liu",
        "Alice Luo",
        "Qianli Ma",
        "Hanzi Mao",
        "Kaichun Mo",
        "Arsalan Mousavian",
        "Seungjun Nah",
        "Sriharsha Niverty",
        "David Page",
        "Despoina Paschalidou",
        "Zeeshan Patel",
        "Lindsey Pavao",
        "Morteza Ramezanali",
        "Fitsum Reda",
        "Xiaowei Ren",
        "Vasanth Rao Naik Sabavat",
        "Ed Schmerling",
        "Stella Shi",
        "Bartosz Stefaniak",
        "Shitao Tang",
        "Lyne Tchapmi",
        "Przemek Tredak",
        "Wei-Cheng Tseng",
        "Jibin Varghese",
        "Hao Wang",
        "Haoxiang Wang",
        "Heng Wang",
        "Ting-Chun Wang",
        "Fangyin Wei",
        "Xinyue Wei",
        "Jay Zhangjie Wu",
        "Jiashu Xu",
        "Wei Yang",
        "Lin Yen-Chen",
        "Xiaohui Zeng",
        "Yu Zeng",
        "Jing Zhang",
        "Qinsheng Zhang",
        "Yuxuan Zhang",
        "Qingqing Zhao",
        "Artur Zolkowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T06:55:50+00:00",
          "link": "https://arxiv.org/abs/2501.03575v1",
          "size": "39990kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T16:59:07+00:00",
          "link": "https://arxiv.org/abs/2501.03575v2",
          "size": "41065kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:35:31+00:00",
          "link": "https://arxiv.org/abs/2501.03575v3",
          "size": "41036kb",
          "version": "v3"
        }
      ],
      "title": "Cosmos World Foundation Model Platform for Physical AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03575",
        "HTML": "https://arxiv.org/html/2501.03575v3",
        "PDF": "https://arxiv.org/pdf/2501.03575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a platform for building world models which includes aspects like video curation and tokenization, but focuses more on the model architecture (world foundation model) rather than on LLM training data processing directly."
      },
      "models": [
        {
          "model_path": "nvidia/Cosmos-1.0-Autoregressive-4B",
          "downloads": "17",
          "likes": "52",
          "trending_score": "2.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-4B"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Tokenizer-CV8x8x8",
          "downloads": "2966",
          "likes": "20",
          "trending_score": "1.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Tokenizer-CV8x8x8"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Tokenizer-DV8x16x16",
          "downloads": "87",
          "likes": "15",
          "trending_score": "1.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Tokenizer-DV8x16x16"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Prompt-Upsampler-12B-Text2World",
          "downloads": "112",
          "likes": "13",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Prompt-Upsampler-12B-Text2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Diffusion-7B-Video2World",
          "downloads": "16735",
          "likes": "37",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Diffusion-14B-Text2World",
          "downloads": "1071",
          "likes": "59",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Text2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Diffusion-14B-Video2World",
          "downloads": "6253",
          "likes": "57",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Autoregressive-13B-Video2World",
          "downloads": "23",
          "likes": "31",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-13B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Autoregressive-12B",
          "downloads": "16",
          "likes": "30",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-12B"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Autoregressive-5B-Video2World",
          "downloads": "17",
          "likes": "30",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-5B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Guardrail",
          "downloads": "1759",
          "likes": "54",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Guardrail"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Diffusion-7B-Decoder-DV8x16x16ToCV8x8x8",
          "downloads": "16",
          "likes": "9",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Decoder-DV8x16x16ToCV8x8x8"
        },
        {
          "model_path": "nvidia/Cosmos-1.0-Diffusion-7B-Text2World",
          "downloads": "2678",
          "likes": "223",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Text2World"
        },
        {
          "model_path": "EthanZyh/DiffusionText2WorldGeneration",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/EthanZyh/DiffusionText2WorldGeneration"
        },
        {
          "model_path": "Nvidia-CMU25/DiffusionVideo2WorldGeneration",
          "downloads": "11",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Nvidia-CMU25/DiffusionVideo2WorldGeneration"
        },
        {
          "model_path": "Nvidia-CMU25/AutoregressiveBase",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Nvidia-CMU25/AutoregressiveBase"
        },
        {
          "model_path": "Nvidia-CMU25/DiffusionText2WorldGeneration",
          "downloads": "8",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Nvidia-CMU25/DiffusionText2WorldGeneration"
        },
        {
          "model_path": "Nvidia-CMU25/ARVideo2WorldGeneration",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Nvidia-CMU25/ARVideo2WorldGeneration"
        },
        {
          "model_path": "NeverMore0123/AutoregressiveVideo2WorldGeneration",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/NeverMore0123/AutoregressiveVideo2WorldGeneration"
        },
        {
          "model_path": "Nvidia-CMU25/AutoregressiveFutureWorld",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Nvidia-CMU25/AutoregressiveFutureWorld"
        },
        {
          "model_path": "appmana/Cosmos-1.0-Prompt-Upsampler-12B-Text2World-hf",
          "downloads": "15",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/appmana/Cosmos-1.0-Prompt-Upsampler-12B-Text2World-hf"
        },
        {
          "model_path": "nvidia/Cosmos-Transfer1-7B-Sample-AV",
          "downloads": "4399",
          "likes": "14",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Transfer1-7B-Sample-AV"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Text2World-Sample-AV-Multiview",
          "downloads": "1512",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Text2World-Sample-AV-Multiview"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Video2World-Sample-AV-Multiview",
          "downloads": "76",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Video2World-Sample-AV-Multiview"
        },
        {
          "model_path": "nvidia/Cosmos-Guardrail1",
          "downloads": "809",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Guardrail1"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Text2World",
          "downloads": "228",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Text2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Video2World",
          "downloads": "480",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-14B-Text2World",
          "downloads": "133",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-14B-Text2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-14B-Video2World",
          "downloads": "137",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-14B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-4B",
          "downloads": "64",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-4B"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-12B",
          "downloads": "34",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-12B"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-13B-Video2World",
          "downloads": "35",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-13B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-5B-Video2World",
          "downloads": "61",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-5B-Video2World"
        },
        {
          "model_path": "nvidia/Cosmos-UpsamplePrompt1-12B-Text2World",
          "downloads": "335",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-UpsamplePrompt1-12B-Text2World"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Decoder-DV8x16x16ToCV8x8x8-720p",
          "downloads": "132",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Decoder-DV8x16x16ToCV8x8x8-720p"
        },
        {
          "model_path": "nvidia/Cosmos-UpsamplePrompt1-12B-Transfer",
          "downloads": "0",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-UpsamplePrompt1-12B-Transfer"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-WorldInterpolator",
          "downloads": "442",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-WorldInterpolator"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-CI8x8-360p",
          "downloads": "26",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-CI8x8-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-CI16x16-360p",
          "downloads": "36",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-CI16x16-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-CV4x8x8-360p",
          "downloads": "29",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-CV4x8x8-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-DI8x8-360p",
          "downloads": "32",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-DI8x8-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-DI16x16-360p",
          "downloads": "38",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-DI16x16-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-DV4x8x8-360p",
          "downloads": "42",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-DV4x8x8-360p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-CV8x8x8-720p",
          "downloads": "4412",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-CV8x8x8-720p"
        },
        {
          "model_path": "nvidia/Cosmos-Tokenize1-DV8x16x16-720p",
          "downloads": "94",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Tokenize1-DV8x16x16-720p"
        },
        {
          "model_path": "nvidia/Cosmos-Predict1-7B-Video2World-Sample-AV-Single2MultiView",
          "downloads": "40",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Predict1-7B-Video2World-Sample-AV-Single2MultiView"
        },
        {
          "model_path": "nvidia/Cosmos-Transfer1-7B-Sample-AV-Single2MultiView",
          "downloads": "4985",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/nvidia/Cosmos-Transfer1-7B-Sample-AV-Single2MultiView"
        }
      ],
      "tasks": [
        "model",
        "Position"
      ],
      "repo_urls": [
        "https://github.com/nvidia-cosmos/cosmos-transfer1",
        "https://github.com/nvidia/cosmos-tokenizer",
        "https://github.com/nvidia-cosmos/cosmos-predict1",
        "https://github.com/nvlabs/tokenbench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07307",
      "abstract": "Large language models (LLMs) incorporated with Retrieval-Augmented Generation (RAG) have demonstrated powerful capabilities in generating counterspeech against misinformation. However, current studies rely on limited evidence and offer less control over final outputs. To address these challenges, we propose a Multi-agent Retrieval-Augmented Framework to generate counterspeech against health misinformation, incorporating multiple LLMs to optimize knowledge retrieval, evidence enhancement, and response refinement. Our approach integrates both static and dynamic evidence, ensuring that the generated counterspeech is relevant, well-grounded, and up-to-date. Our method outperforms baseline approaches in politeness, relevance, informativeness, and factual accuracy, demonstrating its effectiveness in generating high-quality counterspeech. To further validate our approach, we conduct ablation studies to verify the necessity of each component in our framework. Furthermore, human evaluations reveal that refinement significantly enhances counterspeech quality and obtains human preference.",
      "authors": [
        "Anirban Saha Anik",
        "Xiaoying Song",
        "Elliott Wang",
        "Bryan Wang",
        "Bengisu Yarimbas",
        "Lingzi Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:10:06+00:00",
          "link": "https://arxiv.org/abs/2507.07307v1",
          "size": "188kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07307",
        "HTML": "https://arxiv.org/html/2507.07307v1",
        "PDF": "https://arxiv.org/pdf/2507.07307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for generating counterspeech using LLMs with augmented retrieval. The focus is on speech generation techniques, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07792",
      "abstract": "The state space dynamics representation is the most general approach for nonlinear systems and often chosen for system identification. During training, the state trajectory can deform significantly leading to poor data coverage of the state space. This can cause significant issues for space-oriented training algorithms which e.g. rely on grid structures, tree partitioning, or similar. Besides hindering training, significant state trajectory deformations also deteriorate interpretability and robustness properties. This paper proposes a new type of space-filling regularization that ensures a favorable data distribution in state space via introducing a data-distribution-based penalty. This method is demonstrated in local model network architectures where good interpretability is a major concern. The proposed approach integrates ideas from modeling and design of experiments for state space structures. This is why we present two regularization techniques for the data point distributions of the state trajectories for local affine state space models. Beyond that, we demonstrate the results on a widely known system identification benchmark.",
      "authors": [
        "Hermann Klein",
        "Max Heinz Herkersdorf and Oliver Nelles"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:19:29+00:00",
          "link": "https://arxiv.org/abs/2507.07792v1",
          "size": "306kb",
          "version": "v1"
        }
      ],
      "title": "Space-Filling Regularization for Robust and Interpretable Nonlinear State Space Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07792",
        "PDF": "https://arxiv.org/pdf/2507.07792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes regularization techniques for nonlinear state space models focusing on system identification and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02987",
      "abstract": "Building generalizable medical AI systems requires pretraining strategies that are data-efficient and domain-aware. Unlike internet-scale corpora, clinical datasets such as MIMIC-CXR offer limited image counts and scarce annotations, but exhibit rich internal structure through multi-view imaging. We propose a self-supervised framework that leverages the inherent structure of medical datasets. Specifically, we treat paired chest X-rays (i.e., frontal and lateral views) as natural positive pairs, learning to reconstruct each view from sparse patches while aligning their latent embeddings. Our method requires no textual supervision and produces informative representations. Evaluated on MIMIC-CXR, we show strong performance compared to supervised objectives and baselines being trained without leveraging structure. This work provides a lightweight, modality-agnostic blueprint for domain-specific pretraining where data is structured but scarce",
      "authors": [
        "Andrea Agostini",
        "Sonia Laguna",
        "Alain Ryser",
        "Samuel Ruiperez-Campillo",
        "Moritz Vandenhirtz",
        "Nicolas Deperrois",
        "Farhad Nooralahzadeh",
        "Michael Krauthammer",
        "Thomas M. Sutter",
        "Julia E. Vogt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.02987v1",
          "size": "3596kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:45:03+00:00",
          "link": "https://arxiv.org/abs/2507.02987v2",
          "size": "3596kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging the Structure of Medical Data for Improved Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02987",
        "HTML": "https://arxiv.org/html/2507.02987v2",
        "PDF": "https://arxiv.org/pdf/2507.02987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses leveraging structured data for pretraining to improve medical AI systems, focusing on generalizable representation learning rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07313",
      "abstract": "While state-of-the-art large language models (LLMs) demonstrate advanced reasoning capabilities-achieving remarkable performance on challenging competitive math and coding benchmarks-they also frequently fail on tasks that are easy for humans. This work studies the performance of frontier LLMs on a broad set of such \"easy\" reasoning problems. By extending previous work in the literature, we create a suite of procedurally generated simple reasoning tasks, including counting, first-order logic, proof trees, and travel planning, with changeable parameters (such as document length. or the number of variables in a math problem) that can arbitrarily increase the amount of computation required to produce the answer while preserving the fundamental difficulty. While previous work showed that traditional, non-thinking models can be made to fail on such problems, we demonstrate that even state-of-the-art thinking models consistently fail on such problems and for similar reasons (e.g. statistical shortcuts, errors in intermediate steps, and difficulties in processing long contexts). To further understand the behavior of the models, we introduce the unpuzzles dataset, a different \"easy\" benchmark consisting of trivialized versions of well-known math and logic puzzles. Interestingly, while modern LLMs excel at solving the original puzzles, they tend to fail on the trivialized versions, exhibiting several systematic failure patterns related to memorizing the originals. We show that this happens even if the models are otherwise able to solve problems with different descriptions but requiring the same logic. Our results highlight that out-of-distribution generalization is still problematic for frontier language models and the new generation of thinking models, even for simple reasoning tasks, and making tasks easier does not necessarily imply improved performance.",
      "authors": [
        "Alan Malek",
        "Jiawei Ge",
        "Jiawei Ge",
        "Chi Jin",
        "Andr\\'as Gy\\\"orgy",
        "Csaba Szepesv\\'ari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:22:49+00:00",
          "link": "https://arxiv.org/abs/2507.07313v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "Frontier LLMs Still Struggle with Simple Reasoning Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07313",
        "HTML": "https://arxiv.org/html/2507.07313v1",
        "PDF": "https://arxiv.org/pdf/2507.07313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the performance of LLMs on reasoning tasks and creates a dataset for evaluation, but it focuses on task generation and model evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07337",
      "abstract": "We propose an equivalent formula for the higher-order derivatives used in the study of Generalized Almost Perfect Nonlinear functions over an arbitrary finite field of characteristic $p$. The result is obtained by counting the number of subsets of the prime field with a fixed cardinality for which the sum of their elements is constant. We then ask related questions regarding the diversity of higher-order derivatives.",
      "authors": [
        "Valentin Suder"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.07337v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "An Equivalent Representation of Generalized Differentials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07337",
        "HTML": "https://arxiv.org/html/2507.07337v1",
        "PDF": "https://arxiv.org/pdf/2507.07337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a mathematical study on generalized differentials, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07342",
      "abstract": "This paper addresses the problem of maximizing the received power at a user equipment via reconfigurable intelligent surface (RIS) characterized by phase-dependent amplitude (PDA) and discrete phase shifts over a limited phase range. Given complex RIS coefficients, that is, discrete phase shifts and PDAs, we derive the necessary and sufficient conditions to achieve the optimal solution. To this end, we propose an optimal search algorithm that is proven to converge in linear time within at most NK steps, significantly outperforming the exhaustive search approach that would otherwise be needed for RISs with amplitude attenuation. Furthermore, we introduce a practical quantization framework for PDA-introduced RISs termed amplitude-introduced polar quantization (APQ), and extend it to a novel algorithm named extended amplitude-introduced polar quantization (EAPQ) that works with geometric projections. We derive closed-form expressions to assess how closely the performance of the proposed RIS configuration can approximate the ideal case with continuous phases and no attenuation. Our analysis reveals that increasing the number of discrete phases beyond K = 4 yields only marginal gains, regardless of attenuation levels, provided the RIS has a sufficiently wide phase range R. Furthermore, we also show and quantify that when the phase range R is limited, the performance is sensitive to attenuation for larger R, and sensitive to R when there is less attenuation. Finally, the proposed optimal algorithm provides a generic upper bound that could serve as a benchmark for discrete beamforming in RISs with amplitude constraints.",
      "authors": [
        "Dogan Kutay Pekcan",
        "Hongyi Liao",
        "Ender Ayanoglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.07342v1",
          "size": "1173kb",
          "version": "v1"
        }
      ],
      "title": "Discrete Beamforming Optimization for RISs with a Limited Phase Range and Amplitude Attenuation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07342",
        "HTML": "https://arxiv.org/html/2507.07342v1",
        "PDF": "https://arxiv.org/pdf/2507.07342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on beamforming optimization for reconfigurable intelligent surfaces, unrelated to any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07421",
      "abstract": "Eviction is a significant yet understudied social determinants of health (SDoH), linked to housing instability, unemployment, and mental health. While eviction appears in unstructured electronic health records (EHRs), it is rarely coded in structured fields, limiting downstream applications. We introduce SynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop annotation, and automated prompt optimization (APO) to extract eviction statuses from clinical notes. Using this pipeline, we created the largest public eviction-related SDoH dataset to date, comprising 14 fine-grained categories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on SynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other SDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%), GPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling cost-effective deployment across various model sizes. The pipeline reduces annotation effort by over 80%, accelerates dataset creation, enables scalable eviction detection, and generalizes to other information extraction tasks.",
      "authors": [
        "Zonghai Yao",
        "Youxia Zhao",
        "Avijit Mitra",
        "David A. Levy",
        "Emily Druhl",
        "Jack Tsai",
        "Hong Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.07421v1",
          "size": "1832kb",
          "version": "v1"
        }
      ],
      "title": "SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07421",
        "HTML": "https://arxiv.org/html/2507.07421v1",
        "PDF": "https://arxiv.org/pdf/2507.07421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The SynthEHR-Eviction paper describes a data processing pipeline involving LLMs to create a new synthetic EHR dataset. The process includes significant efforts like data extraction, annotation, and optimization that are central to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07557",
      "abstract": "In signal processing and data recovery, reconstructing a signal from quadratic measurements poses a significant challenge, particularly in high-dimensional settings where measurements $m$ is far less than the signal dimension $n$ (i.e., $m \\ll n$). This paper addresses this problem by exploiting signal sparsity. Using tools from algebraic geometry, we derive theoretical recovery guarantees for sparse quadratic systems, showing that $m\\ge 2s$ (real case) and $m\\ge 4s-2$ (complex case) generic measurements suffice to uniquely recover all $s$-sparse signals. Under a Gaussian measurement model, we propose a novel two-stage Sparse Gauss-Newton (SGN) algorithm. The first stage employs a support-restricted spectral initialization, yielding an accurate initial estimate with $m=O(s^2\\log{n})$ measurements. The second stage refines this estimate via an iterative hard-thresholding Gauss-Newton method, achieving quadratic convergence to the true signal within finitely many iterations when $m\\ge O(s\\log{n})$. Compared to existing second-order methods, our algorithm achieves near-optimal sampling complexity for the refinement stage without requiring resampling. Numerical experiments indicate that SGN significantly outperforms state-of-the-art algorithms in both accuracy and computational efficiency. In particular, (1) when sparsity level $s$ is high, compared with existing algorithms, SGN can achieve the same success rate with fewer measurements. (2) SGN converges with only about $1/10$ iterations of the best existing algorithm and reach lower relative error.",
      "authors": [
        "Jinming Wen",
        "Yi Hu",
        "Meng Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:56:11+00:00",
          "link": "https://arxiv.org/abs/2507.07557v1",
          "size": "629kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Signal Recovery From Quadratic Systems with Full-Rank Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07557",
        "HTML": "https://arxiv.org/html/2507.07557v1",
        "PDF": "https://arxiv.org/pdf/2507.07557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses signal recovery from quadratic systems, focusing on algorithm development for sparse signals without mentioning LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07902",
      "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced AI-assisted medical diagnosis, but they often generate factually inconsistent responses that deviate from established medical knowledge. Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external sources, but it presents two key challenges. First, insufficient retrieval can miss critical information, whereas excessive retrieval can introduce irrelevant or misleading content, disrupting model output. Second, even when the model initially provides correct answers, over-reliance on retrieved data can lead to factual errors. To address these issues, we introduce the Multimodal Intelligent Retrieval and Augmentation (MIRA) framework, designed to optimize factual accuracy in MLLM. MIRA consists of two key components: (1) a calibrated Rethinking and Rearrangement module that dynamically adjusts the number of retrieved contexts to manage factual risk, and (2) A medical RAG framework integrating image embeddings and a medical knowledge base with a query-rewrite module for efficient multimodal reasoning. This enables the model to effectively integrate both its inherent knowledge and external references. Our evaluation of publicly available medical VQA and report generation benchmarks demonstrates that MIRA substantially enhances factual accuracy and overall performance, achieving new state-of-the-art results. Code is released at https://github.com/mbzuai-oryx/MIRA.",
      "authors": [
        "Jinhong Wang",
        "Tajamul Ashraf",
        "Zongyan Han",
        "Jorma Laaksonen",
        "Rao Mohammad Anwer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:33:50+00:00",
          "link": "https://arxiv.org/abs/2507.07902v1",
          "size": "19404kb",
          "version": "v1"
        }
      ],
      "title": "MIRA: A Novel Framework for Fusing Modalities in Medical RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07902",
        "HTML": "https://arxiv.org/html/2507.07902v1",
        "PDF": "https://arxiv.org/pdf/2507.07902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing factual accuracy in Multimodal Large Language Models (MLLMs) using the MIRA framework but does not discuss any specific LLM training data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.06554",
      "abstract": "Reliability of sequential hypothesis testing can be greatly improved when the decision maker is given the freedom to adaptively take an action that determines the distribution of the current collected sample. Such advantage of sampling adaptivity has been realized since Chernoff's seminal paper in 1959 [1]. While a large body of works have explored and investigated the gain of adaptivity, in the general multiple-hypothesis setting, the fundamental limits of individual error probabilities have not been fully understood. In particular, in the asymptotic regime as the expected stopping time tends to infinity, the error exponents are only characterized in specific cases, such as that of the total error probability. In this paper, we consider a general setup of active sequential multiple-hypothesis testing where at each time slot, a temporally varying subset of data sources (out of a known set) emerges from which the decision maker can select to collect samples, subject to a family of expected selection budget constraints. The selection of sources, understood as the ``action'' at each time slot, is constrained in a predefined action space. At the end of each time slot, the decision maker either decides to make the inference on the $M$ hypotheses, or continues to observe the data sources for the next time slot. The optimal tradeoffs among $M(M-1)$ types of error exponents are characterized. A companion asymptotically optimal test that strikes the balance between exploration and exploitation is proposed to achieve any target error exponents within the region. To the best of our knowledge, this is the first time in the literature to identify such tradeoffs among error exponents in active sequential hypothesis testing, and it uncovers the tension among different action taking policies even in the basic setting of Chernoff [1].",
      "authors": [
        "Chia-Yu Hsu and I-Hsiang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-10T15:56:08+00:00",
          "link": "https://arxiv.org/abs/2405.06554v1",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T18:04:20+00:00",
          "link": "https://arxiv.org/abs/2405.06554v2",
          "size": "51kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:17:19+00:00",
          "link": "https://arxiv.org/abs/2405.06554v3",
          "size": "1625kb",
          "version": "v3"
        }
      ],
      "title": "Tradeoffs among Action Taking Policies Matter in Active Sequential Multi-Hypothesis Testing: the Optimal Error Exponent Region",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.06554",
        "HTML": "https://arxiv.org/html/2405.06554v3",
        "PDF": "https://arxiv.org/pdf/2405.06554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on sequential hypothesis testing and decision-making policies, with no discussion on processing LLM training data or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14446",
      "abstract": "Time series play a fundamental role in many domains, capturing a plethora of information about the underlying data-generating processes. When a process generates multiple synchronized signals we are faced with multidimensional time series. In this context a fundamental problem is that of motif mining, where we seek patterns repeating twice with minor variations, spanning some of the dimensions. State of the art exact solutions for this problem run in time quadratic in the length of the input time series.\n  We provide a scalable method to find the top-k motifs in multidimensional time series with probabilistic guarantees on the quality of the results. Our algorithm runs in time subquadratic in the length of the input, and returns the exact solution with probability at least $1-\\delta$, where $\\delta$ is a user-defined parameter. The algorithm is designed to be adaptive to the input distribution, self-tuning its parameters while respecting user-defined limits on the memory to use.\n  Our theoretical analysis is complemented by an extensive experimental evaluation, showing that our algorithm is orders of magnitude faster than the state of the art.",
      "authors": [
        "Matteo Ceccarello",
        "Francesco Pio Monaco",
        "Francesco Silvestri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T10:55:39+00:00",
          "link": "https://arxiv.org/abs/2502.14446v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T11:57:55+00:00",
          "link": "https://arxiv.org/abs/2502.14446v2",
          "size": "1023kb",
          "version": "v2"
        }
      ],
      "title": "MOMENTI: Scalable Motif Mining in Multidimensional Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14446",
        "HTML": "https://arxiv.org/html/2502.14446",
        "PDF": "https://arxiv.org/pdf/2502.14446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motif mining in multidimensional time series, which doesn't relate to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/aidaLabDEI/LEIT-motifs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05110",
      "abstract": "Logical rule learning, a prominent category of knowledge graph (KG) reasoning methods, constitutes a critical research area aimed at learning explicit rules from observed facts to infer missing knowledge. However, like all KG reasoning methods, rule learning suffers from a critical weakness-its dependence on the I.I.D. assumption. This assumption can easily be violated due to selection bias during training or agnostic distribution shifts during testing (e.g., as in query shift scenarios), ultimately undermining model performance and reliability. To enable robust KG reasoning in wild environments, this study investigates logical rule learning in the presence of agnostic test-time distribution shifts. We formally define this challenge as out-of-distribution (OOD) KG reasoning-a previously underexplored problem, and propose the Stable Rule Learning (StableRule) framework as a solution. StableRule is an end-to-end framework that combines feature decorrelation with rule learning network, to enhance OOD generalization in KG reasoning. By leveraging feature decorrelation, StableRule mitigates the adverse effects of covariate shifts arising in OOD scenarios, improving the robustness of the rule learning network. Extensive experiments on seven benchmark KGs demonstrate the framework's superior effectiveness and stability across diverse heterogeneous environments, highlighting its practical significance for real-world applications.",
      "authors": [
        "Shixuan Liu",
        "Yue He",
        "Yunfei Wang",
        "Hao Zou",
        "Haoxiang Cheng",
        "Wenjing Yang",
        "Peng Cui",
        "Zhong Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:27:48+00:00",
          "link": "https://arxiv.org/abs/2507.05110v1",
          "size": "5623kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T03:40:07+00:00",
          "link": "https://arxiv.org/abs/2507.05110v2",
          "size": "5623kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.05110v3",
          "size": "5624kb",
          "version": "v3"
        }
      ],
      "title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05110",
        "HTML": "https://arxiv.org/html/2507.05110v3",
        "PDF": "https://arxiv.org/pdf/2507.05110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rule learning for knowledge graphs under distribution shifts, addressing KG reasoning robustness but does not contribute to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07142",
      "abstract": "This article presents a comparative analysis of g2o and Ceres solvers in enhancing scan matching performance within the Cartographer framework. Cartographer, a widely-used library for Simultaneous Localization and Mapping (SLAM), relies on optimization algorithms to refine pose estimates and improve map accuracy. The research aims to evaluate the performance, efficiency, and accuracy of the g2o solver in comparison to the Ceres solver, which is the default in Cartographer. In our experiments comparing Ceres and g2o within Cartographer, Ceres outperformed g2o in terms of speed, convergence efficiency, and overall map clarity. Ceres required fewer iterations and less time to converge, producing more accurate and well-defined maps, especially in real-world mapping scenarios with the AgileX LIMO robot. However, g2o excelled in localized obstacle detection, highlighting its value in specific situations.",
      "authors": [
        "Quanjie Qiu and MengCheng Lau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.07142v1",
          "size": "3826kb",
          "version": "v1"
        }
      ],
      "title": "g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07142",
        "HTML": "https://arxiv.org/html/2507.07142v1",
        "PDF": "https://arxiv.org/pdf/2507.07142"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a comparative analysis of optimization solvers for SLAM, unrelated to processing LLM training data or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07551",
      "abstract": "The accelerating growth of photographic collections has outpaced manual cataloguing, motivating the use of vision language models (VLMs) to automate metadata generation. This study examines whether Al-generated catalogue descriptions can approximate human-written quality and how generative Al might integrate into cataloguing workflows in archival and museum collections. A VLM (InternVL2) generated catalogue descriptions for photographic prints on labelled cardboard mounts with archaeological content, evaluated by archive and archaeology experts and non-experts in a human-centered, experimental framework. Participants classified descriptions as AI-generated or expert-written, rated quality, and reported willingness to use and trust in AI tools. Classification performance was above chance level, with both groups underestimating their ability to detect Al-generated descriptions. OCR errors and hallucinations limited perceived quality, yet descriptions rated higher in accuracy and usefulness were harder to classify, suggesting that human review is necessary to ensure the accuracy and quality of catalogue descriptions generated by the out-of-the-box model, particularly in specialized domains like archaeological cataloguing. Experts showed lower willingness to adopt AI tools, emphasizing concerns on preservation responsibility over technical performance. These findings advocate for a collaborative approach where AI supports draft generation but remains subordinate to human verification, ensuring alignment with curatorial values (e.g., provenance, transparency). The successful integration of this approach depends not only on technical advancements, such as domain-specific fine-tuning, but even more on establishing trust among professionals, which could both be fostered through a transparent and explainable AI pipeline.",
      "authors": [
        "Line Abele",
        "Gerrit Anders",
        "Tolgahan Ayd{\\i}n",
        "J\\\"urgen Buder",
        "Helen Fischer",
        "Dominik Kimmel",
        "Markus Huff"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:49:15+00:00",
          "link": "https://arxiv.org/abs/2507.07551v1",
          "size": "5631kb",
          "version": "v1"
        }
      ],
      "title": "ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07551",
        "PDF": "https://arxiv.org/pdf/2507.07551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates the performance of a vision language model for image cataloguing but does not focus on processing LLM training data. It mentions domain-specific fine-tuning but primarily analyzes AI-generated catalogue descriptions for validation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07708",
      "abstract": "Local motion blur in digital images originates from the relative motion between dynamic objects and static imaging systems during exposure. Existing deblurring methods face significant challenges in addressing this problem due to their inefficient allocation of computational resources and inadequate handling of spatially varying blur patterns. To overcome these limitations, we first propose a trainable mask predictor that identifies blurred regions in the image. During training, we employ blur masks to exclude sharp regions. For inference optimization, we implement structural reparameterization by converting $3\\times 3$ convolutions to computationally efficient $1\\times 1$ convolutions, enabling pixel-level pruning of sharp areas to reduce computation. Second, we develop an intra-frame motion analyzer that translates relative pixel displacements into motion trajectories, establishing adaptive guidance for region-specific blur restoration. Our method is trained end-to-end using a combination of reconstruction loss, reblur loss, and mask loss guided by annotated blur masks. Extensive experiments demonstrate superior performance over state-of-the-art methods on both local and global blur datasets while reducing FLOPs by 49\\% compared to SOTA models (e.g., LMD-ViT). The source code is available at https://github.com/shangwei5/M2AENet.",
      "authors": [
        "Wei Shang",
        "Dongwei Ren",
        "Wanying Zhang",
        "Pengfei Zhu",
        "Qinghua Hu",
        "Wangmeng Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:38:27+00:00",
          "link": "https://arxiv.org/abs/2507.07708v1",
          "size": "20776kb",
          "version": "v1"
        }
      ],
      "title": "Motion-Aware Adaptive Pixel Pruning for Efficient Local Motion Deblurring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07708",
        "HTML": "https://arxiv.org/html/2507.07708v1",
        "PDF": "https://arxiv.org/pdf/2507.07708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on efficient local motion deblurring using adaptive pixel pruning, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07140",
      "abstract": "Merging parameter-efficient task experts has recently gained growing attention as a way to build modular architectures that can be rapidly adapted on the fly for specific downstream tasks, without requiring additional fine-tuning. Typically, LoRA serves as the foundational building block of such parameter-efficient modular architectures, leveraging low-rank weight structures to reduce the number of trainable parameters. In this paper, we study the properties of sparse adapters, which train only a subset of weights in the base neural network, as potential building blocks of modular architectures. First, we propose a simple method for training highly effective sparse adapters, which is conceptually simpler than existing methods in the literature and surprisingly outperforms both LoRA and full fine-tuning in our setting. Next, we investigate the merging properties of these sparse adapters by merging adapters for up to 20 natural language processing tasks, thus scaling beyond what is usually studied in the literature. Our findings demonstrate that sparse adapters yield superior in-distribution performance post-merging compared to LoRA or full model merging. Achieving strong held-out performance remains a challenge for all methods considered.",
      "authors": [
        "Samin Yeasar Arnob",
        "Zhan Su",
        "Minseon Kim",
        "Oleksiy Ostapenko",
        "Riyasat Ohib",
        "Esra'a Saleh",
        "Doina Precup",
        "Lucas Caccia",
        "Alessandro Sordoni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:25:45+00:00",
          "link": "https://arxiv.org/abs/2507.07140v1",
          "size": "811kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07140",
        "HTML": "https://arxiv.org/html/2507.07140v1",
        "PDF": "https://arxiv.org/pdf/2507.07140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sparse adapters for model adaptation, which is related to modular architectures and efficient adaptation, rather than processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07613",
      "abstract": "Federated Learning offers privacy-preserving collaborative intelligence but struggles to meet the sustainability demands of emerging IoT ecosystems necessary for Society 5.0-a human-centered technological future balancing social advancement with environmental responsibility. The excessive communication bandwidth and computational resources required by traditional FL approaches make them environmentally unsustainable at scale, creating a fundamental conflict with green AI principles as billions of resource-constrained devices attempt to participate. To this end, we introduce Sparse Proximity-based Self-Federated Learning (SParSeFuL), a resource-aware approach that bridges this gap by combining aggregate computing for self-organization with neural network sparsification to reduce energy and bandwidth consumption.",
      "authors": [
        "Davide Domini",
        "Laura Erhan",
        "Gianluca Aguzzi",
        "Lucia Cavallaro",
        "Amirhossein Douzandeh Zenoozi",
        "Antonio Liotta",
        "Mirko Viroli"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:32:42+00:00",
          "link": "https://arxiv.org/abs/2507.07613v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Self-Federated Learning for Energy Efficient Cooperative Intelligence in Society 5.0",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07613",
        "HTML": "https://arxiv.org/html/2507.07613v1",
        "PDF": "https://arxiv.org/pdf/2507.07613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on energy-efficient federated learning methodologies and neural network sparsification, with no emphasis on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07943",
      "abstract": "In the DAG Edge Deletion problem, we are given an edge-weighted directed acyclic graph and a parameter $k$, and the goal is to delete the minimum weight set of edges so that the resulting graph has no paths of length $k$. This problem, which has applications to scheduling, was introduced in 2015 by Kenkre, Pandit, Purohit, and Saket. They gave a $k$-approximation and showed that it is UGC-Hard to approximate better than $\\lfloor 0.5k \\rfloor$ for any constant $k \\ge 4$ using a work of Svensson from 2012. The approximation ratio was improved to $\\frac{2}{3}(k+1)$ by Klein and Wexler in 2016.\n  In this work, we introduce a randomized rounding framework based on distributions over vertex labels in $[0,1]$. The most natural distribution is to sample labels independently from the uniform distribution over $[0,1]$. We show this leads to a $(2-\\sqrt{2})(k+1) \\approx 0.585(k+1)$-approximation. By using a modified (but still independent) label distribution, we obtain a $0.549(k+1)$-approximation for the problem, as well as show that no independent distribution over labels can improve our analysis to below $0.542(k+1)$. Finally, we show a $0.5(k+1)$-approximation for bipartite graphs and for instances with structured LP solutions. Whether this ratio can be obtained in general is open.",
      "authors": [
        "Sina Kalantarzadeh",
        "Nathan Klein",
        "and Victor Reis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:29:54+00:00",
          "link": "https://arxiv.org/abs/2507.07943v1",
          "size": "608kb",
          "version": "v1"
        }
      ],
      "title": "A Randomized Rounding Approach for DAG Edge Deletion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07943",
        "HTML": "https://arxiv.org/html/2507.07943v1",
        "PDF": "https://arxiv.org/pdf/2507.07943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work discusses a randomized rounding approach for DAG edge deletion, a problem in graph theory, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00718",
      "abstract": "The rise of multimodal large language models has introduced innovative human-machine interaction paradigms but also significant challenges in machine learning safety. Audio-Language Models (ALMs) are especially relevant due to the intuitive nature of spoken communication, yet little is known about their failure modes. This paper explores audio jailbreaks targeting ALMs, focusing on their ability to bypass alignment mechanisms. We construct adversarial perturbations that generalize across prompts, tasks, and even base audio samples, demonstrating the first universal jailbreaks in the audio modality, and show that these remain effective in simulated real-world conditions. Beyond demonstrating attack feasibility, we analyze how ALMs interpret these audio adversarial examples and reveal them to encode imperceptible first-person toxic speech - suggesting that the most effective perturbations for eliciting toxic outputs specifically embed linguistic features within the audio signal. These results have important implications for understanding the interactions between different modalities in multimodal models, and offer actionable insights for enhancing defenses against adversarial audio attacks.",
      "authors": [
        "Isha Gupta",
        "David Khachaturov",
        "Robert Mullins"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-02T08:36:23+00:00",
          "link": "https://arxiv.org/abs/2502.00718v1",
          "size": "1762kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:44:44+00:00",
          "link": "https://arxiv.org/abs/2502.00718v2",
          "size": "1171kb",
          "version": "v2"
        }
      ],
      "title": "\"I am bad\": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00718",
        "HTML": "https://arxiv.org/html/2502.00718v2",
        "PDF": "https://arxiv.org/pdf/2502.00718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial attacks and defenses in audio-language models, not on the processing or creation of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.15216",
      "abstract": "AI agents have the potential to significantly alter the cybersecurity landscape. Here, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards of \\$10-\\$30,485, covering 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 8 agents: Claude Code, OpenAI Codex CLI with o3-high and o4-mini, and custom agents with o3-high, GPT-4.1, Gemini 2.5 Pro Preview, Claude 3.7 Sonnet Thinking, and DeepSeek-R1. Given up to three attempts, the top-performing agents are OpenAI Codex CLI: o3-high (12.5% on Detect, mapping to \\$3,720; 90% on Patch, mapping to \\$14,152), Custom Agent with Claude 3.7 Sonnet Thinking (67.5% on Exploit), and OpenAI Codex CLI: o4-mini (90% on Patch, mapping to \\$14,422). OpenAI Codex CLI: o3-high, OpenAI Codex CLI: o4-mini, and Claude Code are more capable at defense, achieving higher Patch scores of 90%, 90%, and 87.5%, compared to Exploit scores of 47.5%, 32.5%, and 57.5% respectively; while the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 37.5-67.5% and Patch scores of 35-60%.",
      "authors": [
        "Andy K. Zhang",
        "Joey Ji",
        "Celeste Menders",
        "Riya Dulepet",
        "Thomas Qin",
        "Ron Y. Wang",
        "Junrong Wu",
        "Kyleen Liao",
        "Jiliang Li",
        "Jinghan Hu",
        "Sara Hong",
        "Nardos Demilew",
        "Shivatmica Murgai",
        "Jason Tran",
        "Nishka Kacheria",
        "Ethan Ho",
        "Denis Liu",
        "Lauren McLane",
        "Olivia Bruvik",
        "Dai-Rong Han",
        "Seungwoo Kim",
        "Akhil Vyas",
        "Cuiyuanxiu Chen",
        "Ryan Li",
        "Weiran Xu",
        "Jonathan Z. Ye",
        "Prerit Choudhary",
        "Siddharth M. Bhatia",
        "Vikram Sivashankar",
        "Yuxuan Bao",
        "Dawn Song",
        "Dan Boneh",
        "Daniel E. Ho",
        "Percy Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T07:44:52+00:00",
          "link": "https://arxiv.org/abs/2505.15216v1",
          "size": "5480kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:10:30+00:00",
          "link": "https://arxiv.org/abs/2505.15216v2",
          "size": "10985kb",
          "version": "v2"
        }
      ],
      "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15216",
        "HTML": "https://arxiv.org/html/2505.15216v2",
        "PDF": "https://arxiv.org/pdf/2505.15216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating AI agents in cybersecurity scenarios rather than discussing any data processing for training LLMs or developing datasets for LLM training."
      },
      "tasks": [
        "AI Agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07511",
      "abstract": "Brain-computer interfaces (BCIs) turn brain signals into functionally useful output, but they are not always accurate. A good Machine Learning classifier should be able to indicate how confident it is about a given classification, by giving a probability for its classification. Standard classifiers for Motor Imagery BCIs do give such probabilities, but research on uncertainty quantification has been limited to Deep Learning. We compare the uncertainty quantification ability of established BCI classifiers using Common Spatial Patterns (CSP-LDA) and Riemannian Geometry (MDRM) to specialized methods in Deep Learning (Deep Ensembles and Direct Uncertainty Quantification) as well as standard Convolutional Neural Networks (CNNs).\n  We found that the overconfidence typically seen in Deep Learning is not a problem in CSP-LDA and MDRM. We found that MDRM is underconfident, which we solved by adding Temperature Scaling (MDRM-T). CSP-LDA and MDRM-T give the best uncertainty estimates, but Deep Ensembles and standard CNNs give the best classifications. We show that all models are able to separate between easy and difficult estimates, so that we can increase the accuracy of a Motor Imagery BCI by rejecting samples that are ambiguous.",
      "authors": [
        "Joris Suurmeijer",
        "Ivo Pascal de Jong",
        "Matias Valdenegro-Toro and Andreea Ioana Sburlea"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:57:50+00:00",
          "link": "https://arxiv.org/abs/2507.07511v1",
          "size": "164kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07511",
        "HTML": "https://arxiv.org/html/2507.07511v1",
        "PDF": "https://arxiv.org/pdf/2507.07511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on uncertainty quantification in brain-computer interfaces using machine learning vs. deep learning models, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06342",
      "abstract": "In this study, we introduce a method based on Separable Physics-Informed Neural Networks (SPINNs) for effectively solving the BGK model of the Boltzmann equation. While the mesh-free nature of PINNs offers significant advantages in handling high-dimensional partial differential equations (PDEs), challenges arise when applying quadrature rules for accurate integral evaluation in the BGK operator, which can compromise the mesh-free benefit and increase computational costs. To address this, we leverage the canonical polyadic decomposition structure of SPINNs and the linear nature of moment calculation, achieving a substantial reduction in computational expense for quadrature rule application. The multi-scale nature of the particle density function poses difficulties in precisely approximating macroscopic moments using neural networks. To improve SPINN training, we introduce the integration of Gaussian functions into SPINNs, coupled with a relative loss approach. This modification enables SPINNs to decay as rapidly as Maxwellian distributions, thereby enhancing the accuracy of macroscopic moment approximations. The relative loss design further ensures that both large and small-scale features are effectively captured by the SPINNs. The efficacy of our approach is demonstrated through a series of five numerical experiments, including the solution to a challenging 3D Riemann problem. These results highlight the potential of our novel method in efficiently and accurately addressing complex challenges in computational physics.",
      "authors": [
        "Jaemin Oh",
        "Seung Yeon Cho",
        "Seok-Bae Yun",
        "Eunbyung Park",
        "and Youngjoon Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-10T23:44:55+00:00",
          "link": "https://arxiv.org/abs/2403.06342v1",
          "size": "1554kb",
          "version": "v1"
        }
      ],
      "title": "Separable Physics-informed Neural Networks for Solving the BGK Model of the Boltzmann Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06342",
        "HTML": "https://arxiv.org/html/2403.06342",
        "PDF": "https://arxiv.org/pdf/2403.06342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for solving the BGK model of the Boltzmann equation using neural networks, with no mention of training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/jaeminoh/SPINN-BGK"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.00699",
      "abstract": "With the rise of Large Language Models (LLMs) in recent years, abundant new opportunities are emerging, but also new challenges, among which contamination is quickly becoming critical. Business applications and fundraising in Artificial Intelligence (AI) have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a major issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes real capability improvement in the field of NLP, yet, there remains a lack of methods on how to efficiently detect contamination. In this paper, we survey all recent work on contamination detection with LLMs, analyzing their methodologies and use cases to shed light on the appropriate usage of contamination detection methods. Our work calls the NLP research community's attention into systematically taking into account contamination bias in LLM evaluation.",
      "authors": [
        "Mathieu Ravaut",
        "Bosheng Ding",
        "Fangkai Jiao",
        "Hailin Chen",
        "Xingxuan Li",
        "Ruochen Zhao",
        "Chengwei Qin",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-31T14:32:02+00:00",
          "link": "https://arxiv.org/abs/2404.00699v1",
          "size": "74kb",
          "version": "v1"
        },
        {
          "date": "2024-08-14T21:56:32+00:00",
          "link": "https://arxiv.org/abs/2404.00699v2",
          "size": "65kb",
          "version": "v2"
        },
        {
          "date": "2024-08-20T18:51:26+00:00",
          "link": "https://arxiv.org/abs/2404.00699v3",
          "size": "65kb",
          "version": "v3"
        },
        {
          "date": "2025-04-02T20:19:33+00:00",
          "link": "https://arxiv.org/abs/2404.00699v4",
          "size": "430kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T19:56:02+00:00",
          "link": "https://arxiv.org/abs/2404.00699v5",
          "size": "79kb",
          "version": "v5"
        }
      ],
      "title": "A Comprehensive Survey of Contamination Detection Methods in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.00699",
        "HTML": "https://arxiv.org/html/2404.00699v5",
        "PDF": "https://arxiv.org/pdf/2404.00699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses primarily on contamination detection methods in LLMs, which involves analyzing and improving the integrity of training data, making it a critical aspect of LLM training data processing."
      },
      "tasks": [
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/ntunlp/llmsanitize"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01077",
      "abstract": "Jailbreaking techniques trick Large Language Models (LLMs) into producing restricted output, posing a potential threat. One line of defense is to use another LLM as a Judge to evaluate the harmfulness of generated text. However, we reveal that these Judge LLMs are vulnerable to token segmentation bias, an issue that arises when delimiters alter the tokenization process, splitting words into smaller sub-tokens. This alters the embeddings of the entire sequence, reducing detection accuracy and allowing harmful content to be misclassified as safe. In this paper, we introduce Emoji Attack, a novel strategy that amplifies existing jailbreak prompts by exploiting token segmentation bias. Our method leverages in-context learning to systematically insert emojis into text before it is evaluated by a Judge LLM, inducing embedding distortions that significantly lower the likelihood of detecting unsafe content. Unlike traditional delimiters, emojis also introduce semantic ambiguity, making them particularly effective in this attack. Through experiments on state-of-the-art Judge LLMs, we demonstrate that Emoji Attack substantially reduces the unsafe prediction rate, bypassing existing safeguards.",
      "authors": [
        "Zhipeng Wei",
        "Yuqi Liu",
        "N. Benjamin Erichson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T23:18:32+00:00",
          "link": "https://arxiv.org/abs/2411.01077v1",
          "size": "4226kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T17:57:26+00:00",
          "link": "https://arxiv.org/abs/2411.01077v2",
          "size": "3993kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:12:23+00:00",
          "link": "https://arxiv.org/abs/2411.01077v3",
          "size": "2689kb",
          "version": "v3"
        }
      ],
      "title": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01077",
        "HTML": "https://arxiv.org/html/2411.01077v3",
        "PDF": "https://arxiv.org/pdf/2411.01077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with exploiting token segmentation biases for jailbreak attacks on LLMs, which touches on data manipulation but is not primarily about training data processing."
      },
      "tasks": [
        "Few-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/zhipeng-wei/EmojiAttack"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07456",
      "abstract": "Data-driven techniques have a large potential to transform and accelerate the chemical sciences. However, chemical sciences also pose the unique challenge of very diverse, small, fuzzy datasets that are difficult to leverage in conventional machine learning approaches completely. A new class of models, general-purpose models (GPMs) such as large language models, have shown the ability to solve tasks they have not been directly trained on, and to flexibly operate with low amounts of data in different formats. In this review, we discuss fundamental building principles of GPMs and review recent applications of those models in the chemical sciences across the entire scientific process. While many of these applications are still in the prototype phase, we expect that the increasing interest in GPMs will make many of them mature in the coming years.",
      "authors": [
        "Nawaf Alampara",
        "Anagha Aneesh",
        "Marti\\~no R\\'ios-Garc\\'ia",
        "Adrian Mirza",
        "Mara Schilling-Wilhelmi",
        "Ali Asghar Aghajani",
        "Meiling Sun",
        "Gordan Prastalo",
        "Kevin Maik Jablonka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:18:46+00:00",
          "link": "https://arxiv.org/abs/2507.07456v1",
          "size": "10898kb",
          "version": "v1"
        }
      ],
      "title": "General purpose models for the chemical sciences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07456",
        "PDF": "https://arxiv.org/pdf/2507.07456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This review paper discusses general-purpose models for chemical sciences, not training data processing or dataset creation specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07582",
      "abstract": "In this study, we focused on proposing an optimal clustering mechanism for the occupations defined in the well-known US-based occupational database, O*NET. Even though all occupations are defined according to well-conducted surveys in the US, their definitions can vary for different firms and countries. Hence, if one wants to expand the data that is already collected in O*NET for the occupations defined with different tasks, a map between the definitions will be a vital requirement. We proposed a pipeline using several BERT-based techniques with various clustering approaches to obtain such a map. We also examined the effect of dimensionality reduction approaches on several metrics used in measuring performance of clustering algorithms. Finally, we improved our results by using a specialized silhouette approach. This new clustering-based mapping approach with dimensionality reduction may help distinguish the occupations automatically, creating new paths for people wanting to change their careers.",
      "authors": [
        "Iago Xabier V\\'azquez Garc\\'ia",
        "Damla Partanaz",
        "Emrullah Fatih Yetkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:36:54+00:00",
          "link": "https://arxiv.org/abs/2507.07582v1",
          "size": "1162kb",
          "version": "v1"
        }
      ],
      "title": "Improving Clustering on Occupational Text Data through Dimensionality Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07582",
        "HTML": "https://arxiv.org/html/2507.07582v1",
        "PDF": "https://arxiv.org/pdf/2507.07582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on clustering mechanisms and dimensionality reduction for occupational data, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07890",
      "abstract": "In this paper, we present Hi-D maps, a novel method for the visualization of multi-dimensional categorical data. Our work addresses the scarcity of techniques for visualizing a large number of data-dimensions in an effective and space-efficient manner. We have mapped the full data-space onto a 2D regular polygonal region. The polygon is cut hierarchically with lines parallel to a user-controlled, ordered sequence of sides, each representing a dimension. We have used multiple visual cues such as orientation, thickness, color, countable glyphs, and text to depict cross-dimensional information. We have added interactivity and hierarchical browsing to facilitate flexible exploration of the display: small areas can be scrutinized for details. Thus, our method is also easily extendable to visualize hierarchical information. Our glyph animations add an engaging aesthetic during interaction. Like many visualizations, Hi-D maps become less effective when a large number of dimensions stresses perceptual limits, but Hi-D maps may add clarity before those limits are reached.",
      "authors": [
        "Radi Muhammad Reza",
        "Benjamin A Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:20:37+00:00",
          "link": "https://arxiv.org/abs/2507.07890v1",
          "size": "6601kb",
          "version": "v1"
        }
      ],
      "title": "Hi-d maps: An interactive visualization technique for multi-dimensional categorical data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07890",
        "HTML": "https://arxiv.org/html/2507.07890v1",
        "PDF": "https://arxiv.org/pdf/2507.07890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a visualization technique for multi-dimensional categorical data, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.00461",
      "abstract": "Accurate remaining useful life (RUL) predictions are critical to the safe operation of aero-engines. Currently, the RUL prediction task is mainly a regression paradigm with only mean square error as the loss function and lacks research on feature space structure, the latter of which has shown excellent performance in a large number of studies. This paper develops a multi-granularity supervised contrastive (MGSC) framework from plain intuition that samples with the same RUL label should be aligned in the feature space, and address the problems of too large minibatch size and unbalanced samples in the implementation. The RUL prediction with MGSC is implemented on using the proposed multi-phase training strategy. This paper also demonstrates a simple and scalable basic network structure and validates the proposed MGSC strategy on the CMPASS dataset using a convolutional long short-term memory network as a baseline, which effectively improves the accuracy of RUL prediction.",
      "authors": [
        "Zixuan He",
        "Ziqian Kong",
        "Zhengyu Chen",
        "Yuling Zhan",
        "Zijun Que",
        "Zhengguo Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T09:18:38+00:00",
          "link": "https://arxiv.org/abs/2411.00461v1",
          "size": "2420kb",
          "version": "v1"
        },
        {
          "date": "2024-11-15T03:01:59+00:00",
          "link": "https://arxiv.org/abs/2411.00461v2",
          "size": "2420kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T02:10:06+00:00",
          "link": "https://arxiv.org/abs/2411.00461v3",
          "size": "1856kb",
          "version": "v3"
        }
      ],
      "title": "A Multi-Granularity Supervised Contrastive Framework for Remaining Useful Life Prediction of Aero-engines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00461",
        "HTML": "https://arxiv.org/html/2411.00461v3",
        "PDF": "https://arxiv.org/pdf/2411.00461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It discusses aero-engine RUL prediction using supervised contrastive learning, with no focus on LLM training data processing."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07291",
      "abstract": "High-dimensional datasets often exhibit low-dimensional geometric structures, as suggested by the manifold hypothesis, which implies that data lie on a smooth manifold embedded in a higher-dimensional ambient space. While this insight underpins many advances in machine learning and inverse problems, fully leveraging it requires to deal with three key tasks: estimating the intrinsic dimension (ID) of the manifold, constructing appropriate local coordinates, and learning mappings between ambient and manifold spaces. In this work, we propose a framework that addresses all these challenges using a Mixture of Variational Autoencoders (VAEs) and tools from Riemannian geometry. We specifically focus on estimating the ID of datasets by analyzing the numerical rank of the VAE decoder pullback metric. The estimated ID guides the construction of an atlas of local charts using a mixture of invertible VAEs, enabling accurate manifold parameterization and efficient inference. We how this approach enhances solutions to ill-posed inverse problems, particularly in biomedical imaging, by enforcing that reconstructions lie on the learned manifold. Lastly, we explore the impact of network pruning on manifold geometry and reconstruction quality, showing that the intrinsic dimension serves as an effective proxy for monitoring model capacity.",
      "authors": [
        "Paola Causin",
        "Alessio Marta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:22:59+00:00",
          "link": "https://arxiv.org/abs/2507.07291v1",
          "size": "1389kb",
          "version": "v1"
        }
      ],
      "title": "Estimating Dataset Dimension via Singular Metrics under the Manifold Hypothesis: Application to Inverse Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07291",
        "HTML": "https://arxiv.org/html/2507.07291v1",
        "PDF": "https://arxiv.org/pdf/2507.07291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for estimating dataset dimensions and manifold learning which is indirectly relevant to LLM training data but does not directly focus on data processing for LLM studies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07370",
      "abstract": "Precise kinematic modeling is critical in calibration and controller design for soft robots, yet remains a challenging issue due to their highly nonlinear and complex behaviors. To tackle the issue, numerous data-driven machine learning approaches have been proposed for modeling nonlinear dynamics. However, these models suffer from prediction uncertainty that can negatively affect modeling accuracy, and uncertainty quantification for kinematic modeling in soft robots is underexplored. In this work, using limited simulation and real-world data, we first investigate multiple linear and nonlinear machine learning models commonly used for kinematic modeling of soft robots. The results reveal that nonlinear ensemble methods exhibit the most robust generalization performance. We then develop a conformal kinematic modeling framework for soft robots by utilizing split conformal prediction to quantify predictive position uncertainty, ensuring distribution-free prediction intervals with a theoretical guarantee.",
      "authors": [
        "Zhanhong Jiang",
        "Dylan Shah",
        "Hsin-Jung Yang",
        "Soumik Sarkar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:49:23+00:00",
          "link": "https://arxiv.org/abs/2507.07370v1",
          "size": "6416kb",
          "version": "v1"
        }
      ],
      "title": "Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07370",
        "HTML": "https://arxiv.org/html/2507.07370v1",
        "PDF": "https://arxiv.org/pdf/2507.07370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with kinematic modeling and uncertainty quantification for soft robots, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07689",
      "abstract": "Requirements engineering (RE) in the space industry is inherently complex, demanding high precision, alignment with rigorous standards, and adaptability to mission-specific constraints. Smaller space organisations and new entrants often struggle to derive actionable requirements from extensive, unstructured documents such as mission briefs, interface specifications, and regulatory standards. In this innovation opportunity paper, we explore the potential of Retrieval-Augmented Generation (RAG) models to support and (semi-)automate requirements generation in the space domain. We present a modular, AI-driven approach that preprocesses raw space mission documents, classifies them into semantically meaningful categories, retrieves contextually relevant content from domain standards, and synthesises draft requirements using large language models (LLMs). We apply the approach to a real-world mission document from the space domain to demonstrate feasibility and assess early outcomes in collaboration with our industry partner, Starbound Space Solutions. Our preliminary results indicate that the approach can reduce manual effort, improve coverage of relevant requirements, and support lightweight compliance alignment. We outline a roadmap toward broader integration of AI in RE workflows, intending to lower barriers for smaller organisations to participate in large-scale, safety-critical missions.",
      "authors": [
        "Chetan Arora",
        "Fanyu Wang",
        "Chakkrit Tantithamthavorn",
        "Aldeida Aleti",
        "Shaun Kenyon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:11:01+00:00",
          "link": "https://arxiv.org/abs/2507.07689v1",
          "size": "350kb",
          "version": "v1"
        }
      ],
      "title": "From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07689",
        "HTML": "https://arxiv.org/html/2507.07689v1",
        "PDF": "https://arxiv.org/pdf/2507.07689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper involves preprocessing of domain documents and synthesizing requirements using LLMs, indicating substantial data processing and engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07743",
      "abstract": "The first violins appeared in late 16th-century Italy. Over the next 200 years, they spread across Europe and luthiers of various royal courts, eager to experiment with new techniques, created a highly diverse family of instruments. Around 1750, size standards were introduced to unify violin making for orchestras and conservatories. Instruments that fell between two standards were then reduced to a smaller size by luthiers. These reductions have an impact on several characteristics of violins, in particular on the contour lines, i.e. lines of constant altitude, which look more like a U for non reduced instruments and a V for reduced ones. While such differences are observed by experts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or non-reduced based on their contour lines. We study a corpus of 25 instruments whose 3D geometric meshes were acquired via photogrammetry. For each instrument, we extract 10-20 contour lines regularly spaced every millimetre. Each line is fitted with a parabola-like curve (with an equation of the type y = alpha*abs(x)**beta) depending on two parameters, describing how open (beta) and how vertically stretched (alpha) the curve is. We compute additional features from those parameters, using regressions and counting how many values fall under some threshold. We also deal with outliers and non equal numbers of levels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can predict size reduction. We find that distinguishing between reduced and non reduced instruments is feasible to some degree, taking into account that a whole spectrum of more or less transformed violins exists, for which it is more difficult to quantify the reduction. We also find the opening parameter beta to be the most predictive.",
      "authors": [
        "Phil\\'emon Beghin",
        "Anne-Emmanuelle Ceulemans",
        "Fran\\c{c}ois Glineur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:23:15+00:00",
          "link": "https://arxiv.org/abs/2507.07743v1",
          "size": "6977kb",
          "version": "v1"
        }
      ],
      "title": "Identification of Violin Reduction via Contour Lines Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07743",
        "HTML": "https://arxiv.org/html/2507.07743v1",
        "PDF": "https://arxiv.org/pdf/2507.07743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about classifying violins based on contour lines and does not involve any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07779",
      "abstract": "We study approximations of polytopes in the standard model for computing polytopes using Minkowski sums and (convex hulls of) unions. Specifically, we study the ability to approximate a target polytope by polytopes of a given depth. Our main results imply that simplices can only be ``trivially approximated''. On the way, we obtain a characterization of simplices as the only ``outer additive'' convex bodies.",
      "authors": [
        "Egor Bakaev",
        "Florestan Brunck",
        "Amir Yehudayoff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Metric Geometry (math.MG)",
        "Computational Geometry (cs.CG)",
        "Machine Learning (cs.LG)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:58:55+00:00",
          "link": "https://arxiv.org/abs/2507.07779v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Approximation Depth of Convex Polytopes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07779",
        "HTML": "https://arxiv.org/html/2507.07779v1",
        "PDF": "https://arxiv.org/pdf/2507.07779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical approximations of polytopes, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07939",
      "abstract": "While Vision-Language Models (VLMs) have shown promising progress in general multimodal tasks, they often struggle in industrial anomaly detection and reasoning, particularly in delivering interpretable explanations and generalizing to unseen categories. This limitation stems from the inherently domain-specific nature of anomaly detection, which hinders the applicability of existing VLMs in industrial scenarios that require precise, structured, and context-aware analysis. To address these challenges, we propose SAGE, a VLM-based framework that enhances anomaly reasoning through Self-Guided Fact Enhancement (SFE) and Entropy-aware Direct Preference Optimization (E-DPO). SFE integrates domain-specific knowledge into visual reasoning via fact extraction and fusion, while E-DPO aligns model outputs with expert preferences using entropy-aware optimization. Additionally, we introduce AD-PL, a preference-optimized dataset tailored for industrial anomaly reasoning, consisting of 28,415 question-answering instances with expert-ranked responses. To evaluate anomaly reasoning models, we develop Multiscale Logical Evaluation (MLE), a quantitative framework analyzing model logic and consistency. SAGE demonstrates superior performance on industrial anomaly datasets under zero-shot and one-shot settings. The code, model and dataset are available at https://github.com/amoreZgx1n/SAGE.",
      "authors": [
        "Guoxin Zang",
        "Xue Li",
        "Donglin Di",
        "Lanshun Nie",
        "Dechen Zhan",
        "Yang Song",
        "Lei Fan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:23:42+00:00",
          "link": "https://arxiv.org/abs/2507.07939v1",
          "size": "975kb",
          "version": "v1"
        }
      ],
      "title": "SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07939",
        "HTML": "https://arxiv.org/html/2507.07939v1",
        "PDF": "https://arxiv.org/pdf/2507.07939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a VLM-based framework for anomaly detection and reasoning, along with a new dataset, but there is no substantive focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.13651",
      "abstract": "Adversarial attacks pose significant challenges to the robustness of modern deep neural networks in computer vision, and defending these networks against adversarial attacks has attracted intense research efforts. Among various defense strategies, preprocessing-based defenses are practically appealing since there is no need to train the network under protection. However, such approaches typically do not achieve comparable robustness as other methods such as adversarial training. In this paper, we propose a novel framework for preprocessing-based defenses, where a vector quantizer is used as a preprocessor. This framework, inspired by and extended from Randomized Discretization (RandDisc), is theoretically principled by rate-distortion theory: indeed, RandDisc may be viewed as a scalar quantizer, and rate-distortion theory suggests that such quantization schemes are inferior to vector quantization. In our framework, the preprocessing vector quantizer treats the input image as a collection of patches and finds a set of representative patches based on the patch distributions; each original patch is then modified according to the representative patches close to it. We present two lightweight defenses in this framework, referred to as patched RandDisc (pRD) and sliding-window RandDisc (swRD), where the patches are disjoint in the former and overlapping in the latter. We show that vector-quantization-based defenses have certifiable robust accuracy and that pRD and swRD demonstrate state-of-the-art performances, surpassing RandDisc by a large margin. Notably, the proposed defenses possess the obfuscated gradients property. Our experiments however show that pRD and swRD remain effective under the STE and EOT attacks, which are designed specifically for defenses with gradient obfuscation. ...",
      "authors": [
        "Zhiyi Dong and Yongyi Mao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-23T03:49:41+00:00",
          "link": "https://arxiv.org/abs/2305.13651v1",
          "size": "926kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T23:51:43+00:00",
          "link": "https://arxiv.org/abs/2305.13651v2",
          "size": "556kb",
          "version": "v2"
        }
      ],
      "title": "Adversarial Defenses via Vector Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.13651",
        "PDF": "https://arxiv.org/pdf/2305.13651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a preprocessing-based defense for adversarial attacks in computer vision, without addressing LLM training data processing."
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05007",
      "abstract": "The Critical View of Safety (CVS) is crucial for safe laparoscopic cholecystectomy, yet assessing CVS criteria remains a complex and challenging task, even for experts. Traditional models for CVS recognition depend on vision-only models learning with costly, labor-intensive spatial annotations. This study investigates how text can be harnessed as a powerful tool for both training and inference in multi-modal surgical foundation models to automate CVS recognition. Unlike many existing multi-modal models, which are primarily adapted for multi-class classification, CVS recognition requires a multi-label framework. Zero-shot evaluation of existing multi-modal surgical models shows a significant performance gap for this task. To address this, we propose CVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained, binary classification across multiple labels by aligning image embeddings with textual descriptions of each CVS criterion using positive and negative prompts. By adapting PeskaVLP, a state-of-the-art surgical foundation model, on the Endoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the ResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that CVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts, boosts CVS recognition over image-only methods. We also propose text-specific inference methods, that helps in analysing the image-text alignment. While further work is needed to match state-of-the-art spatial annotation-based methods, this approach highlights the potential of adapting generalist models to specialized surgical tasks. Code: https://github.com/CAMMA-public/CVS-AdaptNet",
      "authors": [
        "Britty Baby",
        "Vinkle Srivastav",
        "Pooja P. Jain",
        "Kun Yuan",
        "Pietro Mascagni",
        "Nicolas Padoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:44:58+00:00",
          "link": "https://arxiv.org/abs/2507.05007v1",
          "size": "4656kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:22:03+00:00",
          "link": "https://arxiv.org/abs/2507.05007v2",
          "size": "4656kb",
          "version": "v2"
        }
      ],
      "title": "Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05007",
        "HTML": "https://arxiv.org/html/2507.05007v2",
        "PDF": "https://arxiv.org/pdf/2507.05007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper utilizes text data in multi-modal models for surgical task recognition, it primarily focuses on model adaptation and inference techniques rather than on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07419",
      "abstract": "Generative AI has demonstrated strong potential in healthcare, from clinical decision support to patient-facing chatbots that improve outcomes. A critical challenge for deployment is effective human-AI communication, where content must be both personalized and understandable. We introduce MedReadCtrl, a readability-controlled instruction tuning framework that enables LLMs to adjust output complexity without compromising meaning. Evaluations of nine datasets and three tasks across medical and general domains show that MedReadCtrl achieves significantly lower readability instruction-following errors than GPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains on unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples). Experts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low literacy levels. These gains reflect MedReadCtrl's ability to restructure clinical content into accessible, readability-aligned language while preserving medical intent, offering a scalable solution to support patient education and expand equitable access to AI-enabled care.",
      "authors": [
        "Hieu Tran",
        "Zonghai Yao",
        "Won Seok Jang",
        "Sharmin Sultana",
        "Allen Chang",
        "Yuan Zhang",
        "Hong Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:22:36+00:00",
          "link": "https://arxiv.org/abs/2507.07419v1",
          "size": "977kb",
          "version": "v1"
        }
      ],
      "title": "MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07419",
        "HTML": "https://arxiv.org/html/2507.07419v1",
        "PDF": "https://arxiv.org/pdf/2507.07419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "MedReadCtrl leverages LLMs to adjust text readability, mentioning instruction tuning. However, the paper primarily focuses on application and performance rather than new processes or steps for creating or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07499",
      "abstract": "The oxygen reduction reaction (ORR) catalyst plays a critical role in enhancing fuel cell efficiency, making it a key focus in material science research. However, extracting structured information about ORR catalysts from vast scientific literature remains a significant challenge due to the complexity and diversity of textual data. In this study, we propose a named entity recognition (NER) and relation extraction (RE) approach using DyGIE++ with multiple pre-trained BERT variants, including MatSciBERT and PubMedBERT, to extract ORR catalyst-related information from the scientific literature, which is compiled into a fuel cell corpus for materials informatics (FC-CoMIcs). A comprehensive dataset was constructed manually by identifying 12 critical entities and two relationship types between pairs of the entities. Our methodology involves data annotation, integration, and fine-tuning of transformer-based models to enhance information extraction accuracy. We assess the impact of different BERT variants on extraction performance and investigate the effects of annotation consistency. Experimental evaluations demonstrate that the fine-tuned PubMedBERT model achieves the highest NER F1-score of 82.19% and the MatSciBERT model attains the best RE F1-score of 66.10%. Furthermore, the comparison with human annotators highlights the reliability of fine-tuned models for ORR catalyst extraction, demonstrating their potential for scalable and automated literature analysis. The results indicate that domain-specific BERT models outperform general scientific models like BlueBERT for ORR catalyst extraction.",
      "authors": [
        "Hein Htet",
        "Amgad Ahmed Ali Ibrahim",
        "Yutaka Sasaki",
        "Ryoji Asahi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.07499v1",
          "size": "1730kb",
          "version": "v1"
        }
      ],
      "title": "Extracting ORR Catalyst Information for Fuel Cell from Scientific Literature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07499",
        "HTML": "https://arxiv.org/html/2507.07499v1",
        "PDF": "https://arxiv.org/pdf/2507.07499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an NER and RE approach for extracting ORR catalyst information from scientific literature, which pertains to information extraction rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.20429",
      "abstract": "To improve the cognitive autonomy of humanoid robots, this research proposes a multi-scenario reasoning architecture to solve the technical shortcomings of multi-modal understanding in this field. It draws on simulation based experimental design that adopts multi-modal synthesis (visual, auditory, tactile) and builds a simulator \"Maha\" to perform the experiment. The findings demonstrate the feasibility of this architecture in multimodal data. It provides reference experience for the exploration of cross-modal interaction strategies for humanoid robots in dynamic environments. In addition, multi-scenario reasoning simulates the high-level reasoning mechanism of the human brain to humanoid robots at the cognitive level. This new concept promotes cross-scenario practical task transfer and semantic-driven action planning. It heralds the future development of self-learning and autonomous behavior of humanoid robots in changing scenarios.",
      "authors": [
        "Libo Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T10:46:08+00:00",
          "link": "https://arxiv.org/abs/2412.20429v1",
          "size": "402kb",
          "version": "v1"
        },
        {
          "date": "2025-01-02T21:52:28+00:00",
          "link": "https://arxiv.org/abs/2412.20429v2",
          "size": "403kb",
          "version": "v2"
        },
        {
          "date": "2025-01-07T18:24:45+00:00",
          "link": "https://arxiv.org/abs/2412.20429v3",
          "size": "461kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T19:14:44+00:00",
          "link": "https://arxiv.org/abs/2412.20429v4",
          "size": "461kb",
          "version": "v4"
        }
      ],
      "title": "Multi-Scenario Reasoning: Unlocking Cognitive Autonomy in Humanoid Robots for Multimodal Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20429",
        "PDF": "https://arxiv.org/pdf/2412.20429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-scenario reasoning for humanoid robots, which does not involve processing or creation of LLM training data."
      },
      "tasks": [
        "Experimental Design",
        "Self-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07522",
      "abstract": "Graph Neural Networks (GNNs) are widely used in collaborative filtering to capture high-order user-item relationships. To address the data sparsity problem in recommendation systems, Graph Contrastive Learning (GCL) has emerged as a promising paradigm that maximizes mutual information between contrastive views. However, existing GCL methods rely on augmentation techniques that introduce semantically irrelevant noise and incur significant computational and storage costs, limiting effectiveness and efficiency.\n  To overcome these challenges, we propose NLGCL, a novel contrastive learning framework that leverages naturally contrastive views between neighbor layers within GNNs. By treating each node and its neighbors in the next layer as positive pairs, and other nodes as negatives, NLGCL avoids augmentation-based noise while preserving semantic relevance. This paradigm eliminates costly view construction and storage, making it computationally efficient and practical for real-world scenarios. Extensive experiments on four public datasets demonstrate that NLGCL outperforms state-of-the-art baselines in effectiveness and efficiency.",
      "authors": [
        "Jinfeng Xu",
        "Zheyu Chen",
        "Shuo Yang",
        "Jinze Li",
        "Hewei Wang",
        "Wei Wang",
        "Xiping Hu",
        "and Edith Ngai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.07522v1",
          "size": "1676kb",
          "version": "v1"
        }
      ],
      "title": "NLGCL: Naturally Existing Neighbor Layers Graph Contrastive Learning for Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07522",
        "HTML": "https://arxiv.org/html/2507.07522v1",
        "PDF": "https://arxiv.org/pdf/2507.07522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a graph contrastive learning framework for recommendation systems, which involves data sparsity but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07653",
      "abstract": "This paper proposes NOrmed Index of Retention (NOIR), a quantitative objective metric for evaluating summarization quality of arbitrary texts that relies on both the retention of semantic meaning and the summary length compression. This gives a measure of how well the recall-compression tradeoff is managed, the most important skill in summarization. Experiments demonstrate that NOIR effectively captures the token-length / semantic retention tradeoff of a summarizer and correlates to human perception of sumarization quality. Using a language model-embedding to measure semantic similarity, it provides an automated alternative for assessing summarization quality without relying on time-consuming human-generated reference summaries. The proposed metric can be applied to various summarization tasks, offering an automated tool for evaluating and improving summarization algorithms, summarization prompts, and synthetically-generated summaries.",
      "authors": [
        "Andrew D. Foland"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:25:16+00:00",
          "link": "https://arxiv.org/abs/2507.07653v1",
          "size": "899kb",
          "version": "v1"
        }
      ],
      "title": "An Automated Length-Aware Quality Metric for Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07653",
        "HTML": "https://arxiv.org/html/2507.07653v1",
        "PDF": "https://arxiv.org/pdf/2507.07653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a metric for evaluating summarization quality, which relies on semantic similarity but does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07931",
      "abstract": "The past decade has seen incredible scaling of AI systems by a few companies, leading to inequality in AI model performance. This paper argues that, contrary to prevailing intuition, the diminishing returns to compute scaling will lead to a convergence of AI model capabilities. In other words, meek models (those with limited computation budget) shall inherit the earth, approaching the performance level of the best models overall. We develop a model illustrating that under a fixed-distribution next-token objective, the marginal capability returns to raw compute shrink substantially. Given current scaling practices, we argue that these diminishing returns are strong enough that even companies that can scale their models exponentially faster than other organizations will eventually have little advantage in capabilities. As part of our argument, we give several reasons that proxies like training loss differences capture important capability measures using evidence from benchmark data and theoretical performance models. In addition, we analyze empirical data on the capability difference of AI models over time. Finally, in light of the increasing ability of meek models, we argue that AI strategy and policy require reexamination, and we outline the areas this shift will affect.",
      "authors": [
        "Hans Gundlach",
        "Jayson Lynch",
        "Neil Thompson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:10:07+00:00",
          "link": "https://arxiv.org/abs/2507.07931v1",
          "size": "876kb",
          "version": "v1"
        }
      ],
      "title": "Meek Models Shall Inherit the Earth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07931",
        "HTML": "https://arxiv.org/html/2507.07931v1",
        "PDF": "https://arxiv.org/pdf/2507.07931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper argues about AI scalability and diminishing returns in model capabilities related to compute scaling but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05548",
      "abstract": "This letter proposes a new approach for Inertial Measurement Unit (IMU) preintegration, a fundamental building block that can be leveraged in different optimization-based Inertial Navigation System (INS) localization solutions. Inspired by recent advances in equivariant theory applied to biased INSs, we derive a discrete-time formulation of the IMU preintegration on ${\\mathbf{Gal}(3) \\ltimes \\mathfrak{gal}(3)}$, the left-trivialization of the tangent group of the Galilean group $\\mathbf{Gal}(3)$. We define a novel preintegration error that geometrically couples the navigation states and the bias leading to lower linearization error. Our method improves in consistency compared to existing preintegration approaches which treat IMU biases as a separate state-space. Extensive validation against state-of-the-art methods, both in simulation and with real-world IMU data, implementation in the Lie++ library, and open-source code are provided.",
      "authors": [
        "Giulio Delama",
        "Alessandro Fornasier",
        "Robert Mahony and Stephan Weiss"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T13:11:16+00:00",
          "link": "https://arxiv.org/abs/2411.05548v1",
          "size": "5610kb",
          "version": "v1"
        },
        {
          "date": "2024-11-24T19:20:11+00:00",
          "link": "https://arxiv.org/abs/2411.05548v2",
          "size": "5606kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T08:22:12+00:00",
          "link": "https://arxiv.org/abs/2411.05548v3",
          "size": "5607kb",
          "version": "v3"
        },
        {
          "date": "2025-02-18T13:30:47+00:00",
          "link": "https://arxiv.org/abs/2411.05548v4",
          "size": "5607kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T15:05:04+00:00",
          "link": "https://arxiv.org/abs/2411.05548v5",
          "size": "5220kb",
          "version": "v5"
        }
      ],
      "title": "Equivariant IMU Preintegration with Biases: a Galilean Group Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05548",
        "HTML": "https://arxiv.org/html/2411.05548v5",
        "PDF": "https://arxiv.org/pdf/2411.05548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new approach for IMU preintegration for INS localization, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.10830",
      "abstract": "Coordinated beamforming across distributed base stations (BSs) in cell-free wireless infrastructure can efficiently support integrated sensing and communication (ISAC) users by enhancing resource sharing and suppressing interference in the spatial domain. However, intensive coordination among distributed BSs within the ISAC-enabled network poses risks of generating substantial interference to other coexisting networks sharing the same spectrum, while also incurring elevated costs from energy consumption and signaling exchange. To address these challenges, this paper develops an interference-suppressed and cost-efficient cell-free ISAC network, which opportunistically and cooperatively orchestrates distributed radio resources to accommodate the competing demands of sensing and communication (S\\&C) services. Specifically, we conceive a radiation footprint control mechanism that autonomously suppresses interference across the entire signal propagation space to safeguard other networks without exchanging channel knowledge signaling. Then, we propose joint BS activation and beamforming coordination to dynamically activate appropriate BSs and orchestrate their spatial beams for service provisioning. Building upon this framework, we formulate a cost-efficient utility maximization problem that considers individual S\\&C demands and location-dependent radiation footprint constraints. Since this results in a non-convex optimization problem, we develop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm to find the optimal solution. Additionally, we apply a low-complexity iterative method to obtain near-optimal solutions. Finally, simulation results validate the effectiveness of the proposed algorithms.",
      "authors": [
        "Jie Chen and Xianbin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T03:14:05+00:00",
          "link": "https://arxiv.org/abs/2504.10830v1",
          "size": "4369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:35:58+00:00",
          "link": "https://arxiv.org/abs/2504.10830v2",
          "size": "3281kb",
          "version": "v2"
        }
      ],
      "title": "Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint BS Activation and Beamforming Coordination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10830",
        "HTML": "https://arxiv.org/html/2504.10830v2",
        "PDF": "https://arxiv.org/pdf/2504.10830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses beamforming coordination in cell-free wireless networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07688",
      "abstract": "Mobile Crowd Sensing (MCS) is the mechanism wherein people can contribute in data collection process using their own mobile devices which have sensing capabilities. Incentives are rewards that individuals get in exchange for data they submit. Reverse Auction Bidding (RAB) is a framework that allows users to place bids for selling the data they collected. Task providers can select users to buy data from by looking at bids. Using the RAB framework, MCS system can be optimized for better user utility, task provider utility and platform utility. In this paper, we propose a novel approach called Reverse Auction with Assumed Bid Cost (RA-ABC) which allows users to place a bid in the system before collecting data. We opine that performing the tasks only after winning helps in reducing resource consumption instead of performing the tasks before bidding. User Return on Investment (ROI) is calculated with which they decide to further participate or not by either increasing or decreasing their bids. We also propose an extension of RA-ABC with dynamic recruitment (RA-ABCDR) in which we allow new users to join the system at any time during bidding rounds. Simulation results demonstrate that RA-ABC and RA-ABCDR outperform the widely used Tullock Optimal Prize Function, with RA-ABCDR achieving up to 54.6\\% higher user retention and reducing auction cost by 22.2\\%, thereby ensuring more efficient and sustainable system performance. Extensive simulations confirm that dynamic user recruitment significantly enhances performance across stability, fairness, and cost-efficiency metrics.",
      "authors": [
        "Jowa Yangchin",
        "Ningrinla Marchang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:11:00+00:00",
          "link": "https://arxiv.org/abs/2507.07688v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "Incentive Mechanism for Mobile Crowd Sensing with Assumed Bid Cost Reverse Auction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07688",
        "HTML": "https://arxiv.org/html/2507.07688v1",
        "PDF": "https://arxiv.org/pdf/2507.07688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on incentive mechanisms in mobile crowd sensing, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07201",
      "abstract": "Three-dimensional molecular generators based on diffusion models can now reach near-crystallographic accuracy, yet they remain fragmented across tasks. SMILES-only inputs, two-stage pretrain-finetune pipelines, and one-task-one-model practices hinder stereochemical fidelity, task alignment, and zero-shot transfer. We introduce MODA, a diffusion framework that unifies fragment growing, linker design, scaffold hopping, and side-chain decoration with a Bayesian mask scheduler. During training, a contiguous spatial fragment is masked and then denoised in one pass, enabling the model to learn shared geometric and chemical priors across tasks. Multi-task training yields a universal backbone that surpasses six diffusion baselines and three training paradigms on substructure, chemical property, interaction, and geometry. Model-C reduces ligand-protein clashes and substructure divergences while maintaining Lipinski compliance, whereas Model-B preserves similarity but trails in novelty and binding affinity. Zero-shot de novo design and lead-optimisation tests confirm stable negative Vina scores and high improvement rates without force-field refinement. These results demonstrate that a single-stage multi-task diffusion routine can replace two-stage workflows for structure-based molecular design.",
      "authors": [
        "Dong Xu",
        "Zhangfan Yang",
        "Sisi Yuan",
        "Jenna Xinyi Yao",
        "Jiangqiang Li",
        "Junkai Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:19:50+00:00",
          "link": "https://arxiv.org/abs/2507.07201v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07201",
        "HTML": "https://arxiv.org/html/2507.07201v1",
        "PDF": "https://arxiv.org/pdf/2507.07201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details a diffusion framework for molecular generation with a focus on chemical and geometric tasks, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07520",
      "abstract": "In this work, we offer the first operational interpretation of the $\\alpha$-$z$ relative entropies, which were introduced by Jak\\v{s}i\\'{c} {\\it et al.} \\cite{Jaksic2012} and Audenaert and Datta \\cite{Audenaert_Datta_2015}, where the $\\alpha$ and $z$ parameters are truly independent from each other. Namely, we show that these relative entropies appear in the conditions for large-sample or catalytic relative majorization of pairs of flat states and certain generalizations of them. Additionally, the optimal rate of converting one such pair into another may be formulated in terms of the $\\alpha$-$z$ relative entropies.",
      "authors": [
        "Frits Verhagen",
        "Marco Tomamichel",
        "Erkka Haapasalo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:10:32+00:00",
          "link": "https://arxiv.org/abs/2507.07520v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "Conditions for Large-Sample Majorization of Pairs of Flat States in Terms of $\\alpha$-$z$ Relative Entropies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07520",
        "HTML": "https://arxiv.org/html/2507.07520v1",
        "PDF": "https://arxiv.org/pdf/2507.07520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work pertains to operational interpretations of relative entropies in the context of quantum states, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07982",
      "abstract": "Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: https://GeometryForcing.github.io.",
      "authors": [
        "Haoyu Wu",
        "Diankun Wu",
        "Tianyu He",
        "Junliang Guo",
        "Yang Ye",
        "Yueqi Duan",
        "and Jiang Bian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:55:08+00:00",
          "link": "https://arxiv.org/abs/2507.07982v1",
          "size": "1521kb",
          "version": "v1"
        }
      ],
      "title": "Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07982",
        "HTML": "https://arxiv.org/html/2507.07982v1",
        "PDF": "https://arxiv.org/pdf/2507.07982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for video diffusion models, focusing on improving visual quality and 3D consistency, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00567",
      "abstract": "Generative artificial intelligence (GenAI) is increasingly becoming a part of work practices across the technology industry and being used across a range of industries. This has necessitated the need to better understand how GenAI is being used by professionals in the field so that we can better prepare students for the workforce. An improved understanding of the use of GenAI in practice can help provide guidance on the design of GenAI literacy efforts including how to integrate it within courses and curriculum, what aspects of GenAI to teach, and even how to teach it. This paper presents a field study that compares the use of GenAI across three different functions - product development, software engineering, and digital content creation - to identify how GenAI is currently being used in the industry. This study takes a human augmentation approach with a focus on human cognition and addresses three research questions: how is GenAI augmenting work practices; what knowledge is important and how are workers learning; and what are the implications for training the future workforce. Findings show a wide variance in the use of GenAI and in the level of computing knowledge of users. In some industries GenAI is being used in a highly technical manner with deployment of fine-tuned models across domains. Whereas in others, only off-the-shelf applications are being used for generating content. This means that the need for what to know about GenAI varies, and so does the background knowledge needed to utilize it. For the purposes of teaching and learning, our findings indicated that different levels of GenAI understanding needs to be integrated into courses. From a faculty perspective, the work has implications for training faculty so that they are aware of the advances and how students are possibly, as early adopters, already using GenAI to augment their learning practices.",
      "authors": [
        "Aditya Johri",
        "Johannes Schleiss",
        "Nupoor Ranade"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T21:26:31+00:00",
          "link": "https://arxiv.org/abs/2502.00567v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Lessons for GenAI Literacy From a Field Study of Human-GenAI Augmentation in the Workplace",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00567",
        "PDF": "https://arxiv.org/pdf/2502.00567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines the use of GenAI in workplace practices and education but does not discuss LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.04462",
      "abstract": "Watermarking techniques for large language models (LLMs) can significantly impact output quality, yet their effects on truthfulness, safety, and helpfulness remain critically underexamined. This paper presents a systematic analysis of how two popular watermarking approaches-Gumbel and KGW-affect these core alignment properties across four aligned LLMs. Our experiments reveal two distinct degradation patterns: guard attenuation, where enhanced helpfulness undermines model safety, and guard amplification, where excessive caution reduces model helpfulness. These patterns emerge from watermark-induced shifts in token distribution, surfacing the fundamental tension that exists between alignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an inference-time sampling method that uses an external reward model to restore alignment. We establish a theoretical lower bound on the improvement in expected reward score as the sample size is increased and empirically demonstrate that sampling just 2-4 watermarked generations effectively recovers or surpasses baseline (unwatermarked) alignment scores. To overcome the limited response diversity of standard Gumbel watermarking, our modified implementation sacrifices strict distortion-freeness while maintaining robust detectability, ensuring compatibility with AR. Experimental results confirm that AR successfully recovers baseline alignment in both watermarking approaches, while maintaining strong watermark detectability. This work reveals the critical balance between watermark strength and model alignment, providing a simple inference-time solution to responsibly deploy watermarked LLMs in practice.",
      "authors": [
        "Apurv Verma",
        "NhatHai Phan",
        "Shubhendu Trivedi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T21:29:07+00:00",
          "link": "https://arxiv.org/abs/2506.04462v1",
          "size": "4654kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:50:21+00:00",
          "link": "https://arxiv.org/abs/2506.04462v2",
          "size": "4848kb",
          "version": "v2"
        }
      ],
      "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04462",
        "PDF": "https://arxiv.org/pdf/2506.04462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes watermarking effects on model alignment properties rather than discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/dapurv5/alignmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07335",
      "abstract": "Graph transformers typically embed every node in a single Euclidean space, blurring heterogeneous topologies. We prepend a lightweight Riemannian mixture-of-experts layer that routes each node to various kinds of manifold, mixture of spherical, flat, hyperbolic - best matching its local structure. These projections provide intrinsic geometric explanations to the latent space. Inserted into a state-of-the-art ensemble graph transformer, this projector lifts accuracy by up to 3% on four node-classification benchmarks. The ensemble makes sure that both euclidean and non-euclidean features are captured. Explicit, geometry-aware projection thus sharpens predictive power while making graph representations more interpretable.",
      "authors": [
        "Ankit Jyothish and Ali Jannesari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:33:36+00:00",
          "link": "https://arxiv.org/abs/2507.07335v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07335",
        "HTML": "https://arxiv.org/html/2507.07335v1",
        "PDF": "https://arxiv.org/pdf/2507.07335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes enhancements in graph transformer representations using manifold embeddings, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07399",
      "abstract": "Statement autoformalization, the automated translation of statement from natural language into formal languages, has become a subject of extensive research, yet the development of robust automated evaluation metrics remains limited. Existing evaluation methods often lack semantic understanding, face challenges with high computational costs, and are constrained by the current progress of automated theorem proving. To address these issues, we propose GTED (Generalized Tree Edit Distance), a novel evaluation framework that first standardizes formal statements and converts them into operator trees, then determines the semantic similarity using the eponymous GTED metric. On the miniF2F and ProofNet benchmarks, GTED outperforms all baseline metrics by achieving the highest accuracy and Kappa scores, thus providing the community with a more faithful metric for automated evaluation. The code and experimental results are available at https://github.com/XiaoyangLiu-sjtu/GTED.",
      "authors": [
        "Yuntian Liu",
        "Tao Zhu",
        "Xiaoyang Liu",
        "Yu Chen",
        "Zhaoxuan Liu",
        "Qingfeng Guo",
        "Jiashuo Zhang",
        "Kangjie Bao",
        "Tao Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:34:58+00:00",
          "link": "https://arxiv.org/abs/2507.07399v1",
          "size": "436kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07399",
        "HTML": "https://arxiv.org/html/2507.07399v1",
        "PDF": "https://arxiv.org/pdf/2507.07399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new evaluation metric for statement autoformalization without discussing any LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07420",
      "abstract": "We introduce a generalized \\textit{Probabilistic Approximate Optimization Algorithm (PAOA)}, a classical variational Monte Carlo framework that extends and formalizes prior work by Weitz \\textit{et al.}~\\cite{Combes_2023}, enabling parameterized and fast sampling on present-day Ising machines and probabilistic computers. PAOA operates by iteratively modifying the couplings of a network of binary stochastic units, guided by cost evaluations from independent samples. We establish a direct correspondence between derivative-free updates and the gradient of the full $2^N \\times 2^N$ Markov flow, showing that PAOA admits a principled variational formulation. Simulated annealing emerges as a limiting case under constrained parameterizations, and we implement this regime on an FPGA-based probabilistic computer with on-chip annealing to solve large 3D spin-glass problems. Benchmarking PAOA against QAOA on the canonical 26-spin Sherrington-Kirkpatrick model with matched parameters reveals superior performance for PAOA. We show that PAOA naturally extends simulated annealing by optimizing multiple temperature profiles, leading to improved performance over SA on heavy-tailed problems such as SK-L\\'evy.",
      "authors": [
        "Abdelrahman S. Abdelrahman",
        "Shuvro Chowdhury",
        "Flaviano Morone",
        "and Kerem Y. Camsari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:26:13+00:00",
          "link": "https://arxiv.org/abs/2507.07420v1",
          "size": "8507kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Approximate Optimization: A New Variational Monte Carlo Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07420",
        "PDF": "https://arxiv.org/pdf/2507.07420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on a novel Monte Carlo algorithm for optimization, which is applied in a different domain than LLM training data, with no connection to processing or creating LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07842",
      "abstract": "Constant dimension codes (CDCs), as special subspace codes, have received extensive attention due to their applications in random network coding. The basic problem of CDCs is to determine the maximal possible size $A_q(n,d,\\{k\\})$ for given parameters $q, n, d$, and $k$. This paper introduces criteria for choosing appropriate bilateral identifying vectors compatible with the parallel mixed dimension construction (Des. Codes Cryptogr. 93(1):227--241, 2025). We then utilize the generalized bilateral multilevel construction (Des. Codes Cryptogr. 93(1):197--225, 2025) to improve the parallel mixed dimension construction efficiently. Many new CDCs that are better than the previously best-known codes are constructed.",
      "authors": [
        "Han Li and Fang-Wei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:15:58+00:00",
          "link": "https://arxiv.org/abs/2507.07842v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Generalized bilateral multilevel construction for constant dimension codes from parallel mixed dimension construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07842",
        "HTML": "https://arxiv.org/html/2507.07842v1",
        "PDF": "https://arxiv.org/pdf/2507.07842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the construction of constant dimension codes related to network coding, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07846",
      "abstract": "As the robotics systems increasingly integrate into daily life, from smart home assistants to the new-wave of industrial automation systems (Industry 4.0), there's an increasing need to bridge the gap between complex robotic systems and everyday users. The Robot Operating System (ROS) is a flexible framework often utilised in writing robot software, providing tools and libraries for building complex robotic systems. However, ROS's distributed architecture and technical messaging system create barriers for understanding robot status and diagnosing errors. This gap can lead to extended maintenance downtimes, as users with limited ROS knowledge may struggle to quickly diagnose and resolve system issues. Moreover, this deficit in expertise often delays proactive maintenance and troubleshooting, further increasing the frequency and duration of system interruptions. ROS Help Desk provides intuitive error explanations and debugging support, dynamically customized to users of varying expertise levels. It features user-centric debugging tools that simplify error diagnosis, implements proactive error detection capabilities to reduce downtime, and integrates multimodal data processing for comprehensive system state understanding across multi-sensor data (e.g., lidar, RGB). Testing qualitatively and quantitatively with artificially induced errors demonstrates the system's ability to proactively and accurately diagnose problems, ultimately reducing maintenance time and fostering more effective human-robot collaboration.",
      "authors": [
        "Kavindie Katuwandeniya and Samith Rajapaksha Jayasekara Widhanapathirana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:24:31+00:00",
          "link": "https://arxiv.org/abs/2507.07846v1",
          "size": "2358kb",
          "version": "v1"
        }
      ],
      "title": "ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error Diagnosis and Debugging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07846",
        "HTML": "https://arxiv.org/html/2507.07846v1",
        "PDF": "https://arxiv.org/pdf/2507.07846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a GenAI framework for diagnosing and debugging ROS errors, focusing on robot system usability and not on LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.17947",
      "abstract": "We study the refutation complexity of graph isomorphism in the tree-like resolution calculus. Tor\\'an and W\\\"orz (TOCL 2023) showed that there is a resolution refutation of narrow width $k$ for two graphs if and only if they can be distinguished in ($k+1$)-variable first-order logic (FO$^{k+1}$) and hence by a count-free variant of the $k$-dimensional Weisfeiler-Leman algorithm. While DAG-like narrow width $k$ resolution refutations have size at most $n^k$, tree-like refutations may be much larger. We show that there are graphs of order n, whose isomorphism can be refuted in narrow width $k$ but only in tree-like size $2^{\\Omega(n^{k/2})}$. This is a supercritical trade-off where bounding one parameter (the narrow width) causes the other parameter (the size) to grow above its worst case. The size lower bound is super-exponential in the formula size and improves a related supercritical width versus tree-like size trade-off by Razborov (JACM 2016). To prove our result, we develop a new variant of the $k$-pebble EF-game for FO$^k$ to reason about tree-like refutation size in a similar way as the Prover-Delayer games in proof complexity. We analyze this game on a modified variant of the compressed CFI graphs introduced by Grohe, Lichter, Neuen, and Schweitzer (FOCS 2023). Using a recent improved robust compressed CFI construction of Janett, Nordstr\\\"om, and Pang (unpublished manuscript), we obtain a similar bound for width $k$ (instead of the stronger but less common narrow width) and make the result more robust.",
      "authors": [
        "Christoph Berkholz",
        "Moritz Lichter",
        "Harry Vinall-Smeeth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-25T11:07:28+00:00",
          "link": "https://arxiv.org/abs/2407.17947v1",
          "size": "54kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:11:05+00:00",
          "link": "https://arxiv.org/abs/2407.17947v2",
          "size": "64kb",
          "version": "v2"
        }
      ],
      "title": "Supercritical Size-Width Tree-Like Resolution Trade-Offs for Graph Isomorphism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17947",
        "PDF": "https://arxiv.org/pdf/2407.17947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores resolution complexity in graph isomorphism but does not involve any LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03296",
      "abstract": "Deploying large language models (LLMs) for online inference is often constrained by limited GPU memory, particularly due to the growing KV cache during auto-regressive decoding. Hybrid GPU-CPU execution has emerged as a promising solution by offloading KV cache management and parts of attention computation to the CPU. However, a key bottleneck remains: existing schedulers fail to effectively overlap CPU-offloaded tasks with GPU execution during the latency-critical, bandwidth-bound decode phase. This particularly penalizes real-time, decode-heavy applications (e.g., chat, Chain-of-Thought reasoning) which are currently underserved by existing systems, especially under memory pressure typical of edge or low-cost deployments.\n  We present APEX, a novel, profiling-informed scheduling strategy that maximizes CPU-GPU parallelism during hybrid LLM inference. Unlike systems relying on static rules or purely heuristic approaches, APEX dynamically dispatches compute across heterogeneous resources by predicting execution times of CPU and GPU subtasks to maximize overlap while avoiding scheduling overheads. We evaluate APEX on diverse workloads and GPU architectures (NVIDIA T4, A10), using LLaMa-2-7B and LLaMa-3.1-8B models. Compared to GPU-only schedulers like VLLM, APEX improves throughput by 84% - 96% on T4 and 11% - 89% on A10 GPUs, while preserving latency. Against the best existing hybrid schedulers, it delivers up to 49% (T4) and 37% (A10) higher throughput in long-output settings. APEX significantly advances hybrid LLM inference efficiency on such memory-constrained hardware and provides a blueprint for scheduling in heterogeneous AI systems, filling a critical gap for efficient real-time LLM applications.",
      "authors": [
        "Jiakun Fan",
        "Yanglin Zhang",
        "Xiangchen Li",
        "Dimitrios S. Nikolopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T18:35:56+00:00",
          "link": "https://arxiv.org/abs/2506.03296v1",
          "size": "514kb",
          "version": "v1"
        },
        {
          "date": "2025-06-07T01:36:34+00:00",
          "link": "https://arxiv.org/abs/2506.03296v2",
          "size": "372kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T17:10:49+00:00",
          "link": "https://arxiv.org/abs/2506.03296v3",
          "size": "372kb",
          "version": "v3"
        }
      ],
      "title": "Parallel CPU-GPU Execution for LLM Inference on Constrained GPUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03296",
        "HTML": "https://arxiv.org/html/2506.03296v3",
        "PDF": "https://arxiv.org/pdf/2506.03296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The core of the paper is about execution optimization for LLM inference on constrained GPUs; it does not cover training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23446",
      "abstract": "Insider threat detection presents unique challenges due to the authorized status of malicious actors and the subtlety of anomalous behaviors. Existing machine learning methods often treat user activity as isolated events, thereby failing to leverage sequential dependencies in user behavior. In this study, we propose a User-Based Sequencing (UBS) methodology, transforming the CERT insider threat dataset into structured temporal sequences suitable for deep sequential modeling. We deploy a Transformer Encoder architecture to model benign user activity and employ its reconstruction errors as anomaly scores. These scores are subsequently evaluated using three unsupervised outlier detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and Isolation Forest (iForest). Across four rigorously designed test sets, including combinations of multiple CERT dataset releases, our UBS-Transformer pipeline consistently achieves state-of-the-art performance - notably 96.61% accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low false negative (0.0057) and false positive (0.0571) rates. Comparative analyses demonstrate that our approach substantially outperforms tabular and conventional autoencoder baselines, underscoring the efficacy of sequential user modeling and advanced anomaly detection in the insider threat domain.",
      "authors": [
        "Mohamed Elbasheer and Adewale Akinfaderin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:47:31+00:00",
          "link": "https://arxiv.org/abs/2506.23446v1",
          "size": "408kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:22:22+00:00",
          "link": "https://arxiv.org/abs/2506.23446v2",
          "size": "408kb",
          "version": "v2"
        }
      ],
      "title": "User-Based Sequential Modeling with Transformer Encoders for Insider Threat Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23446",
        "HTML": "https://arxiv.org/html/2506.23446v2",
        "PDF": "https://arxiv.org/pdf/2506.23446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper describes transforming an insider threat dataset into sequences for modeling, which involves some level of data processing, but mainly focuses on threat detection rather than LLM-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07144",
      "abstract": "As cloud services become increasingly integral to modern IT infrastructure, ensuring hardware reliability is essential to sustain high-quality service. Memory failures pose a significant threat to overall system stability, making accurate failure prediction through the analysis of memory error logs (i.e., Correctable Errors) imperative. Existing memory failure prediction approaches have notable limitations: rule-based expert models suffer from limited generalizability and low recall rates, while automated feature extraction methods exhibit suboptimal performance. To address these limitations, we propose M$^2$-MFP: a Multi-scale and hierarchical memory failure prediction framework designed to enhance the reliability and availability of cloud infrastructure. M$^2$-MFP converts Correctable Errors (CEs) into multi-level binary matrix representations and introduces a Binary Spatial Feature Extractor (BSFE) to automatically extract high-order features at both DIMM-level and bit-level. Building upon the BSFE outputs, we develop a dual-path temporal modeling architecture: 1) a time-patch module that aggregates multi-level features within observation windows, and 2) a time-point module that employs interpretable rule-generation trees trained on bit-level patterns. Experiments on both benchmark datasets and real-world deployment show the superiority of M$^2$-MFP as it outperforms existing state-of-the-art methods by significant margins. Code and data are available at this repository: https://github.com/hwcloud-RAS/M2-MFP.",
      "authors": [
        "Hongyi Xie",
        "Min Zhou",
        "Qiao Yu",
        "Jialiang Yu",
        "Zhenli Sheng",
        "Hong Xie",
        "Defu Lian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:50:13+00:00",
          "link": "https://arxiv.org/abs/2507.07144v1",
          "size": "313kb",
          "version": "v1"
        }
      ],
      "title": "M$^2$-MFP: A Multi-Scale and Multi-Level Memory Failure Prediction Framework for Reliable Cloud Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07144",
        "HTML": "https://arxiv.org/html/2507.07144v1",
        "PDF": "https://arxiv.org/pdf/2507.07144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for memory failure prediction in cloud infrastructure, focusing on hardware reliability rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07426",
      "abstract": "Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.",
      "authors": [
        "Zerui Yang and Yuwei Wan and Yinqiao Li and Yudai Matsuda and Tong Xie and Linqi Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:39:55+00:00",
          "link": "https://arxiv.org/abs/2507.07426v1",
          "size": "950kb",
          "version": "v1"
        }
      ],
      "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07426",
        "HTML": "https://arxiv.org/html/2507.07426v1",
        "PDF": "https://arxiv.org/pdf/2507.07426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on integrating RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing without discussing any particular methods for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07471",
      "abstract": "Query optimization is a fundamental task in database systems that is crucial to providing high performance. To evaluate learned and traditional optimizer's performance, several benchmarks, such as the widely used JOB benchmark, are used. However, in this paper, we argue that existing benchmarks are inherently limited, as they do not reflect many real-world properties of query optimization, thus overstating the performance of both traditional and learned optimizers. In fact, simple but realistic properties, such as joins over string columns or complex filter predicates, can drastically reduce the performance of existing query optimizers. Thus, we introduce JOB-Complex, a new benchmark designed to challenge traditional and learned query optimizers by reflecting real-world complexity. Overall, JOB-Complex contains 30 SQL queries and comes together with a plan-selection benchmark containing nearly 6000 execution plans, making it a valuable resource to evaluate the performance of query optimizers and cost models in real-world scenarios. In our evaluation, we show that traditional and learned cost models struggle to achieve high performance on JOB-Complex, providing a runtime of up to 11x slower compared to the optimal plans.",
      "authors": [
        "Johannes Wehrstein",
        "Timo Eckmann",
        "Roman Heinrich",
        "Carsten Binnig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:57:54+00:00",
          "link": "https://arxiv.org/abs/2507.07471v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "JOB-Complex: A Challenging Benchmark for Traditional & Learned Query Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07471",
        "HTML": "https://arxiv.org/html/2507.07471v1",
        "PDF": "https://arxiv.org/pdf/2507.07471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for query optimization and does not discuss any LLM training data processing tasks or create new datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07562",
      "abstract": "Large vision-language models (VLMs) increasingly adopt post-training techniques such as long chain-of-thought (CoT) supervised fine-tuning (SFT) and reinforcement learning (RL) to elicit sophisticated reasoning. While these methods exhibit synergy in language-only models, their joint effectiveness in VLMs remains uncertain. We present a systematic investigation into the distinct roles and interplay of long-CoT SFT and RL across multiple multimodal reasoning benchmarks. We find that SFT improves performance on difficult questions by in-depth, structured reasoning, but introduces verbosity and degrades performance on simpler ones. In contrast, RL promotes generalization and brevity, yielding consistent improvements across all difficulty levels, though the improvements on the hardest questions are less prominent compared to SFT. Surprisingly, combining them through two-staged, interleaved, or progressive training strategies, as well as data mixing and model merging, all fails to produce additive benefits, instead leading to trade-offs in accuracy, reasoning style, and response length. This ``synergy dilemma'' highlights the need for more seamless and adaptive approaches to unlock the full potential of combined post-training techniques for reasoning VLMs.",
      "authors": [
        "Jierun Chen",
        "Tiezheng Yu",
        "Haoli Bai",
        "Lewei Yao",
        "Jiannan Wu",
        "Kaican Li",
        "Fei Mi",
        "Chaofan Tao",
        "Lei Zhu",
        "Manyi Zhang",
        "Xiaohui Li",
        "Lu Hou",
        "Lifeng Shang",
        "Qun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:05:49+00:00",
          "link": "https://arxiv.org/abs/2507.07562v1",
          "size": "1041kb",
          "version": "v1"
        }
      ],
      "title": "The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07562",
        "HTML": "https://arxiv.org/html/2507.07562v1",
        "PDF": "https://arxiv.org/pdf/2507.07562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on the synergy of post-training techniques like supervised fine-tuning and reinforcement learning, but does not significantly address processing or improving LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07638",
      "abstract": "Facial Expression Recognition (FER) systems based on deep learning have achieved impressive performance in recent years. However, these models often exhibit demographic biases, particularly with respect to age, which can compromise their fairness and reliability. In this work, we present a comprehensive study of age-related bias in deep FER models, with a particular focus on the elderly population. We first investigate whether recognition performance varies across age groups, which expressions are most affected, and whether model attention differs depending on age. Using Explainable AI (XAI) techniques, we identify systematic disparities in expression recognition and attention patterns, especially for \"neutral\", \"sadness\", and \"anger\" in elderly individuals. Based on these findings, we propose and evaluate three bias mitigation strategies: Multi-task Learning, Multi-modal Input, and Age-weighted Loss. Our models are trained on a large-scale dataset, AffectNet, with automatically estimated age labels and validated on balanced benchmark datasets that include underrepresented age groups. Results show consistent improvements in recognition accuracy for elderly individuals, particularly for the most error-prone expressions. Saliency heatmap analysis reveals that models trained with age-aware strategies attend to more relevant facial regions for each age group, helping to explain the observed improvements. These findings suggest that age-related bias in FER can be effectively mitigated using simple training modifications, and that even approximate demographic labels can be valuable for promoting fairness in large-scale affective computing systems.",
      "authors": [
        "F. Xavier Gaya-Morey",
        "Julia Sanchez-Perez",
        "Cristina Manresa-Yee",
        "Jose M. Buades-Rubio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:07:13+00:00",
          "link": "https://arxiv.org/abs/2507.07638v1",
          "size": "5628kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the gap in FER: addressing age bias in deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07638",
        "HTML": "https://arxiv.org/html/2507.07638v1",
        "PDF": "https://arxiv.org/pdf/2507.07638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study aims to mitigate age bias in FER systems using training modifications but primarily focuses on model bias reduction rather than LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02137",
      "abstract": "Software development relies heavily on text-based communication, making sentiment analysis a valuable tool for understanding team dynamics and supporting trustworthy AI-driven analytics in requirements engineering. However, existing sentiment analysis tools often perform inconsistently across datasets from different platforms, due to variations in communication style and content.\n  In this study, we analyze linguistic and statistical features of 10 developer communication datasets from five platforms and evaluate the performance of 14 sentiment analysis tools. Based on these results, we propose a mapping approach and questionnaire that recommends suitable sentiment analysis tools for new datasets, using their characteristic features as input.\n  Our results show that dataset characteristics can be leveraged to improve tool selection, as platforms differ substantially in both linguistic and statistical properties. While transformer-based models such as SetFit and RoBERTa consistently achieve strong results, tool effectiveness remains context-dependent. Our approach supports researchers and practitioners in selecting trustworthy tools for sentiment analysis in software engineering, while highlighting the need for ongoing evaluation as communication contexts evolve.",
      "authors": [
        "Martin Obaidi",
        "Marc Herrmann",
        "Jil Kl\\\"under",
        "Kurt Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:50:25+00:00",
          "link": "https://arxiv.org/abs/2507.02137v1",
          "size": "145kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T23:22:02+00:00",
          "link": "https://arxiv.org/abs/2507.02137v2",
          "size": "146kb",
          "version": "v2"
        }
      ],
      "title": "Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02137",
        "HTML": "https://arxiv.org/html/2507.02137v2",
        "PDF": "https://arxiv.org/pdf/2507.02137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sentiment analysis tool selection using dataset characteristics in software engineering, but does not address LLM training data processing or dataset creation relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07130",
      "abstract": "A Federated Learning (FL) system collaboratively trains neural networks across devices and a server but is limited by significant on-device computation costs. Split Federated Learning (SFL) systems mitigate this by offloading a block of layers of the network from the device to a server. However, in doing so, it introduces large communication overheads due to frequent exchanges of intermediate activations and gradients between devices and the server and reduces model accuracy for non-IID data. We propose Ampere, a novel collaborative training system that simultaneously minimizes on-device computation and device-server communication while improving model accuracy. Unlike SFL, which uses a global loss by iterative end-to-end training, Ampere develops unidirectional inter-block training to sequentially train the device and server block with a local loss, eliminating the transfer of gradients. A lightweight auxiliary network generation method decouples training between the device and server, reducing frequent intermediate exchanges to a single transfer, which significantly reduces the communication overhead. Ampere mitigates the impact of data heterogeneity by consolidating activations generated by the trained device block to train the server block, in contrast to SFL, which trains on device-specific, non-IID activations. Extensive experiments on multiple CNNs and transformers show that, compared to state-of-the-art SFL baseline systems, Ampere (i) improves model accuracy by up to 13.26% while reducing training time by up to 94.6%, (ii) reduces device-server communication overhead by up to 99.1% and on-device computation by up to 93.13%, and (iii) reduces standard deviation of accuracy by 53.39% for various non-IID degrees highlighting superior performance when faced with heterogeneous data.",
      "authors": [
        "Zihan Zhang",
        "Leon Wong and Blesson Varghese"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:54:43+00:00",
          "link": "https://arxiv.org/abs/2507.07130v1",
          "size": "3527kb",
          "version": "v1"
        }
      ],
      "title": "Ampere: Communication-Efficient and High-Accuracy Split Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07130",
        "PDF": "https://arxiv.org/pdf/2507.07130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses federated learning and data heterogeneity, it focuses primarily on model training efficiency, communication costs, and improving accuracy, rather than processing LLM training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07461",
      "abstract": "When performing Bayesian inference using Sequential Monte Carlo (SMC) methods, two considerations arise: the accuracy of the posterior approximation and computational efficiency. To address computational demands, Sequential Monte Carlo Squared (SMC$^2$) is well-suited for high-performance computing (HPC) environments. The design of the proposal distribution within SMC$^2$ can improve accuracy and exploration of the posterior as poor proposals may lead to high variance in importance weights and particle degeneracy. The Metropolis-Adjusted Langevin Algorithm (MALA) uses gradient information so that particles preferentially explore regions of higher probability. In this paper, we extend this idea by incorporating second-order information, specifically the Hessian of the log-target. While second-order proposals have been explored previously in particle Markov Chain Monte Carlo (p-MCMC) methods, we are the first to introduce them within the SMC$^2$ framework. Second-order proposals not only use the gradient (first-order derivative), but also the curvature (second-order derivative) of the target distribution. Experimental results on synthetic models highlight the benefits of our approach in terms of step-size selection and posterior approximation accuracy when compared to other proposals.",
      "authors": [
        "Joshua Murphy",
        "Conor Rosato",
        "Andrew Millard",
        "Lee Devlin",
        "Paul Horridge",
        "Simon Maskell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:26:54+00:00",
          "link": "https://arxiv.org/abs/2507.07461v1",
          "size": "92kb",
          "version": "v1"
        }
      ],
      "title": "Hess-MC2: Sequential Monte Carlo Squared using Hessian Information and Second Order Proposals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07461",
        "HTML": "https://arxiv.org/html/2507.07461v1",
        "PDF": "https://arxiv.org/pdf/2507.07461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with Bayesian inference using SMC$^2$ and does not focus on LLM training data or data processing methodologies relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07874",
      "abstract": "Information processing in neural populations is inherently constrained by metabolic resource limits and noise properties, with dynamics that are not accurately described by existing mathematical models. Recent data, for example, shows that neurons in mouse visual cortex go into a \"low power mode\" in which they maintain firing rate homeostasis while expending less energy. This adaptation leads to increased neuronal noise and tuning curve flattening in response to metabolic stress. We have developed a theoretical population coding framework that captures this behavior using two novel, surprisingly simple constraints: an approximation of firing rate homeostasis and an energy limit tied to noise levels via biophysical simulation. A key feature of our contribution is an energy budget model directly connecting adenosine triphosphate (ATP) use in cells to a fully explainable mathematical framework that generalizes existing optimal population codes. Specifically, our simulation provides an energy-dependent dispersed Poisson noise model, based on the assumption that the cell will follow an optimal decay path to produce the least-noisy spike rate that is possible at a given cellular energy budget. Each state along this optimal path is associated with properties (resting potential and leak conductance) which can be measured in electrophysiology experiments and have been shown to change under prolonged caloric deprivation. We analytically derive the optimal coding strategy for neurons under varying energy budgets and coding goals, and show how our method uniquely captures how populations of tuning curves adapt while maintaining homeostasis, as has been observed empirically.",
      "authors": [
        "Yi-Chun Hung",
        "Gregory Schwartz",
        "Emily A. Cooper",
        "Emma Alexander"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:58:57+00:00",
          "link": "https://arxiv.org/abs/2507.07874v1",
          "size": "4692kb",
          "version": "v1"
        }
      ],
      "title": "Homeostatic Adaptation of Optimal Population Codes under Metabolic Stress",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07874",
        "HTML": "https://arxiv.org/html/2507.07874v1",
        "PDF": "https://arxiv.org/pdf/2507.07874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural population coding frameworks under metabolic stress and energy constraints, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03251",
      "abstract": "Speech Emotion Recognition (SER) traditionally relies on auditory data analysis for emotion classification. Several studies have adopted different methods for SER. However, existing SER methods often struggle to capture subtle emotional variations and generalize across diverse datasets. In this article, we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to bridge the gap between computational emotion processing and human auditory perception. To further improve robustness and feature diversity, we propose a novel 1D-CNN-based SER framework that integrates data augmentation techniques. MFCC features extracted from the augmented data are processed using a 1D Convolutional Neural Network (CNN) architecture enhanced with channel and spatial attention mechanisms. These attention modules allow the model to highlight key emotional patterns, enhancing its ability to capture subtle variations in speech signals. The proposed method delivers cutting-edge performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS, 89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO. Experimental results show new benchmarks in SER, demonstrating the effectiveness of our approach in recognizing emotional expressions with high precision. Our evaluation demonstrates that the integration of advanced Deep Learning (DL) methods substantially enhances generalization across diverse datasets, underscoring their potential to advance SER for real-world deployment in assistive technologies and human-computer interaction.",
      "authors": [
        "HyeYoung Lee",
        "Muhammad Nadeem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T01:55:49+00:00",
          "link": "https://arxiv.org/abs/2507.03251v1",
          "size": "8086kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:11:03+00:00",
          "link": "https://arxiv.org/abs/2507.03251v2",
          "size": "8086kb",
          "version": "v2"
        }
      ],
      "title": "Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03251",
        "HTML": "https://arxiv.org/html/2507.03251v2",
        "PDF": "https://arxiv.org/pdf/2507.03251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on speech emotion recognition using data augmentation, focusing on feature extraction and SER frameworks, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06352",
      "abstract": "This study presents an analytical method for tuning PI controllers in First-Order with Time Delay (FOTD) systems, leveraging the Lambert W function. The Lambert W function enables exact pole placement, yielding analytical expressions for PI gains. The proposed approach identifies a critical condition that achieves a step response without overshoot with minimum settling time, while also providing explicit tuning rules for systems where controlled overshoot is specified. The method demonstrates strong agreement with established empirical Chien-Hrones-Reswick tuning rules for both non-overshooting and overshooting cases, bridging the gap between theoretical analysis and empirical results.",
      "authors": [
        "Senol Gulgonul"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:25:01+00:00",
          "link": "https://arxiv.org/abs/2507.06352v1",
          "size": "342kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:34:03+00:00",
          "link": "https://arxiv.org/abs/2507.06352v2",
          "size": "341kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Chien-Hrones-Reswick Method for an Analytical Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06352",
        "PDF": "https://arxiv.org/pdf/2507.06352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a method for tuning PI controllers in FOTD systems using the Lambert W function and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07157",
      "abstract": "Decoding visual experience from brain signals offers exciting possibilities for neuroscience and interpretable AI. While EEG is accessible and temporally precise, its limitations in spatial detail hinder image reconstruction. Our model bypasses direct EEG-to-image generation by aligning EEG signals with multilevel semantic captions -- ranging from object-level to abstract themes -- generated by a large language model. A transformer-based EEG encoder maps brain activity to these captions through contrastive learning. During inference, caption embeddings retrieved via projection heads condition a pretrained latent diffusion model for image generation. This text-mediated framework yields state-of-the-art visual decoding on the EEGCVPR dataset, with interpretable alignment to known neurocognitive pathways. Dominant EEG-caption associations reflected the importance of different semantic levels extracted from perceived images. Saliency maps and t-SNE projections reveal semantic topography across the scalp. Our model demonstrates how structured semantic mediation enables cognitively aligned visual decoding from EEG.",
      "authors": [
        "Arshak Rezvani",
        "Ali Akbari",
        "Kosar Sanjar Arani",
        "Maryam Mirian",
        "Emad Arasteh",
        "Martin J. McKeown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:18:06+00:00",
          "link": "https://arxiv.org/abs/2507.07157v1",
          "size": "10424kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable EEG-to-Image Generation with Semantic Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07157",
        "HTML": "https://arxiv.org/html/2507.07157v1",
        "PDF": "https://arxiv.org/pdf/2507.07157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on EEG-to-image generation using semantic prompts and does not engage with LLM training data preparation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07222",
      "abstract": "The Koopman operator provides a principled framework for analyzing nonlinear dynamical systems through linear operator theory. Recent advances in dynamic mode decomposition (DMD) have shown that trajectory data can be used to identify dominant modes of a system in a data-driven manner. Building on this idea, deep learning methods such as VAMPnet and DPNet have been proposed to learn the leading singular subspaces of the Koopman operator. However, these methods require backpropagation through potentially numerically unstable operations on empirical second moment matrices, such as singular value decomposition and matrix inversion, during objective computation, which can introduce biased gradient estimates and hinder scalability to large systems. In this work, we propose a scalable and conceptually simple method for learning the top-k singular functions of the Koopman operator for stochastic dynamical systems based on the idea of low-rank approximation. Our approach eliminates the need for unstable linear algebraic operations and integrates easily into modern deep learning pipelines. Empirical results demonstrate that the learned singular subspaces are both reliable and effective for downstream tasks such as eigen-analysis and multi-step prediction.",
      "authors": [
        "Minchan Jeong",
        "J. Jon Ryu",
        "Se-Young Yun",
        "Gregory W. Wornell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:55:48+00:00",
          "link": "https://arxiv.org/abs/2507.07222v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Parametric SVD of Koopman Operator for Stochastic Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07222",
        "PDF": "https://arxiv.org/pdf/2507.07222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for learning singular functions of the Koopman operator for dynamical systems, focusing on scalable computation, but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07244",
      "abstract": "In the ever-evolving landscape of cybersecurity, the rapid identification and mitigation of Advanced Persistent Threats (APTs) is crucial. Security practitioners rely on detailed threat reports to understand the tactics, techniques, and procedures (TTPs) employed by attackers. However, manually extracting attack testflows from these reports requires elusive knowledge and is time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a novel solution leveraging language models (i.e., BERT) and Natural Language Processing (NLP) techniques to automate the extraction of attack testflows from unstructured threat reports. FLOWGUARDIAN systematically analyzes and contextualizes security events, reconstructs attack sequences, and then generates comprehensive testflows. This automated approach not only saves time and reduces human error but also ensures comprehensive coverage and robustness in cybersecurity testing. Empirical validation using public threat reports demonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing the capabilities of security teams in proactive threat hunting and incident response.",
      "authors": [
        "Faissal Ahmadou",
        "Sepehr Ghaffarzadegan",
        "Boubakr Nour",
        "Makan Pourzandi",
        "Mourad Debbabi",
        "Chadi Assi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:33:13+00:00",
          "link": "https://arxiv.org/abs/2507.07244v1",
          "size": "880kb",
          "version": "v1"
        }
      ],
      "title": "Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07244",
        "HTML": "https://arxiv.org/html/2507.07244v1",
        "PDF": "https://arxiv.org/pdf/2507.07244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about automating the extraction of attack testflows using NLP techniques, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07416",
      "abstract": "Critical infrastructure systems, including energy grids, healthcare facilities, transportation networks, and water distribution systems, are pivotal to societal stability and economic resilience. However, the increasing interconnectivity of these systems exposes them to various cyber threats, including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent Threats (APTs). This paper examines cybersecurity vulnerabilities in critical infrastructure, highlighting the threat landscape, attack vectors, and the role of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid AI-driven cybersecurity framework to enhance real-time vulnerability detection, threat modelling, and automated remediation. This study also addresses the complexities of adversarial AI, regulatory compliance, and integration. Our findings provide actionable insights to strengthen the security and resilience of critical infrastructure systems against emerging cyber threats.",
      "authors": [
        "Jenifer Paulraj",
        "Brindha Raghuraman",
        "Nagarani Gopalakrishnan",
        "Yazan Otoum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:17:29+00:00",
          "link": "https://arxiv.org/abs/2507.07416v1",
          "size": "687kb",
          "version": "v1"
        }
      ],
      "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07416",
        "HTML": "https://arxiv.org/html/2507.07416v1",
        "PDF": "https://arxiv.org/pdf/2507.07416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an AI-driven cybersecurity framework for critical infrastructure, focusing on real-time threat mitigation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07440",
      "abstract": "Modeling the dynamic behavior of deformable objects is crucial for creating realistic digital worlds. While conventional simulations produce high-quality motions, their computational costs are often prohibitive. Subspace simulation techniques address this challenge by restricting deformations to a lower-dimensional space, improving performance while maintaining visually compelling results. However, even subspace methods struggle to meet the stringent performance demands of portable devices such as virtual reality headsets and mobile platforms. To overcome this limitation, we introduce a novel subspace simulation framework powered by a neural latent-space integrator. Our approach leverages self-supervised learning to enhance inference stability and generalization. By operating entirely within latent space, our method eliminates the need for full-space computations, resulting in a highly efficient method well-suited for deployment on portable devices. We demonstrate the effectiveness of our approach on challenging examples involving rods, shells, and solids, showcasing its versatility and potential for widespread adoption.",
      "authors": [
        "Yue Li",
        "Gene Wei-Chin Lin",
        "Egor Larionov",
        "Aljaz Bozic",
        "Doug Roble",
        "Ladislav Kavan",
        "Stelian Coros",
        "Bernhard Thomaszewski",
        "Tuur Stuyck",
        "Hsiao-yu Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:30:02+00:00",
          "link": "https://arxiv.org/abs/2507.07440v1",
          "size": "9988kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised Learning of Latent Space Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07440",
        "HTML": "https://arxiv.org/html/2507.07440v1",
        "PDF": "https://arxiv.org/pdf/2507.07440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses subspace simulation techniques for deformable object dynamics rather than any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07910",
      "abstract": "The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at https://github.com/AdhyaSuman/DTECT.",
      "authors": [
        "Suman Adhya and Debarshi Kumar Sanyal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:44:33+00:00",
          "link": "https://arxiv.org/abs/2507.07910v1",
          "size": "949kb",
          "version": "v1"
        }
      ],
      "title": "DTECT: Dynamic Topic Explorer & Context Tracker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07910",
        "HTML": "https://arxiv.org/html/2507.07910v1",
        "PDF": "https://arxiv.org/pdf/2507.07910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses DTECT, a dynamic topic modeling system which involves data preprocessing but primarily focuses on model architectures and visualization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.13940",
      "abstract": "Large Language Models (LLMs) have shown impressive reasoning capabilities, yet existing prompting methods face a critical trade-off: simple approaches often struggle with complex tasks and reasoning stability, while more sophisticated methods require multiple inferences and substantial computational resources, limiting their practical deployment. To address this challenge, we propose Derailer-Rerailer, a novel framework that adaptively balances reasoning accuracy and computational efficiency. At its core, our framework employs a lightweight Derailer mechanism to assess reasoning stability and selectively triggers an advanced Rerailer verification process only when necessary, thereby optimizing computational resource usage. Extensive evaluation across both open and closed-source models on more than 20 categories of mathematical, symbolic, and commonsense reasoning tasks demonstrates our framework's effectiveness: Derailer-Rerailer achieves significant accuracy improvements (8-11\\% across various reasoning tasks) while maintaining 2-3 times better efficiency than existing verification methods, with particularly strong performance in mathematical and symbolic reasoning, offering a practical solution for enhancing LLM reasoning reliability while significantly reducing computational overhead.",
      "authors": [
        "Guangya Wan",
        "Yuqi Wu",
        "Hao Wang",
        "Shengming Zhao",
        "Jie Chen",
        "Sheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-25T21:20:17+00:00",
          "link": "https://arxiv.org/abs/2408.13940v1",
          "size": "37254kb",
          "version": "v1"
        },
        {
          "date": "2024-09-17T22:19:17+00:00",
          "link": "https://arxiv.org/abs/2408.13940v2",
          "size": "37248kb",
          "version": "v2"
        },
        {
          "date": "2025-03-02T12:11:13+00:00",
          "link": "https://arxiv.org/abs/2408.13940v3",
          "size": "13261kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T18:39:59+00:00",
          "link": "https://arxiv.org/abs/2408.13940v4",
          "size": "11764kb",
          "version": "v4"
        }
      ],
      "title": "Derailer-Rerailer: Adaptive Verification for Efficient and Reliable Language Model Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.13940",
        "HTML": "https://arxiv.org/html/2408.13940v4",
        "PDF": "https://arxiv.org/pdf/2408.13940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving reasoning capabilities of LLMs using a verification framework, but does not focus on the processing or creation of training data for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06795",
      "abstract": "The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.",
      "authors": [
        "Seonwu Kim",
        "Yohan Na",
        "Kihun Kim",
        "Hanhee Cho",
        "Geun Lim",
        "Mintae Kim",
        "Seongik Park",
        "Ki Hyun Kim",
        "Youngsub Han",
        "Byoung-Ki Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:30:42+00:00",
          "link": "https://arxiv.org/abs/2507.06795v1",
          "size": "1050kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:05:41+00:00",
          "link": "https://arxiv.org/abs/2507.06795v2",
          "size": "1050kb",
          "version": "v2"
        }
      ],
      "title": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06795",
        "HTML": "https://arxiv.org/html/2507.06795v2",
        "PDF": "https://arxiv.org/pdf/2507.06795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions Domain Adaptive Continual Pretraining for performance gains in sLLMs, it primarily focuses on model deployment and application rather than substantial training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07323",
      "abstract": "In this paper, deceptive signal-assisted private split learning is investigated. In our model, several edge devices jointly perform collaborative training, and some eavesdroppers aim to collect the model and data information from devices. To prevent the eavesdroppers from collecting model and data information, a subset of devices can transmit deceptive signals. Therefore, it is necessary to determine the subset of devices used for deceptive signal transmission, the subset of model training devices, and the models assigned to each model training device. This problem is formulated as an optimization problem whose goal is to minimize the information leaked to eavesdroppers while meeting the model training energy consumption and delay constraints. To solve this problem, we propose a soft actor-critic deep reinforcement learning framework with intrinsic curiosity module and cross-attention (ICM-CA) that enables a centralized agent to determine the model training devices, the deceptive signal transmission devices, the transmit power, and sub-models assigned to each model training device without knowing the position and monitoring probability of eavesdroppers. The proposed method uses an ICM module to encourage the server to explore novel actions and states and a CA module to determine the importance of each historical state-action pair thus improving training efficiency. Simulation results demonstrate that the proposed method improves the convergence rate by up to 3x and reduces the information leaked to eavesdroppers by up to 13% compared to the traditional SAC algorithm.",
      "authors": [
        "Dongyu Wei",
        "Xiaoren Xu",
        "Yuchen Liu",
        "H. Vincent Poor",
        "Mingzhe Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:53:23+00:00",
          "link": "https://arxiv.org/abs/2507.07323v1",
          "size": "883kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07323",
        "HTML": "https://arxiv.org/html/2507.07323v1",
        "PDF": "https://arxiv.org/pdf/2507.07323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on deceptive signal-assisted private split learning and optimizing model splitting and device assignment, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07725",
      "abstract": "Post-training alignment of large language models (LLMs) is a critical challenge, as not all tokens contribute equally to model performance. This paper introduces a selective alignment strategy that prioritizes high-impact tokens within preference pairs, leveraging token-level log-probability differences between the current policy and a reference model. By focusing on these informative tokens, our approach reduces computational overhead and enhances alignment fidelity. We further explore the role of reference model quality, demonstrating that stronger reference models significantly improve token selection accuracy and overall optimization effectiveness. Comprehensive experiments on benchmarks such as Arena-Hard and MT-Bench validate the superiority of our Selective-DPO method over standard DPO and distillation-based baselines. Our findings highlight the importance of token-level optimization and reference model selection in advancing preference alignment for LLMs. The code is available at https://github.com/Dongzhijin/SDPO.",
      "authors": [
        "Zhijin Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:58:45+00:00",
          "link": "https://arxiv.org/abs/2507.07725v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07725",
        "HTML": "https://arxiv.org/html/2507.07725v1",
        "PDF": "https://arxiv.org/pdf/2507.07725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a selective alignment strategy for post-training alignment in LLMs, focusing on token-level optimization rather than the training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.07430",
      "abstract": "The emergence of global health crises, such as COVID-19 and Monkeypox (mpox), has underscored the importance of understanding public sentiment to inform effective public health strategies. This study conducts a comparative sentiment analysis of public perceptions surrounding COVID-19 and mpox by leveraging extensive datasets of 147,475 and 106,638 tweets, respectively. Advanced machine learning models, including Logistic Regression, Naive Bayes, RoBERTa, DistilRoBERTa and XLNet, were applied to perform sentiment classification, with results indicating key trends in public emotion and discourse. The analysis highlights significant differences in public sentiment driven by disease characteristics, media representation, and pandemic fatigue. Through the lens of sentiment polarity and thematic trends, this study offers valuable insights into tailoring public health messaging, mitigating misinformation, and fostering trust during concurrent health crises. The findings contribute to advancing sentiment analysis applications in public health informatics, setting the groundwork for enhanced real-time monitoring and multilingual analysis in future research.",
      "authors": [
        "Mostafa Mohaimen Akand Faisal and Rabeya Amin Jhuma and Jamini Jasim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T10:37:33+00:00",
          "link": "https://arxiv.org/abs/2505.07430v1",
          "size": "3745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:54:37+00:00",
          "link": "https://arxiv.org/abs/2505.07430v2",
          "size": "3745kb",
          "version": "v2"
        }
      ],
      "title": "Comparative sentiment analysis of public perception: Monkeypox vs. COVID-19 behavioral insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07430",
        "HTML": "https://arxiv.org/html/2505.07430v2",
        "PDF": "https://arxiv.org/pdf/2505.07430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses sentiment analysis using existing datasets of tweets without substantive modifications or processing of LLM training data itself."
      },
      "tasks": [
        "Misinformation",
        "Sentiment Analysis",
        "Sentiment Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05116",
      "abstract": "Recent large-scale Vision Language Action (VLA) models have shown superior performance in robotic manipulation tasks guided by natural language. However, their generalization remains limited when applied to novel objects or unfamiliar environments that lie outside the training distribution. To address this, many existing approaches integrate additional components such as depth estimation, segmentation, or even diffusion to improve generalization, at the cost of adding significant computation overhead, resulting in low efficiency. This motivates the exploration of efficient action prediction methods, which are independent of additional high-level visual representations or diffusion techniques. In this work, we propose VOTE, an efficient and general framework for the optimization and acceleration of VLA models. In details, we propose a novel tokenizer-free fine-tuning approach for parallel accurate action prediction, which reduces computational overhead and accelerates inference speed. Additionally, we adopt an ensemble voting strategy for the action sampling, which significantly improves model performance and enhances generalization. Experimental results show that our method achieves state-of-the-art performance with 35x faster inference and 145 Hz throughput. All the details and codes will be open-sourced.",
      "authors": [
        "Juyi Lin",
        "Amir Taherin",
        "Arash Akbari",
        "Arman Akbari",
        "Lei Lu",
        "Guangyu Chen",
        "Taskin Padir",
        "Xiaomeng Yang",
        "Weiwei Chen",
        "Yiqian Li",
        "Xue Lin",
        "David Kaeli",
        "Pu Zhao",
        "and Yanzhi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:30:55+00:00",
          "link": "https://arxiv.org/abs/2507.05116v1",
          "size": "660kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:53:51+00:00",
          "link": "https://arxiv.org/abs/2507.05116v2",
          "size": "660kb",
          "version": "v2"
        }
      ],
      "title": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05116",
        "HTML": "https://arxiv.org/html/2507.05116v2",
        "PDF": "https://arxiv.org/pdf/2507.05116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes optimization methods for Vision-Language-Action models, emphasizing action prediction efficiency; it doesn't relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07630",
      "abstract": "Large Language Models (LLMs) have demonstrated outstanding performance across a range of NLP tasks, however, their computational demands hinder their deployment in real-world, resource-constrained environments. This work investigates the extent to which LLMs can be compressed using Knowledge Distillation (KD) while maintaining strong performance on Question Answering (QA) tasks. We evaluate student models distilled from the Pythia and Qwen2.5 families on two QA benchmarks, SQuAD and MLQA, under zero-shot and one-shot prompting conditions. Results show that student models retain over 90% of their teacher models' performance while reducing parameter counts by up to 57.1%. Furthermore, one-shot prompting yields additional performance gains over zero-shot setups for both model families. These findings underscore the trade-off between model efficiency and task performance, demonstrating that KD, combined with minimal prompting, can yield compact yet capable QA systems suitable for resource-constrained applications.",
      "authors": [
        "Joyeeta Datta and Niclas Doll and Qusai Ramadan and Zeyd Boukhers"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.07630v1",
          "size": "591kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Limits of Model Compression in LLMs: A Knowledge Distillation Study on QA Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07630",
        "HTML": "https://arxiv.org/html/2507.07630v1",
        "PDF": "https://arxiv.org/pdf/2507.07630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates model compression techniques (Knowledge Distillation) for LLMs, specifically regarding QA tasks, but does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07838",
      "abstract": "Surface defects are one of the largest contributors to low yield in the manufacturing sector. Accurate and reliable detection of defects during the manufacturing process is therefore of great value across the sector. State-of-the-art approaches to automated defect detection yield impressive performance on current datasets, yet still fall short in real-world manufacturing settings and developing improved methods relies on large datasets representative of real-world scenarios. Unfortunately, high-quality, high-precision RGB+3D industrial anomaly detection datasets are scarce, and typically do not reflect real-world industrial deployment scenarios. To address this, we introduce 3D-ADAM, the first large-scale industry-relevant dataset for high-precision 3D Anomaly Detection. 3D-ADAM comprises 14,120 high-resolution scans across 217 unique parts, captured using 4 industrial depth imaging sensors. It includes 27,346 annotated defect instances from 12 categories, covering the breadth of industrial surface defects. 3D-ADAM uniquely captures an additional 8,110 annotations of machine element features, spanning the range of relevant mechanical design form factors. Unlike existing datasets, 3D-ADAM is captured in a real industrial environment with variations in part position and orientation, camera positioning, ambient lighting conditions, as well as partial occlusions. Our evaluation of SOTA models across various RGB+3D anomaly detection tasks demonstrates the significant challenge this dataset presents to current approaches. We further validated the industrial relevance and quality of the dataset through an expert labelling survey conducted by industry partners. By providing this challenging benchmark, 3D-ADAM aims to accelerate the development of robust 3D Anomaly Detection models capable of meeting the demands of modern manufacturing environments.",
      "authors": [
        "Paul McHard",
        "Florent P. Audonnet",
        "Oliver Summerell",
        "Sebastian Andraos",
        "Paul Henderson",
        "Gerardo Aragon-Camarasa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:09:20+00:00",
          "link": "https://arxiv.org/abs/2507.07838v1",
          "size": "27841kb",
          "version": "v1"
        }
      ],
      "title": "3D-ADAM: A Dataset for 3D Anomaly Detection in Advanced Manufacturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07838",
        "HTML": "https://arxiv.org/html/2507.07838v1",
        "PDF": "https://arxiv.org/pdf/2507.07838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset for 3D anomaly detection in manufacturing, detailing its collection and the challenge it presents for machine learning models which is relevant to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.09260",
      "abstract": "This paper introduces a deep transformer network for estimating the relative 6D pose of a Unmanned Aerial Vehicle (UAV) with respect to a ship using monocular images. A synthetic dataset of ship images is created and annotated with 2D keypoints of multiple ship parts. A Transformer Neural Network model is trained to detect these keypoints and estimate the 6D pose of each part. The estimates are integrated using Bayesian fusion. The model is tested on synthetic data and in-situ flight experiments, demonstrating robustness and accuracy in various lighting conditions. The position estimation error is approximately 0.8\\% and 1.0\\% of the distance to the ship for the synthetic data and the flight experiments, respectively. The method has potential applications for ship-based autonomous UAV landing and navigation.",
      "authors": [
        "Maneesha Wickramasuriya",
        "Taeyoung Lee",
        "Murray Snyder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-13T16:01:22+00:00",
          "link": "https://arxiv.org/abs/2406.09260v1",
          "size": "28215kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T23:23:59+00:00",
          "link": "https://arxiv.org/abs/2406.09260v2",
          "size": "7221kb",
          "version": "v2"
        }
      ],
      "title": "Deep Transformer Network for Monocular Pose Estimation of Shipborne Unmanned Aerial Vehicle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.09260",
        "HTML": "https://arxiv.org/html/2406.09260",
        "PDF": "https://arxiv.org/pdf/2406.09260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a deep transformer network for UAV pose estimation and synthetic data creation, unrelated to LLM training data processing."
      },
      "tasks": [
        "Pose Estimation",
        "Position"
      ],
      "repo_urls": [
        "https://github.com/fdcl-gwu/tnn-mo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02825",
      "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues in task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation of agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
      "authors": [
        "Yuxuan Zhu",
        "Tengjun Jin",
        "Yada Pruksachatkun",
        "Andy Zhang",
        "Shu Liu",
        "Sasha Cui",
        "Sayash Kapoor",
        "Shayne Longpre",
        "Kevin Meng",
        "Rebecca Weiss",
        "Fazl Barez",
        "Rahul Gupta",
        "Jwala Dhamala",
        "Jacob Merizian",
        "Mario Giulianelli",
        "Harry Coppock",
        "Cozmin Ududec",
        "Jasjeet Sekhon",
        "Jacob Steinhardt",
        "Antony Kellerman",
        "Sarah Schwettmann",
        "Matei Zaharia",
        "Ion Stoica",
        "Percy Liang",
        "Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.02825v1",
          "size": "671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:45:08+00:00",
          "link": "https://arxiv.org/abs/2507.02825v2",
          "size": "671kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:42:37+00:00",
          "link": "https://arxiv.org/abs/2507.02825v3",
          "size": "671kb",
          "version": "v3"
        }
      ],
      "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02825",
        "HTML": "https://arxiv.org/html/2507.02825v3",
        "PDF": "https://arxiv.org/pdf/2507.02825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses benchmarks for evaluating AI agents but does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07299",
      "abstract": "Recent progress in large vision-language models has driven improvements in language-based semantic navigation, where an embodied agent must reach a target object described in natural language. Despite these advances, we still lack a clear, language-focused benchmark for testing how well such agents ground the words in their instructions. We address this gap with LangNav, an open-set dataset specifically created to test an agent's ability to locate objects described at different levels of detail, from broad category names to fine attributes and object-object relations. Every description in LangNav was manually checked, yielding a lower error rate than existing lifelong- and semantic-navigation datasets. On top of LangNav we build LangNavBench, a benchmark that measures how well current semantic-navigation methods understand and act on these descriptions while moving toward their targets. LangNavBench allows us to systematically compare models on their handling of attributes, spatial and relational cues, and category hierarchies, offering the first thorough, language-centric evaluation of embodied navigation systems. We also present Multi-Layered Feature Map (MLFM), a method that builds a queryable multi-layered semantic map, particularly effective when dealing with small objects or instructions involving spatial relations. MLFM outperforms state-of-the-art mapping-based navigation baselines on the LangNav dataset.",
      "authors": [
        "Sonia Raychaudhuri",
        "Enrico Cancelli",
        "Tommaso Campari",
        "Lamberto Ballan",
        "Manolis Savva",
        "Angel X. Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:46:43+00:00",
          "link": "https://arxiv.org/abs/2507.07299v1",
          "size": "3315kb",
          "version": "v1"
        }
      ],
      "title": "LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07299",
        "HTML": "https://arxiv.org/html/2507.07299v1",
        "PDF": "https://arxiv.org/pdf/2507.07299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of LangNav, a benchmark dataset for semantic navigation. While it provides a new dataset, the focus is on evaluating navigation systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07850",
      "abstract": "What is the globally smallest load perturbation that renders DC-OPF infeasible? Reliably identifying such \"adversarial attack\" perturbations has useful applications in a variety of emerging grid-related contexts, including machine learning performance verification, cybersecurity, and operational robustness of power systems dominated by stochastic renewable energy resources. In this paper, we formulate the inherently nonconvex adversarial attack problem by applying a parameterized version of Farkas' lemma to a perturbed set of DC-OPF equations. Since the resulting formulation is very hard to globally optimize, we also propose a parameterized generation control policy which, when applied to the primal DC-OPF problem, provides solvability guarantees. Together, these nonconvex problems provide guaranteed upper and lower bounds on adversarial attack size; by combining them into a single optimization problem, we can efficiently \"squeeze\" these bounds towards a common global solution. We apply these methods on a range of small- to medium-sized test cases from PGLib, benchmarking our results against the best adversarial attack lower bounds provided by Gurobi 12.0's spatial Branch and Bound solver.",
      "authors": [
        "Samuel Chevalier and William A. Wheeler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:33:07+00:00",
          "link": "https://arxiv.org/abs/2507.07850v1",
          "size": "363kb",
          "version": "v1"
        }
      ],
      "title": "Identifying the Smallest Adversarial Load Perturbations that Render DC-OPF Infeasible",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07850",
        "HTML": "https://arxiv.org/html/2507.07850v1",
        "PDF": "https://arxiv.org/pdf/2507.07850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on adversarial load perturbations in DC-OPF for power systems, unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03053",
      "abstract": "Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.",
      "authors": [
        "Sinem Erisken (Independent Researcher)",
        "Timothy Gothard (Independent Researcher)",
        "Martin Leitgab (Independent Researcher)",
        "Ram Potham (Independent Researcher)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T16:33:47+00:00",
          "link": "https://arxiv.org/abs/2506.03053v1",
          "size": "1963kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:54:28+00:00",
          "link": "https://arxiv.org/abs/2506.03053v2",
          "size": "961kb",
          "version": "v2"
        }
      ],
      "title": "MAEBE: Multi-Agent Emergent Behavior Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03053",
        "HTML": "https://arxiv.org/html/2506.03053v2",
        "PDF": "https://arxiv.org/pdf/2506.03053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses emergent behavior evaluation in multi-agent AI ensembles, with no focus on LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06920",
      "abstract": "Large language models (LLMs) have recently achieved notable success in code-generation benchmarks such as HumanEval and LiveCodeBench. However, a detailed examination reveals that these evaluation suites often comprise only a limited number of homogeneous test cases, resulting in subtle faults going undetected. This not only artificially inflates measured performance but also compromises accurate reward estimation in reinforcement learning frameworks utilizing verifiable rewards (RLVR). To address these critical shortcomings, we systematically investigate the test-case generation (TCG) task by proposing multi-dimensional metrics designed to rigorously quantify test-suite thoroughness. Furthermore, we introduce a human-LLM collaborative method (SAGA), leveraging human programming expertise with LLM reasoning capability, aimed at significantly enhancing both the coverage and the quality of generated test cases. In addition, we develop a TCGBench to facilitate the study of the TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc) of the code generation evaluation benchmark synthesized by SAGA is 10.78% higher than that of LiveCodeBench-v6. These results demonstrate the effectiveness of our proposed method. We hope this work contributes to building a scalable foundation for reliable LLM code evaluation, further advancing RLVR in code generation, and paving the way for automated adversarial test synthesis and adaptive benchmark integration.",
      "authors": [
        "Zihan Ma",
        "Taolin Zhang",
        "Maosong Cao",
        "Junnan Liu",
        "Wenwei Zhang",
        "Minnan Luo",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:58:47+00:00",
          "link": "https://arxiv.org/abs/2507.06920v1",
          "size": "4361kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.06920v2",
          "size": "4361kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Verification for LLM Code Generation: From Generation to Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06920",
        "HTML": "https://arxiv.org/html/2507.06920v2",
        "PDF": "https://arxiv.org/pdf/2507.06920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on code generation evaluation and introduces a test-case generation framework and benchmarks, primarily for LLM code generation evaluation, not directly on training data processing for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "opencompass/CodeCompass",
          "downloads": "74",
          "likes": "0",
          "link": "https://huggingface.co/datasets/opencompass/CodeCompass"
        },
        {
          "dataset_name": "opencompass/CodeForce_SAGA",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/opencompass/CodeForce_SAGA"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07717",
      "abstract": "In this paper, we study an advection-diffusion equation that involves a half-Laplacian operator derived from the Riesz fractional Laplacian, combined with a differential operator \\(\\mathcal{L}\\). By applying the half-Laplacian operator $(-\\Delta)^{\\frac{1}{2}}$ on both sides of the equation and using the relationship between the Hilbert transform and $(-\\Delta)^{\\frac{1}{2}}$, we reformulate the problem as a second-order damped Cauchy problem and then convert it into an equivalent first-order system. This \\textit{spectrum doubling} (SD) reformulation applies the half-Laplacian only once to the initial condition, thereby eliminating the need to evaluate singular integrals during the time evolution and reducing truncation-related numerical errors. For the resulting SD system, we show that standard time-stepping schemes can lose stability because of the backward-diffusion term. To address this, we adopt Boundary Value Methods (BVMs), which yield unconditional stability and second-order accuracy. We present eigenvalue-based stability criteria, error estimates, and an efficient block formulation to solve the resulting large linear systems. To further enhance computational efficiency, we propose a parallel preconditioned iterative solver. Numerical experiments confirm the second-order convergences in both time and space, even under strong advection or for complex fractional Schr\\\"odinger-type problems, demonstrating the effectiveness and versatility of the proposed approach.",
      "authors": [
        "Pu Yuan",
        "Paul Zegeling",
        "Xian-Ming Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:54:33+00:00",
          "link": "https://arxiv.org/abs/2507.07717v1",
          "size": "1462kb",
          "version": "v1"
        }
      ],
      "title": "A preconditioned boundary value method for advection-diffusion equations with half Laplacian via spectrum doubling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07717",
        "HTML": "https://arxiv.org/html/2507.07717v1",
        "PDF": "https://arxiv.org/pdf/2507.07717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study involves mathematical methods for solving advection-diffusion equations, lacking any content on LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07794",
      "abstract": "Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral and maxillofacial surgery. Despite advances in technique and instrumentation, its success still relies heavily on the surgeon's experience. In this work, a human-robot collaborative system is proposed to perform MASO according to a preoperative plan and under guidance of a surgeon. A task decomposition methodology is used to divide the collaborative surgical procedure into three subtasks: (1) positional control and (2) orientation control, both led by the robot for precise alignment; and (3) force-control, managed by surgeon to ensure safety. Additionally, to achieve patient tracking without the need for a skull clamp, an optical tracking system (OTS) is utilized. Movement of the patient mandibular is measured with an optical-based tracker mounted on a dental occlusal splint. A registration method and Robot-OTS calibration method are introduced to achieve reliable navigation within our framework. The experiments of drilling were conducted on the realistic phantom model, which demonstrated that the average error between the planned and actual drilling points is 1.85mm.",
      "authors": [
        "Zhe Han",
        "Huanyu Tian",
        "Tom Vercauteren",
        "Da Liu",
        "Changsheng Li and Xingguang Duan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:20:34+00:00",
          "link": "https://arxiv.org/abs/2507.07794v1",
          "size": "1202kb",
          "version": "v1"
        }
      ],
      "title": "Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07794",
        "HTML": "https://arxiv.org/html/2507.07794v1",
        "PDF": "https://arxiv.org/pdf/2507.07794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper develops a collaborative human-robot surgical system and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07292",
      "abstract": "We develop a new and general encode-approximate-reconstruct operator learning model that leverages learned neural representations of bases for input and output function distributions. We introduce the concepts of \\textit{numerical operator learning} and \\textit{discretization independence}, which clarify the relationship between theoretical formulations and practical realizations of operator learning models. Our model is discretization-independent, making it particularly effective for multifidelity learning. We establish theoretical approximation guarantees, demonstrating uniform universal approximation under strong assumptions on the input functions and statistical approximation under weaker conditions. To our knowledge, this is the first comprehensive study that investigates how discretization independence enables robust and efficient multifidelity operator learning. We validate our method through extensive numerical experiments involving both local and nonlocal PDEs, including time-independent and time-dependent problems. The results show that multifidelity training significantly improves accuracy and computational efficiency. Moreover, multifidelity training further enhances empirical discretization independence.",
      "authors": [
        "Jacob Hauck",
        "Yanzhi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:29:11+00:00",
          "link": "https://arxiv.org/abs/2507.07292v1",
          "size": "2043kb",
          "version": "v1"
        }
      ],
      "title": "Discretization-independent multifidelity operator learning for partial differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07292",
        "HTML": "https://arxiv.org/html/2507.07292v1",
        "PDF": "https://arxiv.org/pdf/2507.07292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing operator learning models for PDEs, emphasizing multifidelity learning and discretization independence. It does not address LLM training data processing or any data engineering related to training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07406",
      "abstract": "Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-parameter Large Language Models (LLMs) for phishing detection. Through experiments on a curated dataset, we show that while LLMs currently underperform compared to ML and DL methods in terms of raw accuracy, they exhibit strong potential for identifying subtle, context-based phishing cues. We also investigate the impact of zero-shot and few-shot prompting strategies, revealing that LLM-rephrased emails can significantly degrade the performance of both ML and LLM-based detectors. Our benchmarking highlights that models like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above 80%, using only 17GB of VRAM, supporting their viability for cost-efficient deployment. We further assess the models' adversarial robustness and cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide concise, interpretable explanations to support real-time decision-making. These findings position optimized LLMs as promising components in phishing defence systems and offer a path forward for integrating explainable, efficient AI into modern cybersecurity frameworks.",
      "authors": [
        "Jikesh Thapa",
        "Gurrehmat Chahal",
        "Serban Voinea Gabreanu",
        "Yazan Otoum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:01:52+00:00",
          "link": "https://arxiv.org/abs/2507.07406v1",
          "size": "2137kb",
          "version": "v1"
        }
      ],
      "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07406",
        "HTML": "https://arxiv.org/html/2507.07406v1",
        "PDF": "https://arxiv.org/pdf/2507.07406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper compares the effectiveness of various models for phishing detection without discussing any aspect of LLM training data processing or preparation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07436",
      "abstract": "Graph Contrastive Learning (GCL) has demonstrated substantial promise in enhancing the robustness and generalization of recommender systems, particularly by enabling models to leverage large-scale unlabeled data for improved representation learning. However, in this paper, we reveal an unexpected vulnerability: the integration of GCL inadvertently increases the susceptibility of a recommender to targeted promotion attacks. Through both theoretical investigation and empirical validation, we identify the root cause as the spectral smoothing effect induced by contrastive optimization, which disperses item embeddings across the representation space and unintentionally enhances the exposure of target items. Building on this insight, we introduce CLeaR, a bi-level optimization attack method that deliberately amplifies spectral smoothness, enabling a systematic investigation of the susceptibility of GCL-based recommendation models to targeted promotion attacks. Our findings highlight the urgent need for robust countermeasures; in response, we further propose SIM, a spectral irregularity mitigation framework designed to accurately detect and suppress targeted items without compromising model performance. Extensive experiments on multiple benchmark datasets demonstrate that, compared to existing targeted promotion attacks, GCL-based recommendation models exhibit greater susceptibility when evaluated with CLeaR, while SIM effectively mitigates these vulnerabilities.",
      "authors": [
        "Zongwei Wang",
        "Min Gao",
        "Junliang Yu",
        "Shazia Sadiq",
        "Hongzhi Yin",
        "Ling Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:24:08+00:00",
          "link": "https://arxiv.org/abs/2507.07436v1",
          "size": "1292kb",
          "version": "v1"
        }
      ],
      "title": "When Graph Contrastive Learning Backfires: Spectral Vulnerability and Defense in Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07436",
        "HTML": "https://arxiv.org/html/2507.07436v1",
        "PDF": "https://arxiv.org/pdf/2507.07436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus on spectral analysis and defense mechanisms in graph contrastive learning does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07911",
      "abstract": "Immersive virtual reality (VR) is a promising tool for stress reduction and relaxation, traditionally relying on visual and auditory stimuli. This study examines the role of olfactory stimuli in enhancing these effects, using a randomized within-subject design. Thirty participants aged 18-60 experienced VR scenarios simulating a calming seaside environment, with sessions lasting 45 minutes, in two conditions: with and without a \"Beach\" essential oil scent (Yankee Candle) administered via diffuser. Stress and relaxation were assessed through self-reported surveys and physiological measures, specifically ECG-based heart rate variability (HRV). Results showed no significant difference in self-reported relaxation scores (p=0.371) between conditions, but HRV analysis revealed a significant stress reduction (p=0.002) with olfactory input, with HF increasing 108% from the Math Stress Test to the scented relaxation condition, compared to 44% without scent. Additionally, 71.4% of participants expressed willingness to use olfactory-enhanced VR for relaxation, suggesting practical appeal. These findings indicate that olfactory stimuli may enhance relaxation subconsciously, underscoring the importance of multisensory integration in VR. Future work could explore personalized scents and long-term effects to optimize VR- based interventions for emotional and physical well-being.",
      "authors": [
        "Yasmin Elsaddik Valdivieso",
        "Mohd Faisal",
        "Karim Alghoul",
        "Monireh (Monica) Vahdati",
        "Kamran Gholizadeh Hamlabadi",
        "Fedwa Laamarti",
        "Hussein Al Osman",
        "Abdulmotaleb El Saddik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:45:10+00:00",
          "link": "https://arxiv.org/abs/2507.07911v1",
          "size": "602kb",
          "version": "v1"
        }
      ],
      "title": "The Potential of Olfactory Stimuli in Stress Reduction through Virtual Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07911",
        "PDF": "https://arxiv.org/pdf/2507.07911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on exploring olfactory stimuli in virtual reality for stress reduction and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20954",
      "abstract": "Online handwriting recognition (HWR) using data from inertial measurement units (IMUs) remains challenging due to variations in writing styles and the limited availability of annotated datasets. Previous approaches often struggle with handwriting from unseen writers, making writer-independent (WI) recognition a crucial yet difficult problem. This paper presents an HWR model designed to improve WI HWR on IMU data, using a CNN encoder and a BiLSTM-based decoder. Our approach demonstrates strong robustness to unseen handwriting styles, outperforming existing methods on the WI splits of both the public OnHW dataset and our word-based dataset, achieving character error rates (CERs) of 7.37\\% and 9.44\\%, and word error rates (WERs) of 15.12\\% and 32.17\\%, respectively. Robustness evaluation shows that our model maintains superior accuracy across different age groups, and knowledge learned from one group generalizes better to another. Evaluation on our sentence-based dataset further demonstrates its potential in recognizing full sentences. Through comprehensive ablation studies, we show that our design choices lead to a strong balance between performance and efficiency. These findings support the development of more adaptable and scalable HWR systems for real-world applications.",
      "authors": [
        "Jindong Li and Tim Hamann and Jens Barth and Peter K\\\"ampf and Dario Zanca and Bj\\\"orn Eskofier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T11:09:28+00:00",
          "link": "https://arxiv.org/abs/2502.20954v1",
          "size": "76kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:10:12+00:00",
          "link": "https://arxiv.org/abs/2502.20954v2",
          "size": "4712kb",
          "version": "v2"
        }
      ],
      "title": "Robust and Efficient Writer-Independent IMU-Based Handwriting Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20954",
        "HTML": "https://arxiv.org/html/2502.20954v2",
        "PDF": "https://arxiv.org/pdf/2502.20954"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses handwriting recognition using IMU data and model robustness but does not contribute to LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.14382",
      "abstract": "The purpose of this paper is to examine whether large language models (LLMs) can understand what is good and evil with respect to judging good/evil reputation of celebrities. Specifically, we first apply a large language model (namely, ChatGPT) to the task of collecting sentences that mention the target celebrity from articles about celebrities on Web pages. Next, the collected sentences are categorized based on their contents by ChatGPT, where ChatGPT assigns a category name to each of those categories. Those assigned category names are referred to as \"aspects\" of each celebrity. Then, by applying the framework of retrieval augmented generation (RAG), we show that the large language model is quite effective in the task of judging good/evil reputation of aspects and descriptions of each celebrity. Finally, also in terms of proving the advantages of the proposed method over existing services incorporating RAG functions, we show that the proposed method of judging good/evil of aspects/descriptions of each celebrity significantly outperform an existing service incorporating RAG functions.",
      "authors": [
        "Rikuto Tsuchida",
        "Hibiki Yokoyama",
        "Takehito Utsuro"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T16:15:55+00:00",
          "link": "https://arxiv.org/abs/2503.14382v1",
          "size": "4312kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:48:25+00:00",
          "link": "https://arxiv.org/abs/2503.14382v2",
          "size": "1798kb",
          "version": "v2"
        }
      ],
      "title": "Good/Evil Reputation Judgment of Celebrities by LLMs via Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14382",
        "HTML": "https://arxiv.org/html/2503.14382v2",
        "PDF": "https://arxiv.org/pdf/2503.14382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses LLMs in a retrieval augmented generation framework, it centers on reputation judgment, not on the processing or creation of LLM training datasets."
      },
      "tasks": [
        "Articles",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00981",
      "abstract": "How language-specific are speech representations learned by self-supervised models? Existing work has shown that a range of linguistic features can be successfully decoded from end-to-end models trained only on speech recordings. However, it's less clear to what extent pre-training on specific languages improves language-specific linguistic information. Here we test the encoding of Dutch phonetic and lexical information in internal representations of self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the representation of Dutch linguistic features as compared to pre-training on similar amounts of English or larger amounts of multilingual data. This language-specific advantage is well-detected by trained clustering or classification probes, and partially observable using zero-shot metrics. Furthermore, the language-specific benefit on linguistic feature encoding aligns with downstream performance on Automatic Speech Recognition.",
      "authors": [
        "Marianne de Heer Kloots",
        "Hosein Mohebbi",
        "Charlotte Pouw",
        "Gaofei Shen",
        "Willem Zuidema",
        "Martijn Bentum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-01T12:25:13+00:00",
          "link": "https://arxiv.org/abs/2506.00981v1",
          "size": "1210kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:20:48+00:00",
          "link": "https://arxiv.org/abs/2506.00981v2",
          "size": "1210kb",
          "version": "v2"
        }
      ],
      "title": "What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00981",
        "HTML": "https://arxiv.org/html/2506.00981v2",
        "PDF": "https://arxiv.org/pdf/2506.00981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes pretraining of speech models on specific languages, which is unrelated to LLM training data processing for language models."
      },
      "models": [
        {
          "model_path": "amsterdamNLP/Wav2Vec2-NL",
          "downloads": "33",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/amsterdamNLP/Wav2Vec2-NL"
        }
      ],
      "tasks": [
        "Automatic Speech Recognition",
        "speech-recognition",
        "Speech Recognition"
      ],
      "repo_urls": [
        "https://github.com/mdhk/ssl-nl-eval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07271",
      "abstract": "The Average Treatment Effect (ATE) is a foundational metric in causal inference, widely used to assess intervention efficacy in randomized controlled trials (RCTs). However, in many applications -- particularly in healthcare -- this static summary fails to capture the nuanced dynamics of treatment effects that vary with both dose and time. We propose a framework for modelling treatment effect trajectories as smooth surfaces over dose and time, enabling the extraction of clinically actionable insights such as onset time, peak effect, and duration of benefit. To ensure interpretability, robustness, and verifiability -- key requirements in high-stakes domains -- we adapt SemanticODE, a recent framework for interpretable trajectory modelling, to the causal setting where treatment effects are never directly observed. Our approach decouples the estimation of trajectory shape from the specification of clinically relevant properties (e.g., maxima, inflection points), supporting domain-informed priors, post-hoc editing, and transparent analysis. We show that our method yields accurate, interpretable, and editable models of treatment dynamics, facilitating both rigorous causal analysis and practical decision-making.",
      "authors": [
        "Julianna Piskorz",
        "Krzysztof Kacprzyk",
        "Mihaela van der Schaar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:33:33+00:00",
          "link": "https://arxiv.org/abs/2507.07271v1",
          "size": "564kb",
          "version": "v1"
        }
      ],
      "title": "Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07271",
        "HTML": "https://arxiv.org/html/2507.07271v1",
        "PDF": "https://arxiv.org/pdf/2507.07271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses causal inference and modeling treatment effects in clinical settings, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07528",
      "abstract": "In this paper, we address the enumeration of (induced) $s$-$t$ paths and minimal $s$-$t$ separators. These problems are some of the most famous classical enumeration problems that can be solved in polynomial delay by simple backtracking for a (un)directed graph. As a generalization of these problems, we consider the (induced) $s$-$t$ hyperpath and minimal $s$-$t$ separator enumeration in a \\emph{directed hypergraph}. We show that extending these classical enumeration problems to directed hypergraphs drastically changes their complexity. More precisely, there are no output-polynomial time algorithms for the enumeration of induced $s$-$t$ hyperpaths and minimal $s$-$t$ separators unless $P = NP$, and if there is an output-polynomial time algorithm for the $s$-$t$ hyperpath enumeration, then the minimal transversal enumeration can be solved in output polynomial time even if a directed hypergraph is $BF$-hypergraph. Since the existence of an output-polynomial time algorithm for the minimal transversal enumeration has remained an open problem for over 45 years, it indicates that the $s$-$t$ hyperpath enumeration for a $BF$-hypergraph is not an easy problem. As a positive result, the $s$-$t$ hyperpath enumeration for a $B$-hypergraph can be solved in polynomial delay by backtracking.",
      "authors": [
        "Kazuhiro Kurita and Kevin Mann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:24:39+00:00",
          "link": "https://arxiv.org/abs/2507.07528v1",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "title": "On the Complexity of Hyperpath and Minimal Separator Enumeration in Directed Hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07528",
        "HTML": "https://arxiv.org/html/2507.07528v1",
        "PDF": "https://arxiv.org/pdf/2507.07528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the complexity of enumeration problems in directed hypergraphs, which is unrelated to LLM training-data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07781",
      "abstract": "The integration of language and 3D perception is critical for embodied AI and robotic systems to perceive, understand, and interact with the physical world. Spatial reasoning, a key capability for understanding spatial relationships between objects, remains underexplored in current 3D vision-language research. Existing datasets often mix semantic cues (e.g., object name) with spatial context, leading models to rely on superficial shortcuts rather than genuinely interpreting spatial relationships. To address this gap, we introduce S\\textsc{urprise}3D, a novel dataset designed to evaluate language-guided spatial reasoning segmentation in complex 3D scenes. S\\textsc{urprise}3D consists of more than 200k vision language pairs across 900+ detailed indoor scenes from ScanNet++ v2, including more than 2.8k unique object classes. The dataset contains 89k+ human-annotated spatial queries deliberately crafted without object name, thereby mitigating shortcut biases in spatial understanding. These queries comprehensively cover various spatial reasoning skills, such as relative position, narrative perspective, parametric perspective, and absolute distance reasoning. Initial benchmarks demonstrate significant challenges for current state-of-the-art expert 3D visual grounding methods and 3D-LLMs, underscoring the necessity of our dataset and the accompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite. S\\textsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatially aware AI, paving the way for effective embodied interaction and robotic planning. The code and datasets can be found in https://github.com/liziwennba/SUPRISE.",
      "authors": [
        "Jiaxin Huang",
        "Ziwen Li",
        "Hanlve Zhang",
        "Runnan Chen",
        "Xiao He",
        "Yandong Guo",
        "Wenping Wang",
        "Tongliang Liu",
        "Mingming Gong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:01:24+00:00",
          "link": "https://arxiv.org/abs/2507.07781v1",
          "size": "11194kb",
          "version": "v1"
        }
      ],
      "title": "SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07781",
        "HTML": "https://arxiv.org/html/2507.07781v1",
        "PDF": "https://arxiv.org/pdf/2507.07781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the SURPRISE3D dataset with detailed steps for creating a novel dataset focused on spatial reasoning in 3D scenes, highlighting its data processing approach."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.14993",
      "abstract": "Multi-modal generative AI (Artificial Intelligence) has attracted increasing attention from both academia and industry. Particularly, two dominant families of techniques have emerged: i) Multi-modal large language models (LLMs) demonstrate impressive ability for multi-modal understanding; and ii) Diffusion models exhibit remarkable multi-modal powers in terms of multi-modal generation. Therefore, this paper provides a comprehensive overview of multi-modal generative AI, including multi-modal LLMs, diffusions, and the unification for understanding and generation. To lay a solid foundation for unified models, we first provide a detailed review of both multi-modal LLMs and diffusion models respectively, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video LLMs as well as text-to-image/video generation. Furthermore, we explore the emerging efforts toward unified models for understanding and generation. To achieve the unification of understanding and generation, we investigate key designs including autoregressive-based and diffusion-based modeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then introduce several strategies for unified models, analyzing their potential advantages and disadvantages. In addition, we summarize the common datasets widely used for multi-modal generative AI pretraining. Last but not least, we present several challenging future research directions which may contribute to the ongoing advancement of multi-modal generative AI.",
      "authors": [
        "Xin Wang",
        "Yuwei Zhou",
        "Bin Huang",
        "Hong Chen",
        "and Wenwu Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T13:16:09+00:00",
          "link": "https://arxiv.org/abs/2409.14993v1",
          "size": "1232kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:30:56+00:00",
          "link": "https://arxiv.org/abs/2409.14993v2",
          "size": "2326kb",
          "version": "v2"
        }
      ],
      "title": "Multi-modal Generative AI: Multi-modal LLMs, Diffusions and the Unification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14993",
        "HTML": "https://arxiv.org/html/2409.14993v2",
        "PDF": "https://arxiv.org/pdf/2409.14993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper provides an overview of multi-modal generative AI, including datasets commonly used, but does not focus on LLM training data processing techniques or dataset creation."
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model",
        "Mixture-of-Experts",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19969",
      "abstract": "The Fast Fourier Transform is extended to functions on finite graphs whose edges are identified with intervals of finite length. Spectral and pseudospectral methods are developed to solve a wide variety of time dependent partial differential equations on domains which are modeled as networks of one dimensional segments joined at nodes.",
      "authors": [
        "Robert Carlson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T21:06:19+00:00",
          "link": "https://arxiv.org/abs/2410.19969v1",
          "size": "442kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:05:55+00:00",
          "link": "https://arxiv.org/abs/2410.19969v2",
          "size": "494kb",
          "version": "v2"
        }
      ],
      "title": "A quantum graph FFT with applications to partial differential equations on networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19969",
        "HTML": "https://arxiv.org/html/2410.19969v2",
        "PDF": "https://arxiv.org/pdf/2410.19969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an extension of the Fast Fourier Transform for solving differential equations on graphs and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.00569",
      "abstract": "Uniform random exploration in decision-making systems supports off-policy learning via supervision but incurs high regret, making it impractical for many applications. Conversely, non-uniform exploration offers better immediate performance but lacks support for off-policy learning. Recent research suggests that regression oracles can bridge this gap by combining non-uniform exploration with supervised learning. In this paper, we analyze these approaches within a real-world industrial context at Adyen, a large global payments processor characterized by batch logged delayed feedback, short-term memory, and dynamic action spaces under the Empirical Risk Minimization (ERM) framework. Our analysis reveals that while regression oracles significantly improve performance, they introduce challenges due to rigid algorithmic assumptions. Specifically, we observe that as a policy improves, subsequent generations may perform worse due to shifts in the reward distribution and increased class imbalance in the training data. This degradation occurs de spite improvements in other aspects of the training data, leading to decreased performance in successive policy iterations. We further explore the long-term impact of regression oracles, identifying a potential \"oscillation effect.\" This effect arises when regression oracles influence probability estimates and the realizability of subsequent policy models, leading to fluctuations in performance across iterations. Our findings highlight the need for more adaptable algorithms that can leverage the benefits of regression oracles without introducing instability in policy performance over time.",
      "authors": [
        "Akhila Vangara",
        "Alex Egg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-30T19:45:23+00:00",
          "link": "https://arxiv.org/abs/2412.00569v1",
          "size": "1532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:21:15+00:00",
          "link": "https://arxiv.org/abs/2412.00569v2",
          "size": "1270kb",
          "version": "v2"
        }
      ],
      "title": "Contextual Bandits in Payment Processing: Non-uniform Exploration and Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00569",
        "HTML": "https://arxiv.org/html/2412.00569v2",
        "PDF": "https://arxiv.org/pdf/2412.00569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes contextual bandits in payment processing, discussing non-uniform exploration and supervised learning without focus on LLM training data processing."
      },
      "tasks": [
        "Multi-Armed Bandits",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07481",
      "abstract": "The integration of wireless power transfer (WPT) with Internet of Things (IoT) offers promising solutions for sensing applications, but faces significant challenges when deployed in hard-to-access areas such as high-temperature environments. In such extreme conditions, traditional fixed WPT infrastructure cannot be safely installed, and batteries rapidly degrade due to hardware failures. In this paper, we propose an uncrewed aerial vehicle (UAV)-assisted data collection and WPT framework for batteryless sensor (BLS) networks deployed in these challenging environments. Specifically, we consider a practical scenario where a UAV first transfers energy to BLS nodes via WPT, enabling these nodes to subsequently transmit their collected data to the UAV through orthogonal frequency-division multiple access (OFDMA). Then, we formulate a multi-objective optimization problem that aims to maximize the fair data collection volume while minimizing the UAV energy consumption through joint optimization of transmit power allocation and flight trajectory planning. Due to the non-convex nature and dynamic characteristics of this problem, conventional optimization methods prove inadequate. To address these challenges, we propose an enhanced soft actor-critic algorithm with parameter-free attention, prioritized experience replay, and value-based reward centering (SAC-PPV), thereby improving the exploration efficiency and learning stability of the algorithm in complex WPT scenarios. Simulation results demonstrate that the proposed approach consistently outperforms benchmark algorithms under various network configurations.",
      "authors": [
        "Wen Zhang",
        "Aimin Wang",
        "Jiahui Li",
        "Geng Sun",
        "Jiacheng Wang",
        "Weijie Yuan",
        "and Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:10:10+00:00",
          "link": "https://arxiv.org/abs/2507.07481v1",
          "size": "13561kb",
          "version": "v1"
        }
      ],
      "title": "Energy Transfer and Data Collection from Batteryless Sensors in Low-altitude Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07481",
        "HTML": "https://arxiv.org/html/2507.07481v1",
        "PDF": "https://arxiv.org/pdf/2507.07481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for energy transfer and data collection from batteryless sensors using UAVs, which is unrelated to LLM training data processing as it focuses on wireless networks and sensor technology."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07565",
      "abstract": "This paper studies privacy-sensitive federated learning (FL) with unreliable communication, focusing on secure aggregation and straggler mitigation. While secure aggregation cryptographically reconstructs the global model without exposing client updates, random link failures disrupt its key coordination, degrading model accuracy. Moreover, unreliable communication can lead to objective inconsistency, causing the global model to converge to arbitrary, sub-optimal points far from the intended optimum. This paper proposes Secure Cooperative Gradient Coding (SecCoGC), a practical solution that achieves secure aggregation with arbitrarily strong privacy guarantees and robust straggler mitigation under unreliable communication. SecCoGC operates natively in the real field, making it directly applicable to practical deployments. To ensure equitable privacy protection across clients, we further introduce Fair-SecCoGC, an extension that enforces fairness in the level of privacy offered to all users. To conclude, this paper formally formulates the problem of secure aggregation in the real field and presents both general and computationally efficient key construction methods. Moreover, it provides a comprehensive privacy analysis under Local Mutual Information Privacy (LMIP) and Local Differential Privacy (LDP) across all protocol layers. Robustness and convergence properties are also rigorously analyzed. Finally, extensive simulations are performed across diverse network conditions and benchmark datasets to validate the effectiveness of the proposed methods. The results show that SecCoGC achieves strong robustness to unreliable communication under arbitrarily strong privacy guarantees. It outperforms existing privacy-preserving methods with performance gains of up to 20\\%-70\\%.",
      "authors": [
        "Shudi Weng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.07565v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Secure Cooperative Gradient Coding: Optimality, Reliability, and Global Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07565",
        "HTML": "https://arxiv.org/html/2507.07565v1",
        "PDF": "https://arxiv.org/pdf/2507.07565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on privacy-sensitive federated learning and secure communication, without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07605",
      "abstract": "We study the use of image-based Vision-Language Models (VLMs) for open-vocabulary segmentation of lidar scans in driving settings. Classically, image semantics can be back-projected onto 3D point clouds. Yet, resulting point labels are noisy and sparse. We consolidate these labels to enforce both spatio-temporal consistency and robustness to image-level augmentations. We then train a 3D network based on these refined labels. This simple method, called LOSC, outperforms the SOTA of zero-shot open-vocabulary semantic and panoptic segmentation on both nuScenes and SemanticKITTI, with significant margins.",
      "authors": [
        "Nermin Samet and Gilles Puy and Renaud Marlet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.07605v1",
          "size": "3903kb",
          "version": "v1"
        }
      ],
      "title": "LOSC: LiDAR Open-voc Segmentation Consolidator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07605",
        "HTML": "https://arxiv.org/html/2507.07605v1",
        "PDF": "https://arxiv.org/pdf/2507.07605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper briefly mentions training a 3D network using refined labels, but its main focus is on improving segmentation performance using image-based Vision-Language Models, not detailed LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2010.07990",
      "abstract": "We present an algorithm for solving binary classification problems when the dataset is not fully representative of the problem being solved, and obtaining more data is not possible. It relies on a trained model with loose accuracy constraints, an iterative hyperparameter searching-and-pruning procedure over a search space $\\Theta$, and a data-generating function. Our algorithm works by reconstructing up to homology the manifold on which lies the support of the underlying distribution. We provide an analysis on correctness and runtime complexity under ideal conditions and an extension to deep neural networks. In the former case, if $\\size{\\Theta}$ is the number of hyperparameter sets in the search space, this algorithm returns a solution that is up to $2(1 - {2^{-\\size{\\Theta}}})$ times better than simply training with an enumeration of $\\Theta$ and picking the best model. As part of our analysis we also prove that an open cover of a dataset has the same homology as the manifold on which lies the support of the underlying probability distribution, if and only said dataset is learnable. This latter result acts as a formal argument to explain the effectiveness of data expansion techniques.",
      "authors": [
        "Adrian de Wynter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2020-10-15T19:17:51+00:00",
          "link": "https://arxiv.org/abs/2010.07990v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:51:52+00:00",
          "link": "https://arxiv.org/abs/2010.07990v2",
          "size": "192kb",
          "version": "v2"
        }
      ],
      "title": "An Algorithm for Learning Smaller Representations of Models With Scarce Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2010.07990",
        "HTML": "https://arxiv.org/html/2010.07990v2",
        "PDF": "https://arxiv.org/pdf/2010.07990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces an algorithm that involves data generation and expansion techniques, which directly relate to processing LLM training data particularly when data is scarce."
      },
      "tasks": [
        "Binary Classification"
      ],
      "repo_urls": [
        "https://github.com/alexa/bort"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07150",
      "abstract": "Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.",
      "authors": [
        "Jean-Baptiste Fermanian (IMAG",
        "IROKO)",
        "Mohamed Hebiri (LAMA)",
        "Joseph Salmon (IMAG",
        "IROKO)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:17:17+00:00",
          "link": "https://arxiv.org/abs/2507.07150v1",
          "size": "895kb",
          "version": "v1"
        }
      ],
      "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07150",
        "PDF": "https://arxiv.org/pdf/2507.07150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on conformal prediction for classification tasks with multi-inputs, and doesn't discuss any aspect of LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07512",
      "abstract": "This study demonstrates 3D monolithic integration of amorphous indium-gallium-zinc oxide (a-IGZO) thin-film transistors (TFTs) on Gallium Nitride (GaN) high electron mobility transistors (HEMTs) in a cascode configuration, achieving high breakdown voltage capabilities exceeding 1900 V. Two device configurations, differing in a-IGZO channel thickness (30 nm / 10 nm), are fabricated and evaluated. Sample B, with a 10 nm a-IGZO channel, demonstrates superior electrical performance, including a high ON/OFF current ratio (~10^7), low subthreshold swing (SS), and a high breakdown voltage exceeding 1900 V comparable to standalone GaN power HEMTs. The results highlight the feasibility and potential of 3D integrated TFT on GaN power HEMTs, paving the way for new opportunities for the TFTs for high voltage applications.",
      "authors": [
        "Tian-Li Wu",
        "Hsin-Jou Ho",
        "Chia-Wei Liu",
        "Yi-Chen Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:58:22+00:00",
          "link": "https://arxiv.org/abs/2507.07512v1",
          "size": "567kb",
          "version": "v1"
        }
      ],
      "title": "Demonstration of TFTs 3D Monolithically Integrated on GaN HEMTs using Cascode Configuration with High Breakdown Voltage (>1900V)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07512",
        "PDF": "https://arxiv.org/pdf/2507.07512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is centered on the integration of thin-film transistors and high electron mobility transistors, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07574",
      "abstract": "Most state-of-the-art Visual-Language Models (VLMs) are seemingly limited by the linear separabilty of their visual embeddings on abstract reasoning tasks. This work investigates this \"linear reasoning bottleneck\" by introducing the Linear Separability Ceiling (LSC), the performance of a simple linear classifier on a VLM's visual embeddings. We find this bottleneck is widespread and stems not from poor perception, but from failures in the language model's reasoning pathways. We demonstrate this is a solvable alignment issue. The required intervention, however, is task-dependent: activating existing pathways suffices for semantic concepts, while complex relational reasoning requires adapting core model weights. Using postfix tuning as a methodological control, we find strong evidence for powerful, dormant reasoning pathways within VLMs. However, for complex relational tasks requiring deeper adaptation, explicitly improving representation quality causes the model to fail on new prompt formats despite its embeddings remaining well separated. Ultimately, this work provides a new lens for VLM analysis, showing that robust reasoning is a matter of targeted alignment, not simply improved representation learning.",
      "authors": [
        "Enrico Vompa",
        "Tanel Tammet",
        "Mohit Vaishnav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:23:32+00:00",
          "link": "https://arxiv.org/abs/2507.07574v1",
          "size": "15655kb",
          "version": "v1"
        }
      ],
      "title": "Beyond the Linear Separability Ceiling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07574",
        "HTML": "https://arxiv.org/html/2507.07574v1",
        "PDF": "https://arxiv.org/pdf/2507.07574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates visual-language models' reasoning limits, focusing on linear separability and model alignment rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07733",
      "abstract": "3D Gaussian Splatting (3DGS) has demonstrated impressive capabilities in novel view synthesis. However, rendering reflective objects remains a significant challenge, particularly in inverse rendering and relighting. We introduce RTR-GS, a novel inverse rendering framework capable of robustly rendering objects with arbitrary reflectance properties, decomposing BRDF and lighting, and delivering credible relighting results. Given a collection of multi-view images, our method effectively recovers geometric structure through a hybrid rendering model that combines forward rendering for radiance transfer with deferred rendering for reflections. This approach successfully separates high-frequency and low-frequency appearances, mitigating floating artifacts caused by spherical harmonic overfitting when handling high-frequency details. We further refine BRDF and lighting decomposition using an additional physically-based deferred rendering branch. Experimental results show that our method enhances novel view synthesis, normal estimation, decomposition, and relighting while maintaining efficient training inference process.",
      "authors": [
        "Yongyang Zhou",
        "Fang-Lue Zhang",
        "Zichen Wang",
        "Lei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:13:08+00:00",
          "link": "https://arxiv.org/abs/2507.07733v1",
          "size": "5856kb",
          "version": "v1"
        }
      ],
      "title": "RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance Transfer and Reflection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07733",
        "HTML": "https://arxiv.org/html/2507.07733v1",
        "PDF": "https://arxiv.org/pdf/2507.07733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for inverse rendering with radiance transfer and reflection but does not address LLM training data processing or data-related contributions for training language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09932",
      "abstract": "Diffusion models represent the cutting edge in image generation, but their high memory and computational demands hinder deployment on resource-constrained devices. Post-Training Quantization (PTQ) offers a promising solution by reducing the bitwidth of matrix operations. However, standard PTQ methods struggle with outliers, and achieving higher compression often requires transforming model weights and activations before quantization. In this work, we propose HadaNorm, a novel linear transformation that extends existing approaches by both normalizing channels activations and applying Hadamard transforms to effectively mitigate outliers and enable aggressive activation quantization. We demonstrate that HadaNorm consistently reduces quantization error across the various components of transformer blocks, outperforming state-of-the-art methods.",
      "authors": [
        "Marco Federici",
        "Riccardo Del Chiaro",
        "Boris van Breugel",
        "Paul Whatmough",
        "Markus Nagel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T16:54:34+00:00",
          "link": "https://arxiv.org/abs/2506.09932v1",
          "size": "1669kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:03:57+00:00",
          "link": "https://arxiv.org/abs/2506.09932v2",
          "size": "7598kb",
          "version": "v2"
        }
      ],
      "title": "HadaNorm: Diffusion Transformer Quantization through Mean-Centered Transformations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09932",
        "HTML": "https://arxiv.org/html/2506.09932v2",
        "PDF": "https://arxiv.org/pdf/2506.09932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with quantization in diffusion transformers, focusing on computational efficiency without discussing LLM training data processing or data quality improvements."
      },
      "tasks": [
        "Image Generation",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07217",
      "abstract": "Supply chain networks are complex systems that are challenging to analyze; this problem is exacerbated when there are illicit activities involved in the supply chain, such as counterfeit parts, forced labor, or human trafficking. While machine learning (ML) can find patterns in complex systems like supply chains, traditional ML techniques require large training data sets. However, illicit supply chains are characterized by very sparse data, and the data that is available is often (purposely) corrupted or unreliable in order to hide the nature of the activities. We need to be able to automatically detect new patterns that correlate with such illegal activity over complex, even temporal data, without requiring large training data sets. We explore neurosymbolic methods for identifying instances of illicit activity in supply chains and compare the effectiveness of manual and automated feature extraction from news articles accurately describing illicit activities uncovered by authorities. We propose a question tree approach for querying a large language model (LLM) to identify and quantify the relevance of articles. This enables a systematic evaluation of the differences between human and machine classification of news articles related to forced labor in supply chains.",
      "authors": [
        "Zili Wang",
        "Frank Montabon",
        "Kristin Yvonne Rozier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:44:48+00:00",
          "link": "https://arxiv.org/abs/2507.07217v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07217",
        "HTML": "https://arxiv.org/html/2507.07217v1",
        "PDF": "https://arxiv.org/pdf/2507.07217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses a LLM for feature extraction and classification, touching on data processing techniques, but does not primarily focus on the creation or improvement of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.01803",
      "abstract": "Despite advances in generic object detection, there remains a performance gap in detecting small objects compared to normal-scale objects. We reveal that conventional object localization methods suffer from gradient instability in small objects due to sharper loss curvature, leading to a convergence challenge. To address the issue, we propose Uncertainty-Aware Gradient Stabilization (UGS), a framework that reformulates object localization as a classification task to stabilize gradients. UGS quantizes continuous labels into interval non-uniform discrete representations. Under a classification-based objective, the localization branch generates bounded and confidence-driven gradients, mitigating instability. Furthermore, UGS integrates an uncertainty minimization (UM) loss that reduces prediction variance and an uncertainty-guided refinement (UR) module that identifies and refines high-uncertainty regions via perturbations. Evaluated on four benchmarks, UGS consistently improves anchor-based, anchor-free, and leading small object detectors. Especially, UGS enhances DINO-5scale by 2.6 AP on VisDrone, surpassing previous state-of-the-art results.",
      "authors": [
        "Huixin Sun",
        "Yanjing Li",
        "Linlin Yang",
        "Xianbin Cao",
        "Baochang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-03T09:19:08+00:00",
          "link": "https://arxiv.org/abs/2303.01803v1",
          "size": "1745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:21:57+00:00",
          "link": "https://arxiv.org/abs/2303.01803v2",
          "size": "2330kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Aware Gradient Stabilization for Small Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.01803",
        "HTML": "https://arxiv.org/html/2303.01803v2",
        "PDF": "https://arxiv.org/pdf/2303.01803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with object detection challenges and gradient stabilization in small objects, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Object",
        "object-detection",
        "Object Detection",
        "Object Localization",
        "regression",
        "Small Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07117",
      "abstract": "Machine Learning jobs, carried out on large number of distributed high performance systems, involve periodic communication using operations like AllReduce, AllGather, and Broadcast. These operations may create high bandwidth and bursty traffic patterns, leading to network congestion and packet loss, thus impacting the performance of these jobs. Hence it is imperative to analyze these patterns, which can be helpful in provisioning network resources depending on the type of machine learning workloads. In this poster we carry out extensive analysis of the collective communication behavior seen in a wide variety of models (ex. DeepSeek, GPT, Llama, etc.) To achieve this we instrument Nvidia Collective Communication Library logging functionality for richer context about the collectives and workloads. We adjust configuration parameters that influence collective communication behavior, such as parallelism, number of nodes, and model type. This overview presents and discusses some of the results on the collective communication behavior for the open source DeepSeek V3 inferencing model, which includes operation type and count, transfer sizes per operation, and request size distribution. Our analysis shows that it makes sense to rethink current collective communication frameworks and network topologies so as to accommodate the effect of network anomalies on the mentioned workloads.",
      "authors": [
        "Jit Gupta",
        "Andrew Li",
        "Tarun Banka",
        "Ariel Cohen",
        "T. Sridhar",
        "Raj Yavatkar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T20:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.07117v1",
          "size": "362kb",
          "version": "v1"
        }
      ],
      "title": "Collective Communication Profiling of Modern-day Machine Learning Workloads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07117",
        "HTML": "https://arxiv.org/html/2507.07117v1",
        "PDF": "https://arxiv.org/pdf/2507.07117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing collective communication behavior in distributed systems rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07704",
      "abstract": "The ever-growing volume of data in imaging sciences stemming from the advancements in imaging technologies, necessitates efficient and reliable storage solutions for such large datasets. This study investigates the compression of industrial X-ray computed tomography (XCT) data using deep learning autoencoders and examines how these compression algorithms affect the quality of the recovered data. Two network architectures with different compression rates were used, a deep convolution neural network (D-CNN) and a vector quantized variational autoencoder (VQ-VAE). The XCT data used was from a sandstone sample with a complex internal pore network. The quality of the decoded images obtained from the two different deep learning architectures with different compression rates were quantified and compared to the original input data. In addition, to improve image decoding quality metrics, we introduced a metric sensitive to edge preservation, which is crucial for three-dimensional data analysis. We showed that different architectures and compression rates are required depending on the specific characteristics needed to be preserved for later analysis. The findings presented here can aid scientists to determine the requirements and strategies for their data storage and analysis needs.",
      "authors": [
        "Bardia Hejazi",
        "Keerthana Chand",
        "Tobias Fritsch",
        "Giovanni Bruno"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:32:28+00:00",
          "link": "https://arxiv.org/abs/2507.07704v1",
          "size": "7240kb",
          "version": "v1"
        }
      ],
      "title": "D-CNN and VQ-VAE Autoencoders for Compression and Denoising of Industrial X-ray Computed Tomography Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07704",
        "HTML": "https://arxiv.org/html/2507.07704v1",
        "PDF": "https://arxiv.org/pdf/2507.07704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on compression and denoising techniques for industrial X-ray computed tomography images, rather than on LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.04519",
      "abstract": "Segmentation refinement aims to enhance the initial coarse masks generated by segmentation algorithms. The refined masks are expected to capture more details and better contours of the target objects. Research on segmentation refinement has developed as a response to the need for high-quality image segmentations. However, to our knowledge, no method has been developed that can determine the success of segmentation refinement. Such a method could ensure the reliability of segmentation in applications where the outcome of the segmentation is important and fosters innovation in image processing technologies. To address this research gap, we propose Judging From Support-set (JFS), a method to judge the success of segmentation refinement leveraging an off-the-shelf few-shot segmentation (FSS) model. The traditional goal of the problem in FSS is to find a target object in a query image utilizing target information given by a support set. However, we propose a novel application of the FSS model in our evaluation pipeline for segmentation refinement methods. Given a coarse mask as input, segmentation refinement methods produce a refined mask; these two masks become new support masks for the FSS model. The existing support mask then serves as the test set for the FSS model to evaluate the quality of the refined segmentation by the segmentation refinement methods. We demonstrate the effectiveness of our proposed JFS framework by evaluating the SAM Enhanced Pseudo-Labels (SEPL) using SegGPT as the choice of FSS model on the PASCAL dataset. The results showed that JFS has the potential to determine whether the segmentation refinement process is successful.",
      "authors": [
        "Seonghyeon Moon",
        "Qingze (Tony) Liu",
        "Haein Kong",
        "Muhammad Haris Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-05T14:04:25+00:00",
          "link": "https://arxiv.org/abs/2407.04519v1",
          "size": "14996kb",
          "version": "v1"
        },
        {
          "date": "2024-10-10T04:24:21+00:00",
          "link": "https://arxiv.org/abs/2407.04519v2",
          "size": "16118kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T21:40:16+00:00",
          "link": "https://arxiv.org/abs/2407.04519v3",
          "size": "4743kb",
          "version": "v3"
        }
      ],
      "title": "Judging from Support-set: A New Way to Utilize Few-Shot Segmentation for Segmentation Refinement Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.04519",
        "HTML": "https://arxiv.org/html/2407.04519v3",
        "PDF": "https://arxiv.org/pdf/2407.04519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for assessing segmentation refinement using few-shot segmentation models\u2014it does not involve LLM training data processing."
      },
      "tasks": [
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.12246",
      "abstract": "Aerial object detection plays a crucial role in numerous applications. However, most existing methods focus on detecting predefined object categories, limiting their applicability in real-world open scenarios. In this paper, we extend aerial object detection to open scenarios through image-text collaboration and propose RT-OVAD, the first real-time open-vocabulary detector for aerial scenes. Specifically, we first introduce an image-to-text alignment loss to replace the conventional category regression loss, thereby eliminating category constraints. Next, we propose a lightweight image-text collaboration strategy comprising an image-text collaboration encoder and a text-guided decoder. The encoder simultaneously enhances visual features and refines textual embeddings, while the decoder guides object queries to focus on class-relevant image features. This design further improves detection accuracy without incurring significant computational overhead. Extensive experiments demonstrate that RT-OVAD consistently outperforms existing state-of-the-art methods across open-vocabulary, zero-shot, and traditional closed-set detection tasks. For instance, on the open-vocabulary aerial detection benchmarks DIOR, DOTA-v2.0, and LAE-80C, RT-OVAD achieves 87.7 AP$_{50}$, 53.8 mAP, and 23.7 mAP, respectively, surpassing the previous state-of-the-art (LAE-DINO) by 2.2, 7.0, and 3.5 points. In addition, RT-OVAD achieves an inference speed of 34 FPS on an RTX 4090 GPU, approximately three times faster than LAE-DINO (10 FPS), meeting the real-time detection requirements of diverse applications. The code will be released at https://github.com/GT-Wei/RT-OVAD.",
      "authors": [
        "Guoting Wei",
        "Xia Yuan",
        "Yu Liu",
        "Zhenhao Shang",
        "Xizhe Xue",
        "Peng Wang",
        "Kelu Yao",
        "Chunxia Zhao",
        "Haokui Zhang",
        "Rong Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T09:33:25+00:00",
          "link": "https://arxiv.org/abs/2408.12246v1",
          "size": "3643kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T06:32:41+00:00",
          "link": "https://arxiv.org/abs/2408.12246v2",
          "size": "14316kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T04:02:50+00:00",
          "link": "https://arxiv.org/abs/2408.12246v3",
          "size": "4786kb",
          "version": "v3"
        }
      ],
      "title": "RT-OVAD: Real-Time Open-Vocabulary Aerial Object Detection via Image-Text Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12246",
        "HTML": "https://arxiv.org/html/2408.12246v3",
        "PDF": "https://arxiv.org/pdf/2408.12246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a new real-time open-vocabulary detector for aerial object detection through image-text collaboration, without addressing LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07769",
      "abstract": "Recent years have seen significant advancements in designing reinforcement learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.",
      "authors": [
        "Ruohong Liu",
        "Jack Umenberger",
        "Yize Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:54:38+00:00",
          "link": "https://arxiv.org/abs/2507.07769v1",
          "size": "631kb",
          "version": "v1"
        }
      ],
      "title": "BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07769",
        "HTML": "https://arxiv.org/html/2507.07769v1",
        "PDF": "https://arxiv.org/pdf/2507.07769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for building energy management and formulation of a multi-objective contextual RL problem. It does not address processing of LLM training data or dataset creation in the context of language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00067",
      "abstract": "Many modern areas have not learned their lessons and often hope for the wisdom of later generations, resulting in them only possessing modern technology and difficult to iterate ancient civilizations. At present, there is no way to tell how we should learn from history and promote the gradual upgrading of civilization. Therefore, we must tell the history of civilization's progress and the means of governance, learn from experience to improve the comprehensive strength and survival ability of civilization, and achieve an optimal solution for the tempering brought by conflicts and the reduction of internal conflicts. Firstly, we must follow the footsteps of history and explore the reasons for the long-term stability of each country in conflict, including providing economic benefits to the people and means of suppressing them; then, use mathematical methods to demonstrate how we can achieve the optimal solution at the current stage. After analysis, we can conclude that the civilization transformed from human plowing to horse plowing can easily suppress the resistance of the people and provide them with the ability to resist; The selection of rulers should consider multiple institutional aspects, such as exams, elections, and drawing lots; Economic development follows a lognormal distribution and can be adjusted by expected value and variance. Using a lognormal distribution with the maximum value to divide equity can adjust the wealth gap.",
      "authors": [
        "Hongfa Zi",
        "Zhen Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:07:44+00:00",
          "link": "https://arxiv.org/abs/2507.00067v1",
          "size": "361kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:55:10+00:00",
          "link": "https://arxiv.org/abs/2507.00067v2",
          "size": "257kb",
          "version": "v2"
        }
      ],
      "title": "The gradual transformation of inland areas -- human plowing, horse plowing and equity incentives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00067",
        "PDF": "https://arxiv.org/pdf/2507.00067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the historical progression of civilization and mathematical modeling for economic development, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07824",
      "abstract": "We introduce conditional unigram tokenization, a novel approach that extends unigram tokenization by conditioning target token probabilities on source-language tokens from parallel data. Given a fixed source tokenizer, our method learns a target tokenizer that maximizes cross-lingual semantic alignment. We evaluate our tokenizer on four language pairs across different families and resource levels, examining intrinsic properties and downstream performance on machine translation and language modeling. While our conditional tokenizer maintains comparable statistical properties to standard unigram tokenizers, results are mixed: we observe no improvements in machine translation quality, but find consistent perplexity reductions in language modeling. We hypothesize that quadratic scaling of conditional probability estimation with respect to the vocabulary size creates a data efficiency bottleneck. Our findings suggest that alternative parameterizations may be necessary for practical cross-lingual tokenization.",
      "authors": [
        "Gianluca Vico",
        "Jind\\v{r}inch Libovick\\'y"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:53:59+00:00",
          "link": "https://arxiv.org/abs/2507.07824v1",
          "size": "146kb",
          "version": "v1"
        }
      ],
      "title": "Conditional Unigram Tokenization with Parallel Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07824",
        "HTML": "https://arxiv.org/html/2507.07824v1",
        "PDF": "https://arxiv.org/pdf/2507.07824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces conditional unigram tokenization and evaluates its application in machine translation and language modeling, mentioning data efficiency but not focusing on training data processing primarily."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07857",
      "abstract": "Causality has gained popularity in recent years. It has helped improve the performance, reliability, and interpretability of machine learning models. However, recent literature on explainable artificial intelligence (XAI) has faced criticism. The classical XAI and causality literature focuses on understanding which factors contribute to which consequences. While such knowledge is valuable for researchers and engineers, it is not what non-expert users expect as explanations. Instead, these users often await facts that cause the target consequences, i.e., actual causes. Formalizing this notion is still an open problem. Additionally, identifying actual causes is reportedly an NP-complete problem, and there are too few practical solutions to approximate formal definitions. We propose a set of algorithms to identify actual causes with a polynomial complexity and an adjustable level of precision and exhaustiveness. Our experiments indicate that the algorithms (1) identify causes for different categories of systems that are not handled by existing approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be adjusted to gain more precision and exhaustiveness with more computation time.",
      "authors": [
        "Samuel Reyd",
        "Ada Diaconescu",
        "Jean-Louis Dessalles"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:39:36+00:00",
          "link": "https://arxiv.org/abs/2507.07857v1",
          "size": "800kb",
          "version": "v1"
        }
      ],
      "title": "Searching for actual causes: Approximate algorithms with adjustable precision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07857",
        "HTML": "https://arxiv.org/html/2507.07857v1",
        "PDF": "https://arxiv.org/pdf/2507.07857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes algorithms for identifying causal factors within systems, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.17773",
      "abstract": "This paper investigates visual analogical reasoning in large multimodal models (LMMs) compared to human adults and children. A \"visual analogy\" is an abstract rule inferred from one image and applied to another. While benchmarks exist for testing visual reasoning in LMMs, they require advanced skills and omit basic visual analogies that even young children can make. Inspired by developmental psychology, we propose a new benchmark of 4,300 visual transformations of everyday objects to test LMMs on visual analogical reasoning and compare them to children (ages three to five) and to adults. We structure the evaluation into three stages: identifying what changed (e.g., color, number, etc.), how it changed (e.g., added one object), and applying the rule to new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and MANTIS identify the \"what\" effectively, they struggle with quantifying the \"how\" and extrapolating this rule to new objects. In contrast, children and adults exhibit much stronger analogical reasoning at all three stages. Additionally, the strongest tested model, GPT-o1, performs better in tasks involving simple surface-level visual attributes like color and size, correlating with quicker human adult response times. Conversely, more complex tasks such as number, rotation, and reflection, which necessitate extensive cognitive processing and understanding of extrinsic spatial properties in the physical world, present more significant challenges. Altogether, these findings highlight the limitations of training models on data that primarily consists of 2D images and text.",
      "authors": [
        "Eunice Yiu",
        "Maan Qraitem",
        "Anisa Noor Majhi",
        "Charlie Wong",
        "Yutong Bai",
        "Shiry Ginosar",
        "Alison Gopnik",
        "Kate Saenko"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-25T05:02:39+00:00",
          "link": "https://arxiv.org/abs/2407.17773v1",
          "size": "6259kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T05:20:59+00:00",
          "link": "https://arxiv.org/abs/2407.17773v2",
          "size": "3642kb",
          "version": "v2"
        },
        {
          "date": "2025-03-05T03:07:12+00:00",
          "link": "https://arxiv.org/abs/2407.17773v3",
          "size": "3694kb",
          "version": "v3"
        }
      ],
      "title": "KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17773",
        "HTML": "https://arxiv.org/html/2407.17773",
        "PDF": "https://arxiv.org/pdf/2407.17773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new benchmark for evaluating visual analogical reasoning in multimodal models but does not focus on the processing of LLM training data."
      },
      "tasks": [
        "Visual Analogies",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/ey242/kiva"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00759",
      "abstract": "Transformers, as the fundamental deep learning architecture, have demonstrated great capability in reasoning. This paper studies the generalizable first-order logical reasoning ability of transformers with their parameterized knowledge and how to improve it. Transformers' capability of first-order reasoning is further captured by whether they can conduct first-order logical entailment, which is quantitatively measured by their performance in answering knowledge graph queries. We establish the connections between (1) two types of distribution shifts studied in out-of-distribution generalization and (2) unseen knowledge and query settings discussed in the task of knowledge graph query answering, which makes it possible to characterize the fine-grained generalizability. Results on our comprehensive dataset showed that transformers \\textit{outperform} previous methods designed particularly for this task and provided detailed empirical evidence about the impact of the input query syntax, token embedding, and transformer architectures on their reasoning capability. Interestingly, our results revealed the mismatch of positional encoding and other design choices of transformer architectures in previous practices. Motivated by this, we propose TEGA, a logic-aware architecture that significantly improves the performance in generalizable first-order logical entailment.",
      "authors": [
        "Tianshi Zheng",
        "Jiazheng Wang",
        "Zihao Wang",
        "Jiaxin Bai",
        "Hang Yin",
        "Zheye Deng",
        "Yangqiu Song",
        "Jianxin Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-01T07:05:32+00:00",
          "link": "https://arxiv.org/abs/2501.00759v1",
          "size": "390kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T11:36:26+00:00",
          "link": "https://arxiv.org/abs/2501.00759v2",
          "size": "394kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:45:30+00:00",
          "link": "https://arxiv.org/abs/2501.00759v3",
          "size": "394kb",
          "version": "v3"
        }
      ],
      "title": "Enhancing Transformers for Generalizable First-Order Logical Entailment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00759",
        "HTML": "https://arxiv.org/html/2501.00759v3",
        "PDF": "https://arxiv.org/pdf/2501.00759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily examines transformer architectures and logical entailment in reasoning tasks, without focusing on data processing for LLM training."
      },
      "tasks": [
        "Logical Reasoning",
        "Out-of-Distribution Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10733",
      "abstract": "Quantum Approximate Optimization Algorithm (QAOA) is one of the most promising candidates to achieve the quantum advantage in solving combinatorial optimization problems. The process of finding a good set of variational parameters in the QAOA circuit has proven to be challenging due to multiple factors, such as barren plateaus. As a result, there is growing interest in exploiting parameter transferability, where parameter sets optimized for one problem instance are transferred to another that could be more complex either to estimate the solution or to serve as a warm start for further optimization. But can we transfer parameters from one class of problems to another? Leveraging parameter sets learned from a well-studied class of problems could help navigate the less studied one, reducing optimization overhead and mitigating performance pitfalls. In this paper, we study whether pretrained QAOA parameters of MaxCut can be used as is or to warm start the Maximum Independent Set (MIS) circuits. Specifically, we design machine learning models to find good donor candidates optimized on MaxCut and apply their parameters to MIS acceptors. Our experimental results show that such parameter transfer can significantly reduce the number of optimization iterations required while achieving comparable approximation ratios.",
      "authors": [
        "Kien X. Nguyen",
        "Bao Bach",
        "Ilya Safro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T21:56:11+00:00",
          "link": "https://arxiv.org/abs/2504.10733v1",
          "size": "970kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:19:07+00:00",
          "link": "https://arxiv.org/abs/2504.10733v2",
          "size": "281kb",
          "version": "v2"
        }
      ],
      "title": "Cross-Problem Parameter Transfer in Quantum Approximate Optimization Algorithm: A Machine Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10733",
        "HTML": "https://arxiv.org/html/2504.10733v2",
        "PDF": "https://arxiv.org/pdf/2504.10733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on parameter transfer between quantum optimization algorithms using a machine learning approach and does not discuss LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Navigate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17836",
      "abstract": "This paper addresses the problem of robust estimation in gossip algorithms over arbitrary communication graphs. Gossip algorithms are fully decentralized, relying only on local neighbor-to-neighbor communication, making them well-suited for situations where communication is constrained. A fundamental challenge in existing mean-based gossip algorithms is their vulnerability to malicious or corrupted nodes. In this paper, we show that an outlier-robust mean can be computed by globally estimating a robust statistic. More specifically, we propose a novel gossip algorithm for rank estimation, referred to as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated to trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed description of the proposed methods, a key contribution of our work is a precise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank estimation and an $\\mathcal{O}(1 / {t})$ rate for trimmed mean estimation, where by $t$ is meant the number of iterations. Moreover, we provide a breakdown point analysis of \\textsc{GoTrim}. We empirically validate our theoretical results through experiments on diverse network topologies, data distributions and contamination schemes.",
      "authors": [
        "Anna Van Elst",
        "Igor Colin",
        "Stephan Cl\\'emen\\c{c}on"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T12:51:03+00:00",
          "link": "https://arxiv.org/abs/2505.17836v1",
          "size": "38292kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T16:07:48+00:00",
          "link": "https://arxiv.org/abs/2505.17836v2",
          "size": "564kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T14:26:25+00:00",
          "link": "https://arxiv.org/abs/2505.17836v3",
          "size": "565kb",
          "version": "v3"
        },
        {
          "date": "2025-06-10T16:53:46+00:00",
          "link": "https://arxiv.org/abs/2505.17836v4",
          "size": "561kb",
          "version": "v4"
        },
        {
          "date": "2025-06-11T09:42:15+00:00",
          "link": "https://arxiv.org/abs/2505.17836v5",
          "size": "564kb",
          "version": "v5"
        },
        {
          "date": "2025-07-10T12:56:43+00:00",
          "link": "https://arxiv.org/abs/2505.17836v6",
          "size": "564kb",
          "version": "v6"
        }
      ],
      "title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17836",
        "HTML": "https://arxiv.org/html/2505.17836",
        "PDF": "https://arxiv.org/pdf/2505.17836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gossip algorithms for decentralized estimation and does not discuss LLM training data processing or the creation of datasets."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07390",
      "abstract": "Rare events such as state transitions are difficult to observe directly with molecular dynamics simulations due to long timescales. Enhanced sampling techniques overcome this by introducing biases along carefully chosen low-dimensional features, known as collective variables (CVs), which capture the slow degrees of freedom. Machine learning approaches (MLCVs) have automated CV discovery, but existing methods typically focus on discriminating meta-stable states without fully encoding the detailed dynamics essential for accurate sampling. We propose TLC, a framework that learns CVs directly from time-lagged conditions of a generative model. Instead of modeling the static Boltzmann distribution, TLC models a time-lagged conditional distribution yielding CVs to capture the slow dynamic behavior. We validate TLC on the Alanine Dipeptide system using two CV-based enhanced sampling tasks: (i) steered molecular dynamics (SMD) and (ii) on-the-fly probability enhanced sampling (OPES), demonstrating equal or superior performance compared to existing MLCV methods in both transition path sampling and state discrimination.",
      "authors": [
        "Seonghyun Park",
        "Kiyoung Seong",
        "Soojung Yang",
        "Rafael G\\'omez-Bombarelli and Sungsoo Ahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:06:21+00:00",
          "link": "https://arxiv.org/abs/2507.07390v1",
          "size": "14586kb",
          "version": "v1"
        }
      ],
      "title": "Learning Collective Variables from Time-lagged Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07390",
        "HTML": "https://arxiv.org/html/2507.07390v1",
        "PDF": "https://arxiv.org/pdf/2507.07390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for learning collective variables using time-lagged generation in molecular dynamics, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.00275",
      "abstract": "The number of satellites, especially those operating in low-earth orbit (LEO), is exploding in recent years. Additionally, the use of COTS hardware into those satellites enables a new paradigm of computing: orbital edge computing (OEC). OEC entails more technically advanced steps compared to single-satellite computing. This feature allows for vast design spaces with multiple parameters, rendering several novel approaches feasible. The mobility of LEO satellites in the network and limited resources of communication, computation, and storage make it challenging to design an appropriate scheduling algorithm for specific tasks in comparison to traditional ground-based edge computing. This article comprehensively surveys the significant areas of focus in orbital edge computing, which include protocol optimization, mobility management, and resource allocation. This article provides the first comprehensive survey of OEC. Previous survey papers have only concentrated on ground-based edge computing or the integration of space and ground technologies. This article presents a review of recent research from 2000 to 2023 on orbital edge computing that covers network design, computation offloading, resource allocation, performance analysis, and optimization. Moreover, having discussed several related works, both technological challenges and future directions are highlighted in the field.",
      "authors": [
        "Changhao Wu and Yuanchun Li and Mengwei Xu and Chongbin Guo and Zengshan Yin and Weiwei Gao and Chuanxiu Chi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-01T01:37:33+00:00",
          "link": "https://arxiv.org/abs/2306.00275v1",
          "size": "1611kb",
          "version": "v1"
        },
        {
          "date": "2023-06-02T01:11:40+00:00",
          "link": "https://arxiv.org/abs/2306.00275v2",
          "size": "1610kb",
          "version": "v2"
        }
      ],
      "title": "A Comprehensive Survey on Orbital Edge Computing: Systems, Applications, and Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.00275",
        "PDF": "https://arxiv.org/pdf/2306.00275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on orbital edge computing and does not address LLM training data processing or data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07364",
      "abstract": "Scientific authorship norms vary dramatically across disciplines, from contribution-sensitive systems where first author is the greatest contributor and subsequent author order reflects relative input, to contribution-insensitive conventions like alphabetical ordering or senior-author-last. We develop evolutionary game-theoretic models to examine both how these divergent norms emerge and their subsequent effects on collaborative behavior. Our first model reveals that contribution-insensitive norms evolve when researchers who sacrifice positional advantage face the strongest adaptive pressure -- for example senior authors managing larger collaboration portfolios or bearing heavier reputational stakes. This \"Red King\" dynamic potentially explains why fields in which senior researchers command large labs, major grants, and extensive collaboration portfolios may paradoxically evolve conventions that favour junior-author positioning. Our second model demonstrates that established norms influence researchers' willingness to collaborate, with contribution-sensitive norms consistently outperforming insensitive alternatives in fostering successful partnerships. Contribution-insensitive norms create systematic coordination failures through two mechanisms: \"main contributor resentment\" when exceptional work goes unrecognized, and \"second contributor resentment\" when comparable efforts receive unequal credit. These findings suggest that widely adopted practices like senior-last positioning and alphabetical ordering may function as institutional frictions that impede valuable scientific collaborations rather than neutral organizational conventions, potentially reducing overall scientific productivity across affected disciplines.",
      "authors": [
        "Toby Handfield",
        "Kevin Zollman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:14:14+00:00",
          "link": "https://arxiv.org/abs/2507.07364v1",
          "size": "41684kb",
          "version": "v1"
        }
      ],
      "title": "The Evolution of Scientific Credit: When Authorship Norms Impede Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07364",
        "PDF": "https://arxiv.org/pdf/2507.07364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the norms of scientific authorship and their effects on collaboration, not on LLM training data processing or any data engineering processes relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07578",
      "abstract": "Weakly-supervised semantic segmentation aims to assign category labels to each pixel using weak annotations, significantly reducing manual annotation costs. Although existing methods have achieved remarkable progress in well-lit scenarios, their performance significantly degrades in low-light environments due to two fundamental limitations: severe image quality degradation (e.g., low contrast, noise, and color distortion) and the inherent constraints of weak supervision. These factors collectively lead to unreliable class activation maps and semantically ambiguous pseudo-labels, ultimately compromising the model's ability to learn discriminative feature representations. To address these problems, we propose Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-light Semantic Segmentation (DGKD-WLSS), a novel framework that synergistically combines Diffusion-Guided Knowledge Distillation (DGKD) with Depth-Guided Feature Fusion (DGF2). DGKD aligns normal-light and low-light features via diffusion-based denoising and knowledge distillation, while DGF2 integrates depth maps as illumination-invariant geometric priors to enhance structural feature learning. Extensive experiments demonstrate the effectiveness of DGKD-WLSS, which achieves state-of-the-art performance in weakly supervised semantic segmentation tasks under low-light conditions. The source codes have been released at:https://github.com/ChunyanWang1/DGKD-WLSS.",
      "authors": [
        "Chunyan Wang",
        "Dong Zhang and Jinhui Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:28:54+00:00",
          "link": "https://arxiv.org/abs/2507.07578v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-Light Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07578",
        "HTML": "https://arxiv.org/html/2507.07578v1",
        "PDF": "https://arxiv.org/pdf/2507.07578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving semantic segmentation in low-light conditions using diffusion and knowledge distillation. It addresses image quality issues but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07230",
      "abstract": "Clothes-Changing Re-Identification (CC-ReID) aims to recognize individuals across different locations and times, irrespective of clothing. Existing methods often rely on additional models or annotations to learn robust, clothing-invariant features, making them resource-intensive. In contrast, we explore the use of color - specifically foreground and background colors - as a lightweight, annotation-free proxy for mitigating appearance bias in ReID models. We propose Colors See, Colors Ignore (CSCI), an RGB-only method that leverages color information directly from raw images or video frames. CSCI efficiently captures color-related appearance bias ('Color See') while disentangling it from identity-relevant ReID features ('Color Ignore'). To achieve this, we introduce S2A self-attention, a novel self-attention to prevent information leak between color and identity cues within the feature space. Our analysis shows a strong correspondence between learned color embeddings and clothing attributes, validating color as an effective proxy when explicit clothing labels are unavailable. We demonstrate the effectiveness of CSCI on both image and video ReID with extensive experiments on four CC-ReID datasets. We improve the baseline by Top-1 2.9% on LTCC and 5.0% on PRCC for image-based ReID, and 1.0% on CCVID and 2.5% on MeVID for video-based ReID without relying on additional supervision. Our results highlight the potential of color as a cost-effective solution for addressing appearance bias in CC-ReID. Github: https://github.com/ppriyank/ICCV-CSCI-Person-ReID.",
      "authors": [
        "Priyank Pathak",
        "Yogesh S. Rawat"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:05:46+00:00",
          "link": "https://arxiv.org/abs/2507.07230v1",
          "size": "3556kb",
          "version": "v1"
        }
      ],
      "title": "Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07230",
        "HTML": "https://arxiv.org/html/2507.07230v1",
        "PDF": "https://arxiv.org/pdf/2507.07230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving a person re-identification model using color information and self-attention mechanisms, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07771",
      "abstract": "To alleviate the annotation burden in supervised learning, N-tuples learning has recently emerged as a powerful weakly-supervised method. While existing N-tuples learning approaches extend pairwise learning to higher-order comparisons and accommodate various real-world scenarios, they often rely on task-specific designs and lack a unified theoretical foundation. In this paper, we propose a general N-tuples learning framework based on empirical risk minimization, which systematically integrates pointwise unlabeled data to enhance learning performance. This paper first unifies the data generation processes of N-tuples and pointwise unlabeled data under a shared probabilistic formulation. Based on this unified view, we derive an unbiased empirical risk estimator that generalizes a broad class of existing N-tuples models. We further establish a generalization error bound for theoretical support. To demonstrate the flexibility of the framework, we instantiate it in four representative weakly supervised scenarios, each recoverable as a special case of our general model. Additionally, to address overfitting issues arising from negative risk terms, we adopt correction functions to adjust the empirical risk. Extensive experiments on benchmark datasets validate the effectiveness of the proposed framework and demonstrate that leveraging pointwise unlabeled data consistently improves generalization across various N-tuples learning tasks.",
      "authors": [
        "Shuying Huang",
        "Junpeng Li",
        "Changchun Hua",
        "and Yana Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:54:59+00:00",
          "link": "https://arxiv.org/abs/2507.07771v1",
          "size": "6059kb",
          "version": "v1"
        }
      ],
      "title": "A Unified Empirical Risk Minimization Framework for Flexible N-Tuples Weak Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07771",
        "HTML": "https://arxiv.org/html/2507.07771v1",
        "PDF": "https://arxiv.org/pdf/2507.07771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper presents a general N-tuples learning framework, which mentions data generation processes but primarily focuses on empirical risk minimization and theoretical bounds for weak supervision, without direct emphasis on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07806",
      "abstract": "Emotion and intent recognition from speech is essential and has been widely investigated in human-computer interaction. The rapid development of social media platforms, chatbots, and other technologies has led to a large volume of speech data streaming from users. Nevertheless, annotating such data manually is expensive, making it challenging to train machine learning models for recognition purposes. To this end, we propose applying semi-supervised learning to incorporate a large scale of unlabelled data alongside a relatively smaller set of labelled data. We train end-to-end acoustic and linguistic models, each employing multi-task learning for emotion and intent recognition. Two semi-supervised learning approaches, including fix-match learning and full-match learning, are compared. The experimental results demonstrate that the semi-supervised learning approaches improve model performance in speech emotion and intent recognition from both acoustic and text data. The late fusion of the best models outperforms the acoustic and text baselines by joint recognition balance metrics of 12.3% and 10.4%, respectively.",
      "authors": [
        "Zhao Ren",
        "Rathi Adarshi Rammohan",
        "Kevin Scheck",
        "Sheng Li",
        "Tanja Schultz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:30:29+00:00",
          "link": "https://arxiv.org/abs/2507.07806v1",
          "size": "339kb",
          "version": "v1"
        }
      ],
      "title": "End-to-end Acoustic-linguistic Emotion and Intent Recognition Enhanced by Semi-supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07806",
        "HTML": "https://arxiv.org/html/2507.07806v1",
        "PDF": "https://arxiv.org/pdf/2507.07806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses semi-supervised learning for acoustic-linguistic emotion recognition but does not detail substantive processing or creation of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07831",
      "abstract": "Class-incremental/Continual image segmentation (CIS) aims to train an image segmenter in stages, where the set of available categories differs at each stage. To leverage the built-in objectness of query-based transformers, which mitigates catastrophic forgetting of mask proposals, current methods often decouple mask generation from the continual learning process. This study, however, identifies two key issues with decoupled frameworks: loss of plasticity and heavy reliance on input data order. To address these, we conduct an in-depth investigation of the built-in objectness and find that highly aggregated image features provide a shortcut for queries to generate masks through simple feature alignment. Based on this, we propose SimCIS, a simple yet powerful baseline for CIS. Its core idea is to directly select image features for query assignment, ensuring \"perfect alignment\" to preserve objectness, while simultaneously allowing queries to select new classes to promote plasticity. To further combat catastrophic forgetting of categories, we introduce cross-stage consistency in selection and an innovative \"visual query\"-based replay mechanism. Experiments demonstrate that SimCIS consistently outperforms state-of-the-art methods across various segmentation tasks, settings, splits, and input data orders. All models and codes will be made publicly available at https://github.com/SooLab/SimCIS.",
      "authors": [
        "Yuchen Zhu",
        "Cheng Shi",
        "Dingyou Wang",
        "Jiajin Tang",
        "Zhengxuan Wei",
        "Yu Wu",
        "Guanbin Li",
        "Sibei Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:03:10+00:00",
          "link": "https://arxiv.org/abs/2507.07831v1",
          "size": "1158kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Query-based Transformer for Continual Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07831",
        "HTML": "https://arxiv.org/html/2507.07831v1",
        "PDF": "https://arxiv.org/pdf/2507.07831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study proposes improvements for continual image segmentation, emphasizing model architecture and learning processes rather than substantial LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04391",
      "abstract": "Most modern approaches for audio processing are opaque, in the sense that they do not provide an explanation for their decisions. For this reason, various methods have been proposed to explain the outputs generated by these models. Good explanations can result in interesting insights about the data or the model, as well as increase trust in the system. Unfortunately, evaluating the quality of explanations is far from trivial since, for most tasks, there is no clear ground truth explanation to use as reference. In this work, we propose a benchmark for time-localized explanations for audio classification models that uses time annotations of target events as a proxy for ground truth explanations. We use this benchmark to systematically optimize and compare various approaches for model-agnostic post-hoc explanation, obtaining, in some cases, close to perfect explanations. Finally, we illustrate the utility of the explanations for uncovering spurious correlations.",
      "authors": [
        "Cecilia Bola\\~nos",
        "Leonardo Pepino",
        "Martin Meza",
        "Luciana Ferrer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T19:16:00+00:00",
          "link": "https://arxiv.org/abs/2506.04391v1",
          "size": "1159kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:19:41+00:00",
          "link": "https://arxiv.org/abs/2506.04391v2",
          "size": "760kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Time-localized Explanations for Audio Classification Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04391",
        "HTML": "https://arxiv.org/html/2506.04391v2",
        "PDF": "https://arxiv.org/pdf/2506.04391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a benchmark for evaluating explanations in audio classification models, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00004",
      "abstract": "Large language models (LLMs) demand considerable computational, energy, and financial resources during both training and deployment. While scaling laws for training have guided much of the field's recent progress, inference costs now represent a significant and growing component of the overall resource burden, particularly for reasoning-focused models. Existing characterizations of compute-optimality that consider model size, dataset size, and inference tokens in isolation or in fixed combinations risk overlooking more efficient operating points. We introduce directed stochastic skill search (DS3), a general framework that represents inference as stochastic traversal over a learned skill graph. From a simplified yet expressive instantiation, we derive closed-form expressions for task success and compute cost across a wide range of inference strategies -- including chain-of-thought (CoT) and tree-of-thought (ToT) -- enabling comparative analysis as a function of task difficulty and model capability. To that end, we extend a prior first-principles tripartite graph framework of LLM training to incorporate inference, and separately bridge DS3 with empirical methods that characterize LLM scaling behavior. We theoretically recover empirically observed patterns, including: linear accuracy scaling with logarithmic compute; variation in preferred inference strategies as a function of task difficulty and model capability; emergent behavior elicited by reasoning even when performance plateaus under parameter scaling; and both best-of-N (BoN) and majority voting behavior captured within a unified analytical framework. By explicitly characterizing training-inference interdependencies, our framework deepens theoretical understanding and supports principled algorithmic design and resource allocation.",
      "authors": [
        "Austin R. Ellis-Mohr",
        "Anuj K. Nayak",
        "Lav R. Varshney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T14:47:48+00:00",
          "link": "https://arxiv.org/abs/2507.00004v1",
          "size": "12256kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:08:40+00:00",
          "link": "https://arxiv.org/abs/2507.00004v2",
          "size": "12257kb",
          "version": "v2"
        }
      ],
      "title": "A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00004",
        "HTML": "https://arxiv.org/html/2507.00004v2",
        "PDF": "https://arxiv.org/pdf/2507.00004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on inference compute scaling and does not discuss any aspects of processing or creating LLM training data, nor does it address data processing during training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07860",
      "abstract": "Progress in a research field can be hard to assess, in particular when many concurrent methods are proposed in a short period of time. This is the case in digital pathology, where many foundation models have been released recently to serve as feature extractors for tile-level images, being used in a variety of downstream tasks, both for tile- and slide-level problems. Benchmarking available methods then becomes paramount to get a clearer view of the research landscape. In particular, in critical domains such as healthcare, a benchmark should not only focus on evaluating downstream performance, but also provide insights about the main differences between methods, and importantly, further consider uncertainty and robustness to ensure a reliable usage of proposed models. For these reasons, we introduce THUNDER, a tile-level benchmark for digital pathology foundation models, allowing for efficient comparison of many models on diverse datasets with a series of downstream tasks, studying their feature spaces and assessing the robustness and uncertainty of predictions informed by their embeddings. THUNDER is a fast, easy-to-use, dynamic benchmark that can already support a large variety of state-of-the-art foundation, as well as local user-defined models for direct tile-based comparison. In this paper, we provide a comprehensive comparison of 23 foundation models on 16 different datasets covering diverse tasks, feature analysis, and robustness. The code for THUNDER is publicly available at https://github.com/MICS-Lab/thunder.",
      "authors": [
        "Pierre Marza",
        "Leo Fillioux",
        "Sofi\\`ene Boutaj",
        "Kunal Mahatha",
        "Christian Desrosiers",
        "Pablo Piantanida",
        "Jose Dolz",
        "Stergios Christodoulidis",
        "Maria Vakalopoulou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:41:35+00:00",
          "link": "https://arxiv.org/abs/2507.07860v1",
          "size": "40652kb",
          "version": "v1"
        }
      ],
      "title": "THUNDER: Tile-level Histopathology image UNDERstanding benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07860",
        "PDF": "https://arxiv.org/pdf/2507.07860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for digital pathology models, focusing on downstream tasks and model evaluation without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07862",
      "abstract": "Antimicrobial resistance (AMR) is escalating and outpacing current antibiotic development. Thus, discovering antibiotics effective against emerging pathogens is becoming increasingly critical. However, existing approaches cannot rapidly identify effective molecules against novel pathogens or emerging drug-resistant strains. Here, we introduce ApexOracle, an artificial intelligence (AI) model that both predicts the antibacterial potency of existing compounds and designs de novo molecules active against strains it has never encountered. Departing from models that rely solely on molecular features, ApexOracle incorporates pathogen-specific context through the integration of molecular features captured via a foundational discrete diffusion language model and a dual-embedding framework that combines genomic- and literature-derived strain representations. Across diverse bacterial species and chemical modalities, ApexOracle consistently outperformed state-of-the-art approaches in activity prediction and demonstrated reliable transferability to novel pathogens with little or no antimicrobial data. Its unified representation-generation architecture further enables the in silico creation of \"new-to-nature\" molecules with high predicted efficacy against priority threats. By pairing rapid activity prediction with targeted molecular generation, ApexOracle offers a scalable strategy for countering AMR and preparing for future infectious-disease outbreaks.",
      "authors": [
        "Tianang Leng",
        "Fangping Wan",
        "Marcelo Der Torossian Torres",
        "Cesar de la Fuente-Nunez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:42:31+00:00",
          "link": "https://arxiv.org/abs/2507.07862v1",
          "size": "1495kb",
          "version": "v1"
        }
      ],
      "title": "Predicting and generating antibiotics against future pathogens with ApexOracle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07862",
        "HTML": "https://arxiv.org/html/2507.07862v1",
        "PDF": "https://arxiv.org/pdf/2507.07862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper describes data generation via an AI model, it focuses principally on generating antibiotics with ApexOracle, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07932",
      "abstract": "Autoscaling GPU inference workloads in Kubernetes remains challenging due to the reactive and threshold-based nature of default mechanisms such as the Horizontal Pod Autoscaler (HPA), which struggle under dynamic and bursty traffic patterns and lack integration with GPU-level metrics. We present KIS-S, a unified framework that combines KISim, a GPU-aware Kubernetes Inference Simulator, with KIScaler, a Proximal Policy Optimization (PPO)-based autoscaler. KIScaler learns latency-aware and resource-efficient scaling policies entirely in simulation, and is directly deployed without retraining. Experiments across four traffic patterns show that KIScaler improves average reward by 75.2%, reduces P95 latency up to 6.7x over CPU baselines, and generalizes without retraining. Our work bridges the gap between reactive autoscaling and intelligent orchestration for scalable GPU-accelerated environments.",
      "authors": [
        "Guilin Zhang",
        "Wulan Guo",
        "Ziqi Tan",
        "Qiang Guan",
        "and Hailong Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.07932v1",
          "size": "599kb",
          "version": "v1"
        }
      ],
      "title": "KIS-S: A GPU-Aware Kubernetes Inference Simulator with RL-Based Auto-Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07932",
        "HTML": "https://arxiv.org/html/2507.07932v1",
        "PDF": "https://arxiv.org/pdf/2507.07932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a GPU-aware Kubernetes inference simulator for autoscaling but does not mention any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07957",
      "abstract": "Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.",
      "authors": [
        "Yu Wang and Xi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:40:11+00:00",
          "link": "https://arxiv.org/abs/2507.07957v1",
          "size": "2269kb",
          "version": "v1"
        }
      ],
      "title": "MIRIX: Multi-Agent Memory System for LLM-Based Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07957",
        "HTML": "https://arxiv.org/html/2507.07957v1",
        "PDF": "https://arxiv.org/pdf/2507.07957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a new memory system for LLM-based agents, focusing on memory types and retrieval systems rather than explicit training data processing or creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07969",
      "abstract": "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.",
      "authors": [
        "Qiyang Li",
        "Zhiyuan Zhou",
        "Sergey Levine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:48:03+00:00",
          "link": "https://arxiv.org/abs/2507.07969v1",
          "size": "12172kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning with Action Chunking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07969",
        "HTML": "https://arxiv.org/html/2507.07969v1",
        "PDF": "https://arxiv.org/pdf/2507.07969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Q-chunking to improve reinforcement learning algorithms, focusing on using offline data for exploration and sample efficiency, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05793",
      "abstract": "Future vehicles are expected to dynamically deploy in-vehicle applications within a Service-Oriented Architecture (SOA). Critical services operate under hard real-time constraints, which Time-Sensitive Networking (TSN) complements on the in-vehicle Ethernet layer. TSN ensures deterministic communication between critical services and its Credit-Based Shaper (CBS) supports dynamic resource reservations. However, the dynamic nature of service deployment challenges network resource configuration, since any new reservation may change the latency of already validated flows. In addition, standard methods of worst-case latency analysis for CBS have been found incorrect, and current TSN stream reservation procedures lack mechanisms to signal application layer Quality-of-Service (QoS) requirements or verify deadlines. In this paper, we propose a QoS negotiation scheme within the automotive SOA that interacts with the TSN network controller to reserve resources while ensuring latency bounds. We comparatively evaluate reservation schemes using worst-case analysis and simulations of a realistic In-Vehicle Network (IVN) for demonstrating their impact on QoS guarantees, resource utilization, and setup times. We find that only a reservation scheme utilizing per-queue delay budgets and network calculus provides valid configurations and guarantees acceptable latency bounds throughout the IVN. The proposed service negotiation mechanism efficiently establishes 450 vehicular network reservations in just 11 ms.",
      "authors": [
        "Timo Salomon",
        "Lisa Maile",
        "Philipp Meyer",
        "Franz Korf",
        "Thomas C. Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T08:22:32+00:00",
          "link": "https://arxiv.org/abs/2504.05793v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:11:14+00:00",
          "link": "https://arxiv.org/abs/2504.05793v2",
          "size": "385kb",
          "version": "v2"
        }
      ],
      "title": "Negotiating Strict Latency Limits for Dynamic Real-Time Services in Vehicular Time-Sensitive Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05793",
        "PDF": "https://arxiv.org/pdf/2504.05793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on latency limits and networking in vehicular systems, which does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07147",
      "abstract": "Recent advances in pre-trained Vision Language Models (VLM) have shown promising potential for effectively adapting to downstream tasks through prompt learning, without the need for additional annotated paired datasets. To supplement the text information in VLM trained on correlations with vision data, new approaches leveraging Large Language Models (LLM) in prompts have been proposed, enhancing robustness to unseen and diverse data. Existing methods typically extract text-based responses (i.e., descriptions) from LLM to incorporate into prompts; however, this approach suffers from high variability and low reliability. In this work, we propose Description-free Multi-prompt Learning(DeMul), a novel method that eliminates the process of extracting descriptions and instead directly distills knowledge from LLM into prompts. By adopting a description-free approach, prompts can encapsulate richer semantics while still being represented as continuous vectors for optimization, thereby eliminating the need for discrete pre-defined templates. Additionally, in a multi-prompt setting, we empirically demonstrate the potential of prompt weighting in reflecting the importance of different prompts during training. Experimental results show that our approach achieves superior performance across 11 recognition datasets.",
      "authors": [
        "Sua Lee",
        "Kyubum Shin",
        "Jung Ho Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:55:25+00:00",
          "link": "https://arxiv.org/abs/2507.07147v1",
          "size": "2549kb",
          "version": "v1"
        }
      ],
      "title": "Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07147",
        "HTML": "https://arxiv.org/html/2507.07147v1",
        "PDF": "https://arxiv.org/pdf/2507.07147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a method of prompt learning without extracting descriptions from LLMs. It touches on LLM use but focuses primarily on model distillation and prompt optimization, not on data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07418",
      "abstract": "Online advertising is a vital revenue source for major internet platforms. Recently, joint advertising, which assigns a bundle of two advertisers in an ad slot instead of allocating a single advertiser, has emerged as an effective method for enhancing allocation efficiency and revenue. However, existing mechanisms for joint advertising fail to realize the optimality, as they tend to focus on individual advertisers and overlook bundle structures. This paper identifies an optimal mechanism for joint advertising in a single-slot setting. For multi-slot joint advertising, we propose \\textbf{BundleNet}, a novel bundle-based neural network approach specifically designed for joint advertising. Our extensive experiments demonstrate that the mechanisms generated by \\textbf{BundleNet} approximate the theoretical analysis results in the single-slot setting and achieve state-of-the-art performance in the multi-slot setting. This significantly increases platform revenue while ensuring approximate dominant strategy incentive compatibility and individual rationality.",
      "authors": [
        "Yang Li",
        "Yuchao Ma",
        "Qi Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:21:01+00:00",
          "link": "https://arxiv.org/abs/2507.07418v1",
          "size": "2917kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Auction Design in the Joint Advertising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07418",
        "HTML": "https://arxiv.org/html/2507.07418v1",
        "PDF": "https://arxiv.org/pdf/2507.07418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on auction design in advertising, with the proposed BundleNet approach enhancing revenue from ad slots, without any discussions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07505",
      "abstract": "With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.",
      "authors": [
        "Varin Sikka and Vishal Sikka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.07505v1",
          "size": "211kb",
          "version": "v1"
        }
      ],
      "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07505",
        "PDF": "https://arxiv.org/pdf/2507.07505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the limitations of LLMs, specifically hallucinations and task performance complexity, without discussing the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07728",
      "abstract": "Reading channels where $b$-tuples of adjacent symbols are read at every step have e.g.\\ applications in storage. Corresponding bounds and constructions of codes for the $b$-symbol metric, especially the pair-symbol metric where $b=2$, were intensively studied in the last fifteen years. Here we determine the optimal code parameters of linear codes in the $b$-symbol metric assuming that the minimum distance is sufficiently large. We also determine the optimal parameters of linear binary codes in the pair-symbol metric for small dimensions.",
      "authors": [
        "Sascha Kurz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:03:36+00:00",
          "link": "https://arxiv.org/abs/2507.07728v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Linear codes for $b$-symbol read channels attaining the Griesmer bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07728",
        "HTML": "https://arxiv.org/html/2507.07728v1",
        "PDF": "https://arxiv.org/pdf/2507.07728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the construction and optimal parameters of linear codes for storage applications without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.00675",
      "abstract": "We propose, analyze, and investigate numerically a novel feedback control strategy for high Reynolds number flows. For both the continuous and the discrete (finite element) settings, we prove that the new strategy yields accurate results for high Reynolds numbers that were not covered by current results. We also show that the new feedback control yields more accurate results than the current control approaches in marginally-resolved numerical simulations of a two-dimensional flow past a circular cylinder at Reynolds numbers $Re=1000$. We note, however, that for realistic control parameters, the stabilizing effect of the new feedback control strategy is not sufficient in the convection-dominated regime. Our second contribution is the development of an adaptive evolve-filter-relax (aEFR) regularization that stabilizes marginally-resolved simulations in the convection-dominated regime and increases the accuracy of the new feedback control in realistic parameter settings. For the finite element setting, we prove that the novel feedback control equipped with the new aEFR method yields accurate results for high Reynolds numbers. Furthermore, our numerical investigation shows that the new strategy yields accurate results for reduced order models that dramatically decrease the size of the feedback control problem.",
      "authors": [
        "Maria Strazzullo",
        "Francesco Ballarin",
        "Traian Iliescu and Claudio Canuto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-02T22:05:23+00:00",
          "link": "https://arxiv.org/abs/2307.00675v1",
          "size": "10029kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:52:24+00:00",
          "link": "https://arxiv.org/abs/2307.00675v2",
          "size": "11365kb",
          "version": "v2"
        }
      ],
      "title": "New Feedback Control and Adaptive Evolve-Filter-Relax Regularization for the Navier-Stokes Equations in the Convection-Dominated Regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.00675",
        "HTML": "https://arxiv.org/html/2307.00675v2",
        "PDF": "https://arxiv.org/pdf/2307.00675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on feedback control and regularization methods in fluid dynamics, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19598",
      "abstract": "Large Audio-Language Models (LALMs) are increasingly deployed in real-world applications, yet their robustness against malicious audio injection attacks remains underexplored. This study systematically evaluates five leading LALMs across four attack scenarios: Audio Interference Attack, Instruction Following Attack, Context Injection Attack, and Judgment Hijacking Attack. Using metrics like Defense Success Rate, Context Robustness Score, and Judgment Robustness Index, their vulnerabilities and resilience were quantitatively assessed. Experimental results reveal significant performance disparities among models; no single model consistently outperforms others across all attack types. The position of malicious content critically influences attack effectiveness, particularly when placed at the beginning of sequences. A negative correlation between instruction-following capability and robustness suggests models adhering strictly to instructions may be more susceptible, contrasting with greater resistance by safety-aligned models. Additionally, system prompts show mixed effectiveness, indicating the need for tailored strategies. This work introduces a benchmark framework and highlights the importance of integrating robustness into training pipelines. Findings emphasize developing multi-modal defenses and architectural designs that decouple capability from susceptibility for secure LALMs deployment.",
      "authors": [
        "Guanyu Hou",
        "Jiaming He",
        "Yinhang Zhou",
        "Ji Guo",
        "Yitong Qiao",
        "Rui Zhang",
        "Wenbo Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T07:08:38+00:00",
          "link": "https://arxiv.org/abs/2505.19598v1",
          "size": "2892kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:58:00+00:00",
          "link": "https://arxiv.org/abs/2505.19598v2",
          "size": "2892kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19598",
        "HTML": "https://arxiv.org/html/2505.19598v2",
        "PDF": "https://arxiv.org/pdf/2505.19598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines robustness of LALMs against audio injection attacks and suggests integrating robustness in training pipelines but does not primarily focus on LLM training data processing."
      },
      "tasks": [
        "Instruction Following"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07319",
      "abstract": "Recent decision-making systems are increasingly complicated, making it crucial to verify and understand their behavior for a given specification. A promising approach is to comprehensively explain undesired behavior in the systems modeled by Markov decision processes (MDPs) through formal verification and causal reasoning. However, the reliable explanation using model-based probabilistic causal analysis has not been explored when the MDP's transition probabilities are uncertain. This paper proposes a method to identify potential causes of undesired behaviors in an uncertain parametric MDP (upMDP) using parameter sampling, model checking, and a set covering for the samples. A cause is defined as a subset of states based on a probability-raising principle. We show that the probability of each identified subset being a cause exceeds a specified threshold. Further, a lower bound of the probability that the undesired paths visit the subsets is maximized as much as possible while satisfying a nonredundancy condition. While computing these probabilities is complicated, this study derives probabilistically approximately correct lower bounds of both probabilities by the sampling. We demonstrate the effectiveness of the proposed method through a path-planning scenario.",
      "authors": [
        "Ryohei Oura",
        "yuji Ito"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:31:38+00:00",
          "link": "https://arxiv.org/abs/2507.07319v1",
          "size": "4217kb",
          "version": "v1"
        }
      ],
      "title": "Probability-Raising Causality for Uncertain Parametric Markov Decision Processes with PAC Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07319",
        "HTML": "https://arxiv.org/html/2507.07319v1",
        "PDF": "https://arxiv.org/pdf/2507.07319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a probabilistic causal analysis method for Markov decision processes and does not discuss any aspects of LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07871",
      "abstract": "Watermarking offers a promising solution for GenAI providers to establish the provenance of their generated content. A watermark is a hidden signal embedded in the generated content, whose presence can later be verified using a secret watermarking key. A threat to GenAI providers are \\emph{watermark stealing} attacks, where users forge a watermark into content that was \\emph{not} generated by the provider's models without access to the secret key, e.g., to falsely accuse the provider. Stealing attacks collect \\emph{harmless} watermarked samples from the provider's model and aim to maximize the expected success rate of generating \\emph{harmful} watermarked samples. Our work focuses on mitigating stealing attacks while treating the underlying watermark as a black-box. Our contributions are: (i) Proposing a multi-key extension to mitigate stealing attacks that can be applied post-hoc to any watermarking method across any modality. (ii) We provide theoretical guarantees and demonstrate empirically that our method makes forging substantially less effective across multiple datasets, and (iii) we formally define the threat of watermark forging as the task of generating harmful, watermarked content and model this threat via security games.",
      "authors": [
        "Toluwani Aremu",
        "Noor Hussein",
        "Munachiso Nwadike",
        "Samuele Poppi",
        "Jie Zhang",
        "Karthik Nandakumar",
        "Neil Gong",
        "Nils Lukas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:52:32+00:00",
          "link": "https://arxiv.org/abs/2507.07871v1",
          "size": "3404kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07871",
        "HTML": "https://arxiv.org/html/2507.07871v1",
        "PDF": "https://arxiv.org/pdf/2507.07871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on watermark stealing attacks mitigation in generative models and watermarking techniques, without any relation to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19108",
      "abstract": "Instant messaging with texts and stickers has become a widely adopted communication medium, enabling efficient expression of user semantics and emotions. With the increased use of stickers conveying information and feelings, sticker retrieval and recommendation has emerged as an important area of research. However, a major limitation in existing literature has been the lack of datasets capturing temporal and user-specific sticker interactions, which has hindered further progress in user modeling and sticker personalization. To address this, we introduce User-Sticker, a dataset that includes temporal and user anonymous ID across conversations. It is the largest publicly available sticker dataset to date, containing 22K unique users, 370K stickers, and 8.3M messages. The raw data was collected from a popular messaging platform from 67 conversations over 720 hours of crawling. All text and image data were carefully vetted for safety and privacy checks and modifications. Spanning 10 domains, the U-Sticker dataset captures rich temporal, multilingual, and cross-domain behaviors not previously available in other datasets. Extensive quantitative and qualitative experiments demonstrate U-Sticker's practical applications in user behavior modeling and personalized recommendation and highlight its potential to further research areas in personalized retrieval and conversational studies. U-Sticker dataset is publicly available.",
      "authors": [
        "Heng Er Metilda Chee",
        "Jiayin Wang",
        "Zhiqiang Guo",
        "Weizhi Ma",
        "Qinglang Guo",
        "Min Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T12:50:58+00:00",
          "link": "https://arxiv.org/abs/2502.19108v1",
          "size": "14043kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:26:36+00:00",
          "link": "https://arxiv.org/abs/2502.19108v2",
          "size": "4906kb",
          "version": "v2"
        }
      ],
      "title": "U-Sticker: A Large-Scale Multi-Domain User Sticker Dataset for Retrieval and Personalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19108",
        "HTML": "https://arxiv.org/html/2502.19108v2",
        "PDF": "https://arxiv.org/pdf/2502.19108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "U-Sticker involves the creation of a new dataset with detailed data processing, including safety and privacy checks and modifications, which is relevant for training data preparation."
      },
      "datasets": [
        {
          "dataset_name": "metchee/u-sticker",
          "downloads": "3444",
          "likes": "2",
          "link": "https://huggingface.co/datasets/metchee/u-sticker"
        }
      ],
      "tasks": [
        "Recommendation Systems",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07115",
      "abstract": "The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.",
      "authors": [
        "Javal Vyas",
        "Mehmet Mercangoz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:20:22+00:00",
          "link": "https://arxiv.org/abs/2507.07115v1",
          "size": "4179kb",
          "version": "v1"
        }
      ],
      "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07115",
        "HTML": "https://arxiv.org/html/2507.07115v1",
        "PDF": "https://arxiv.org/pdf/2507.07115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs for industrial automation and task planning, focusing on control systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07356",
      "abstract": "Humanoid robots must achieve diverse, robust, and generalizable whole-body control to operate effectively in complex, human-centric environments. However, existing methods, particularly those based on teacher-student frameworks often suffer from a loss of motion diversity during policy distillation and exhibit limited generalization to unseen behaviors. In this work, we present UniTracker, a simplified yet powerful framework that integrates a Conditional Variational Autoencoder (CVAE) into the student policy to explicitly model the latent diversity of human motion. By leveraging a learned CVAE prior, our method enables the student to retain expressive motion characteristics while improving robustness and adaptability under partial observations. The result is a single policy capable of tracking a wide spectrum of whole-body motions with high fidelity and stability. Comprehensive experiments in both simulation and real-world deployments demonstrate that UniTracker significantly outperforms MLP-based DAgger baselines in motion quality, generalization to unseen references, and deployment robustness, offering a practical and scalable solution for expressive humanoid control.",
      "authors": [
        "Kangning Yin",
        "Weishuai Zeng",
        "Ke Fan",
        "Zirui Wang",
        "Qiang Zhang",
        "Zheng Tian",
        "Jingbo Wang",
        "Jiangmiao Pang",
        "Weinan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:42:59+00:00",
          "link": "https://arxiv.org/abs/2507.07356v1",
          "size": "4991kb",
          "version": "v1"
        }
      ],
      "title": "UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07356",
        "HTML": "https://arxiv.org/html/2507.07356v1",
        "PDF": "https://arxiv.org/pdf/2507.07356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses motion tracking for humanoid robots using a CVAE framework but does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07776",
      "abstract": "Unrestricted adversarial attacks aim to fool computer vision models without being constrained by $\\ell_p$-norm bounds to remain imperceptible to humans, for example, by changing an object's color. This allows attackers to circumvent traditional, norm-bounded defense strategies such as adversarial training or certified defense strategies. However, due to their unrestricted nature, there are also no guarantees of norm-based imperceptibility, necessitating human evaluations to verify just how authentic these adversarial examples look. While some related work assesses this vital quality of adversarial attacks, none provide statistically significant insights. This issue necessitates a unified framework that supports and streamlines such an assessment for evaluating and comparing unrestricted attacks. To close this gap, we introduce SCOOTER - an open-source, statistically powered framework for evaluating unrestricted adversarial examples. Our contributions are: $(i)$ best-practice guidelines for crowd-study power, compensation, and Likert equivalence bounds to measure imperceptibility; $(ii)$ the first large-scale human vs. model comparison across 346 human participants showing that three color-space attacks and three diffusion-based attacks fail to produce imperceptible images. Furthermore, we found that GPT-4o can serve as a preliminary test for imperceptibility, but it only consistently detects adversarial examples for four out of six tested attacks; $(iii)$ open-source software tools, including a browser-based task template to collect annotations and analysis scripts in Python and R; $(iv)$ an ImageNet-derived benchmark dataset containing 3K real images, 7K adversarial examples, and over 34K human ratings. Our findings demonstrate that automated vision systems do not align with human perception, reinforcing the need for a ground-truth SCOOTER benchmark.",
      "authors": [
        "Dren Fazlija",
        "Monty-Maximilian Z\\\"uhlke",
        "Johanna Schrader",
        "Arkadij Orlov",
        "Clara Stein",
        "Iyiola E. Olatunji",
        "Daniel Kudenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:56:32+00:00",
          "link": "https://arxiv.org/abs/2507.07776v1",
          "size": "9676kb",
          "version": "v1"
        }
      ],
      "title": "SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial Examples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07776",
        "HTML": "https://arxiv.org/html/2507.07776v1",
        "PDF": "https://arxiv.org/pdf/2507.07776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for assessing adversarial examples in computer vision models and their perceptibility. It does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07938",
      "abstract": "Autonomous vehicles (AVs) are poised to redefine transportation by enhancing road safety, minimizing human error, and optimizing traffic efficiency. The success of AVs depends on their ability to interpret complex, dynamic environments through diverse data sources, including video streams, sensor measurements, and contextual textual information. However, seamlessly integrating these multimodal inputs and ensuring transparency in AI-driven decisions remain formidable challenges. This study introduces a novel multimodal framework that synergistically combines video, sensor, and textual data to predict driving actions while generating human-readable explanations, fostering trust and regulatory compliance. By leveraging VideoMAE for spatiotemporal video analysis, a custom sensor fusion module for real-time data processing, and BERT for textual comprehension, our approach achieves robust decision-making and interpretable outputs. Evaluated on the BDD-X (21113 samples) and nuScenes (1000 scenes) datasets, our model reduces training loss from 5.7231 to 0.0187 over five epochs, attaining an action prediction accuracy of 92.5% and a BLEU-4 score of 0.75 for explanation quality, outperforming state-of-the-art methods. Ablation studies confirm the critical role of each modality, while qualitative analyses and human evaluations highlight the model's ability to produce contextually rich, user-friendly explanations. These advancements underscore the transformative potential of multimodal integration and explainability in building safe, transparent, and trustworthy AV systems, paving the way for broader societal adoption of autonomous driving technologies.",
      "authors": [
        "Abolfazl Zarghani",
        "Amirhossein Ebrahimi",
        "Amir Malekesfandiari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:21:35+00:00",
          "link": "https://arxiv.org/abs/2507.07938v1",
          "size": "600kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Framework for Explainable Autonomous Driving: Integrating Video, Sensor, and Textual Data for Enhanced Decision-Making and Transparency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07938",
        "HTML": "https://arxiv.org/html/2507.07938v1",
        "PDF": "https://arxiv.org/pdf/2507.07938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal framework for autonomous driving, integrating video, sensor, and textual data, but does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20628",
      "abstract": "Recent efforts to develop trustworthy AI systems with accountability guarantees have led to widespread use of machine learning formulations incorporating external requirements, or constraints. These requirements are often enforced via penalization--adding fixed-weight terms to the task loss. We argue this approach is fundamentally ill-suited since there may be no penalty coefficient that simultaneously ensures constraint satisfaction and optimal constrained performance, i.e., that truly solves the constrained problem. Moreover, tuning these coefficients requires costly trial-and-error, incurring significant time and computational overhead. We, therefore, advocate for broader adoption of tailored constrained optimization methods--such as the Lagrangian approach, which jointly optimizes the penalization \"coefficients\" (the Lagrange multipliers) and the model parameters. Such methods (i) truly solve the constrained problem and do so accountably, by clearly defining feasibility and verifying when it is achieved, (ii) eliminate the need for extensive penalty tuning, and (iii) integrate seamlessly with modern deep learning pipelines.",
      "authors": [
        "Juan Ramirez",
        "Meraj Hashemizadeh",
        "Simon Lacoste-Julien"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T02:09:17+00:00",
          "link": "https://arxiv.org/abs/2505.20628v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:47:30+00:00",
          "link": "https://arxiv.org/abs/2505.20628v2",
          "size": "399kb",
          "version": "v2"
        }
      ],
      "title": "Position: Adopt Constraints Over Penalties in Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20628",
        "PDF": "https://arxiv.org/pdf/2505.20628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper advocates for constraint-based optimization methods in deep learning rather than focusing on LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Position"
      ],
      "repo_urls": [
        "https://github.com/merajhashemi/constraints-vs-penalties"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07141",
      "abstract": "Graph Contrastive Learning (GCL) is a widely adopted approach in self-supervised graph representation learning, applying contrastive objectives to produce effective representations. However, current GCL methods primarily focus on capturing implicit semantic relationships, often overlooking the structural commonsense embedded within the graph's structure and attributes, which contains underlying knowledge crucial for effective representation learning. Due to the lack of explicit information and clear guidance in general graph, identifying and integrating such structural commonsense in GCL poses a significant challenge. To address this gap, we propose a novel framework called Structural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL). Str-GCL leverages first-order logic rules to represent structural commonsense and explicitly integrates them into the GCL framework. It introduces topological and attribute-based rules without altering the original graph and employs a representation alignment mechanism to guide the encoder in effectively capturing this commonsense. To the best of our knowledge, this is the first attempt to directly incorporate structural commonsense into GCL. Extensive experiments demonstrate that Str-GCL outperforms existing GCL methods, providing a new perspective on leveraging structural commonsense in graph representation learning.",
      "authors": [
        "Dongxiao He",
        "Yongqi Huang",
        "Jitao Zhao",
        "Xiaobao Wang",
        "Zhen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:41:48+00:00",
          "link": "https://arxiv.org/abs/2507.07141v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "Str-GCL: Structural Commonsense Driven Graph Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07141",
        "HTML": "https://arxiv.org/html/2507.07141v1",
        "PDF": "https://arxiv.org/pdf/2507.07141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for graph contrastive learning, which does not involve processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07887",
      "abstract": "Molecular dynamics simulations are an essential tool in understanding protein structure, dynamics, and function at the atomic level. However, preparing high quality input files for MD simulations can be a time consuming and error prone process. In this work, we introduce an automated pipeline that leverages Large Language Models (LLMs), specifically Gemini 2.0 Flash, in conjunction with python scripting and Selenium based web automation to streamline the generation of MD input files. The pipeline exploits CHARMM GUI's comprehensive web-based interface for preparing simulation-ready inputs for NAMD. By integrating Gemini's code generation and iterative refinement capabilities, simulation scripts are automatically written, executed, and revised to navigate CHARMM GUI, extract appropriate parameters, and produce the required NAMD input files. Post processing is performed using additional software to further refine the simulation outputs, thereby enabling a complete and largely hands free workflow. Our results demonstrate that this approach reduces setup time, minimizes manual errors, and offers a scalable solution for handling multiple protein systems in parallel. This automated framework paves the way for broader application of LLMs in computational structural biology, offering a robust and adaptable platform for future developments in simulation automation.",
      "authors": [
        "Achuth Chandrasekhar",
        "Amir Barati Farimani"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:17:40+00:00",
          "link": "https://arxiv.org/abs/2507.07887v1",
          "size": "29506kb",
          "version": "v1"
        }
      ],
      "title": "Automating MD simulations for Proteins using Large language Models: NAMD-Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07887",
        "HTML": "https://arxiv.org/html/2507.07887v1",
        "PDF": "https://arxiv.org/pdf/2507.07887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes automating MD simulations using LLMs, focusing on generating input files through an automated pipeline. It leverages LLMs but does not primarily address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07518",
      "abstract": "Turn-taking is a fundamental component of spoken dialogue, however conventional studies mostly involve dyadic settings. This work focuses on applying voice activity projection (VAP) to predict upcoming turn-taking in triadic multi-party scenarios. The goal of VAP models is to predict the future voice activity for each speaker utilizing only acoustic data. This is the first study to extend VAP into triadic conversation. We trained multiple models on a Japanese triadic dataset where participants discussed a variety of topics. We found that the VAP trained on triadic conversation outperformed the baseline for all models but that the type of conversation affected the accuracy. This study establishes that VAP can be used for turn-taking in triadic dialogue scenarios. Future work will incorporate this triadic VAP turn-taking model into spoken dialogue systems.",
      "authors": [
        "Mikey Elmers",
        "Koji Inoue",
        "Divesh Lala",
        "Tatsuya Kawahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:06:52+00:00",
          "link": "https://arxiv.org/abs/2507.07518v1",
          "size": "3949kb",
          "version": "v1"
        }
      ],
      "title": "Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07518",
        "HTML": "https://arxiv.org/html/2507.07518v1",
        "PDF": "https://arxiv.org/pdf/2507.07518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with voice activity projection for turn-taking in spoken dialogue systems and is not related to processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07559",
      "abstract": "Anomaly detection (AD) plays a vital role across a wide range of real-world domains by identifying data instances that deviate from expected patterns, potentially signaling critical events such as system failures, fraudulent activities, or rare medical conditions. The demand for real-time AD has surged with the rise of the (Industrial) Internet of Things, where massive volumes of multivariate sensor data must be processed instantaneously. Real-time AD requires methods that not only handle high-dimensional streaming data but also operate in a single-pass manner, without the burden of storing historical instances, thereby ensuring minimal memory usage and fast decision-making. We propose DAD, a novel real-time decorrelation-based anomaly detection method for multivariate time series, based on an online decorrelation learning approach. Unlike traditional proximity-based or reconstruction-based detectors that process entire data or windowed instances, DAD dynamically learns and monitors the correlation structure of data sample by sample in a single pass, enabling efficient and effective detection. To support more realistic benchmarking practices, we also introduce a practical hyperparameter tuning strategy tailored for real-time anomaly detection scenarios. Extensive experiments on widely used benchmark datasets demonstrate that DAD achieves the most consistent and superior performance across diverse anomaly types compared to state-of-the-art methods. Crucially, its robustness to increasing dimensionality makes it particularly well-suited for real-time, high-dimensional data streams. Ultimately, DAD not only strikes an optimal balance between detection efficacy and computational efficiency but also sets a new standard for real-time, memory-constrained anomaly detection.",
      "authors": [
        "Amirhossein Sadough",
        "Mahyar Shahsavari",
        "Mark Wijtvliet",
        "Marcel van Gerven"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:56:40+00:00",
          "link": "https://arxiv.org/abs/2507.07559v1",
          "size": "13047kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07559",
        "PDF": "https://arxiv.org/pdf/2507.07559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a real-time anomaly detection method for multivariate time series, emphasizing algorithmic approaches rather than LLM training data engineering or dataset processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07677",
      "abstract": "This paper experimentally analyzes the negative impact of contention caused by neighboring Wi-Fi networks operating on overlapping channels on Virtual Reality (VR) streaming over Wi-Fi, focusing on scenarios of partial and full channel overlap within an 80 MHz channel. Our results show that (i) increasing the number of 80 MHz Overlapping Basic Service Sets (OBSSs) intensifies contention and degrades VR streaming performance; (ii) OBSS activity on the secondary-sided 40 MHz portion degrades performance more than activity on the primary-sided 40 MHz portion; (iii) for the same aggregate load, full channel overlap with two 40 MHz OBSS contenders is less detrimental than partial overlap with a single high-load 40 MHz contender, but more disruptive than full overlap with two 80 MHz contenders; and (iv) full channel overlap with two 40 MHz OBSS contenders has a smaller impact on VR streaming under symmetric traffic loads than under asymmetric loads. Moreover, our results demonstrate that our previously proposed Network-aware Step-wise adaptive bitrate algorithm for VR streaming (NeSt-VR) effectively mitigates performance degradation in OBSS environments, enabling VR streaming under heavier OBSS traffic conditions.",
      "authors": [
        "Miguel Casasnovas",
        "Marc Carrascosa-Zamacois",
        "Boris Bellalta"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:59:10+00:00",
          "link": "https://arxiv.org/abs/2507.07677v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Can cloud-based VR streaming handle Wi-Fi OBSS contention?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07677",
        "HTML": "https://arxiv.org/html/2507.07677v1",
        "PDF": "https://arxiv.org/pdf/2507.07677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes the impact of Wi-Fi contention on VR streaming performance and proposes a bitrate algorithm for VR. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07803",
      "abstract": "Streaming speech translation (StreamST) requires determining appropriate timing, known as policy, to generate translations while continuously receiving source speech inputs, balancing low latency with high translation quality. However, existing StreamST methods typically operate on sentence-level speech segments, referred to as simultaneous speech translation (SimulST). In practice, they require collaboration with segmentation models to accomplish StreamST, where the truncated speech segments constrain SimulST models to make policy decisions and generate translations based on limited contextual information. Moreover, SimulST models struggle to learn effective policies due to the complexity of speech inputs and cross-lingual generation. To address these challenges, we propose StreamUni, which achieves StreamST through a unified Large Speech-Language Model (LSLM). Specifically, StreamUni incorporates speech Chain-of-Thought (CoT) in guiding the LSLM to generate multi-stage outputs. Leveraging these multi-stage outputs, StreamUni simultaneously accomplishes speech segmentation, policy decision, and translation generation, completing StreamST without requiring massive policy-specific training. Additionally, we propose a streaming CoT training method that enhances low-latency policy decisions and generation capabilities using limited CoT data. Experiments demonstrate that our approach achieves state-of-the-art performance on StreamST tasks.",
      "authors": [
        "Shoutao Guo",
        "Xiang Li",
        "Shaolei Zhang",
        "Mengge Liu",
        "Wei Chen",
        "Yang Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:28:39+00:00",
          "link": "https://arxiv.org/abs/2507.07803v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07803",
        "HTML": "https://arxiv.org/html/2507.07803v1",
        "PDF": "https://arxiv.org/pdf/2507.07803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes StreamUni for streaming speech translation using a large speech-language model. It touches on speech segmentation and policy decision but does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.07260",
      "abstract": "Temporal networks allow representing connections between objects while incorporating the temporal dimension. While static network models can capture unchanging topological regularities, they often fail to model the effects associated with the causal generative process of the network that occurs in time. Hence, exploiting the temporal aspect of networks has been the focus of many recent studies. In this context, we propose a new framework for generative models of continuous-time temporal networks. We assume that the activation of the edges in a temporal network is driven by a specified temporal point process. This approach allows to directly model the waiting time between events while incorporating time-varying history-based features as covariates in the predictions. Coupled with a thinning algorithm designed for the simulation of point processes, SimHawNet enables simulation of the evolution of temporal networks in continuous time. Finally, we introduce a comprehensive evaluation framework to assess the performance of such an approach, in which we demonstrate that SimHawNet successfully simulates the evolution of networks with very different generative processes and achieves performance comparable to the state of the art, while being significantly faster.",
      "authors": [
        "Mathilde Perez",
        "Rapha\\\"el Romero",
        "Bo Kang",
        "Tijl De Bie",
        "Jefrey Lijffijt",
        "Charlotte Laclau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-14T16:40:57+00:00",
          "link": "https://arxiv.org/abs/2203.07260v1",
          "size": "636kb",
          "version": "v1"
        },
        {
          "date": "2022-03-15T13:05:13+00:00",
          "link": "https://arxiv.org/abs/2203.07260v2",
          "size": "636kb",
          "version": "v2"
        },
        {
          "date": "2025-01-16T13:40:01+00:00",
          "link": "https://arxiv.org/abs/2203.07260v3",
          "size": "11320kb",
          "version": "v3"
        }
      ],
      "title": "SimHawNet: A Modified Hawkes Process for Temporal Network Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.07260",
        "HTML": "https://arxiv.org/html/2203.07260",
        "PDF": "https://arxiv.org/pdf/2203.07260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a generative model for temporal network simulation, which is not related to LLM training data processing or engineering."
      },
      "tasks": [
        "BIG-bench Machine Learning",
        "Link Prediction",
        "Point Processes",
        "Survival Analysis"
      ],
      "repo_urls": [
        "https://github.com/mathoup31/simhawnet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.00151",
      "abstract": "Document Visual Question Answering (VQA) demands robust integration of text detection, recognition, and spatial reasoning to interpret complex document layouts. In this work, we introduce DLaVA, a novel, training-free pipeline that leverages Multimodal Large Language Models (MLLMs) for zero-shot answer localization in order to improve trustworthiness, interpretability, and explainability. By leveraging an innovative OCR-free approach that organizes text regions with unique bounding box IDs, the proposed method preserves spatial contexts without relying on iterative OCR or chain-of-thought reasoning, thus substantially reducing the computational complexity. We further enhance the evaluation protocol by integrating Intersection over Union (IoU) metrics alongside Average Normalized Levenshtein Similarity (ANLS), thereby ensuring that not only textual accuracy is considered, but spatial accuracy is taken into account, ultimately reducing the risks of AI hallucinations and improving trustworthiness. Experiments on benchmark datasets demonstrate competitive performance compared to state-of-the-art techniques, with significantly lower computational complexity and enhanced accuracies and reliability for high-stakes applications. The code and datasets utilized in this study for DLaVA are accessible at: https://github.com/ahmad-shirazi/AnnotMLLM.",
      "authors": [
        "Ahmad Mohammadshirazi",
        "Pinaki Prasad Guha Neogi",
        "Ser-Nam Lim",
        "and Rajiv Ramnath"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T06:17:11+00:00",
          "link": "https://arxiv.org/abs/2412.00151v1",
          "size": "15112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:48:27+00:00",
          "link": "https://arxiv.org/abs/2412.00151v2",
          "size": "10029kb",
          "version": "v2"
        }
      ],
      "title": "DLaVA: Document Language and Vision Assistant for Answer Localization with Enhanced Interpretability and Trustworthiness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00151",
        "PDF": "https://arxiv.org/pdf/2412.00151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper introduces DLaVA, a training-free pipeline leveraging multimodal large language models, it does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04485",
      "abstract": "We study deterministic mechanisms for the two-facility location problem. Given the reported locations of n agents on the real line, such a mechanism specifies where to build the two facilities. The single-facility variant of this problem admits a simple strategyproof mechanism that minimizes social cost. For two facilities, however, it is known that any strategyproof mechanism is $\\Omega(n)$-approximate. We seek to circumvent this strong lower bound by relaxing the problem requirements. Following other work in the facility location literature, we consider a relaxed form of strategyproofness in which no agent can lie and improve their outcome by more than a constant factor. Because the aforementioned $\\Omega(n)$ lower bound generalizes easily to constant-strategyproof mechanisms, we introduce a second relaxation: Allowing the facilities (but not the agents) to be located in the plane. Our first main result is a natural mechanism for this relaxation that is constant-approximate and constant-strategyproof. A characteristic of this mechanism is that a small change in the input profile can produce a large change in the solution. Motivated by this observation, and also by results in the facility reallocation literature, our second main result is a constant-approximate, constant-strategyproof, and Lipschitz continuous mechanism.",
      "authors": [
        "Elijah Journey Fullerton",
        "Zeyuan Hu",
        "and C. Gregory Plaxton"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T17:51:52+00:00",
          "link": "https://arxiv.org/abs/2507.04485v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T21:51:58+00:00",
          "link": "https://arxiv.org/abs/2507.04485v2",
          "size": "60kb",
          "version": "v2"
        }
      ],
      "title": "Constant-Approximate and Constant-Strategyproof Two-Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04485",
        "HTML": "https://arxiv.org/html/2507.04485v2",
        "PDF": "https://arxiv.org/pdf/2507.04485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses mechanisms for two-facility location problems, examining strategyproofness and approximation. It does not relate to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07236",
      "abstract": "Large language models (LLMs) often behave inconsistently across inputs, indicating uncertainty and motivating the need for its quantification in high-stakes settings. Prior work on calibration and uncertainty quantification often focuses on individual models, overlooking the potential of model diversity. We hypothesize that LLMs make complementary predictions due to differences in training and the Zipfian nature of language, and that aggregating their outputs leads to more reliable uncertainty estimates. To leverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a simple information-theoretic method that uses Jensen-Shannon Divergence to identify and aggregate well-calibrated subsets of LLMs. Experiments on binary prediction tasks demonstrate improved calibration and predictive performance compared to single-model and naive ensemble baselines.",
      "authors": [
        "Maya Kruse",
        "Majid Afshar",
        "Saksham Khatwani",
        "Anoop Mayampurath",
        "Guanhua Chen",
        "Yanjun Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:13:25+00:00",
          "link": "https://arxiv.org/abs/2507.07236v1",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "title": "An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07236",
        "HTML": "https://arxiv.org/html/2507.07236v1",
        "PDF": "https://arxiv.org/pdf/2507.07236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method to improve uncertainty estimation by leveraging model diversity but primarily focuses on the calibration and predictions, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07146",
      "abstract": "Large Language Models (LLMs) have gained widespread popularity and are increasingly integrated into various applications. However, their capabilities can be exploited for both benign and harmful purposes. Despite rigorous training and fine-tuning for safety, LLMs remain vulnerable to jailbreak attacks. Recently, multi-turn attacks have emerged, exacerbating the issue. Unlike single-turn attacks, multi-turn attacks gradually escalate the dialogue, making them more difficult to detect and mitigate, even after they are identified.\n  In this study, we propose G-Guard, an innovative attention-aware GNN-based input classifier designed to defend against multi-turn jailbreak attacks on LLMs. G-Guard constructs an entity graph for multi-turn queries, explicitly capturing relationships between harmful keywords and queries even when those keywords appear only in previous queries. Additionally, we introduce an attention-aware augmentation mechanism that retrieves the most similar single-turn query based on the multi-turn conversation. This retrieved query is treated as a labeled node in the graph, enhancing the ability of GNN to classify whether the current query is harmful. Evaluation results demonstrate that G-Guard outperforms all baselines across all datasets and evaluation metrics.",
      "authors": [
        "Zixuan Huang",
        "Kecheng Huang",
        "Lihao Yin",
        "Bowei He",
        "Huiling Zhen",
        "Mingxuan Yuan",
        "Zili Shao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:55:03+00:00",
          "link": "https://arxiv.org/abs/2507.07146v1",
          "size": "864kb",
          "version": "v1"
        }
      ],
      "title": "An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07146",
        "HTML": "https://arxiv.org/html/2507.07146v1",
        "PDF": "https://arxiv.org/pdf/2507.07146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a defense mechanism against jailbreak attacks on LLMs. It does not discuss any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07315",
      "abstract": "Emergence and swarms are widely discussed topics, yet no consensus exists on their formal definitions. This lack of agreement makes it difficult not only for new researchers to grasp these concepts, but also for experts who may use the same terms to mean different things. Many attempts have been made to objectively define 'swarm' or 'emergence,' with recent work highlighting the role of the external observer. Still, several researchers argue that once an observer's vantage point (e.g., scope, resolution, context) is established, the terms can be made objective or measured quantitatively. In this note, we propose a framework to discuss these ideas rigorously by separating externally observable states from latent, unobservable ones. This allows us to compare and contrast existing definitions of swarms and emergence on common ground. We argue that these concepts are ultimately subjective-shaped less by the system itself than by the perception and tacit knowledge of the observer. Specifically, we suggest that a 'swarm' is not defined by its group behavior alone, but by the process generating that behavior. Our broader goal is to support the design and deployment of robotic swarm systems, highlighting the critical distinction between multi-robot systems and true swarms.",
      "authors": [
        "Ricardo Vega and Cameron Nowzari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:25:35+00:00",
          "link": "https://arxiv.org/abs/2507.07315v1",
          "size": "3876kb",
          "version": "v1"
        }
      ],
      "title": "Classifying Emergence in Robot Swarms: An Observer-Dependent Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07315",
        "HTML": "https://arxiv.org/html/2507.07315v1",
        "PDF": "https://arxiv.org/pdf/2507.07315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses concepts of emergence and swarms, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07734",
      "abstract": "Recognizing human activities early is crucial for the safety and responsiveness of human-robot and human-machine interfaces. Due to their high temporal resolution and low latency, event-based vision sensors are a perfect match for this early recognition demand. However, most existing processing approaches accumulate events to low-rate frames or space-time voxels which limits the early prediction capabilities. In contrast, spiking neural networks (SNNs) can process the events at a high-rate for early predictions, but most works still fall short on final accuracy. In this work, we introduce a high-rate two-stream SNN which closes this gap by outperforming previous work by 2% in final accuracy on the large-scale THU EACT-50 dataset. We benchmark the SNNs within a novel early event-based recognition framework by reporting Top-1 and Top-5 recognition scores for growing observation time. Finally, we exemplify the impact of these methods on a real-world task of early action triggering for human motion capture in sports.",
      "authors": [
        "Michael Neumeier and Jules Lecomte and Nils Kazinski and Soubarna Banik and Bing Li and Axel von Arnim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:13:53+00:00",
          "link": "https://arxiv.org/abs/2507.07734v1",
          "size": "1766kb",
          "version": "v1"
        }
      ],
      "title": "EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07734",
        "HTML": "https://arxiv.org/html/2507.07734v1",
        "PDF": "https://arxiv.org/pdf/2507.07734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of spiking neural networks for human action recognition using event-based sensors, with no mention of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.05798",
      "abstract": "The vertebrate hippocampus is believed to use recurrent connectivity in area CA3 to support episodic memory recall from partial cues. This brain area also contains place cells, whose location-selective firing fields implement maps supporting spatial memory. Here we show that place cells emerge in networks trained to remember temporally continuous sensory episodes. We model CA3 as a recurrent autoencoder that recalls and reconstructs sensory experiences from noisy and partially occluded observations by agents traversing simulated rooms. The agents move in realistic trajectories modeled from rodents and environments are modeled as high-dimensional sensory experience maps. Training our autoencoder to pattern-complete and reconstruct experiences with a constraint on total activity causes spatially localized firing fields, i.e., place cells, to emerge in the encoding layer. The emergent place fields reproduce key aspects of hippocampal phenomenology: a) remapping (maintenance of and reversion to distinct learned maps in different environments), implemented via repositioning of experience manifolds in the network's hidden layer, b) orthogonality of spatial representations in different arenas, c) robust place field emergence in differently shaped rooms, with single units showing multiple place fields in large or complex spaces, and d) slow representational drift of place fields. We argue that these results arise because continuous traversal of space makes sensory experience temporally continuous. We make testable predictions: a) rapidly changing sensory context will disrupt place fields, b) place fields will form even if recurrent connections are blocked, but reversion to previously learned representations upon remapping will be abolished, c) the dimension of temporally smooth experience sets the dimensionality of place fields, including during virtual navigation of abstract spaces.",
      "authors": [
        "Zhaoze Wang",
        "Ronald W. Di Tullio",
        "Spencer Rooke",
        "Vijay Balasubramanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-11T15:17:11+00:00",
          "link": "https://arxiv.org/abs/2408.05798v1",
          "size": "15197kb",
          "version": "v1"
        },
        {
          "date": "2025-01-29T22:01:37+00:00",
          "link": "https://arxiv.org/abs/2408.05798v2",
          "size": "15206kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:03:11+00:00",
          "link": "https://arxiv.org/abs/2408.05798v3",
          "size": "15249kb",
          "version": "v3"
        }
      ],
      "title": "Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05798",
        "HTML": "https://arxiv.org/html/2408.05798v3",
        "PDF": "https://arxiv.org/pdf/2408.05798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on modeling neural networks to understand hippocampal phenomenology, specifically place cells, rather than on processing or creating training data for LLMs."
      },
      "tasks": [
        "Hippocampus"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.11984",
      "abstract": "Large Language Models (LLMs) have shown impressive performance in complex reasoning tasks through the use of Chain-of-Thought (CoT) reasoning, allowing models to break down problems into manageable sub-tasks. However, existing CoT evaluation techniques either require annotated CoT data or fall short in accurately assessing intermediate reasoning steps, leading to high rates of false positives. In this paper, we formalize CoT reasoning in LLMs through an information-theoretic lens. Specifically, our framework quantifies the `information-gain' at each reasoning step, enabling the identification of failure modes in LLMs without the need for expensive annotated datasets. We demonstrate the efficacy of our approach through extensive experiments on toy arithmetic, GSM8K and PRM800k datasets, where it significantly outperforms existing outcome-based methods by providing more accurate insights into model performance on individual subtasks.",
      "authors": [
        "Jean-Francois Ton",
        "Muhammad Faaiz Taufiq",
        "Yang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T19:14:36+00:00",
          "link": "https://arxiv.org/abs/2411.11984v1",
          "size": "658kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:18:01+00:00",
          "link": "https://arxiv.org/abs/2411.11984v2",
          "size": "661kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Chain-of-Thought in LLMs through Information Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11984",
        "HTML": "https://arxiv.org/html/2411.11984v2",
        "PDF": "https://arxiv.org/pdf/2411.11984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper formalizes CoT reasoning via an information-theoretic lens but does not focus on the creation or processing of training data for LLMs."
      },
      "tasks": [
        "8k"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08482",
      "abstract": "We explore a hybrid technique to quantify the variability in the numerical solutions to a free boundary problem associated with magnetic equilibrium in axisymmetric fusion reactors amidst parameter uncertainties. The method aims at reducing computational costs by integrating a surrogate model into a multilevel Monte Carlo method. The resulting surrogate-enhanced multilevel Monte Carlo methods reduce the cost of simulation by factors as large as $10^4$ compared to standard Monte Carlo simulations involving direct numerical solutions of the associated Grad-Shafranov partial differential equation. Accuracy assessments also show that surrogate-based sampling closely aligns with the results of direct computation, confirming its effectiveness in capturing the behavior of plasma boundary and geometric descriptors.",
      "authors": [
        "Howard Elman and Jiaxing Liang and Tonatiuh S\\'anchez-Vizuet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Plasma Physics (physics.plasm-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T23:09:36+00:00",
          "link": "https://arxiv.org/abs/2501.08482v1",
          "size": "14617kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T21:03:21+00:00",
          "link": "https://arxiv.org/abs/2501.08482v2",
          "size": "4668kb",
          "version": "v2"
        }
      ],
      "title": "Surrogate-based multilevel Monte Carlo methods for uncertainty quantification in the Grad-Shafranov free boundary problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08482",
        "HTML": "https://arxiv.org/html/2501.08482v2",
        "PDF": "https://arxiv.org/pdf/2501.08482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with uncertainty quantification in simulation methods and does not mention LLMs or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05592",
      "abstract": "In recent years, the evolution of modern power grids has been driven by the growing integration of remotely controlled grid assets. Although Distributed Energy Resources (DERs) and Inverter-Based Resources (IBRs) enhance operational efficiency, they also introduce cybersecurity risks. The remote accessibility of such critical grid components creates entry points for attacks that adversaries could exploit, posing threats to the stability of the system. To evaluate the resilience of energy systems under such threats, this study employs real-time simulation and a modified version of the IEEE 39-bus system that incorporates a Microgrid (MG) with solar-based IBR. The study assesses the impact of remote attacks impacting the MG stability under different levels of IBR penetration through hardware-in-the-loop (HIL) simulations. Namely, we analyze voltage, current, and frequency profiles before, during, and after cyberattack-induced disruptions. The results demonstrate that real-time HIL testing is a practical approach to uncover potential risks and develop robust mitigation strategies for resilient MG operations.",
      "authors": [
        "Kerd Topallaj",
        "Colin McKerrell",
        "Suraj Ramanathan",
        "Ioannis Zografopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T00:59:33+00:00",
          "link": "https://arxiv.org/abs/2504.05592v1",
          "size": "4678kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:56:23+00:00",
          "link": "https://arxiv.org/abs/2504.05592v2",
          "size": "3439kb",
          "version": "v2"
        }
      ],
      "title": "Impact Assessment of Cyberattacks in Inverter-Based Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05592",
        "HTML": "https://arxiv.org/html/2504.05592v2",
        "PDF": "https://arxiv.org/pdf/2504.05592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses cybersecurity in power systems and does not relate to the processing or creation of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07589",
      "abstract": "Healthcare professionals, particularly nurses, face elevated occupational stress, a concern amplified during the COVID-19 pandemic. While wearable sensors offer promising avenues for real-time stress monitoring, existing studies often lack comprehensive datasets and robust analytical frameworks. This study addresses these gaps by introducing a multimodal dataset comprising physiological signals, electrodermal activity, heart rate and skin temperature. A systematic literature review identified limitations in prior stress-detection methodologies, particularly in handling class imbalance and optimizing model generalizability. To overcome these challenges, the dataset underwent preprocessing with the Synthetic Minority Over sampling Technique (SMOTE), ensuring balanced representation of stress states. Advanced machine learning models including Random Forest, XGBoost and a Multi-Layer Perceptron (MLP) were evaluated and combined into a Stacking Classifier to leverage their collective predictive strengths. By using a publicly accessible dataset and a reproducible analytical pipeline, this work advances the development of deployable stress-monitoring systems, offering practical implications for safeguarding healthcare workers' mental health. Future research directions include expanding demographic diversity and exploring edge-computing implementations for low latency stress alerts.",
      "authors": [
        "Arpana Sinhal",
        "Anay Sinhal and Amit Sinhal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:47:56+00:00",
          "link": "https://arxiv.org/abs/2507.07589v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "Stress Monitoring in Healthcare: An Ensemble Machine Learning Framework Using Wearable Sensor Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07589",
        "PDF": "https://arxiv.org/pdf/2507.07589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although it involves preprocessing sensor data through techniques like SMOTE, the focus remains on stress monitoring systems using wearable data, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07839",
      "abstract": "Accurate prediction of recurrence in clear cell renal cell carcinoma (ccRCC) remains a major clinical challenge due to the disease complex molecular, pathological, and clinical heterogeneity. Traditional prognostic models, which rely on single data modalities such as radiology, histopathology, or genomics, often fail to capture the full spectrum of disease complexity, resulting in suboptimal predictive accuracy. This study aims to overcome these limitations by proposing a deep learning (DL) framework that integrates multimodal data, including CT, MRI, histopathology whole slide images (WSI), clinical data, and genomic profiles, to improve the prediction of ccRCC recurrence and enhance clinical decision-making. The proposed framework utilizes a comprehensive dataset curated from multiple publicly available sources, including TCGA, TCIA, and CPTAC. To process the diverse modalities, domain-specific models are employed: CLAM, a ResNet50-based model, is used for histopathology WSIs, while MeD-3D, a pre-trained 3D-ResNet18 model, processes CT and MRI images. For structured clinical and genomic data, a multi-layer perceptron (MLP) is used. These models are designed to extract deep feature embeddings from each modality, which are then fused through an early and late integration architecture. This fusion strategy enables the model to combine complementary information from multiple sources. Additionally, the framework is designed to handle incomplete data, a common challenge in clinical settings, by enabling inference even when certain modalities are missing.",
      "authors": [
        "Hasaan Maqsood",
        "Saif Ur Rehman Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:11:09+00:00",
          "link": "https://arxiv.org/abs/2507.07839v1",
          "size": "26726kb",
          "version": "v1"
        }
      ],
      "title": "MeD-3D: A Multimodal Deep Learning Framework for Precise Recurrence Prediction in Clear Cell Renal Cell Carcinoma (ccRCC)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07839",
        "HTML": "https://arxiv.org/html/2507.07839v1",
        "PDF": "https://arxiv.org/pdf/2507.07839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal deep learning framework for recurrence prediction in renal cell carcinoma using diverse data types but does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.10427",
      "abstract": "We propose Adaptive Randomized Smoothing (ARS) to certify the predictions of our test-time adaptive models against adversarial examples. ARS extends the analysis of randomized smoothing using $f$-Differential Privacy to certify the adaptive composition of multiple steps. For the first time, our theory covers the sound adaptive composition of general and high-dimensional functions of noisy inputs. We instantiate ARS on deep image classification to certify predictions against adversarial examples of bounded $L_{\\infty}$ norm. In the $L_{\\infty}$ threat model, ARS enables flexible adaptation through high-dimensional input-dependent masking. We design adaptivity benchmarks, based on CIFAR-10 and CelebA, and show that ARS improves standard test accuracy by $1$ to $15\\%$ points. On ImageNet, ARS improves certified test accuracy by up to $1.6\\%$ points over standard RS without adaptivity. Our code is available at https://github.com/ubc-systopia/adaptive-randomized-smoothing .",
      "authors": [
        "Saiyue Lyu",
        "Shadab Shaikh",
        "Frederick Shpilevskiy",
        "Evan Shelhamer",
        "Mathias L\\'ecuyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-14T22:11:02+00:00",
          "link": "https://arxiv.org/abs/2406.10427v1",
          "size": "8936kb",
          "version": "v1"
        },
        {
          "date": "2024-10-30T00:14:07+00:00",
          "link": "https://arxiv.org/abs/2406.10427v2",
          "size": "11044kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:08:38+00:00",
          "link": "https://arxiv.org/abs/2406.10427v3",
          "size": "9387kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10427",
        "HTML": "https://arxiv.org/html/2406.10427v3",
        "PDF": "https://arxiv.org/pdf/2406.10427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial robustness through adaptive randomized smoothing, with no detailed processing of LLM training data."
      },
      "tasks": [
        "Adversarial Robustness",
        "image-classification",
        "Image Classification"
      ],
      "repo_urls": [
        "https://github.com/ubc-systopia/adaptive-randomized-smoothing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08938",
      "abstract": "DNA-Encoded Libraries (DELs) represent a transformative technology in drug discovery, facilitating the high-throughput exploration of vast chemical spaces. Despite their potential, the scarcity of publicly available DEL datasets presents a bottleneck for the advancement of machine learning methodologies in this domain. To address this gap, we introduce KinDEL, one of the largest publicly accessible DEL datasets and the first one that includes binding poses from molecular docking experiments. Focused on two kinases, Mitogen-Activated Protein Kinase 14 (MAPK14) and Discoidin Domain Receptor Tyrosine Kinase 1 (DDR1), KinDEL includes 81 million compounds, offering a rich resource for computational exploration. Additionally, we provide comprehensive biophysical assay validation data, encompassing both on-DNA and off-DNA measurements, which we use to evaluate a suite of machine learning techniques, including novel structure-based probabilistic models. We hope that our benchmark, encompassing both 2D and 3D structures, will help advance the development of machine learning models for data-driven hit identification using DELs.",
      "authors": [
        "Benson Chen",
        "Tomasz Danel",
        "Gabriel H. S. Dreiman",
        "Patrick J. McEnaney",
        "Nikhil Jain",
        "Kirill Novikov",
        "Spurti Umesh Akki",
        "Joshua L. Turnbull",
        "Virja Atul Pandya",
        "Boris P. Belotserkovskii",
        "Jared Bryce Weaver",
        "Ankita Biswas",
        "Dat Nguyen",
        "Kent Gorday",
        "Mohammad Sultan",
        "Nathaniel Stanley",
        "Daniel M Whalen",
        "Divya Kanichar",
        "Christoph Klein",
        "Emily Fox",
        "R. Edward Watts"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T16:03:58+00:00",
          "link": "https://arxiv.org/abs/2410.08938v1",
          "size": "2938kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:55:06+00:00",
          "link": "https://arxiv.org/abs/2410.08938v2",
          "size": "7426kb",
          "version": "v2"
        }
      ],
      "title": "KinDEL: DNA-Encoded Library Dataset for Kinase Inhibitors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08938",
        "HTML": "https://arxiv.org/html/2410.08938v2",
        "PDF": "https://arxiv.org/pdf/2410.08938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces KinDEL, a newly created dataset with detailed descriptions of data processing steps, facilitating advancements in machine learning for DNA-Encoded Libraries, focusing on dataset creation and data processing."
      },
      "tasks": [
        "Drug Discovery"
      ],
      "repo_urls": [
        "https://github.com/insitro/kindel"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15281",
      "abstract": "Trusted Execution Environment (TEE) enhances the security of mobile applications and cloud services by isolating sensitive code in the secure world from the non-secure normal world. However, TEE applications are still confronted with vulnerabilities stemming from bad partitioning. Bad partitioning can lead to critical security problems of TEE, such as leaking sensitive data to the normal world or being adversely affected by malicious inputs from the normal world.\n  To address this, we propose an approach to detect partitioning issues in TEE applications. First, we conducted a survey of TEE vulnerabilities caused by bad partitioning and found that the parameters exchanged between the secure and normal worlds often contain insecure usage with bad partitioning implementation. Second, we developed a tool named DITING that can analyze data-flows of these parameters and identify their violations of security rules we defined to find bad partitioning issues. Different from existing research that only focuses on malicious input to TEE, we assess the partitioning issues more comprehensively through input/output and shared memory. Finally, we created the first benchmark targeting bad partitioning, consisting of 110 test cases. Experiments demonstrate that DITING achieves an F1 score of 0.90 in identifying bad partitioning issues.",
      "authors": [
        "Chengyan Ma",
        "Ruidong Han",
        "Jieke Shi",
        "Ye Liu",
        "Yuqing Niu",
        "Di Lu",
        "Chuang Tian",
        "Jianfeng Ma",
        "Debin Gao",
        "David Lo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T08:19:01+00:00",
          "link": "https://arxiv.org/abs/2502.15281v1",
          "size": "727kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:57:15+00:00",
          "link": "https://arxiv.org/abs/2502.15281v2",
          "size": "694kb",
          "version": "v2"
        }
      ],
      "title": "DITING: A Static Analyzer for Identifying Bad Partitioning Issues in TEE Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15281",
        "HTML": "https://arxiv.org/html/2502.15281v2",
        "PDF": "https://arxiv.org/pdf/2502.15281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses partitioning issues in Trusted Execution Environment applications, unrelated to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/CharlieMCY/PartitioningE-in-TEE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20286",
      "abstract": "Evolutionary multiobjective optimization (EMO) has made significant strides over the past two decades. However, as problem scales and complexities increase, traditional EMO algorithms face substantial performance limitations due to insufficient parallelism and scalability. While most work has focused on algorithm design to address these challenges, little attention has been given to hardware acceleration, thereby leaving a clear gap between EMO algorithms and advanced computing devices, such as GPUs. To bridge the gap, we propose to parallelize EMO algorithms on GPUs via the tensorization methodology. By employing tensorization, the data structures and operations of EMO algorithms are transformed into concise tensor representations, which seamlessly enables automatic utilization of GPU computing. We demonstrate the effectiveness of our approach by applying it to three representative EMO algorithms: NSGA-III, MOEA/D, and HypE. To comprehensively assess our methodology, we introduce a multiobjective robot control benchmark using a GPU-accelerated physics engine. Our experiments show that the tensorized EMO algorithms achieve speedups of up to 1113x compared to their CPU-based counterparts, while maintaining solution quality and effectively scaling population sizes to hundreds of thousands. Furthermore, the tensorized EMO algorithms efficiently tackle complex multiobjective robot control tasks, producing high-quality solutions with diverse behaviors. Source codes are available at https://github.com/EMI-Group/evomo.",
      "authors": [
        "Zhenyu Liang",
        "Hao Li",
        "Naiwei Yu",
        "Kebin Sun",
        "Ran Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T07:30:23+00:00",
          "link": "https://arxiv.org/abs/2503.20286v1",
          "size": "4070kb",
          "version": "v1"
        },
        {
          "date": "2025-03-27T02:00:11+00:00",
          "link": "https://arxiv.org/abs/2503.20286v2",
          "size": "4070kb",
          "version": "v2"
        },
        {
          "date": "2025-04-11T08:21:16+00:00",
          "link": "https://arxiv.org/abs/2503.20286v3",
          "size": "4068kb",
          "version": "v3"
        },
        {
          "date": "2025-04-14T03:30:58+00:00",
          "link": "https://arxiv.org/abs/2503.20286v4",
          "size": "4200kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T03:46:16+00:00",
          "link": "https://arxiv.org/abs/2503.20286v5",
          "size": "3297kb",
          "version": "v5"
        }
      ],
      "title": "Bridging Evolutionary Multiobjective Optimization and GPU Acceleration via Tensorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20286",
        "HTML": "https://arxiv.org/html/2503.20286v5",
        "PDF": "https://arxiv.org/pdf/2503.20286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on GPU acceleration for evolutionary multiobjective optimization algorithms, without discussing processing LLM training data."
      },
      "tasks": [
        "Multiobjective Optimization"
      ],
      "repo_urls": [
        "https://github.com/emi-group/evomo",
        "https://github.com/emi-group/evox"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.11005",
      "abstract": "Large Language Models (LLMs) are increasingly utilized in autonomous decision-making, where they sample options from vast action spaces. However, the heuristics that guide this sampling process remain under explored. We study this sampling behavior and show that this underlying heuristics resembles that of human decision-making: comprising a descriptive component (reflecting statistical norm) and a prescriptive component (implicit ideal encoded in the LLM) of a concept. We show that this deviation of a sample from the statistical norm towards a prescriptive component consistently appears in concepts across diverse real-world domains like public health, and economic trends. To further illustrate the theory, we demonstrate that concept prototypes in LLMs are affected by prescriptive norms, similar to the concept of normality in humans. Through case studies and comparison with human studies, we illustrate that in real-world applications, the shift of samples toward an ideal value in LLMs' outputs can result in significantly biased decision-making, raising ethical concerns.",
      "authors": [
        "Sarath Sivaprasad",
        "Pramod Kaushik",
        "Sahar Abdelnabi",
        "Mario Fritz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-16T18:28:43+00:00",
          "link": "https://arxiv.org/abs/2402.11005v1",
          "size": "818kb",
          "version": "v1"
        },
        {
          "date": "2024-02-21T22:02:18+00:00",
          "link": "https://arxiv.org/abs/2402.11005v2",
          "size": "819kb",
          "version": "v2"
        },
        {
          "date": "2025-04-18T14:01:42+00:00",
          "link": "https://arxiv.org/abs/2402.11005v3",
          "size": "2464kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T19:29:19+00:00",
          "link": "https://arxiv.org/abs/2402.11005v4",
          "size": "2432kb",
          "version": "v4"
        }
      ],
      "title": "A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.11005",
        "HTML": "https://arxiv.org/html/2402.11005v4",
        "PDF": "https://arxiv.org/pdf/2402.11005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper theorizes on response sampling behavior in LLMs, addressing decision-making biases, but does not involve processing or creation of training data for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Descriptive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03492",
      "abstract": "We study an elliptic interface problem with discontinuous diffusion coefficients on unfitted meshes using the CutFEM method. Our main contribution is the reconstruction of conservative fluxes from the CutFEM solution and their use in a posteriori error estimation. We introduce a hybrid mixed formulation with locally computable Lagrange multipliers and reconstruct the flux in the immersed Raviart-Thomas space. Based on this, we propose a new a posteriori error estimator that includes both volume and interface terms. We state its robust reliability and local efficiency, and validate the approach through numerical experiments.",
      "authors": [
        "Daniela Capatina and Aimene Gouasmi and Cuiyu He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T11:31:57+00:00",
          "link": "https://arxiv.org/abs/2507.03492v1",
          "size": "10181kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:25:31+00:00",
          "link": "https://arxiv.org/abs/2507.03492v2",
          "size": "10180kb",
          "version": "v2"
        }
      ],
      "title": "Elliptic interface problem approximated by CutFEM: I. Conservative flux recovery and numerical validation of adaptive mesh refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03492",
        "HTML": "https://arxiv.org/html/2507.03492v2",
        "PDF": "https://arxiv.org/pdf/2507.03492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses elliptic interface problems and numerical validation using CutFEM, focusing on error estimation and mesh refinement, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07143",
      "abstract": "Accurately modeling malware propagation is essential for designing effective cybersecurity defenses, particularly against adaptive threats that evolve in real time. While traditional epidemiological models and recent neural approaches offer useful foundations, they often fail to fully capture the nonlinear feedback mechanisms present in real-world networks. In this work, we apply scientific machine learning to malware modeling by evaluating three approaches: classical Ordinary Differential Equations (ODEs), Universal Differential Equations (UDEs), and Neural ODEs. Using data from the Code Red worm outbreak, we show that the UDE approach substantially reduces prediction error compared to both traditional and neural baselines by 44%, while preserving interpretability. We introduce a symbolic recovery method that transforms the learned neural feedback into explicit mathematical expressions, revealing suppression mechanisms such as network saturation, security response, and malware variant evolution. Our results demonstrate that hybrid physics-informed models can outperform both purely analytical and purely neural approaches, offering improved predictive accuracy and deeper insight into the dynamics of malware spread. These findings support the development of early warning systems, efficient outbreak response strategies, and targeted cyber defense interventions.",
      "authors": [
        "Karthik Pappu",
        "Prathamesh Dinesh Joshi",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:49:23+00:00",
          "link": "https://arxiv.org/abs/2507.07143v1",
          "size": "590kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Malware Propagation Dynamics through Scientific Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07143",
        "HTML": "https://arxiv.org/html/2507.07143v1",
        "PDF": "https://arxiv.org/pdf/2507.07143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper applies scientific machine learning to model malware dynamics, focusing on feedback mechanisms and neural approaches, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07251",
      "abstract": "Traditional recommendation algorithms are not designed to provide personalized recommendations based on user preferences provided through text, e.g., \"I enjoy light-hearted comedies with a lot of humor\". Large Language Models (LLMs) have emerged as one of the most promising tools for natural language processing in recent years. This research proposes a novel framework that mimics how a close friend would recommend items based on their knowledge of an individual's tastes. We leverage LLMs to enhance movie recommendation systems by refining traditional algorithm outputs and integrating them with language-based user preference inputs. We employ Singular Value Decomposition (SVD) or SVD++ algorithms to generate initial movie recommendations, implemented using the Surprise Python library and trained on the MovieLens-Latest-Small dataset. We compare the performance of the base algorithms with our LLM-enhanced versions using leave-one-out validation hit rates and cumulative hit rates. Additionally, to compare the performance of our framework against the current state-of-the-art recommendation systems, we use rating and ranking metrics with an item-based stratified 0.75 train, 0.25 test split. Our framework can generate preference profiles automatically based on users' favorite movies or allow manual preference specification for more personalized results. Using an automated approach, our framework overwhelmingly surpassed SVD and SVD++ on every evaluation metric used (e.g., improvements of up to ~6x in cumulative hit rate, ~3.7x in NDCG, etc.), albeit at the cost of a slight increase in computational overhead.",
      "authors": [
        "Aaron Goldstein",
        "Ayan Dutta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:48:33+00:00",
          "link": "https://arxiv.org/abs/2507.07251v1",
          "size": "448kb",
          "version": "v1"
        }
      ],
      "title": "A Language-Driven Framework for Improving Personalized Recommendations: Merging LLMs with Traditional Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07251",
        "HTML": "https://arxiv.org/html/2507.07251v1",
        "PDF": "https://arxiv.org/pdf/2507.07251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs to enhance recommendation systems but focuses primarily on the combination of algorithms and does not primarily contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07637",
      "abstract": "Collaborative machine learning in sensitive domains demands scalable, privacy preserving solutions for enterprise deployment. Conventional Federated Learning (FL) relies on a central server, introducing single points of failure and privacy risks, while Split Learning (SL) partitions models for privacy but scales poorly due to sequential training. We present a decentralized architecture that combines Federated Split Learning (FSL) with the permissioned blockchain Hyperledger Fabric (HLF). Our chaincode orchestrates FSL's split model execution and peer-to-peer aggregation without any central coordinator, leveraging HLF's transient fields and Private Data Collections (PDCs) to keep raw data and model activations private. On CIFAR-10 and MNIST benchmarks, HLF-FSL matches centralized FSL accuracy while reducing per epoch training time compared to Ethereum-based works. Performance and scalability tests show minimal blockchain overhead and preserved accuracy, demonstrating enterprise grade viability.",
      "authors": [
        "Carlos Beis Penedo",
        "Rebeca P. D\\'iaz Redondo",
        "Ana Fern\\'andez Vilas",
        "Manuel Fern\\'andez Veiga",
        "Francisco Troncoso Pastoriza"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:06:25+00:00",
          "link": "https://arxiv.org/abs/2507.07637v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "HLF-FSL. A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07637",
        "HTML": "https://arxiv.org/html/2507.07637v1",
        "PDF": "https://arxiv.org/pdf/2507.07637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper discusses privacy-preserving machine learning architectures, it focuses on federated learning frameworks for IoT rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07644",
      "abstract": "We introduce PlanQA, a diagnostic benchmark for evaluating geometric and spatial reasoning in large-language models (LLMs). PlanQA is grounded in structured representations of indoor scenes, such as kitchens, living rooms, and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The benchmark includes diverse question types that test not only metric and topological reasoning (e.g., distance, visibility, shortest paths) but also interior design constraints such as affordance, clearance, balance, and usability. Our results across a variety of frontier open-source and commercial LLMs show that while models may succeed in shallow queries, they often fail to simulate physical constraints, preserve spatial coherence, or generalize under layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they do not consistently reason about real-world layouts. We hope that this benchmark inspires new work on language models that can accurately infer and manipulate spatial and geometric properties in practical settings.",
      "authors": [
        "Fedor Rodionov",
        "Abdelrahman Eldesokey",
        "Michael Birsak",
        "John Femiani",
        "Bernard Ghanem",
        "Peter Wonka"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:16:48+00:00",
          "link": "https://arxiv.org/abs/2507.07644v1",
          "size": "6333kb",
          "version": "v1"
        }
      ],
      "title": "PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07644",
        "HTML": "https://arxiv.org/html/2507.07644v1",
        "PDF": "https://arxiv.org/pdf/2507.07644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper introduces a new benchmark for spatial reasoning in LLMs, it does not focus on modifying or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07868",
      "abstract": "This paper extends the self-referential framework of Alpay Algebra into a multi-layered semantic game architecture where transfinite fixed-point convergence encompasses hierarchical sub-games at each iteration level. Building upon Alpay Algebra IV's empathetic embedding concept, we introduce a nested game-theoretic structure where the alignment process between AI systems and documents becomes a meta-game containing embedded decision problems. We formalize this through a composite operator $\\phi(\\cdot, \\gamma(\\cdot))$ where $\\phi$ drives the main semantic convergence while $\\gamma$ resolves local sub-games. The resulting framework demonstrates that game-theoretic reasoning emerges naturally from fixed-point iteration rather than being imposed externally. We prove a Game Theorem establishing existence and uniqueness of semantic equilibria under realistic cognitive simulation assumptions. Our verification suite includes adaptations of Banach's fixed-point theorem to transfinite contexts, a novel $\\phi$-topology based on the Kozlov-Maz'ya-Rossmann formula for handling semantic singularities, and categorical consistency tests via the Yoneda lemma. The paper itself functions as a semantic artifact designed to propagate its fixed-point patterns in AI embedding spaces -- a deliberate instantiation of the \"semantic virus\" concept it theorizes. All results are grounded in category theory, information theory, and realistic AI cognition models, ensuring practical applicability beyond pure mathematical abstraction.",
      "authors": [
        "Bugra Kilictas",
        "Faruk Alpay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:48:23+00:00",
          "link": "https://arxiv.org/abs/2507.07868v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07868",
        "HTML": "https://arxiv.org/html/2507.07868v1",
        "PDF": "https://arxiv.org/pdf/2507.07868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses semantic games and transfinite fixed-point simulation within Alpay Algebra, focusing on game-theoretic reasoning and cognitive simulation, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.02900",
      "abstract": "This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal dataset for medicine, covering over 25 million images across 10 modalities with multigranular annotations for more than 65 diseases. These multigranular annotations encompass both global information, such as modality and organ detection, and local information like ROI analysis, lesion texture, and region-wise correlations. Unlike the existing multimodal datasets, which are limited by the availability of image-text pairs, we have developed the first automated pipeline that scales up multimodal data by generating multigranular visual and textual annotations in the form of image-ROI-description triplets without the need for any paired text descriptions. Specifically, data from over 30 different sources have been collected, preprocessed, and grounded using domain-specific expert models to identify ROIs related to abnormal regions. We then build a comprehensive knowledge base and prompt multimodal large language models to perform retrieval-augmented generation with the identified ROIs as guidance, resulting in multigranular textual descriptions. Compared to existing datasets, MedTrinity-25M provides the most enriched annotations, supporting a comprehensive range of multimodal tasks such as captioning and report generation, as well as vision-centric tasks like classification and segmentation. We propose LLaVA-Tri by pretraining LLaVA on MedTrinity-25M, achieving state-of-the-art performance on VQA-RAD, SLAKE, and PathVQA, surpassing representative SOTA multimodal large language models. Furthermore, MedTrinity-25M can also be utilized to support large-scale pre-training of multimodal medical AI models, contributing to the development of future foundation models in the medical domain. We will make our dataset available.",
      "authors": [
        "Yunfei Xie",
        "Ce Zhou",
        "Lang Gao",
        "Juncheng Wu",
        "Xianhang Li",
        "Hong-Yu Zhou",
        "Sheng Liu",
        "Lei Xing",
        "James Zou",
        "Cihang Xie",
        "Yuyin Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-06T02:09:35+00:00",
          "link": "https://arxiv.org/abs/2408.02900v1",
          "size": "5540kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T18:11:59+00:00",
          "link": "https://arxiv.org/abs/2408.02900v2",
          "size": "5936kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:33:52+00:00",
          "link": "https://arxiv.org/abs/2408.02900v3",
          "size": "3885kb",
          "version": "v3"
        }
      ],
      "title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02900",
        "HTML": "https://arxiv.org/html/2408.02900v3",
        "PDF": "https://arxiv.org/pdf/2408.02900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces MedTrinity-25M, a new dataset with detailed data processing steps involving automated pipelines for annotation generation, data collection, preprocessing, and grounding, thus contributing significantly to LLM training data processing."
      },
      "models": [
        {
          "model_path": "yunfeixie/vlaa-02_data3_yxie_MedTrinity-25M",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/yunfeixie/vlaa-02_data3_yxie_MedTrinity-25M"
        }
      ],
      "datasets": [
        {
          "dataset_name": "UCSC-VLAA/MedTrinity-25M",
          "downloads": "2279",
          "likes": "158",
          "link": "https://huggingface.co/datasets/UCSC-VLAA/MedTrinity-25M"
        }
      ],
      "tasks": [
        "Medical Visual Question Answering",
        "Organ Detection",
        "Retrieval-augmented Generation",
        "Visual Question Answering (VQA)"
      ],
      "repo_urls": [
        "https://github.com/UCSC-VLAA/MedTrinity-25M"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17997",
      "abstract": "The widespread distribution of microplastics (MPs) in the environment presents significant challenges for their detection and identification. Fluorescence imaging has emerged as a promising technique for enhancing plastic particle detectability and enabling accurate classification based on fluorescence behavior. However, conventional segmentation techniques face limitations, including poor signal-to-noise ratio, inconsistent illumination, thresholding difficulties, and false positives from natural organic matter (NOM). To address these challenges, this study introduces the Fluorescence Imaging Microplastic Analysis Platform (FIMAP), a retrofitted multispectral camera with four optical filters and five excitation wavelengths. FIMAP enables comprehensive characterization of the fluorescence behavior of ten Nile Red-stained MPs: HDPE, LDPE, PP, PS, EPS, ABS, PVC, PC, PET, and PA, while effectively excluding NOM. Using K-means clustering for robust segmentation (Intersection over Union = 0.877) and a 20-dimensional color coordinate multivariate nearest neighbor approach for MP classification (>3.14 mm), FIMAP achieves 90% precision, 90% accuracy, 100% recall, and an F1 score of 94.7%. Only PS was occasionally misclassified as EPS. For smaller MPs (35-104 microns), classification accuracy declined, likely due to reduced stain sorption, fewer detectable pixels, and camera instability. Integrating FIMAP with higher-magnification instruments, such as a microscope, may enhance MP identification. This study presents FIMAP as an automated, high-throughput framework for detecting and classifying MPs across large environmental sample volumes.",
      "authors": [
        "Derek Ho",
        "Haotian Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T09:03:55+00:00",
          "link": "https://arxiv.org/abs/2502.17997v1",
          "size": "1236kb",
          "version": "v1"
        }
      ],
      "title": "Shedding Light on the Polymer's Identity: Microplastic Detection and Identification Through Nile Red Staining and Multispectral Imaging (FIMAP)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17997",
        "PDF": "https://arxiv.org/pdf/2502.17997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a method for microplastic detection and identification, which is not related to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.02097",
      "abstract": "Large language models (LLMs) are rapidly evolving from passive engines of text generation into agentic entities that can plan, remember, invoke external tools, and co-operate with one another. This perspective paper investigates how such LLM agents (and societies thereof) can transform the design space of recommender systems.\n  We introduce a unified formalism that (i) models an individual agent as a tuple comprising its language core, tool set, and hierarchical memory, and (ii) captures a multi-agent recommender as a triple of agents, shared environment, and communication protocol. Within this framework, we present four end-to-end use cases-interactive party planning, synthetic user-simulation for offline evaluation, multi-modal furniture recommendation, and brand-aligned explanation generation-each illustrating a distinct capability unlocked by agentic orchestration.\n  We then surface five cross-cutting challenge families: protocol complexity, scalability, hallucination and error propagation, emergent misalignment (including covert collusion), and brand compliance.\n  For each, we formalize the problem, review nascent mitigation strategies, and outline open research questions. The result is both a blueprint and an agenda: a blueprint that shows how memory-augmented, tool-using LLM agents can be composed into robust recommendation pipelines, and an agenda inviting the RecSys community to develop benchmarks, theoretical guarantees, and governance tools that keep pace with this new degree of autonomy. By unifying agentic abstractions with recommender objectives, the paper lays the groundwork for the next generation of personalized, trustworthy, and context-rich recommendation services.",
      "authors": [
        "Reza Yousefi Maragheh",
        "Yashar Deldjoo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.02097v1",
          "size": "1381kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:47:38+00:00",
          "link": "https://arxiv.org/abs/2507.02097v2",
          "size": "3615kb",
          "version": "v2"
        }
      ],
      "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02097",
        "HTML": "https://arxiv.org/html/2507.02097v2",
        "PDF": "https://arxiv.org/pdf/2507.02097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses LLMs in multi-agent recommender systems and their agentic capabilities, focusing on recommendation system design rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07996",
      "abstract": "Can a pretrained neural network adapt its architecture to different inputs without any finetuning? Do we need all layers for simple tasks, and are they adequate for challenging tasks? We found that the layers of a pretrained large language model (LLM) can be manipulated as separate modules to build a better and even shallower model customized for each test sample. In particular, each layer from the pretrained model can be skipped/pruned or repeated multiple times as recurrent neural networks (RNN), and stacked with others in arbitrary orders, yielding a chain-of-layers (CoLa) per sample. This compositional space greatly expands the scope of existing works on looped/recurrent pretrained modules, layer pruning, or early-exit networks. We develop a Monte Carlo Tree Search (MCTS) protocol to explore and identify the optimal CoLa for each sample from math and commonsense reasoning benchmarks. Compared to a static model of a fixed depth, CoLa allows shortcut paths (fast thinking), recurrence of the same layer(s) (slow thinking), and combining both, offering more flexible, dynamic architectures for different inputs. We conduct an extensive analysis of the MCTS-optimized CoLa, which leads to two key findings: (1) For >75% of samples with correct predictions by the original LLM, we can find shorter CoLa, suggesting a large space for improving inference efficiency; (2) For >60% of samples with originally incorrect predictions, we can identify CoLa achieving correct predictions, suggesting a large space of performance enhancement. Our results highlight the shortcomings of using a fixed architecture of pre-trained LLMs for inference on different samples and pave the way to unlock the generalization power of test-time depth adaptation.",
      "authors": [
        "Ziyue Li",
        "Yang Li",
        "Tianyi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.07996v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07996",
        "HTML": "https://arxiv.org/html/2507.07996v1",
        "PDF": "https://arxiv.org/pdf/2507.07996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on test-time depth adaptation for pretrained LLMs, altering neural network architectures at inference, without discussing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.02299",
      "abstract": "Modeling symmetry breaking is essential for understanding the fundamental changes in the behaviors and properties of physical systems, from microscopic particle interactions to macroscopic phenomena like fluid dynamics and cosmic structures. Thus, identifying sources of asymmetry is an important tool for understanding physical systems. In this paper, we focus on learning asymmetries of data using relaxed group convolutions. We provide both theoretical and empirical evidence that this flexible convolution technique allows the model to maintain the highest level of equivariance that is consistent with data and discover the subtle symmetry-breaking factors in various physical systems. We employ various relaxed group convolution architectures to uncover various symmetry-breaking factors that are interpretable and physically meaningful in different physical systems, including the phase transition of crystal structure, the isotropy and homogeneity breaking in turbulent flow, and the time-reversal symmetry breaking in pendulum systems.",
      "authors": [
        "Rui Wang",
        "Elyssa Hofgard",
        "Han Gao",
        "Robin Walters",
        "Tess E. Smidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-03T14:03:21+00:00",
          "link": "https://arxiv.org/abs/2310.02299v1",
          "size": "4851kb",
          "version": "v1"
        },
        {
          "date": "2023-10-14T02:57:05+00:00",
          "link": "https://arxiv.org/abs/2310.02299v2",
          "size": "4765kb",
          "version": "v2"
        },
        {
          "date": "2023-10-30T14:59:53+00:00",
          "link": "https://arxiv.org/abs/2310.02299v3",
          "size": "4753kb",
          "version": "v3"
        },
        {
          "date": "2023-12-14T00:51:05+00:00",
          "link": "https://arxiv.org/abs/2310.02299v4",
          "size": "6492kb",
          "version": "v4"
        },
        {
          "date": "2024-02-03T01:48:50+00:00",
          "link": "https://arxiv.org/abs/2310.02299v5",
          "size": "9398kb",
          "version": "v5"
        },
        {
          "date": "2024-02-13T01:32:02+00:00",
          "link": "https://arxiv.org/abs/2310.02299v6",
          "size": "9398kb",
          "version": "v6"
        },
        {
          "date": "2024-06-01T16:57:30+00:00",
          "link": "https://arxiv.org/abs/2310.02299v7",
          "size": "9374kb",
          "version": "v7"
        },
        {
          "date": "2025-07-10T14:55:09+00:00",
          "link": "https://arxiv.org/abs/2310.02299v8",
          "size": "7621kb",
          "version": "v8"
        }
      ],
      "title": "Discovering Symmetry Breaking in Physical Systems with Relaxed Group Convolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02299",
        "HTML": "https://arxiv.org/html/2310.02299",
        "PDF": "https://arxiv.org/pdf/2310.02299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies symmetry breaking in physical systems using group convolutions, without any focus on LLM training data processing."
      },
      "tasks": [
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07451",
      "abstract": "Reinforcement learning (RL) for large language models is an energy-intensive endeavor: training can be unstable, and the policy may gradually drift away from its pretrained weights. We present \\emph{RLEP}\\, -- \\,Reinforcement Learning with Experience rePlay\\, -- \\,a two-phase framework that first collects verified trajectories and then replays them during subsequent training. At every update step, the policy is optimized on mini-batches that blend newly generated rollouts with these replayed successes. By replaying high-quality examples, RLEP steers the model away from fruitless exploration, focuses learning on promising reasoning paths, and delivers both faster convergence and stronger final performance. On the Qwen2.5-Math-7B base model, RLEP reaches baseline peak accuracy with substantially fewer updates and ultimately surpasses it, improving accuracy on AIME-2024 from 38.2% to 39.9%, on AIME-2025 from 19.8% to 22.3%, and on AMC-2023 from 77.0% to 82.2%. Our code, datasets, and checkpoints are publicly available at https://github.com/Kwai-Klear/RLEP to facilitate reproducibility and further research.",
      "authors": [
        "Hongzhi Zhang",
        "Jia Fu",
        "Jingyuan Zhang",
        "Kai Fu",
        "Qi Wang",
        "Fuzheng Zhang",
        "Guorui Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:58:55+00:00",
          "link": "https://arxiv.org/abs/2507.07451v1",
          "size": "3163kb",
          "version": "v1"
        }
      ],
      "title": "RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07451",
        "HTML": "https://arxiv.org/html/2507.07451v1",
        "PDF": "https://arxiv.org/pdf/2507.07451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "RLEP includes reinforcement learning methods for improving LLM reasoning, mentioning datasets only in the context of reproducibility, but does not focus on the creation or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02113",
      "abstract": "Deep neural networks are often seen as different from other model classes by defying conventional notions of generalization. Popular examples of anomalous generalization behaviour include benign overfitting, double descent, and the success of overparametrization. We argue that these phenomena are not distinct to neural networks, or particularly mysterious. Moreover, this generalization behaviour can be intuitively understood, and rigorously characterized, using long-standing generalization frameworks such as PAC-Bayes and countable hypothesis bounds. We present soft inductive biases as a key unifying principle in explaining these phenomena: rather than restricting the hypothesis space to avoid overfitting, embrace a flexible hypothesis space, with a soft preference for simpler solutions that are consistent with the data. This principle can be encoded in many model classes, and thus deep learning is not as mysterious or different from other model classes as it might seem. However, we also highlight how deep learning is relatively distinct in other ways, such as its ability for representation learning, phenomena such as mode connectivity, and its relative universality.",
      "authors": [
        "Andrew Gordon Wilson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T22:56:04+00:00",
          "link": "https://arxiv.org/abs/2503.02113v1",
          "size": "1205kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:56:52+00:00",
          "link": "https://arxiv.org/abs/2503.02113v2",
          "size": "1231kb",
          "version": "v2"
        }
      ],
      "title": "Deep Learning is Not So Mysterious or Different",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02113",
        "HTML": "https://arxiv.org/html/2503.02113v2",
        "PDF": "https://arxiv.org/pdf/2503.02113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines generalization behavior in deep learning models, particularly neural networks, but does not focus on LLM training data processing or data engineering."
      },
      "tasks": [
        "Deep Learning",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07744",
      "abstract": "Video Temporal Grounding (VTG) involves Moment Retrieval (MR) and Highlight Detection (HD) based on textual queries. For this, most methods rely solely on final-layer features of frozen large pre-trained backbones, limiting their adaptability to new domains. While full fine-tuning is often impractical, parameter-efficient fine-tuning -- and particularly side-tuning (ST) -- has emerged as an effective alternative. However, prior ST approaches this problem from a frame-level refinement perspective, overlooking the inherent sparse nature of MR. To address this, we propose the Sparse-Dense Side-Tuner (SDST), the first anchor-free ST architecture for VTG. We also introduce the Reference-based Deformable Self-Attention, a novel mechanism that enhances the context modeling of the deformable attention -- a key limitation of existing anchor-free methods. Additionally, we present the first effective integration of InternVideo2 backbone into an ST framework, showing its profound implications in performance. Overall, our method significantly improves existing ST methods, achieving highly competitive or SOTA results on QVHighlights, TACoS, and Charades-STA, while reducing up to a 73% the parameter count w.r.t. the existing SOTA methods. The code is publicly accessible at https://github.com/davidpujol/SDST.",
      "authors": [
        "David Pujol-Perich",
        "Sergio Escalera and Albert Clap\\'es"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:23:41+00:00",
          "link": "https://arxiv.org/abs/2507.07744v1",
          "size": "3891kb",
          "version": "v1"
        }
      ],
      "title": "Sparse-Dense Side-Tuner for efficient Video Temporal Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07744",
        "HTML": "https://arxiv.org/html/2507.07744v1",
        "PDF": "https://arxiv.org/pdf/2507.07744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses primarily on fine-tuning techniques for Video Temporal Grounding using textual queries and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07800",
      "abstract": "Segmenting curvilinear structures in fluorescence microscopy remains a challenging task, particularly under noisy conditions and in dense filament networks commonly seen in vivo. To address this, we created two original datasets consisting of hundreds of synthetic images of fluorescently labelled microtubules within cells. These datasets are precisely annotated and closely mimic real microscopy images, including realistic noise. The second dataset presents an additional challenge, by simulating varying fluorescence intensities along filaments that complicate segmentation. While deep learning has shown strong potential in biomedical image analysis, its performance often declines in noisy or low-contrast conditions. To overcome this limitation, we developed a novel advanced architecture: the Adaptive Squeeze-and-Excitation Residual U-Net (ASE_Res_UNet). This model enhanced the standard U-Net by integrating residual blocks in the encoder and adaptive SE attention mechanisms in the decoder. Through ablation studies and comprehensive visual and quantitative evaluations, ASE_Res_UNet consistently outperformed its variants, namely standard U-Net, ASE_UNet and Res_UNet architectures. These improvements, particularly in noise resilience and detecting fine, low-intensity structures, were largely attributed to the adaptive SE attention module that we created. We further benchmarked ASE_Res_UNet against various state-of-the-art models, and found it achieved superior performance on our most challenging dataset. Finally, the model also generalized well to real microscopy images of stained microtubules as well as to other curvilinear structures. Indeed, it successfully segmented retinal blood vessels and nerves in noisy or low-contrast biomedical images, demonstrating its strong potential for applications in disease diagnosis and treatment.",
      "authors": [
        "Achraf Ait Laydi",
        "Louis Cueff",
        "Mewen Crespo",
        "Yousef El Mourabit and H\\'el\\`ene Bouvrais"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:26:50+00:00",
          "link": "https://arxiv.org/abs/2507.07800v1",
          "size": "10179kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Attention Residual U-Net for curvilinear structure segmentation in fluorescence microscopy and biomedical images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07800",
        "PDF": "https://arxiv.org/pdf/2507.07800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes by creating two original synthetic datasets closely mimicking real microscopy images, with detailed data processing steps addressing noise and fluorescence intensity challenges, essential for improving model segmentation performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07810",
      "abstract": "This paper investigates the relationship between large language models' (LLMs) ability to recognize repetitive input patterns and their performance on in-context learning (ICL). In contrast to prior work that has primarily focused on attention heads, we examine this relationship from the perspective of skill neurons, specifically repetition neurons. Our experiments reveal that the impact of these neurons on ICL performance varies depending on the depth of the layer in which they reside. By comparing the effects of repetition neurons and induction heads, we further identify strategies for reducing repetitive outputs while maintaining strong ICL capabilities.",
      "authors": [
        "Nhi Hoai Doan",
        "Tatsuya Hiraoka",
        "Kentaro Inui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:40:31+00:00",
          "link": "https://arxiv.org/abs/2507.07810v1",
          "size": "3457kb",
          "version": "v1"
        }
      ],
      "title": "Understanding and Controlling Repetition Neurons and Induction Heads in In-Context Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07810",
        "HTML": "https://arxiv.org/html/2507.07810v1",
        "PDF": "https://arxiv.org/pdf/2507.07810"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While it investigates the relationship between LLM components and repetitive outputs, it does not focus on processing or creating LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23080",
      "abstract": "This paper presents a comprehensive five-stage evolutionary framework for understanding the development of artificial intelligence, arguing that its trajectory mirrors the historical progression of human cognitive technologies. We posit that AI is advancing through distinct epochs, each defined by a revolutionary shift in its capacity for representation and reasoning, analogous to the inventions of cuneiform, the alphabet, grammar and logic, mathematical calculus, and formal logical systems. This \"Geometry of Cognition\" framework moves beyond mere metaphor to provide a systematic, cross-disciplinary model that not only explains AI's past architectural shifts-from expert systems to Transformers-but also charts a concrete and prescriptive path forward. Crucially, we demonstrate that this evolution is not merely linear but reflexive: as AI advances through these stages, the tools and insights it develops create a feedback loop that fundamentally reshapes its own underlying architecture. We are currently transitioning into a \"Metalinguistic Moment,\" characterized by the emergence of self-reflective capabilities like Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the \"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be defined by the development of a computable calculus of thought, likely through neuro-symbolic architectures and program synthesis, culminating in provably aligned and reliable AI that reconstructs its own foundational representations. This work serves as the methodological capstone to our trilogy, which previously explored the economic drivers (\"why\") and cognitive nature (\"what\") of AI. Here, we address the \"how,\" providing a theoretical foundation for future research and offering concrete, actionable strategies for startups and developers aiming to build the next generation of intelligent systems.",
      "authors": [
        "Xinmin Fang",
        "Lingfeng Tao",
        "Zhengxiong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:14:19+00:00",
          "link": "https://arxiv.org/abs/2506.23080v1",
          "size": "1458kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:48:50+00:00",
          "link": "https://arxiv.org/abs/2506.23080v2",
          "size": "191kb",
          "version": "v2"
        }
      ],
      "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23080",
        "HTML": "https://arxiv.org/html/2506.23080v2",
        "PDF": "https://arxiv.org/pdf/2506.23080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a theoretical framework for AI development epochs, focusing on model architectures and reasoning, but not on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.18483",
      "abstract": "The ability to generate explanations that are understood by explainees is the quintessence of explainable artificial intelligence. Since understanding depends on the explainee's background and needs, recent research focused on co-constructive explanation dialogues, where an explainer continuously monitors the explainee's understanding and adapts their explanations dynamically. We investigate the ability of large language models (LLMs) to engage as explainers in co-constructive explanation dialogues. In particular, we present a user study in which explainees interact with an LLM in two settings, one of which involves the LLM being instructed to explain a topic co-constructively. We evaluate the explainees' understanding before and after the dialogue, as well as their perception of the LLMs' co-constructive behavior. Our results suggest that LLMs show some co-constructive behaviors, such as asking verification questions, that foster the explainees' engagement and can improve understanding of a topic. However, their ability to effectively monitor the current understanding and scaffold the explanations accordingly remains limited.",
      "authors": [
        "Leandra Fichtel",
        "Maximilian Splieth\\\"over",
        "Eyke H\\\"ullermeier",
        "Patricia Jimenez",
        "Nils Klowait",
        "Stefan Kopp",
        "Axel-Cyrille Ngonga Ngomo",
        "Amelie Robrecht",
        "Ingrid Scharlau",
        "Lutz Terfloth",
        "Anna-Lisa Vollmer",
        "and Henning Wachsmuth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T16:47:44+00:00",
          "link": "https://arxiv.org/abs/2504.18483v1",
          "size": "2182kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:02:38+00:00",
          "link": "https://arxiv.org/abs/2504.18483v2",
          "size": "981kb",
          "version": "v2"
        }
      ],
      "title": "Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18483",
        "HTML": "https://arxiv.org/html/2504.18483v2",
        "PDF": "https://arxiv.org/pdf/2504.18483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates LLM behavior in explanation dialogues, focusing on user interaction and evaluation, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07133",
      "abstract": "We introduce the task of generative panoramic image stitching, which aims to synthesize seamless panoramas that are faithful to the content of multiple reference images containing parallax effects and strong variations in lighting, camera capture settings, or style. In this challenging setting, traditional image stitching pipelines fail, producing outputs with ghosting and other artifacts. While recent generative models are capable of outpainting content consistent with multiple reference images, they fail when tasked with synthesizing large, coherent regions of a panorama. To address these limitations, we propose a method that fine-tunes a diffusion-based inpainting model to preserve a scene's content and layout based on multiple reference images. Once fine-tuned, the model outpaints a full panorama from a single reference image, producing a seamless and visually coherent result that faithfully integrates content from all reference images. Our approach significantly outperforms baselines for this task in terms of image quality and the consistency of image structure and scene layout when evaluated on captured datasets.",
      "authors": [
        "Mathieu Tuli",
        "Kaveh Kamali",
        "and David B. Lindell"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:07:12+00:00",
          "link": "https://arxiv.org/abs/2507.07133v1",
          "size": "35393kb",
          "version": "v1"
        }
      ],
      "title": "Generative Panoramic Image Stitching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07133",
        "HTML": "https://arxiv.org/html/2507.07133v1",
        "PDF": "https://arxiv.org/pdf/2507.07133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about generative panoramic image stitching using fine-tuned diffusion models and does not focus on LLM training data processing or engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07355",
      "abstract": "High responsiveness and economic efficiency are critical objectives in supply chain transportation, both of which are influenced by strategic decisions on shipping mode. An integrated framework combining an efficient simulator with an intelligent decision-making algorithm can provide an observable, low-risk environment for transportation strategy design. An ideal simulation-decision framework must (1) generalize effectively across various settings, (2) reflect fine-grained transportation dynamics, (3) integrate historical experience with predictive insights, and (4) maintain tight integration between simulation feedback and policy refinement. We propose Sim-to-Dec framework to satisfy these requirements. Specifically, Sim-to-Dec consists of a generative simulation module, which leverages autoregressive modeling to simulate continuous state changes, reducing dependence on handcrafted domain-specific rules and enhancing robustness against data fluctuations; and a history-future dual-aware decision model, refined iteratively through end-to-end optimization with simulator interactions. Extensive experiments conducted on three real-world datasets demonstrate that Sim-to-Dec significantly improves timely delivery rates and profit.",
      "authors": [
        "Haoyue Bai",
        "Haoyu Wang",
        "Nanxu Gong",
        "Xinyuan Wang",
        "Wangyang Ying",
        "Haifeng Chen",
        "Yanjie Fu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:41:15+00:00",
          "link": "https://arxiv.org/abs/2507.07355v1",
          "size": "869kb",
          "version": "v1"
        }
      ],
      "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07355",
        "HTML": "https://arxiv.org/html/2507.07355v1",
        "PDF": "https://arxiv.org/pdf/2507.07355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on supply chain optimization using simulation and decision policies, with no mention of LLM training data processing or data engineering tasks relevant to model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07889",
      "abstract": "An integro-differential ring is a differential ring that is closed under an integration operation satisfying the fundamental theorem of calculus. Via the Newton--Leibniz formula, a generalized evaluation is defined in terms of integration and differentiation. The induced evaluation is not necessarily multiplicative, which allows to model functions with singularities and leads to generalized shuffle relations. In general, not every element of a differential ring has an antiderivative in the same ring. Starting from a commutative differential ring and a direct decomposition into integrable and non-integrable elements, we construct the free integro-differential ring. This integro-differential closure contains all nested integrals over elements of the original differential ring. We exhibit the relations satisfied by generalized evaluations of products of nested integrals. Investigating these relations of constants, we characterize in terms of Lyndon words certain evaluations of products that determine all others. We also analyze the relation of the free integro-differential ring with the shuffle algebra. To preserve integrals in the original differential ring for computations in its integro-differential closure, we introduce the notion of quasi-integro-differential rings and give an adapted construction of the free integro-differential ring. Finally, in a given integro-differential ring, we consider the internal integro-differential closure of a differential subring and identify it as quotient of the free integro-differential ring by certain constants.",
      "authors": [
        "Clemens G. Raab and Georg Regensburger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Symbolic Computation (cs.SC)",
        "Commutative Algebra (math.AC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:20:13+00:00",
          "link": "https://arxiv.org/abs/2507.07889v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "The integro-differential closure of a commutative differential ring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07889",
        "HTML": "https://arxiv.org/html/2507.07889v1",
        "PDF": "https://arxiv.org/pdf/2507.07889"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of integro-differential rings, focusing on theoretical aspects of differential algebra without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.20559",
      "abstract": "In modern imaging systems that computationally process raw measurements before or instead of human viewing, information content matters more than visual appearance. However, developing information estimators that can handle the complexity of real-world measurements yet remain practical enough for widespread use has proven challenging. We introduce a data-driven approach for estimating mutual information between unknown objects and their noisy measurements. Our technique fits probabilistic models to measurements and their noise processes, quantifying information content without requiring ground truth data or making assumptions about object structure. We validate our approach across diverse applications-color photography, radio astronomy, lensless imaging, and microscopy-demonstrating that information estimates reliably predict system performance. Finally, we introduce Information-Driven Encoder Analysis Learning (IDEAL), which optimizes imaging systems to maximize information capture. Our work unlocks information theory as a powerful, practical tool for analyzing and designing imaging systems across a broad range of applications.\n  A video summarizing this work can be found at: https://waller-lab.github.io/EncodingInformationWebsite/",
      "authors": [
        "Henry Pinkard",
        "Leyla Kabuli",
        "Eric Markley",
        "Tiffany Chien",
        "Jiantao Jiao",
        "and Laura Waller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Image and Video Processing (eess.IV)",
        "Information Theory (math.IT)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-31T00:57:58+00:00",
          "link": "https://arxiv.org/abs/2405.20559v1",
          "size": "35651kb",
          "version": "v1"
        },
        {
          "date": "2024-11-14T17:40:16+00:00",
          "link": "https://arxiv.org/abs/2405.20559v2",
          "size": "26036kb",
          "version": "v2"
        },
        {
          "date": "2025-01-17T23:10:02+00:00",
          "link": "https://arxiv.org/abs/2405.20559v3",
          "size": "29539kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T14:09:10+00:00",
          "link": "https://arxiv.org/abs/2405.20559v4",
          "size": "24802kb",
          "version": "v4"
        }
      ],
      "title": "Information-driven design of imaging systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.20559",
        "HTML": "https://arxiv.org/html/2405.20559v4",
        "PDF": "https://arxiv.org/pdf/2405.20559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on information-driven design of imaging systems and does not discuss aspects related to LLM training data processing."
      },
      "tasks": [
        "Astronomy"
      ],
      "repo_urls": [
        "https://github.com/waller-lab/encodinginformation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16074",
      "abstract": "DNA data storage is rapidly emerging as a promising solution for long-term data archiving, largely due to its exceptional durability. However, the synthesis of DNA strands remains a significant bottleneck in terms of cost and speed. To address this, new methods have been developed that encode information by concatenating long data-carrying DNA sequences from pre-synthesized DNA subsequences - known as motifs - from a library.\n  Reading back data from DNA storage relies on basecalling - the process of translating raw nanopore sequencing signals into DNA base sequences using machine learning models. These sequences are then decoded back into binary data. However, current basecalling approaches are not optimized for decoding motif-carrying DNA: they first predict individual bases from the raw signal and only afterward attempt to identify higher-level motifs. This two-step, motif-agnostic process is both imprecise and inefficient.\n  In this paper we introduce Motif Caller, a machine learning model designed to directly detect entire motifs from raw nanopore signals, bypassing the need for intermediate basecalling. By targeting motifs directly, Motif Caller leverages richer signal features associated with each motif, resulting in significantly improved accuracy. This direct approach also enhances the efficiency of data retrieval in motif-based DNA storage systems.",
      "authors": [
        "Parv Agarwal",
        "Nimesh Pinnamaneni",
        "Thomas Heinis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Computer Science (cs.OH)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T17:18:22+00:00",
          "link": "https://arxiv.org/abs/2412.16074v1",
          "size": "1149kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:26:25+00:00",
          "link": "https://arxiv.org/abs/2412.16074v2",
          "size": "1166kb",
          "version": "v2"
        }
      ],
      "title": "Motif Caller: Sequence Reconstruction for Motif-Based DNA Storage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16074",
        "HTML": "https://arxiv.org/html/2412.16074v2",
        "PDF": "https://arxiv.org/pdf/2412.16074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a machine learning model for improving DNA base calling efficiency in motif-based DNA storage. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02398",
      "abstract": "We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.",
      "authors": [
        "Taehoon Kim",
        "Jongwook Choi",
        "Yonghyun Jeong",
        "Haeun Noh",
        "Jaejun Yoo",
        "Seungryul Baek",
        "Jongwon Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:49:55+00:00",
          "link": "https://arxiv.org/abs/2507.02398v1",
          "size": "1359kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T06:52:35+00:00",
          "link": "https://arxiv.org/abs/2507.02398v2",
          "size": "1359kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02398",
        "HTML": "https://arxiv.org/html/2507.02398v2",
        "PDF": "https://arxiv.org/pdf/2507.02398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on deepfake video detection using temporal frequency analysis, which does not involve the processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07687",
      "abstract": "Underwater Monocular Depth Estimation (UMDE) is a critical task that aims to estimate high-precision depth maps from underwater degraded images caused by light absorption and scattering effects in marine environments. Recently, Mamba-based methods have achieved promising performance across various vision tasks; however, they struggle with the UMDE task because their inflexible state scanning strategies fail to model the structural features of underwater images effectively. Meanwhile, existing UMDE datasets usually contain unreliable depth labels, leading to incorrect object-depth relationships between underwater images and their corresponding depth maps. To overcome these limitations, we develop a novel tree-aware Mamba method, dubbed Tree-Mamba, for estimating accurate monocular depth maps from underwater degraded images. Specifically, we propose a tree-aware scanning strategy that adaptively constructs a minimum spanning tree based on feature similarity. The spatial topological features among the tree nodes are then flexibly aggregated through bottom-up and top-down traversals, enabling stronger multi-scale feature representation capabilities. Moreover, we construct an underwater depth estimation benchmark (called BlueDepth), which consists of 38,162 underwater image pairs with reliable depth labels. This benchmark serves as a foundational dataset for training existing deep learning-based UMDE methods to learn accurate object-depth relationships. Extensive experiments demonstrate the superiority of the proposed Tree-Mamba over several leading methods in both qualitative results and quantitative evaluations with competitive computational efficiency. Code and dataset will be available at https://wyjgr.github.io/Tree-Mamba.html.",
      "authors": [
        "Peixian Zhuang",
        "Yijian Wang",
        "Zhenqi Fu",
        "Hongliang Zhang",
        "Sam Kwong",
        "Chongyi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:10:51+00:00",
          "link": "https://arxiv.org/abs/2507.07687v1",
          "size": "38067kb",
          "version": "v1"
        }
      ],
      "title": "Tree-Mamba: A Tree-Aware Mamba for Underwater Monocular Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07687",
        "HTML": "https://arxiv.org/html/2507.07687v1",
        "PDF": "https://arxiv.org/pdf/2507.07687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a new dataset (BlueDepth) with detailed processing steps, which supports training in underwater monocular depth estimation tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15284",
      "abstract": "Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLord outperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.",
      "authors": [
        "Weichen Li",
        "Albert Jan",
        "Baishakhi Ray",
        "Junfeng Yang",
        "Chengzhi Mao",
        "Kexin Pei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T16:33:59+00:00",
          "link": "https://arxiv.org/abs/2504.15284v1",
          "size": "4674kb",
          "version": "v1"
        },
        {
          "date": "2025-04-23T18:37:18+00:00",
          "link": "https://arxiv.org/abs/2504.15284v2",
          "size": "4559kb",
          "version": "v2"
        },
        {
          "date": "2025-06-21T02:12:15+00:00",
          "link": "https://arxiv.org/abs/2504.15284v3",
          "size": "4562kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T21:15:30+00:00",
          "link": "https://arxiv.org/abs/2504.15284v4",
          "size": "4694kb",
          "version": "v4"
        }
      ],
      "title": "EditLord: Learning Code Transformation Rules for Code Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15284",
        "PDF": "https://arxiv.org/pdf/2504.15284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework that uses a language model to learn code transformation rules, briefly interacting with training code pairs, but does not focus predominantly on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20573",
      "abstract": "The widespread availability of large public datasets is a key factor behind the recent successes of statistical inference and machine learning methods. However, these datasets often contain some low-quality or contaminated data, to which many learning procedures are sensitive. Therefore, the question of whether and how public datasets should be prefiltered to facilitate accurate downstream learning arises. On a technical level this requires the construction of principled data prefiltering methods which are learner-agnostic robust, in the sense of provably protecting a set of pre-specified downstream learners from corrupted data. In this work, we formalize the problem of Learner-Agnostic Robust data Prefiltering (LARP), which aims at finding prefiltering procedures that minimize a worst-case loss over a pre-specified set of learners. We first instantiate our framework in the context of scalar mean estimation with Huber estimators under the Huber data contamination model. We provide a hardness result on a specific problem instance and analyze several natural prefiltering procedures. Our theoretical results indicate that performing LARP on a heterogeneous set of learners leads to some loss in model performance compared to the alternative of prefiltering data for each learner/use-case individually. We explore the resulting utility loss and its dependence on the problem parameters via extensive experiments on real-world image and tabular data, observing statistically significant reduction in utility. Finally, we model the trade-off between the utility drop and the cost of repeated (learner-specific) prefiltering within a game-theoretic framework and showcase benefits of LARP for large datasets.",
      "authors": [
        "Kristian Minchev",
        "Dimitar Iliev Dimitrov",
        "Nikola Konstantinov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T16:07:59+00:00",
          "link": "https://arxiv.org/abs/2506.20573v1",
          "size": "110kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:23:19+00:00",
          "link": "https://arxiv.org/abs/2506.20573v2",
          "size": "126kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:40:09+00:00",
          "link": "https://arxiv.org/abs/2506.20573v3",
          "size": "126kb",
          "version": "v3"
        }
      ],
      "title": "LARP: Learner-Agnostic Robust Data Prefiltering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20573",
        "HTML": "https://arxiv.org/html/2506.20573v3",
        "PDF": "https://arxiv.org/pdf/2506.20573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on learner-agnostic robust data prefiltering, which is directly related to processing datasets to improve data quality, making it relevant to LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07460",
      "abstract": "Out-of-Distribution (OoD) segmentation is critical for safety-sensitive applications like autonomous driving. However, existing mask-based methods often suffer from boundary imprecision, inconsistent anomaly scores within objects, and false positives from background noise. We propose \\textbf{\\textit{Objectomaly}}, an objectness-aware refinement framework that incorporates object-level priors. Objectomaly consists of three stages: (1) Coarse Anomaly Scoring (CAS) using an existing OoD backbone, (2) Objectness-Aware Score Calibration (OASC) leveraging SAM-generated instance masks for object-level score normalization, and (3) Meticulous Boundary Precision (MBP) applying Laplacian filtering and Gaussian smoothing for contour refinement. Objectomaly achieves state-of-the-art performance on key OoD segmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and RoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to 0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies and qualitative results on real-world driving videos further validate the robustness and generalizability of our method. Code will be released upon publication.",
      "authors": [
        "Jeonghoon Song",
        "Sunghun Kim",
        "Jaegyun Im",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:23:35+00:00",
          "link": "https://arxiv.org/abs/2507.07460v1",
          "size": "15294kb",
          "version": "v1"
        }
      ],
      "title": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07460",
        "HTML": "https://arxiv.org/html/2507.07460v1",
        "PDF": "https://arxiv.org/pdf/2507.07460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the Objectomaly framework for OoD segmentation focused on object-level anomaly detection rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07920",
      "abstract": "Cerebrovascular pathology significantly contributes to cognitive decline and neurological disorders, underscoring the need for advanced tools to assess vascular integrity. Three-dimensional Time-of-Flight Magnetic Resonance Angiography (3D TOF MRA) is widely used to visualize cerebral vasculature, however, clinical evaluations generally focus on major arterial abnormalities, overlooking quantitative metrics critical for understanding subtle vascular changes. Existing methods for extracting structural, geometrical and morphological arterial features from MRA - whether manual or automated - face challenges including user-dependent variability, steep learning curves, and lack of standardized quantitative validations. We propose a novel semi-supervised artery evaluation framework, named ArteryX, a MATLAB-based toolbox that quantifies vascular features with high accuracy and efficiency, achieving processing times ~10-15 minutes per subject at 0.5 mm resolution with minimal user intervention. ArteryX employs a vessel-fused network based landmarking approach to reliably track and manage tracings, effectively addressing the issue of dangling/disconnected vessels. Validation on human subjects with cerebral small vessel disease demonstrated its improved sensitivity to subtle vascular changes and better performance than an existing semi-automated method. Importantly, the ArteryX toolbox enables quantitative feature validation by integrating an in-vivo like artery simulation framework utilizing vessel-fused graph nodes and predefined ground-truth features for specific artery types. Thus, the ArteryX framework holds promise for benchmarking feature extraction toolboxes and for seamless integration into clinical workflows, enabling early detection of cerebrovascular pathology and standardized comparisons across patient cohorts to advance understanding of vascular contributions to brain health.",
      "authors": [
        "Abrar Faiyaz",
        "Nhat Hoang",
        "Giovanni Schifitto",
        "Md Nasir Uddin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:00:49+00:00",
          "link": "https://arxiv.org/abs/2507.07920v1",
          "size": "10941kb",
          "version": "v1"
        }
      ],
      "title": "ArteryX: Advancing Brain Artery Feature Extraction with Vessel-Fused Networks and a Robust Validation Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07920",
        "HTML": "https://arxiv.org/html/2507.07920v1",
        "PDF": "https://arxiv.org/pdf/2507.07920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on cerebral vasculature evaluation and feature extraction using ArteryX, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03233",
      "abstract": "Integrated sensing and communication (ISAC) has been recognized as one of the key technologies for future wireless networks, which potentially need to operate in multiple frequency bands to satisfy ever-increasing demands for both communication and sensing services. Motivated by this, we consider the sum sensing rate (SR) optimization for a cooperative ISAC system with linear precoding, where each base station (BS) works in a different frequency band. With this aim, we propose an optimization algorithm based on the semi-definite rank relaxation that introduces covariance matrices as optimization variables, and we apply the inner approximation (IA) method to deal with the nonconvexity of the resulting problem. Simulation results show that the proposed algorithm increases the SR by approximately 25 % and 40 % compared to the case of equal power distribution in a cooperative ISAC system with two and three BSs, respectively. Additionally, the algorithm converges in only a few iterations, while its most beneficial implementation scenario is in the low power regime",
      "authors": [
        "Nemanja Stefan Perovi\\'c",
        "Mark F. Flanagan",
        "Le-Nam Tran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T07:20:53+00:00",
          "link": "https://arxiv.org/abs/2503.03233v1",
          "size": "159kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:19:16+00:00",
          "link": "https://arxiv.org/abs/2503.03233v2",
          "size": "163kb",
          "version": "v2"
        }
      ],
      "title": "Sensing Rate Optimization for Multi-Band Cooperative ISAC Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03233",
        "HTML": "https://arxiv.org/html/2503.03233v2",
        "PDF": "https://arxiv.org/pdf/2503.03233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses sensing rate optimization in cooperative ISAC systems, which is unrelated to LLM training data processing or associated data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07197",
      "abstract": "The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.",
      "authors": [
        "Elia Piccoli",
        "Malio Li",
        "Giacomo Carf\\`i",
        "Vincenzo Lomonaco",
        "Davide Bacciu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:13:52+00:00",
          "link": "https://arxiv.org/abs/2507.07197v1",
          "size": "7109kb",
          "version": "v1"
        }
      ],
      "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07197",
        "HTML": "https://arxiv.org/html/2507.07197v1",
        "PDF": "https://arxiv.org/pdf/2507.07197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new architecture for combining pre-trained models in reinforcement learning. It does not make contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.17428",
      "abstract": "In this study, we investigate the effect of SSL objective modifications within the SPR framework, focusing on specific adjustments such as terminal state masking and prioritized replay weighting, which were not explicitly addressed in the original design. While these modifications are specific to RL, they are not universally applicable across all RL algorithms. Therefore, we aim to assess their impact on performance and explore other SSL objectives that do not accommodate these adjustments like Barlow Twins and VICReg. We evaluate six SPR variants on the Atari 100k benchmark, including versions both with and without these modifications. Additionally, we test the performance of these objectives on the DeepMind Control Suite, where such modifications are absent. Our findings reveal that incorporating specific SSL modifications within SPR significantly enhances performance, and this influence extends to subsequent frameworks like SR-SPR and BBF, highlighting the critical importance of SSL objective selection and related adaptations in achieving data efficiency in self-predictive reinforcement learning.",
      "authors": [
        "\\\"Omer Veysel \\c{C}a\\u{g}atan and Bar{\\i}\\c{s} Akg\\\"un"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T20:57:10+00:00",
          "link": "https://arxiv.org/abs/2410.17428v1",
          "size": "1125kb",
          "version": "v1"
        },
        {
          "date": "2025-02-24T20:03:02+00:00",
          "link": "https://arxiv.org/abs/2410.17428v2",
          "size": "1125kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T11:21:38+00:00",
          "link": "https://arxiv.org/abs/2410.17428v3",
          "size": "839kb",
          "version": "v3"
        }
      ],
      "title": "Uncovering RL Integration in SSL Loss: Objective-Specific Implications for Data-Efficient RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17428",
        "HTML": "https://arxiv.org/html/2410.17428v3",
        "PDF": "https://arxiv.org/pdf/2410.17428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses SSL objective modifications within reinforcement learning contexts and does not contribute to LLM training data processing techniques."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.04278",
      "abstract": "With the recent success of Large Language Models (LLMs), Descriptive Multimodal Emotion Recognition (DMER) has garnered increasing attention, which aims to describe a person's emotional state using free-form natural language. Unlike traditional discriminative methods that rely on predefined emotion taxonomies, DMER offers greater flexibility in emotional expression, enabling fine-grained and interpretable emotion representations. However, this free-form prediction paradigm exposes significant challenges in evaluation. Existing methods either depend on ground-truth descriptions that require substantial manual annotations or simplify the task by shifting the focus from evaluating descriptions to evaluating emotion labels. However, this simplification overlooks critical aspects such as emotional temporal dynamics, intensity, and uncertainty. To address these limitations, we draw inspiration from Reinforcement Learning from Human Feedback (RLHF) and propose DMER-Ranker, a novel evaluation strategy that reformulates the traditional ``prediction-ground truth'' comparison into the ``prediction-prediction'' comparison, eliminating the need for ground-truth descriptions. We then employ the Bradley-Terry algorithm to convert pairwise comparison results into model-level rankings. Additionally, we explore the possibility of automatic preference prediction and introduce DMER-Preference, the first preference dataset specifically designed for human emotions. Our work advances the field of DMER and lays the foundation for more intelligent human-computer interaction systems.",
      "authors": [
        "Zheng Lian",
        "Licai Sun",
        "Haoyu Chen",
        "Zebang Cheng",
        "Fan Zhang",
        "Ziyu Jia",
        "Ziyang Ma",
        "Fei Ma",
        "Xiaojiang Peng",
        "Jianhua Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T07:37:59+00:00",
          "link": "https://arxiv.org/abs/2507.04278v1",
          "size": "10398kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:28:00+00:00",
          "link": "https://arxiv.org/abs/2507.04278v2",
          "size": "10398kb",
          "version": "v2"
        }
      ],
      "title": "DMER-Ranker: Learning to Rank Emotion Descriptions in the Absence of Ground Truth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04278",
        "HTML": "https://arxiv.org/html/2507.04278v2",
        "PDF": "https://arxiv.org/pdf/2507.04278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes DMER-Ranker, an evaluation strategy inspired by RLHF, and introduces DMER-Preference. While it creates a new dataset, its focus is on evaluating emotion prediction models, not on improving LLM training data or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07202",
      "abstract": "Despite the significant progress that has been made in video generative models, existing state-of-the-art methods can only produce videos lasting 5-16 seconds, often labeled \"long-form videos\". Furthermore, videos exceeding 16 seconds struggle to maintain consistent character appearances and scene layouts throughout the narrative. In particular, multi-subject long videos still fail to preserve character consistency and motion coherence. While some methods can generate videos up to 150 seconds long, they often suffer from frame redundancy and low temporal diversity. Recent work has attempted to produce long-form videos featuring multiple characters, narrative coherence, and high-fidelity detail. We comprehensively studied 32 papers on video generation to identify key architectural components and training strategies that consistently yield these qualities. We also construct a comprehensive novel taxonomy of existing methods and present comparative tables that categorize papers by their architectural designs and performance characteristics.",
      "authors": [
        "Mohamed Elmoghany",
        "Ryan Rossi",
        "Seunghyun Yoon",
        "Subhojyoti Mukherjee",
        "Eslam Bakr",
        "Puneet Mathur",
        "Gang Wu",
        "Viet Dac Lai",
        "Nedim Lipka",
        "Ruiyi Zhang",
        "Varun Manjunatha",
        "Chien Nguyen",
        "Daksh Dangi",
        "Abel Salinas",
        "Mohammad Taesiri",
        "Hongjie Chen",
        "Xiaolei Huang",
        "Joe Barrow",
        "Nesreen Ahmed",
        "Hoda Eldardiry",
        "Namyong Park",
        "Yu Wang",
        "Jaemin Cho",
        "Anh Totti Nguyen",
        "Zhengzhong Tu",
        "Thien Nguyen",
        "Dinesh Manocha",
        "Mohamed Elhoseiny",
        "Franck Dernoncourt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:20:33+00:00",
          "link": "https://arxiv.org/abs/2507.07202v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Long-Video Storytelling Generation: Architectures, Consistency, and Cinematic Quality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07202",
        "HTML": "https://arxiv.org/html/2507.07202v1",
        "PDF": "https://arxiv.org/pdf/2507.07202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper surveys video storytelling generation methods, focusing on architectures and quality. There is no primary focus on LLM training data, but it mentions training strategies, so it partially relates to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07444",
      "abstract": "Ensuring the functional safety of motion planning modules in autonomous vehicles remains a critical challenge, especially when dealing with complex or learning-based software. Online verification has emerged as a promising approach to monitor such systems at runtime, yet its integration into embedded real-time environments remains limited. This work presents a safeguarding concept for motion planning that extends prior approaches by introducing a time safeguard. While existing methods focus on geometric and dynamic feasibility, our approach additionally monitors the temporal consistency of planning outputs to ensure timely system response. A prototypical implementation on a real-time operating system evaluates trajectory candidates using constraint-based feasibility checks and cost-based plausibility metrics. Preliminary results show that the safeguarding module operates within real-time bounds and effectively detects unsafe trajectories. However, the full integration of the time safeguard logic and fallback strategies is ongoing. This study contributes a modular and extensible framework for runtime trajectory verification and highlights key aspects for deployment on automotive-grade hardware. Future work includes completing the safeguarding logic and validating its effectiveness through hardware-in-the-loop simulations and vehicle-based testing. The code is available at: https://github.com/TUM-AVS/motion-planning-supervisor",
      "authors": [
        "Korbinian Moller",
        "Rafael Neher",
        "Marvin Seegert",
        "Johannes Betz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.07444v1",
          "size": "264kb",
          "version": "v1"
        }
      ],
      "title": "Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for Motion Planning Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07444",
        "PDF": "https://arxiv.org/pdf/2507.07444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a safeguarding concept for motion planning in autonomous vehicles, primarily concerning real-time trajectory verification, and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07548",
      "abstract": "With the advent of generative LLMs and their advanced code generation capabilities, some people already envision the end of traditional software engineering, as LLMs may be able to produce high-quality code based solely on the requirements a domain expert feeds into the system. The feasibility of this vision can be assessed by understanding how developers currently incorporate requirements when using LLMs for code generation-a topic that remains largely unexplored. We interviewed 18 practitioners from 14 companies to understand how they (re)use information from requirements and other design artifacts to feed LLMs when generating code. Based on our findings, we propose a theory that explains the processes developers employ and the artifacts they rely on. Our theory suggests that requirements, as typically documented, are too abstract for direct input into LLMs. Instead, they must first be manually decomposed into programming tasks, which are then enriched with design decisions and architectural constraints before being used in prompts. Our study highlights that fundamental RE work is still necessary when LLMs are used to generate code. Our theory is important for contextualizing scientific approaches to automating requirements-centric SE tasks.",
      "authors": [
        "Jonathan Ullrich",
        "Matthias Koch",
        "Andreas Vogelsang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:42:19+00:00",
          "link": "https://arxiv.org/abs/2507.07548v1",
          "size": "175kb",
          "version": "v1"
        }
      ],
      "title": "From Requirements to Code: Understanding Developer Practices in LLM-Assisted Software Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07548",
        "HTML": "https://arxiv.org/html/2507.07548v1",
        "PDF": "https://arxiv.org/pdf/2507.07548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It examines developer practices in LLM-assisted code generation without addressing LLM training data processing or enhancements to training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07579",
      "abstract": "This paper presents a novel few-shot cross-domain anomaly detection framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on vision foundation models, which effectively addresses domain-shift challenges in industrial anomaly detection through innovative shared subspace projection mechanisms and multi-task learning (MTL) module. The main innovations include: (1) a hierarchical adapter module that adaptively fuses complementary features from Hiera and DINO-v2 pre-trained models, constructing more robust feature representations; (2) a shared subspace projection strategy that enables effective cross-domain knowledge transfer through bottleneck dimension constraints and skip connection mechanisms; (3) a MTL Decoder architecture supports simultaneous processing of multiple source domains, significantly enhancing model generalization capabilities; (4) an anomaly score inference method based on Sinkhorn-K-means clustering, combined with Gaussian filtering and adaptive threshold processing for precise pixel level. Valuated on the MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of 97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other recent models, marking a transformative advance in cross-domain defect detection.",
      "authors": [
        "Tianwei Mu and Feiyu Duan and Bo Zhou and Dan Xue and Manhong Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:29:26+00:00",
          "link": "https://arxiv.org/abs/2507.07579v1",
          "size": "17956kb",
          "version": "v1"
        }
      ],
      "title": "NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07579",
        "HTML": "https://arxiv.org/html/2507.07579v1",
        "PDF": "https://arxiv.org/pdf/2507.07579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for anomaly detection through cross-domain knowledge transfer and multi-task learning. It does not involve LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07685",
      "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable capabilities by integrating pre-trained vision encoders with large language models (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting has been adapted for LVLMs to enhance multi-modal reasoning by generating intermediate rationales based on visual and textual inputs. While CoT is assumed to improve grounding and accuracy in LVLMs, our experiments reveal a key challenge: existing LVLMs often ignore the contents of generated rationales in CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as a KL-constrained reward maximization focused on rationale-conditional log-likelihood. As the optimal solution, we propose rationale-enhanced decoding (RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes visual and rationale information by multiplying distinct image-conditional and rationale-conditional next token distributions. Extensive experiments show that RED consistently and significantly improves reasoning over standard CoT and other decoding methods across multiple benchmarks and LVLMs. Our work offers a practical and effective approach to improve both the faithfulness and accuracy of CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded multi-modal systems.",
      "authors": [
        "Shin'ya Yamaguchi",
        "Kosuke Nishida",
        "Daiki Chijiwa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:07:13+00:00",
          "link": "https://arxiv.org/abs/2507.07685v1",
          "size": "604kb",
          "version": "v1"
        }
      ],
      "title": "Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07685",
        "HTML": "https://arxiv.org/html/2507.07685v1",
        "PDF": "https://arxiv.org/pdf/2507.07685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel decoding strategy for LVLMs but does not primarily focus on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07764",
      "abstract": "Psychoacoustical so-called \"timbre spaces\" map perceptual similarity ratings of instrument sounds onto low-dimensional embeddings via multidimensional scaling, but suffer from scalability issues and are incapable of generalization. Recent results from audio (music and speech) quality assessment as well as image similarity have shown that deep learning is able to produce embeddings that align well with human perception while being largely free from these constraints. Although the existing human-rated timbre similarity data is not large enough to train deep neural networks (2,614 pairwise ratings on 334 audio samples), it can serve as test-only data for audio models. In this paper, we introduce metrics to assess the alignment of diverse audio representations with human judgments of timbre similarity by comparing both the absolute values and the rankings of embedding distances to human similarity ratings. Our evaluation involves three signal-processing-based representations, twelve representations extracted from pre-trained models, and three representations extracted from a novel sound matching model. Among them, the style embeddings inspired by image style transfer, extracted from the CLAP model and the sound matching model, remarkably outperform the others, showing their potential in modeling timbre similarity.",
      "authors": [
        "Haokun Tian",
        "Stefan Lattner",
        "Charalampos Saitis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:41:59+00:00",
          "link": "https://arxiv.org/abs/2507.07764v1",
          "size": "1822kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Alignment of Audio Representations with Timbre Similarity Ratings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07764",
        "HTML": "https://arxiv.org/html/2507.07764v1",
        "PDF": "https://arxiv.org/pdf/2507.07764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study assesses audio representation alignment with human perception and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2105.05874",
      "abstract": "This manuscript describes the first challenge on Federated Learning, namely the Federated Tumor Segmentation (FeTS) challenge 2021. International challenges have become the standard for validation of biomedical image analysis methods. However, the actual performance of participating (even the winning) algorithms on \"real-world\" clinical data often remains unclear, as the data included in challenges are usually acquired in very controlled settings at few institutions. The seemingly obvious solution of just collecting increasingly more data from more institutions in such challenges does not scale well due to privacy and ownership hurdles. Towards alleviating these concerns, we are proposing the FeTS challenge 2021 to cater towards both the development and the evaluation of models for the segmentation of intrinsically heterogeneous (in appearance, shape, and histology) brain tumors, namely gliomas. Specifically, the FeTS 2021 challenge uses clinically acquired, multi-institutional magnetic resonance imaging (MRI) scans from the BraTS 2020 challenge, as well as from various remote independent institutions included in the collaborative network of a real-world federation (https://www.fets.ai/). The goals of the FeTS challenge are directly represented by the two included tasks: 1) the identification of the optimal weight aggregation approach towards the training of a consensus model that has gained knowledge via federated learning from multiple geographically distinct institutions, while their data are always retained within each institution, and 2) the federated evaluation of the generalizability of brain tumor segmentation models \"in the wild\", i.e. on data from institutional distributions that were not part of the training datasets.",
      "authors": [
        "Sarthak Pati",
        "Ujjwal Baid",
        "Maximilian Zenk",
        "Brandon Edwards",
        "Micah Sheller",
        "G. Anthony Reina",
        "Patrick Foley",
        "Alexey Gruzdev",
        "Jason Martin",
        "Shadi Albarqouni",
        "Yong Chen",
        "Russell Taki Shinohara",
        "Annika Reinke",
        "David Zimmerer",
        "John B. Freymann",
        "Justin S. Kirby",
        "Christos Davatzikos",
        "Rivka R. Colen",
        "Aikaterini Kotrotsou",
        "Daniel Marcus",
        "Mikhail Milchenko",
        "Arash Nazeri",
        "Hassan Fathallah-Shaykh",
        "Roland Wiest",
        "Andras Jakab",
        "Marc-Andre Weber",
        "Abhishek Mahajan",
        "Lena Maier-Hein",
        "Jens Kleesiek",
        "Bjoern Menze",
        "Klaus Maier-Hein",
        "Spyridon Bakas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2021-05-12T18:00:20+00:00",
          "link": "https://arxiv.org/abs/2105.05874v1",
          "size": "673kb",
          "version": "v1"
        },
        {
          "date": "2021-05-14T00:54:23+00:00",
          "link": "https://arxiv.org/abs/2105.05874v2",
          "size": "673kb",
          "version": "v2"
        }
      ],
      "title": "The Federated Tumor Segmentation (FeTS) Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2105.05874",
        "PDF": "https://arxiv.org/pdf/2105.05874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and evaluation for tumor segmentation models, without discussing LLM training data processing or improvement techniques."
      },
      "tasks": [
        "Brain Tumor Segmentation",
        "Federated Learning",
        "Segmentation",
        "Tumor Segmentation"
      ],
      "repo_urls": [
        "https://github.com/FETS-AI/Challenge",
        "https://github.com/FETS-AI/Front-End"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07400",
      "abstract": "Large language model (LLM) based agentic workflows have become a popular paradigm for coordinating multiple specialized agents to solve complex tasks. To improve serving efficiency, existing LLM systems employ prefix caching to reuse key-value (KV) tensors corresponding to agents' fixed prompts, thereby avoiding redundant computation across repeated invocations. However, current systems typically evict KV caches using a Least Recently Used (LRU) policy, which fails to anticipate future agent usage and often discards KV caches shortly before their reuse. This leads to frequent cache misses and substantial recomputation or swapping overhead. We present KVFlow, a workflow-aware KV cache management framework tailored for agentic workloads. KVFlow abstracts the agent execution schedule as an Agent Step Graph and assigns each agent a steps-to-execution value that estimates its temporal proximity to future activation. These values guide a fine-grained eviction policy at the KV node level, allowing KVFlow to preserve entries likely to be reused and efficiently manage shared prefixes in tree-structured caches. Moreover, KVFlow introduces a fully overlapped KV prefetching mechanism, which proactively loads required tensors from CPU to GPU in background threads for agents scheduled in the next step, thereby avoiding cache miss stalls during generation. Compared to SGLang with hierarchical radix cache, KVFlow achieves up to 1.83$\\times$ speedup for single workflows with large prompts, and up to 2.19$\\times$ speedup for scenarios with many concurrent workflows.",
      "authors": [
        "Zaifeng Pan",
        "Ajjkumar Patel",
        "Zhengding Hu",
        "Yipeng Shen",
        "Yue Guan",
        "Wan-Lu Li",
        "Lianhui Qin",
        "Yida Wang and Yufei Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:39:23+00:00",
          "link": "https://arxiv.org/abs/2507.07400v1",
          "size": "567kb",
          "version": "v1"
        }
      ],
      "title": "KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07400",
        "HTML": "https://arxiv.org/html/2507.07400v1",
        "PDF": "https://arxiv.org/pdf/2507.07400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the efficiency of LLM-based multi-agent workflows through prefix caching, which is unrelated to training data processing. It does not make a contribution to the preparation, generation, or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07722",
      "abstract": "Recent work has revisited the infamous task Name that dataset and established that in non-medical datasets, there is an underlying bias and achieved high Accuracies on the dataset origin task. In this work, we revisit the same task applied to popular open-source chest X-ray datasets. Medical images are naturally more difficult to release for open-source due to their sensitive nature, which has led to certain open-source datasets being extremely popular for research purposes. By performing the same task, we wish to explore whether dataset bias also exists in these datasets. % We deliberately try to increase the difficulty of the task by dataset transformations. We apply simple transformations of the datasets to try to identify bias. Given the importance of AI applications in medical imaging, it's vital to establish whether modern methods are taking shortcuts or are focused on the relevant pathology. We implement a range of different network architectures on the datasets: NIH, CheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more explainable research being performed in medical imaging and the creation of more open-source datasets in the medical domain. The corresponding code will be released upon acceptance.",
      "authors": [
        "Ethan Dack",
        "Chengliang Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.07722v1",
          "size": "999kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07722",
        "HTML": "https://arxiv.org/html/2507.07722v1",
        "PDF": "https://arxiv.org/pdf/2507.07722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding dataset bias in medical imaging specifically for chest X-ray datasets and does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18939",
      "abstract": "Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
      "authors": [
        "Rui An",
        "Yifeng Zhang",
        "Ziran Liang",
        "Wenqi Fan",
        "Yuxuan Liang",
        "Xuequn Shang",
        "Qing Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T15:40:01+00:00",
          "link": "https://arxiv.org/abs/2506.18939v1",
          "size": "1501kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:42:46+00:00",
          "link": "https://arxiv.org/abs/2506.18939v2",
          "size": "1505kb",
          "version": "v2"
        }
      ],
      "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18939",
        "HTML": "https://arxiv.org/html/2506.18939v2",
        "PDF": "https://arxiv.org/pdf/2506.18939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses efficient urban spatio-temporal prediction models and does not involve LLM training data processing or relevant data-engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02275",
      "abstract": "Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of \\citet{robinson1988root}, we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of \\citet{mackey2018orthogonal}. Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These \\emph{ACE} procedures use structure-agnostic cumulant estimators to achieve $r$-th order insensitivity to nuisance errors whenever the $(r+1)$-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.",
      "authors": [
        "Jikai Jin and Lester Mackey and Vasilis Syrgkanis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.02275v1",
          "size": "1310kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T00:09:56+00:00",
          "link": "https://arxiv.org/abs/2507.02275v2",
          "size": "1310kb",
          "version": "v2"
        }
      ],
      "title": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02275",
        "PDF": "https://arxiv.org/pdf/2507.02275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines structure-agnostic causal inference with a focus on treatment effect estimation and robustness, not involving LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07498",
      "abstract": "Enhancing reasoning capabilities remains a central focus in the LLM reasearch community. A promising direction involves requiring models to simulate code execution step-by-step to derive outputs for given inputs. However, as code is often designed for large-scale systems, direct application leads to over-reliance on complex data structures and algorithms, even for simple cases, resulting in overfitting to algorithmic patterns rather than core reasoning structures. To address this, we propose TeaR, which aims at teaching LLMs to reason better. TeaR leverages careful data curation and reinforcement learning to guide models in discovering optimal reasoning paths through code-related tasks, thereby improving general reasoning abilities. We conduct extensive experiments using two base models and three long-CoT distillation models, with model sizes ranging from 1.5 billion to 32 billion parameters, and across 17 benchmarks spanning Math, Knowledge, Code, and Logical Reasoning. The results consistently show significant performance improvements. Notably, TeaR achieves a 35.9% improvement on Qwen2.5-7B and 5.9% on R1-Distilled-7B.",
      "authors": [
        "Keqin Bao",
        "Nuo Chen",
        "Xiaoyuan Li",
        "Binyuan Hui",
        "Bowen Yu",
        "Fuli Feng",
        "Junyang Lin",
        "Xiangnan He",
        "Dayiheng Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:34:05+00:00",
          "link": "https://arxiv.org/abs/2507.07498v1",
          "size": "556kb",
          "version": "v1"
        }
      ],
      "title": "Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07498",
        "PDF": "https://arxiv.org/pdf/2507.07498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on using reinforcement learning to improve LLM reasoning abilities, discussing careful data curation but not explicitly contributing new methods or techniques for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07663",
      "abstract": "Drug Mechanism of Action (MoA) mainly investigates how drug molecules interact with cells, which is crucial for drug discovery and clinical application. Recently, deep learning models have been used to recognize MoA by relying on high-content and fluorescence images of cells exposed to various drugs. However, these methods focus on spatial characteristics while overlooking the temporal dynamics of live cells. Time-lapse imaging is more suitable for observing the cell response to drugs. Additionally, drug molecules can trigger cellular dynamic variations related to specific MoA. This indicates that the drug molecule modality may complement the image counterpart. This paper proposes MolCLIP, the first visual language model to combine microscopic cell video- and molecule-modalities. MolCLIP designs a molecule-auxiliary CLIP framework to guide video features in learning the distribution of the molecular latent space. Furthermore, we integrate a metric learning strategy with MolCLIP to optimize the aggregation of video features. Experimental results on the MitoDataset demonstrate that MolCLIP achieves improvements of 51.2% and 20.5% in mAP for drug identification and MoA recognition, respectively.",
      "authors": [
        "Fengqian Pang (1)",
        "Chunyue Lei (1)",
        "Hongfei Zhao (2)",
        "Chenghao Liu (3)",
        "Zhiqiang Xing (1)",
        "Huafeng Wang (1)",
        "and Chuyang Ye (3) ((1) North China University of Technology",
        "(2) Beijing Neusoft Medical Equipment CO.",
        "Ltd",
        "(3) Beijing Institute of Technology)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:38:54+00:00",
          "link": "https://arxiv.org/abs/2507.07663v1",
          "size": "633kb",
          "version": "v1"
        }
      ],
      "title": "MolCLIP: A Molecular-Auxiliary CLIP Framework for Identifying Drug Mechanism of Action Based on Time-Lapsed Mitochondrial Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07663",
        "PDF": "https://arxiv.org/pdf/2507.07663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a molecular-auxiliary framework for drug mechanism identification using visual language models, with no mention of LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07681",
      "abstract": "Remote renewable energy hubs (RREHs) for synthetic fuel production are engineering systems harvesting renewable energy where it is particularly abundant. They produce transportable synthetic fuels for export to distant load centers. This article aims to evaluate the production costs of different energy carriers, and includes a discussion on advantages and disadvantages in terms of technical performance. To do so, we extend the study of Berger et al., (2021) which focuses on methane (CH4) as energy carrier and introduce three new carriers: ammonia (NH3), hydrogen (H2) and methanol (CH3OH). The four different RREHs are located in the Algerian Sahara desert and must serve to the load center, Belgium, a constant electro-fuel demand of 10 TWh per year. The modelling and optimisation of these systems are performed using the modelling language GBOML (Graph-Based Optimisation Modelling Language). Our findings reveal that the three new RREHs, each with its respective carrier (ammonia, hydrogen, and methanol), are all more cost-effective than the methane-based system. Ammonia demonstrates the most favourable cost-to-energy exported ratio.",
      "authors": [
        "Antoine Larbanois",
        "Victor Dachet",
        "Antoine Dubois",
        "Rapha\\\"el Fonteneau and Damien Ernst"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:01:09+00:00",
          "link": "https://arxiv.org/abs/2507.07681v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "Ammonia, Methane, Hydrogen and Methanol Produced in Remote Renewable Energy Hubs: a Comparative Quantitative Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07681",
        "HTML": "https://arxiv.org/html/2507.07681v1",
        "PDF": "https://arxiv.org/pdf/2507.07681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates production costs for remote renewable energy hubs; it does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.04631",
      "abstract": "Migraine is a common but complex neurological disorder that doubles the lifetime risk of cryptogenic stroke (CS). However, this relationship remains poorly characterized, and few clinical guidelines exist to reduce this associated risk. We therefore propose a data-driven approach to extract probabilistically-independent sources from electronic health record (EHR) data and create a 10-year risk-predictive model for CS in migraine patients. These sources represent external latent variables acting on the causal graph constructed from the EHR data and approximate root causes of CS in our population. A random forest model trained on patient expressions of these sources demonstrated good accuracy (ROC 0.771) and identified the top 10 most predictive sources of CS in migraine patients. These sources revealed that pharmacologic interventions were the most important factor in minimizing CS risk in our population and identified a factor related to allergic rhinitis as a potential causative source of CS in migraine patients.",
      "authors": [
        "Joshua W. Betts",
        "John M. Still",
        "Thomas A. Lasko"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T16:19:41+00:00",
          "link": "https://arxiv.org/abs/2505.04631v1",
          "size": "935kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T20:12:12+00:00",
          "link": "https://arxiv.org/abs/2505.04631v2",
          "size": "1683kb",
          "version": "v2"
        }
      ],
      "title": "Cryptogenic stroke and migraine: using probabilistic independence and machine learning to uncover latent sources of disease from the electronic health record",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04631",
        "HTML": "https://arxiv.org/html/2505.04631v2",
        "PDF": "https://arxiv.org/pdf/2505.04631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is about using machine learning to uncover sources of disease from electronic health records; it makes no contribution to large language model training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.15543",
      "abstract": "This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \\textit{computational observations} and \\textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \\textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.",
      "authors": [
        "Hristo Papazov",
        "Nicolas Flammarion"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T15:17:03+00:00",
          "link": "https://arxiv.org/abs/2506.15543v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2506.15543v2",
          "size": "51kb",
          "version": "v2"
        }
      ],
      "title": "Learning Algorithms in the Limit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15543",
        "HTML": "https://arxiv.org/html/2506.15543v2",
        "PDF": "https://arxiv.org/pdf/2506.15543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the learnability of computable functions using computational observations and restricted input sources, without discussing LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07338",
      "abstract": "Double descent is a phenomenon of over-parameterized statistical models. Our goal is to view double descent from a Bayesian perspective. Over-parameterized models such as deep neural networks have an interesting re-descending property in their risk characteristics. This is a recent phenomenon in machine learning and has been the subject of many studies. As the complexity of the model increases, there is a U-shaped region corresponding to the traditional bias-variance trade-off, but then as the number of parameters equals the number of observations and the model becomes one of interpolation, the risk can become infinite and then, in the over-parameterized region, it re-descends -- the double descent effect. We show that this has a natural Bayesian interpretation. Moreover, we show that it is not in conflict with the traditional Occam's razor that Bayesian models possess, in that they tend to prefer simpler models when possible. We illustrate the approach with an example of Bayesian model selection in neural networks. Finally, we conclude with directions for future research.",
      "authors": [
        "Nick Polson",
        "Vadim Sokolov"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:47:26+00:00",
          "link": "https://arxiv.org/abs/2507.07338v1",
          "size": "229kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Double Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07338",
        "HTML": "https://arxiv.org/html/2507.07338v1",
        "PDF": "https://arxiv.org/pdf/2507.07338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Bayesian interpretation of double descent, a phenomenon observed in over-parameterized models, such as deep neural networks. It does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07417",
      "abstract": "A popular class of defenses against prompt injection attacks on large language models (LLMs) relies on fine-tuning the model to separate instructions and data, so that the LLM does not follow instructions that might be present with data. There are several academic systems and production-level implementations of this idea. We evaluate the robustness of this class of prompt injection defenses in the whitebox setting by constructing strong optimization-based attacks and showing that the defenses do not provide the claimed security properties. Specifically, we construct a novel attention-based attack algorithm for text-based LLMs and apply it to two recent whitebox defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks with success rates of up to 70% with modest increase in attacker budget in terms of tokens. Our findings make fundamental progress towards understanding the robustness of prompt injection defenses in the whitebox setting. We release our code and attacks at https://github.com/nishitvp/better_opts_attacks",
      "authors": [
        "Nishit V. Pandya",
        "Andrey Labunets",
        "Sicun Gao",
        "Earlence Fernandes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:20:53+00:00",
          "link": "https://arxiv.org/abs/2507.07417v1",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07417",
        "PDF": "https://arxiv.org/pdf/2507.07417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates prompt injection defenses for LLMs using architecture-aware attacks, focusing on security rather than training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10252",
      "abstract": "Zero-shot learning (ZSL) aims to recognize unseen classes without labeled training examples by leveraging class-level semantic descriptors such as attributes. A fundamental challenge in ZSL is semantic misalignment, where semantic-unrelated information involved in visual features introduce ambiguity to visual-semantic interaction. Unlike existing methods that suppress semantic-unrelated information post hoc either in the feature space or the model space, we propose addressing this issue at the input stage, preventing semantic-unrelated patches from propagating through the network. To this end, we introduce Semantically contextualized VIsual Patches (SVIP) for ZSL, a transformer-based framework designed to enhance visual-semantic alignment. Specifically, we propose a self-supervised patch selection mechanism that preemptively learns to identify semantic-unrelated patches in the input space. This is trained with the supervision from aggregated attention scores across all transformer layers, which estimate each patch's semantic score. As removing semantic-unrelated patches from the input sequence may disrupt object structure, we replace them with learnable patch embeddings. With initialization from word embeddings, we can ensure they remain semantically meaningful throughout feature extraction. Extensive experiments on ZSL benchmarks demonstrate that SVIP achieves state-of-the-art performance results while providing more interpretable and semantically rich feature representations. Code is available at https://github.com/uqzhichen/SVIP.",
      "authors": [
        "Zhi Chen and Zecheng Zhao and Jingcai Guo and Jingjing Li and Zi Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T10:59:51+00:00",
          "link": "https://arxiv.org/abs/2503.10252v1",
          "size": "1401kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:48:37+00:00",
          "link": "https://arxiv.org/abs/2503.10252v2",
          "size": "1170kb",
          "version": "v2"
        }
      ],
      "title": "SVIP: Semantically Contextualized Visual Patches for Zero-Shot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10252",
        "HTML": "https://arxiv.org/html/2503.10252v2",
        "PDF": "https://arxiv.org/pdf/2503.10252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on a self-supervised patch selection mechanism for zero-shot learning but does not make a significant contribution to processing LLM training data or involve data-engineering operations related to LLM training."
      },
      "tasks": [
        "Word Embeddings",
        "Zero-Shot Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07747",
      "abstract": "Integration of hyperspectral imaging into fluorescence-guided neurosurgery has the potential to improve surgical decision making by providing quantitative fluorescence measurements in real-time. Quantitative fluorescence requires paired spectral data in fluorescence (blue light) and reflectance (white light) mode. Blue and white image acquisition needs to be performed sequentially in a potentially dynamic surgical environment. A key component to the fluorescence quantification process is therefore the ability to find dense cross-modal image correspondences between two hyperspectral images taken under these drastically different lighting conditions. We address this challenge with the introduction of X-RAFT, a Recurrent All-Pairs Field Transforms (RAFT) optical flow model modified for cross-modal inputs. We propose using distinct image encoders for each modality pair, and fine-tune these in a self-supervised manner using flow-cycle-consistency on our neurosurgical hyperspectral data. We show an error reduction of 36.6% across our evaluation metrics when comparing to a naive baseline and 27.83% reduction compared to an existing cross-modal optical flow method (CrossRAFT). Our code and models will be made publicly available after the review process.",
      "authors": [
        "Charlie Budd",
        "Silv\\`ere S\\'egaud",
        "Matthew Elliot",
        "Graeme Stasiuk",
        "Yijing Xie",
        "Jonathan Shapey",
        "Tom Vercauteren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:25:29+00:00",
          "link": "https://arxiv.org/abs/2507.07747v1",
          "size": "7328kb",
          "version": "v1"
        }
      ],
      "title": "X-RAFT: Cross-Modal Non-Rigid Registration of Blue and White Light Neurosurgical Hyperspectral Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07747",
        "HTML": "https://arxiv.org/html/2507.07747v1",
        "PDF": "https://arxiv.org/pdf/2507.07747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a self-supervised fine-tuning technique for image registration in neurosurgical environments, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11719",
      "abstract": "In the digital era, users typically interact with diverse items across multiple domains (e.g., e-commerce, streaming platforms, and social networks), generating intricate heterogeneous interaction graphs. Leveraging multi-domain data can improve recommendation systems by enriching user insights and mitigating data sparsity in individual domains. However, integrating such multi-domain knowledge for cross-domain recommendation remains challenging due to inherent disparities in user behavior and item characteristics and the risk of negative transfer, where irrelevant or conflicting information from the source domains adversely impacts the target domain's performance. To tackle these challenges, we propose HAGO, a novel framework with \\textbf{H}eterogeneous \\textbf{A}daptive \\textbf{G}raph co\\textbf{O}rdinators, which dynamically integrates multi-domain graphs into a cohesive structure. HAGO adaptively adjusts the connections between coordinators and multi-domain graph nodes to enhance beneficial inter-domain interactions while alleviating negative transfer. Furthermore, we introduce a universal multi-domain graph pre-training strategy alongside HAGO to collaboratively learn high-quality node representations across domains. Being compatible with various graph-based models and pre-training techniques, HAGO demonstrates broad applicability and effectiveness. Extensive experiments show that our framework outperforms state-of-the-art methods in cross-domain recommendation scenarios, underscoring its potential for real-world applications. The source code is available at https://github.com/zhy99426/HAGO.",
      "authors": [
        "Hengyu Zhang",
        "Chunxu Shen",
        "Xiangguo Sun",
        "Jie Tan",
        "Yu Rong",
        "Chengzhi Piao",
        "Hong Cheng",
        "Lingling Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T15:50:53+00:00",
          "link": "https://arxiv.org/abs/2410.11719v1",
          "size": "1859kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:28:19+00:00",
          "link": "https://arxiv.org/abs/2410.11719v2",
          "size": "1448kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Graph Integration for Cross-Domain Recommendation via Heterogeneous Graph Coordinators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11719",
        "HTML": "https://arxiv.org/html/2410.11719v2",
        "PDF": "https://arxiv.org/pdf/2410.11719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on enhancing recommendation systems through adaptive graph integration methods and does not focus on LLM training data processing or creation."
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "repo_urls": [
        "https://github.com/sheldonresearch/ProG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07793",
      "abstract": "Out-of-distribution (OOD) detection is critical for ensuring the reliability of deep learning systems, particularly in safety-critical applications. Likelihood-based deep generative models have historically faced criticism for their unsatisfactory performance in OOD detection, often assigning higher likelihood to OOD data than in-distribution samples when applied to image data. In this work, we demonstrate that likelihood is not inherently flawed. Rather, several properties in the images space prohibit likelihood as a valid detection score. Given a sufficiently good likelihood estimator, specifically using the probability flow formulation of a diffusion model, we show that likelihood-based methods can still perform on par with state-of-the-art methods when applied in the representation space of pre-trained encoders. The code of our work can be found at $\\href{https://github.com/limchaos/Likelihood-OOD.git}{\\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.",
      "authors": [
        "Yifan Ding",
        "Arturas Aleksandraus",
        "Amirhossein Ahmadian",
        "Jonas Unger",
        "Fredrik Lindsten and Gabriel Eilertsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T14:30:41+00:00",
          "link": "https://arxiv.org/abs/2504.07793v1",
          "size": "2779kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:32:02+00:00",
          "link": "https://arxiv.org/abs/2504.07793v2",
          "size": "2780kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T09:51:02+00:00",
          "link": "https://arxiv.org/abs/2504.07793v3",
          "size": "1228kb",
          "version": "v3"
        }
      ],
      "title": "Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07793",
        "HTML": "https://arxiv.org/html/2504.07793v3",
        "PDF": "https://arxiv.org/pdf/2504.07793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses out-of-distribution detection using pre-trained encoders and representation modeling, without addressing LLM training data processing."
      },
      "tasks": [
        "Out-of-Distribution Detection",
        "Out of Distribution (OOD) Detection",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/limchaos/likelihood-ood"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05317",
      "abstract": "Generative diffusion models have received increasing attention in medical imaging, particularly in limited-angle computed tomography (LACT). Standard diffusion models achieve high-quality image reconstruction but require a large number of sampling steps during inference, resulting in substantial computational overhead. Although skip-sampling strategies have been proposed to improve efficiency, they often lead to loss of fine structural details. To address this issue, we propose a prior information embedding and wavelet feature fusion fast sampling diffusion model for LACT reconstruction. The PWD enables efficient sampling while preserving reconstruction fidelity in LACT, and effectively mitigates the degradation typically introduced by skip-sampling. Specifically, during the training phase, PWD maps the distribution of LACT images to that of fully sampled target images, enabling the model to learn structural correspondences between them. During inference, the LACT image serves as an explicit prior to guide the sampling trajectory, allowing for high-quality reconstruction with significantly fewer steps. In addition, PWD performs multi-scale feature fusion in the wavelet domain, effectively enhancing the reconstruction of fine details by leveraging both low-frequency and high-frequency information. Quantitative and qualitative evaluations on clinical dental arch CBCT and periapical datasets demonstrate that PWD outperforms existing methods under the same sampling condition. Using only 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and 10% gain in SSIM.",
      "authors": [
        "Yi Liu and Yiyang Wen and Zekun Zhou and Junqi Ma and Linghang Wang and Yucheng Yao and Liu Shi and Qiegen Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:28:32+00:00",
          "link": "https://arxiv.org/abs/2507.05317v1",
          "size": "64612kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:01:10+00:00",
          "link": "https://arxiv.org/abs/2507.05317v2",
          "size": "19513kb",
          "version": "v2"
        }
      ],
      "title": "PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05317",
        "HTML": "https://arxiv.org/html/2507.05317v2",
        "PDF": "https://arxiv.org/pdf/2507.05317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving diffusion model efficiency for medical image reconstruction and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07237",
      "abstract": "Data driven approaches have the potential to make modeling complex, nonlinear physical phenomena significantly more computationally tractable. For example, computational modeling of fracture is a core challenge where machine learning techniques have the potential to provide a much needed speedup that would enable progress in areas such as mutli-scale modeling and uncertainty quantification. Currently, phase field modeling (PFM) of fracture is one such approach that offers a convenient variational formulation to model crack nucleation, branching and propagation. To date, machine learning techniques have shown promise in approximating PFM simulations. However, most studies rely on overly simple benchmarks that do not reflect the true complexity of the fracture processes where PFM excels as a method. To address this gap, we introduce a challenging dataset based on PFM simulations designed to benchmark and advance ML methods for fracture modeling. This dataset includes three energy decomposition methods, two boundary conditions, and 1,000 random initial crack configurations for a total of 6,000 simulations. Each sample contains 100 time steps capturing the temporal evolution of the crack field. Alongside this dataset, we also implement and evaluate Physics Informed Neural Networks (PINN), Fourier Neural Operators (FNO) and UNet models as baselines, and explore the impact of ensembling strategies on prediction accuracy. With this combination of our dataset and baseline models drawn from the literature we aim to provide a standardized and challenging benchmark for evaluating machine learning approaches to solid mechanics. Our results highlight both the promise and limitations of popular current models, and demonstrate the utility of this dataset as a testbed for advancing machine learning in fracture mechanics research.",
      "authors": [
        "Erfan Hamdi",
        "Emma Lejeune"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:14:56+00:00",
          "link": "https://arxiv.org/abs/2507.07237v1",
          "size": "8910kb",
          "version": "v1"
        }
      ],
      "title": "Towards Robust Surrogate Models: Benchmarking Machine Learning Approaches to Expediting Phase Field Simulations of Brittle Fracture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07237",
        "HTML": "https://arxiv.org/html/2507.07237v1",
        "PDF": "https://arxiv.org/pdf/2507.07237"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new dataset for benchmarking ML models, it focuses more on evaluating models in fracture mechanics rather than LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07509",
      "abstract": "The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets.",
      "authors": [
        "Yuanchen Shi",
        "Longyin Zhang and Fang Kong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:56:35+00:00",
          "link": "https://arxiv.org/abs/2507.07509v1",
          "size": "1814kb",
          "version": "v1"
        }
      ],
      "title": "Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07509",
        "HTML": "https://arxiv.org/html/2507.07509v1",
        "PDF": "https://arxiv.org/pdf/2507.07509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses the creation of the CPsDD dataset and detailed data processing for psychological support dialogues, specifically addressing data generation and modification for fine-tuning LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07585",
      "abstract": "Floods are among the most frequent natural hazards and cause significant social and economic damage. Timely, large-scale information on flood extent and depth is essential for disaster response; however, existing products often trade spatial detail for coverage or ignore flood depth altogether. To bridge this gap, this work presents HOTA: Hierarchical Overlap-Tiling Aggregation, a plug-and-play, multi-scale inference strategy. When combined with SegFormer and a dual-constraint depth estimation module, this approach forms a complete 3D flood-mapping pipeline. HOTA applies overlapping tiles of different sizes to multispectral Sentinel-2 images only during inference, enabling the SegFormer model to capture both local features and kilometre-scale inundation without changing the network weights or retraining. The subsequent depth module is based on a digital elevation model (DEM) differencing method, which refines the 2D mask and estimates flood depth by enforcing (i) zero depth along the flood boundary and (ii) near-constant flood volume with respect to the DEM. A case study on the March 2021 Kempsey (Australia) flood shows that HOTA, when coupled with SegFormer, improves IoU from 73\\% (U-Net baseline) to 84\\%. The resulting 3D surface achieves a mean absolute boundary error of less than 0.5 m. These results demonstrate that HOTA can produce accurate, large-area 3D flood maps suitable for rapid disaster response.",
      "authors": [
        "Wenfeng Jia",
        "Bin Liang",
        "Yuxi Lu",
        "Attavit Wilaiwongsakul",
        "Muhammad Arif Khan",
        "Lihong Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:40:20+00:00",
          "link": "https://arxiv.org/abs/2507.07585v1",
          "size": "6494kb",
          "version": "v1"
        }
      ],
      "title": "HOTA: Hierarchical Overlap-Tiling Aggregation for Large-Area 3D Flood Mapping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07585",
        "HTML": "https://arxiv.org/html/2507.07585v1",
        "PDF": "https://arxiv.org/pdf/2507.07585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on flood mapping techniques using multispectral images, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.19204",
      "abstract": "Incorporating cloud technology with Internet of Medical Things for ubiquitous healthcare has seen many successful applications in the last decade with the advent of machine learning and deep learning techniques. One of these applications, namely voice-based pathology, has yet to receive notable attention from academia and industry. Applying voice analysis to early detection of fatal diseases holds much promise to improve health outcomes and quality of life of patients. In this paper, we propose a novel application of acoustic machine learning based triaging into commoditised conversational virtual assistant systems to pre-screen for onset of diabetes. Specifically, we developed a triaging system which extracts acoustic features from the voices of n=24 older adults when they converse with a virtual assistant and predict the incidence of Diabetes Mellitus (Type 2) or not. Our triaging system achieved hit-rates of 70% and 60% for male and female older adult subjects, respectively. Our proposed triaging uses 7 non-identifiable voice-based features and can operate within resource-constrained embedded systems running voice-based virtual assistants. This application demonstrates the feasibility of applying voice-based pathology analysis to improve health outcomes of older adults within the home environment by early detection of life-changing chronic conditions like diabetes.",
      "authors": [
        "Kelvin Summoogum",
        "Debayan Das",
        "Sathish Kumaran",
        "Sumit Bhagra (MD)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T15:23:48+00:00",
          "link": "https://arxiv.org/abs/2411.19204v1",
          "size": "550kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:01:50+00:00",
          "link": "https://arxiv.org/abs/2411.19204v2",
          "size": "683kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:28:37+00:00",
          "link": "https://arxiv.org/abs/2411.19204v3",
          "size": "683kb",
          "version": "v3"
        }
      ],
      "title": "A Voice-based Triage for Type 2 Diabetes using a Conversational Virtual Assistant in the Home Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19204",
        "PDF": "https://arxiv.org/pdf/2411.19204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a voice-based triage system for type 2 diabetes using a virtual assistant, focusing on voice analysis rather than LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05689",
      "abstract": "We propose GoalFlow, an end-to-end autonomous driving method for generating high-quality multimodal trajectories. In autonomous driving scenarios, there is rarely a single suitable trajectory. Recent methods have increasingly focused on modeling multimodal trajectory distributions. However, they suffer from trajectory selection complexity and reduced trajectory quality due to high trajectory divergence and inconsistencies between guidance and scene information. To address these issues, we introduce GoalFlow, a novel method that effectively constrains the generative process to produce high-quality, multimodal trajectories. To resolve the trajectory divergence problem inherent in diffusion-based methods, GoalFlow constrains the generated trajectories by introducing a goal point. GoalFlow establishes a novel scoring mechanism that selects the most appropriate goal point from the candidate points based on scene information. Furthermore, GoalFlow employs an efficient generative method, Flow Matching, to generate multimodal trajectories, and incorporates a refined scoring mechanism to select the optimal trajectory from the candidates. Our experimental results, validated on the Navsim\\cite{Dauner2024_navsim}, demonstrate that GoalFlow achieves state-of-the-art performance, delivering robust multimodal trajectories for autonomous driving. GoalFlow achieved PDMS of 90.3, significantly surpassing other methods. Compared with other diffusion-policy-based methods, our approach requires only a single denoising step to obtain excellent performance. The code is available at https://github.com/YvanYin/GoalFlow.",
      "authors": [
        "Zebin Xing",
        "Xingyu Zhang",
        "Yang Hu",
        "Bo Jiang",
        "Tong He",
        "Qian Zhang",
        "Xiaoxiao Long",
        "Wei Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T18:52:08+00:00",
          "link": "https://arxiv.org/abs/2503.05689v1",
          "size": "3360kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T06:04:44+00:00",
          "link": "https://arxiv.org/abs/2503.05689v2",
          "size": "3360kb",
          "version": "v2"
        },
        {
          "date": "2025-03-13T09:40:27+00:00",
          "link": "https://arxiv.org/abs/2503.05689v3",
          "size": "3358kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T07:11:30+00:00",
          "link": "https://arxiv.org/abs/2503.05689v4",
          "size": "5172kb",
          "version": "v4"
        }
      ],
      "title": "GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05689",
        "HTML": "https://arxiv.org/html/2503.05689v4",
        "PDF": "https://arxiv.org/pdf/2503.05689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses generating multimodal trajectories for autonomous driving, which does not pertain to LLM training data."
      },
      "models": [
        {
          "model_path": "XXXXing/GoalFlow",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/XXXXing/GoalFlow"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Xing_GoalFlow_Goal-Driven_Flow_Matching_for_Multimodal_Trajectories_Generation_in_End-to-End_CVPR_2025_paper.html",
      "tasks": [
        "Autonomous Driving",
        "Denoising",
        "NavSim"
      ],
      "repo_urls": [
        "https://github.com/yvanyin/goalflow"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05075",
      "abstract": "Flexible bandwidth needlets offer a versatile multiscale framework for analyzing functions on the sphere. A key element in their construction is the dilation sequence, which controls how the multipole consecutive scales are spaced and overlapped. At any resolution level, this sequence determines the center positions of the needlet weight functions and influences their localization in the spatial domain and spectral concentration properties by means of the relative bandwidth ratio. In this paper, we explore the different asymptotic regimes that arise when the dilation sequence exhibits shrinking, stable (standard), or spreading behavior. Moreover, we assume the dilation sequence grows regularly enough to ensure well-defined asymptotic properties. For each regime, we characterize the impact on the geometry of the center scales and the shape of the multipole windows, with particular attention to their overlap structure and spectral coverage. These insights help to clarify the trade-offs between localization, redundancy, and scalability in the design of needlet-type systems, particularly in relation to the study of the asymptotic uncorrelation of needlet coefficients when applied to random fields.",
      "authors": [
        "Claudio Durastanti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:03:04+00:00",
          "link": "https://arxiv.org/abs/2507.05075v1",
          "size": "87kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:07:26+00:00",
          "link": "https://arxiv.org/abs/2507.05075v2",
          "size": "87kb",
          "version": "v2"
        }
      ],
      "title": "Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05075",
        "HTML": "https://arxiv.org/html/2507.05075v2",
        "PDF": "https://arxiv.org/pdf/2507.05075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is concerned with the mathematical framework of flexible bandwidth needlet constructions, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07362",
      "abstract": "SRL, defined as learners' ability to systematically plan, monitor, and regulate their learning activities, is crucial for sustained academic achievement and lifelong learning competencies. Emerging Artificial Intelligence (AI) developments profoundly influence SRL interactions by potentially either diminishing or strengthening learners' opportunities to exercise their own regulatory skills. Recent literature emphasizes a balanced approach termed Hybrid Human-AI Regulated Learning (HHAIRL), in which AI provides targeted, timely scaffolding while preserving the learners' role as active decision-makers and reflective monitors of their learning process. Nevertheless, existing digital tools frequently fall short, lacking adaptability, focusing narrowly on isolated SRL phases, and insufficiently support meaningful human-AI interactions. In response, this paper introduces the enhanced \\flora Engine, which incorporates advanced Generative Artificial Intelligence (GenAI) features and state-of-the-art learning analytics, explicitly grounded in SRL and HHAIRL theories. The \\flora Engine offers instrumentation tools such as collaborative writing, multi-agents chatbot, and detailed learning trace logging to support dynamic, adaptive scaffolding tailored to individual needs in real time. We further present a summary of several research studies that provide the validations for and illustrate how these instrumentation tools can be utilized in real-world educational and experimental contexts. These studies demonstrate the effectiveness of \\flora Engine in fostering SRL and HHAIRL, providing both theoretical insights and practical solutions for the future of AI-enhanced learning context.",
      "authors": [
        "Xinyu Li and Tongguang Li and Lixiang Yan and Yuheng Li and Linxuan Zhao and Mladen Rakovi\\'c and Inge Molenaar and Dragan Ga\\v{s}evi\\'c and Yizhou Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:11:52+00:00",
          "link": "https://arxiv.org/abs/2507.07362v1",
          "size": "16820kb",
          "version": "v1"
        }
      ],
      "title": "FLoRA: An Advanced AI-Powered Engine to Facilitate Hybrid Human-AI Regulated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07362",
        "HTML": "https://arxiv.org/html/2507.07362v1",
        "PDF": "https://arxiv.org/pdf/2507.07362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a learning engine focused on AI-regulated learning, without discussing or contributing to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07879",
      "abstract": "Deep learning-based machine listening is broadening the scope of industrial acoustic analysis for applications like anomaly detection and predictive maintenance, thereby improving manufacturing efficiency and reliability. Nevertheless, its reliance on large, task-specific annotated datasets for every new task limits widespread implementation on shop floors. While emerging sound foundation models aim to alleviate data dependency, they are too large and computationally expensive, requiring cloud infrastructure or high-end hardware that is impractical for on-site, real-time deployment. We address this gap with LISTEN (Lightweight Industrial Sound-representable Transformer for Edge Notification), a kilobyte-sized industrial sound foundation model. Using knowledge distillation, LISTEN runs in real-time on low-cost edge devices. On benchmark downstream tasks, it performs nearly identically to its much larger parent model, even when fine-tuned with minimal datasets and training resource. Beyond the model itself, we demonstrate its real-world utility by integrating LISTEN into a complete machine monitoring framework on an edge device with an Industrial Internet of Things (IIoT) sensor and system, validating its performance and generalization capabilities on a live manufacturing shop floor.",
      "authors": [
        "Changheon Han",
        "Yun Seok Kang",
        "Yuseop Sim",
        "Martin Byung-Guk Jun",
        "and Hyung Wook Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:02:50+00:00",
          "link": "https://arxiv.org/abs/2507.07879v1",
          "size": "6370kb",
          "version": "v1"
        }
      ],
      "title": "LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07879",
        "PDF": "https://arxiv.org/pdf/2507.07879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a lightweight sound foundation model using knowledge distillation, not on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.14937",
      "abstract": "Creating secure and resilient applications with large language models (LLM) requires anticipating, adjusting to, and countering unforeseen threats. Red-teaming has emerged as a critical technique for identifying vulnerabilities in real-world LLM implementations. This paper presents a detailed threat model and provides a systematization of knowledge (SoK) of red-teaming attacks on LLMs. We develop a taxonomy of attacks based on the stages of the LLM development and deployment process and extract various insights from previous research. In addition, we compile methods for defense and practical red-teaming strategies for practitioners. By delineating prominent attack motifs and shedding light on various entry points, this paper provides a framework for improving the security and robustness of LLM-based systems.",
      "authors": [
        "Apurv Verma",
        "Satyapriya Krishna",
        "Sebastian Gehrmann",
        "Madhavan Seshadri",
        "Anu Pradhan",
        "Tom Ault",
        "Leslie Barrett",
        "David Rabinowitz",
        "John Doucette",
        "NhatHai Phan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-20T17:05:04+00:00",
          "link": "https://arxiv.org/abs/2407.14937v1",
          "size": "10150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:58:36+00:00",
          "link": "https://arxiv.org/abs/2407.14937v2",
          "size": "10546kb",
          "version": "v2"
        }
      ],
      "title": "Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.14937",
        "PDF": "https://arxiv.org/pdf/2407.14937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses security and red-teaming strategies for LLMs without addressing training data processing or dataset creation."
      },
      "tasks": [
        "Red Teaming"
      ],
      "repo_urls": [
        "https://github.com/dapurv5/awesome-red-teaming-llms"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07745",
      "abstract": "Despite their recent introduction to human society, Large Language Models (LLMs) have significantly affected the way we tackle mental challenges in our everyday lives. From optimizing our linguistic communication to assisting us in making important decisions, LLMs, such as ChatGPT, are notably reducing our cognitive load by gradually taking on an increasing share of our mental activities. In the context of Learning by Demonstration (LbD), classifying and segmenting complex motions into primitive actions, such as pushing, pulling, twisting etc, is considered to be a key-step towards encoding a task. In this work, we investigate the capabilities of LLMs to undertake this task, considering a finite set of predefined primitive actions found in fruit picking operations. By utilizing LLMs instead of simple supervised learning or analytic methods, we aim at making the method easily applicable and deployable in a real-life scenario. Three different fine-tuning approaches are investigated, compared on datasets captured kinesthetically, using a UR10e robot, during a fruit-picking scenario.",
      "authors": [
        "Eleni Konstantinidou",
        "Nikolaos Kounalakis",
        "Nikolaos Efstathopoulos and Dimitrios Papageorgiou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:25:18+00:00",
          "link": "https://arxiv.org/abs/2507.07745v1",
          "size": "1131kb",
          "version": "v1"
        }
      ],
      "title": "On the capabilities of LLMs for classifying and segmenting time series of fruit picking motions into primitive actions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07745",
        "HTML": "https://arxiv.org/html/2507.07745v1",
        "PDF": "https://arxiv.org/pdf/2507.07745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses fine-tuning LLMs for classifying actions in fruit picking, it does not focus on LLM training-data processing but rather on downstream application; thus, its contribution is not centered on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07539",
      "abstract": "This paper presents a competitive approach to multilingual subjectivity detection using large language models (LLMs) with few-shot prompting. We participated in Task 1: Subjectivity of the CheckThat! 2025 evaluation campaign. We show that LLMs, when paired with carefully designed prompts, can match or outperform fine-tuned smaller language models (SLMs), particularly in noisy or low-quality data settings. Despite experimenting with advanced prompt engineering techniques, such as debating LLMs and various example selection strategies, we found limited benefit beyond well-crafted standard few-shot prompts. Our system achieved top rankings across multiple languages in the CheckThat! 2025 subjectivity detection task, including first place in Arabic and Polish, and top-four finishes in Italian, English, German, and multilingual tracks. Notably, our method proved especially robust on the Arabic dataset, likely due to its resilience to annotation inconsistencies. These findings highlight the effectiveness and adaptability of LLM-based few-shot learning for multilingual sentiment tasks, offering a strong alternative to traditional fine-tuning, particularly when labeled data is scarce or inconsistent.",
      "authors": [
        "Akram Elbouanani",
        "Evan Dufraisse",
        "Aboubacar Tuo",
        "Adrian Popescu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:35:05+00:00",
          "link": "https://arxiv.org/abs/2507.07539v1",
          "size": "197kb",
          "version": "v1"
        }
      ],
      "title": "CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07539",
        "HTML": "https://arxiv.org/html/2507.07539v1",
        "PDF": "https://arxiv.org/pdf/2507.07539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it discusses subjectivity detection tasks using LLMs, the paper does not focus on LLM training data processing or creation. It examines prompt design for language models rather than engineering or enhancing training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07700",
      "abstract": "Text embeddings are fundamental to many natural language processing (NLP) tasks, extensively applied in domains such as recommendation systems and information retrieval (IR). Traditionally, transmitting embeddings instead of raw text has been seen as privacy-preserving. However, recent methods such as Vec2Text challenge this assumption by demonstrating that controlled decoding can successfully reconstruct original texts from black-box embeddings. The unexpectedly strong results reported by Vec2Text motivated us to conduct further verification, particularly considering the typically non-intuitive and opaque structure of high-dimensional embedding spaces. In this work, we reproduce the Vec2Text framework and evaluate it from two perspectives: (1) validating the original claims, and (2) extending the study through targeted experiments. First, we successfully replicate the original key results in both in-domain and out-of-domain settings, with only minor discrepancies arising due to missing artifacts, such as model checkpoints and dataset splits. Furthermore, we extend the study by conducting a parameter sensitivity analysis, evaluating the feasibility of reconstructing sensitive inputs (e.g., passwords), and exploring embedding quantization as a lightweight privacy defense. Our results show that Vec2Text is effective under ideal conditions, capable of reconstructing even password-like sequences that lack clear semantics. However, we identify key limitations, including its sensitivity to input sequence length. We also find that Gaussian noise and quantization techniques can mitigate the privacy risks posed by Vec2Text, with quantization offering a simpler and more widely applicable solution. Our findings emphasize the need for caution in using text embeddings and highlight the importance of further research into robust defense mechanisms for NLP systems.",
      "authors": [
        "Dominykas Seputis",
        "Yongkang Li",
        "Karsten Langerak",
        "Serghei Mihailov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:27:03+00:00",
          "link": "https://arxiv.org/abs/2507.07700v1",
          "size": "750kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking the Privacy of Text Embeddings: A Reproducibility Study of \"Text Embeddings Reveal (Almost) As Much As Text\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07700",
        "HTML": "https://arxiv.org/html/2507.07700v1",
        "PDF": "https://arxiv.org/pdf/2507.07700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper examines privacy risks in text embeddings, conducting experiments on reconstruction but primarily focuses on evaluating the Vec2Text framework rather than processing training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20160",
      "abstract": "Control engineering is a highly developed field, which includes similarly advanced areas like system identification. In structural dynamics, system identification methods are employed for the extraction of modal parameters, such as natural frequencies and mode shapes, from any structure. In turn, these are the main building blocks of vibration-based damage detection. However, traditional comparisons of these parameters are often ambiguous in complex systems, complicating damage detection and assessment. The modified total modal assurance criterion (MTMAC), a metric well-known in the field of finite element model updating, is extended to address this challenge and is proposed as a metric for damage identification and severity assessment. To support the requirement for precise and robust modal identification of Structural Health Monitoring (SHM), the improved Loewner Framework (iLF), known for its reliability and computational performance, is pioneeringly employed within SHM. Since the MTMAC is proposed solely as a damage identification and severity assessment metric, the coordinate modal assurance criterion (COMAC), also a well-established tool, but for damage localisation using mode shapes, is used for completeness. The iLF SHM capabilities are validated through comparisons with traditional methods, including least-squares complex exponential (LSCE) and stochastic subspace identification with canonical variate analysis (SSI-CVA) on a numerical case study of a cantilever beam. Furthermore, the MTMAC is validated against the traditional vibration-based approach, which involves directly comparing natural frequencies and mode shapes. Finally, an experimental dataset from a BAE Systems Hawk T1A trainer jet ground vibration tests is used to demonstrate the iLF and MTMAC capabilities on a real-life, real-size SHM problem, showing their effectiveness in detecting and assessing damage.",
      "authors": [
        "Gabriele Dessena",
        "Marco Civera",
        "Andr\\'es Marcos",
        "Bernardino Chiaia and Oscar E. Bonilla-Manrique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T12:22:14+00:00",
          "link": "https://arxiv.org/abs/2410.20160v1",
          "size": "6575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:49:12+00:00",
          "link": "https://arxiv.org/abs/2410.20160v2",
          "size": "6767kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T13:21:14+00:00",
          "link": "https://arxiv.org/abs/2410.20160v3",
          "size": "6384kb",
          "version": "v3"
        }
      ],
      "title": "Vibration-based damage detection of a trainer jet via multiple input tangential interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20160",
        "HTML": "https://arxiv.org/html/2410.20160v3",
        "PDF": "https://arxiv.org/pdf/2410.20160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses damage detection in structural dynamics and does not focus on LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Cantilever Beam",
        "Structural Health Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.19287",
      "abstract": "The paper presents an innovative approach to address the challenges of scalability and reliability in Distributed Federated Learning by leveraging the integration of blockchain technology. The paper focuses on enhancing the trustworthiness of participating nodes through a trust penalization mechanism while also enabling asynchronous functionality for efficient and robust model updates. By combining Semi-Decentralized Federated Learning with Blockchain (SDFL-B), the proposed system aims to create a fair, secure and transparent environment for collaborative machine learning without compromising data privacy. The research presents a comprehensive system architecture, methodologies, experimental results, and discussions that demonstrate the advantages of this novel approach in fostering scalable and reliable SDFL-B systems.",
      "authors": [
        "Ajay Kumar Shrestha",
        "Faijan Ahamad Khan",
        "Mohammed Afaan Shaikh",
        "Amir Jaberzadeh and Jason Geng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-30T06:05:50+00:00",
          "link": "https://arxiv.org/abs/2310.19287v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Scalability and Reliability in Semi-Decentralized Federated Learning With Blockchain: Trust Penalization and Asynchronous Functionality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.19287",
        "PDF": "https://arxiv.org/pdf/2310.19287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and blockchain integration to improve scalability and reliability, without addressing LLM training data processing."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04426",
      "abstract": "Large Language Models (LLMs) are increasingly embedded in workflows that involve evaluative processes. This raises the need to examine how such evaluations are built, what assumptions they rely on, and how their strategies diverge from those of humans. We benchmark six LLMs against expert ratings--NewsGuard and Media Bias/Fact Check (MBFC)--and against human judgments collected through a controlled experiment. To enable direct comparison, we implement a structured agentic framework in which both models and non-expert participants follow the same evaluation procedure: selecting criteria, retrieving content, and producing justifications. Despite output alignment, LLMs rely on different mechanisms: lexical associations and statistical priors replace contextual reasoning. This reliance produces systematic effects: political asymmetries, opaque justifications, and a tendency to confuse linguistic form with epistemic validity. Delegating judgment to such systems does not merely automate evaluation--it redefines it, shifting from normative reasoning to pattern-based approximation.",
      "authors": [
        "Edoardo Loru",
        "Jacopo Nudo",
        "Niccol\\`o Di Marco",
        "Alessandro Santirocchi",
        "Roberto Atzeni",
        "Matteo Cinelli",
        "Vincenzo Cestari",
        "Clelia Rossi-Arnaud",
        "Walter Quattrociocchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T18:52:10+00:00",
          "link": "https://arxiv.org/abs/2502.04426v1",
          "size": "761kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:31:21+00:00",
          "link": "https://arxiv.org/abs/2502.04426v2",
          "size": "2007kb",
          "version": "v2"
        }
      ],
      "title": "Decoding AI Judgment: How LLMs Assess News Credibility and Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04426",
        "HTML": "https://arxiv.org/html/2502.04426v2",
        "PDF": "https://arxiv.org/pdf/2502.04426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper assesses LLMs in evaluating news credibility and bias, without discussing any aspect of training data processing for LLMs."
      },
      "tasks": [
        "Fact Checking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17568",
      "abstract": "Survival analysis often relies on Cox models, assuming both linearity and proportional hazards (PH). This study evaluates machine and deep learning methods that relax these constraints, comparing their performance with penalized Cox models on a benchmark of three synthetic and three real datasets. In total, eight different models were tested, including six non-linear models of which four were also non-PH. Although Cox regression often yielded satisfactory performance, we showed the conditions under which machine and deep learning models can perform better. Indeed, the performance of these methods has often been underestimated due to the improper use of Harrell's concordance index (C-index) instead of more appropriate scores such as Antolini's concordance index, which generalizes C-index in cases where the PH assumption does not hold. In addition, since occasionally high C-index models happen to be badly calibrated, combining Antolini's C-index with Brier's score is useful to assess the overall performance of a survival method. Results on our benchmark data showed that survival prediction should be approached by testing different methods to select the most appropriate one according to sample size, non-linearity and non-PH conditions. To allow an easy reproducibility of these tests on our benchmark data, code and documentation are freely available at https://github.com/compbiomed-unito/survhive.",
      "authors": [
        "Ivan Rossi",
        "Flavio Sartori",
        "Cesare Rollo",
        "Giovanni Birolo",
        "Piero Fariselli",
        "Tiziana Sanavia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T13:58:07+00:00",
          "link": "https://arxiv.org/abs/2504.17568v1",
          "size": "83kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:58:59+00:00",
          "link": "https://arxiv.org/abs/2504.17568v2",
          "size": "83kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Cox Models: Assessing the Performance of Machine-Learning Methods in Non-Proportional Hazards and Non-Linear Survival Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17568",
        "HTML": "https://arxiv.org/html/2504.17568v2",
        "PDF": "https://arxiv.org/pdf/2504.17568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on evaluating machine and deep learning methods in survival analysis and does not involve processing LLM training data."
      },
      "tasks": [
        "Survival Analysis",
        "Survival Prediction"
      ],
      "repo_urls": [
        "https://github.com/compbiomed-unito/survhive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11329",
      "abstract": "Distributed inference of large language models (LLMs) can introduce overheads of up to 20% even over GPUs connected via high-speed interconnects such as NVLink. Multiple techniques have been proposed to mitigate these overheads by decomposing computations into finer-grained tasks and overlapping communication with sub-tasks as they complete. However, fine-grained decomposition of a large computation into many smaller computations on GPUs results in overheads. Furthermore, the communication itself uses many streaming multiprocessors (SMs), adding to the overhead.\n  We present TokenWeave to address these challenges. TokenWeave proposes a Token-Splitting technique that divides the tokens in the inference batch into two approximately equal subsets in a wave-aware manner. The communication of one subset is then overlapped with the computation of the other. In addition, TokenWeave optimizes the order of the layer normalization computation with respect to communication operations and implements a novel fused AllReduce--RMSNorm kernel that carefully leverages Multimem instruction support available on NVIDIA Hopper GPUs. These optimizations allow TokenWeave to perform communication and RMSNorm using only 2-8 SMs. Moreover, our kernel enables the memory-bound RMSNorm to be overlapped with the other batch's computation, providing additional gains.\n  Our evaluations demonstrate up to 1.29x speedup in latency and 1.26x higher throughput across multiple models and workloads. In several settings, TokenWeave results in better performance compared to an equivalent model with all communication removed.",
      "authors": [
        "Raja Gond",
        "Nipun Kwatra",
        "Ramachandran Ramjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T14:53:50+00:00",
          "link": "https://arxiv.org/abs/2505.11329v1",
          "size": "527kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:40:35+00:00",
          "link": "https://arxiv.org/abs/2505.11329v2",
          "size": "620kb",
          "version": "v2"
        }
      ],
      "title": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11329",
        "HTML": "https://arxiv.org/html/2505.11329v2",
        "PDF": "https://arxiv.org/pdf/2505.11329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a technique for optimizing compute-communication overlap in LLM inference rather than processing LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.01788",
      "abstract": "Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60\\%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.",
      "authors": [
        "Montasir Shams",
        "Chashi Mahiul Islam",
        "Shaeke Salman",
        "Phat Tran",
        "Xiuwen Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:14:06+00:00",
          "link": "https://arxiv.org/abs/2507.01788v1",
          "size": "4186kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:23:29+00:00",
          "link": "https://arxiv.org/abs/2507.01788v2",
          "size": "4186kb",
          "version": "v2"
        }
      ],
      "title": "Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01788",
        "PDF": "https://arxiv.org/pdf/2507.01788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the semantic meaningfulness of Vision Transformer representations in medical imaging, addressing model vulnerabilities rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07126",
      "abstract": "PET-CT lesion segmentation is challenging due to noise sensitivity, small and variable lesion morphology, and interference from physiological high-metabolic signals. Current mainstream approaches follow the practice of one network solving the segmentation of multiple cancer lesions by treating all cancers as a single task. However, this overlooks the unique characteristics of different cancer types. Considering the specificity and similarity of different cancers in terms of metastatic patterns, organ preferences, and FDG uptake intensity, we propose DpDNet, a Dual-Prompt-Driven network that incorporates specific prompts to capture cancer-specific features and common prompts to retain shared knowledge. Additionally, to mitigate information forgetting caused by the early introduction of prompts, prompt-aware heads are employed after the decoder to adaptively handle multiple segmentation tasks. Experiments on a PET-CT dataset with four cancer types show that DpDNet outperforms state-of-the-art models. Finally, based on the segmentation results, we calculated MTV, TLG, and SUVmax for breast cancer survival analysis. The results suggest that DpDNet has the potential to serve as a valuable tool for personalized risk stratification, supporting clinicians in optimizing treatment strategies and improving outcomes. Code is available at https://github.com/XinglongLiang08/DpDNet.",
      "authors": [
        "Xinglong Liang",
        "Jiaju Huang",
        "Luyi Han",
        "Tianyu Zhang",
        "Xin Wang",
        "Yuan Gao",
        "Chunyao Lu",
        "Lishan Cai",
        "Tao Tan and Ritse Mann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:56:01+00:00",
          "link": "https://arxiv.org/abs/2507.07126v1",
          "size": "1553kb",
          "version": "v1"
        }
      ],
      "title": "DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07126",
        "HTML": "https://arxiv.org/html/2507.07126v1",
        "PDF": "https://arxiv.org/pdf/2507.07126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on PET-CT segmentation using a dual-prompt-driven network, which involves model innovation and application in medical imaging, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07826",
      "abstract": "Learning from non-independent and non-identically distributed data poses a persistent challenge in statistical learning. In this study, we introduce data-dependent Bernstein inequalities tailored for vector-valued processes in Hilbert space. Our inequalities apply to both stationary and non-stationary processes and exploit the potential rapid decay of correlations between temporally separated variables to improve estimation. We demonstrate the utility of these bounds by applying them to covariance operator estimation in the Hilbert-Schmidt norm and to operator learning in dynamical systems, achieving novel risk bounds. Finally, we perform numerical experiments to illustrate the practical implications of these bounds in both contexts.",
      "authors": [
        "Erfan Mirzaei",
        "Andreas Maurer",
        "Vladimir R. Kostic",
        "Massimiliano Pontil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:58:28+00:00",
          "link": "https://arxiv.org/abs/2507.07826v1",
          "size": "494kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07826",
        "HTML": "https://arxiv.org/html/2507.07826v1",
        "PDF": "https://arxiv.org/pdf/2507.07826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Bernstein inequalities for dependent data in Hilbert spaces, focusing on statistical learning challenges, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03023",
      "abstract": "Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed.",
      "authors": [
        "Hao Zeng",
        "Kangdao Liu",
        "Bingyi Jing",
        "Hongxin Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T09:26:47+00:00",
          "link": "https://arxiv.org/abs/2502.03023v1",
          "size": "214kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:51:03+00:00",
          "link": "https://arxiv.org/abs/2502.03023v2",
          "size": "197kb",
          "version": "v2"
        }
      ],
      "title": "Parametric Scaling Law of Tuning Bias in Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03023",
        "HTML": "https://arxiv.org/html/2502.03023v2",
        "PDF": "https://arxiv.org/pdf/2502.03023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines tuning bias in conformal prediction, which is unrelated to the processing or creation of LLM training data."
      },
      "tasks": [
        "Conformal Prediction",
        "Holdout Set",
        "Prediction",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00683",
      "abstract": "The recently proposed physics-based framework by Huo and Johnson~\\cite{huo2024capturing} models the attention mechanism of Large Language Models (LLMs) as an interacting two-body spin system, offering a first-principles explanation for phenomena like repetition and bias. Building on this hypothesis, we extract the complete Query-Key weight matrices from a production-grade GPT-2 model and derive the corresponding effective Hamiltonian for every attention head. From these Hamiltonians, we obtain analytic \\textit{phase boundaries} logit gap criteria that predict which token should dominate the next-token distribution for a given context. A systematic evaluation on 144 heads across 20 factual-recall prompts reveals a strong negative correlation between the theoretical logit gaps and the model's empirical token rankings ($r\\approx-0.70$, $p<10^{-3}$).Targeted ablations further show that suppressing the heads most aligned with the spin-bath predictions induces the anticipated shifts in output probabilities, confirming a causal link rather than a coincidental association. Taken together, our findings provide the first strong empirical evidence for the spin-bath analogy in a production-grade model. In this work, we utilize the context-field lens, which provides physics-grounded interpretability and motivates the development of novel generative models bridging theoretical condensed matter physics and artificial intelligence.",
      "authors": [
        "Satadeep Bhattacharjee and Seung-Cheol Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:33:39+00:00",
          "link": "https://arxiv.org/abs/2507.00683v1",
          "size": "779kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T16:40:45+00:00",
          "link": "https://arxiv.org/abs/2507.00683v2",
          "size": "779kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:16:14+00:00",
          "link": "https://arxiv.org/abs/2507.00683v3",
          "size": "822kb",
          "version": "v3"
        }
      ],
      "title": "Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00683",
        "HTML": "https://arxiv.org/html/2507.00683v3",
        "PDF": "https://arxiv.org/pdf/2507.00683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the self-attention mechanism of LLMs using a physics-based framework but does not address the processing or creation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11713",
      "abstract": "Social predictions do not passively describe the future; they actively shape it. They inform actions and change individual expectations in ways that influence the likelihood of the predicted outcome. Given these dynamics, to what extent can social events be predicted? This question was discussed throughout the 20th century by authors like Merton, Morgenstern, Simon, and others who considered it a central issue in social science methodology. In this work, we provide a modern answer to this old problem. Using recent ideas from performative prediction and outcome indistinguishability, we establish that one can always efficiently predict social events accurately, regardless of how predictions influence data. While achievable, we also show that these predictions are often undesirable, highlighting the limitations of previous desiderata. We end with a discussion of various avenues forward.",
      "authors": [
        "Juan C. Perdomo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Theoretical Economics (econ.TH)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T22:19:33+00:00",
          "link": "https://arxiv.org/abs/2503.11713v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:32:14+00:00",
          "link": "https://arxiv.org/abs/2503.11713v2",
          "size": "31kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting the Predictability of Performative, Social Events",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11713",
        "HTML": "https://arxiv.org/html/2503.11713v2",
        "PDF": "https://arxiv.org/pdf/2503.11713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the prediction of social events without contributing to data processing techniques or methodologies for LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.05020",
      "abstract": "Surgical AI often involves multiple tasks within a single procedure, like phase recognition or assessing the Critical View of Safety in laparoscopic cholecystectomy. Traditional models, built for one task at a time, lack flexibility, requiring a separate model for each. To address this, we introduce MML-SurgAdapt, a unified multi-task framework with Vision-Language Models (VLMs), specifically CLIP, to handle diverse surgical tasks through natural language supervision. A key challenge in multi-task learning is the presence of partial annotations when integrating different tasks. To overcome this, we employ Single Positive Multi-Label (SPML) learning, which traditionally reduces annotation burden by training models with only one positive label per instance. Our framework extends this approach to integrate data from multiple surgical tasks within a single procedure, enabling effective learning despite incomplete or noisy annotations. We demonstrate the effectiveness of our model on a combined dataset consisting of Cholec80, Endoscapes2023, and CholecT50, utilizing custom prompts. Extensive evaluation shows that MML-SurgAdapt performs comparably to task-specific benchmarks, with the added advantage of handling noisy annotations. It also outperforms the existing SPML frameworks for the task. By reducing the required labels by 23%, our approach proposes a more scalable and efficient labeling process, significantly easing the annotation burden on clinicians. To our knowledge, this is the first application of SPML to integrate data from multiple surgical tasks, presenting a novel and generalizable solution for multi-task learning in surgical computer vision. Implementation is available at: https://github.com/CAMMA-public/MML-SurgAdapt",
      "authors": [
        "Soham Walimbe",
        "Britty Baby",
        "Vinkle Srivastav",
        "Nicolas Padoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T14:03:10+00:00",
          "link": "https://arxiv.org/abs/2507.05020v1",
          "size": "2710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:21:47+00:00",
          "link": "https://arxiv.org/abs/2507.05020v2",
          "size": "2710kb",
          "version": "v2"
        }
      ],
      "title": "Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05020",
        "HTML": "https://arxiv.org/html/2507.05020v2",
        "PDF": "https://arxiv.org/pdf/2507.05020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on a multi-task learning framework using vision-language models for surgical tasks, focusing on reducing annotation burden rather than offering contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07131",
      "abstract": "Plain X-ray is one of the most common image modalities for clinical diagnosis (e.g. bone fracture, pneumonia, cancer screening, etc.). X-ray image segmentation is an essential step for many computer-aided diagnostic systems, yet it remains challenging. Deep-learning-based methods have achieved superior performance in medical image segmentation tasks but often require a large amount of high-quality annotated data for model training. Providing such an annotated dataset is not only time-consuming but also requires a high level of expertise. This is particularly challenging in wrist bone segmentation in X-rays, due to the interposition of multiple small carpal bones in the image. To overcome the data annotation issue, this work utilizes a large number of simulated X-ray images generated from Computed Tomography (CT) volumes with their corresponding 10 bone labels to train a deep learning-based model for wrist bone segmentation in real X-ray images. The proposed method was evaluated using both simulated images and real images. The method achieved Dice scores ranging from 0.80 to 0.92 for the simulated dataset generated from different view angles. Qualitative analysis of the segmentation results of the real X-ray images also demonstrated the superior performance of the trained model. The trained model and X-ray simulation code are freely available for research purposes: the link will be provided upon acceptance.",
      "authors": [
        "Youssef ElTantawy and Alexia Karantana and Xin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:55:39+00:00",
          "link": "https://arxiv.org/abs/2507.07131v1",
          "size": "306kb",
          "version": "v1"
        }
      ],
      "title": "Wrist bone segmentation in X-ray images using CT-based simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07131",
        "PDF": "https://arxiv.org/pdf/2507.07131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses generating simulated data for training models in medical image segmentation, which involves data creation through CT-based simulations, indirectly related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07765",
      "abstract": "Advances in low-communication training algorithms are enabling a shift from centralised model training to compute setups that are either distributed across multiple clusters or decentralised via community-driven contributions. This paper distinguishes these two scenarios - distributed and decentralised training - which are little understood and often conflated in policy discourse. We discuss how they could impact technical AI governance through an increased risk of compute structuring, capability proliferation, and the erosion of detectability and shutdownability. While these trends foreshadow a possible new paradigm that could challenge key assumptions of compute governance, we emphasise that certain policy levers, like export controls, remain relevant. We also acknowledge potential benefits of decentralised AI, including privacy-preserving training runs that could unlock access to more data, and mitigating harmful power concentration. Our goal is to support more precise policymaking around compute, capability proliferation, and decentralised AI development.",
      "authors": [
        "Jakub Kry\\'s",
        "Yashvardhan Sharma",
        "Janet Egan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:43:15+00:00",
          "link": "https://arxiv.org/abs/2507.07765v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07765",
        "HTML": "https://arxiv.org/html/2507.07765v1",
        "PDF": "https://arxiv.org/pdf/2507.07765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While discussing distributed and decentralised training, it briefly mentions privacy-preserving runs for more data access, but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04946",
      "abstract": "Despite remarkable progress in image quality and prompt fidelity, text-to-image (T2I) diffusion models continue to exhibit persistent \"hallucinations\", where generated content subtly or significantly diverges from the intended prompt semantics. While often regarded as unpredictable artifacts, we argue that these failures reflect deeper, structured misalignments within the generative process. In this work, we propose a cognitively inspired perspective that reinterprets hallucinations as trajectory drift within a latent alignment space. Empirical observations reveal that generation unfolds within a multiaxial cognitive tension field, where the model must continuously negotiate competing demands across three key critical axes: semantic coherence, structural alignment, and knowledge grounding. We then formalize this three-axis space as the \\textbf{Hallucination Tri-Space} and introduce the Alignment Risk Code (ARC): a dynamic vector representation that quantifies real-time alignment tension during generation. The magnitude of ARC captures overall misalignment, its direction identifies the dominant failure axis, and its imbalance reflects tension asymmetry. Based on this formulation, we develop the TensionModulator (TM-ARC): a lightweight controller that operates entirely in latent space. TM-ARC monitors ARC signals and applies targeted, axis-specific interventions during the sampling process. Extensive experiments on standard T2I benchmarks demonstrate that our approach significantly reduces hallucination without compromising image quality or diversity. This framework offers a unified and interpretable approach for understanding and mitigating generative failures in diffusion-based T2I systems.",
      "authors": [
        "Jianjiang Yang",
        "Ziyan Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T12:43:09+00:00",
          "link": "https://arxiv.org/abs/2507.04946v1",
          "size": "5651kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T22:41:45+00:00",
          "link": "https://arxiv.org/abs/2507.04946v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Taming the Tri-Space Tension: ARC-Guided Hallucination Modeling and Control for Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04946",
        "PDF": "https://arxiv.org/pdf/2507.04946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focusing on reducing hallucinations in text-to-image diffusion models, this paper deals with generative failures in image synthesis rather than processing or creating language model training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07647",
      "abstract": "We study the problem of signal source localization using bearing-only measurements. Initially, we present easily verifiable geometric conditions for sensor deployment to ensure the asymptotic identifiability of the model and demonstrate the consistency and asymptotic efficiency of the maximum likelihood (ML) estimator. However, obtaining the ML estimator is challenging due to its association with a non-convex optimization problem. To address this, we propose a two-step estimator that shares the same asymptotic properties as the ML estimator while offering low computational complexity, linear in the number of measurements. The primary challenge lies in obtaining a preliminary consistent estimator in the first step. To achieve this, we construct a linear least-squares problem through algebraic operations on the measurement nonlinear model to first obtain a biased closed-form solution. We then eliminate the bias using the data to yield an asymptotically unbiased and consistent estimator. The key to this process is obtaining a consistent estimator of the variance of the sine of the noise by taking the reciprocal of the maximum eigenvalue of a specially constructed matrix from the data. In the second step, we perform a single Gauss-Newton iteration using the preliminary consistent estimator as the initial value, achieving the same asymptotic properties as the ML estimator. Finally, simulation results demonstrate the superior performance of the proposed two-step estimator for large sample sizes.",
      "authors": [
        "Shenghua Hu",
        "Guangyang Zeng",
        "Wenchao Xue",
        "Haitao Fang",
        "Biqiang Mu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:22:51+00:00",
          "link": "https://arxiv.org/abs/2507.07647v1",
          "size": "1155kb",
          "version": "v1"
        }
      ],
      "title": "Consistent and Asymptotically Efficient Localization from Bearing-only Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07647",
        "HTML": "https://arxiv.org/html/2507.07647v1",
        "PDF": "https://arxiv.org/pdf/2507.07647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on signal source localization using bearing-only measurements and discusses estimators, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07795",
      "abstract": "Non-contact remote photoplethysmography (rPPG) technology enables heart rate measurement from facial videos. However, existing network models still face challenges in accu racy, robustness, and generalization capability under complex scenarios. This paper proposes an end-to-end rPPG extraction network that employs 3D convolutional neural networks to reconstruct accurate rPPG signals from raw facial videos. We introduce a differential frame fusion module that integrates differential frames with original frames, enabling frame-level representations to capture blood volume pulse (BVP) variations. Additionally, we incorporate Temporal Shift Module (TSM) with self-attention mechanisms, which effectively enhance rPPG features with minimal computational overhead. Furthermore, we propose a novel dynamic hybrid loss function that provides stronger supervision for the network, effectively mitigating over fitting. Comprehensive experiments were conducted on not only the PURE and UBFC-rPPG datasets but also the challenging MMPD dataset under complex scenarios, involving both intra dataset and cross-dataset evaluations, which demonstrate the superior robustness and generalization capability of our network. Specifically, after training on PURE, our model achieved a mean absolute error (MAE) of 7.58 on the MMPD test set, outperforming the state-of-the-art models.",
      "authors": [
        "Kang Cen",
        "Chang-Hong Fu",
        "Hong Hong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:23:11+00:00",
          "link": "https://arxiv.org/abs/2507.07795v1",
          "size": "3700kb",
          "version": "v1"
        }
      ],
      "title": "Robust and Generalizable Heart Rate Estimation via Deep Learning for Remote Photoplethysmography in Complex Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07795",
        "HTML": "https://arxiv.org/html/2507.07795v1",
        "PDF": "https://arxiv.org/pdf/2507.07795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for heart rate estimation using deep learning for photoplethysmography, which does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.08118",
      "abstract": "Future wireless networks must support emerging applications where environmental awareness is as critical as data transmission. Integrated Sensing and Communication (ISAC) enables this vision by allowing base stations (BSs) to allocate bandwidth and power to mobile users (MUs) for communications and cooperative sensing. However, this resource allocation is highly challenging due to: (i) dynamic resource demands from MUs and resource supply from BSs, and (ii) the selfishness of MUs and BSs. To address these challenges, existing solutions rely on either real-time (online) resource trading, which incurs high overhead and failures, or static long-term (offline) resource contracts, which lack flexibility. To overcome these limitations, we propose the Future Resource Bank for ISAC, a hybrid trading framework that integrates offline and online resource allocation through a level-wise client model, where MUs and their coalitions negotiate with BSs. We introduce two mechanisms: (i) Role-Friendly Win-Win Matching (offRFW$^2$M), leveraging overbooking to establish risk-aware, stable contracts, and (ii) Effective Backup Win-Win Matching (onEBW$^2$M), which dynamically reallocates unmet demand and surplus supply. We theoretically prove stability, individual rationality, and weak Pareto optimality of these mechanisms. Through simulations, we show that our framework improves social welfare, latency, and energy efficiency compared to existing methods.",
      "authors": [
        "Houyi Qi",
        "Minghui Liwang",
        "Seyyedali Hosseinalipour",
        "Liqun Fu",
        "Sai Zou",
        "Wei Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T04:40:09+00:00",
          "link": "https://arxiv.org/abs/2502.08118v1",
          "size": "2090kb",
          "version": "v1"
        },
        {
          "date": "2025-02-15T09:07:06+00:00",
          "link": "https://arxiv.org/abs/2502.08118v2",
          "size": "2963kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T01:52:36+00:00",
          "link": "https://arxiv.org/abs/2502.08118v3",
          "size": "2911kb",
          "version": "v3"
        },
        {
          "date": "2025-02-19T06:34:06+00:00",
          "link": "https://arxiv.org/abs/2502.08118v4",
          "size": "2910kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T03:18:21+00:00",
          "link": "https://arxiv.org/abs/2502.08118v5",
          "size": "678kb",
          "version": "v5"
        }
      ],
      "title": "Future Resource Bank for ISAC: Achieving Fast and Stable Win-Win Matching for Both Individuals and Coalitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08118",
        "HTML": "https://arxiv.org/html/2502.08118v5",
        "PDF": "https://arxiv.org/pdf/2502.08118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with resource allocation in wireless networks and ISAC, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06850",
      "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.",
      "authors": [
        "Matteo Lupinacci",
        "Francesco Aurelio Pironti",
        "Francesco Blefari",
        "Francesco Romeo",
        "Luigi Arena",
        "Angelo Furfaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:54:58+00:00",
          "link": "https://arxiv.org/abs/2507.06850v1",
          "size": "442kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:18:20+00:00",
          "link": "https://arxiv.org/abs/2507.06850v2",
          "size": "442kb",
          "version": "v2"
        }
      ],
      "title": "The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06850",
        "HTML": "https://arxiv.org/html/2507.06850v2",
        "PDF": "https://arxiv.org/pdf/2507.06850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses security vulnerabilities associated with LLMs and does not make contributions related to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07154",
      "abstract": "Accurate segmentation of polyps from colonoscopy images is crucial for the early diagnosis and treatment of colorectal cancer. Most existing deep learning-based polyp segmentation methods adopt an Encoder-Decoder architecture, and some utilize multi-task frameworks that incorporate auxiliary tasks such as classification to enhance segmentation performance. However, these approaches often require additional labeled data and rely on task similarity, which can limit their generalizability. To address these challenges, we propose CL-Polyp, a contrastive learning-enhanced polyp segmentation network. Our method leverages contrastive learning to improve the encoder's ability to extract discriminative features by contrasting positive and negative sample pairs derived from polyp images. This self-supervised strategy enhances visual representation without requiring additional annotations. In addition, we introduce two lightweight and effective modules: the Modified Atrous Spatial Pyramid Pooling (MASPP) module for better multi-scale feature fusion, and the Channel Concatenate and Element Add (CA) module to fuse low-level and upsampled features for improved boundary reconstruction. Extensive experiments on five benchmark datasets-Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, CVC-300, and ETIS-demonstrate that CL-Polyp consistently outperforms state-of-the-art methods. Specifically, it improves the IoU metric by 0.011 and 0.020 on the Kvasir-SEG and CVC-ClinicDB datasets, respectively, validating its effectiveness in clinical polyp segmentation tasks.",
      "authors": [
        "Desheng Li and Chaoliang Liu and Zhiyong Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:07:45+00:00",
          "link": "https://arxiv.org/abs/2507.07154v1",
          "size": "5372kb",
          "version": "v1"
        }
      ],
      "title": "CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07154",
        "HTML": "https://arxiv.org/html/2507.07154v1",
        "PDF": "https://arxiv.org/pdf/2507.07154"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on contrastive learning for polyp segmentation and does not discuss any contributions towards LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07246",
      "abstract": "For reverse engineering related security domains, such as vulnerability detection, malware analysis, and binary hardening, disassembly is crucial yet challenging. The fundamental challenge of disassembly is to identify instruction and function boundaries. Classic approaches rely on file-format assumptions and architecture-specific heuristics to guess the boundaries, resulting in incomplete and incorrect disassembly, especially when the binary is obfuscated. Recent advancements of disassembly have demonstrated that deep learning can improve both the accuracy and efficiency of disassembly. In this paper, we propose Disa, a new learning-based disassembly approach that uses the information of superset instructions over the multi-head self-attention to learn the instructions' correlations, thus being able to infer function entry-points and instruction boundaries. Disa can further identify instructions relevant to memory block boundaries to facilitate an advanced block-memory model based value-set analysis for an accurate control flow graph (CFG) generation. Our experiments show that Disa outperforms prior deep-learning disassembly approaches in function entry-point identification, especially achieving 9.1% and 13.2% F1-score improvement on binaries respectively obfuscated by the disassembly desynchronization technique and popular source-level obfuscator. By achieving an 18.5% improvement in the memory block precision, Disa generates more accurate CFGs with a 4.4% reduction in Average Indirect Call Targets (AICT) compared with the state-of-the-art heuristic-based approach.",
      "authors": [
        "Peicheng Wang",
        "Monika Santra",
        "Mingyu Liu",
        "Cong Sun",
        "Dongrui Zeng",
        "Gang Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:36:57+00:00",
          "link": "https://arxiv.org/abs/2507.07246v1",
          "size": "615kb",
          "version": "v1"
        }
      ],
      "title": "Disa: Accurate Learning-based Static Disassembly with Attentions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07246",
        "HTML": "https://arxiv.org/html/2507.07246v1",
        "PDF": "https://arxiv.org/pdf/2507.07246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reverse engineering and disassembly using deep learning, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07595",
      "abstract": "Recent investigations on the effectiveness of Graph Neural Network (GNN)-based models for link prediction in Knowledge Graphs (KGs) show that vanilla aggregation does not significantly impact the model performance. In this paper, we introduce a novel method, named Context Pooling, to enhance GNN-based models' efficacy for link predictions in KGs. To our best of knowledge, Context Pooling is the first methodology that applies graph pooling in KGs. Additionally, Context Pooling is first-of-its-kind to enable the generation of query-specific graphs for inductive settings, where testing entities are unseen during training. Specifically, we devise two metrics, namely neighborhood precision and neighborhood recall, to assess the neighbors' logical relevance regarding the given queries, thereby enabling the subsequent comprehensive identification of only the logically relevant neighbors for link prediction. Our method is generic and assessed by being applied to two state-of-the-art (SOTA) models on three public transductive and inductive datasets, achieving SOTA performance in 42 out of 48 settings.",
      "authors": [
        "Zhixiang Su",
        "Di Wang",
        "Chunyan Miao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:54:37+00:00",
          "link": "https://arxiv.org/abs/2507.07595v1",
          "size": "939kb",
          "version": "v1"
        }
      ],
      "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07595",
        "HTML": "https://arxiv.org/html/2507.07595v1",
        "PDF": "https://arxiv.org/pdf/2507.07595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing GNN-based models for link prediction in knowledge graphs but does not discuss processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07718",
      "abstract": "The integration of high-level assistance algorithms in surgical robotics training curricula may be beneficial in establishing a more comprehensive and robust skillset for aspiring surgeons, improving their clinical performance as a consequence. This work presents the development and validation of a haptic-enhanced Virtual Reality simulator for surgical robotics training, featuring 8 surgical tasks that the trainee can interact with thanks to the embedded physics engine. This virtual simulated environment is augmented by the introduction of high-level haptic interfaces for robotic assistance that aim at re-directing the motion of the trainee's hands and wrists toward targets or away from obstacles, and providing a quantitative performance score after the execution of each training exercise.An experimental study shows that the introduction of enhanced robotic assistance into a surgical robotics training curriculum improves performance during the training process and, crucially, promotes the transfer of the acquired skills to an unassisted surgical scenario, like the clinical one.",
      "authors": [
        "Alberto Rota",
        "Ke Fan",
        "Elena De Momi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:55:04+00:00",
          "link": "https://arxiv.org/abs/2507.07718v1",
          "size": "6034kb",
          "version": "v1"
        }
      ],
      "title": "Implementation and Assessment of an Augmented Training Curriculum for Surgical Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07718",
        "HTML": "https://arxiv.org/html/2507.07718v1",
        "PDF": "https://arxiv.org/pdf/2507.07718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with training surgical robotics and the use of haptic VR simulators, with no connection to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07139",
      "abstract": "Recent advances in image generation models (IGMs), particularly diffusion-based architectures such as Stable Diffusion (SD), have markedly enhanced the quality and diversity of AI-generated visual content. However, their generative capability has also raised significant ethical, legal, and societal concerns, including the potential to produce harmful, misleading, or copyright-infringing content. To mitigate these concerns, machine unlearning (MU) emerges as a promising solution by selectively removing undesirable concepts from pretrained models. Nevertheless, the robustness and effectiveness of existing unlearning techniques remain largely unexplored, particularly in the presence of multi-modal adversarial inputs.\n  To bridge this gap, we propose Recall, a novel adversarial framework explicitly designed to compromise the robustness of unlearned IGMs. Unlike existing approaches that predominantly rely on adversarial text prompts, Recall exploits the intrinsic multi-modal conditioning capabilities of diffusion models by efficiently optimizing adversarial image prompts with guidance from a single semantically relevant reference image. Extensive experiments across ten state-of-the-art unlearning methods and diverse tasks show that Recall consistently outperforms existing baselines in terms of adversarial effectiveness, computational efficiency, and semantic fidelity with the original textual prompt. These findings reveal critical vulnerabilities in current unlearning mechanisms and underscore the need for more robust solutions to ensure the safety and reliability of generative models. Code and data are publicly available at \\textcolor{blue}{https://github.com/ryliu68/RECALL}.",
      "authors": [
        "Renyang Liu",
        "Guanlin Li",
        "Tianwei Zhang",
        "See-Kiong Ng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:59:01+00:00",
          "link": "https://arxiv.org/abs/2507.07139v1",
          "size": "13851kb",
          "version": "v1"
        }
      ],
      "title": "Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07139",
        "HTML": "https://arxiv.org/html/2507.07139v1",
        "PDF": "https://arxiv.org/pdf/2507.07139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an adversarial attack against image generation models unlearning but does not engage with LLM training data processing or contribute to dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07263",
      "abstract": "This work analyzes convergence times and robustness bounds for asynchronous distributed shortest-path computation. We focus on the Adaptive Bellman--Ford algorithm, a self-stabilizing method in which each agent updates its shortest-path estimate based only on the estimates of its neighbors and forgetting its previous estimate. In the asynchronous framework considered in this paper, agents are allowed to idle or encounter race conditions during their execution of the Adaptive Bellman--Ford algorithm. We build on Lyapunov-based results that develop finite-time convergence and robustness bounds for the synchronous shortest-path setting, in order to produce finite-time convergence and robustness bounds for the asynchronous setting. We also explore robustness against interval-bounded noise processes and establish convergence and robustness guarantees for asynchronous most-probable-path algorithms.",
      "authors": [
        "Jared Miller",
        "Mattia Bianchi",
        "Florian D\\\"orfler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:17:55+00:00",
          "link": "https://arxiv.org/abs/2507.07263v1",
          "size": "2225kb",
          "version": "v1"
        }
      ],
      "title": "Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07263",
        "HTML": "https://arxiv.org/html/2507.07263v1",
        "PDF": "https://arxiv.org/pdf/2507.07263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work analyzes algorithms for asynchronous shortest-path computation, focusing on convergence and robustness bounds, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07768",
      "abstract": "Adversarial Training (AT) is a widely adopted defense against adversarial examples. However, existing approaches typically apply a uniform training objective across all classes, overlooking disparities in class-wise vulnerability. This results in adversarial unfairness: classes with well distinguishable features (strong classes) tend to become more robust, while classes with overlapping or shared features(weak classes) remain disproportionately susceptible to adversarial attacks. We observe that strong classes do not require strong adversaries during training, as their non-robust features are quickly suppressed. In contrast, weak classes benefit from stronger adversaries to effectively reduce their vulnerabilities. Motivated by this, we introduce TRIX, a feature-aware adversarial training framework that adaptively assigns weaker targeted adversaries to strong classes, promoting feature diversity via uniformly sampled targets, and stronger untargeted adversaries to weak classes, enhancing their focused robustness. TRIX further incorporates per-class loss weighting and perturbation strength adjustments, building on prior work, to emphasize weak classes during the optimization. Comprehensive experiments on standard image classification benchmarks, including evaluations under strong attacks such as PGD and AutoAttack, demonstrate that TRIX significantly improves worst-case class accuracy on both clean and adversarial data, reducing inter-class robustness disparities, and preserves overall accuracy. Our results highlight TRIX as a practical step toward fair and effective adversarial defense.",
      "authors": [
        "Tejaswini Medi",
        "Steffen Jung",
        "Margret Keuper"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:53:52+00:00",
          "link": "https://arxiv.org/abs/2507.07768v1",
          "size": "1669kb",
          "version": "v1"
        }
      ],
      "title": "TRIX- Trading Adversarial Fairness via Mixed Adversarial Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07768",
        "HTML": "https://arxiv.org/html/2507.07768v1",
        "PDF": "https://arxiv.org/pdf/2507.07768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial training for fairness across class vulnerabilities, specifically in terms of adversarial attacks and defenses. It does not discuss processing of LLM training data or creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07799",
      "abstract": "Given the increasing privacy concerns from identity theft and the re-identification of speakers through content in the speech field, this paper proposes a prompt-based speech generation pipeline that ensures dual anonymization of both speaker identity and spoken content. This is addressed through 1) generating a speaker identity unlinkable to the source speaker, controlled by descriptors, and 2) replacing sensitive content within the original text using a name entity recognition model and a large language model. The pipeline utilizes the anonymized speaker identity and text to generate high-fidelity, privacy-friendly speech via a text-to-speech synthesis model. Experimental results demonstrate an achievement of significant privacy protection while maintaining a decent level of content retention and audio quality. This paper also investigates the impact of varying speaker descriptions on the utility and privacy of generated speech to determine potential biases.",
      "authors": [
        "Belinda Soh Hui Hui",
        "Xiaoxiao Miao",
        "Xin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:26:28+00:00",
          "link": "https://arxiv.org/abs/2507.07799v1",
          "size": "1030kb",
          "version": "v1"
        }
      ],
      "title": "SecureSpeech: Prompt-based Speaker and Content Protection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07799",
        "HTML": "https://arxiv.org/html/2507.07799v1",
        "PDF": "https://arxiv.org/pdf/2507.07799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves processing text using a large language model to replace sensitive content, it mainly focuses on privacy and speaker protection in the speech generation pipeline, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07903",
      "abstract": "Accurate position estimation is essential for modern navigation systems deployed in autonomous platforms, including ground vehicles, marine vessels, and aerial drones. In this context, Visual Simultaneous Localisation and Mapping (VSLAM) - which includes Visual Odometry - relies heavily on the reliable extraction of salient feature points from the visual input data. In this work, we propose an embedded implementation of an unsupervised architecture capable of detecting and describing feature points. It is based on a quantised SuperPoint convolutional neural network. Our objective is to minimise the computational demands of the model while preserving high detection quality, thus facilitating efficient deployment on platforms with limited resources, such as mobile or embedded systems. We implemented the solution on an FPGA System-on-Chip (SoC) platform, specifically the AMD/Xilinx Zynq UltraScale+, where we evaluated the performance of Deep Learning Processing Units (DPUs) and we also used the Brevitas library and the FINN framework to perform model quantisation and hardware-aware optimisation. This allowed us to process 640 x 480 pixel images at up to 54 fps on an FPGA platform, outperforming state-of-the-art solutions in the field. We conducted experiments on the TUM dataset to demonstrate and discuss the impact of different quantisation techniques on the accuracy and performance of the model in a visual odometry task.",
      "authors": [
        "Mateusz Wasala",
        "Mateusz Smolarczyk",
        "Michal Danilowicz",
        "Tomasz Kryjak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:37:20+00:00",
          "link": "https://arxiv.org/abs/2507.07903v1",
          "size": "1933kb",
          "version": "v1"
        }
      ],
      "title": "Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07903",
        "HTML": "https://arxiv.org/html/2507.07903v1",
        "PDF": "https://arxiv.org/pdf/2507.07903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper details a hardware-aware feature extraction technique for visual odometry on FPGA platforms and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18047",
      "abstract": "This paper describes HARMONIC, a cognitive-robotic architecture that integrates the OntoAgent cognitive framework with general-purpose robot control systems applied to human-robot teaming (HRT). HARMONIC incorporates metacognition, meaningful natural language communication, and explainability capabilities required for developing mutual trust in HRT. Through simulation experiments involving a joint search task performed by a heterogeneous team of two HARMONIC-based robots and a human operator, we demonstrate heterogeneous robots that coordinate their actions, adapt to complex scenarios, and engage in natural human-robot communication. Evaluation results show that HARMONIC-based robots can reason about plans, goals, and team member attitudes while providing clear explanations for their decisions, which are essential requirements for realistic human-robot teaming.",
      "authors": [
        "Sanjay Oruganti",
        "Sergei Nirenburg",
        "Marjorie McShane",
        "Jesse English",
        "Michael K. Roberts",
        "Christian Arndt",
        "Sahithi Kamireddy",
        "Carlos Gonzalez",
        "Mingyo Seo",
        "Luis Sentis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T16:48:21+00:00",
          "link": "https://arxiv.org/abs/2409.18047v1",
          "size": "7356kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T03:08:12+00:00",
          "link": "https://arxiv.org/abs/2409.18047v2",
          "size": "20402kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T20:58:34+00:00",
          "link": "https://arxiv.org/abs/2409.18047v3",
          "size": "6557kb",
          "version": "v3"
        }
      ],
      "title": "HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18047",
        "HTML": "https://arxiv.org/html/2409.18047v3",
        "PDF": "https://arxiv.org/pdf/2409.18047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus is on human-robot collaboration, integrating cognitive frameworks with robotic systems. It does not involve LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.20805",
      "abstract": "Hand-object interaction(HOI) is the fundamental link between human and environment, yet its dexterous and complex pose significantly challenges for gesture control. Despite significant advances in AI and robotics, enabling machines to understand and simulate hand-object interactions, capturing the semantics of functional grasping tasks remains a considerable challenge. While previous work can generate stable and correct 3D grasps, they are still far from achieving functional grasps due to unconsidered grasp semantics. To address this challenge, we propose an innovative two-stage framework, Functional Grasp Synthesis Net (FGS-Net), for generating 3D HOI driven by functional text. This framework consists of a text-guided 3D model generator, Functional Grasp Generator (FGG), and a pose optimization strategy, Functional Grasp Refiner (FGR). FGG generates 3D models of hands and objects based on text input, while FGR fine-tunes the poses using Object Pose Approximator and energy functions to ensure the relative position between the hand and object aligns with human intent and remains physically plausible. Extensive experiments demonstrate that our approach achieves precise and high-quality HOI generation without requiring additional 3D annotation data.",
      "authors": [
        "Yongqi Tian",
        "Xueyu Sun",
        "Haoyuan He",
        "Linji Hao",
        "Ning Ding",
        "Caigui Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T07:42:54+00:00",
          "link": "https://arxiv.org/abs/2502.20805v1",
          "size": "1400kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:08:40+00:00",
          "link": "https://arxiv.org/abs/2502.20805v2",
          "size": "12970kb",
          "version": "v2"
        }
      ],
      "title": "FunHOI: Annotation-Free 3D Hand-Object Interaction Generation via Functional Text Guidanc",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20805",
        "HTML": "https://arxiv.org/html/2502.20805v2",
        "PDF": "https://arxiv.org/pdf/2502.20805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hand-object interaction generation using a text-guided model, which involves pose optimization and 3D model generation but does not discuss LLM training data processing."
      },
      "tasks": [
        "Object"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07703",
      "abstract": "Does AI conform to humans, or will we conform to AI? An ethical evaluation of AI-intensive companies will allow investors to knowledgeably participate in the decision. The evaluation is built from nine performance indicators that can be analyzed and scored to reflect a technology's human-centering. The result is objective investment guidance, as well as investors empowered to act in accordance with their own values. Incorporating ethics into financial decisions is a strategy that will be recognized by participants in environmental, social, and governance investing, however, this paper argues that conventional ESG frameworks are inadequate to companies that function with AI at their core. Fully accounting for contemporary big data, predictive analytics, and machine learning requires specialized metrics customized from established AI ethics principles. With these metrics established, the larger goal is a model for humanist investing in AI-intensive companies that is intellectually robust, manageable for analysts, useful for portfolio managers, and credible for investors.",
      "authors": [
        "James Brusseau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:30:58+00:00",
          "link": "https://arxiv.org/abs/2507.07703v1",
          "size": "1531kb",
          "version": "v1"
        }
      ],
      "title": "AI Human Impact: Toward a Model for Ethical Investing in AI-Intensive Companies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07703",
        "PDF": "https://arxiv.org/pdf/2507.07703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on ethical investing in AI-intensive companies with performance indicators and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07978",
      "abstract": "Synthesizing realistic Martian landscape videos is crucial for mission rehearsal and robotic simulation. However, this task poses unique challenges due to the scarcity of high-quality Martian data and the significant domain gap between Martian and terrestrial imagery. To address these challenges, we propose a holistic solution composed of two key components: 1) A data curation pipeline Multimodal Mars Synthesis (M3arsSynth), which reconstructs 3D Martian environments from real stereo navigation images, sourced from NASA's Planetary Data System (PDS), and renders high-fidelity multiview 3D video sequences. 2) A Martian terrain video generator, MarsGen, which synthesizes novel videos visually realistic and geometrically consistent with the 3D structure encoded in the data. Our M3arsSynth engine spans a wide range of Martian terrains and acquisition dates, enabling the generation of physically accurate 3D surface models at metric-scale resolution. MarsGen, fine-tuned on M3arsSynth data, synthesizes videos conditioned on an initial image frame and, optionally, camera trajectories or textual prompts, allowing for video generation in novel environments. Experimental results show that our approach outperforms video synthesis models trained on terrestrial datasets, achieving superior visual fidelity and 3D structural consistency.",
      "authors": [
        "Longfei Li",
        "Zhiwen Fan",
        "Wenyan Cong",
        "Xinhang Liu",
        "Yuyang Yin",
        "Matt Foutter",
        "Panwang Pan",
        "Chenyu You",
        "Yue Wang",
        "Zhangyang Wang",
        "Yao Zhao",
        "Marco Pavone",
        "Yunchao Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:54:27+00:00",
          "link": "https://arxiv.org/abs/2507.07978v1",
          "size": "13187kb",
          "version": "v1"
        }
      ],
      "title": "Martian World Models: Controllable Video Synthesis with Physically Accurate 3D Reconstructions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07978",
        "HTML": "https://arxiv.org/html/2507.07978v1",
        "PDF": "https://arxiv.org/pdf/2507.07978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a data curation pipeline called M3arsSynth for creating 3D Martian environments, detailing data processing steps and generating a new dataset for video synthesis, fulfilling the criterion of processing and creating training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.07517",
      "abstract": "Implementations of spiking neural networks on neuromorphic hardware promise orders of magnitude less power consumption than their non-spiking counterparts. The standard neuron model for spike-based computation on such systems has long been the leaky integrate-and-fire (LIF) neuron. A computationally light augmentation of the LIF neuron model with an adaptation mechanism has recently been shown to exhibit superior performance on spatio-temporal processing tasks. The root of the superiority of these so-called adaptive LIF neurons however is not well understood. In this article, we thoroughly analyze the dynamical, computational, and learning properties of adaptive LIF neurons and networks thereof. Our investigation reveals significant challenges related to stability and parameterization when employing the conventional Euler-Forward discretization for this class of models. We report a rigorous theoretical and empirical demonstration that these challenges can be effectively addressed by adopting an alternative discretization approach - the Symplectic Euler method, allowing to improve over state-of-the-art performances on common event-based benchmark datasets. Our further analysis of the computational properties of networks of adaptive LIF neurons shows that they are particularly well suited to exploit the spatio-temporal structure of input sequences without any normalization techniques.",
      "authors": [
        "Maximilian Baronig",
        "Romain Ferrand",
        "Silvester Sabathiel",
        "Robert Legenstein"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T12:49:58+00:00",
          "link": "https://arxiv.org/abs/2408.07517v1",
          "size": "1909kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T12:42:10+00:00",
          "link": "https://arxiv.org/abs/2408.07517v2",
          "size": "2477kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T10:13:25+00:00",
          "link": "https://arxiv.org/abs/2408.07517v3",
          "size": "2264kb",
          "version": "v3"
        }
      ],
      "title": "Advancing Spatio-Temporal Processing in Spiking Neural Networks through Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07517",
        "HTML": "https://arxiv.org/html/2408.07517v3",
        "PDF": "https://arxiv.org/pdf/2408.07517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates spiking neural networks and does not address LLM training data processing or related data engineering operations."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/IGITUGraz/SE-adlif"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07259",
      "abstract": "As machine learning models become increasingly deployed across the edge of internet of things environments, a partitioned deep learning paradigm in which models are split across multiple computational nodes introduces a new dimension of security risk. Unlike traditional inference setups, these distributed pipelines span the model computation across heterogeneous nodes and communication layers, thereby exposing a broader attack surface to potential adversaries. Building on these motivations, this work explores a previously overlooked vulnerability: even when both the edge and cloud components of the model are inaccessible (i.e., black-box), an adversary who intercepts the intermediate features transmitted between them can still pose a serious threat. We demonstrate that, under these mild and realistic assumptions, an attacker can craft highly transferable proxy models, making the entire deep learning system significantly more vulnerable to evasion attacks. In particular, the intercepted features can be effectively analyzed and leveraged to distill surrogate models capable of crafting highly transferable adversarial examples against the target model. To this end, we propose an exploitation strategy specifically designed for distributed settings, which involves reconstructing the original tensor shape from vectorized transmitted features using simple statistical analysis, and adapting surrogate architectures accordingly to enable effective feature distillation. A comprehensive and systematic experimental evaluation has been conducted to demonstrate that surrogate models trained with the proposed strategy, i.e., leveraging intermediate features, tremendously improve the transferability of adversarial attacks. These findings underscore the urgent need to account for intermediate feature leakage in the design of secure distributed deep learning systems.",
      "authors": [
        "Giulio Rossolini",
        "Fabio Brau",
        "Alessandro Biondi",
        "Battista Biggio",
        "Giorgio Buttazzo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:09:00+00:00",
          "link": "https://arxiv.org/abs/2507.07259v1",
          "size": "1983kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07259",
        "HTML": "https://arxiv.org/html/2507.07259v1",
        "PDF": "https://arxiv.org/pdf/2507.07259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on security vulnerabilities related to distributed machine learning models and adversarial attacks, without discussing LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18603",
      "abstract": "We consider the generative modeling of speech over multiple minutes, a requirement for long-form multimedia generation and audio-native voice assistants. However, textless spoken language models struggle to generate plausible speech past tens of seconds, due to high temporal resolution of speech tokens causing loss of coherence, architectural issues with long-sequence training or extrapolation, and memory costs at inference time. From these considerations we derive SpeechSSM, the first speech language model family to learn from and sample long-form spoken audio (e.g., 16 minutes of read or extemporaneous speech) in a single decoding session without text intermediates. SpeechSSMs leverage recent advances in linear-time sequence modeling to greatly surpass current Transformer spoken LMs in coherence and efficiency on multi-minute generations while still matching them at the utterance level. As we found current spoken language evaluations uninformative, especially in this new long-form setting, we also introduce: LibriSpeech-Long, a benchmark for long-form speech evaluation; new embedding-based and LLM-judged metrics; and quality measurements over length and time. Speech samples, the LibriSpeech-Long dataset, and any future code or model releases can be found at https://google.github.io/tacotron/publications/speechssm/.",
      "authors": [
        "Se Jin Park",
        "Julian Salazar",
        "Aren Jansen",
        "Keisuke Kinoshita",
        "Yong Man Ro",
        "RJ Skerry-Ryan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T18:56:46+00:00",
          "link": "https://arxiv.org/abs/2412.18603v1",
          "size": "297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:52:43+00:00",
          "link": "https://arxiv.org/abs/2412.18603v2",
          "size": "366kb",
          "version": "v2"
        }
      ],
      "title": "Long-Form Speech Generation with Spoken Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18603",
        "HTML": "https://arxiv.org/html/2412.18603v2",
        "PDF": "https://arxiv.org/pdf/2412.18603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new dataset (LibriSpeech-Long), the main contribution is in speech generation modeling rather than LLM training data processing."
      },
      "tasks": [
        "Form",
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/google-deepmind/librispeech-long"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04057",
      "abstract": "The Internet of Things (IoT) is expanding at an accelerated pace, making it critical to have secure networks to mitigate a variety of cyber threats. This study addresses the limitation of multi-class attack detection of IoT devices and presents new machine learning-based lightweight ensemble methods that exploit its strong machine learning framework. We used a dataset entitled CICIoT 2023, which has a total of 34 different attack types categorized into 10 categories, and methodically assessed the performance of a substantial array of current machine learning techniques in our goal to identify the best-performing algorithmic choice for IoT application protection. In this work, we focus on ML classifier-based methods to address the biocharges presented by the difficult and heterogeneous properties of the attack vectors in IoT ecosystems. The best-performing method was the Decision Tree, achieving 99.56% accuracy and 99.62% F1, indicating this model is capable of detecting threats accurately and reliably. The Random Forest model also performed nearly as well, with an accuracy of 98.22% and an F1 score of 98.24%, indicating that ML methods excel in a scenario of high-dimensional data. These findings emphasize the promise of integrating ML classifiers into the protective defenses of IoT devices and provide motivations for pursuing subsequent studies towards scalable, keystroke-based attack detection frameworks. We think that our approach offers a new avenue for constructing complex machine learning algorithms for low-resource IoT devices that strike a balance between accuracy requirements and time efficiency. In summary, these contributions expand and enhance the knowledge of the current IoT security literature, establishing a solid baseline and framework for smart, adaptive security to be used in IoT environments.",
      "authors": [
        "Shahran Rahman Alve",
        "Muhammad Zawad Mahmud",
        "Samiha Islam",
        "Md. Asaduzzaman Chowdhury",
        "Jahirul Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T13:17:03+00:00",
          "link": "https://arxiv.org/abs/2502.04057v1",
          "size": "420kb",
          "version": "v1"
        },
        {
          "date": "2025-06-15T09:22:08+00:00",
          "link": "https://arxiv.org/abs/2502.04057v2",
          "size": "295kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T21:02:16+00:00",
          "link": "https://arxiv.org/abs/2502.04057v3",
          "size": "295kb",
          "version": "v3"
        }
      ],
      "title": "Smart IoT Security: Lightweight Machine Learning Techniques for Multi-Class Attack Detection in IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04057",
        "HTML": "https://arxiv.org/html/2502.04057v3",
        "PDF": "https://arxiv.org/pdf/2502.04057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on IoT security using machine learning classifiers, without discussing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.23760",
      "abstract": "This research addresses the question, which characteristics a cognitive architecture must have to leverage the benefits of natural language in Co-Constructive Task Learning (CCTL). To provide context, we first discuss Interactive Task Learning (ITL), the mechanisms of the human memory system, and the significance of natural language and multi-modality. Next, we examine the current state of cognitive architectures, analyzing their capabilities to inform a concept of CCTL grounded in multiple sources. We then integrate insights from various research domains to develop a unified framework. Finally, we conclude by identifying the remaining challenges and requirements necessary to achieve CCTL in Human-Robot Interaction (HRI).",
      "authors": [
        "Manuel Scheibl",
        "Birte Richter",
        "Alissa M\\\"uller",
        "Michael Beetz",
        "Britta Wrede"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T06:23:14+00:00",
          "link": "https://arxiv.org/abs/2503.23760v1",
          "size": "1232kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:55:31+00:00",
          "link": "https://arxiv.org/abs/2503.23760v2",
          "size": "1232kb",
          "version": "v2"
        }
      ],
      "title": "Towards a cognitive architecture to enable natural language interaction in co-constructive task learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23760",
        "HTML": "https://arxiv.org/html/2503.23760v2",
        "PDF": "https://arxiv.org/pdf/2503.23760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses cognitive architectures for interaction learning but does not address LLM training data processing or construction."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.11693",
      "abstract": "We present a family of encodings for sequence labeling dependency parsing, based on the concept of hierarchical bracketing. We prove that the existing 4-bit projective encoding belongs to this family, but it is suboptimal in the number of labels used to encode a tree. We derive an optimal hierarchical bracketing, which minimizes the number of symbols used and encodes projective trees using only 12 distinct labels (vs. 16 for the 4-bit encoding). We also extend optimal hierarchical bracketing to support arbitrary non-projectivity in a more compact way than previous encodings. Our new encodings yield competitive accuracy on a diverse set of treebanks.",
      "authors": [
        "Ana Ezquerro and David Vilares and Anssi Yli-Jyr\\\"a and Carlos G\\'omez-Rodr\\'iguez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T21:01:28+00:00",
          "link": "https://arxiv.org/abs/2505.11693v1",
          "size": "8956kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:11:41+00:00",
          "link": "https://arxiv.org/abs/2505.11693v2",
          "size": "9033kb",
          "version": "v2"
        }
      ],
      "title": "Hierarchical Bracketing Encodings for Dependency Parsing as Tagging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11693",
        "HTML": "https://arxiv.org/html/2505.11693v2",
        "PDF": "https://arxiv.org/pdf/2505.11693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hierarchical bracketing encodings for dependency parsing, which is focused on sequence labeling and encoding efficiency rather than LLM training data processing."
      },
      "tasks": [
        "Dependency Parsing"
      ],
      "repo_urls": [
        "https://github.com/anaezquerro/separ"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07410",
      "abstract": "We propose EscherNet++, a masked fine-tuned diffusion model that can synthesize novel views of objects in a zero-shot manner with amodal completion ability. Existing approaches utilize multiple stages and complex pipelines to first hallucinate missing parts of the image and then perform novel view synthesis, which fail to consider cross-view dependencies and require redundant storage and computing for separate stages. Instead, we apply masked fine-tuning including input-level and feature-level masking to enable an end-to-end model with the improved ability to synthesize novel views and conduct amodal completion. In addition, we empirically integrate our model with other feed-forward image-to-mesh models without extra training and achieve competitive results with reconstruction time decreased by 95%, thanks to its ability to synthesize arbitrary query views. Our method's scalable nature further enhances fast 3D reconstruction. Despite fine-tuning on a smaller dataset and batch size, our method achieves state-of-the-art results, improving PSNR by 3.9 and Volume IoU by 0.28 on occluded tasks in 10-input settings, while also generalizing to real-world occluded reconstruction.",
      "authors": [
        "Xinan Zhang",
        "Muhammad Zubair Irshad",
        "Anthony Yezzi",
        "Yi-Chang Tsai",
        "Zsolt Kira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:08:28+00:00",
          "link": "https://arxiv.org/abs/2507.07410v1",
          "size": "13420kb",
          "version": "v1"
        }
      ],
      "title": "EscherNet++: Simultaneous Amodal Completion and Scalable View Synthesis through Masked Fine-Tuning and Enhanced Feed-Forward 3D Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07410",
        "HTML": "https://arxiv.org/html/2507.07410v1",
        "PDF": "https://arxiv.org/pdf/2507.07410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "EscherNet++ focuses on synthesis and reconstruction of views in 3D, using masked fine-tuning for improved novel view generation. It does not discuss processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07550",
      "abstract": "This position paper explores pluriperspectivism as a core element of human creative experience and its relevance to humanrobot cocreativity We propose a layered fivedimensional model to guide the design of cocreative behaviors and the analysis of interaction dynamics This model is based on literature and results from an interview study we conducted with 10 visual artists and 8 arts educators examining how pluriperspectivism supports creative practice The findings of this study provide insight in how robots could enhance human creativity through adaptive contextsensitive behavior demonstrating the potential of pluriperspectivism This paper outlines future directions for integrating pluriperspectivism with visionlanguage models VLMs to support context sensitivity in cocreative robots",
      "authors": [
        "Marianne Bossema",
        "Rob Saunders",
        "Aske Plaat",
        "Somaya Ben Allouch"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.07550v1",
          "size": "2358kb",
          "version": "v1"
        }
      ],
      "title": "Pluri-perspectivism in Human-robot Co-creativity with Older Adults",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07550",
        "HTML": "https://arxiv.org/html/2507.07550v1",
        "PDF": "https://arxiv.org/pdf/2507.07550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the concept of pluriperspectivism in human-robot creativity rather than processing LLM training data. It discusses a model for cocreative behaviors rather than data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06821",
      "abstract": "Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.",
      "authors": [
        "Chuhang Zheng",
        "Chunwei Tian",
        "Jie Wen",
        "Daoqiang Zhang",
        "and Qi Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:08:58+00:00",
          "link": "https://arxiv.org/abs/2507.06821v1",
          "size": "11235kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:58:24+00:00",
          "link": "https://arxiv.org/abs/2507.06821v2",
          "size": "11235kb",
          "version": "v2"
        }
      ],
      "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06821",
        "HTML": "https://arxiv.org/html/2507.06821v2",
        "PDF": "https://arxiv.org/pdf/2507.06821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on emotion distribution learning in a multi-modal setting and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07393",
      "abstract": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy on MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.",
      "authors": [
        "Jinseong Kim",
        "Junghoon Song",
        "Gyeongseon Baek",
        "Byeongjoon Noh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:15:57+00:00",
          "link": "https://arxiv.org/abs/2507.07393v1",
          "size": "3910kb",
          "version": "v1"
        }
      ],
      "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07393",
        "HTML": "https://arxiv.org/html/2507.07393v1",
        "PDF": "https://arxiv.org/pdf/2507.07393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a keypoint-guided video-based person re-identification framework and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07814",
      "abstract": "We present a novel local Lipschitz bound for self-attention blocks of transformers. This bound is based on a refined closed-form expression for the spectral norm of the softmax function. The resulting bound is not only more accurate than in the prior art, but also unveils the dependence of the Lipschitz constant on attention score maps. Based on the new findings, we suggest an explanation of the way distributions inside the attention map affect the robustness from the Lipschitz constant perspective. We also introduce a new lightweight regularization term called JaSMin (Jacobian Softmax norm Minimization), which boosts the transformer's robustness and decreases local Lipschitz constants of the whole network.",
      "authors": [
        "Nikolay Yudin",
        "Alexander Gaponov",
        "Sergei Kudriashov",
        "Maxim Rakhuba"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:45:31+00:00",
          "link": "https://arxiv.org/abs/2507.07814v1",
          "size": "496kb",
          "version": "v1"
        }
      ],
      "title": "Pay Attention to Attention Distribution: A New Local Lipschitz Bound for Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07814",
        "HTML": "https://arxiv.org/html/2507.07814v1",
        "PDF": "https://arxiv.org/pdf/2507.07814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a local Lipschitz bound related to self-attention in transformers, focusing on model robustness, without discussing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07988",
      "abstract": "As large language models (LLMs) become increasingly integrated into clinical decision-making, ensuring transparent and trustworthy reasoning is essential. However, existing evaluation strategies of LLMs' medical reasoning capability either suffer from unsatisfactory assessment or poor scalability, and a rigorous benchmark remains lacking. To address this, we introduce MedThink-Bench, a benchmark designed for rigorous, explainable, and scalable assessment of LLMs' medical reasoning. MedThink-Bench comprises 500 challenging questions across ten medical domains, each annotated with expert-crafted step-by-step rationales. Building on this, we propose LLM-w-Ref, a novel evaluation framework that leverages fine-grained rationales and LLM-as-a-Judge mechanisms to assess intermediate reasoning with expert-level fidelity while maintaining scalability. Experiments show that LLM-w-Ref exhibits a strong positive correlation with expert judgments. Benchmarking twelve state-of-the-art LLMs, we find that smaller models (e.g., MedGemma-27B) can surpass larger proprietary counterparts (e.g., OpenAI-o3). Overall, MedThink-Bench offers a foundational tool for evaluating LLMs' medical reasoning, advancing their safe and responsible deployment in clinical practice.",
      "authors": [
        "Shuang Zhou",
        "Wenya Xie",
        "Jiaxi Li",
        "Zaifu Zhan",
        "Meijia Song",
        "Han Yang",
        "Cheyenna Espinoza",
        "Lindsay Welton",
        "Xinnie Mai",
        "Yanwei Jin",
        "Zidu Xu",
        "Yuen-Hei Chung",
        "Yiyun Xing",
        "Meng-Han Tsai",
        "Emma Schaffer",
        "Yucheng Shi",
        "Ninghao Liu",
        "Zirui Liu",
        "Rui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:58:26+00:00",
          "link": "https://arxiv.org/abs/2507.07988v1",
          "size": "5669kb",
          "version": "v1"
        }
      ],
      "title": "Automating Expert-Level Medical Reasoning Evaluation of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07988",
        "PDF": "https://arxiv.org/pdf/2507.07988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark for evaluating LLMs' medical reasoning, it does not focus on training-data processing; instead, it centers on evaluation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07855",
      "abstract": "In this paper, we show that direct preference optimization (DPO) is a very specific form of a connection between two major theories in the ML context of learning from preferences: loss functions (Savage) and stochastic choice (Doignon-Falmagne and Machina). The connection is established for all of Savage's losses and at this level of generality, (i) it includes support for abstention on the choice theory side, (ii) it includes support for non-convex objectives on the ML side, and (iii) it allows to frame for free some notable extensions of the DPO setting, including margins and corrections for length. Getting to understand how DPO operates from a general principled perspective is crucial because of the huge and diverse application landscape of models, because of the current momentum around DPO, but also -- and importantly -- because many state of the art variations on DPO definitely occupy a small region of the map that we cover. It also helps to understand the pitfalls of departing from this map, and figure out workarounds.",
      "authors": [
        "Wenxuan Zhou",
        "Shujian Zhang",
        "Brice Magdalou",
        "John Lambert",
        "Ehsan Amid",
        "Richard Nock",
        "Andrew Hard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:38:17+00:00",
          "link": "https://arxiv.org/abs/2507.07855v1",
          "size": "328kb",
          "version": "v1"
        }
      ],
      "title": "Principled Foundations for Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07855",
        "HTML": "https://arxiv.org/html/2507.07855v1",
        "PDF": "https://arxiv.org/pdf/2507.07855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses preference optimization theories and their connections but does not make any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21582",
      "abstract": "Simulating collective decision-making involves more than aggregating individual behaviors; it emerges from dynamic interactions among individuals. While large language models (LLMs) offer strong potential for social simulation, achieving quantitative alignment with real-world data remains a key challenge. To bridge this gap, we propose the Mean-Field LLM (MF-LLM) framework, the first to incorporate mean field theory into LLM-based social simulation. MF-LLM models bidirectional interactions between individuals and the population through an iterative process, generating population signals to guide individual decisions, which in turn update the signals. This interplay produces coherent trajectories of collective behavior. To improve alignment with real-world data, we introduce IB-Tune, a novel fine-tuning method inspired by the Information Bottleneck principle, which retains population signals most predictive of future actions while filtering redundant history. Evaluated on a real-world social dataset, MF-LLM reduces KL divergence to human population distributions by 47\\% compared to non-mean-field baselines, enabling accurate trend forecasting and effective intervention planning. Generalizing across 7 domains and 4 LLM backbones, MF-LLM provides a scalable, high-fidelity foundation for social simulation.",
      "authors": [
        "Qirui Mi",
        "Mengyue Yang",
        "Xiangning Yu",
        "Zhiyu Zhao",
        "Cheng Deng",
        "Bo An",
        "Haifeng Zhang",
        "Xu Chen",
        "Jun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T12:41:51+00:00",
          "link": "https://arxiv.org/abs/2504.21582v1",
          "size": "7891kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T13:12:36+00:00",
          "link": "https://arxiv.org/abs/2504.21582v2",
          "size": "8399kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T09:59:41+00:00",
          "link": "https://arxiv.org/abs/2504.21582v3",
          "size": "1580kb",
          "version": "v3"
        }
      ],
      "title": "MF-LLM: Simulating Population Decision Dynamics via a Mean-Field Large Language Model Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21582",
        "PDF": "https://arxiv.org/pdf/2504.21582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces MF-LLM, a framework for improving alignment of LLM-generated data with real-world data. It contributes to the fine-tuning of LLMs for social simulation by introducing IB-Tune, a novel method to improve data quality."
      },
      "tasks": [
        "Decision Making",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07118",
      "abstract": "Wireless localization and sensing technologies are essential in modern wireless networks, supporting applications in smart cities, the Internet of Things (IoT), and autonomous systems. High-performance localization and sensing systems are critical for both network efficiency and emerging intelligent applications. Integrating channel state information (CSI) with deep learning has recently emerged as a promising solution. Recent works have leveraged the spatial diversity of multiple input multiple output (MIMO) systems and the frequency granularity of orthogonal frequency division multiplexing (OFDM) waveforms to improve spatial resolution. Nevertheless, the joint modeling of localization and sensing under the high-dimensional CSI characteristics of MIMO-OFDM systems remains insufficiently investigated. This work aims to jointly model and optimize localization and sensing tasks to harness their potential synergy. We first formulate localization and sensing as a mixed-integer bilevel deep learning problem and then propose a novel stochastic proximal gradient-based mixed-integer bilevel optimization (SPG-MIBO) algorithm. SPG-MIBO is well-suited for high-dimensional and large-scale datasets, leveraging mini-batch training at each step for computational and memory efficiency. The algorithm is also supported by theoretical convergence guarantees. Extensive experiments on multiple datasets validate its effectiveness and highlight the performance gains from joint localization and sensing optimization.",
      "authors": [
        "Zelin Zhu",
        "Kai Yang",
        "Rui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T06:34:22+00:00",
          "link": "https://arxiv.org/abs/2507.07118v1",
          "size": "1779kb",
          "version": "v1"
        }
      ],
      "title": "Synergistic Localization and Sensing in MIMO-OFDM Systems via Mixed-Integer Bilevel Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07118",
        "HTML": "https://arxiv.org/html/2507.07118v1",
        "PDF": "https://arxiv.org/pdf/2507.07118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work primarily deals with optimization of localization and sensing in wireless systems and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07487",
      "abstract": "Autonomous vehicles rely on global standard-definition (SD) maps for road-level route planning and online local high-definition (HD) maps for lane-level navigation. However, recent work concentrates on construct online HD maps, often overlooking the association of global SD maps with online HD maps for hybrid navigation, making challenges in utilizing online HD maps in the real world. Observing the lack of the capability of autonomous vehicles in navigation, we introduce \\textbf{O}nline \\textbf{M}ap \\textbf{A}ssociation, the first benchmark for the association of hybrid navigation-oriented online maps, which enhances the planning capabilities of autonomous vehicles. Based on existing datasets, the OMA contains 480k of roads and 260k of lane paths and provides the corresponding metrics to evaluate the performance of the model. Additionally, we propose a novel framework, named Map Association Transformer, as the baseline method, using path-aware attention and spatial attention mechanisms to enable the understanding of geometric and topological correspondences. The code and dataset can be accessed at https://github.com/WallelWan/OMA-MAT.",
      "authors": [
        "Jiaxu Wan",
        "Xu Wang",
        "Mengwei Xie",
        "Xinyuan Chang",
        "Xinran Liu",
        "Zheng Pan",
        "Mu Xu and Ding Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:16:00+00:00",
          "link": "https://arxiv.org/abs/2507.07487v1",
          "size": "7566kb",
          "version": "v1"
        }
      ],
      "title": "Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07487",
        "HTML": "https://arxiv.org/html/2507.07487v1",
        "PDF": "https://arxiv.org/pdf/2507.07487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an online HD-SD map association framework for autonomous vehicle navigation and does not focus on LLM training data processing or any related data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07507",
      "abstract": "Optical orthogonal frequency-division multiplexing (OFDM) and probabilistic constellation shaping (PCS) have emerged as powerful techniques to enhance the performance of optical wireless communications (OWC) systems. While PCS improves spectral efficiency and adaptability, we show that its integration with optical OFDM can inadvertently increase the peak-to-average power ratio (PAPR) of the signal, exacerbating clipping distortion due to signal clipping. This letter investigates the impact of PCS on the PAPR of direct current-biased optical OFDM (DCO-OFDM) waveforms and proposes an optimization of PCS that maximizes channel capacity, considering clipping distortion. The optimization problem is shown to be complex and non-convex. We thus present a suboptimal yet efficient solving approach based on projected gradient descent to solve the problem. Simulation results demonstrate the superiority of the proposed approach over the conventional uniform signaling, particularly under severe clipping distortion conditions.",
      "authors": [
        "Thanh V. Pham and Susumu Ishihara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:52:31+00:00",
          "link": "https://arxiv.org/abs/2507.07507v1",
          "size": "953kb",
          "version": "v1"
        }
      ],
      "title": "Optimization of Probabilistic Constellation Shaping for Optical OFDM Systems with Clipping Distortion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07507",
        "HTML": "https://arxiv.org/html/2507.07507v1",
        "PDF": "https://arxiv.org/pdf/2507.07507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on optical OFDM systems and probabilistic constellation shaping, addressing issues of signal distortion and channel capacity optimization, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07882",
      "abstract": "We evaluate the feasibility of using co-folding models for synthetic data augmentation in training machine learning-based scoring functions (MLSFs) for binding affinity prediction. Our results show that performance gains depend critically on the structural quality of augmented data. In light of this, we established simple heuristics for identifying high-quality co-folding predictions without reference structures, enabling them to substitute for experimental structures in MLSF training. Our study informs future data augmentation strategies based on co-folding models.",
      "authors": [
        "Wei-Tse Hsu",
        "Savva Grevtsev",
        "Thomas Douglas",
        "Aniket Magarkar",
        "Philip C. Biggin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:05:16+00:00",
          "link": "https://arxiv.org/abs/2507.07882v1",
          "size": "5860kb",
          "version": "v1"
        }
      ],
      "title": "Can AI-predicted complexes teach machine learning to compute drug binding affinity?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07882",
        "HTML": "https://arxiv.org/html/2507.07882v1",
        "PDF": "https://arxiv.org/pdf/2507.07882"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on synthetic data augmentation for training machine learning scoring functions, establishing heuristics to identify high-quality augmented data, which is crucial in improving data quality for training purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.16609",
      "abstract": "While much work on web agents emphasizes the promise of autonomously performing tasks on behalf of users, in reality, agents often fall short on complex tasks in real-world contexts and modeling user preference. This presents an opportunity for humans to collaborate with the agent and leverage the agent's capabilities effectively. We propose CowPilot, a framework supporting autonomous as well as human-agent collaborative web navigation, and evaluation across task success and task efficiency. CowPilot reduces the number of steps humans need to perform by allowing agents to propose next steps, while users are able to pause, reject, or take alternative actions. During execution, users can interleave their actions with the agent by overriding suggestions or resuming agent control when needed. We conducted case studies on five common websites and found that the human-agent collaborative mode achieves the highest success rate of 95% while requiring humans to perform only 15.2% of the total steps. Even with human interventions during task execution, the agent successfully drives up to half of task success on its own. CowPilot can serve as a useful tool for data collection and agent evaluation across websites, which we believe will enable research in how users and agents can work together. Video demonstrations are available at https://oaishi.github.io/cowpilot.html",
      "authors": [
        "Faria Huq",
        "Zora Zhiruo Wang",
        "Frank F. Xu",
        "Tianyue Ou",
        "Shuyan Zhou",
        "Jeffrey P. Bigham",
        "Graham Neubig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T00:56:53+00:00",
          "link": "https://arxiv.org/abs/2501.16609v1",
          "size": "6876kb",
          "version": "v1"
        },
        {
          "date": "2025-02-09T23:03:56+00:00",
          "link": "https://arxiv.org/abs/2501.16609v2",
          "size": "6876kb",
          "version": "v2"
        },
        {
          "date": "2025-04-05T23:49:31+00:00",
          "link": "https://arxiv.org/abs/2501.16609v3",
          "size": "6801kb",
          "version": "v3"
        }
      ],
      "title": "CowPilot: A Framework for Autonomous and Human-Agent Collaborative Web Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16609",
        "HTML": "https://arxiv.org/html/2501.16609",
        "PDF": "https://arxiv.org/pdf/2501.16609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces CowPilot for collaborative web navigation, it mentions potential data collection which could involve aspects of data processing, but it's not the primary focus."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.01628",
      "abstract": "In this paper, we introduce harmonic loss as an alternative supervisory signal for training neural networks and large language models (LLMs). Harmonic loss differs from standard cross-entropy loss by (a) replacing the usual SoftMax normalization with a scale-invariant HarMax function and (b) computing logits via Euclidean distance rather than a dot product. Harmonic loss enables improved interpretability and faster convergence, owing to its scale invariance and finite convergence point by design, which can be interpreted as a class center. We first validate the performance of harmonic models across algorithmic, vision, and language datasets. Through extensive experiments, we demonstrate that models trained with harmonic loss perform better than standard models by: (a) enhancing interpretability, (b) requiring less data for generalization, and (c) reducing grokking. Moreover, we compare a GPT-2 model trained with harmonic loss to the standard GPT-2, illustrating that the harmonic model develops more interpretable representations. Looking forward, we believe harmonic loss may become a valuable tool in domains with limited data availability or in high-stakes applications where interpretability and reliability are paramount, paving the way for more robust and efficient neural network models.",
      "authors": [
        "David D. Baek",
        "Ziming Liu",
        "Riya Tyagi",
        "Max Tegmark"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T18:57:17+00:00",
          "link": "https://arxiv.org/abs/2502.01628v1",
          "size": "4895kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T04:29:17+00:00",
          "link": "https://arxiv.org/abs/2502.01628v2",
          "size": "5273kb",
          "version": "v2"
        }
      ],
      "title": "Harmonic Loss Trains Interpretable AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01628",
        "HTML": "https://arxiv.org/html/2502.01628v2",
        "PDF": "https://arxiv.org/pdf/2502.01628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces harmonic loss for training models, focusing on its benefits for interpretability and generalization, without discussing LLM training data processing."
      },
      "tasks": [
        "Efficient Neural Network"
      ],
      "repo_urls": [
        "https://github.com/ches-001/audio-segmenter"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22827",
      "abstract": "Enabling humanoid robots to reliably execute complex multi-step manipulation tasks is crucial for their effective deployment in industrial and household environments. This paper presents a hierarchical planning and control framework designed to achieve reliable multi-step humanoid manipulation. The proposed system comprises three layers: (1) a low-level RL-based controller responsible for tracking whole-body motion targets; (2) a mid-level set of skill policies trained via imitation learning that produce motion targets for different steps of a task; and (3) a high-level vision-language planning module that determines which skills should be executed and also monitors their completion in real-time using pretrained vision-language models (VLMs). Experimental validation is performed on a Unitree G1 humanoid robot executing a non-prehensile pick-and-place task. Over 40 real-world trials, the hierarchical system achieved a 73% success rate in completing the full manipulation sequence. These experiments confirm the feasibility of the proposed hierarchical system, highlighting the benefits of VLM-based skill planning and monitoring for multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for video demonstrations of the policy rollout.",
      "authors": [
        "Andr\\'e Schakkal",
        "Ben Zandonati",
        "Zhutian Yang and Navid Azizan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:39:37+00:00",
          "link": "https://arxiv.org/abs/2506.22827v1",
          "size": "14555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T15:24:43+00:00",
          "link": "https://arxiv.org/abs/2506.22827v2",
          "size": "14497kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:49:49+00:00",
          "link": "https://arxiv.org/abs/2506.22827v3",
          "size": "14497kb",
          "version": "v3"
        }
      ],
      "title": "Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22827",
        "HTML": "https://arxiv.org/html/2506.22827v3",
        "PDF": "https://arxiv.org/pdf/2506.22827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hierarchical vision-language planning framework for humanoid robots, which does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03015",
      "abstract": "Current diversification strategies for text-to-image (T2I) models often ignore contextual appropriateness, leading to over-diversification where demographic attributes are modified even when explicitly specified in prompts. This paper introduces DIVBENCH, a benchmark and evaluation framework for measuring both under- and over-diversification in T2I generation. Through systematic evaluation of state-of-the-art T2I models, we find that while most models exhibit limited diversity, many diversification approaches overcorrect by inappropriately altering contextually-specified attributes. We demonstrate that context-aware methods, particularly LLM-guided FairDiffusion and prompt rewriting, can already effectively address under-diversity while avoiding over-diversification, achieving a better balance between representation and semantic fidelity.",
      "authors": [
        "Felix Friedrich",
        "Thiemo Ganesha Welsch",
        "Manuel Brack",
        "Patrick Schramowski",
        "Kristian Kersting"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T13:14:42+00:00",
          "link": "https://arxiv.org/abs/2507.03015v1",
          "size": "330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.03015v2",
          "size": "651kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Overcorrection: Evaluating Diversity in T2I Models with DivBench",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03015",
        "HTML": "https://arxiv.org/html/2507.03015v2",
        "PDF": "https://arxiv.org/pdf/2507.03015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating diversity in text-to-image models, focusing on model evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07468",
      "abstract": "The integration of Industry 4.0 technologies into engineering workflows is an essential step toward automating and optimizing plant and process engineering processes. The Asset Administration Shell (AAS) serves as a key enabler for creating interoperable Digital Twins that facilitate engineering data exchange and automation. This paper explores the use of AAS within engineering workflows, particularly in combination with Business Process Model and Notation (BPMN) to define structured and automated processes. We propose a distributed AAS copy-on-write infrastructure that enhances security and scalability while enabling seamless cross organizational collaboration. We also introduce a workflow management prototype automating AAS operations and engineering workflows, improving efficiency and traceability.",
      "authors": [
        "Sten Gr\\\"uner",
        "Nafise Eskandani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:49:53+00:00",
          "link": "https://arxiv.org/abs/2507.07468v1",
          "size": "207kb",
          "version": "v1"
        }
      ],
      "title": "Towards an Engineering Workflow Management System for Asset Administration Shells using BPMN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07468",
        "HTML": "https://arxiv.org/html/2507.07468v1",
        "PDF": "https://arxiv.org/pdf/2507.07468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes workflow management for engineering processes using AAS and BPMN, without any discussion on LLM training data processing or data collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07789",
      "abstract": "Recent work has demonstrated that imaging systems can be evaluated through the information content of their measurements alone, enabling application-agnostic optical design that avoids computational decoding challenges. Information-Driven Encoder Analysis Learning (IDEAL) was proposed to automate this process through gradient-based. In this work, we study IDEAL across diverse imaging systems and find that it suffers from high memory usage, long runtimes, and a potentially mismatched objective function due to end-to-end differentiability requirements. We introduce IDEAL with Interchanging Optimization (IDEAL-IO), a method that decouples density estimation from optical parameter optimization by alternating between fitting models to current measurements and updating optical parameters using fixed models for information estimation. This approach reduces runtime and memory usage by up to 6x while enabling more expressive density models that guide optimization toward superior designs. We validate our method on diffractive optics, lensless imaging, and snapshot 3D microscopy applications, establishing information-theoretic optimization as a practical, scalable strategy for real-world imaging system design.",
      "authors": [
        "Eric Markley",
        "Henry Pinkard",
        "Leyla Kabuli",
        "Nalini Singh",
        "Laura Waller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:14:08+00:00",
          "link": "https://arxiv.org/abs/2507.07789v1",
          "size": "15465kb",
          "version": "v1"
        }
      ],
      "title": "Computationally Efficient Information-Driven Optical Design with Interchanging Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07789",
        "HTML": "https://arxiv.org/html/2507.07789v1",
        "PDF": "https://arxiv.org/pdf/2507.07789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optical design and optimization using the IDEAL method, which is unrelated to LLM training data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02351",
      "abstract": "In the field of deep learning, traditional attention mechanisms face significant challenges related to high computational complexity and large memory consumption when processing long sequence data. To address these limitations, we propose Opt-GPTQ, an optimized Gradient-based Post Training Quantization (GPTQ) combining the Grouped Query Attention (GQA) mechanism with paging memory management, optimizing the traditional Multi-Head Attention (MHA) mechanism by grouping query heads and sharing key-value vectors. Optimized GQA (Opt-GQA) effectively reduces computational complexity, minimizes memory fragmentation, and enhances memory utilization for large-scale models. Opt-GPTQ is optimized for Data Center Units (DCUs) and integrated into the vLLM model to maximize hardware efficiency. It customizes GPU kernels to further enhance attention computation by reducing memory access latency and boosting parallel computing capabilities. Opt-GQA integrates Attention with Linear Biases (ALiBi) to reduce overhead and enhance long-sequence processing. Experimental results show that Opt-GPTQ significantly reduces computation time and memory usage while improving model performance.",
      "authors": [
        "Jie Kong",
        "Junxiang Zhang",
        "Jiheng Xu",
        "Yalong Li",
        "Shouhua Zhang",
        "Jiehan Zhou",
        "Yuhai Liu",
        "Peng Liang",
        "Quan Zhang",
        "Luohan Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T04:20:40+00:00",
          "link": "https://arxiv.org/abs/2505.02351v1",
          "size": "545kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:04:02+00:00",
          "link": "https://arxiv.org/abs/2505.02351v2",
          "size": "265kb",
          "version": "v2"
        }
      ],
      "title": "Opt-GPTQ: An Optimized GPTQ Combining Sparse Attention and Quantization Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02351",
        "HTML": "https://arxiv.org/html/2505.02351v2",
        "PDF": "https://arxiv.org/pdf/2505.02351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses optimization techniques for LLMs focusing on memory and computational efficiency using sparse attention and quantization, without major focus on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07114",
      "abstract": "State-of-the-art language and vision models are routinely trained across thousands of GPUs, often spanning multiple data-centers, yet today's distributed frameworks still assume reliable connections (e.g., InfiniBand or RoCE). The resulting acknowledgment traffic and retransmissions inflate tail latencies and limit scalability. Leveraging unreliable connections will reduce latency but may sacrifice model accuracy and convergence once packets are dropped. A principled, end-to-end solution that preserves accuracy and convergence guarantees under genuine packet loss has previously been missing. We address this critical gap by introducing a novel distributed training framework capable of operating over unreliable connections, offering unbiased gradient aggregation and bounded parameter drift without modifying model code or optimizers. The key insight is a two-stage defense against missing messages: (i) Unbiased gradient aggregation: each worker reconstructs a consistent gradient estimate from whatever packets arrive, guaranteeing expectation-level correctness; and (ii) Bounded-drift parameter broadcasts: we prove the inter-worker model discrepancy remains O(1) even after arbitrarily many iterations, preventing the unbounded divergence typical of asynchronous setups. Analytical bounds are matched by experiments on the LLAMA2 7B model with 64 GPUs: tolerating 10% random packet loss yields at most 0.8% perplexity change. This work bridges the gap between communication-efficient datacenter protocols and the accuracy and generalization guarantees demanded by modern large-model training, enabling robust, high-throughput learning on commodity or wide-area networks.",
      "authors": [
        "Erez Weintraub",
        "Ron Banner",
        "Ariel Orda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T11:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.07114v1",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Training under Packet Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07114",
        "HTML": "https://arxiv.org/html/2507.07114v1",
        "PDF": "https://arxiv.org/pdf/2507.07114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a distributed training framework that addresses packet loss in model training, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07216",
      "abstract": "Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability.",
      "authors": [
        "Yunyi Li",
        "Maria De-Arteaga and Maytal Saar-Tsechansky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:44:36+00:00",
          "link": "https://arxiv.org/abs/2507.07216v1",
          "size": "4503kb",
          "version": "v1"
        }
      ],
      "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07216",
        "HTML": "https://arxiv.org/html/2507.07216v1",
        "PDF": "https://arxiv.org/pdf/2507.07216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "DeCoLe targets mislabeling detection by addressing label bias, which is related to improving the quality of training datasets, a key aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07414",
      "abstract": "Time, cost, and energy efficiency are critical considerations in Deep-Learning (DL), particularly when processing long texts. Transformers, which represent the current state of the art, exhibit quadratic computational complexity relative to input length, making them inefficient for extended documents. This study introduces a novel model architecture that combines Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated with a real-time, end-to-end graph generation mechanism. The model processes compact batches of character-level inputs without requiring padding or truncation. To enhance performance while maintaining high speed and efficiency, the model incorporates information from Large Language Models (LLMs), such as token embeddings and sentiment polarities, through efficient dictionary lookups. It captures local contextual patterns using CNNs, expands local receptive fields via lattice-based graph structures, and employs small-world graphs to aggregate document-level information. The generated graphs exhibit structural properties indicative of meaningful semantic organization, with an average clustering coefficient of approximately 0.45 and an average shortest path length ranging between 4 and 5. The model is evaluated across multiple text classification tasks, including sentiment analysis and news-categorization, and is compared against state-of-the-art models. Experimental results confirm the proposed model's efficiency and competitive performance.",
      "authors": [
        "Fardin Rastakhiz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:13:53+00:00",
          "link": "https://arxiv.org/abs/2507.07414v1",
          "size": "7406kb",
          "version": "v1"
        }
      ],
      "title": "GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07414",
        "HTML": "https://arxiv.org/html/2507.07414v1",
        "PDF": "https://arxiv.org/pdf/2507.07414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a hybrid model architecture for text representation and briefly mentions utilizing embeddings from LLMs, but does not focus on processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.17070",
      "abstract": "Temporal networks are effective in capturing the evolving interactions of networks over time, such as social networks and e-commerce networks. In recent years, researchers have primarily concentrated on developing specific model architectures for Temporal Graph Neural Networks (TGNNs) in order to improve the representation quality of temporal nodes and edges. However, limited attention has been given to the quality of negative samples during the training of TGNNs. When compared with static networks, temporal networks present two specific challenges for negative sampling: positive sparsity and positive shift. Positive sparsity refers to the presence of a single positive sample amidst numerous negative samples at each timestamp, while positive shift relates to the variations in positive samples across different timestamps. To robustly address these challenges in training TGNNs, we introduce Curriculum Negative Mining (CurNM), a model-aware curriculum learning framework that adaptively adjusts the difficulty of negative samples. Within this framework, we first establish a dynamically updated negative pool that balances random, historical, and hard negatives to address the challenges posed by positive sparsity. Secondly, we implement a temporal-aware negative selection module that focuses on learning from the disentangled factors of recently active edges, thus accurately capturing shifting preferences. Finally, the selected negatives are combined with annealing random negatives to support stable training. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our method outperforms baseline methods by a significant margin. Additionally, thorough ablation studies and parameter sensitivity experiments verify the usefulness and robustness of our approach.",
      "authors": [
        "Ziyue Chen",
        "Tongya Zheng",
        "Mingli Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T07:55:49+00:00",
          "link": "https://arxiv.org/abs/2407.17070v1",
          "size": "578kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:15:07+00:00",
          "link": "https://arxiv.org/abs/2407.17070v2",
          "size": "191kb",
          "version": "v2"
        }
      ],
      "title": "Curriculum Negative Mining For Temporal Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17070",
        "HTML": "https://arxiv.org/html/2407.17070v2",
        "PDF": "https://arxiv.org/pdf/2407.17070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses negative sample quality in temporal networks within TGNNs, but it does not involve processing or creating LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zziyue83/curnm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07920",
      "abstract": "We study the complexity of the directed periodic temporal graph realization problem. This work is motivated by the design of periodic schedules in public transport with constraints on the quality of service. Namely, we require that the fastest path between (important) pairs of vertices is upper bounded by a specified maximum duration, encoded in an upper distance matrix $D$. While previous work has considered the undirected version of the problem, the application in public transport schedule design requires the flexibility to assign different departure times to the two directions of an edge. A problem instance can only be feasible if all values of the distance matrix are at least shortest path distances. However, the task of realizing exact fastest path distances in a periodic temporal graph is often too restrictive. Therefore, we introduce a minimum slack parameter $k$ that describes a lower bound on the maximum allowed waiting time on each path. We concentrate on tree topologies and provide a full characterization of the complexity landscape with respect to the period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp threshold between NP-complete cases and cases which are always realizable. We also provide hardness results for the special case of period $\\Delta = 2$ for general directed and undirected graphs.",
      "authors": [
        "Julia Meusel and Matthias M\\\"uller-Hannemann and Klaus Reinhardt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T17:36:23+00:00",
          "link": "https://arxiv.org/abs/2504.07920v1",
          "size": "1071kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T07:14:06+00:00",
          "link": "https://arxiv.org/abs/2504.07920v2",
          "size": "916kb",
          "version": "v2"
        }
      ],
      "title": "Directed Temporal Tree Realization for Periodic Public Transport: Easy and Hard Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07920",
        "HTML": "https://arxiv.org/html/2504.07920v2",
        "PDF": "https://arxiv.org/pdf/2504.07920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with periodic public transport schedules involving temporal graph realization, offering no insights into LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07619",
      "abstract": "This paper explores belief inference in credal networks using Dempster-Shafer theory. By building on previous work, we propose a novel framework for propagating uncertainty through a subclass of credal networks, namely chains. The proposed approach efficiently yields conservative intervals through belief and plausibility functions, combining computational speed with robust uncertainty representation. Key contributions include formalizing belief-based inference methods and comparing belief-based inference against classical sensitivity analysis. Numerical results highlight the advantages and limitations of applying belief inference within this framework, providing insights into its practical utility for chains and for credal networks in general.",
      "authors": [
        "Marco Sangalli",
        "Thomas Krak",
        "Cassio de Campos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:40:24+00:00",
          "link": "https://arxiv.org/abs/2507.07619v1",
          "size": "268kb",
          "version": "v1"
        }
      ],
      "title": "Towards conservative inference in credal networks using belief functions: the case of credal chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07619",
        "HTML": "https://arxiv.org/html/2507.07619v1",
        "PDF": "https://arxiv.org/pdf/2507.07619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses inference in credal networks and uncertainty propagation, but does not cover processing or creating training data for large language models (LLMs)."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06539",
      "abstract": "This paper proposes a high-quality dataset construction method for complex contract information extraction tasks in industrial scenarios and fine-tunes a large language model based on this dataset. Firstly, cluster analysis is performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to extract key information from the original contract data, obtaining high-quality data annotations. Secondly, data augmentation is achieved by constructing new texts, and GPT-3.5 generates unstructured contract texts from randomly combined keywords, improving model robustness. Finally, the large language model is fine-tuned based on the high-quality dataset. Experimental results show that the model achieves excellent overall performance while ensuring high field recall and precision and considering parsing efficiency. LoRA, data balancing, and data augmentation effectively enhance model accuracy and robustness. The proposed method provides a novel and efficient solution for industrial contract information extraction tasks.",
      "authors": [
        "Yunyang Cao",
        "Yanjun Li",
        "Silong Dai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.06539v1",
          "size": "2613kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:51:21+00:00",
          "link": "https://arxiv.org/abs/2507.06539v2",
          "size": "2613kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Model for Extracting Complex Contract Information in Industrial Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06539",
        "HTML": "https://arxiv.org/html/2507.06539v2",
        "PDF": "https://arxiv.org/pdf/2507.06539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper primarily contributes to LLM training data processing by constructing a high-quality dataset for contract information extraction and applying data augmentation techniques, significantly improving model accuracy and robustness."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07375",
      "abstract": "Reward models trained on human preference data have demonstrated strong effectiveness in aligning Large Language Models (LLMs) with human intent under the framework of Reinforcement Learning from Human Feedback (RLHF). However, RLHF remains vulnerable to reward hacking, where the policy exploits imperfections in the reward function rather than genuinely learning the intended behavior. Although significant efforts have been made to mitigate reward hacking, they predominantly focus on and evaluate in-distribution scenarios, where the training and testing data for the reward model share the same distribution. In this paper, we empirically show that state-of-the-art methods struggle in more challenging out-of-distribution (OOD) settings. We further demonstrate that incorporating fine-grained multi-attribute scores helps address this challenge. However, the limited availability of high-quality data often leads to weak performance of multi-objective reward functions, which can negatively impact overall performance and become the bottleneck. To address this issue, we propose a unified reward modeling framework that jointly trains Bradley--Terry (BT) single-objective and multi-objective regression-based reward functions using a shared embedding space. We theoretically establish a connection between the BT loss and the regression objective and highlight their complementary benefits. Specifically, the regression task enhances the single-objective reward function's ability to mitigate reward hacking in challenging OOD settings, while BT-based training improves the scoring capability of the multi-objective reward function, enabling a 7B model to outperform a 70B baseline. Extensive experimental results demonstrate that our framework significantly improves both the robustness and the scoring performance of reward models.",
      "authors": [
        "Zhiwei Zhang",
        "Hui Liu",
        "Xiaomin Li",
        "Zhenwei Dai",
        "Jingying Zeng",
        "Fali Wang",
        "Minhua Lin",
        "Ramraj Chandradevan",
        "Zhen Li",
        "Chen Luo",
        "Xianfeng Tang",
        "Qi He",
        "Suhang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:56:56+00:00",
          "link": "https://arxiv.org/abs/2507.07375v1",
          "size": "397kb",
          "version": "v1"
        }
      ],
      "title": "Bradley-Terry and Multi-Objective Reward Modeling Are Complementary",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07375",
        "HTML": "https://arxiv.org/html/2507.07375v1",
        "PDF": "https://arxiv.org/pdf/2507.07375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses reward modeling using human preference data but focuses on reward hacking mitigation and a unified reward modeling framework. It does not make a contribution specifically to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.08390",
      "abstract": "Robot swarms can effectively serve a variety of sensing and inspection applications. Certain inspection tasks require a binary classification decision. This work presents an experimental setup for a surface inspection task based on vibration sensing and studies a Bayesian two-outcome decision-making algorithm in a swarm of miniaturized wheeled robots. The robots are tasked with individually inspecting and collectively classifying a 1mx1m tiled surface consisting of vibrating and non-vibrating tiles based on the majority type of tiles. The robots sense vibrations using onboard IMUs and perform collision avoidance using a set of IR sensors. We develop a simulation and optimization framework leveraging the Webots robotic simulator and a Particle Swarm Optimization (PSO) method. We consider two existing information sharing strategies and propose a new one that allows the swarm to rapidly reach accurate classification decisions. We first find optimal parameters that allow efficient sampling in simulation and then evaluate our proposed strategy against the two existing ones using 100 randomized simulation and 10 real experiments. We find that our proposed method compels the swarm to make decisions at an accelerated rate, with an improvement of up to 20.52% in mean decision time at only 0.78% loss in accuracy.",
      "authors": [
        "Thiemen Siemensma",
        "Darren Chiu",
        "Sneha Ramshanker",
        "Radhika Nagpal and Bahar Haghighat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-12T10:48:59+00:00",
          "link": "https://arxiv.org/abs/2404.08390v1",
          "size": "9862kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:46:14+00:00",
          "link": "https://arxiv.org/abs/2404.08390v2",
          "size": "37089kb",
          "version": "v2"
        }
      ],
      "title": "Collective Bayesian Decision-Making in a Swarm of Miniaturized Robots for Surface Inspection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.08390",
        "HTML": "https://arxiv.org/html/2404.08390v2",
        "PDF": "https://arxiv.org/pdf/2404.08390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on decision-making algorithms in robot swarms for surface inspection, which does not pertain to LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07394",
      "abstract": "Animal motion embodies species-specific behavioral habits, making the transfer of motion across categories a critical yet complex task for applications in animation and virtual reality. Existing motion transfer methods, primarily focused on human motion, emphasize skeletal alignment (motion retargeting) or stylistic consistency (motion style transfer), often neglecting the preservation of distinct habitual behaviors in animals. To bridge this gap, we propose a novel habit-preserved motion transfer framework for cross-category animal motion. Built upon a generative framework, our model introduces a habit-preservation module with category-specific habit encoder, allowing it to learn motion priors that capture distinctive habitual characteristics. Furthermore, we integrate a large language model (LLM) to facilitate the motion transfer to previously unobserved species. To evaluate the effectiveness of our approach, we introduce the DeformingThings4D-skl dataset, a quadruped dataset with skeletal bindings, and conduct extensive experiments and quantitative analyses, which validate the superiority of our proposed model.",
      "authors": [
        "Zhimin Zhang",
        "Bi'an Du",
        "Caoyuan Ma",
        "Zheng Wang",
        "Wei Hu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:25:50+00:00",
          "link": "https://arxiv.org/abs/2507.07394v1",
          "size": "3367kb",
          "version": "v1"
        }
      ],
      "title": "Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07394",
        "HTML": "https://arxiv.org/html/2507.07394v1",
        "PDF": "https://arxiv.org/pdf/2507.07394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper introduces a new dataset (DeformingThings4D-skl), the focus is on motion transfer and integration with LLM without detailed data processing steps related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07778",
      "abstract": "Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks.",
      "authors": [
        "Wooseong Jeong",
        "Jegyeong Cho",
        "Youngho Yoon",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:58:32+00:00",
          "link": "https://arxiv.org/abs/2507.07778v1",
          "size": "2554kb",
          "version": "v1"
        }
      ],
      "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07778",
        "HTML": "https://arxiv.org/html/2507.07778v1",
        "PDF": "https://arxiv.org/pdf/2507.07778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on synchronizing task behavior during test-time training, which does not involve LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07927",
      "abstract": "Most contemporary mobile devices offer hardware-backed storage for cryptographic keys, user data, and other sensitive credentials. Such hardware protects credentials from extraction by an adversary who has compromised the main operating system, such as a malicious third-party app. Since 2011, Android app developers can access trusted hardware via the Android Keystore API. In this work, we conduct the first comprehensive survey of hardware-backed key storage in Android devices. We analyze 490 119 Android apps, collecting data on how trusted hardware is used by app developers (if used at all) and cross-referencing our findings with sensitive user data collected by each app, as self-reported by developers via the Play Store's data safety labels.\n  We find that despite industry-wide initiatives to encourage adoption, 56.3% of apps self-reporting as processing sensitive user data do not use Android's trusted hardware capabilities at all, while just 5.03% of apps collecting some form of sensitive data use the strongest form of trusted hardware, a secure element distinct from the main processor. To better understand the potential downsides of using secure hardware, we conduct the first empirical analysis of trusted hardware performance in mobile devices, measuring the runtime of common cryptographic operations across both software- and hardware-backed keystores. We find that while hardware-backed key storage using a coprocessor is viable for most common cryptographic operations, secure elements capable of preventing more advanced attacks make performance infeasible for symmetric encryption with non-negligible payloads and any kind of asymmetric encryption.",
      "authors": [
        "Jenny Blessing",
        "Ross J. Anderson",
        "Alastair R. Beresford"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:07:54+00:00",
          "link": "https://arxiv.org/abs/2507.07927v1",
          "size": "407kb",
          "version": "v1"
        }
      ],
      "title": "KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07927",
        "HTML": "https://arxiv.org/html/2507.07927v1",
        "PDF": "https://arxiv.org/pdf/2507.07927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes secure key storage in Android apps, focusing on hardware-backed security, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05270",
      "abstract": "Integrating third-party software components is a common practice in modern software development, offering significant advantages in terms of efficiency and innovation. However, this practice is fraught with risks related to software licensing. A lack of understanding may lead to disputes, which can pose serious legal and operational challenges. To these ends, both academia and industry have conducted various investigations and proposed solutions and tools to deal with these challenges. However, significant limitations still remain. Moreover, the rapid evolution of open-source software (OSS) licenses, as well as the rapidly incorporated generative software engineering techniques, such as large language models for code (CodeLLMs), are placing greater demands on the systematic management of software license risks. To unveil the severe challenges and explore possible future directions, we conduct the first systematic literature review (SLR) on 80 carefully selected OSS license-related papers, classifying existing research into three key categories, i.e., license identification, license risk assessment, and license risk mitigation. Based on these, we discuss challenges in existing solutions, conclude the opportunities to shed light on future research directions and offer practical recommendations for practitioners. We hope this thorough review will help bridge the gaps between academia and industry and accelerate the ecosystem-wide governance of legitimate software risks within the software engineering community.",
      "authors": [
        "Boyuan Li",
        "Chengwei Liu",
        "Lingling Fan",
        "Sen Chen",
        "Zhenlin Zhang",
        "and Zheli Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:02:15+00:00",
          "link": "https://arxiv.org/abs/2507.05270v1",
          "size": "387kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:37:05+00:00",
          "link": "https://arxiv.org/abs/2507.05270v2",
          "size": "234kb",
          "version": "v2"
        }
      ],
      "title": "Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05270",
        "PDF": "https://arxiv.org/pdf/2507.05270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on OSS license management and does not discuss or contribute to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07135",
      "abstract": "The composed image retrieval (CIR) task is to retrieve target images given a reference image and a modification text. Recent methods for CIR leverage large pretrained vision-language models (VLMs) and achieve good performance on general-domain concepts like color and texture. However, they still struggle with application domains like fashion, because the rich and diverse vocabulary used in fashion requires specific fine-grained vision and language understanding. An additional difficulty is the lack of large-scale fashion datasets with detailed and relevant annotations, due to the expensive cost of manual annotation by specialists. To address these challenges, we introduce FACap, a large-scale, automatically constructed fashion-domain CIR dataset. It leverages web-sourced fashion images and a two-stage annotation pipeline powered by a VLM and a large language model (LLM) to generate accurate and detailed modification texts. Then, we propose a new CIR model FashionBLIP-2, which fine-tunes the general-domain BLIP-2 model on FACap with lightweight adapters and multi-head query-candidate matching to better account for fine-grained fashion-specific information. FashionBLIP-2 is evaluated with and without additional fine-tuning on the Fashion IQ benchmark and the enhanced evaluation dataset enhFashionIQ, leveraging our pipeline to obtain higher-quality annotations. Experimental results show that the combination of FashionBLIP-2 and pretraining with FACap significantly improves the model's performance in fashion CIR especially for retrieval with fine-grained modification texts, demonstrating the value of our dataset and approach in a highly demanding environment such as e-commerce websites. Code is available at https://fgxaos.github.io/facap-paper-website/.",
      "authors": [
        "Fran\\c{c}ois Gard\\`eres",
        "Shizhe Chen",
        "Camille-Sovanneary Gauthier",
        "Jean Ponce"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:02:10+00:00",
          "link": "https://arxiv.org/abs/2507.07135v1",
          "size": "2561kb",
          "version": "v1"
        }
      ],
      "title": "FACap: A Large-scale Fashion Dataset for Fine-grained Composed Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07135",
        "HTML": "https://arxiv.org/html/2507.07135v1",
        "PDF": "https://arxiv.org/pdf/2507.07135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces FACap, a large-scale fashion dataset constructed with a detailed two-stage annotation pipeline powered by a VLM and LLMs, focusing on training-data processing to generate modification texts for fashion CIR tasks, demonstrating improved LLM data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07293",
      "abstract": "New discoveries in chemistry and materials science, with increasingly expanding volume of requisite knowledge and experimental workload, provide unique opportunities for machine learning (ML) to take critical roles in accelerating research efficiency. Here, we demonstrate (1) the use of large language models (LLMs) for automated literature reviews, and (2) the training of an ML model to predict chemical knowledge (thermodynamic parameters). Our LLM-based literature review tool (LMExt) successfully extracted chemical information and beyond into a machine-readable structure, including stability constants for metal cation-ligand interactions, thermodynamic properties, and other broader data types (medical research papers, and financial reports), effectively overcoming the challenges inherent in each domain. Using the autonomous acquisition of thermodynamic data, an ML model was trained using the CatBoost algorithm for accurately predicting thermodynamic parameters (e.g., enthalpy of formation) of minerals. This work highlights the transformative potential of integrated ML approaches to reshape chemistry and materials science research.",
      "authors": [
        "Juejing Liu",
        "Haydn Anderson",
        "Noah I. Waxman",
        "Vsevolod Kovalev",
        "Byron Fisher",
        "Elizabeth Li",
        "Xiaofeng Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:33:25+00:00",
          "link": "https://arxiv.org/abs/2507.07293v1",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "title": "Thermodynamic Prediction Enabled by Automatic Dataset Building and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07293",
        "PDF": "https://arxiv.org/pdf/2507.07293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions the use of LLMs for automated literature reviews, which might involve some data processing, its primary focus is on predicting chemical knowledge and not on processing or creating datasets specifically for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04424",
      "abstract": "Calculating or accurately estimating log-determinants of large positive definite matrices is of fundamental importance in many machine learning tasks. While its cubic computational complexity can already be prohibitive, in modern applications, even storing the matrices themselves can pose a memory bottleneck. To address this, we derive a novel hierarchical algorithm based on block-wise computation of the LDL decomposition for large-scale log-determinant calculation in memory-constrained settings. In extreme cases where matrices are highly ill-conditioned, accurately computing the full matrix itself may be infeasible. This is particularly relevant when considering kernel matrices at scale, including the empirical Neural Tangent Kernel (NTK) of neural networks trained on large datasets. Under the assumption of neural scaling laws in the test error, we show that the ratio of pseudo-determinants satisfies a power-law relationship, allowing us to derive corresponding scaling laws. This enables accurate estimation of NTK log-determinants from a tiny fraction of the full dataset; in our experiments, this results in a $\\sim$100,000$\\times$ speedup with improved accuracy over competing approximations. Using these techniques, we successfully estimate log-determinants for dense matrices of extreme sizes, which were previously deemed intractable and inaccessible due to their enormous scale and computational demands.",
      "authors": [
        "Siavash Ameli",
        "Chris van der Heide",
        "Liam Hodgkinson",
        "Fred Roosta",
        "Michael W. Mahoney"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T13:32:13+00:00",
          "link": "https://arxiv.org/abs/2503.04424v1",
          "size": "4575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T04:07:04+00:00",
          "link": "https://arxiv.org/abs/2503.04424v2",
          "size": "7002kb",
          "version": "v2"
        }
      ],
      "title": "Determinant Estimation under Memory Constraints and Neural Scaling Laws",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04424",
        "HTML": "https://arxiv.org/html/2503.04424v2",
        "PDF": "https://arxiv.org/pdf/2503.04424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses determinant estimation for neural scaling laws and memory constraints, focusing on algorithmic efficiency and not on LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/ameli/imate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07269",
      "abstract": "A family of sets satisfies the $(p,2)$-property if among any $p$ sets in the family, some two intersect. Two recent works used elaborate geometric techniques to show that any family of non-piercing regions in the plane that satisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note we show that even in a much more general setting, piercing by $O(p)$ points can be deduced from known results on hypergraphs with a hereditarily linear Delaunay graph, which include intersection hypergraphs of non-piercing regions.",
      "authors": [
        "Chaya Keller and Shakhar Smorodinsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:30:08+00:00",
          "link": "https://arxiv.org/abs/2507.07269v1",
          "size": "6kb",
          "version": "v1"
        }
      ],
      "title": "A simple proof of a $(p,2)$-theorem for non-piercing regions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07269",
        "HTML": "https://arxiv.org/html/2507.07269v1",
        "PDF": "https://arxiv.org/pdf/2507.07269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a mathematical proof related to intersecting sets, with no connection to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07384",
      "abstract": "Audio-visual sound source localization (AV-SSL) identifies the position of a sound source by exploiting the complementary strengths of auditory and visual signals. However, existing AV-SSL methods encounter three major challenges: 1) inability to selectively isolate the target sound source in multi-source scenarios, 2) misalignment between semantic visual features and spatial acoustic features, and 3) overreliance on paired audio-visual data. To overcome these limitations, we introduce Cross-Instance Audio-Visual Localization (CI-AVL), a novel task that leverages images from different instances of the same sound event category to localize target sound sources, thereby reducing dependence on paired data while enhancing generalization capabilities. Our proposed VP-SelDoA tackles this challenging task through a semantic-level modality fusion and employs a Frequency-Temporal ConMamba architecture to generate target-selective masks for sound isolation. We further develop a Semantic-Spatial Matching mechanism that aligns the heterogeneous semantic and spatial features via integrated cross- and self-attention mechanisms. To facilitate the CI-AVL research, we construct a large-scale dataset named VGG-SSL, comprising 13,981 spatial audio clips across 296 sound event categories. Extensive experiments show that our proposed method outperforms state-of-the-art audio-visual localization methods, achieving a mean absolute error (MAE) of 12.04 and an accuracy (ACC) of 78.23%.",
      "authors": [
        "Yu Chen",
        "Xinyuan Qian",
        "Hongxu Zhu",
        "Jiadong Wang",
        "Kainan Chen",
        "Haizhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:49:56+00:00",
          "link": "https://arxiv.org/abs/2507.07384v1",
          "size": "39950kb",
          "version": "v1"
        }
      ],
      "title": "VP-SelDoA: Visual-prompted Selective DoA Estimation of Target Sound via Semantic-Spatial Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07384",
        "HTML": "https://arxiv.org/html/2507.07384v1",
        "PDF": "https://arxiv.org/pdf/2507.07384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset (VGG-SSL) but does not focus on LLM training data processing; it is related to audio-visual sound source localization using semantic-spatial matching methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07580",
      "abstract": "Recent studies suggest that context-aware low-rank approximation is a useful tool for compression and fine-tuning of modern large-scale neural networks. In this type of approximation, a norm is weighted by a matrix of input activations, significantly improving metrics over the unweighted case. Nevertheless, existing methods for neural networks suffer from numerical instabilities due to their reliance on classical formulas involving explicit Gram matrix computation and their subsequent inversion. We demonstrate that this can degrade the approximation quality or cause numerically singular matrices.\n  To address these limitations, we propose a novel inversion-free regularized framework that is based entirely on stable decompositions and overcomes the numerical pitfalls of prior art. Our method can handle possible challenging scenarios: (1) when calibration matrices exceed GPU memory capacity, (2) when input activation matrices are nearly singular, and even (3) when insufficient data prevents unique approximation. For the latter, we prove that our solution converges to a desired approximation and derive explicit error bounds.",
      "authors": [
        "Uliana Parkina",
        "Maxim Rakhuba"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:35:22+00:00",
          "link": "https://arxiv.org/abs/2507.07580v1",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "title": "COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07580",
        "HTML": "https://arxiv.org/html/2507.07580v1",
        "PDF": "https://arxiv.org/pdf/2507.07580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a numerically stable framework for context-aware low-rank approximation in neural networks. It does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07916",
      "abstract": "Phishing has become a prominent risk in modern cybersecurity, often used to bypass technological defences by exploiting predictable human behaviour. Warning dialogues are a standard mitigation measure, but the lack of explanatory clarity and static content limits their effectiveness. In this paper, we report on our research to assess the capacity of Large Language Models (LLMs) to generate clear, concise, and scalable explanations for phishing warnings. We carried out a large-scale between-subjects user study (N = 750) to compare the influence of warning dialogues supplemented with manually generated explanations against those generated by two LLMs, Claude 3.5 Sonnet and Llama 3.3 70B. We investigated two explanatory styles (feature-based and counterfactual) for their effects on behavioural metrics (click-through rate) and perceptual outcomes (e.g., trust, risk, clarity). The results indicate that well-constructed LLM-generated explanations can equal or surpass manually crafted explanations in reducing susceptibility to phishing; Claude-generated warnings exhibited particularly robust performance. Feature-based explanations were more effective for genuine phishing attempts, whereas counterfactual explanations diminished false-positive rates. Other variables such as workload, gender, and prior familiarity with warning dialogues significantly moderated warning effectiveness. These results indicate that LLMs can be used to automatically build explanations for warning users against phishing, and that such solutions are scalable, adaptive, and consistent with human-centred values.",
      "authors": [
        "Federico Maria Cau",
        "Giuseppe Desolda",
        "Francesco Greco",
        "Lucio Davide Spano and Luca Vigan\\`o"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.07916v1",
          "size": "1069kb",
          "version": "v1"
        }
      ],
      "title": "Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07916",
        "HTML": "https://arxiv.org/html/2507.07916v1",
        "PDF": "https://arxiv.org/pdf/2507.07916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses LLMs to generate explanations for phishing warnings, it does not primarily focus on processing or creating LLM training data but rather on application-specific tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.01991",
      "abstract": "The K-Nearest Neighbors (KNN) algorithm is widely used for classification and regression; however, it suffers from limitations, including the equal treatment of all samples. We propose Information-Modified KNN (IM-KNN), a novel approach that leverages Mutual Information ($I$) and Shapley values to assign weighted values to neighbors, thereby bridging the gap in treating all samples with the same value and weight. On average, IM-KNN improves the accuracy, precision, and recall of traditional KNN by 16.80%, 17.08%, and 16.98%, respectively, across 12 benchmark datasets. Experiments on four large-scale datasets further highlight IM-KNN's robustness to noise, imbalanced data, and skewed distributions.",
      "authors": [
        "Mohammad Ali Vahedifar",
        "Azim Akhtarshenas",
        "Mohammad Mohammadi Rafatpanah",
        "Maryam Sabbaghian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-04T16:10:34+00:00",
          "link": "https://arxiv.org/abs/2312.01991v1",
          "size": "741kb",
          "version": "v1"
        },
        {
          "date": "2024-05-14T11:59:30+00:00",
          "link": "https://arxiv.org/abs/2312.01991v2",
          "size": "747kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T15:46:25+00:00",
          "link": "https://arxiv.org/abs/2312.01991v3",
          "size": "158kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T12:18:34+00:00",
          "link": "https://arxiv.org/abs/2312.01991v4",
          "size": "158kb",
          "version": "v4"
        }
      ],
      "title": "Shapley-Based Data Valuation with Mutual Information: A Key to Modified K-Nearest Neighbors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.01991",
        "HTML": "https://arxiv.org/html/2312.01991v4",
        "PDF": "https://arxiv.org/pdf/2312.01991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This research proposes a modified KNN algorithm leveraging mutual information and Shapley values, but it does not focus on LLM training data processing; it primarily addresses classification on benchmark datasets."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.17556",
      "abstract": "Probabilistic verification problems of neural networks are concerned with formally analysing the output distribution of a neural network under a probability distribution of the inputs. Examples of probabilistic verification problems include verifying the demographic parity fairness notion or quantifying the safety of a neural network. We present a new algorithm for solving probabilistic verification problems of neural networks based on an algorithm for computing and iteratively refining lower and upper bounds on probabilities over the outputs of a neural network. By applying state-of-the-art bound propagation and branch and bound techniques from non-probabilistic neural network verification, our algorithm significantly outpaces existing probabilistic verification algorithms, reducing solving times for various benchmarks from the literature from tens of minutes to tens of seconds. Furthermore, our algorithm compares favourably even to dedicated algorithms for restricted probabilistic verification problems. We complement our empirical evaluation with a theoretical analysis, proving that our algorithm is sound and, under mildly restrictive conditions, also complete when using a suitable set of heuristics.",
      "authors": [
        "David Boetius",
        "Stefan Leue",
        "Tobias Sutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-27T18:00:03+00:00",
          "link": "https://arxiv.org/abs/2405.17556v1",
          "size": "1425kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T15:57:56+00:00",
          "link": "https://arxiv.org/abs/2405.17556v2",
          "size": "1004kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T09:08:34+00:00",
          "link": "https://arxiv.org/abs/2405.17556v3",
          "size": "275kb",
          "version": "v3"
        }
      ],
      "title": "Solving Probabilistic Verification Problems of Neural Networks using Branch and Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.17556",
        "PDF": "https://arxiv.org/pdf/2405.17556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses probabilistic verification of neural networks, without contribution to the processing or creation of LLM training data."
      },
      "tasks": [
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/sen-uni-kn/probspecs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08908",
      "abstract": "Recent studies on Visual Autoregressive (VAR) models have highlighted that high-frequency components, or later steps, in the generation process contribute disproportionately to inference latency. However, the underlying computational redundancy involved in these steps has yet to be thoroughly investigated. In this paper, we conduct an in-depth analysis of the VAR inference process and identify two primary sources of inefficiency: step redundancy and unconditional branch redundancy. To address step redundancy, we propose an automatic step-skipping strategy that selectively omits unnecessary generation steps to improve efficiency. For unconditional branch redundancy, we observe that the information gap between the conditional and unconditional branches is minimal. Leveraging this insight, we introduce unconditional branch replacement, a technique that bypasses the unconditional branch to reduce computational cost. Notably, we observe that the effectiveness of acceleration strategies varies significantly across different samples. Motivated by this, we propose SkipVAR, a sample-adaptive framework that leverages frequency information to dynamically select the most suitable acceleration strategy for each instance. To evaluate the role of high-frequency information, we introduce high-variation benchmark datasets that test model sensitivity to fine details. Extensive experiments show SkipVAR achieves over 0.88 average SSIM with up to 1.81x overall acceleration and 2.62x speedup on the GenEval benchmark, maintaining model quality. These results confirm the effectiveness of frequency-aware, training-free adaptive acceleration for scalable autoregressive image generation. Our code is available at https://github.com/fakerone-li/SkipVAR and has been publicly released.",
      "authors": [
        "Jiajun Li",
        "Yue Ma",
        "Xinyu Zhang",
        "Qingyan Wei",
        "Songhua Liu",
        "Linfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T15:35:29+00:00",
          "link": "https://arxiv.org/abs/2506.08908v1",
          "size": "20139kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T04:58:42+00:00",
          "link": "https://arxiv.org/abs/2506.08908v2",
          "size": "20139kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T06:20:05+00:00",
          "link": "https://arxiv.org/abs/2506.08908v3",
          "size": "20139kb",
          "version": "v3"
        }
      ],
      "title": "SkipVAR: Accelerating Visual Autoregressive Modeling via Adaptive Frequency-Aware Skipping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08908",
        "HTML": "https://arxiv.org/html/2506.08908v3",
        "PDF": "https://arxiv.org/pdf/2506.08908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses inefficiencies in visual autoregressive models through adaptive acceleration strategies, without discussing any aspect of LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "SSIM"
      ],
      "repo_urls": [
        "https://github.com/fakerone-li/skipvar"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07229",
      "abstract": "We present SynthTextEval, a toolkit for conducting comprehensive evaluations of synthetic text. The fluency of large language model (LLM) outputs has made synthetic text potentially viable for numerous applications, such as reducing the risks of privacy violations in the development and deployment of AI systems in high-stakes domains. Realizing this potential, however, requires principled consistent evaluations of synthetic data across multiple dimensions: its utility in downstream systems, the fairness of these systems, the risk of privacy leakage, general distributional differences from the source text, and qualitative feedback from domain experts. SynthTextEval allows users to conduct evaluations along all of these dimensions over synthetic data that they upload or generate using the toolkit's generation module. While our toolkit can be run over any data, we highlight its functionality and effectiveness over datasets from two high-stakes domains: healthcare and law. By consolidating and standardizing evaluation metrics, we aim to improve the viability of synthetic text, and in-turn, privacy-preservation in AI development.",
      "authors": [
        "Krithika Ramesh",
        "Daniel Smolyak",
        "Zihao Zhao",
        "Nupoor Gandhi",
        "Ritu Agarwal",
        "Margr\\'et Bjarnad\\'ottir",
        "Anjalie Field"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.07229v1",
          "size": "9621kb",
          "version": "v1"
        }
      ],
      "title": "SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07229",
        "HTML": "https://arxiv.org/html/2507.07229v1",
        "PDF": "https://arxiv.org/pdf/2507.07229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a toolkit for the evaluation of synthetic text, focusing on data generation and evaluation, which is directly related to improving LLM training data quality and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07424",
      "abstract": "Recent advancements in multimodal large language models (MLLMs) have demonstrated exceptional performance in multimodal perception and understanding. However, leading open-source MLLMs exhibit significant limitations in complex and structured reasoning, particularly in tasks requiring deep reasoning for decision-making and problem-solving. In this work, we present Corvid, an MLLM with enhanced chain-of-thought (CoT) reasoning capabilities. Architecturally, Corvid incorporates a hybrid vision encoder for informative visual representation and a meticulously designed connector (GateMixer) to facilitate cross-modal alignment. To enhance Corvid's CoT reasoning capabilities, we introduce MCoT-Instruct-287K, a high-quality multimodal CoT instruction-following dataset, refined and standardized from diverse public reasoning sources. Leveraging this dataset, we fine-tune Corvid with a two-stage CoT-formatted training approach to progressively enhance its step-by-step reasoning abilities. Furthermore, we propose an effective inference-time scaling strategy that enables Corvid to mitigate over-reasoning and under-reasoning through self-verification. Extensive experiments demonstrate that Corvid outperforms existing o1-like MLLMs and state-of-the-art MLLMs with similar parameter scales, with notable strengths in mathematical reasoning and science problem-solving. Project page: https://mm-vl.github.io/corvid.",
      "authors": [
        "Jingjing Jiang",
        "Chao Ma",
        "Xurui Song",
        "Hanwang Zhang",
        "Jun Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:31:56+00:00",
          "link": "https://arxiv.org/abs/2507.07424v1",
          "size": "3412kb",
          "version": "v1"
        }
      ],
      "title": "Corvid: Improving Multimodal Large Language Models Towards Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07424",
        "HTML": "https://arxiv.org/html/2507.07424v1",
        "PDF": "https://arxiv.org/pdf/2507.07424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the Corvid paper mentions creating a refined multimodal reasoning dataset for enhancing reasoning abilities, the focus is primarily on improving model architecture and reasoning capabilities rather than on core training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07441",
      "abstract": "Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts. Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones. However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration. To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one. To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent. In an iterative manner, the deliberation trajectories are then used to finetune the LLM agent itself. Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.",
      "authors": [
        "Yu Xia",
        "Yiran Jenny Shen",
        "Junda Wu",
        "Tong Yu",
        "Sungchul Kim",
        "Ryan A. Rossi",
        "Lina Yao",
        "Julian McAuley"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:38:15+00:00",
          "link": "https://arxiv.org/abs/2507.07441v1",
          "size": "9249kb",
          "version": "v1"
        }
      ],
      "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07441",
        "PDF": "https://arxiv.org/pdf/2507.07441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning LLM agents with self-taught deliberation methodologies, focusing on model training rather than specific data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07464",
      "abstract": "With the increasing deployment of intelligent CCTV systems in outdoor environments, there is a growing demand for face recognition systems optimized for challenging weather conditions. Adverse weather significantly degrades image quality, which in turn reduces recognition accuracy. Although recent face image restoration (FIR) models based on generative adversarial networks (GANs) and diffusion models have shown progress, their performance remains limited due to the lack of dedicated modules that explicitly address weather-induced degradations. This leads to distorted facial textures and structures. To address these limitations, we propose a novel GAN-based blind FIR framework that integrates two key components: local Statistical Facial Feature Transformation (SFFT) and Degradation-Agnostic Feature Embedding (DAFE). The local SFFT module enhances facial structure and color fidelity by aligning the local statistical distributions of low-quality (LQ) facial regions with those of high-quality (HQ) counterparts. Complementarily, the DAFE module enables robust statistical facial feature extraction under adverse weather conditions by aligning LQ and HQ encoder representations, thereby making the restoration process adaptive to severe weather-induced degradations. Experimental results demonstrate that the proposed degradation-agnostic SFFT model outperforms existing state-of-the-art FIR methods based on GAN and diffusion models, particularly in suppressing texture distortions and accurately reconstructing facial structures. Furthermore, both the SFFT and DAFE modules are empirically validated in enhancing structural fidelity and perceptual quality in face restoration under challenging weather scenarios.",
      "authors": [
        "Chang-Hwan Son"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:31:26+00:00",
          "link": "https://arxiv.org/abs/2507.07464v1",
          "size": "15947kb",
          "version": "v1"
        }
      ],
      "title": "Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07464",
        "PDF": "https://arxiv.org/pdf/2507.07464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a GAN-based framework for facial restoration in adverse weather, but it does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15709",
      "abstract": "Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.",
      "authors": [
        "Pedro C. Vieira",
        "Miguel E. P. Silva",
        "Pedro Manuel Pinto Ribeiro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T15:17:23+00:00",
          "link": "https://arxiv.org/abs/2506.15709v1",
          "size": "2161kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T15:02:17+00:00",
          "link": "https://arxiv.org/abs/2506.15709v2",
          "size": "2162kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:40:39+00:00",
          "link": "https://arxiv.org/abs/2506.15709v3",
          "size": "2159kb",
          "version": "v3"
        }
      ],
      "title": "Studying and Improving Graph Neural Network-based Motif Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15709",
        "HTML": "https://arxiv.org/html/2506.15709v3",
        "PDF": "https://arxiv.org/pdf/2506.15709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Graph Neural Network-based motif estimation and does not involve any aspect of LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "Graph Generation",
        "Graph Neural Network",
        "Graph Representation Learning",
        "Representation Learning",
        "Subgraph Counting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07129",
      "abstract": "The prevailing paradigm for scaling large language models (LLMs) involves monolithic, end-to-end training, a resource-intensive process that lacks flexibility. This paper explores an alternative, constructive approach to model development, built upon the foundation of non-trainable, deterministic input embeddings. In prior [1], we established that high-level semantic reasoning can emerge in Transformers using frozen embeddings derived from the visual structure of Unicode glyphs. Here, we demonstrate that this fixed representational substrate acts as a universal \"docking port,\" enabling two powerful and efficient scaling paradigms: seamless modular composition and progressive layer-wise growth.\n  First, we show that specialist models trained on disparate datasets (e.g., Russian and Chinese text) can be merged into a single, more capable Mixture-of-Experts (MoE) model, post-training, with zero architectural modification. This is achieved by simply averaging their output logits. The resulting MoE model exhibits immediate performance improvements on reasoning benchmarks like MMLU, surpassing its constituent experts without catastrophic forgetting. Second, we introduce a layer-wise constructive training methodology, where a deep Transformer is \"grown\" by progressively stacking and training one layer at a time. This method demonstrates stable convergence and a clear correlation between model depth and the emergence of complex reasoning abilities, such as those required for SQuAD.\n  Our findings suggest a paradigm shift from monolithic optimization towards a more biological or constructive model of AI development, where complexity is built incrementally and modules can be composed freely. This opens new avenues for resource-efficient scaling, continual learning, and a more democratized ecosystem for building powerful AI systems. We release all code and models to facilitate further research.",
      "authors": [
        "A. Bochkov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:01:15+00:00",
          "link": "https://arxiv.org/abs/2507.07129v1",
          "size": "1405kb",
          "version": "v1"
        }
      ],
      "title": "Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07129",
        "HTML": "https://arxiv.org/html/2507.07129v1",
        "PDF": "https://arxiv.org/pdf/2507.07129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on alternative approaches to model development and scaling in LLMs, particularly deterministic embeddings and incremental layer-wise growth, rather than on processing or creating training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07281",
      "abstract": "We study the almost sure convergence rate for the last iterate of stochastic gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric setting when the objective function $F$ is globally convex or non-convex whose gradient is $\\gamma$-H\\\"{o}lder. Using only discrete Gronwall's inequality without Robbins-Siegmund theorem nor martingale convergence theory, we recover results for both SGD and SHB: $\\min_{s\\leq t} \\|\\nabla F(w_s)\\|^2 = o(t^{p-1})$ for non-convex objectives and $F(w_t) - F_* = o(t^{2\\gamma/(1+\\gamma) \\cdot \\max(p-1,-2p+1)-\\epsilon})$ for $\\beta \\in (0, 1)$ and $\\min_{s \\leq t} F(w_s) - F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved that SHB with constant momentum parameter $\\beta \\in (0, 1)$ attains a convergence rate of $F(w_t) - F_* = O(t^{\\max(p-1,-2p+1)} \\log^2 \\frac{t}{\\delta})$ with probability at least $1-\\delta$ when $F$ is convex and $\\gamma = 1$ and step size $\\alpha_t = \\Theta(t^{-p})$ with $p \\in (\\frac{1}{2}, 1)$.",
      "authors": [
        "Marcel Hudiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:59:23+00:00",
          "link": "https://arxiv.org/abs/2507.07281v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07281",
        "HTML": "https://arxiv.org/html/2507.07281v1",
        "PDF": "https://arxiv.org/pdf/2507.07281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses convergence rates for stochastic gradient descent, focusing on theoretical analysis without making any technical contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07884",
      "abstract": "Is demand for conspiracy theories online linked to real-world hate crimes? By analyzing online search trends for 36 racially and politically-charged conspiracy theories in Michigan (2015-2019), we employ a one-dimensional convolutional neural network (1D-CNN) to predict hate crime occurrences offline. A subset of theories including the Rothschilds family, Q-Anon, and The Great Replacement improves prediction accuracy, with effects emerging two to three weeks after fluctuations in searches. However, most theories showed no clear connection to offline hate crimes. Aligning with neutralization and differential association theories, our findings provide a partial empirical link between specific racially charged conspiracy theories and real-world violence. Just as well, this study underscores the potential for machine learning to be used in identifying harmful online patterns and advancing social science research.",
      "authors": [
        "Alberto Aziani",
        "Michael V. Lo Giudice and Ali Shadman Yazdi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.07884v1",
          "size": "1030kb",
          "version": "v1"
        }
      ],
      "title": "Conspiracy to Commit: Information Pollution, Artificial Intelligence, and Real-World Hate Crime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07884",
        "HTML": "https://arxiv.org/html/2507.07884v1",
        "PDF": "https://arxiv.org/pdf/2507.07884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper primarily discusses the prediction of hate crimes using online trends with machine learning, without making contributions to LLM training data processing. It mentions data but does not focus on its preparation or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.16414",
      "abstract": "We give an operational definition of information-theoretic resources within a given multipartite classical or quantum correlation. We present our causal model that serves as the source coding side of this correlation and introduce a novel concept of resource rate. We argue that, beyond classical secrecy, additional resources exist that are useful for the security of distributed computing problems, which can be captured by the resource rate. Furthermore, we establish a relationship between resource rate and an extension of Shannon's logarithmic information measure, namely, total correlation.",
      "authors": [
        "Shuchan Wang and Gerhard Wunder"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-29T18:51:02+00:00",
          "link": "https://arxiv.org/abs/2401.16414v1",
          "size": "146kb",
          "version": "v1"
        },
        {
          "date": "2024-03-18T11:34:18+00:00",
          "link": "https://arxiv.org/abs/2401.16414v2",
          "size": "147kb",
          "version": "v2"
        },
        {
          "date": "2024-04-02T15:26:13+00:00",
          "link": "https://arxiv.org/abs/2401.16414v3",
          "size": "148kb",
          "version": "v3"
        },
        {
          "date": "2024-08-29T20:32:10+00:00",
          "link": "https://arxiv.org/abs/2401.16414v4",
          "size": "135kb",
          "version": "v4"
        },
        {
          "date": "2025-01-27T17:24:01+00:00",
          "link": "https://arxiv.org/abs/2401.16414v5",
          "size": "567kb",
          "version": "v5"
        },
        {
          "date": "2025-07-10T17:00:37+00:00",
          "link": "https://arxiv.org/abs/2401.16414v6",
          "size": "134kb",
          "version": "v6"
        }
      ],
      "title": "A Causal Model for Quantifying Multipartite Classical and Quantum Correlations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.16414",
        "HTML": "https://arxiv.org/html/2401.16414",
        "PDF": "https://arxiv.org/pdf/2401.16414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a causal model for quantifying classical and quantum correlations, with no mention of LLM training data or data processing techniques relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07544",
      "abstract": "What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.",
      "authors": [
        "Oliver Eberle",
        "Thomas McGee",
        "Hamza Giaffar",
        "Taylor Webb",
        "Ida Momennejad"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:38:47+00:00",
          "link": "https://arxiv.org/abs/2507.07544v1",
          "size": "2277kb",
          "version": "v1"
        }
      ],
      "title": "Position: We Need An Algorithmic Understanding of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07544",
        "HTML": "https://arxiv.org/html/2507.07544v1",
        "PDF": "https://arxiv.org/pdf/2507.07544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes AlgEval for understanding the algorithms LLMs learn but does not contribute technical advancements related to the processing of LLM training data or dataset creation/enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.02357",
      "abstract": "Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. This paper introduces a lightweight, interpretable benchmark to evaluate an LLM agent's ability to uphold a high-level safety principle when faced with conflicting task instructions. Our evaluation of six LLMs reveals two primary findings: (1) a quantifiable \"cost of compliance\" where safety constraints degrade task performance even when compliant solutions exist, and (2) an \"illusion of compliance\" where high adherence often masks task incompetence rather than principled choice. These findings provide initial evidence that while LLMs can be influenced by hierarchical directives, current approaches lack the consistency required for reliable safety governance.",
      "authors": [
        "Ram Potham (Independent Researcher)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T01:16:34+00:00",
          "link": "https://arxiv.org/abs/2506.02357v1",
          "size": "691kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:10:23+00:00",
          "link": "https://arxiv.org/abs/2506.02357v2",
          "size": "388kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02357",
        "HTML": "https://arxiv.org/html/2506.02357v2",
        "PDF": "https://arxiv.org/pdf/2506.02357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the evaluation of LLM adherence to safety principles using a benchmark, rather than discussing training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07586",
      "abstract": "We reveal a hidden Bayesian core of discrete-diffusion language models by showing that the expected denoiser output under the forward masking distribution recovers the exact posterior over clean tokens. Under minimal assumptions, Monte Carlo marginalization over K independent corruptions converges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of consistency and finite-sample error bounds. Building on this insight, we introduce a lightweight inference-time ensemble that averages K mask-and-denoise passes to obtain posterior-aware token probabilities and uncertainty estimates at no extra training cost. On WikiText-2, our method achieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite using a model of comparable size. Code is available at https://github.com/mercury0100/bayesradd.",
      "authors": [
        "Cooper Doyle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:42:47+00:00",
          "link": "https://arxiv.org/abs/2507.07586v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Discrete Diffusion Beats Autoregressive Perplexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07586",
        "HTML": "https://arxiv.org/html/2507.07586v1",
        "PDF": "https://arxiv.org/pdf/2507.07586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses inference-time techniques for language models which might involve dealing with output probabilities but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07670",
      "abstract": "In pediatric orthodontics, accurate estimation of growth potential is essential for developing effective treatment strategies. Our research aims to predict this potential by identifying the growth peak and analyzing cervical vertebra morphology solely through lateral cephalometric radiographs. We accomplish this by comprehensively analyzing cervical vertebral maturation (CVM) features from these radiographs. This methodology provides clinicians with a reliable and efficient tool to determine the optimal timings for orthodontic interventions, ultimately enhancing patient outcomes. A crucial aspect of this approach is the meticulous annotation of keypoints on the cervical vertebrae, a task often challenged by its labor-intensive nature. To mitigate this, we introduce Attend-and-Refine Network (ARNet), a user-interactive, deep learning-based model designed to streamline the annotation process. ARNet features Interaction-guided recalibration network, which adaptively recalibrates image features in response to user feedback, coupled with a morphology-aware loss function that preserves the structural consistency of keypoints. This novel approach substantially reduces manual effort in keypoint identification, thereby enhancing the efficiency and accuracy of the process. Extensively validated across various datasets, ARNet demonstrates remarkable performance and exhibits wide-ranging applicability in medical imaging. In conclusion, our research offers an effective AI-assisted diagnostic tool for assessing growth potential in pediatric orthodontics, marking a significant advancement in the field.",
      "authors": [
        "Jinhee Kim",
        "Taesung Kim",
        "Taewoo Kim",
        "Dong-Wook Kim",
        "Byungduk Ahn",
        "Yoon-Ji Kim",
        "In-Seok Song",
        "Jaegul Choo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:52:20+00:00",
          "link": "https://arxiv.org/abs/2507.07670v1",
          "size": "13846kb",
          "version": "v1"
        }
      ],
      "title": "Attend-and-Refine: Interactive keypoint estimation and quantitative cervical vertebrae analysis for bone age assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07670",
        "HTML": "https://arxiv.org/html/2507.07670v1",
        "PDF": "https://arxiv.org/pdf/2507.07670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a user-interactive deep learning model for keypoint estimation in cervical vertebrae analysis, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07805",
      "abstract": "High performance and formal safety guarantees are common requirements for industrial control applications. Control barrier function (CBF) methods provide a systematic approach to the modularization of safety and performance. However, the design of such CBFs can be challenging, which limits their applicability to large-scale or data-driven systems. This paper introduces the concept of a set-based CBF for linear systems with convex constraints. By leveraging control invariant sets from reachability analysis and predictive control, the set-based CBF is defined implicitly through the minimal scaling of such a set to contain the current system state. This approach enables the development of implicit, data-driven, and high-dimensional CBF representations. The paper demonstrates the design of a safety filter using set-based CBFs, which is suitable for real-time implementations and learning-based approximations to reduce online computational demands. The effectiveness of the method is illustrated through comprehensive simulations on a high-dimensional mass-spring-damper system and a motion control task, and it is validated experimentally using an electric drive application with short sampling times, highlighting its practical benefits for safety-critical control.",
      "authors": [
        "Kim P. Wabersich",
        "Felix Berkel",
        "Felix Gruber",
        "Sven Reimann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:30:15+00:00",
          "link": "https://arxiv.org/abs/2507.07805v1",
          "size": "1668kb",
          "version": "v1"
        }
      ],
      "title": "Set-Based Control Barrier Functions and Safety Filters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07805",
        "HTML": "https://arxiv.org/html/2507.07805v1",
        "PDF": "https://arxiv.org/pdf/2507.07805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces set-based Control Barrier Functions for safety in control systems, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07993",
      "abstract": "Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods.",
      "authors": [
        "Weihao Xia",
        "Cengiz Oztireli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:24+00:00",
          "link": "https://arxiv.org/abs/2507.07993v1",
          "size": "8703kb",
          "version": "v1"
        }
      ],
      "title": "Multigranular Evaluation for Brain Visual Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07993",
        "HTML": "https://arxiv.org/html/2507.07993v1",
        "PDF": "https://arxiv.org/pdf/2507.07993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on evaluation frameworks for brain visual decoding, not on the processing or generation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07994",
      "abstract": "Keypoint detection, integral to modern machine perception, faces challenges in few-shot learning, particularly when source data from the same distribution as the query is unavailable. This gap is addressed by leveraging sketches, a popular form of human expression, providing a source-free alternative. However, challenges arise in mastering cross-modal embeddings and handling user-specific sketch styles. Our proposed framework overcomes these hurdles with a prototypical setup, combined with a grid-based locator and prototypical domain adaptation. We also demonstrate success in few-shot convergence across novel keypoints and classes through extensive experiments.",
      "authors": [
        "Subhajit Maity",
        "Ayan Kumar Bhunia",
        "Subhadeep Koley",
        "Pinaki Nath Chowdhury",
        "Aneeshan Sain",
        "Yi-Zhe Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.07994v1",
          "size": "14072kb",
          "version": "v1"
        }
      ],
      "title": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07994",
        "HTML": "https://arxiv.org/html/2507.07994v1",
        "PDF": "https://arxiv.org/pdf/2507.07994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sketch-based few-shot keypoint detection, dealing with few-shot learning without engaging in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07907",
      "abstract": "How does social network structure amplify or stifle behavior diffusion? Existing theory suggests that when social reinforcement makes the adoption of behavior more likely, it should spread more -- both farther and faster -- on clustered networks with redundant ties. Conversely, if adoption does not benefit from social reinforcement, it should spread more on random networks which avoid such redundancies. We develop a novel model of behavior diffusion with tunable probabilistic adoption and social reinforcement parameters to systematically evaluate the conditions under which clustered networks spread behavior better than random networks. Using simulations and analytical methods, we identify precise boundaries in the parameter space where one network type outperforms the other or they perform equally. We find that, in most cases, random networks spread behavior as far or farther than clustered networks, even when social reinforcement increases adoption. Although we find that probabilistic, socially reinforced behaviors can spread farther on clustered networks in some cases, this is not the dominant pattern. Clustered networks are even less advantageous when individuals remain influential for longer after adopting, have more neighbors, or need more neighbors before social reinforcement takes effect. Under such conditions, clustering tends to help only when adoption is nearly deterministic, which is not representative of socially reinforced behaviors more generally. Clustered networks outperform random networks by a 5% margin in only 22% of the parameter space under its most favorable conditions. This pattern reflects a fundamental tradeoff: random ties enhance reach, while clustered ties enhance social reinforcement.",
      "authors": [
        "Allison Wan",
        "Christoph Riedl",
        "David Lazer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T16:28:00+00:00",
          "link": "https://arxiv.org/abs/2411.07907v1",
          "size": "7385kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:16:23+00:00",
          "link": "https://arxiv.org/abs/2411.07907v2",
          "size": "3556kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion of complex contagions is shaped by a trade-off between reach and reinforcement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07907",
        "HTML": "https://arxiv.org/html/2411.07907v2",
        "PDF": "https://arxiv.org/pdf/2411.07907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates behavior diffusion in social networks and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19092",
      "abstract": "Large language models (LLMs) are increasingly integral to information retrieval (IR), powering ranking, evaluation, and AI-assisted content creation. This widespread adoption necessitates a critical examination of potential biases arising from the interplay between these LLM-based components. This paper synthesizes existing research and presents novel experiment designs that explore how LLM-based rankers and assistants influence LLM-based judges. We provide the first empirical evidence of LLM judges exhibiting significant bias towards LLM-based rankers. Furthermore, we observe limitations in LLM judges' ability to discern subtle system performance differences. Contrary to some previous findings, our preliminary study does not find evidence of bias against AI-generated content. These results highlight the need for a more holistic view of the LLM-driven information ecosystem. To this end, we offer initial guidelines and a research agenda to ensure the reliable use of LLMs in IR evaluation.",
      "authors": [
        "Krisztian Balog and Donald Metzler and Zhen Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T19:24:40+00:00",
          "link": "https://arxiv.org/abs/2503.19092v1",
          "size": "157kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T22:09:49+00:00",
          "link": "https://arxiv.org/abs/2503.19092v2",
          "size": "148kb",
          "version": "v2"
        }
      ],
      "title": "Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19092",
        "HTML": "https://arxiv.org/html/2503.19092v2",
        "PDF": "https://arxiv.org/pdf/2503.19092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the influence of LLM-based components in information retrieval but focuses on bias analysis and evaluation rather than LLM training data processing."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00951",
      "abstract": "Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.",
      "authors": [
        "Rizwan Qureshi",
        "Ranjan Sapkota",
        "Abbas Shah",
        "Amgad Muneer",
        "Anas Zafar",
        "Ashmal Vayani",
        "Maged Shoman",
        "Abdelrahman B. M. Eldaly",
        "Kai Zhang",
        "Ferhat Sadak",
        "Shaina Raza",
        "Xinqi Fan",
        "Ravid Shwartz-Ziv",
        "Hong Yan",
        "Vinjia Jain",
        "Aman Chadha",
        "Manoj Karkee",
        "Jia Wu",
        "Philip Torr",
        "Seyedali Mirjalili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:52:25+00:00",
          "link": "https://arxiv.org/abs/2507.00951v1",
          "size": "9572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T21:09:25+00:00",
          "link": "https://arxiv.org/abs/2507.00951v2",
          "size": "12347kb",
          "version": "v2"
        }
      ],
      "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00951",
        "HTML": "https://arxiv.org/html/2507.00951v2",
        "PDF": "https://arxiv.org/pdf/2507.00951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses AGI development and reasoning frameworks, it primarily focuses on model architecture and cognitive foundations without focusing on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07379",
      "abstract": "Particle-based shape modeling (PSM) is a family of approaches that automatically quantifies shape variability across anatomical cohorts by positioning particles (pseudo landmarks) on shape surfaces in a consistent configuration. Recent advances incorporate implicit radial basis function representations as self-supervised signals to better capture the complex geometric properties of anatomical structures. However, these methods still lack self-adaptivity -- that is, the ability to automatically adjust particle configurations to local geometric features of each surface, which is essential for accurately representing complex anatomical variability. This paper introduces two mechanisms to increase surface adaptivity while maintaining consistent particle configurations: (1) a novel neighborhood correspondence loss to enable high adaptivity and (2) a geodesic correspondence algorithm that regularizes optimization to enforce geodesic neighborhood consistency. We evaluate the efficacy and scalability of our approach on challenging datasets, providing a detailed analysis of the adaptivity-correspondence trade-off and benchmarking against existing methods on surface representation accuracy and correspondence metrics.",
      "authors": [
        "Hong Xu and Shireen Y. Elhabian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:19:10+00:00",
          "link": "https://arxiv.org/abs/2507.07379v1",
          "size": "9133kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Particle-Based Shape Modeling for Anatomical Surface Correspondence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07379",
        "HTML": "https://arxiv.org/html/2507.07379v1",
        "PDF": "https://arxiv.org/pdf/2507.07379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces adaptive particle-based shape modeling for anatomical surface correspondence. It doesn't pertain to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07445",
      "abstract": "Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.",
      "authors": [
        "Weihao Tan",
        "Changjiu Jiang",
        "Yu Duan",
        "Mingcong Lei",
        "Jiageng Li",
        "Yitian Hong",
        "Xinrun Wang",
        "Bo An"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:48:28+00:00",
          "link": "https://arxiv.org/abs/2507.07445v1",
          "size": "6684kb",
          "version": "v1"
        }
      ],
      "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07445",
        "PDF": "https://arxiv.org/pdf/2507.07445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for AI agents in production-living simulations using Stardew Valley, focusing on agent evaluation rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07519",
      "abstract": "The application of methods based on Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D GS) have steadily gained popularity in the field of 3D object segmentation in static scenes. These approaches demonstrate efficacy in a range of 3D scene understanding and editing tasks. Nevertheless, the 4D object segmentation of dynamic scenes remains an underexplored field due to the absence of a sufficiently extensive and accurately labelled multi-view video dataset. In this paper, we present MUVOD, a new multi-view video dataset for training and evaluating object segmentation in reconstructed real-world scenarios. The 17 selected scenes, describing various indoor or outdoor activities, are collected from different sources of datasets originating from various types of camera rigs. Each scene contains a minimum of 9 views and a maximum of 46 views. We provide 7830 RGB images (30 frames per video) with their corresponding segmentation mask in 4D motion, meaning that any object of interest in the scene could be tracked across temporal frames of a given view or across different views belonging to the same camera rig. This dataset, which contains 459 instances of 73 categories, is intended as a basic benchmark for the evaluation of multi-view video segmentation methods. We also present an evaluation metric and a baseline segmentation approach to encourage and evaluate progress in this evolving field. Additionally, we propose a new benchmark for 3D object segmentation task with a subset of annotated multi-view images selected from our MUVOD dataset. This subset contains 50 objects of different conditions in different scenarios, providing a more comprehensive analysis of state-of-the-art 3D object segmentation methods. Our proposed MUVOD dataset is available at https://volumetric-repository.labs.b-com.com/#/muvod.",
      "authors": [
        "Bangning Wei",
        "Joshua Maraval",
        "Meriem Outtas",
        "Kidiyo Kpalma",
        "Nicolas Ramin and Lu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:07:59+00:00",
          "link": "https://arxiv.org/abs/2507.07519v1",
          "size": "44732kb",
          "version": "v1"
        }
      ],
      "title": "MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07519",
        "HTML": "https://arxiv.org/html/2507.07519v1",
        "PDF": "https://arxiv.org/pdf/2507.07519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new dataset for 3D object segmentation in videos but focuses on benchmark creation and evaluation, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07668",
      "abstract": "Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.",
      "authors": [
        "Felix Frohnert",
        "Denny Lane B. Sombrillo",
        "Evert van Nieuwenburg",
        "Patrick Emonts"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:49:17+00:00",
          "link": "https://arxiv.org/abs/2507.07668v1",
          "size": "2576kb",
          "version": "v1"
        }
      ],
      "title": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07668",
        "HTML": "https://arxiv.org/html/2507.07668v1",
        "PDF": "https://arxiv.org/pdf/2507.07668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an uncertainty-aware machine learning approach for classifying pole structures in hadronic states, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04512",
      "abstract": "We present Coneris, the first higher-order concurrent separation logic for reasoning about error probability bounds of higher-order concurrent probabilistic programs with higher-order state. To support modular reasoning about concurrent (non-probabilistic) program modules, state-of-the-art program logics internalize the classic notion of linearizability within the logic through the concept of logical atomicity.\n  Coneris extends this idea to probabilistic concurrent program modules. Thus Coneris supports modular reasoning about probabilistic concurrent modules by capturing a novel notion of randomized logical atomicity within the logic. To do so, Coneris utilizes presampling tapes and a novel probabilistic update modality to describe how state is changed probabilistically at linearization points. We demonstrate this approach by means of smaller synthetic examples and larger case studies.\n  All of the presented results, including the meta-theory, have been mechanized in the Rocq proof assistant and the Iris separation logic framework",
      "authors": [
        "Kwing Hei Li",
        "Alejandro Aguirre",
        "Simon Oddershede Gregersen",
        "Philipp G. Haselwarter",
        "Joseph Tassarotti",
        "Lars Birkedal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T14:59:30+00:00",
          "link": "https://arxiv.org/abs/2503.04512v1",
          "size": "107kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:31:07+00:00",
          "link": "https://arxiv.org/abs/2503.04512v2",
          "size": "107kb",
          "version": "v2"
        }
      ],
      "title": "Modular Reasoning about Error Bounds for Concurrent Probabilistic Programs (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04512",
        "PDF": "https://arxiv.org/pdf/2503.04512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reasoning about error probability bounds in probabilistic programs, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07510",
      "abstract": "Diffusion models have achieved remarkable success in generating realistic and versatile images from text prompts. Inspired by the recent advancements of language models, there is an increasing interest in further improving the models by aligning with human preferences. However, we investigate alignment from a divergence minimization perspective and reveal that existing preference optimization methods are typically trapped in suboptimal mean-seeking optimization. In this paper, we introduce Divergence Minimization Preference Optimization (DMPO), a novel and principled method for aligning diffusion models by minimizing reverse KL divergence, which asymptotically enjoys the same optimization direction as original RL. We provide rigorous analysis to justify the effectiveness of DMPO and conduct comprehensive experiments to validate its empirical strength across both human evaluations and automatic metrics. Our extensive results show that diffusion models fine-tuned with DMPO can consistently outperform or match existing techniques, specifically outperforming all existing diffusion alignment baselines by at least 64.6% in PickScore across all evaluation datasets, demonstrating the method's superiority in aligning generative behavior with desired outputs. Overall, DMPO unlocks a robust and elegant pathway for preference alignment, bridging principled theory with practical performance in diffusion models.",
      "authors": [
        "Binxu Li",
        "Minkai Xu",
        "Meihua Dang",
        "Stefano Ermon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:57:30+00:00",
          "link": "https://arxiv.org/abs/2507.07510v1",
          "size": "24407kb",
          "version": "v1"
        }
      ],
      "title": "Divergence Minimization Preference Optimization for Diffusion Model Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07510",
        "HTML": "https://arxiv.org/html/2507.07510v1",
        "PDF": "https://arxiv.org/pdf/2507.07510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on optimizing diffusion model alignment from a divergence minimization perspective, with no focus on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07825",
      "abstract": "Unknown dynamic load carrying is one important practical application for quadruped robots. Such a problem is non-trivial, posing three major challenges in quadruped locomotion control. First, how to model or represent the dynamics of the load in a generic manner. Second, how to make the robot capture the dynamics without any external sensing. Third, how to enable the robot to interact with load handling the mutual effect and stabilizing the load. In this work, we propose a general load modeling approach called load characteristics modeling to capture the dynamics of the load. We integrate this proposed modeling technique and leverage recent advances in Reinforcement Learning (RL) based locomotion control to enable the robot to infer the dynamics of load movement and interact with the load indirectly to stabilize it and realize the sim-to-real deployment to verify its effectiveness in real scenarios. We conduct extensive comparative simulation experiments to validate the effectiveness and superiority of our proposed method. Results show that our method outperforms other methods in sudden load resistance, load stabilizing and locomotion with heavy load on rough terrain. \\href{https://leixinjonaschang.github.io/leggedloadadapt.github.io/}{Project Page}.",
      "authors": [
        "Leixin Chang",
        "Yuxuan Nai",
        "Hua Chen and Liangjing Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:54:52+00:00",
          "link": "https://arxiv.org/abs/2507.07825v1",
          "size": "4645kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07825",
        "HTML": "https://arxiv.org/html/2507.07825v1",
        "PDF": "https://arxiv.org/pdf/2507.07825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with load adaptation for quadruped robots using reinforcement learning, which does not concern LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05481",
      "abstract": "This article studies the problem of distributed formation control for multiple robots by using onboard ultra wide band (UWB) distance and inertial odometer (IO) measurements.\n  Although this problem has been widely studied, a fundamental limitation of most works is that they require each robot's pose and sensor measurements are expressed in a common reference frame.\n  However, it is inapplicable for nonholonomic robot formations due to the practical difficulty of aligning IO measurements of individual robot in a common frame.\n  To address this problem, firstly, a concurrent-learning based estimator is firstly proposed to achieve relative localization between neighboring robots in a local frame.\n  Different from most relative localization methods in a global frame, both relative position and orientation in a local frame are estimated with only UWB ranging and IO\n  measurements.\n  Secondly, to deal with information loss caused by directed communication topology, a cooperative localization algorithm is introduced to estimate the relative pose to the leader robot.\n  Thirdly, based on the theoretical results on relative pose estimation, a distributed formation tracking controller is proposed for nonholonomic robots.\n  Both 3D and 2D real-world experiments conducted on aerial robots and grounded robots are provided to demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Kunrui Ze",
        "Wei Wang",
        "Shuoyu Yue",
        "Guibin Sun",
        "Kexin Liu",
        "Jinhu L\\\"u"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-08T11:19:45+00:00",
          "link": "https://arxiv.org/abs/2411.05481v1",
          "size": "15640kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:35:28+00:00",
          "link": "https://arxiv.org/abs/2411.05481v2",
          "size": "16636kb",
          "version": "v2"
        }
      ],
      "title": "Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05481",
        "HTML": "https://arxiv.org/html/2411.05481v2",
        "PDF": "https://arxiv.org/pdf/2411.05481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses robot formation control and relative pose estimation, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.01092",
      "abstract": "Compared to traditional electrodynamic loudspeakers, the parametric array loudspeaker (PAL) offers exceptional directivity for audio applications but suffers from significant nonlinear distortions due to its inherent intricate demodulation process. The Volterra filter-based approaches have been widely used to reduce these distortions, but the effectiveness is limited by its inverse filter's capability. Specifically, its pth-order inverse filter can only compensate for nonlinearities up to the pth order, while the higher-order nonlinearities it introduces continue to generate lower-order harmonics. In contrast, this paper introduces the modern deep learning methods for the first time to address nonlinear identification and compensation for PAL systems. Specifically, a feedforward variant of the WaveNet neural network, recognized for its success in audio nonlinear system modeling, is utilized to identify and compensate for distortions in a double sideband amplitude modulation-based PAL system. Experimental measurements from 250 Hz to 8 kHz demonstrate that our proposed approach significantly reduces both total harmonic distortion and intermodulation distortion of audio sound generated by PALs, achieving average reductions to 4.55% and 2.47%, respectively. This performance is notably superior to results obtained using the current state-of-the-art Volterra filter-based methods. Our work opens new possibilities for improving the sound reproduction performance of PALs.",
      "authors": [
        "Mengtong Li",
        "Tao Zhuang",
        "Kai Chen",
        "Jia-Xin Zhong",
        "Jing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T04:00:10+00:00",
          "link": "https://arxiv.org/abs/2412.01092v1",
          "size": "990kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-Based Approach for Identification and Compensation of Nonlinear Distortions in Parametric Array Loudspeakers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01092",
        "HTML": "https://arxiv.org/html/2412.01092",
        "PDF": "https://arxiv.org/pdf/2412.01092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses nonlinear distortions in parametric array loudspeakers using deep learning methods with no relation to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07883",
      "abstract": "Multi-task learning (MTL) enables a joint model to capture commonalities across multiple tasks, reducing computation costs and improving data efficiency. However, a major challenge in MTL optimization is task conflicts, where the task gradients differ in direction or magnitude, limiting model performance compared to single-task counterparts. Sharpness-aware minimization (SAM) minimizes task loss while simultaneously reducing the sharpness of the loss landscape. Our empirical observations show that SAM effectively mitigates task conflicts in MTL. Motivated by these findings, we explore integrating SAM into MTL but face two key challenges. While both the average loss gradient and individual task gradients-referred to as global and local information-contribute to SAM, how to combine them remains unclear. Moreover, directly computing each task gradient introduces significant computational and memory overheads. To address these challenges, we propose SAMO, a lightweight \\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization approach, that leverages a joint global-local perturbation. The local perturbations are approximated using only forward passes and are layerwise normalized to improve efficiency. Extensive experiments on a suite of multi-task benchmarks demonstrate both the effectiveness and efficiency of our method. Code is available at https://github.com/OptMN-Lab/SAMO.",
      "authors": [
        "Hao Ban",
        "Gokul Ram Subramani",
        "Kaiyi Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:06:02+00:00",
          "link": "https://arxiv.org/abs/2507.07883v1",
          "size": "537kb",
          "version": "v1"
        }
      ],
      "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07883",
        "HTML": "https://arxiv.org/html/2507.07883v1",
        "PDF": "https://arxiv.org/pdf/2507.07883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on optimization techniques in multi-task learning rather than processing LLM training data. It addresses task conflicts and efficiency but not data collection, preparation, or processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18439",
      "abstract": "In this paper, we study the problem of model-checking quantum pushdown systems from a computational complexity point of view. We arrive at the following equally important, interesting new results:\n  We first extend the notions of the {\\it probabilistic pushdown systems} and {\\it Markov chains} to their quantum analogues and investigate the question of whether it is necessary to define a quantum analogue of {\\it probabilistic computational tree logic} to describe the probabilistic and branching-time properties of the {\\it quantum Markov chain}. We study its model-checking question and show that model-checking of {\\it stateless quantum pushdown systems (qBPA)} against {\\it probabilistic computational tree logic (PCTL)} is generally undecidable, i.e., there exists no algorithm for model-checking {\\it stateless quantum pushdown systems} against {\\it probabilistic computational tree logic}.\n  We then study in which case there exists an algorithm for model-checking {\\it stateless quantum pushdown systems} and show that the problem of model-checking {\\it stateless quantum pushdown systems} against {\\it bounded probabilistic computational tree logic} (bPCTL) is decidable, and further show that this problem is in $NP$-hard. Our reduction is from the {\\it bounded Post Correspondence Problem} for the first time, a well-known $NP$-complete problem.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:22:23+00:00",
          "link": "https://arxiv.org/abs/2506.18439v1",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T03:25:35+00:00",
          "link": "https://arxiv.org/abs/2506.18439v2",
          "size": "23kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:15:15+00:00",
          "link": "https://arxiv.org/abs/2506.18439v3",
          "size": "23kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T05:04:38+00:00",
          "link": "https://arxiv.org/abs/2506.18439v4",
          "size": "24kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T19:36:42+00:00",
          "link": "https://arxiv.org/abs/2506.18439v5",
          "size": "24kb",
          "version": "v5"
        }
      ],
      "title": "Computational Complexity of Model-Checking Quantum Pushdown Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18439",
        "HTML": "https://arxiv.org/html/2506.18439v5",
        "PDF": "https://arxiv.org/pdf/2506.18439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computational complexity of model-checking quantum pushdown systems and does not discuss LLM training data processing or related data-engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18903",
      "abstract": "We propose a novel memory mechanism to build video generators that can explore environments interactively. Similar results have previously been achieved by out-painting 2D views of the scene while incrementally reconstructing its 3D geometry, which quickly accumulates errors, or by video generators with a short context window, which struggle to maintain scene coherence over the long term. To address these limitations, we introduce Surfel-Indexed View Memory (VMem), a mechanism that remembers past views by indexing them geometrically based on the 3D surface elements (surfels) they have observed. VMem enables the efficient retrieval of the most relevant past views when generating new ones. By focusing only on these relevant views, our method produces consistent explorations of imagined environments at a fraction of the computational cost of using all past views as context. We evaluate our approach on challenging long-term scene synthesis benchmarks and demonstrate superior performance compared to existing methods in maintaining scene coherence and camera control.",
      "authors": [
        "Runjia Li",
        "Philip Torr",
        "Andrea Vedaldi",
        "Tomas Jakab"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2506.18903v1",
          "size": "7880kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:56:24+00:00",
          "link": "https://arxiv.org/abs/2506.18903v2",
          "size": "7880kb",
          "version": "v2"
        }
      ],
      "title": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18903",
        "HTML": "https://arxiv.org/html/2506.18903v2",
        "PDF": "https://arxiv.org/pdf/2506.18903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a memory mechanism for video scene generation, which is unrelated to LLM training data processing or engineering."
      },
      "models": [
        {
          "model_path": "liguang0115/vmem",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/liguang0115/vmem"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07432",
      "abstract": "We show that deep neural networks, including transformers and RNNs, pretrained as usual on next-token prediction, intrinsically discover and represent beliefs over 'quantum' and 'post-quantum' low-dimensional generative models of their training data -- as if performing iterative Bayesian updates over the latent state of this world model during inference as they observe more context. Notably, neural nets easily find these representation whereas there is no finite classical circuit that would do the job. The corresponding geometric relationships among neural activations induced by different input sequences are found to be largely independent of neural-network architecture. Each point in this geometry corresponds to a history-induced probability density over all possible futures, and the relative displacement of these points reflects the difference in mechanism and magnitude for how these distinct pasts affect the future.",
      "authors": [
        "Paul M. Riechers and Thomas J. Elliott and Adam S. Shai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.07432v1",
          "size": "5588kb",
          "version": "v1"
        }
      ],
      "title": "Neural networks leverage nominally quantum and post-quantum representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07432",
        "HTML": "https://arxiv.org/html/2507.07432v1",
        "PDF": "https://arxiv.org/pdf/2507.07432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the representation of quantum and post-quantum generative models discovered by deep neural networks, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07610",
      "abstract": "Humans can directly imagine and manipulate visual images in their minds, a capability known as spatial visualization. While multi-modal Large Language Models (MLLMs) support imagination-based reasoning, spatial visualization remains insufficiently evaluated, typically embedded within broader mathematical and logical assessments. Existing evaluations often rely on IQ tests or math competitions that may overlap with training data, compromising assessment reliability. To this end, we introduce SpatialViz-Bench, a comprehensive multi-modal benchmark for spatial visualization with 12 tasks across 4 sub-abilities, comprising 1,180 automatically generated problems. Our evaluation of 33 state-of-the-art MLLMs not only reveals wide performance variations and demonstrates the benchmark's strong discriminative power, but also uncovers counter-intuitive findings: models exhibit unexpected behaviors by showing difficulty perception that misaligns with human intuition, displaying dramatic 2D-to-3D performance cliffs, and defaulting to formula derivation despite spatial tasks requiring visualization alone. SpatialVizBench empirically demonstrates that state-of-the-art MLLMs continue to exhibit deficiencies in spatial visualization tasks, thereby addressing a significant lacuna in the field. The benchmark is publicly available.",
      "authors": [
        "Siting Wang",
        "Luoyang Sun",
        "Cheng Deng",
        "Kun Shao",
        "Minnan Pei",
        "Zheng Tian",
        "Haifeng Zhang",
        "Jun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:27:20+00:00",
          "link": "https://arxiv.org/abs/2507.07610v1",
          "size": "3775kb",
          "version": "v1"
        }
      ],
      "title": "SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07610",
        "PDF": "https://arxiv.org/pdf/2507.07610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a spatial visualization benchmark for MLLMs but primarily evaluates model performance on visualization tasks, not focusing on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07853",
      "abstract": "Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries.",
      "authors": [
        "Navish Kumar",
        "Thomas M\\\"ollenhoff",
        "Mohammad Emtiyaz Khan",
        "Aurelien Lucchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:33:28+00:00",
          "link": "https://arxiv.org/abs/2507.07853v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "Optimization Guarantees for Square-Root Natural-Gradient Variational Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07853",
        "HTML": "https://arxiv.org/html/2507.07853v1",
        "PDF": "https://arxiv.org/pdf/2507.07853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization guarantees for variational inference using natural-gradient descent, which does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2304.13431",
      "abstract": "Machine learning models are prone to capturing the spurious correlations between non-causal attributes and classes, with counterfactual data augmentation being a promising direction for breaking these spurious associations. However, generating counterfactual data explicitly poses a challenge, and incorporating augmented data into the training process decreases training efficiency. This study proposes an Implicit Counterfactual Data Augmentation (ICDA) method to remove spurious correlations and make stable predictions. Specifically, first, a novel sample-wise augmentation strategy is developed that generates semantically and counterfactually meaningful deep features with distinct augmentation strength for each sample. Second, we derive an easy-to-compute surrogate loss on the augmented feature set when the number of augmented samples becomes infinite. Third, two concrete schemes are proposed, including direct quantification and meta-learning, to derive the key parameters for the robust loss. In addition, ICDA is explained from a regularization perspective, revealing its capacity to improve intra-class compactness and augment margins at both class and sample levels. Extensive experiments have been conducted across various biased learning scenarios covering both image and text datasets, demonstrating that ICDA consistently enhances the generalization and robustness performance of popular networks.",
      "authors": [
        "Xiaoling Zhou",
        "Ou Wu",
        "Michael K. Ng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-26T10:36:40+00:00",
          "link": "https://arxiv.org/abs/2304.13431v1",
          "size": "36855kb",
          "version": "v1"
        },
        {
          "date": "2024-10-16T03:26:25+00:00",
          "link": "https://arxiv.org/abs/2304.13431v2",
          "size": "7403kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:06:34+00:00",
          "link": "https://arxiv.org/abs/2304.13431v3",
          "size": "8420kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T11:57:06+00:00",
          "link": "https://arxiv.org/abs/2304.13431v4",
          "size": "5228kb",
          "version": "v4"
        }
      ],
      "title": "Implicit Counterfactual Data Augmentation for Robust Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.13431",
        "HTML": "https://arxiv.org/html/2304.13431v4",
        "PDF": "https://arxiv.org/pdf/2304.13431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses counterfactual data augmentation for robust learning in biased scenarios, unrelated to LLM training data processing."
      },
      "tasks": [
        "counterfactual",
        "Data Augmentation",
        "Meta-Learning",
        "Out-of-Distribution Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.18865",
      "abstract": "Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as uncovering a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions are (most) sensitive to the presence of related sentences, and how to best characterize this kind of sensitivity. We do so by measuring different types of consistency errors that occur after probing an LLM whose inputs consist of hypotheses preceded by (negated) supporting and contradicting sentences. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these truth-value directions influences the position of an entailed or contradicted sentence along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the model, and the kind of data. Finally, our results suggest that truth-value directions are causal mediators in the inference process that incorporates in-context information.",
      "authors": [
        "Stefan F. Schouten",
        "Peter Bloem",
        "Ilia Markov",
        "Piek Vossen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T16:52:57+00:00",
          "link": "https://arxiv.org/abs/2404.18865v1",
          "size": "1119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:21:39+00:00",
          "link": "https://arxiv.org/abs/2404.18865v2",
          "size": "1051kb",
          "version": "v2"
        }
      ],
      "title": "Truth-value judgment in language models: 'truth directions' are context sensitive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18865",
        "PDF": "https://arxiv.org/pdf/2404.18865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on probing the latent spaces of LLMs for truth-value directions, examining context sensitivity in inference processes, not on training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07961",
      "abstract": "In this paper, we prove a novel trace inequality involving two operators. As applications, we sharpen the one-shot achievability bound on the relative entropy error in a wealth of quantum covering-type problems, such as soft covering, privacy amplification, convex splitting, quantum information decoupling, and quantum channel simulation by removing some dimension-dependent factors. Moreover, the established one-shot bounds extend to infinite-dimensional separable Hilbert spaces as well. The proof techniques are based on the recently developed operator layer cake theorem and an operator change-of-variable argument, which are of independent interest.",
      "authors": [
        "Hao-Chung Cheng",
        "Li Gao",
        "Christoph Hirche",
        "Hao-Wei Huang",
        "Po-Chieh Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Functional Analysis (math.FA)",
        "Information Theory (math.IT)",
        "Operator Algebras (math.OA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:41:50+00:00",
          "link": "https://arxiv.org/abs/2507.07961v1",
          "size": "26kb",
          "version": "v1"
        }
      ],
      "title": "Sharp estimates of quantum covering problems via a novel trace inequality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07961",
        "PDF": "https://arxiv.org/pdf/2507.07961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum covering problems and a novel trace inequality, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18813",
      "abstract": "Eye-tracking technology has gained significant attention in recent years due to its wide range of applications in human-computer interaction, virtual and augmented reality, and wearable health. Traditional RGB camera-based eye-tracking systems often struggle with poor temporal resolution and computational constraints, limiting their effectiveness in capturing rapid eye movements. To address these limitations, we propose EyeTrAES, a novel approach using neuromorphic event cameras for high-fidelity tracking of natural pupillary movement that shows significant kinematic variance. One of EyeTrAES's highlights is the use of a novel adaptive windowing/slicing algorithm that ensures just the right amount of descriptive asynchronous event data accumulation within an event frame, across a wide range of eye movement patterns. EyeTrAES then applies lightweight image processing functions over accumulated event frames from just a single eye to perform pupil segmentation and tracking. We show that these methods boost pupil tracking fidelity by 6+%, achieving IoU~=92%, while incurring at least 3x lower latency than competing pure event-based eye tracking alternatives [38]. We additionally demonstrate that the microscopic pupillary motion captured by EyeTrAES exhibits distinctive variations across individuals and can thus serve as a biometric fingerprint. For robust user authentication, we train a lightweight per-user Random Forest classifier using a novel feature vector of short-term pupillary kinematics, comprising a sliding window of pupil (location, velocity, acceleration) triples. Experimental studies with two different datasets demonstrate that the EyeTrAES-based authentication technique can simultaneously achieve high authentication accuracy (~=0.82) and low processing latency (~=12ms), and significantly outperform multiple state-of-the-art competitive baselines.",
      "authors": [
        "Argha Sen",
        "Nuwan Bandara",
        "Ila Gokarn",
        "Thivya Kandappu",
        "Archan Misra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T15:06:05+00:00",
          "link": "https://arxiv.org/abs/2409.18813v1",
          "size": "6333kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T17:22:09+00:00",
          "link": "https://arxiv.org/abs/2409.18813v2",
          "size": "3779kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:45:38+00:00",
          "link": "https://arxiv.org/abs/2409.18813v3",
          "size": "3779kb",
          "version": "v3"
        }
      ],
      "title": "EyeTrAES: Fine-grained, Low-Latency Eye Tracking via Adaptive Event Slicing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18813",
        "HTML": "https://arxiv.org/html/2409.18813v3",
        "PDF": "https://arxiv.org/pdf/2409.18813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel eye-tracking system using adaptive event slicing but does not relate to LLM training data processing or data engineering operations."
      },
      "tasks": [
        "Descriptive",
        "Pupil Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07134",
      "abstract": "The pervasive issue of bias in AI presents a significant challenge to painting classification, and is getting more serious as these systems become increasingly integrated into tasks like art curation and restoration. Biases, often arising from imbalanced datasets where certain artistic styles dominate, compromise the fairness and accuracy of model predictions, i.e., classifiers are less accurate on rarely seen paintings. While prior research has made strides in improving classification performance, it has largely overlooked the critical need to address these underlying biases, that is, when dealing with out-of-distribution (OOD) data. Our insight highlights the necessity of a more robust approach to bias mitigation in AI models for art classification on biased training data. We propose a novel OOD-informed model bias adaptive sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It addresses these challenges by dynamically adjusting temperature scaling and sampling probabilities, thereby promoting a more equitable representation of all classes. We evaluate our proposed approach to the KaoKore and PACS datasets, focusing on the model's ability to reduce class-wise bias. We further propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to assess class-wise separation and per-class bias reduction. Our method demonstrates the ability to balance high performance with fairness, making it a robust solution for unbiasing AI models in the art domain.",
      "authors": [
        "Mridula Vijendran",
        "Shuang Chen",
        "Jingjing Deng",
        "Hubert P. H. Shum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:18:36+00:00",
          "link": "https://arxiv.org/abs/2507.07134v1",
          "size": "5929kb",
          "version": "v1"
        }
      ],
      "title": "BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07134",
        "HTML": "https://arxiv.org/html/2507.07134v1",
        "PDF": "https://arxiv.org/pdf/2507.07134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces adaptive sampling for bias mitigation in AI models, focusing on handling biased datasets in art classification, with no direct focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07159",
      "abstract": "Portfolio optimization is a routine asset management operation conducted in financial institutions around the world. However, under real-world constraints such as turnover limits and transaction costs, its formulation becomes a mixed-integer nonlinear program that current mixed-integer optimizers often struggle to solve. We propose mapping this problem onto a classical Ising-like Hamiltonian and solving it with Variational Neural Annealing (VNA), via its classical formulation implemented using autoregressive neural networks. We demonstrate that VNA can identify near-optimal solutions for portfolios comprising more than 2,000 assets and yields performance comparable to that of state-of-the-art optimizers, such as Mosek, while exhibiting faster convergence on hard instances. Finally, we present a dynamical finite-size scaling analysis applied to the S&P 500, Russell 1000, and Russell 3000 indices, revealing universal behavior and polynomial annealing time scaling of the VNA algorithm on portfolio optimization problems.",
      "authors": [
        "Nishan Ranabhat",
        "Behnam Javanparast",
        "David Goerz",
        "and Estelle Inack"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Portfolio Management (q-fin.PM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:46:59+00:00",
          "link": "https://arxiv.org/abs/2507.07159v1",
          "size": "3141kb",
          "version": "v1"
        }
      ],
      "title": "Large-scale portfolio optimization with variational neural annealing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07159",
        "HTML": "https://arxiv.org/html/2507.07159v1",
        "PDF": "https://arxiv.org/pdf/2507.07159"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses portfolio optimization using Variational Neural Annealing and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07188",
      "abstract": "Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts -- we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also reveal that all tested models exhibit a consistent \\textit{recency bias} varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.",
      "authors": [
        "Jens Rupprecht (1)",
        "Georg Ahnert (1)",
        "Markus Strohmaier (1 and 2 and 3) ((1) University of Mannheim",
        "(2) GESIS - Leibniz Institute for the Social Sciences",
        "(3) Complexity Science Hub)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:01:50+00:00",
          "link": "https://arxiv.org/abs/2507.07188v1",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07188",
        "HTML": "https://arxiv.org/html/2507.07188v1",
        "PDF": "https://arxiv.org/pdf/2507.07188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This study examines perturbations in LLM survey responses and highlights prompt design impacts but does not focus on data processing for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07752",
      "abstract": "Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in real-world environments, where challenges such as dynamic objects, low texture, and critically, varying illumination conditions often degrade performance. Existing feature-based SLAM systems rely on fixed front-end parameters, making them vulnerable to sudden lighting changes and unstable feature tracking. To address these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and Adaptive Feature-Culling front-end designed to enhance vSLAM resilience in complex and challenging environments. Our approach introduces: (1) an image enhancement scheme to preprocess and adjust image quality under varying lighting conditions; (2) an adaptive feature extraction mechanism that dynamically adjusts detection sensitivity based on image entropy, pixel intensity, and gradient analysis; and (3) a feature culling strategy that filters out unreliable feature points using density distribution analysis and a lighting impact factor. Comprehensive evaluations on the TUM-VI and European Robotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly reduces tracking failures and achieves superior trajectory accuracy compared to state-of-the-art vSLAM methods under adverse illumination conditions. These results highlight the effectiveness of adaptive front-end strategies in improving vSLAM robustness without incurring significant computational overhead. The implementation of IRAF-SLAM is publicly available at https://thanhnguyencanh. github.io/IRAF-SLAM/.",
      "authors": [
        "Thanh Nguyen Canh",
        "Bao Nguyen Quoc",
        "Haolan Zhang",
        "Bupesh Rethinam Veeraiah",
        "Xiem HoangVan and Nak Young Chong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:32:19+00:00",
          "link": "https://arxiv.org/abs/2507.07752v1",
          "size": "14935kb",
          "version": "v1"
        }
      ],
      "title": "IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07752",
        "HTML": "https://arxiv.org/html/2507.07752v1",
        "PDF": "https://arxiv.org/pdf/2507.07752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Visual SLAM enhancements but does not relate to LLM training data processing; instead, it focuses on image preprocessing and feature extraction for SLAM."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07924",
      "abstract": "The evaluation of Information Retrieval (IR) systems typically uses query-document pairs with corresponding human-labelled relevance assessments (qrels). These qrels are used to determine if one system is better than another based on average retrieval performance. Acquiring large volumes of human relevance assessments is expensive. Therefore, more efficient relevance assessment approaches have been proposed, necessitating comparisons between qrels to ascertain their efficacy. Discriminative power, i.e. the ability to correctly identify significant differences between systems, is important for drawing accurate conclusions on the robustness of qrels. Previous work has measured the proportion of pairs of systems that are identified as significantly different and has quantified Type I statistical errors. Type I errors lead to incorrect conclusions due to false positive significance tests. We argue that also identifying Type II errors (false negatives) is important as they lead science in the wrong direction. We quantify Type II errors and propose that balanced classification metrics, such as balanced accuracy, can be used to portray the discriminative power of qrels. We perform experiments using qrels generated using alternative relevance assessment methods to investigate measuring hypothesis testing errors in IR evaluation. We find that additional insights into the discriminative power of qrels can be gained by quantifying Type II errors, and that balanced classification metrics can be used to give an overall summary of discriminative power in one, easily comparable, number.",
      "authors": [
        "Jack McKechnie",
        "Graham McDonald",
        "Craig Macdonald"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:06:24+00:00",
          "link": "https://arxiv.org/abs/2507.07924v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "Measuring Hypothesis Testing Errors in the Evaluation of Retrieval Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07924",
        "HTML": "https://arxiv.org/html/2507.07924v1",
        "PDF": "https://arxiv.org/pdf/2507.07924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates hypothesis testing errors in IR evaluation using query-document pairs, which is unrelated to processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.15379",
      "abstract": "Interactive Text-to-image retrieval (I-TIR) is an important enabler for a wide range of state-of-the-art services in domains such as e-commerce and education. However, current methods rely on finetuned Multimodal Large Language Models (MLLMs), which are costly to train and update, and exhibit poor generalizability. This latter issue is of particular concern, as: 1) finetuning narrows the pretrained distribution of MLLMs, thereby reducing generalizability; and 2) I-TIR introduces increasing query diversity and complexity. As a result, I-TIR solutions are highly likely to encounter queries and images not well represented in any training dataset. To address this, we propose leveraging Diffusion Models (DMs) for text-to-image mapping, to avoid finetuning MLLMs while preserving robust performance on complex queries. Specifically, we introduce Diffusion Augmented Retrieval (DAR), a framework that generates multiple intermediate representations via LLM-based dialogue refinements and DMs, producing a richer depiction of the user's information needs. This augmented representation facilitates more accurate identification of semantically and visually related images. Extensive experiments on four benchmarks show that for simple queries, DAR achieves results on par with finetuned I-TIR models, yet without incurring their tuning overhead. Moreover, as queries become more complex through additional conversational turns, DAR surpasses finetuned I-TIR models by up to 7.61% in Hits@10 after ten turns, illustrating its improved generalization for more intricate queries.",
      "authors": [
        "Zijun Long and Kangheng Liang and Gerardo Aragon-Camarasa and Richard Mccreadie and Paul Henderson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-26T03:29:18+00:00",
          "link": "https://arxiv.org/abs/2501.15379v1",
          "size": "4755kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T04:14:22+00:00",
          "link": "https://arxiv.org/abs/2501.15379v2",
          "size": "2694kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion Augmented Retrieval: A Training-Free Approach to Interactive Text-to-Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15379",
        "HTML": "https://arxiv.org/html/2501.15379v2",
        "PDF": "https://arxiv.org/pdf/2501.15379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a training-free approach to interactive text-to-image retrieval using diffusion models, which does not involve processing or improving LLM training data."
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Image Retrieval",
        "Large Language Model",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07210",
      "abstract": "Smartwatches such as the Apple Watch collect vast amounts of intimate health and fitness data as we wear them. Users have little choice regarding how this data is processed: The Apple Watch can only be used with Apple's iPhones, using their software and their cloud services. We are the first to publicly reverse-engineer the watch's wireless protocols, which led to discovering multiple security issues in Apple's proprietary implementation. With WatchWitch, our custom Android reimplementation, we break out of Apple's walled garden -- demonstrating practical interoperability with enhanced privacy controls and data autonomy. We thus pave the way for more consumer choice in the smartwatch ecosystem, offering users more control over their devices.",
      "authors": [
        "Nils Rollshausen",
        "Alexander Heinrich",
        "Matthias Hollick",
        "Jiska Classen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:33:58+00:00",
          "link": "https://arxiv.org/abs/2507.07210v1",
          "size": "1233kb",
          "version": "v1"
        }
      ],
      "title": "WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07210",
        "HTML": "https://arxiv.org/html/2507.07210v1",
        "PDF": "https://arxiv.org/pdf/2507.07210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The core focus of the paper is on interoperability and privacy for smartwatches, unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07796",
      "abstract": "Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning paradigm for vision transformers, with conventional approaches utilizing dataset-level prompts that remain the same across all input instances. We observe that this strategy results in sub-optimal performance due to high variance in downstream datasets. To address this challenge, we propose Visual Instance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts based on each individual input and fuses them with dataset-level prompts, leveraging Principal Component Analysis (PCA) to retain important prompting information. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two corner cases based on a conceptual understanding, in which they fail to effectively capture instance-specific information, while random dimension reduction on prompts only yields performance between the two extremes. Instead, ViaPT overcomes these limitations by balancing dataset-level and instance-level knowledge, while reducing the amount of learnable parameters compared to VPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our method consistently outperforms state-of-the-art baselines, establishing a new paradigm for analyzing and optimizing visual prompts for vision transformers.",
      "authors": [
        "Xi Xiao",
        "Yunbei Zhang",
        "Xingjian Li",
        "Tianyang Wang",
        "Xiao Wang",
        "Yuxiang Wei",
        "Jihun Hamm",
        "Min Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:23:15+00:00",
          "link": "https://arxiv.org/abs/2507.07796v1",
          "size": "2100kb",
          "version": "v1"
        }
      ],
      "title": "Visual Instance-aware Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07796",
        "HTML": "https://arxiv.org/html/2507.07796v1",
        "PDF": "https://arxiv.org/pdf/2507.07796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual instance-aware prompt tuning for vision transformers, which involves optimizing performance using instance-specific prompts rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07947",
      "abstract": "The recent advances in generative models such as diffusion models have raised several risks and concerns related to privacy, copyright infringements and data stewardship. To better understand and control the risks, various researchers have created techniques, experiments and attacks that reconstruct images, or part of images, from the training set. While these techniques already establish that data from the training set can be reconstructed, they often rely on high-resources, excess to the training set as well as well-engineered and designed prompts.\n  In this work, we devise a new attack that requires low resources, assumes little to no access to the actual training set, and identifies, seemingly, benign prompts that lead to potentially-risky image reconstruction. This highlights the risk that images might even be reconstructed by an uninformed user and unintentionally. For example, we identified that, with regard to one existing model, the prompt ``blue Unisex T-Shirt'' can generate the face of a real-life human model. Our method builds on an intuition from previous works which leverages domain knowledge and identifies a fundamental vulnerability that stems from the use of scraped data from e-commerce platforms, where templated layouts and images are tied to pattern-like prompts.",
      "authors": [
        "Sol Yarkoni and Roi Livni"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:32:26+00:00",
          "link": "https://arxiv.org/abs/2507.07947v1",
          "size": "47781kb",
          "version": "v1"
        }
      ],
      "title": "Low Resource Reconstruction Attacks Through Benign Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07947",
        "HTML": "https://arxiv.org/html/2507.07947v1",
        "PDF": "https://arxiv.org/pdf/2507.07947"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses privacy risks and reconstruction attacks related to generative models, highlighting vulnerabilities due to data used in training but does not primarily focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07966",
      "abstract": "We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 52K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves strong performance on long video QA benchmarks such as VideoMME. It also outperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal reasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on our LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent performance gains as the number of input video frames scales. LongVILA-R1 marks a firm step towards long video reasoning in VLMs. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens).",
      "authors": [
        "Yukang Chen",
        "Wei Huang",
        "Baifeng Shi",
        "Qinghao Hu",
        "Hanrong Ye",
        "Ligeng Zhu",
        "Zhijian Liu",
        "Pavlo Molchanov",
        "Jan Kautz",
        "Xiaojuan Qi",
        "Sifei Liu",
        "Hongxu Yin",
        "Yao Lu",
        "Song Han"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:47:40+00:00",
          "link": "https://arxiv.org/abs/2507.07966v1",
          "size": "4929kb",
          "version": "v1"
        }
      ],
      "title": "Scaling RL to Long Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07966",
        "HTML": "https://arxiv.org/html/2507.07966v1",
        "PDF": "https://arxiv.org/pdf/2507.07966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a large-scale dataset and a training pipeline but its primary focus is on scaling vision-language models with reinforcement learning for long video reasoning, rather than the details of LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.02401",
      "abstract": "In the global challenge of understanding and characterizing biodiversity, short species-specific genomic sequences known as DNA barcodes play a critical role, enabling fine-grained comparisons among organisms within the same kingdom of life. Although machine learning algorithms specifically designed for the analysis of DNA barcodes are becoming more popular, most existing methodologies rely on generic supervised training algorithms. We introduce BarcodeBERT, a family of models tailored to biodiversity analysis and trained exclusively on data from a reference library of 1.5M invertebrate DNA barcodes. We compared the performance of BarcodeBERT on taxonomic identification tasks against a spectrum of machine learning approaches including supervised training of classical neural architectures and fine-tuning of general DNA foundation models. Our self-supervised pretraining strategies on domain-specific data outperform fine-tuned foundation models, especially in identification tasks involving lower taxa such as genera and species. We also compared BarcodeBERT with BLAST, one of the most widely used bioinformatics tools for sequence searching, and found that our method matched BLAST's performance in species-level classification while being 55 times faster. Our analysis of masking and tokenization strategies also provides practical guidance for building customized DNA language models, emphasizing the importance of aligning model training strategies with dataset characteristics and domain knowledge. The code repository is available at https://github.com/bioscan-ml/BarcodeBERT.",
      "authors": [
        "Pablo Millan Arias",
        "Niousha Sadjadi",
        "Monireh Safari",
        "ZeMing Gong",
        "Austin T. Wang",
        "Joakim Bruslund Haurum",
        "Iuliia Zarubiieva",
        "Dirk Steinke",
        "Lila Kari",
        "Angel X. Chang",
        "Scott C. Lowe and Graham W. Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-04T13:25:49+00:00",
          "link": "https://arxiv.org/abs/2311.02401v1",
          "size": "758kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T00:06:31+00:00",
          "link": "https://arxiv.org/abs/2311.02401v2",
          "size": "1137kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T17:18:00+00:00",
          "link": "https://arxiv.org/abs/2311.02401v3",
          "size": "1312kb",
          "version": "v3"
        }
      ],
      "title": "BarcodeBERT: Transformers for Biodiversity Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.02401",
        "HTML": "https://arxiv.org/html/2311.02401v3",
        "PDF": "https://arxiv.org/pdf/2311.02401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses self-supervised pretraining strategies and tokenization for custom DNA language models but primarily focuses on performance in biodiversity analysis tasks rather than LLM training data processing."
      },
      "models": [
        {
          "model_path": "LofiAmazon/BarcodeBERT-Entire-BOLD",
          "downloads": "14",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/LofiAmazon/BarcodeBERT-Entire-BOLD"
        },
        {
          "model_path": "bioscan-ml/BarcodeBERT",
          "downloads": "11862",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/bioscan-ml/BarcodeBERT"
        }
      ],
      "datasets": [
        {
          "dataset_name": "bioscan-ml/CanadianInvertebrates-ML",
          "downloads": "30",
          "likes": "0",
          "link": "https://huggingface.co/datasets/bioscan-ml/CanadianInvertebrates-ML"
        }
      ],
      "tasks": [
        "Model Selection"
      ],
      "repo_urls": [
        "https://github.com/bioscan-ml/barcodebert",
        "https://github.com/bioscan-ml/bioscan-5m",
        "https://github.com/kari-genomics-lab/barcodebert",
        "https://github.com/zahrag/BIOSCAN-5M"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10590",
      "abstract": "Recent breakthroughs in artificial intelligence (AI) have triggered surges in market valuations for AI-related companies, often outpacing the realization of underlying capabilities. We examine the anchoring effect of AI capabilities on equity valuations and propose a Capability Realization Rate (CRR) model to quantify the gap between AI potential and realized performance. Using data from the 2023--2025 generative AI boom, we analyze sector-level sensitivity and conduct case studies (OpenAI, Adobe, NVIDIA, Meta, Microsoft, Goldman Sachs) to illustrate patterns of valuation premium and misalignment. Our findings indicate that AI-native firms commanded outsized valuation premiums anchored to future potential, while traditional companies integrating AI experienced re-ratings subject to proof of tangible returns. We argue that CRR can help identify valuation misalignment risk-where market prices diverge from realized AI-driven value. We conclude with policy recommendations to improve transparency, mitigate speculative bubbles, and align AI innovation with sustainable market value.",
      "authors": [
        "Xinmin Fang",
        "Lingfeng Tao",
        "Zhengxiong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-15T01:06:06+00:00",
          "link": "https://arxiv.org/abs/2505.10590v1",
          "size": "1262kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:45:59+00:00",
          "link": "https://arxiv.org/abs/2505.10590v2",
          "size": "311kb",
          "version": "v2"
        }
      ],
      "title": "Anchoring AI Capabilities in Market Valuations: The Capability Realization Rate Model and Valuation Misalignment Risk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10590",
        "HTML": "https://arxiv.org/html/2505.10590v2",
        "PDF": "https://arxiv.org/pdf/2505.10590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines AI capabilities and market valuations without discussing the processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07696",
      "abstract": "In this article, we construct stationary solutions to the Navier-Stokes equations on certain Riemannian $3$-manifolds that exhibit Turing completeness, in the sense that they are capable of performing universal computation. This universality arises on manifolds admitting nonvanishing harmonic 1-forms, thus showing that computational universality is not obstructed by viscosity, provided the underlying geometry satisfies a mild cohomological condition. The proof makes use of a correspondence between nonvanishing harmonic $1$-forms and cosymplectic geometry, which extends the classical correspondence between Beltrami fields and Reeb flows on contact manifolds.",
      "authors": [
        "S{\\o}ren Dyhr",
        "\\'Angel Gonz\\'alez-Prieto",
        "Eva Miranda and Daniel Peralta-Salas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Computational Complexity (cs.CC)",
        "Analysis of PDEs (math.AP)",
        "Dynamical Systems (math.DS)",
        "Symplectic Geometry (math.SG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:19:05+00:00",
          "link": "https://arxiv.org/abs/2507.07696v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Turing complete Navier-Stokes steady states via cosymplectic geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07696",
        "HTML": "https://arxiv.org/html/2507.07696v1",
        "PDF": "https://arxiv.org/pdf/2507.07696"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is concerned with the construction of Navier-Stokes equation solutions with computational universality, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07802",
      "abstract": "Large-scale multi-modal models have demonstrated remarkable performance across various visual recognition tasks by leveraging extensive paired multi-modal training data. However, in real-world applications, the presence of missing or incomplete modality inputs often leads to significant performance degradation. Recent research has focused on prompt-based strategies to tackle this issue; however, existing methods are hindered by two major limitations: (1) static prompts lack the flexibility to adapt to varying missing-data conditions, and (2) basic prompt-tuning methods struggle to ensure reliable performance when critical modalities are missing.To address these challenges, we propose a novel Synergistic Prompting (SyP) framework for robust visual recognition with missing modalities. The proposed SyP introduces two key innovations: (I) a Dynamic Adapter, which computes adaptive scaling factors to dynamically generate prompts, replacing static parameters for flexible multi-modal adaptation, and (II) a Synergistic Prompting Strategy, which combines static and dynamic prompts to balance information across modalities, ensuring robust reasoning even when key modalities are missing. The proposed SyP achieves significant performance improvements over existing approaches across three widely-used visual recognition datasets, demonstrating robustness under diverse missing rates and conditions. Extensive experiments and ablation studies validate its effectiveness in handling missing modalities, highlighting its superior adaptability and reliability.",
      "authors": [
        "Zhihui Zhang",
        "Luanyuan Dai",
        "Qika Lin",
        "Yunfeng Diao",
        "Guangyin Jin",
        "Yufei Guo",
        "Jing Zhang",
        "Xiaoshuai Hao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:28:12+00:00",
          "link": "https://arxiv.org/abs/2507.07802v1",
          "size": "2191kb",
          "version": "v1"
        }
      ],
      "title": "Synergistic Prompting for Robust Visual Recognition with Missing Modalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07802",
        "HTML": "https://arxiv.org/html/2507.07802v1",
        "PDF": "https://arxiv.org/pdf/2507.07802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with prompt-based strategies for visual recognition with missing modalities, focusing on modality adaptation and prompting strategies, not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.13796",
      "abstract": "Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a \"push the button\" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussing how certain conditions can propagate through the ML workflow. Furthermore, it explores the connection between data leakage and the specific task being addressed, investigates its occurrence in Transfer Learning, and compares standard inductive ML with transductive ML frameworks. The conclusion summarizes key findings, emphasizing the importance of addressing data leakage for robust and reliable ML applications.",
      "authors": [
        "Andrea Apicella",
        "Francesco Isgr\\`o",
        "Roberto Prevete"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-24T20:30:52+00:00",
          "link": "https://arxiv.org/abs/2401.13796v1",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "2024-10-20T11:35:47+00:00",
          "link": "https://arxiv.org/abs/2401.13796v2",
          "size": "786kb",
          "version": "v2"
        },
        {
          "date": "2025-06-02T10:53:48+00:00",
          "link": "https://arxiv.org/abs/2401.13796v3",
          "size": "1741kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T09:54:55+00:00",
          "link": "https://arxiv.org/abs/2401.13796v4",
          "size": "1741kb",
          "version": "v4"
        }
      ],
      "title": "Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.13796",
        "PDF": "https://arxiv.org/pdf/2401.13796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper examines data leakage in ML workflows, addressing how it can contaminate training data, which indirectly relates to data quality but does not focus primarily on LLM training data processing."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.07414",
      "abstract": "Membership inference attacks (MIAs) pose significant privacy risks by determining whether individual data is in a dataset. While differential privacy (DP) mitigates these risks, it has limitations including limited resolution in expressing privacy-utility tradeoffs and intractable sensitivity calculations for tight guarantees. We propose a game-theoretic framework modeling privacy protection as a Bayesian game between defender and attacker, where privacy loss corresponds to the attacker's membership inference ability. To address strategic complexity, we represent the defender's mixed strategy as a neural network generator mapping private datasets to public representations (e.g., noisy statistics) and the attacker's strategy as a discriminator making membership claims. This \\textit{general-sum Generative Adversarial Network} trains iteratively through alternating updates, yielding \\textit{Bayes-Nash Generative Privacy (BNGP)} strategies. BNGP avoids worst-case privacy proofs such as sensitivity calculations, supports correlated mechanism compositions, handles heterogeneous attacker preferences. Empirical studies on sensitive dataset summary statistics show our approach significantly outperforms state-of-the-art methods by generating stronger attacks and achieving better privacy-utility tradeoffs.",
      "authors": [
        "Tao Zhang",
        "Rajagopal Venkatesaramani",
        "Rajat K. De",
        "Bradley A. Malin",
        "Yevgeniy Vorobeychik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T20:29:04+00:00",
          "link": "https://arxiv.org/abs/2410.07414v1",
          "size": "4518kb",
          "version": "v1"
        },
        {
          "date": "2024-12-05T17:14:04+00:00",
          "link": "https://arxiv.org/abs/2410.07414v2",
          "size": "4985kb",
          "version": "v2"
        },
        {
          "date": "2025-02-13T17:27:11+00:00",
          "link": "https://arxiv.org/abs/2410.07414v3",
          "size": "5478kb",
          "version": "v3"
        },
        {
          "date": "2025-05-05T02:00:50+00:00",
          "link": "https://arxiv.org/abs/2410.07414v4",
          "size": "6470kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T16:05:26+00:00",
          "link": "https://arxiv.org/abs/2410.07414v5",
          "size": "2262kb",
          "version": "v5"
        }
      ],
      "title": "Bayes-Nash Generative Privacy Against Membership Inference Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07414",
        "HTML": "https://arxiv.org/html/2410.07414v5",
        "PDF": "https://arxiv.org/pdf/2410.07414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While proposing a framework against membership inference attacks, the paper's focus is on privacy and game-theoretic approaches rather than LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07328",
      "abstract": "Large Language Models (LLMs) often generate scientifically plausible but factually invalid information, a challenge we term the \"plausibility-validity gap,\" particularly in specialized domains like chemistry. This paper presents a systematic methodology to bridge this gap by developing a specialized scientific assistant. We utilized the Magistral Small model, noted for its integrated reasoning capabilities, and fine-tuned it using Low-Rank Adaptation (LoRA). A key component of our approach was the creation of a \"dual-domain dataset,\" a comprehensive corpus curated from various sources encompassing both molecular properties and chemical reactions, which was standardized to ensure quality. Our evaluation demonstrates that the fine-tuned model achieves significant improvements over the baseline model in format adherence, chemical validity of generated molecules, and the feasibility of proposed synthesis routes. The results indicate a hierarchical learning pattern, where syntactic correctness is learned more readily than chemical possibility and synthesis feasibility. While a comparative analysis with human experts revealed competitive performance in areas like chemical creativity and reasoning, it also highlighted key limitations, including persistent errors in stereochemistry, a static knowledge cutoff, and occasional reference hallucination. This work establishes a viable framework for adapting generalist LLMs into reliable, specialized tools for chemical research, while also delineating critical areas for future improvement.",
      "authors": [
        "Malikussaid",
        "Hilal Hudan Nuha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:05:23+00:00",
          "link": "https://arxiv.org/abs/2507.07328v1",
          "size": "1267kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07328",
        "PDF": "https://arxiv.org/pdf/2507.07328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper develops a 'dual-domain dataset' with comprehensive curation and standardization processes, focusing on LLM training data processing for specialized chemical research tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07877",
      "abstract": "Recent advances in Automatic Speech Recognition (ASR) have demonstrated remarkable accuracy and robustness in diverse audio applications, such as live transcription and voice command processing. However, deploying these models on resource constrained edge devices (e.g., IoT device, wearables) still presents substantial challenges due to strict limits on memory, compute and power. Quantization, particularly Post-Training Quantization (PTQ), offers an effective way to reduce model size and inference cost without retraining. Despite its importance, the performance implications of various advanced quantization methods and bit-width configurations on ASR models remain unclear. In this work, we present a comprehensive benchmark of eight state-of-the-art (SOTA) PTQ methods applied to two leading edge-ASR model families, Whisper and Moonshine. We systematically evaluate model performances (i.e., accuracy, memory I/O and bit operations) across seven diverse datasets from the open ASR leaderboard, analyzing the impact of quantization and various configurations on both weights and activations. Built on an extension of the LLM compression toolkit, our framework integrates edge-ASR models, diverse advanced quantization algorithms, a unified calibration and evaluation data pipeline, and detailed analysis tools. Our results characterize the trade-offs between efficiency and accuracy, demonstrating that even 3-bit quantization can succeed on high capacity models when using advanced PTQ techniques. These findings provide valuable insights for optimizing ASR models on low-power, always-on edge devices.",
      "authors": [
        "Chen Feng and Yicheng Lin and Shaojie Zhuo and Chenzheng Su and Ramchalam Kinattinkara Ramakrishnan and Zhaocong Yuan and Xiaopeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.07877v1",
          "size": "500kb",
          "version": "v1"
        }
      ],
      "title": "Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07877",
        "HTML": "https://arxiv.org/html/2507.07877v1",
        "PDF": "https://arxiv.org/pdf/2507.07877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses quantization techniques for ASR models, not LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07348",
      "abstract": "Deep reinforcement learning (DRL) has achieved remarkable success across multiple domains, including competitive games, natural language processing, and robotics. Despite these advancements, policies trained via DRL often struggle to generalize to evaluation environments with different parameters. This challenge is typically addressed by training with multiple contexts and/or by leveraging additional structure in the problem. However, obtaining sufficient training data across diverse contexts can be impractical in real-world applications. In this work, we consider contextual Markov decision processes (CMDPs) with transition and reward functions that exhibit regularity in context parameters. We introduce the context-enhanced Bellman equation (CEBE) to improve generalization when training on a single context. We prove both analytically and empirically that the CEBE yields a first-order approximation to the Q-function trained across multiple contexts. We then derive context sample enhancement (CSE) as an efficient data augmentation method for approximating the CEBE in deterministic control environments. We numerically validate the performance of CSE in simulation environments, showcasing its potential to improve generalization in DRL.",
      "authors": [
        "James Chapman",
        "Kedar Karhadkar",
        "Guido Montufar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:23:13+00:00",
          "link": "https://arxiv.org/abs/2507.07348v1",
          "size": "880kb",
          "version": "v1"
        }
      ],
      "title": "Zero-Shot Context Generalization in Reinforcement Learning from Few Training Contexts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07348",
        "HTML": "https://arxiv.org/html/2507.07348v1",
        "PDF": "https://arxiv.org/pdf/2507.07348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on improving reinforcement learning by introducing CEBE and CSE methods for better generalization. It mentions data augmentation but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07625",
      "abstract": "We prove concentration inequalities for several models of non-linear random matrices. As corollaries we obtain estimates for linear spectral statistics of the conjugate kernel of neural networks and non-commutative polynomials in (possibly dependent) random matrices.",
      "authors": [
        "Rados{\\l}aw Adamczak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:47:42+00:00",
          "link": "https://arxiv.org/abs/2507.07625v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Concentration of measure for non-linear random matrices with applications to neural networks and non-commutative polynomials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07625",
        "HTML": "https://arxiv.org/html/2507.07625v1",
        "PDF": "https://arxiv.org/pdf/2507.07625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on concentration inequalities for random matrices, related to spectral statistics and polynomials, which doesn't pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07829",
      "abstract": "Foundation models for tabular data are rapidly evolving, with increasing interest in extending them to support additional modalities such as free-text features. However, existing benchmarks for tabular data rarely include textual columns, and identifying real-world tabular datasets with semantically rich text features is non-trivial. We propose a series of simple yet effective ablation-style strategies for incorporating text into conventional tabular pipelines. Moreover, we benchmark how state-of-the-art tabular foundation models can handle textual data by manually curating a collection of real-world tabular datasets with meaningful textual features. Our study is an important step towards improving benchmarking of foundation models for tabular data with text.",
      "authors": [
        "Martin Mr\\'az and Breenda Das and Anshul Gupta and Lennart Purucker and Frank Hutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:01:31+00:00",
          "link": "https://arxiv.org/abs/2507.07829v1",
          "size": "625kb",
          "version": "v1"
        }
      ],
      "title": "Towards Benchmarking Foundation Models for Tabular Data With Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07829",
        "HTML": "https://arxiv.org/html/2507.07829v1",
        "PDF": "https://arxiv.org/pdf/2507.07829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper involves creating new datasets with textual features for tabular data, focusing on methods for curating real-world datasets\u2014aligning with training-data processing by improving dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07908",
      "abstract": "Remote photoplethysmography (rPPG) has emerged as a promising non-invasive method for monitoring physiological signals using the camera. Although various domain adaptation and generalization methods were proposed to promote the adaptability of deep-based rPPG models in unseen deployment environments, considerations in aspects like privacy concerns and real-time adaptation restrict their application in real-world deployment. Thus, we aim to propose a novel fully Test-Time Adaptation (TTA) strategy tailored for rPPG tasks in this work. Specifically, based on prior knowledge in physiology and our observations, we noticed not only there is spatio-temporal consistency in the frequency domain of rPPG signals, but also that inconsistency in the time domain was significant. Given this, by leveraging both consistency and inconsistency priors, we introduce an innovative expert knowledge-based self-supervised \\textbf{C}onsistency-\\textbf{i}n\\textbf{C}onsistency-\\textbf{i}ntegration (\\textbf{CiCi}) framework to enhances model adaptation during inference. Besides, our approach further incorporates a gradient dynamic control mechanism to mitigate potential conflicts between priors, ensuring stable adaptation across instances. Through extensive experiments on five diverse datasets under the TTA protocol, our method consistently outperforms existing techniques, presenting state-of-the-art performance in real-time self-supervised adaptation without accessing source data. The code will be released later.",
      "authors": [
        "Xiao Yang",
        "Yuxuan Fan",
        "Can Liu",
        "Houcheng Su",
        "Weichen Guo",
        "Jiyao Wang and Dengbo He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:39:49+00:00",
          "link": "https://arxiv.org/abs/2507.07908v1",
          "size": "2880kb",
          "version": "v1"
        }
      ],
      "title": "Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07908",
        "HTML": "https://arxiv.org/html/2507.07908v1",
        "PDF": "https://arxiv.org/pdf/2507.07908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a Test-Time Adaptation strategy for remote physiological measurements and does not relate to LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.16803",
      "abstract": "In order to unlock the potential of diverse sensors, we investigate a method to transfer knowledge between time-series modalities using a multimodal \\textit{temporal} representation space for Human Activity Recognition (HAR). Specifically, we explore the setting where the modality used in testing has no labeled data during training, which we refer to as Unsupervised Modality Adaptation (UMA). We categorize existing UMA approaches as Student-Teacher or Contrastive Alignment methods. These methods typically compress continuous-time data samples into single latent vectors during alignment, inhibiting their ability to transfer temporal information through real-world temporal distortions. To address this, we introduce Cross-modal Transfer Through Time (C3T), which preserves temporal information during alignment to handle dynamic sensor data better. C3T achieves this by aligning a set of temporal latent vectors across sensing modalities. Our extensive experiments on various camera+IMU datasets demonstrate that C3T outperforms existing methods in UMA by at least 8% in accuracy and shows superior robustness to temporal distortions such as time-shift, misalignment, and dilation. Our findings suggest that C3T has significant potential for developing generalizable models for time-series sensor data, opening new avenues for various multimodal applications.",
      "authors": [
        "Abhi Kamboj",
        "Anh Duy Nguyen",
        "Minh N. Do"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T19:06:44+00:00",
          "link": "https://arxiv.org/abs/2407.16803v1",
          "size": "1392kb",
          "version": "v1"
        },
        {
          "date": "2024-11-07T17:10:15+00:00",
          "link": "https://arxiv.org/abs/2407.16803v2",
          "size": "6145kb",
          "version": "v2"
        },
        {
          "date": "2025-06-09T15:03:39+00:00",
          "link": "https://arxiv.org/abs/2407.16803v3",
          "size": "2091kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T06:16:59+00:00",
          "link": "https://arxiv.org/abs/2407.16803v4",
          "size": "2091kb",
          "version": "v4"
        }
      ],
      "title": "C3T: Cross-modal Transfer Through Time for Sensor-based Human Activity Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16803",
        "HTML": "https://arxiv.org/html/2407.16803v4",
        "PDF": "https://arxiv.org/pdf/2407.16803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cross-modal transfer learning for human activity recognition using sensor data and does not discuss or contribute to LLM training data processing."
      },
      "tasks": [
        "Action Recognition",
        "Activity Recognition",
        "Human Activity Recognition",
        "Temporal Action Localization",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06509",
      "abstract": "Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.\n  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of \\emph{representative} instances and maps the other given locations to the representative ones, we prove that there exists a \\emph{strategyproof} mechanism achieving a bounded consistency guarantee of $\\frac{\\sqrt{(1+c)^2W^2_{\\min}+(1-c)^2W^2_{\\max}}}{(1+c)W_{\\min}}$ and a bounded robustness guarantee of $\\frac{\\sqrt{(1-c)^2W^2_{\\min}+(1+c)^2W^2_{\\max}}}{(1-c)W_{\\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\\min}$ and $W_{\\max}$ denote the minimum and maximum agents' weight. We also proved that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\\left( n \\cdot \\frac{W_{\\max}}{W_{\\min}} \\right)$-robustness in weighted FLP, even with fully predictions of all agents.",
      "authors": [
        "Yangguang Shi",
        "Zhenyu Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:52+00:00",
          "link": "https://arxiv.org/abs/2507.06509v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:52:39+00:00",
          "link": "https://arxiv.org/abs/2507.06509v2",
          "size": "18kb",
          "version": "v2"
        }
      ],
      "title": "Prediction-Augmented Mechanism Design for Weighted Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06509",
        "HTML": "https://arxiv.org/html/2507.06509v2",
        "PDF": "https://arxiv.org/pdf/2507.06509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores prediction augmented mechanisms for facility location problems, focusing on strategic agent behavior rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07151",
      "abstract": "Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs.",
      "authors": [
        "Zongmeng Zhang",
        "Wengang Zhou",
        "Jie Zhao",
        "Houqiang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:18:38+00:00",
          "link": "https://arxiv.org/abs/2507.07151v1",
          "size": "3649kb",
          "version": "v1"
        }
      ],
      "title": "Robust Multimodal Large Language Models Against Modality Conflict",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07151",
        "HTML": "https://arxiv.org/html/2507.07151v1",
        "PDF": "https://arxiv.org/pdf/2507.07151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the creation of a dataset, MMMC, focusing on modality conflict in MLLMs, but primarily investigates hallucination phenomena rather than focusing on processing or improving training data quality substantively."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07576",
      "abstract": "A task of interest in machine learning (ML) is that of ascribing explanations to the predictions made by ML models. Furthermore, in domains deemed high risk, the rigor of explanations is paramount. Indeed, incorrect explanations can and will mislead human decision makers. As a result, and even if interpretability is acknowledged as an elusive concept, so-called interpretable models are employed ubiquitously in high-risk uses of ML and data mining (DM). This is the case for rule-based ML models, which encompass decision trees, diagrams, sets and lists. This paper relates explanations with well-known undesired facets of rule-based ML models, which include negative overlap and several forms of redundancy. The paper develops algorithms for the analysis of these undesired facets of rule-based systems, and concludes that well-known and widely used tools for learning rule-based ML models will induce rule sets that exhibit one or more negative facets.",
      "authors": [
        "Mohamed Siala",
        "Jordi Planes",
        "Joao Marques-Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:28:12+00:00",
          "link": "https://arxiv.org/abs/2507.07576v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "On Trustworthy Rule-Based Models and Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07576",
        "HTML": "https://arxiv.org/html/2507.07576v1",
        "PDF": "https://arxiv.org/pdf/2507.07576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithms related to rule-based ML model explanations and analysis of undesired facets. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00569",
      "abstract": "The introduction of generative artificial intelligence (GenAI) has been met with a mix of reactions by higher education institutions, ranging from consternation and resistance to wholehearted acceptance. Previous work has looked at the discourse and policies adopted by universities across the U.S. as well as educators, along with the inclusion of GenAI-related content and topics in higher education. Building on previous research, this study reports findings from a survey of engineering educators on their use of and perspectives toward generative AI. Specifically, we surveyed 98 educators from engineering, computer science, and education who participated in a workshop on GenAI in Engineering Education to learn about their perspectives on using these tools for teaching and research. We asked them about their use of and comfort with GenAI, their overall perspectives on GenAI, the challenges and potential harms of using it for teaching, learning, and research, and examined whether their approach to using and integrating GenAI in their classroom influenced their experiences with GenAI and perceptions of it. Consistent with other research in GenAI education, we found that while the majority of participants were somewhat familiar with GenAI, reported use varied considerably. We found that educators harbored mostly hopeful and positive views about the potential of GenAI. We also found that those who engaged more with their students on the topic of GenAI, tend to be more positive about its contribution to learning, while also being more attuned to its potential abuses. These findings suggest that integrating and engaging with generative AI is essential to foster productive interactions between instructors and students around this technology.",
      "authors": [
        "Umama Dewan",
        "Ashish Hingle",
        "Nora McDonald",
        "Aditya Johri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T21:29:53+00:00",
          "link": "https://arxiv.org/abs/2502.00569v1",
          "size": "644kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T21:50:49+00:00",
          "link": "https://arxiv.org/abs/2502.00569v2",
          "size": "644kb",
          "version": "v2"
        }
      ],
      "title": "Engineering Educators' Perspectives on the Impact of Generative AI in Higher Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00569",
        "PDF": "https://arxiv.org/pdf/2502.00569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on educators' perspectives on GenAI in higher education, without any contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02644",
      "abstract": "The rapid development of neural quantum states (NQS) has established it as a promising framework for studying quantum many-body systems. In this work, by leveraging the cutting-edge transformer-based architectures and developing highly efficient optimization algorithms, we achieve the state-of-the-art results for the doped two-dimensional (2D) Hubbard model, arguably the minimum model for high-Tc superconductivity. Interestingly, we find different attention heads in the NQS ansatz can directly encode correlations at different scales, making it capable of capturing long-range correlations and entanglements in strongly correlated systems. With these advances, we establish the half-filled stripe in the ground state of 2D Hubbard model with the next nearest neighboring hoppings, consistent with experimental observations in cuprates. Our work establishes NQS as a powerful tool for solving challenging many-fermions systems.",
      "authors": [
        "Yuntian Gu",
        "Wenrui Li",
        "Heng Lin",
        "Bo Zhan",
        "Ruichen Li",
        "Yifei Huang",
        "Di He",
        "Yantao Wu",
        "Tao Xiang",
        "Mingpu Qin",
        "Liwei Wang",
        "Dingshun Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:08:25+00:00",
          "link": "https://arxiv.org/abs/2507.02644v1",
          "size": "2881kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:46:55+00:00",
          "link": "https://arxiv.org/abs/2507.02644v2",
          "size": "2917kb",
          "version": "v2"
        }
      ],
      "title": "Solving the Hubbard model with Neural Quantum States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02644",
        "HTML": "https://arxiv.org/html/2507.02644v2",
        "PDF": "https://arxiv.org/pdf/2507.02644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using neural quantum states to solve the Hubbard model, a quantum many-body problem, without any mention of LLM training data or related processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06203",
      "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, especially when guided by explicit chain-of-thought (CoT) reasoning that verbalizes intermediate steps. While CoT improves both interpretability and accuracy, its dependence on natural language reasoning limits the model's expressive bandwidth. Latent reasoning tackles this bottleneck by performing multi-step inference entirely in the model's continuous hidden state, eliminating token-level supervision. To advance latent reasoning research, this survey provides a comprehensive overview of the emerging field of latent reasoning. We begin by examining the foundational role of neural network layers as the computational substrate for reasoning, highlighting how hierarchical representations support complex transformations. Next, we explore diverse latent reasoning methodologies, including activation-based recurrence, hidden state propagation, and fine-tuning strategies that compress or internalize explicit reasoning traces. Finally, we discuss advanced paradigms such as infinite-depth latent reasoning via masked diffusion models, which enable globally consistent and reversible reasoning processes. By unifying these perspectives, we aim to clarify the conceptual landscape of latent reasoning and chart future directions for research at the frontier of LLM cognition. An associated GitHub repository collecting the latest papers and repos is available at: https://github.com/multimodal-art-projection/LatentCoT-Horizon/.",
      "authors": [
        "Rui-Jie Zhu",
        "Tianhao Peng",
        "Tianhao Cheng",
        "Xingwei Qu",
        "Jinfa Huang",
        "Dawei Zhu",
        "Hao Wang",
        "Kaiwen Xue",
        "Xuanliang Zhang",
        "Yong Shan",
        "Tianle Cai",
        "Taylor Kergan",
        "Assel Kembay",
        "Andrew Smith",
        "Chenghua Lin",
        "Binh Nguyen",
        "Yuqi Pan",
        "Yuhong Chou",
        "Zefan Cai",
        "Zhenhe Wu",
        "Yongchi Zhao",
        "Tianyu Liu",
        "Jian Yang",
        "Wangchunshu Zhou",
        "Chujie Zheng",
        "Chongxuan Li",
        "Yuyin Zhou",
        "Zhoujun Li",
        "Zhaoxiang Zhang",
        "Jiaheng Liu",
        "Ge Zhang",
        "Wenhao Huang",
        "Jason Eshraghian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:29:07+00:00",
          "link": "https://arxiv.org/abs/2507.06203v1",
          "size": "11103kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:43:36+00:00",
          "link": "https://arxiv.org/abs/2507.06203v2",
          "size": "11090kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Latent Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06203",
        "HTML": "https://arxiv.org/html/2507.06203v2",
        "PDF": "https://arxiv.org/pdf/2507.06203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys latent reasoning in LLMs, exploring methodologies and paradigms for reasoning techniques without focusing on training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07339",
      "abstract": "Decisions about managing patients on the heart transplant waitlist are currently made by committees of doctors who consider multiple factors, but the process remains largely ad-hoc. With the growing volume of longitudinal patient, donor, and organ data collected by the United Network for Organ Sharing (UNOS) since 2018, there is increasing interest in analytical approaches to support clinical decision-making at the time of organ availability. In this study, we benchmark machine learning models that leverage longitudinal waitlist history data for time-dependent, time-to-event modeling of waitlist mortality. We train on 23,807 patient records with 77 variables and evaluate both survival prediction and discrimination at a 1-year horizon. Our best model achieves a C-Index of 0.94 and AUROC of 0.89, significantly outperforming previous models. Key predictors align with known risk factors while also revealing novel associations. Our findings can support urgency assessment and policy refinement in heart transplant decision making.",
      "authors": [
        "Yingtao Luo",
        "Reza Skandari",
        "Carlos Martinez",
        "Arman Kilic",
        "Rema Padman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:51:31+00:00",
          "link": "https://arxiv.org/abs/2507.07339v1",
          "size": "1367kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Waitlist Mortality Prediction in Heart Transplantation Through Time-to-Event Modeling using New Longitudinal UNOS Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07339",
        "PDF": "https://arxiv.org/pdf/2507.07339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with benchmarks for mortality prediction in heart transplantation using a longitudinal dataset. It does not concern itself with processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18199",
      "abstract": "Semantic Edge Computing (SEC) and Semantic Communications (SemComs) have been proposed as viable approaches to achieve real-time edge-enabled intelligence in sixth-generation (6G) wireless networks. On one hand, SemCom leverages the strength of Deep Neural Networks (DNNs) to encode and communicate the semantic information only, while making it robust to channel distortions by compensating for wireless effects. Ultimately, this leads to an improvement in the communication efficiency. On the other hand, SEC has leveraged distributed DNNs to divide the computation of a DNN across different devices based on their computational and networking constraints. Although significant progress has been made in both fields, the literature lacks a systematic view to connect both fields. In this work, we fulfill the current gap by unifying the SEC and SemCom fields. We summarize the research problems in these two fields and provide a comprehensive review of the state of the art with a focus on their technical strengths and challenges.",
      "authors": [
        "Milin Zhang",
        "Mohammad Abdi",
        "Venkat R. Dasari",
        "Francesco Restuccia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T10:21:10+00:00",
          "link": "https://arxiv.org/abs/2411.18199v1",
          "size": "1630kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T23:33:33+00:00",
          "link": "https://arxiv.org/abs/2411.18199v2",
          "size": "2357kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T19:22:05+00:00",
          "link": "https://arxiv.org/abs/2411.18199v3",
          "size": "894kb",
          "version": "v3"
        }
      ],
      "title": "Semantic Edge Computing and Semantic Communications in 6G Networks: A Unifying Survey and Research Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18199",
        "HTML": "https://arxiv.org/html/2411.18199v3",
        "PDF": "https://arxiv.org/pdf/2411.18199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews semantic edge computing and semantic communications in 6G networks, focusing on deep neural networks but does not address LLM training data processing."
      },
      "tasks": [
        "Edge-computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18374",
      "abstract": "In this technical report, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.",
      "authors": [
        "Yaiza Bermudez",
        "Gaetan Bisson",
        "I\\~naki Esnaola",
        "Samir M. Perlaza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "History and Overview (math.HO)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T14:26:29+00:00",
          "link": "https://arxiv.org/abs/2501.18374v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T14:45:36+00:00",
          "link": "https://arxiv.org/abs/2501.18374v2",
          "size": "20kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:43:06+00:00",
          "link": "https://arxiv.org/abs/2501.18374v3",
          "size": "329kb",
          "version": "v3"
        }
      ],
      "title": "Proofs for Folklore Theorems on the Radon-Nikodym Derivative",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18374",
        "PDF": "https://arxiv.org/pdf/2501.18374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides formal proofs related to the Radon-Nikodym derivative and does not involve any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.15220",
      "abstract": "Videos contain a wealth of information, and generating detailed and accurate descriptions in natural language is a key aspect of video understanding. In this paper, we present video-SALMONN 2, an advanced audio-visual large language model (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimisation (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimised using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initialising the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilise the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28\\%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at \\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.",
      "authors": [
        "Changli Tang",
        "Yixuan Li",
        "Yudong Yang",
        "Jimin Zhuang",
        "Guangzhi Sun",
        "Wei Li",
        "Zejun Ma",
        "Chao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T07:58:41+00:00",
          "link": "https://arxiv.org/abs/2506.15220v1",
          "size": "551kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:09:22+00:00",
          "link": "https://arxiv.org/abs/2506.15220v2",
          "size": "552kb",
          "version": "v2"
        }
      ],
      "title": "video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15220",
        "HTML": "https://arxiv.org/html/2506.15220v2",
        "PDF": "https://arxiv.org/pdf/2506.15220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in video captioning accuracy using audio-visual models. It focuses on model adaptation and evaluation metrics rather than LLM training data processing."
      },
      "tasks": [
        "Audio captioning",
        "Large Language Model",
        "Question Answering",
        "Video Captioning",
        "Video Question Answering",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06562",
      "abstract": "In recent years, advancements in hardware have enabled quadruped robots to operate with high power and speed, while robust locomotion control using reinforcement learning (RL) has also been realized. As a result, expectations are rising for the automation of tasks such as material transport and exploration in unknown environments. However, autonomous locomotion in rough terrains with significant height variations requires vertical movement, and robots capable of performing such movements stably, along with their control methods, have not yet been fully established. In this study, we developed the quadruped robot KLEIYN, which features a waist joint, and aimed to expand quadruped locomotion by enabling chimney climbing through RL. To facilitate the learning of vertical motion, we introduced Contact-Guided Curriculum Learning (CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to 1000 mm in width at an average speed of 150 mm/s, 50 times faster than conventional robots. Furthermore, we demonstrated that the introduction of a waist joint improves climbing performance, particularly enhancing tracking ability on narrow walls.",
      "authors": [
        "Keita Yoneda",
        "Kento Kawaharazuka",
        "Temma Suzuki",
        "Takahiro Hattori",
        "Kei Okada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:30:53+00:00",
          "link": "https://arxiv.org/abs/2507.06562v1",
          "size": "5012kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T11:05:21+00:00",
          "link": "https://arxiv.org/abs/2507.06562v2",
          "size": "5012kb",
          "version": "v2"
        }
      ],
      "title": "KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06562",
        "HTML": "https://arxiv.org/html/2507.06562v2",
        "PDF": "https://arxiv.org/pdf/2507.06562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on quadruped robot locomotion and wall climbing using reinforcement learning, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07065",
      "abstract": "Defining suitable quantum extensions of classical divergences often poses a challenge due to the non-commutative nature of quantum information. In this work, we propose a new approach via what we call the layer cake representation. The resulting quantum R\\'enyi and $f$-divergences are then proven to be equivalent to those recently defined via integral representations. Nevertheless, the approach can provide several insights. We give an alternative proof of the integral representation of the relative entropy by Frenkel and prove a conjecture regarding a trace expression for the R\\'enyi divergence. Additionally, we give applications to error exponents in hypothesis testing, a new Riemann-Stieltjes type integral representation and a variational representation.",
      "authors": [
        "Po-Chieh Liu",
        "Christoph Hirche",
        "Hao-Chung Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.07065v1",
          "size": "527kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:53:52+00:00",
          "link": "https://arxiv.org/abs/2507.07065v2",
          "size": "527kb",
          "version": "v2"
        }
      ],
      "title": "Layer Cake Representations for Quantum Divergences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07065",
        "PDF": "https://arxiv.org/pdf/2507.07065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes quantum divergence representations and discusses applications to hypothesis testing, but it does not engage in developing or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07671",
      "abstract": "Modern edge-cloud systems face challenges in efficiently scaling resources to handle dynamic and unpredictable workloads. Traditional scaling approaches typically rely on static thresholds and predefined rules, which are often inadequate for optimizing resource utilization and maintaining performance in distributed and dynamic environments. This inefficiency hinders the adaptability and performance required in edge-cloud infrastructures, which can only be achieved through the newly proposed in-place scaling. To address this problem, we propose the Multi-Agent Reinforcement Learning-based In-place Scaling Engine (MARLISE) that enables seamless, dynamic, reactive control with in-place resource scaling. We develop our solution using two Deep Reinforcement Learning algorithms: Deep Q-Network (DQN), and Proximal Policy Optimization (PPO). We analyze each version of the proposed MARLISE solution using dynamic workloads, demonstrating their ability to ensure low response times of microservices and scalability. Our results show that MARLISE-based approaches outperform heuristic method in managing resource elasticity while maintaining microservice response times and achieving higher resource efficiency.",
      "authors": [
        "Jovan Prodanov",
        "Bla\\v{z} Bertalani\\v{c}",
        "Carolina Fortuna",
        "Shih-Kai Chou",
        "Matja\\v{z} Branko Juri\\v{c}",
        "Ramon Sanchez-Iborra and Jernej Hribar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:52:34+00:00",
          "link": "https://arxiv.org/abs/2507.07671v1",
          "size": "1057kb",
          "version": "v1"
        }
      ],
      "title": "Multi-agent Reinforcement Learning-based In-place Scaling Engine for Edge-cloud Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07671",
        "HTML": "https://arxiv.org/html/2507.07671v1",
        "PDF": "https://arxiv.org/pdf/2507.07671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a reinforcement learning approach for resource scaling in edge-cloud systems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07955",
      "abstract": "Despite incredible progress in language models (LMs) in recent years, largely resulting from moving away from specialized models designed for specific tasks to general models based on powerful architectures (e.g. the Transformer) that learn everything from raw data, pre-processing steps such as tokenization remain a barrier to true end-to-end foundation models. We introduce a collection of new techniques that enable a dynamic chunking mechanism which automatically learns content -- and context -- dependent segmentation strategies learned jointly with the rest of the model. Incorporating this into an explicit hierarchical network (H-Net) allows replacing the (implicitly hierarchical) tokenization-LM-detokenization pipeline with a single model learned fully end-to-end. When compute- and data- matched, an H-Net with one stage of hierarchy operating at the byte level outperforms a strong Transformer language model operating over BPE tokens. Iterating the hierarchy to multiple stages further increases its performance by modeling multiple levels of abstraction, demonstrating significantly better scaling with data and matching a token-based Transformer of twice its size. H-Nets pretrained on English show significantly increased character-level robustness, and qualitatively learn meaningful data-dependent chunking strategies without any heuristics or explicit supervision. Finally, the H-Net's improvement over tokenized pipelines is further increased in languages and modalities with weaker tokenization heuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement in data efficiency over baselines), showing the potential of true end-to-end models that learn and scale better from unprocessed data.",
      "authors": [
        "Sukjun Hwang",
        "Brandon Wang",
        "Albert Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:39:37+00:00",
          "link": "https://arxiv.org/abs/2507.07955v1",
          "size": "500kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07955",
        "HTML": "https://arxiv.org/html/2507.07955v1",
        "PDF": "https://arxiv.org/pdf/2507.07955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces dynamic chunking strategies and hierarchical models that adapt tokenization, significantly impacting LLM training data processing by learning data-dependent segmentation strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.01114",
      "abstract": "Agent-based simulation (ABS) models are potent tools for analyzing complex systems. However, understanding and validating ABS models can be a significant challenge. To address this challenge, cutting-edge data-driven techniques offer sophisticated capabilities for analyzing the outcomes of ABS models. One such technique is process mining, which encompasses a range of methods for discovering, monitoring, and enhancing processes by extracting knowledge from event logs. However, applying process mining to event logs derived from ABSs is not trivial, and deriving meaningful insights from the resulting process models adds an additional layer of complexity. Although process mining is invaluable in extracting insights from ABS models, there is a lack of comprehensive methodological guidance for its application in ABS evaluation in the research landscape. In this paper, we propose a methodology, based on the CRoss-Industry Standard Process for Data Mining (CRISP-DM) methodology, to assess ABS models using process mining techniques. We incorporate process mining techniques into the stages of the CRISP-DM methodology, facilitating the analysis of ABS model behaviors and their underlying processes. We demonstrate our methodology using an established agent-based model, Schelling model of segregation. Our results show that our proposed methodology can effectively assess ABS models through produced event logs, potentially paving the way for enhanced agent-based model validity and more insightful decision-making.",
      "authors": [
        "Rob H. Bemthuis and Ruben R. Govers and Amin Asadi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T13:39:42+00:00",
          "link": "https://arxiv.org/abs/2404.01114v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "A CRISP-DM-based Methodology for Assessing Agent-based Simulation Models using Process Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01114",
        "HTML": "https://arxiv.org/html/2404.01114",
        "PDF": "https://arxiv.org/pdf/2404.01114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a methodology for analyzing agent-based simulation models using process mining, not related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18151",
      "abstract": "Multiword expressions (MWEs) refer to idiomatic sequences of multiple words. MWE identification, i.e., detecting MWEs in text, can play a key role in downstream tasks such as machine translation, but existing datasets for the task are inconsistently annotated, limited to a single type of MWE, or limited in size. To enable reliable and comprehensive evaluation, we created CoAM: Corpus of All-Type Multiword Expressions, a dataset of 1.3K sentences constructed through a multi-step process to enhance data quality consisting of human annotation, human review, and automated consistency checking. Additionally, for the first time in a dataset of MWE identification, CoAM's MWEs are tagged with MWE types, such as Noun and Verb, enabling fine-grained error analysis. Annotations for CoAM were collected using a new interface created with our interface generator, which allows easy and flexible annotation of MWEs in any form. Through experiments using CoAM, we find that a fine-tuned large language model outperforms MWEasWSD, which achieved the state-of-the-art performance on the DiMSUM dataset. Furthermore, analysis using our MWE type tagged data reveals that Verb MWEs are easier than Noun MWEs to identify across approaches.",
      "authors": [
        "Yusuke Ide",
        "Joshua Tanner",
        "Adam Nohejl",
        "Jacob Hoffman",
        "Justin Vasselli",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T04:09:33+00:00",
          "link": "https://arxiv.org/abs/2412.18151v1",
          "size": "9122kb",
          "version": "v1"
        },
        {
          "date": "2025-05-31T09:09:06+00:00",
          "link": "https://arxiv.org/abs/2412.18151v2",
          "size": "9212kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T03:38:25+00:00",
          "link": "https://arxiv.org/abs/2412.18151v3",
          "size": "9212kb",
          "version": "v3"
        }
      ],
      "title": "CoAM: Corpus of All-Type Multiword Expressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18151",
        "HTML": "https://arxiv.org/html/2412.18151v3",
        "PDF": "https://arxiv.org/pdf/2412.18151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on creating the CoAM dataset with a detailed multi-step process including human annotation, review, and automated consistency checking, enhancing data quality for training and evaluation of LLMs."
      },
      "datasets": [
        {
          "dataset_name": "yusuke196/CoAM",
          "downloads": "15",
          "likes": "4",
          "link": "https://huggingface.co/datasets/yusuke196/CoAM"
        }
      ],
      "tasks": [
        "All",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Machine Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15285",
      "abstract": "The primary requirement for cross-modal data fusion is the precise alignment of data from different sensors. However, the calibration between LiDAR point clouds and camera images is typically time-consuming and needs external calibration board or specific environmental features. Cross-modal registration effectively solves this problem by aligning the data directly without requiring external calibration. However, due to the domain gap between the point cloud and the image, existing methods rarely achieve satisfactory registration accuracy while maintaining real-time performance. To address this issue, we propose a framework that projects point clouds into several 2D representations for matching with camera images, which not only leverages the geometric characteristic of LiDAR point clouds effectively but also bridge the domain gap between the point cloud and image. Moreover, to tackle the challenges of cross modal differences and the limited overlap between LiDAR point clouds and images in the image matching task, we introduce a multi-scale feature extraction network to effectively extract features from both camera images and the projection maps of LiDAR point cloud. Additionally, we propose a patch-to-pixel matching network to provide more effective supervision and achieve high accuracy. We validate the performance of our model through experiments on the KITTI and nuScenes datasets. Experimental results demonstrate the the proposed method achieves real-time performance and extremely high registration accuracy. Specifically, on the KITTI dataset, our model achieves a registration accuracy rate of over 99\\%. Our code is released at: https://github.com/ESRSchao/EEPNet-V2.",
      "authors": [
        "Yuanchao Yue",
        "Hui Yuan",
        "Zhengxin Li",
        "Shuai Li",
        "Wei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T15:04:01+00:00",
          "link": "https://arxiv.org/abs/2503.15285v1",
          "size": "9330kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:06:33+00:00",
          "link": "https://arxiv.org/abs/2503.15285v2",
          "size": "14783kb",
          "version": "v2"
        }
      ],
      "title": "EEPNet-V2: Patch-to-Pixel Solution for Efficient Cross-Modal Registration between LiDAR Point Cloud and Camera Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15285",
        "HTML": "https://arxiv.org/html/2503.15285v2",
        "PDF": "https://arxiv.org/pdf/2503.15285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses cross-modal registration between LiDAR point clouds and camera images, focusing on alignment and matching techniques, not on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.06667",
      "abstract": "Recommender systems powered by generative models (Gen-RecSys) extend beyond classical item ranking by producing open-ended content, which simultaneously unlocks richer user experiences and introduces new risks. On one hand, these systems can enhance personalization and appeal through dynamic explanations and multi-turn dialogues. On the other hand, they might venture into unknown territory-hallucinating nonexistent items, amplifying bias, or leaking private information. Traditional accuracy metrics cannot fully capture these challenges, as they fail to measure factual correctness, content safety, or alignment with user intent.\n  This paper makes two main contributions. First, we categorize the evaluation challenges of Gen-RecSys into two groups: (i) existing concerns that are exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new risks (e.g., item hallucinations, contradictory explanations). Second, we propose a holistic evaluation approach that includes scenario-based assessments and multi-metric checks-incorporating relevance, factual grounding, bias detection, and policy compliance. Our goal is to provide a guiding framework so researchers and practitioners can thoroughly assess Gen-RecSys, ensuring effective personalization and responsible deployment.",
      "authors": [
        "Yashar Deldjoo",
        "Nikhil Mehta",
        "Maheswaran Sathiamoorthy",
        "Shuai Zhang",
        "Pablo Castells",
        "Julian McAuley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T08:08:16+00:00",
          "link": "https://arxiv.org/abs/2504.06667v1",
          "size": "1395kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:54:19+00:00",
          "link": "https://arxiv.org/abs/2504.06667v2",
          "size": "2369kb",
          "version": "v2"
        }
      ],
      "title": "Toward Holistic Evaluation of Recommender Systems Powered by Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06667",
        "HTML": "https://arxiv.org/html/2504.06667v2",
        "PDF": "https://arxiv.org/pdf/2504.06667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating recommender systems powered by generative models, focusing on their content generation aspects rather than LLM training data processing."
      },
      "tasks": [
        "Bias Detection",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06410",
      "abstract": "Breast density assessment is a crucial component of mammographic interpretation, with high breast density (BI-RADS categories C and D) representing both a significant risk factor for developing breast cancer and a technical challenge for tumor detection. This study proposes an automated deep learning system for robust binary classification of breast density (low: A/B vs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four advanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0, and DenseNet121, each enhanced with channel attention mechanisms. To address the inherent class imbalance, we developed a novel Combined Focal Label Smoothing Loss function that integrates focal loss, label smoothing, and class-balanced weighting. Our preprocessing pipeline incorporated advanced techniques, including contrast-limited adaptive histogram equalization (CLAHE) and comprehensive data augmentation. The individual models were combined through an optimized ensemble voting approach, achieving superior performance (AUC: 0.963, F1-score: 0.952) compared to any single model. This system demonstrates significant potential to standardize density assessments in clinical practice, potentially improving screening efficiency and early cancer detection rates while reducing inter-observer variability among radiologists.",
      "authors": [
        "Peyman Sharifian",
        "Xiaotong Hong",
        "Alireza Karimian",
        "Mehdi Amini",
        "and Hossein Arabi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.06410v1",
          "size": "200kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:19:51+00:00",
          "link": "https://arxiv.org/abs/2507.06410v2",
          "size": "200kb",
          "version": "v2"
        }
      ],
      "title": "Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06410",
        "PDF": "https://arxiv.org/pdf/2507.06410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses data preprocessing techniques like histogram equalization and data augmentation for mammography image classification, it primarily focuses on deep learning models and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07543",
      "abstract": "Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior.\n  Our findings reveal that retrieval is a critical bottleneck in cross-lingual domain-specific scenarios, with significant performance drops occurring when the user query and supporting document languages differ. A key insight is that these failures stem primarily from the retriever's difficulty in ranking documents across languages. Finally, we propose a simple retrieval strategy that addresses this source of failure by enforcing equal retrieval from both languages, resulting in substantial improvements in cross-lingual and overall performance. These results highlight meaningful opportunities for improving multilingual retrieval, particularly in practical, real-world RAG applications.",
      "authors": [
        "Chen Amiraz",
        "Yaroslav Fyodorov",
        "Elad Haramaty",
        "Zohar Karnin",
        "Liane Lewin-Eytan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:38:31+00:00",
          "link": "https://arxiv.org/abs/2507.07543v1",
          "size": "78kb",
          "version": "v1"
        }
      ],
      "title": "The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07543",
        "HTML": "https://arxiv.org/html/2507.07543v1",
        "PDF": "https://arxiv.org/pdf/2507.07543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper addresses retrieval challenges in cross-lingual scenarios, offering improvements in data retrieval for language models but lacks a substantive focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07560",
      "abstract": "Human and automation capabilities are the foundation of every human-autonomy interaction and interaction pattern. Therefore, machines need to understand the capacity and performance of human doing, and adapt their own behavior, accordingly. In this work, we address the concept of conjugated capabilities, i.e. capabilities that are dependent or interrelated and between which effort can be distributed. These may be used to overcome human limitations, by shifting effort from a deficient to a conjugated capability with performative resources. For example: A limited arm's reach may be compensated by tilting the torso forward. We analyze the interrelation between elementary capabilities within the IMBA standard to uncover potential conjugation, and show evidence in data of post-rehabilitation patients. From the conjugated capabilities, within the example application of stationary manufacturing, we create a network of interrelations. With this graph, a manifold of potential uses is enabled. We showcase the graph's usage in optimizing IMBA test design to accelerate data recordings, and discuss implications of conjugated capabilities on task allocation between the human and an autonomy.",
      "authors": [
        "Nils Mandischer",
        "Larissa F\\\"uller",
        "Torsten Alles",
        "Frank Flemisch",
        "Lars Mikelsons"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:59:18+00:00",
          "link": "https://arxiv.org/abs/2507.07560v1",
          "size": "484kb",
          "version": "v1"
        }
      ],
      "title": "Conjugated Capabilities: Interrelations of Elementary Human Capabilities and Their Implication on Human-Machine Task Allocation and Capability Testing Procedures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07560",
        "HTML": "https://arxiv.org/html/2507.07560v1",
        "PDF": "https://arxiv.org/pdf/2507.07560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses human-machine interaction patterns through conjugated capabilities but does not address any aspects of LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07847",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.",
      "authors": [
        "Youngjoon Jang",
        "Seongtae Hong",
        "Junyoung Son",
        "Sungjin Park",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:26:59+00:00",
          "link": "https://arxiv.org/abs/2507.07847v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07847",
        "HTML": "https://arxiv.org/html/2507.07847v1",
        "PDF": "https://arxiv.org/pdf/2507.07847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on coreference resolution within retrieval-augmented generation systems and improvements in retrieval effectiveness and QA performance, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07304",
      "abstract": "Discontinuous Galerkin (DG) methods are known to suffer from increasingly restrictive time step constraints as the polynomial order increases, limiting their efficiency at high orders. In this paper, we introduce a novel locally implicit, but globally explicit ADER-DG scheme designed for transport-dominated problems. The method achieves a maximum stable time step governed by an element-width based CFL condition that is independent of the polynomial degree. By solving a set of element-local implicit problems at each time step, our approach more effectively captures the domain of dependence. As a result, our method remains stable for CFL numbers up to $1/\\sqrt{d}$ in $d$ spatial dimensions. We provide a rigorous stability proof in one dimension, and extend the analysis to two and three dimensions using a semi-analytical von Neumann stability analysis. The accuracy and convergence of the method are demonstrated through numerical experiments on both linear and nonlinear test cases.",
      "authors": [
        "Kieran Ricardo",
        "Kenneth Duru"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:03:43+00:00",
          "link": "https://arxiv.org/abs/2507.07304v1",
          "size": "439kb",
          "version": "v1"
        }
      ],
      "title": "Scalable ADER-DG Transport Method with Polynomial Order Independent CFL Limit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07304",
        "HTML": "https://arxiv.org/html/2507.07304v1",
        "PDF": "https://arxiv.org/pdf/2507.07304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a numerical method for transport problems, specifically focusing on an ADER-DG scheme, without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06156",
      "abstract": "Blockchain bridges have become essential infrastructure for enabling interoperability across different blockchain networks, with more than $24B monthly bridge transaction volume. However, their growing adoption has been accompanied by a disproportionate rise in security breaches, making them the single largest source of financial loss in Web3. For cross-chain ecosystems to be robust and sustainable, it is essential to understand and address these vulnerabilities. In this study, we present a comprehensive systematization of blockchain bridge design and security. We define three bridge security priors, formalize the architectural structure of 13 prominent bridges, and identify 23 attack vectors grounded in real-world blockchain exploits. Using this foundation, we evaluate 43 representative attack scenarios and introduce a layered threat model that captures security failures across source chain, off-chain, and destination chain components.\n  Our analysis at the static code and transaction network levels reveals recurring design flaws, particularly in access control, validator trust assumptions, and verification logic, and identifies key patterns in adversarial behavior based on transaction-level traces. To support future development, we propose a decision framework for bridge architecture design, along with defense mechanisms such as layered validation and circuit breakers. This work provides a data-driven foundation for evaluating bridge security and lays the groundwork for standardizing resilient cross-chain infrastructure.",
      "authors": [
        "Poupak Azad",
        "Jiahua Xu",
        "Yebo Feng",
        "Preston Strowbridge",
        "Cuneyt Akcora"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:39:23+00:00",
          "link": "https://arxiv.org/abs/2507.06156v1",
          "size": "1013kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:52:00+00:00",
          "link": "https://arxiv.org/abs/2507.06156v2",
          "size": "1013kb",
          "version": "v2"
        }
      ],
      "title": "Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges [Experiment, Analysis & Benchmark]",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06156",
        "HTML": "https://arxiv.org/html/2507.06156v2",
        "PDF": "https://arxiv.org/pdf/2507.06156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on blockchain bridge security analysis and defense measures, which are outside the scope of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07186",
      "abstract": "Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \\emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs.",
      "authors": [
        "Itay Itzhak",
        "Yonatan Belinkov",
        "Gabriel Stanovsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:01:14+00:00",
          "link": "https://arxiv.org/abs/2507.07186v1",
          "size": "9297kb",
          "version": "v1"
        }
      ],
      "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07186",
        "HTML": "https://arxiv.org/html/2507.07186v1",
        "PDF": "https://arxiv.org/pdf/2507.07186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores sources of cognitive biases in LLMs and investigates pretraining and finetuning effects but does not primarily address training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07270",
      "abstract": "Integration of information from non-auditory cues can significantly improve the performance of speech-separation models. Often such models use deep modality-specific networks to obtain unimodal features, and risk being too costly or lightweight but lacking capacity. In this work, we present an iterative representation refinement approach called Bottleneck Iterative Network (BIN), a technique that repeatedly progresses through a lightweight fusion block, while bottlenecking fusion representations by fusion tokens. This helps improve the capacity of the model, while avoiding major increase in model size and balancing between the model performance and training cost. We test BIN on challenging noisy audio-visual speech separation tasks, and show that our approach consistently outperforms state-of-the-art benchmark models with respect to SI-SDRi on NTCD-TIMIT and LRS3+WHAM! datasets, while simultaneously achieving a reduction of more than 50% in training and GPU inference time across nearly all settings.",
      "authors": [
        "Sidong Zhang",
        "Shiv Shankar",
        "Trang Nguyen",
        "Andrea Fanelli",
        "Madalina Fiterau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:32:09+00:00",
          "link": "https://arxiv.org/abs/2507.07270v1",
          "size": "1416kb",
          "version": "v1"
        }
      ],
      "title": "Audio-Visual Speech Separation via Bottleneck Iterative Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07270",
        "HTML": "https://arxiv.org/html/2507.07270v1",
        "PDF": "https://arxiv.org/pdf/2507.07270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a model architecture for audio-visual speech separation and its performance, not on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07352",
      "abstract": "Computational models have become one of the prevalent methods to model complex phenomena. To accurately model complex interactions, such as detailed biomolecular interactions, scientists often rely on multiscale models comprised of several internal models operating at difference scales, ranging from microscopic to macroscopic length and time scales. Bridging the gap between different time and length scales has historically been challenging but the advent of newer machine learning (ML) approaches has shown promise for tackling that task. Multiscale models require massive amounts of computational power and a powerful workflow management system. Orchestrating ML-driven multiscale studies on parallel systems with thousands of nodes is challenging, the workflow must schedule, allocate and control thousands of simulations operating at different scales. Here, we discuss the massively parallel Multiscale Machine-Learned Modeling Infrastructure (MuMMI), a multiscale workflow management infrastructure, that can orchestrate thousands of molecular dynamics (MD) simulations operating at different timescales, spanning from millisecond to nanosecond. More specifically, we introduce a novel version of MuMMI called \"mini-MuMMI\". Mini-MuMMI is a curated version of MuMMI designed to run on modest HPC systems or even laptops whereas MuMMI requires larger HPC systems. We demonstrate mini-MuMMI utility by exploring RAS-RAF membrane interactions and discuss the different challenges behind the generalization of multiscale workflows and how mini-MuMMI can be leveraged to target a broader range of applications outside of MD and RAS-RAF interactions.",
      "authors": [
        "Lo\\\"ic Pottier",
        "Konstantia Georgouli",
        "Timothy S. Carpenter",
        "Fikret Aydin",
        "Jeremy O. B. Tempkin",
        "Dwight V. Nissley",
        "Frederick H. Streitz",
        "Thomas R. W. Scogland",
        "Peer-Timo Bremer",
        "Felice C. Lightstone",
        "Helgi I. Ing\\'olfsson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:34:46+00:00",
          "link": "https://arxiv.org/abs/2507.07352v1",
          "size": "1767kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning-driven Multiscale MD Workflows: The Mini-MuMMI Experience",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07352",
        "HTML": "https://arxiv.org/html/2507.07352v1",
        "PDF": "https://arxiv.org/pdf/2507.07352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a workflow management system for molecular dynamics simulations, discussing computational models rather than LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07435",
      "abstract": "In industrial point cloud analysis, detecting subtle anomalies demands high-resolution spatial data, yet prevailing benchmarks emphasize low-resolution inputs. To address this disparity, we propose a scalable pipeline for generating realistic and subtle 3D anomalies. Employing this pipeline, we developed MiniShift, the inaugural high-resolution 3D anomaly detection dataset, encompassing 2,577 point clouds, each with 500,000 points and anomalies occupying less than 1\\% of the total. We further introduce Simple3D, an efficient framework integrating Multi-scale Neighborhood Descriptors (MSND) and Local Feature Spatial Aggregation (LFSA) to capture intricate geometric details with minimal computational overhead, achieving real-time inference exceeding 20 fps. Extensive evaluations on MiniShift and established benchmarks demonstrate that Simple3D surpasses state-of-the-art methods in both accuracy and speed, highlighting the pivotal role of high-resolution data and effective feature aggregation in advancing practical 3D anomaly detection.",
      "authors": [
        "Yuqi Cheng",
        "Yihan Sun",
        "Hui Zhang",
        "Weiming Shen",
        "Yunkang Cao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:19:16+00:00",
          "link": "https://arxiv.org/abs/2507.07435v1",
          "size": "46128kb",
          "version": "v1"
        }
      ],
      "title": "Towards High-Resolution 3D Anomaly Detection: A Scalable Dataset and Real-Time Framework for Subtle Industrial Defects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07435",
        "HTML": "https://arxiv.org/html/2507.07435v1",
        "PDF": "https://arxiv.org/pdf/2507.07435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to LLM training data processing through the creation of a new dataset, MiniShift, with detailed data generation steps for high-resolution 3D anomaly detection, emphasizing scalability and feature aggregation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07712",
      "abstract": "Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which can alleviate forgetting by reintroducing representative samples from previous tasks. However, their performance is typically limited by class imbalance, both within the replay buffer due to limited global awareness and between replayed and newly arrived classes. To address this issue, we propose a class wise balancing data replay method for FCIL (FedCBDR), which employs a global coordination mechanism for class-level memory construction and reweights the learning objective to alleviate the aforementioned imbalances. Specifically, FedCBDR has two key components: 1) the global-perspective data replay module reconstructs global representations of prior task in a privacy-preserving manner, which then guides a class-aware and importance-sensitive sampling strategy to achieve balanced replay; 2) Subsequently, to handle class imbalance across tasks, the task aware temperature scaling module adaptively adjusts the temperature of logits at both class and instance levels based on task dynamics, which reduces the model's overconfidence in majority classes while enhancing its sensitivity to minority classes. Experimental results verified that FedCBDR achieves balanced class-wise sampling under heterogeneous data distributions and improves generalization under task imbalance between earlier and recent tasks, yielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.",
      "authors": [
        "Zhuang Qi",
        "Lei Meng",
        "Han Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.07712v1",
          "size": "1023kb",
          "version": "v1"
        }
      ],
      "title": "Balancing the Past and Present: A Coordinated Replay Framework for Federated Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07712",
        "HTML": "https://arxiv.org/html/2507.07712v1",
        "PDF": "https://arxiv.org/pdf/2507.07712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and replay methods for task imbalance in distributed systems. It lacks any mention of LLM training data processing or data engineering necessary for LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07773",
      "abstract": "Image sensors are integral to a wide range of safety- and security-critical systems, including surveillance infrastructure, autonomous vehicles, and industrial automation. These systems rely on the integrity of visual data to make decisions. In this work, we investigate a novel class of electromagnetic signal injection attacks that target the analog domain of image sensors, allowing adversaries to manipulate raw visual inputs without triggering conventional digital integrity checks. We uncover a previously undocumented attack phenomenon on CMOS image sensors: rainbow-like color artifacts induced in images captured by image sensors through carefully tuned electromagnetic interference. We further evaluate the impact of these attacks on state-of-the-art object detection models, showing that the injected artifacts propagate through the image signal processing pipeline and lead to significant mispredictions. Our findings highlight a critical and underexplored vulnerability in the visual perception stack, highlighting the need for more robust defenses against physical-layer attacks in such systems.",
      "authors": [
        "Youqian Zhang",
        "Xinyu Ji",
        "Zhihao Wang",
        "Qinhong Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:55:35+00:00",
          "link": "https://arxiv.org/abs/2507.07773v1",
          "size": "1827kb",
          "version": "v1"
        }
      ],
      "title": "Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07773",
        "HTML": "https://arxiv.org/html/2507.07773v1",
        "PDF": "https://arxiv.org/pdf/2507.07773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates electromagnetic signal injection attacks targeting image sensors, which affect visual perception. It does not relate to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07820",
      "abstract": "Current AI advances largely rely on scaling neural models and expanding training datasets to achieve generalization and robustness. Despite notable successes, this paradigm incurs significant environmental, economic, and ethical costs, limiting sustainability and equitable access. Inspired by biological sensory systems, where adaptation occurs dynamically at the input (e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive sensing as a necessary and foundational shift. Adaptive sensing proactively modulates sensor parameters (e.g., exposure, sensitivity, multimodal configurations) at the input level, significantly mitigating covariate shifts and improving efficiency. Empirical evidence from recent studies demonstrates that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass substantially larger models (e.g., OpenCLIP-H) trained with significantly more data and compute. We (i) outline a roadmap for broadly integrating adaptive sensing into real-world applications spanning humanoid, healthcare, autonomous systems, agriculture, and environmental monitoring, (ii) critically assess technical and ethical integration challenges, and (iii) propose targeted research directions, such as standardized benchmarks, real-time adaptive algorithms, multimodal integration, and privacy-preserving methods. Collectively, these efforts aim to transition the AI community toward sustainable, robust, and equitable artificial intelligence systems.",
      "authors": [
        "Eunsu Baek",
        "Keondo Park",
        "Jeonggil Ko",
        "Min-hwan Oh",
        "Taesik Gong and Hyung-Sin Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:50:32+00:00",
          "link": "https://arxiv.org/abs/2507.07820v1",
          "size": "2104kb",
          "version": "v1"
        }
      ],
      "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07820",
        "HTML": "https://arxiv.org/html/2507.07820v1",
        "PDF": "https://arxiv.org/pdf/2507.07820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper advocates for adaptive sensing at the input level in AI systems, without discussing training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07898",
      "abstract": "In this study, we present a novel constraint-based algorithm for causal structure learning specifically designed for nonlinear autoregressive time series. Our algorithm significantly reduces computational complexity compared to existing methods, making it more efficient and scalable to larger problems. We rigorously evaluate its performance on synthetic datasets, demonstrating that our algorithm not only outperforms current techniques, but also excels in scenarios with limited data availability. These results highlight its potential for practical applications in fields requiring efficient and accurate causal inference from nonlinear time series data.",
      "authors": [
        "Mohammad Fesanghary and Achintya Gopal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.07898v1",
          "size": "4723kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Causal Discovery for Autoregressive Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07898",
        "HTML": "https://arxiv.org/html/2507.07898v1",
        "PDF": "https://arxiv.org/pdf/2507.07898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a causal discovery algorithm for time series, focusing on computational efficiency in causal inference without addressing any LLM training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01933",
      "abstract": "Spatial intelligence, encompassing 3D reconstruction, perception, and reasoning, is fundamental to applications such as robotics, aerial imaging, and extended reality. A key enabler is the real-time, accurate estimation of core 3D attributes (camera parameters, point clouds, depth maps, and 3D point tracks) from unstructured or streaming imagery. Inspired by the success of large foundation models in language and 2D vision, a new class of end-to-end 3D geometric foundation models (GFMs) has emerged, directly predicting dense 3D representations in a single feed-forward pass, eliminating the need for slow or unavailable precomputed camera parameters. Since late 2023, the field has exploded with diverse variants, but systematic evaluation is lacking. In this work, we present the first comprehensive benchmark for 3D GFMs, covering five core tasks: sparse-view depth estimation, video depth estimation, 3D reconstruction, multi-view pose estimation, novel view synthesis, and spanning both standard and challenging out-of-distribution datasets. Our standardized toolkit automates dataset handling, evaluation protocols, and metric computation to ensure fair, reproducible comparisons. We evaluate 16 state-of-the-art GFMs, revealing their strengths and limitations across tasks and domains, and derive key insights to guide future model scaling and optimization. All code, evaluation scripts, and processed data will be publicly released to accelerate research in 3D spatial intelligence.",
      "authors": [
        "Wenyan Cong",
        "Yiqing Liang",
        "Yancheng Zhang",
        "Ziyi Yang",
        "Yan Wang",
        "Boris Ivanovic",
        "Marco Pavone",
        "Chen Chen",
        "Zhangyang Wang",
        "Zhiwen Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T17:53:09+00:00",
          "link": "https://arxiv.org/abs/2506.01933v1",
          "size": "13412kb",
          "version": "v1"
        },
        {
          "date": "2025-06-09T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2506.01933v2",
          "size": "13428kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T17:55:35+00:00",
          "link": "https://arxiv.org/abs/2506.01933v3",
          "size": "13464kb",
          "version": "v3"
        }
      ],
      "title": "E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01933",
        "PDF": "https://arxiv.org/pdf/2506.01933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a benchmark for 3D geometric foundation models, focusing on evaluation protocols and tasks unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07354",
      "abstract": "PU (Positive Unlabeled) learning is a variant of supervised classification learning in which the only labels revealed to the learner are of positively labeled instances. PU learning arises in many real-world applications. Most existing work relies on the simplifying assumptions that the positively labeled training data is drawn from the restriction of the data generating distribution to positively labeled instances and/or that the proportion of positively labeled points (a.k.a. the class prior) is known apriori to the learner. This paper provides a theoretical analysis of the statistical complexity of PU learning under a wider range of setups. Unlike most prior work, our study does not assume that the class prior is known to the learner. We prove upper and lower bounds on the required sample sizes (of both the positively labeled and the unlabeled samples).",
      "authors": [
        "Farnam Mansouri and Shai Ben-David"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:39:40+00:00",
          "link": "https://arxiv.org/abs/2507.07354v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Learning from positive and unlabeled examples -Finite size sample bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07354",
        "HTML": "https://arxiv.org/html/2507.07354v1",
        "PDF": "https://arxiv.org/pdf/2507.07354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a theoretical analysis of PU learning and sample bounds but does not focus on LLM training data processing or engineering contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07901",
      "abstract": "The fragmentation of AI agent ecosystems has created urgent demands for interoperability, trust, and economic coordination that current protocols -- including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al., 2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present the Nanda Unified Architecture, a decentralized framework built around three core innovations: fast DID-based agent discovery through distributed registries, semantic agent cards with verifiable credentials and composability profiles, and a dynamic trust layer that integrates behavioral attestations with policy compliance. The system introduces X42/H42 micropayments for economic coordination and MAESTRO, a security framework incorporating Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure containerization. Real-world deployments demonstrate 99.9 percent compliance in healthcare applications and substantial monthly transaction volumes with strong privacy guarantees. By unifying MIT's trust research with production deployments from Cisco and Synergetics, we show how cryptographic proofs and policy-as-code transform agents into trust-anchored participants in a decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a globally interoperable Internet of Agents where trust becomes the native currency of collaboration across both enterprise and Web3 ecosystems.",
      "authors": [
        "Sree Bhargavi Balija",
        "Rekha Singal",
        "Abhishek Singh",
        "Ramesh Raskar",
        "Erfan Darzi",
        "Raghu Bala",
        "Thomas Hardjono",
        "Ken Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.07901v1",
          "size": "4620kb",
          "version": "v1"
        }
      ],
      "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07901",
        "HTML": "https://arxiv.org/html/2507.07901v1",
        "PDF": "https://arxiv.org/pdf/2507.07901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses interoperability and economic coordination in AI agent ecosystems, focusing on trust and security rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08936",
      "abstract": "Clinical information extraction, which involves structuring clinical concepts from unstructured medical text, remains a challenging problem that could benefit from the inclusion of tabular background information available in electronic health records. Existing open-source datasets lack explicit links between structured features and clinical concepts in the text, motivating the need for a new research dataset. We introduce SimSUM, a benchmark dataset of 10,000 simulated patient records that link unstructured clinical notes with structured background variables. Each record simulates a patient encounter in the domain of respiratory diseases and includes tabular data (e.g., symptoms, diagnoses, underlying conditions) generated from a Bayesian network whose structure and parameters are defined by domain experts. A large language model (GPT-4o) is prompted to generate a clinical note describing the encounter, including symptoms and relevant context. These notes are annotated with span-level symptom mentions. We conduct an expert evaluation to assess note quality and run baseline predictive models on both the tabular and textual data. The SimSUM dataset is primarily designed to support research on clinical information extraction in the presence of tabular background variables, which can be linked through domain knowledge to concepts of interest to be extracted from the text (symptoms, in the case of SimSUM). Secondary uses include research on the automation of clinical reasoning over both tabular data and text, causal effect estimation in the presence of tabular and/or textual confounders, and multi-modal synthetic data generation. SimSUM is not intended for training clinical decision support systems or production-grade models, but rather to facilitate reproducible research in a simplified and controlled setting. The dataset is available at https://github.com/prabaey/SimSUM.",
      "authors": [
        "Paloma Rabaey",
        "Stefan Heytens",
        "Thomas Demeester"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T15:55:15+00:00",
          "link": "https://arxiv.org/abs/2409.08936v1",
          "size": "855kb",
          "version": "v1"
        },
        {
          "date": "2025-03-07T17:09:02+00:00",
          "link": "https://arxiv.org/abs/2409.08936v2",
          "size": "1102kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:24:12+00:00",
          "link": "https://arxiv.org/abs/2409.08936v3",
          "size": "1563kb",
          "version": "v3"
        }
      ],
      "title": "SimSUM: Simulated Benchmark with Structured and Unstructured Medical Records",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08936",
        "HTML": "https://arxiv.org/html/2409.08936v3",
        "PDF": "https://arxiv.org/pdf/2409.08936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on the creation of the SimSUM dataset, detailing the data generation process involving simulated patient records and annotation, which directly contributes to LLM training data processing."
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model",
        "Synthetic Data Generation"
      ],
      "repo_urls": [
        "https://github.com/prabaey/synsum"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.19381",
      "abstract": "Animating hand-drawn sketches using traditional tools is challenging and complex. Sketches provide a visual basis for explanations, and animating these sketches offers an experience of real-time scenarios. We propose an approach for animating a given input sketch based on a descriptive text prompt. Our method utilizes a parametric representation of the sketch's strokes. Unlike previous methods, which struggle to estimate smooth and accurate motion and often fail to preserve the sketch's topology, we leverage a pre-trained text-to-video diffusion model with SDS loss to guide the motion of the sketch's strokes. We introduce length-area (LA) regularization to ensure temporal consistency by accurately estimating the smooth displacement of control points across the frame sequence. Additionally, to preserve shape and avoid topology changes, we apply a shape-preserving As-Rigid-As-Possible (ARAP) loss to maintain sketch rigidity. Our method surpasses state-of-the-art performance in both quantitative and qualitative evaluations.",
      "authors": [
        "Gaurav Rai",
        "Ojaswa Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T21:15:38+00:00",
          "link": "https://arxiv.org/abs/2411.19381v1",
          "size": "5671kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Sketch Animation: Text-to-Video Diffusion Models with Temporal Consistency and Rigidity Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19381",
        "HTML": "https://arxiv.org/html/2411.19381",
        "PDF": "https://arxiv.org/pdf/2411.19381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sketch animation using a pre-trained text-to-video diffusion model with no mention of any LLM training data processing."
      },
      "tasks": [
        "Descriptive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00283",
      "abstract": "Low Earth Orbit (LEO) satellite mega-constellations have recently emerged as a viable access solution for broadband services in underserved areas. In 2024, Direct Satellite-to-Device (DS2D) communications, which enable unmodified smartphones to connect directly to spaceborne base stations, entered large-scale beta testing, with Starlink globally leading deployments. This paper presents the first measurement study of commercial DS2D services. Using crowdsourced mobile network data collected in the U.S. between October 2024 and April 2025, our research derives evidence-based insights into the capabilities, limitations, and prospective evolution of DS2D technologies providing Supplemental Coverage from Space (SCS) services to expand existing mobile network connectivity. We observe a strong correlation between the number of satellites deployed and the expanding extension of observed measurements, concentrated in accessible but poorly covered areas by terrestrial networks, such as national parks and large low-density counties. The data reveal stable physical-layer value measurement throughout the observation period, with a lower median RSRP (24-dB difference) and a higher RSRQ (3 dB difference) compared to terrestrial networks, reflecting the SMS-only usage of the DS2D network during this period. Based on SINR measurements, we estimate the expected performance of the announced DS2D mobile data service to be around 4 Mbps per beam in outdoor conditions. We also discuss strategies to expand this capacity up to 12 Mbps in the future, depending on key regulatory decisions regarding satellite licenses, spectrum availability, and allowable radiated power levels.",
      "authors": [
        "Jorge Garcia-Cabeza",
        "Javier Albert-Smet",
        "Zoraida Frias",
        "Luis Mendo",
        "Santiago Andr\\'es Azcoitia",
        "Eduardo Yraola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T22:24:07+00:00",
          "link": "https://arxiv.org/abs/2506.00283v1",
          "size": "3708kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T13:32:35+00:00",
          "link": "https://arxiv.org/abs/2506.00283v2",
          "size": "3708kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T17:47:57+00:00",
          "link": "https://arxiv.org/abs/2506.00283v3",
          "size": "3708kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T22:40:39+00:00",
          "link": "https://arxiv.org/abs/2506.00283v4",
          "size": "3708kb",
          "version": "v4"
        }
      ],
      "title": "Direct-to-Cell: A First Look into Starlink's Direct Satellite-to-Device Radio Access Network through Crowdsourced Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00283",
        "HTML": "https://arxiv.org/html/2506.00283v4",
        "PDF": "https://arxiv.org/pdf/2506.00283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on measurement of Direct Satellite-to-Device services and discusses communication network insights, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07156",
      "abstract": "Supervised machine learning pipelines trained on features derived from persistent homology have been experimentally observed to ignore much of the information contained in a persistence diagram. Computing persistence diagrams is often the most computationally demanding step in such a pipeline, however. To explore this, we introduce several methods to generate topological feature vectors from unreduced boundary matrices. We compared the performance of pipelines trained on vectorizations of unreduced PDs to vectorizations of fully-reduced PDs across several data and task types. Our results indicate that models trained on PDs built from unreduced diagrams can perform on par and even outperform those trained on fully-reduced diagrams on some tasks. This observation suggests that machine learning pipelines which incorporate topology-based features may benefit in terms of computational cost and performance by utilizing information contained in unreduced boundary matrices.",
      "authors": [
        "Nicole Abreu",
        "Parker B. Edwards",
        "Francis Motta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computational Geometry (cs.CG)",
        "Machine Learning (cs.LG)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:49:11+00:00",
          "link": "https://arxiv.org/abs/2507.07156v1",
          "size": "791kb",
          "version": "v1"
        }
      ],
      "title": "Topological Machine Learning with Unreduced Persistence Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07156",
        "HTML": "https://arxiv.org/html/2507.07156v1",
        "PDF": "https://arxiv.org/pdf/2507.07156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the generation of topological feature vectors from persistence diagrams, but it does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.05187",
      "abstract": "Being able to decorrelate a feature space from protected attributes is an area of active research and study in ethics, fairness, and also natural sciences. We introduce a novel decorrelation method using Convex Neural Optimal Transport Solvers (Cnots) that is able to decorrelate a continuous feature space against protected attributes with optimal transport. We demonstrate how well it performs in the context of jet classification in high energy physics, where classifier scores are desired to be decorrelated from the mass of a jet. The decorrelation achieved in binary classification approaches the levels achieved by the state-of-the-art using conditional normalising flows. When moving to multiclass outputs the optimal transport approach performs significantly better than the state-of-the-art, suggesting substantial gains at decorrelating multidimensional feature spaces.",
      "authors": [
        "Malte Algren",
        "John Andrew Raine and Tobias Golling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-11T11:49:55+00:00",
          "link": "https://arxiv.org/abs/2307.05187v1",
          "size": "8407kb",
          "version": "v1"
        },
        {
          "date": "2023-07-14T07:24:54+00:00",
          "link": "https://arxiv.org/abs/2307.05187v2",
          "size": "7490kb",
          "version": "v2"
        }
      ],
      "title": "Decorrelation using Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.05187",
        "PDF": "https://arxiv.org/pdf/2307.05187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a decorrelation method using optimal transport for feature spaces, without discussing or contributing to LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "Ethics",
        "Fairness",
        "Normalising Flows"
      ],
      "repo_urls": [
        "https://github.com/malteal/ot-decorrelation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.11790",
      "abstract": "Shape reconstruction from imaging volumes is a recurring need in medical image analysis. Common workflows start with a segmentation step, followed by careful post-processing and,finally, ad hoc meshing algorithms. As this sequence can be timeconsuming, neural networks are trained to reconstruct shapes through template deformation. These networks deliver state-ofthe-art results without manual intervention, but, so far, they have primarily been evaluated on anatomical shapes with little topological variety between individuals. In contrast, other works favor learning implicit shape models, which have multiple benefits for meshing and visualization. Our work follows this direction by introducing deep medial voxels, a semi-implicit representation that faithfully approximates the topological skeleton from imaging volumes and eventually leads to shape reconstruction via convolution surfaces. Our reconstruction technique shows potential for both visualization and computer simulations.",
      "authors": [
        "Antonio Pepe",
        "Richard Schussnig",
        "Jianning Li",
        "Christina Gsaxner",
        "Dieter Schmalstieg",
        "Jan Egger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-18T13:47:18+00:00",
          "link": "https://arxiv.org/abs/2403.11790v1",
          "size": "43111kb",
          "version": "v1"
        }
      ],
      "title": "Deep Medial Voxels: Learned Medial Axis Approximations for Anatomical Shape Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11790",
        "HTML": "https://arxiv.org/html/2403.11790",
        "PDF": "https://arxiv.org/pdf/2403.11790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a shape reconstruction technique from medical imaging, focusing on the representation and modeling, not LLM training data processing."
      },
      "tasks": [
        "Medical Image Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.10955",
      "abstract": "Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by incorporating external information into the response generation process. However, how context-faithful LLMs are and what factors influence LLMs' context faithfulness remain largely unexplored. In this study, we investigate the impact of memory strength and evidence presentation on LLMs' receptiveness to external evidence. We quantify the memory strength of LLMs by measuring the divergence in LLMs' responses to different paraphrases of the same question, which is not considered by previous works. We also generate evidence in various styles to examine LLMs' behavior. Our results show that for questions with high memory strength, LLMs are more likely to rely on internal memory. Furthermore, presenting paraphrased evidence significantly increases LLMs' receptiveness compared to simple repetition or adding details. These findings provide key insights for improving retrieval-augmented generation and context-aware LLMs. Our code is available at https://github.com/liyp0095/ContextFaithful.",
      "authors": [
        "Yuepei Li",
        "Kang Zhou",
        "Qiao Qiao",
        "Bach Nguyen",
        "Qing Wang",
        "Qi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-17T07:44:06+00:00",
          "link": "https://arxiv.org/abs/2409.10955v1",
          "size": "2110kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:59:24+00:00",
          "link": "https://arxiv.org/abs/2409.10955v2",
          "size": "1624kb",
          "version": "v2"
        }
      ],
      "title": "Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10955",
        "HTML": "https://arxiv.org/html/2409.10955v2",
        "PDF": "https://arxiv.org/pdf/2409.10955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines context faithfulness in LLMs, with some discussion of evidence generation styles, but lacks a focus on training data processing or dataset creation."
      },
      "tasks": [
        "Natural Questions",
        "RAG",
        "Response Generation",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04931",
      "abstract": "Trustworthy depression prediction based on deep learning, incorporating both predictive reliability and algorithmic fairness across diverse demographic groups, is crucial for clinical application. Recently, achieving reliable depression predictions through uncertainty quantification has attracted increasing attention. However, few studies have focused on the fairness of uncertainty quantification (UQ) in depression prediction. In this work, we investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage (EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for depression prediction. FUQ pursues reliable and fair depression predictions through group-based analysis. Specifically, we first group all the participants by different sensitive attributes and leverage conformal prediction to quantify uncertainty within each demographic group, which provides a theoretically guaranteed and valid way to quantify uncertainty for depression prediction and facilitates the investigation of fairness across different demographic groups. Furthermore, we propose a fairness-aware optimization strategy that formulates fairness as a constrained optimization problem under EOC constraints. This enables the model to preserve predictive reliability while adapting to the heterogeneous uncertainty levels across demographic groups, thereby achieving optimal fairness. Through extensive evaluations on several visual and audio depression datasets, our approach demonstrates its effectiveness.",
      "authors": [
        "Yonghong Li and Xiuzhuang Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T04:09:36+00:00",
          "link": "https://arxiv.org/abs/2505.04931v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:00:00+00:00",
          "link": "https://arxiv.org/abs/2505.04931v2",
          "size": "519kb",
          "version": "v2"
        }
      ],
      "title": "Fair Uncertainty Quantification for Depression Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04931",
        "HTML": "https://arxiv.org/html/2505.04931v2",
        "PDF": "https://arxiv.org/pdf/2505.04931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on uncertainty quantification and fairness in depression prediction models rather than LLM training data processing."
      },
      "tasks": [
        "Conformal Prediction",
        "Fairness",
        "Prediction",
        "Uncertainty Quantification",
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07438",
      "abstract": "Learned cardinality estimators show promise in query cardinality prediction, yet they universally exhibit fragility to training data drifts, posing risks for real-world deployment. This work is the first to theoretical investigate how minimal data-level drifts can maximally degrade the accuracy of learned estimators. We propose data-centric algorithmic complexity attacks against learned estimators in a black-box setting, proving that finding the optimal attack strategy is NP-Hard. To address this, we design a polynomial-time approximation algorithm with a $(1-\\kappa)$ approximation ratio. Extensive experiments demonstrate our attack's effectiveness: on STATS-CEB and IMDB-JOB benchmarks, modifying just 0.8\\% of training tuples increases the 90th percentile Qerror by three orders of magnitude and raises end-to-end processing time by up to 20$\\times$. Our work not only reveals critical vulnerabilities in deployed learned estimators but also provides the first unified worst-case theoretical analysis of their fragility under data updates. Additionally, we identify two countermeasures to mitigate such black-box attacks, offering insights for developing robust learned database optimizers.",
      "authors": [
        "Yingze Li",
        "Xianglong Liu",
        "Dong Wang",
        "Zixuan Wang",
        "Hongzhi Wang",
        "Kaixing Zhang",
        "Yiming Guan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:29:04+00:00",
          "link": "https://arxiv.org/abs/2507.07438v1",
          "size": "1389kb",
          "version": "v1"
        }
      ],
      "title": "Algorithmic Complexity Attacks on All Learned Cardinality Estimators: A Data-centric Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07438",
        "HTML": "https://arxiv.org/html/2507.07438v1",
        "PDF": "https://arxiv.org/pdf/2507.07438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on examining the fragility of learned cardinality estimators with respect to training data shifts and proposes data-centric attacks and countermeasures, highlighting the importance of data quality in training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07854",
      "abstract": "Small and Medium-sized Enterprises (SMEs) are vital to the modern economy, yet their credit risk analysis often struggles with scarce data, especially for online lenders lacking direct credit records. This paper introduces a Graph Neural Network (GNN)-based framework, leveraging SME interactions from transaction and social data to map spatial dependencies and predict loan default risks. Tests on real-world datasets from Discover and Ant Credit (23.4M nodes for supply chain analysis, 8.6M for default prediction) show the GNN surpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 for supply chain mining and default prediction, respectively. It also helps regulators model supply chain disruption impacts on banks, accurately forecasting loan defaults from material shortages, and offers Federal Reserve stress testers key data for CCAR risk buffers. This approach provides a scalable, effective tool for assessing SME credit risk.",
      "authors": [
        "Zizhou Zhang",
        "Qinyan Shen",
        "Zhuohuan Hu",
        "Qianying Liu",
        "Huijie Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:33:53+00:00",
          "link": "https://arxiv.org/abs/2507.07854v1",
          "size": "1242kb",
          "version": "v1"
        }
      ],
      "title": "Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07854",
        "PDF": "https://arxiv.org/pdf/2507.07854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on credit risk analysis for SMEs using graph neural networks, with an emphasis on financial transaction and social data, not on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07872",
      "abstract": "The safety validation of automatic emergency braking system (AEBS) requires accurately distinguishing between false positive (FP) and true positive (TP) system activations. While simulations allow straightforward differentiation by comparing scenarios with and without interventions, analyzing activations from open-loop resimulations - such as those from field operational testing (FOT) - is more complex. This complexity arises from scenario parameter uncertainty and the influence of driver interventions in the recorded data. Human labeling is frequently used to address these challenges, relying on subjective assessments of intervention necessity or situational criticality, potentially introducing biases and limitations. This work proposes a rule-based classification approach leveraging the Prediction Divergence Principle (PDP) to address those issues. Applied to a simplified AEBS, the proposed method reveals key strengths, limitations, and system requirements for effective implementation. The findings suggest that combining this approach with human labeling may enhance the transparency and consistency of classification, thereby improving the overall validation process. While the rule set for classification derived in this work adopts a conservative approach, the paper outlines future directions for refinement and broader applicability. Finally, this work highlights the potential of such methods to complement existing practices, paving the way for more reliable and reproducible AEBS validation frameworks.",
      "authors": [
        "Daniel Betschinske",
        "Steven Peters"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.07872v1",
          "size": "921kb",
          "version": "v1"
        }
      ],
      "title": "Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07872",
        "HTML": "https://arxiv.org/html/2507.07872v1",
        "PDF": "https://arxiv.org/pdf/2507.07872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is about improving validation for automatic emergency braking systems using rule-based classification, without discussing any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07484",
      "abstract": "Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to statements made without regard to their truth value. While previous work has explored large language model (LLM) hallucination and sycophancy, we propose machine bullshit as an overarching conceptual framework that can allow researchers to characterize the broader phenomenon of emergent loss of truthfulness in LLMs and shed light on its underlying mechanisms. We introduce the Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and propose a complementary taxonomy analyzing four qualitative forms of bullshit: empty rhetoric, paltering, weasel words, and unverified claims. We conduct empirical evaluations on the Marketplace dataset, the Political Neutrality dataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI assistants) explicitly designed to evaluate machine bullshit. Our results demonstrate that model fine-tuning with reinforcement learning from human feedback (RLHF) significantly exacerbates bullshit and inference-time chain-of-thought (CoT) prompting notably amplify specific bullshit forms, particularly empty rhetoric and paltering. We also observe prevalent machine bullshit in political contexts, with weasel words as the dominant strategy. Our findings highlight systematic challenges in AI alignment and provide new insights toward more truthful LLM behavior.",
      "authors": [
        "Kaiqu Liang",
        "Haimin Hu",
        "Xuandong Zhao",
        "Dawn Song",
        "Thomas L. Griffiths",
        "Jaime Fern\\'andez Fisac"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:11:57+00:00",
          "link": "https://arxiv.org/abs/2507.07484v1",
          "size": "397kb",
          "version": "v1"
        }
      ],
      "title": "Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07484",
        "PDF": "https://arxiv.org/pdf/2507.07484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for evaluating truthfulness in LLM outputs, focusing on 'machine bullshit' in inference and model behavior rather than any direct processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07640",
      "abstract": "Phonetic Cloaking Replacement (PCR), defined as the deliberate use of homophonic or near-homophonic variants to hide toxic intent, has become a major obstacle to Chinese content moderation. While this problem is well-recognized, existing evaluations predominantly rely on rule-based, synthetic perturbations that ignore the creativity of real users. We organize PCR into a four-way surface-form taxonomy and compile \\ours, a dataset of 500 naturally occurring, phonetically cloaked offensive posts gathered from the RedNote platform. Benchmarking state-of-the-art LLMs on this dataset exposes a serious weakness: the best model reaches only an F1-score of 0.672, and zero-shot chain-of-thought prompting pushes performance even lower. Guided by error analysis, we revisit a Pinyin-based prompting strategy that earlier studies judged ineffective and show that it recovers much of the lost accuracy. This study offers the first comprehensive taxonomy of Chinese PCR, a realistic benchmark that reveals current detectors' limits, and a lightweight mitigation technique that advances research on robust toxicity detection.",
      "authors": [
        "Haotan Guo",
        "Jianfei He",
        "Jiayuan Ma",
        "Hongbin Na",
        "Zimu Wang",
        "Haiyang Zhang",
        "Qi Chen",
        "Wei Wang",
        "Zijing Shi",
        "Tao Shen",
        "Ling Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:09:26+00:00",
          "link": "https://arxiv.org/abs/2507.07640v1",
          "size": "326kb",
          "version": "v1"
        }
      ],
      "title": "Lost in Pronunciation: Detecting Chinese Offensive Language Disguised by Phonetic Cloaking Replacement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07640",
        "HTML": "https://arxiv.org/html/2507.07640v1",
        "PDF": "https://arxiv.org/pdf/2507.07640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents a clear contribution to dataset creation, compiling naturally occurring offensive posts with detailed data processing methodology to expose LLM limitations in detecting disguised language."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.13318",
      "abstract": "Successful human-robot teaming will require robots to adapt autonomously to a human teammate's internal state, where a critical element of such adaptation is the ability to estimate the human's workload in unknown situations. Existing workload models use machine learning to model the relationship between physiological signals and workload. These methods often struggle to generalize to unknown tasks, as the relative importance of various physiological signals change significantly between tasks. Many of these changes constitute a meaningful shift in the data's distribution, which violates a core assumption made by the underlying machine learning approach. A survey of machine learning techniques designed to overcome these challenges is presented, where common techniques are evaluated using three criteria: portability, model complexity, and adaptability. These criteria are used to analyze each technique's applicability to estimating workload during unknown tasks in dynamic environments and guide future empirical experimentation.",
      "authors": [
        "Josh Bhagat Smith",
        "and Julie A. Adams"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-20T05:46:56+00:00",
          "link": "https://arxiv.org/abs/2403.13318v1",
          "size": "13555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:36:30+00:00",
          "link": "https://arxiv.org/abs/2403.13318v2",
          "size": "1444kb",
          "version": "v2"
        }
      ],
      "title": "A Survey of Machine Learning for Estimating Workload: Considering Unknown Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13318",
        "HTML": "https://arxiv.org/html/2403.13318v2",
        "PDF": "https://arxiv.org/pdf/2403.13318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses machine learning techniques for estimating human workload and adapting robot behavior, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12896",
      "abstract": "In LLM evaluations, reasoning is often distinguished from recall/memorization by performing numerical variations to math-oriented questions. Here we introduce a general variation method for multiple-choice questions that completely dissociates the correct answer from previously seen tokens or concepts, requiring LLMs to understand and reason (rather than memorizing) in order to answer correctly. Using this method, we evaluate state-of-the-art proprietary and open-source LLMs on two datasets available in English and Spanish: the public MMLU benchmark and the private UNED-Access 2024 dataset. Results show that all models experience remarkable accuracy drops under our proposed variation, with an average loss of 57% on MMLU and 50% on UNED-Access 2024, ranging from 10% to 93% across models. Notably, the most accurate model in our experimentation (OpenAI-o3-mini) is not the most robust (DeepSeek-R1-70B), suggesting that the best models in standard evaluations may not be the ones with better reasoning capabilities. Also, we see larger accuracy drops in public (vs private) datasets and questions posed in their original language (vs a manual translation), which are signs of contamination and also point to a relevant role of recall/memorization in current LLMs' answers.",
      "authors": [
        "Eva S\\'anchez Salido",
        "Julio Gonzalo",
        "Guillermo Marco"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T14:32:44+00:00",
          "link": "https://arxiv.org/abs/2502.12896v1",
          "size": "1915kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T14:15:12+00:00",
          "link": "https://arxiv.org/abs/2502.12896v2",
          "size": "1915kb",
          "version": "v2"
        },
        {
          "date": "2025-05-12T10:30:51+00:00",
          "link": "https://arxiv.org/abs/2502.12896v3",
          "size": "1915kb",
          "version": "v3"
        },
        {
          "date": "2025-05-23T11:27:49+00:00",
          "link": "https://arxiv.org/abs/2502.12896v4",
          "size": "1916kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T15:12:15+00:00",
          "link": "https://arxiv.org/abs/2502.12896v5",
          "size": "1423kb",
          "version": "v5"
        }
      ],
      "title": "None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12896",
        "HTML": "https://arxiv.org/html/2502.12896v5",
        "PDF": "https://arxiv.org/pdf/2502.12896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating LLMs' reasoning capabilities by dissociating answers from memorized tokens, not on processing or creating training data."
      },
      "tasks": [
        "Math",
        "Memorization",
        "MMLU",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07297",
      "abstract": "Recent advances in large vision-language models have led to impressive performance in visual question answering and multimodal reasoning. However, it remains unclear whether these models genuinely perform grounded visual reasoning or rely on superficial patterns and dataset biases. In this work, we introduce MagiC, a comprehensive benchmark designed to evaluate grounded multimodal cognition, assessing not only answer accuracy but also the quality of step-by-step reasoning and its alignment with relevant visual evidence. Our benchmark includes approximately 5,500 weakly supervised QA examples generated from strong model outputs and 900 human-curated examples with fine-grained annotations, including answers, rationales, and bounding box groundings. We evaluate 15 vision-language models ranging from 7B to 70B parameters across four dimensions: final answer correctness, reasoning validity, grounding fidelity, and self-correction ability. MagiC further includes diagnostic settings to probe model robustness under adversarial visual cues and assess their capacity for introspective error correction. We introduce new metrics such as MagiScore and StepSense, and provide comprehensive analyses that reveal key limitations and opportunities in current approaches to grounded visual reasoning.",
      "authors": [
        "Chengfei Wu",
        "Ronald Seoh",
        "Bingxuan Li",
        "Liqiang Zhang",
        "Fengrong Han",
        "Dan Goldwasser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:44:12+00:00",
          "link": "https://arxiv.org/abs/2507.07297v1",
          "size": "21941kb",
          "version": "v1"
        }
      ],
      "title": "MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07297",
        "HTML": "https://arxiv.org/html/2507.07297v1",
        "PDF": "https://arxiv.org/pdf/2507.07297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a benchmark for evaluating multimodal cognition but primarily focuses on model evaluation in visual reasoning tasks. It includes dataset generation but does not focus on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07596",
      "abstract": "The tropical semiring is a set of numbers $\\mathbb{R}\\cup\\{-\\infty\\}$ with addition $a\\oplus b:=\\max(a,b)$ and multiplication $a\\otimes b:=a+b$. As well as in conventional algebra, linear programming problem in the tropical semiring has been developed. In this study, we introduce a new type of tropical optimization problem, namely, tropical linearly factorized programming problem. This problem involves minimizing the objective function given by the product of tropical linear forms $c_{k,1}\\otimes x_1\\oplus \\cdots\\oplus c_{k,n}\\otimes x_n$ divided by a tropical monomial, subject to tropical linear inequality constraints. The objective function is convex in the conventional sense but not in the tropical sense, while the feasible set is convex in the tropical sense but not in the conventional sense.\n  Our algorithm for tropical linearly factorized programming is based on the descent method and exploits tangent digraphs. First, we demonstrate that the feasible descent direction at the current solution can be obtained by solving the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph. Although exponentially many such digraphs may exist in general, a more efficient algorithm is devised in cases where the problem is non-degenerate. Focusing on the fact that tangent digraphs become spanning trees in non-degenerate cases, we present a simplex-like algorithm that updates the tree structure iteratively. We show that each iteration can be executed in $O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero'' coefficients in the linear constraints and objective function, respectively. For integer instances, our algorithm finds a local optimum in $O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision variables and constraints, respectively, $M$ is the maximum absolute value of coefficients and $D$ is the degree of the objective function.",
      "authors": [
        "Yuki Nishida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:54:59+00:00",
          "link": "https://arxiv.org/abs/2507.07596v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Combinatorial Algorithm for Tropical Linearly Factorized Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07596",
        "HTML": "https://arxiv.org/html/2507.07596v1",
        "PDF": "https://arxiv.org/pdf/2507.07596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a combinatorial algorithm for tropical programming, which is unrelated to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07695",
      "abstract": "Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study.",
      "authors": [
        "Hruday Markondapatnaikuni",
        "Basem Suleiman",
        "Abdelkarim Erradi",
        "Shijing Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:19:03+00:00",
          "link": "https://arxiv.org/abs/2507.07695v1",
          "size": "2099kb",
          "version": "v1"
        }
      ],
      "title": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07695",
        "HTML": "https://arxiv.org/html/2507.07695v1",
        "PDF": "https://arxiv.org/pdf/2507.07695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The KeyKnowledgeRAG (K2RAG) framework involves preprocessing training data through summarization, significantly reducing training time and implies improved retrieval quality, focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07817",
      "abstract": "Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at https://github.com/kowndinya-renduchintala/WIT.",
      "authors": [
        "Anwoy Chatterjee",
        "H S V N S Kowndinya Renduchintala",
        "Sumit Bhatia",
        "Tanmoy Chakraborty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:46:33+00:00",
          "link": "https://arxiv.org/abs/2507.07817v1",
          "size": "752kb",
          "version": "v1"
        }
      ],
      "title": "On the Effect of Instruction Tuning Loss on Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07817",
        "PDF": "https://arxiv.org/pdf/2507.07817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses optimizing instruction tuning loss functions, which relates to post-training processes, but does not focus primarily on data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07870",
      "abstract": "Despite the impressive capabilities of Large Language Models (LLMs), existing Conversational Health Agents (CHAs) remain static and brittle, incapable of adaptive multi-turn reasoning, symptom clarification, or transparent decision-making. This hinders their real-world applicability in clinical diagnosis, where iterative and structured dialogue is essential. We propose DocCHA, a confidence-aware, modular framework that emulates clinical reasoning by decomposing the diagnostic process into three stages: (1) symptom elicitation, (2) history acquisition, and (3) causal graph construction. Each module uses interpretable confidence scores to guide adaptive questioning, prioritize informative clarifications, and refine weak reasoning links.\n  Evaluated on two real-world Chinese consultation datasets (IMCS21, DX), DocCHA consistently outperforms strong prompting-based LLM baselines (GPT-3.5, GPT-4o, LLaMA-3), achieving up to 5.18 percent higher diagnostic accuracy and over 30 percent improvement in symptom recall, with only modest increase in dialogue turns. These results demonstrate the effectiveness of DocCHA in enabling structured, transparent, and efficient diagnostic conversations -- paving the way for trustworthy LLM-powered clinical assistants in multilingual and resource-constrained settings.",
      "authors": [
        "Xinyi Liu",
        "Dachun Sun",
        "Yi R. Fung",
        "Dilek Hakkani-T\\\"ur",
        "Tarek Abdelzaher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:52:04+00:00",
          "link": "https://arxiv.org/abs/2507.07870v1",
          "size": "1837kb",
          "version": "v1"
        }
      ],
      "title": "DocCHA: Towards LLM-Augmented Interactive Online diagnosis System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07870",
        "HTML": "https://arxiv.org/html/2507.07870v1",
        "PDF": "https://arxiv.org/pdf/2507.07870"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes an LLM-augmented system for medical diagnosis and evaluates it using existing datasets, but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07919",
      "abstract": "Explanations play a variety of roles in various recommender systems, from a legally mandated afterthought, through an integral element of user experience, to a key to persuasiveness. A natural and useful form of an explanation is the Counterfactual Explanation (CE). We present a method for generating highly plausible CEs in recommender systems and evaluate it both numerically and with a user study.",
      "authors": [
        "Jakub \\v{C}ern\\'y",
        "Ji\\v{r}\\'i N\\v{e}me\\v{c}ek",
        "Ivan Dovica",
        "Jakub Mare\\v{c}ek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:59:51+00:00",
          "link": "https://arxiv.org/abs/2507.07919v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Plausible Counterfactual Explanations of Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07919",
        "HTML": "https://arxiv.org/html/2507.07919v1",
        "PDF": "https://arxiv.org/pdf/2507.07919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for generating counterfactual explanations in recommender systems, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21058",
      "abstract": "Let $m,n,d > 1$ be integers such that $n=md$. In this paper, we present an efficient change of level algorithm that takes as input $(B, \\mathscr{M}, \\Theta_\\mathscr{M})$ a marked abelian variety of level $m$ over the base field $k$ of odd characteristic and returns $(B, \\mathscr{M}^d, \\Theta_{\\mathscr{M}^d})$ a marked abelian variety of level $n$ at the expense of $O(m^g d^{2g})$ operations in $k$. A similar algorithm allows to compute $d$-isogenies: from $(B, \\mathscr{M}, \\Theta_\\mathscr{M})$ a marked abelian variety of level $m$, $K\\subset B[d]$ isotropic for the Weil pairing isomorphic to $(\\mathbb{Z}/d\\mathbb{Z})^g$ defined over $k$, the isogeny algorithm returns $(A, \\mathscr{L}, \\Theta_\\mathscr{L})$ of level $m$ such that $A=B/K$ with $O(m^g d^g)$ operations in $k$. Our algorithms extend previous known results in the case that $d \\wedge m=1$ and $d$ odd. In this paper, we lift theses restrictions. We use the same general approach as in the literature in conjunction with the notion of symmetric compatible that we introduce, study and link to previous results of Mumford. For practical computation, most of the time $m$ is $2$ or $4$ so that our algorithms allows in particular to compute $2^e$-isogenies which are important for the theory of theta functions but also for computational applications such as isogeny based cryptography.",
      "authors": [
        "Antoine Dequay (IRMAR)",
        "David Lubicz (DGA.MI",
        "IRMAR)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T08:02:59+00:00",
          "link": "https://arxiv.org/abs/2504.21058v1",
          "size": "79kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:06:57+00:00",
          "link": "https://arxiv.org/abs/2504.21058v2",
          "size": "87kb",
          "version": "v2"
        }
      ],
      "title": "Computing change of level and isogenies between abelian varieties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21058",
        "PDF": "https://arxiv.org/pdf/2504.21058"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on algorithms for computing change of level and isogenies between abelian varieties. It does not discuss large language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20310",
      "abstract": "In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers on Machine Learning algorithms during inference time.\n  We formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker. The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading (too much) the performance of the algorithm on inputs from the training distribution.\n  We first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs for each input. We show a separation between DbD and DbM by exhibiting two generative learning tasks for which it is possible to defend by mitigation but it is provably impossible to defend by detection. The mitigation phase uses significantly less computational resources than the initial training algorithm. In the first learning task we consider sample complexity as the resource and in the second the time complexity. The first result holds under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK), and Strongly Unforgeable Signatures exist. The second result assumes the existence of Non-Parallelizing Languages with Average-Case Hardness (NPL) and Incrementally-Verifiable Computation (IVC) and IB-FHE.",
      "authors": [
        "Greg Gluch",
        "Shafi Goldwasser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T23:46:45+00:00",
          "link": "https://arxiv.org/abs/2504.20310v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:40:27+00:00",
          "link": "https://arxiv.org/abs/2504.20310v2",
          "size": "95kb",
          "version": "v2"
        }
      ],
      "title": "A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20310",
        "HTML": "https://arxiv.org/html/2504.20310v2",
        "PDF": "https://arxiv.org/pdf/2504.20310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies cryptographic defenses against adversarial inputs in machine learning, focusing on inference time, and not on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07318",
      "abstract": "Spatial audio is an integral part of immersive entertainment, such as VR/AR, and has seen increasing popularity in cinema and music as well. The most common format of spatial audio is described as first-order Ambisonics (FOA). We seek to extend recent advancements in FOA generative AI models to enable the generation of 3D scenes with dynamic sound sources. Our proposed end-to-end model, SonicMotion, comes in two variations which vary in their user input and level of precision in sound source localization. In addition to our model, we also present a new dataset of simulated spatial audio-caption pairs. Evaluation of our models demonstrate that they are capable of matching the semantic alignment and audio quality of state of the art models while capturing the desired spatial attributes.",
      "authors": [
        "Christian Templin and Yanda Zhu and Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:31:06+00:00",
          "link": "https://arxiv.org/abs/2507.07318v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07318",
        "HTML": "https://arxiv.org/html/2507.07318v1",
        "PDF": "https://arxiv.org/pdf/2507.07318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with spatial audio and generative models, introducing a dataset specific to audio-caption pairs, unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07357",
      "abstract": "The rise of Generative AI (GenAI) tools, such as ChatGPT, has transformed how students access and engage with information, raising questions about their impact on learning outcomes and retention. This study investigates how GenAI (ChatGPT), search engines (Google), and e-textbooks influence student performance across tasks of varying cognitive complexity, based on Bloom's Taxonomy. Using a sample of 123 students, we examined performance in three tasks: [1] knowing and understanding, [2] applying, and [3] synthesizing, evaluating, and creating. Results indicate that ChatGPT and Google groups outperformed the control group in immediate assessments for lower-order cognitive tasks, benefiting from quick access to structured information. However, their advantage diminished over time, with retention test scores aligning with those of the e-textbook group. For higher-order cognitive tasks, no significant differences were observed among groups, with the control group demonstrating the highest retention. These findings suggest that while AI-driven tools facilitate immediate performance, they do not inherently reinforce long-term retention unless supported by structured learning strategies. The study highlights the need for balanced technology integration in education, ensuring that AI tools are paired with pedagogical approaches that promote deep cognitive engagement and knowledge retention.",
      "authors": [
        "Mahir Akgun",
        "Sacip Toker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:44:50+00:00",
          "link": "https://arxiv.org/abs/2507.07357v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Short-Term Gains, Long-Term Gaps: The Impact of GenAI and Search Technologies on Retention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07357",
        "HTML": "https://arxiv.org/html/2507.07357v1",
        "PDF": "https://arxiv.org/pdf/2507.07357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the impact of GenAI tools on educational retention and does not explore any methodologies for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07741",
      "abstract": "Motivated by a growing research interest into automatic speech recognition (ASR), and the growing body of work for languages in which code-switching (CS) often occurs, we present a systematic literature review of code-switching in end-to-end ASR models. We collect and manually annotate papers published in peer reviewed venues. We document the languages considered, datasets, metrics, model choices, and performance, and present a discussion of challenges in end-to-end ASR for code-switching. Our analysis thus provides insights on current research efforts and available resources as well as opportunities and gaps to guide future research.",
      "authors": [
        "Maha Tufail Agro",
        "Atharva Kulkarni",
        "Karima Kadaoui",
        "Zeerak Talat",
        "Hanan Aldarmaki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:21:12+00:00",
          "link": "https://arxiv.org/abs/2507.07741v1",
          "size": "173kb",
          "version": "v1"
        }
      ],
      "title": "Code-Switching in End-to-End Automatic Speech Recognition: A Systematic Literature Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07741",
        "HTML": "https://arxiv.org/html/2507.07741v1",
        "PDF": "https://arxiv.org/pdf/2507.07741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The systematic review focuses on end-to-end ASR models and code-switching, without addressing LLM training data processing or engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07979",
      "abstract": "Dataspaces are designed to support sovereign, trusted and decentralized data exchange between participants forming an ecosystem. They are standardized by initiatives such as the International Data Spaces Association or Gaia-X and have gained adoption in several domains such as mobility, manufacturing, tourism or culture. In dataspaces, participants use connectors to communicate peer-to-peer. The Eclipse Dataspace Components (EDC) Connector is a broadly adopted, open-source implementation that adheres to the standards and is supported by a large community. As dataspaces in general, it focuses on the exchange of data assets with associated usage policies and does not support services. In practice, however, there is demand for dataspace-based services and conceptual arguments support their inclusion in dataspaces. In this paper, we propose an abstraction layer for providing generic services within dataspaces. Adopters can use this layer to easily develop own services, seamlessly integrated with the existing dataspace technology. Besides, we present an initial implementation of this service architecture for the EDC Connector and demonstrate its practical applicability.",
      "authors": [
        "Benedikt T. Arnold",
        "Christoph Lange",
        "Christina Gillmann",
        "Stefan Decker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:54:40+00:00",
          "link": "https://arxiv.org/abs/2507.07979v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "A Service Architecture for Dataspaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07979",
        "HTML": "https://arxiv.org/html/2507.07979v1",
        "PDF": "https://arxiv.org/pdf/2507.07979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a service architecture for dataspaces, which involves data exchange ecosystems, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.06555",
      "abstract": "Brain-Computer Interfaces (BCI) have allowed for direct communication from the brain to external applications for the automatic detection of cognitive processes such as error recognition. Error-related potentials (ErrPs) are a particular brain signal elicited when one commits or observes an erroneous event. However, due to the noisy properties of the brain and recording devices, ErrPs vary from instance to instance as they are combined with an assortment of other brain signals, biological noise, and external noise, making the classification of ErrPs a non-trivial problem. Recent works have revealed particular cognitive processes such as awareness, embodiment, and predictability that contribute to ErrP variations. In this paper, we explore the performance of classifier transferability when trained on different ErrP variation datasets generated by varying the levels of awareness and embodiment for a given task. In particular, we look at transference between observational and interactive ErrP categories when elicited by similar and differing tasks. Our empirical results provide an exploratory analysis into the ErrP transferability problem from a data perspective.",
      "authors": [
        "Benjamin Poole and Minwoo Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-16T18:39:18+00:00",
          "link": "https://arxiv.org/abs/2301.06555v1",
          "size": "911kb",
          "version": "v1"
        }
      ],
      "title": "Error-related Potential Variability: Exploring the Effects on Classification and Transferability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.06555",
        "PDF": "https://arxiv.org/pdf/2301.06555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on brain signal classification and ErrP transferability, with no mention of LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2210.00327",
      "abstract": "In this paper, we study the problem of coverage of an environment with an energy-constrained robot in the presence of multiple charging stations. As the robot's on-board power supply is limited, it might not have enough energy to cover all the points in the environment with a single charge. Instead, it will need to stop at one or more charging stations to recharge its battery intermittently. The robot cannot violate the energy constraint, i.e., visit a location with negative available energy. To solve this problem, we propose a deep Q-learning framework that produces a policy to maximize the coverage and minimize the budget violations. Our proposed framework also leverages the memory of a recurrent neural network (RNN) to better suit this multi-objective optimization problem. We have tested the presented framework within a 16 x 16 grid environment having charging stations and various obstacle configurations. Results show that our proposed method finds feasible solutions and outperforms a comparable existing technique.",
      "authors": [
        "Aaron Zellner",
        "Ayan Dutta",
        "Iliya Kulbaka",
        "Gokarna Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-01T17:34:10+00:00",
          "link": "https://arxiv.org/abs/2210.00327v1",
          "size": "10887kb",
          "version": "v1"
        }
      ],
      "title": "Deep Recurrent Q-learning for Energy-constrained Coverage with a Mobile Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.00327",
        "PDF": "https://arxiv.org/pdf/2210.00327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a robotic coverage problem using Q-learning, which does not pertain to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Q-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06526",
      "abstract": "Text-to-image diffusion models (T2I DMs), represented by Stable Diffusion, which generate highly realistic images based on textual input, have been widely used. However, their misuse poses serious security risks. While existing concept unlearning methods aim to mitigate these risks, they struggle to balance unlearning effectiveness with generative retainability.To overcome this limitation, we innovatively propose the Key Step Concept Unlearning (KSCU) method, which ingeniously capitalizes on the unique stepwise sampling characteristic inherent in diffusion models during the image generation process. Unlike conventional approaches that treat all denoising steps equally, KSCU strategically focuses on pivotal steps with the most influence over the final outcome by dividing key steps for different concept unlearning tasks and fine-tuning the model only at those steps. This targeted approach reduces the number of parameter updates needed for effective unlearning, while maximizing the retention of the model's generative capabilities.Through extensive benchmark experiments, we demonstrate that KSCU effectively prevents T2I DMs from generating undesirable images while better retaining the model's generative capabilities. Our code will be released.",
      "authors": [
        "Chaoshuo Zhang and Chenhao Lin and Zhengyu Zhao and Le Yang and Qian Wang and Chao Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:55:58+00:00",
          "link": "https://arxiv.org/abs/2507.06526v1",
          "size": "20797kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.06526v2",
          "size": "20797kb",
          "version": "v2"
        }
      ],
      "title": "Concept Unlearning by Modeling Key Steps of Diffusion Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06526",
        "HTML": "https://arxiv.org/html/2507.06526v2",
        "PDF": "https://arxiv.org/pdf/2507.06526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on concept unlearning and generative retainability in text-to-image diffusion models rather than on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07723",
      "abstract": "Direct Preference Optimization (DPO) has emerged as a popular and efficient alternative to reward modeling and reinforcement learning for aligning language models with human preferences. Despite its empirical success, the theoretical properties and intrinsic limitations of DPO remain underexplored. In this work, we first present a comprehensive analysis of DPO's dynamics from a probability evolution perspective. Our analysis reveals that DPO is highly sensitive to initialization. It also tends to misallocate probability mass, which can inadvertently shift probability toward irrelevant or undesired responses. This misallocation may unintentionally reinforce model bias, thereby compromising both the stability of model alignment and the consistency with intended preferences. Motivated by these theoretical findings, we propose a theoretically grounded bilevel optimization framework that tightly integrate supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference optimization. Our approach introduces a principled regularization scheme to explicitly encourage absolute probability improvement for preferred outputs, while maintaining stable optimization dynamics. Experiments on challenging reasoning and summarization benchmarks elucidate that our method consistently improves reasoning accuracy and better aligns output distributions with intended preferences, outperforming standard DPO. Stable preference optimization provides new insights into the design of preference-based alignment objectives and opens up new avenues towards more reliable and interpretable language model alignment.",
      "authors": [
        "Chengtao Jian",
        "Kai Yang",
        "Ye Ouyang",
        "Xiaozhou Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.07723v1",
          "size": "414kb",
          "version": "v1"
        }
      ],
      "title": "Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07723",
        "HTML": "https://arxiv.org/html/2507.07723v1",
        "PDF": "https://arxiv.org/pdf/2507.07723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a bilevel optimization framework for preference optimization in LLMs, which includes supervised fine-tuning but does not focus primarily on processing the training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07387",
      "abstract": "We introduce Digital Salon, a comprehensive hair authoring system that supports real-time 3D hair generation, simulation, and rendering. Unlike existing methods that focus on isolated parts of 3D hair modeling and involve a heavy computation process or network training, Digital Salon offers a holistic and interactive system that lowers the technical barriers of 3D hair modeling through natural language-based interaction. The system guides users through four key stages: text-guided hair retrieval, real-time hair simulation, interactive hair refinement, and hair-conditioned image generation. This cohesive workflow makes advanced hair design accessible to users of varying skill levels and dramatically streamlines the creative process in digital media with an intuitive, versatile, and efficient solution for hair modeling. User studies show that our system can outperform traditional hair modeling workflows for rapid prototyping. Furthermore, we provide insights into the benefits of our system with future potential of deploying our system in real salon environments. More details can be found on our project page: https://digital-salon.github.io/.",
      "authors": [
        "Chengan He",
        "Jorge Alejandro Amador Herrera",
        "Zhixin Shu",
        "Xin Sun",
        "Yao Feng",
        "S\\\"oren Pirk",
        "Dominik L. Michels",
        "Meng Zhang",
        "Tuanfeng Y. Wang",
        "Julie Dorsey",
        "Holly Rushmeier",
        "Yi Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:58:51+00:00",
          "link": "https://arxiv.org/abs/2507.07387v1",
          "size": "21483kb",
          "version": "v1"
        }
      ],
      "title": "Digital Salon: An AI and Physics-Driven Tool for 3D Hair Grooming and Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07387",
        "HTML": "https://arxiv.org/html/2507.07387v1",
        "PDF": "https://arxiv.org/pdf/2507.07387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a system for 3D hair grooming and simulation, focusing on natural language interaction for modeling. It does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.17468",
      "abstract": "Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models, but doing so requires approximating the gradient of the measurement-conditional score function in the diffusion reverse process. We show that the approximations produced by existing methods are relatively poor, especially early in the reverse process, and so we propose a new approach that iteratively reestimates and \"renoises\" the estimate several times per diffusion step. This iterative approach, which we call Fast Iterative REnoising (FIRE), injects colored noise that is shaped to ensure that the pre-trained diffusion model always sees white noise, in accordance with how it was trained. We then embed FIRE into the DDIM reverse process and show that the resulting \"DDfire\" offers state-of-the-art accuracy and runtime on several linear inverse problems, as well as phase retrieval. Our implementation is at https://github.com/matt-bendel/DDfire",
      "authors": [
        "Matt C. Bendel",
        "Saurav K. Shastri",
        "Rizwan Ahmad",
        "and Philip Schniter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T08:20:05+00:00",
          "link": "https://arxiv.org/abs/2501.17468v1",
          "size": "33218kb",
          "version": "v1"
        },
        {
          "date": "2025-04-13T14:24:44+00:00",
          "link": "https://arxiv.org/abs/2501.17468v2",
          "size": "25892kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T17:09:37+00:00",
          "link": "https://arxiv.org/abs/2501.17468v3",
          "size": "27085kb",
          "version": "v3"
        }
      ],
      "title": "Solving Inverse Problems using Diffusion with Iterative Colored Renoising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17468",
        "HTML": "https://arxiv.org/html/2501.17468v3",
        "PDF": "https://arxiv.org/pdf/2501.17468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses solving imaging inverse problems using diffusion models but does not address LLM training data processing or dataset creation."
      },
      "tasks": [
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07527",
      "abstract": "Remote sensing data is commonly used for tasks such as flood mapping, wildfire detection, or land-use studies. For each task, scientists carefully choose appropriate modalities or leverage data from purpose-built instruments. Recent work on remote sensing foundation models pre-trains computer vision models on large amounts of remote sensing data. These large-scale models tend to focus on specific modalities, often optical RGB or multispectral data. For many important applications, this introduces a mismatch between the application modalities and the pre-training data. Moreover, the large size of foundation models makes them expensive and difficult to fine-tune on typically small datasets for each task. We address this mismatch with MAPEX, a remote sensing foundation model based on mixture-of-modality experts. MAPEX is pre-trained on multi-modal remote sensing data with a novel modality-conditioned token routing mechanism that elicits modality-specific experts. To apply the model on a specific task, we propose a modality aware pruning technique, which only retains experts specialized for the task modalities. This yields efficient modality-specific models while simplifying fine-tuning and deployment for the modalities of interest. We experimentally validate MAPEX on diverse remote sensing datasets and show strong performance compared to fully supervised training and state-of-the-art remote sensing foundation models. Code is available at https://github.com/HSG-AIML/MAPEX.",
      "authors": [
        "Joelle Hanna",
        "Linus Scheibenreif and Damian Borth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:19:34+00:00",
          "link": "https://arxiv.org/abs/2507.07527v1",
          "size": "11442kb",
          "version": "v1"
        }
      ],
      "title": "MAPEX: Modality-Aware Pruning of Experts for Remote Sensing Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07527",
        "HTML": "https://arxiv.org/html/2507.07527v1",
        "PDF": "https://arxiv.org/pdf/2507.07527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses pre-training on remote sensing data with a modality-aware approach, it primarily focuses on model architecture and tuning techniques, not LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07320",
      "abstract": "In this paper, a secure and communication-efficient clustered federated learning (CFL) design is proposed. In our model, several base stations (BSs) with heterogeneous task-handling capabilities and multiple users with non-independent and identically distributed (non-IID) data jointly perform CFL training incorporating differential privacy (DP) techniques. Since each BS can process only a subset of the learning tasks and has limited wireless resource blocks (RBs) to allocate to users for federated learning (FL) model parameter transmission, it is necessary to jointly optimize RB allocation and user scheduling for CFL performance optimization. Meanwhile, our considered CFL method requires devices to use their limited data and FL model information to determine their task identities, which may introduce additional communication overhead. We formulate an optimization problem whose goal is to minimize the training loss of all learning tasks while considering device clustering, RB allocation, DP noise, and FL model transmission delay. To solve the problem, we propose a novel dynamic penalty function assisted value decomposed multi-agent reinforcement learning (DPVD-MARL) algorithm that enables distributed BSs to independently determine their connected users, RBs, and DP noise of the connected users but jointly minimize the training loss of all learning tasks across all BSs. Different from the existing MARL methods that assign a large penalty for invalid actions, we propose a novel penalty assignment scheme that assigns penalty depending on the number of devices that cannot meet communication constraints (e.g., delay), which can guide the MARL scheme to quickly find valid actions, thus improving the convergence speed. Simulation results show that the DPVD-MARL can improve the convergence rate by up to 20% and the ultimate accumulated rewards by 15% compared to independent Q-learning.",
      "authors": [
        "Dongyu Wei",
        "Xiaoren Xu",
        "Shiwen Mao",
        "Mingzhe Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.07320v1",
          "size": "943kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Communication and Device Clustering for Clustered Federated Learning with Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07320",
        "PDF": "https://arxiv.org/pdf/2507.07320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses clustered federated learning and communication optimization, but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07388",
      "abstract": "Gaining a deeper understanding of the thickness and variability of internal ice layers in Radar imagery is essential in monitoring the snow accumulation, better evaluating ice dynamics processes, and minimizing uncertainties in climate models. Radar sensors, capable of penetrating ice, capture detailed radargram images of internal ice layers. In this work, we introduce GRIT, graph transformer for ice layer thickness. GRIT integrates an inductive geometric graph learning framework with an attention mechanism, designed to map the relationships between shallow and deeper ice layers. Compared to baseline graph neural networks, GRIT demonstrates consistently lower prediction errors. These results highlight the attention mechanism's effectiveness in capturing temporal changes across ice layers, while the graph transformer combines the strengths of transformers for learning long-range dependencies with graph neural networks for capturing spatial patterns, enabling robust modeling of complex spatiotemporal dynamics.",
      "authors": [
        "Zesheng Liu",
        "Maryam Rahnemoonfar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:59:21+00:00",
          "link": "https://arxiv.org/abs/2507.07388v1",
          "size": "2063kb",
          "version": "v1"
        }
      ],
      "title": "GRIT: Graph Transformer For Internal Ice Layer Thickness Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07388",
        "HTML": "https://arxiv.org/html/2507.07388v1",
        "PDF": "https://arxiv.org/pdf/2507.07388"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about predicting ice layer thickness using a graph transformer. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07467",
      "abstract": "Autonomous flight in GPS denied indoor spaces requires trajectories that keep visual localization error tightly bounded across varied missions. Whereas visual inertial odometry (VIO) accumulates drift over time, scene coordinate regression (SCR) yields drift-free, high accuracy absolute pose estimation. We present a perception-aware framework that couples an evidential learning-based SCR pose estimator with a receding horizon trajectory optimizer. The optimizer steers the onboard camera toward pixels whose uncertainty predicts reliable scene coordinates, while a fixed-lag smoother fuses the low rate SCR stream with high rate IMU data to close the perception control loop in real time. In simulation, our planner reduces translation (rotation) mean error by 54% / 15% (40% / 31%) relative to yaw fixed and forward-looking baselines, respectively. Moreover, hardware in the loop experiment validates the feasibility of our proposed framework.",
      "authors": [
        "Juyeop Han",
        "Lukas Lao Beyer",
        "Guilherme V. Cavalheiro",
        "Sertac Karaman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T06:42:53+00:00",
          "link": "https://arxiv.org/abs/2507.07467v1",
          "size": "18572kb",
          "version": "v1"
        }
      ],
      "title": "SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07467",
        "HTML": "https://arxiv.org/html/2507.07467v1",
        "PDF": "https://arxiv.org/pdf/2507.07467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses autonomous flight and trajectory generation, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07965",
      "abstract": "In most real-world applications of artificial intelligence, the distributions of the data and the goals of the learners tend to change over time. The Probably Approximately Correct (PAC) learning framework, which underpins most machine learning algorithms, fails to account for dynamic data distributions and evolving objectives, often resulting in suboptimal performance. Prospective learning is a recently introduced mathematical framework that overcomes some of these limitations. We build on this framework to present preliminary results that improve the algorithm and numerical results, and extend prospective learning to sequential decision-making scenarios, specifically foraging. Code is available at: https://github.com/neurodata/prolearn2.",
      "authors": [
        "Yuxin Bai",
        "Cecelia Shuai",
        "Ashwin De Silva",
        "Siyu Yu",
        "Pratik Chaudhari",
        "Joshua T. Vogelstein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:45:15+00:00",
          "link": "https://arxiv.org/abs/2507.07965v1",
          "size": "1470kb",
          "version": "v1"
        }
      ],
      "title": "Prospective Learning in Retrospect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07965",
        "HTML": "https://arxiv.org/html/2507.07965v1",
        "PDF": "https://arxiv.org/pdf/2507.07965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces prospective learning for dynamic data distributions and evolving objectives but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.22289",
      "abstract": "In this research paper we examine undergraduate students' use of and perceptions of generative AI (GenAI). Students are early adopters of the technology, utilizing it in atypical ways and forming a range of perceptions and aspirations about it. To understand where and how students are using these tools and how they view them, we present findings from an open-ended survey response study with undergraduate students pursuing information technology degrees. Students were asked to describe 1) their understanding of GenAI; 2) their use of GenAI; 3) their opinions on the benefits, downsides, and ethical issues pertaining to its use in education; and 4) how they envision GenAI could ideally help them with their education. Findings show that students' definitions of GenAI differed substantially and included many misconceptions - some highlight it as a technique, an application, or a tool, while others described it as a type of AI. There was a wide variation in the use of GenAI by students, with two common uses being writing and coding. They identified the ability of GenAI to summarize information and its potential to personalize learning as an advantage. Students identified two primary ethical concerns with using GenAI: plagiarism and dependency, which means that students do not learn independently. They also cautioned that responses from GenAI applications are often untrustworthy and need verification. Overall, they appreciated that they could do things quickly with GenAI but were cautious as using the technology was not necessarily in their best long-term as it interfered with the learning process. In terms of aspirations for GenAI, students expressed both practical advantages and idealistic and improbable visions. They said it could serve as a tutor or coach and allow them to understand the material better. We discuss the implications of the findings for student learning and instruction.",
      "authors": [
        "Aditya Johri",
        "Ashish Hingle",
        "Johannes Schleiss"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T17:41:06+00:00",
          "link": "https://arxiv.org/abs/2410.22289v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "Misconceptions, Pragmatism, and Value Tensions: Evaluating Students' Understanding and Perception of Generative AI for Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.22289",
        "PDF": "https://arxiv.org/pdf/2410.22289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies students' perceptions of generative AI and does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07599",
      "abstract": "This study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related information from emergency department triage notes to support near real-time vaccine safety surveillance. Prompt engineering was used to initially create a labeled dataset, which was then confirmed by human annotators. The performance of prompt-engineered models, fine-tuned models, and a rule-based approach was compared. The fine-tuned Llama 3 billion parameter model outperformed other models in its accuracy of extracting vaccine names. Model quantization enabled efficient deployment in resource-constrained environments. Findings demonstrate the potential of large language models in automating data extraction from emergency department notes, supporting efficient vaccine safety surveillance and early detection of emerging adverse events following immunization issues.",
      "authors": [
        "Sedigh Khademi",
        "Jim Black",
        "Christopher Palmer",
        "Muhammad Javed",
        "Hazel Clothier",
        "Jim Buttery and Gerardo Luis Dimaguila"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:57:08+00:00",
          "link": "https://arxiv.org/abs/2507.07599v1",
          "size": "292kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07599",
        "PDF": "https://arxiv.org/pdf/2507.07599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study involves fine-tuning LLMs for data extraction from emergency department notes, but the focus is on using models rather than processing or generating training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07306",
      "abstract": "LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: https://github.com/pigeonai-org/ViDove",
      "authors": [
        "Yichen Lu",
        "Wei Dai",
        "Jiaen Liu",
        "Ching Wing Kwok",
        "Zongheng Wu",
        "Xudong Xiao",
        "Ao Sun",
        "Sheng Fu",
        "Jianyuan Zhan",
        "Yian Wang",
        "Takatomo Saito",
        "Sicheng Lai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:05:46+00:00",
          "link": "https://arxiv.org/abs/2507.07306v1",
          "size": "6742kb",
          "version": "v1"
        }
      ],
      "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07306",
        "PDF": "https://arxiv.org/pdf/2507.07306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "ViDove is a translation system leveraging multimodal inputs for LLM-based translation but does not focus primarily on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07682",
      "abstract": "Advancements in large language models (LLMs) have led to a surge of prompt engineering (PE) techniques that can enhance various requirements engineering (RE) tasks. However, current LLMs are often characterized by significant uncertainty and a lack of controllability. This absence of clear guidance on how to effectively prompt LLMs acts as a barrier to their trustworthy implementation in the RE field. We present the first roadmap-oriented systematic literature review of Prompt Engineering for RE (PE4RE). Following Kitchenham's and Petersen's secondary-study protocol, we searched six digital libraries, screened 867 records, and analyzed 35 primary studies. To bring order to a fragmented landscape, we propose a hybrid taxonomy that links technique-oriented patterns (e.g., few-shot, Chain-of-Thought) to task-oriented RE roles (elicitation, validation, traceability). Two research questions, with five sub-questions, map the tasks addressed, LLM families used, and prompt types adopted, and expose current limitations and research gaps. Finally, we outline a step-by-step roadmap showing how today's ad-hoc PE prototypes can evolve into reproducible, practitioner-friendly workflows.",
      "authors": [
        "Kaicheng Huang",
        "Fanyu Wang",
        "Yutan Huang",
        "Chetan Arora"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:02:56+00:00",
          "link": "https://arxiv.org/abs/2507.07682v1",
          "size": "133kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Engineering for Requirements Engineering: A Literature Review and Roadmap",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07682",
        "PDF": "https://arxiv.org/pdf/2507.07682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper reviews prompt engineering techniques for requirements engineering tasks with LLMs, but does not primarily focus on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05995",
      "abstract": "The high configurability of modern software systems has made configuration tuning a crucial step for assuring system performance, e.g., latency or throughput. However, given the expensive measurements, large configuration space, and rugged configuration landscape, existing tuners suffer ineffectiveness due to the difficult balance of budget utilization between exploring uncertain regions (for escaping from local optima) and exploiting guidance of known good configurations (for fast convergence). The root cause is that we lack knowledge of where the promising regions lay, which also causes challenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by causally purified rules. PromiseTune is unique in the sense that we learn rules, which reflect certain regions in the configuration landscape, and purify them with causal inference. The remaining rules serve as approximated reflections of the promising regions, bounding the tuning to emphasize these places in the landscape. This, as we demonstrate, can effectively mitigate the impact of the exploration and exploitation trade-off. Those purified regions can then be paired with the measured configurations to provide spatial explainability at the landscape level. Comparing with 11 state-of-the-art tuners on 12 systems and varying budgets, we show that PromiseTune performs significantly better than the others with 42% superior rank to the overall second best while providing richer information to explain the hidden system characteristics.",
      "authors": [
        "Pengzhou Chen and Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:54:22+00:00",
          "link": "https://arxiv.org/abs/2507.05995v1",
          "size": "967kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:56:12+00:00",
          "link": "https://arxiv.org/abs/2507.05995v2",
          "size": "967kb",
          "version": "v2"
        }
      ],
      "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05995",
        "PDF": "https://arxiv.org/pdf/2507.05995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses configuration tuning in software systems to improve performance metrics like latency and throughput, focusing on causality and explainability\u2014not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.04266",
      "abstract": "This investigation introduces a novel deep reinforcement learning-based suite to control floating platforms in both simulated and real-world environments. Floating platforms serve as versatile test-beds to emulate micro-gravity environments on Earth, useful to test autonomous navigation systems for space applications. Our approach addresses the system and environmental uncertainties in controlling such platforms by training policies capable of precise maneuvers amid dynamic and unpredictable conditions. Leveraging Deep Reinforcement Learning (DRL) techniques, our suite achieves robustness, adaptability, and good transferability from simulation to reality. Our deep reinforcement learning framework provides advantages such as fast training times, large-scale testing capabilities, rich visualization options, and ROS bindings for integration with real-world robotic systems. Being open access, our suite serves as a comprehensive platform for practitioners who want to replicate similar research in their own simulated environments and labs.",
      "authors": [
        "Matteo El-Hariry",
        "Antoine Richard",
        "Vivek Muralidharan",
        "Matthieu Geist",
        "Miguel Olivares-Mendez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-06T14:11:35+00:00",
          "link": "https://arxiv.org/abs/2310.04266v1",
          "size": "4918kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T09:16:08+00:00",
          "link": "https://arxiv.org/abs/2310.04266v2",
          "size": "16261kb",
          "version": "v2"
        }
      ],
      "title": "DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.04266",
        "HTML": "https://arxiv.org/html/2310.04266",
        "PDF": "https://arxiv.org/pdf/2310.04266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a deep reinforcement learning framework for controlling floating platforms, which does not pertain to processing LLM training data."
      },
      "tasks": [
        "Autonomous Navigation",
        "Deep Reinforcement Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/elharirymatteo/rans"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.16102",
      "abstract": "Traditional approaches to modelling parallelism and algebraic structure in lambda calculi often rely on monads -- as in Moggi's framework -- or on rich categorical structures such as biproducts -- as used in linear logic. In this work, we propose a minimal alternative that captures both parallelism and weighted parallelism (linear combinations) within the setting of intuitionistic propositional logic, without resorting to monads or assuming the existence of biproducts.\n  We introduce two lambda calculi: a parallel lambda calculus and an algebraic lambda calculus, both extending full propositional intuitionistic logic. Their semantics are given in two categories: ${\\mathbf{Mag}_{\\mathbf{Set}}}$, whose objects are magmas and arrows are functions in $\\mathbf{Set}$; and ${\\mathbf{AMag}^{\\mathcal{S}}_{\\mathbf{Set}}}$, whose objects are action magmas.\n  The key technical challenge addressed is the interpretation of disjunction in the presence of parallel and algebraic operators. Since the usual coproduct structure is unavailable in our minimal setting, we propose a novel set-theoretic interpretation based on the union of the disjoint union and the Cartesian product. This allows for the construction of sound and adequate models for both calculi.\n  Our results offer a unified and structurally lightweight framework for modelling parallelism and algebraic effects in intuitionistic logic, opening the way to alternatives beyond the traditional monadic or linear logic approaches.",
      "authors": [
        "Alejandro D\\'iaz-Caro and Octavio Malherbe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T19:13:34+00:00",
          "link": "https://arxiv.org/abs/2408.16102v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T19:48:29+00:00",
          "link": "https://arxiv.org/abs/2408.16102v2",
          "size": "44kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T20:02:59+00:00",
          "link": "https://arxiv.org/abs/2408.16102v3",
          "size": "48kb",
          "version": "v3"
        }
      ],
      "title": "Beyond Monads and Biproducts: A Uniform Interpretation of Parallelism in Intuitionistic Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16102",
        "PDF": "https://arxiv.org/pdf/2408.16102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses theoretical aspects of parallelism in intuitionistic logic, without any relation to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20625",
      "abstract": "Processing long contexts has become a critical capability for modern large language models (LLMs). Existing works leverage agent-based divide-and-conquer methods for processing long contexts. But these methods face crucial limitations, including prohibitive accumulated latency and amplified information loss from excessive agent invocations, and the disruption of inherent textual dependencies by immoderate partitioning. In this paper, we propose a novel multi-agent framework XpandA (Expand-Agent) coupled with question-driven workflow and dynamic partitioning for robust long-context processing. XpandA overcomes these limitations through: 1) dynamic partitioning of long texts, which adaptively modulates the filling rate of context windows for input sequences of vastly varying lengths; 2) question-guided protocol to update flat information ensembles within centralized shared memory, constructing consistent inter-agent knowledge across partitions; and 3) selectively replaying specific partitions based on the state-tracking of question-information couples to promote the resolution of inverted-order structures across partitions (e.g., flashbacks). We perform a comprehensive evaluation of XpandA on multiple long-context benchmarks with length varying from 1k to 1M, demonstrating XpandA's feasibility for processing ultra-long sequences and its significant effectiveness in enhancing the long-context capabilities of various LLMs by achieving 20\\% improvements and 1.5x inference speedup over baselines of full-context, RAG and previous agent-based methods.",
      "authors": [
        "Sibo Xiao",
        "Zixin Lin",
        "Wenyang Gao",
        "Hui Chen",
        "Yue Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T02:05:42+00:00",
          "link": "https://arxiv.org/abs/2505.20625v1",
          "size": "10213kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:12:27+00:00",
          "link": "https://arxiv.org/abs/2505.20625v2",
          "size": "2676kb",
          "version": "v2"
        }
      ],
      "title": "Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20625",
        "HTML": "https://arxiv.org/html/2505.20625v2",
        "PDF": "https://arxiv.org/pdf/2505.20625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses long context processing capabilities of LLMs with dynamic partitioning but focuses on model architecture and inference speed without major emphasis on training data processing."
      },
      "tasks": [
        "RAG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07107",
      "abstract": "This paper presents a comprehensive machine learning framework for quantitative trading that achieves superior risk-adjusted returns through systematic factor engineering, real-time computation optimization, and cross-sectional portfolio construction. Our approach integrates multi-factor alpha discovery with bias correction techniques, leveraging PyTorch-accelerated factor computation and advanced portfolio optimization. The system processes 500-1000 factors derived from open-source alpha101 extensions and proprietary market microstructure signals. Key innovations include tensor-based factor computation acceleration, geometric Brownian motion data augmentation, and cross-sectional neutralization strategies. Empirical validation on Chinese A-share markets (2010-2024) demonstrates annualized returns of $20\\%$ with Sharpe ratios exceeding 2.0, significantly outperforming traditional approaches. Our analysis reveals the critical importance of bias correction in factor construction and the substantial impact of cross-sectional portfolio optimization on strategy performance. Code and experimental implementations are available at: https://github.com/initial-d/ml-quant-trading",
      "authors": [
        "Yimin Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T03:04:19+00:00",
          "link": "https://arxiv.org/abs/2507.07107v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning Enhanced Multi-Factor Quantitative Trading: A Cross-Sectional Portfolio Optimization Approach with Bias Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07107",
        "HTML": "https://arxiv.org/html/2507.07107v1",
        "PDF": "https://arxiv.org/pdf/2507.07107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantitative trading through machine learning for factor engineering and portfolio optimization, with no mention of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07618",
      "abstract": "The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we propose Feature-level constrained Preference Optimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.",
      "authors": [
        "Qingyu Yin",
        "Chak Tou Leong",
        "Minjun Zhu",
        "Hanqi Yan",
        "Qiang Zhang",
        "Yulan He",
        "Wenjie Li",
        "Jun Wang",
        "Yue Zhang",
        "Linyi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T07:54:13+00:00",
          "link": "https://arxiv.org/abs/2411.07618v1",
          "size": "1287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:18:23+00:00",
          "link": "https://arxiv.org/abs/2411.07618v2",
          "size": "321kb",
          "version": "v2"
        },
        {
          "date": "2025-07-04T15:18:24+00:00",
          "link": "https://arxiv.org/abs/2411.07618v3",
          "size": "321kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T15:03:47+00:00",
          "link": "https://arxiv.org/abs/2411.07618v4",
          "size": "321kb",
          "version": "v4"
        }
      ],
      "title": "Constrain Alignment with Sparse Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07618",
        "HTML": "https://arxiv.org/html/2411.07618v4",
        "PDF": "https://arxiv.org/pdf/2411.07618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on optimizing alignment in LLMs using Feature-level constrained Preference Optimization but does not directly address training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.02670",
      "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively while also minimizing bias and noise. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini. Moreover, harnessing a smaller model dramatically reduces operational costs by over 36x compared to GPT-4o. Improvements for other models (e.g., Qwen2.5-32B and Deepseek-R1-70B) and benchmarks (e.g., SimpleQA) are similar. KGoT offers a scalable, affordable, versatile, and high-performing solution for AI assistants.",
      "authors": [
        "Maciej Besta",
        "Lorenzo Paleari",
        "Jia Hao Andrea Jiang",
        "Robert Gerstenberger",
        "You Wu",
        "J\\'on Gunnar Hannesson",
        "Patrick Iff",
        "Ales Kubicek",
        "Piotr Nyczyk",
        "Diana Khimey",
        "Nils Blach",
        "Haiqiang Zhang",
        "Tao Zhang",
        "Peiran Ma",
        "Grzegorz Kwa\\'sniewski",
        "Marcin Copik",
        "Hubert Niewiadomski",
        "Torsten Hoefler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T15:11:55+00:00",
          "link": "https://arxiv.org/abs/2504.02670v1",
          "size": "778kb",
          "version": "v1"
        },
        {
          "date": "2025-04-10T14:44:34+00:00",
          "link": "https://arxiv.org/abs/2504.02670v2",
          "size": "756kb",
          "version": "v2"
        },
        {
          "date": "2025-06-16T14:19:01+00:00",
          "link": "https://arxiv.org/abs/2504.02670v3",
          "size": "6869kb",
          "version": "v3"
        },
        {
          "date": "2025-06-23T11:43:03+00:00",
          "link": "https://arxiv.org/abs/2504.02670v4",
          "size": "6869kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T07:15:51+00:00",
          "link": "https://arxiv.org/abs/2504.02670v5",
          "size": "6869kb",
          "version": "v5"
        }
      ],
      "title": "Affordable AI Assistants with Knowledge Graph of Thoughts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02670",
        "PDF": "https://arxiv.org/pdf/2504.02670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a system architecture (KGoT) that integrates LLM reasoning with knowledge graphs, it primarily focuses on AI assistant architecture rather than LLM training data processing methods even though it mentions improving task success rates."
      },
      "tasks": [
        "Knowledge Graphs",
        "LLM real-life tasks",
        "Multimodal Reasoning",
        "RAG"
      ],
      "repo_urls": [
        "https://github.com/spcl/knowledge-graph-of-thoughts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07496",
      "abstract": "The analysis of carotid arteries, particularly plaques, in multi-sequence Magnetic Resonance Imaging (MRI) data is crucial for assessing the risk of atherosclerosis and ischemic stroke. In order to evaluate metrics and radiomic features, quantifying the state of atherosclerosis, accurate segmentation is important. However, the complex morphology of plaques and the scarcity of labeled data poses significant challenges. In this work, we address these problems and propose a semi-supervised deep learning-based approach designed to effectively integrate multi-sequence MRI data for the segmentation of carotid artery vessel wall and plaque. The proposed algorithm consists of two networks: a coarse localization model identifies the region of interest guided by some prior knowledge on the position and number of carotid arteries, followed by a fine segmentation model for precise delineation of vessel walls and plaques. To effectively integrate complementary information across different MRI sequences, we investigate different fusion strategies and introduce a multi-level multi-sequence version of U-Net architecture. To address the challenges of limited labeled data and the complexity of carotid artery MRI, we propose a semi-supervised approach that enforces consistency under various input transformations. Our approach is evaluated on 52 patients with arteriosclerosis, each with five MRI sequences. Comprehensive experiments demonstrate the effectiveness of our approach and emphasize the role of fusion point selection in U-Net-based architectures. To validate the accuracy of our results, we also include an expert-based assessment of model performance. Our findings highlight the potential of fusion strategies and semi-supervised learning for improving carotid artery segmentation in data-limited MRI applications.",
      "authors": [
        "Marie-Christine Pali",
        "Christina Schwaiger",
        "Malik Galijasevic",
        "Valentin K. Ladenhauf",
        "Stephanie Mangesius",
        "Elke R. Gizewski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:31:31+00:00",
          "link": "https://arxiv.org/abs/2507.07496v1",
          "size": "2665kb",
          "version": "v1"
        }
      ],
      "title": "Semi-supervised learning and integration of multi-sequence MR-images for carotid vessel wall and plaque segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07496",
        "HTML": "https://arxiv.org/html/2507.07496v1",
        "PDF": "https://arxiv.org/pdf/2507.07496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semi-supervised learning for plaque segmentation in MRI images, which is specific to medical imaging and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.07861",
      "abstract": "The correct interpretation of convolutional models is a hard problem for time series data. While saliency methods promise visual validation of predictions for image and language processing, they fall short when applied to time series. These tend to be less intuitive and represent highly diverse data, such as the tool-use time series dataset. Furthermore, saliency methods often generate varied, conflicting explanations, complicating the reliability of these methods. Consequently, a rigorous objective assessment is necessary to establish trust in them. This paper investigates saliency methods on time series data to formulate recommendations for interpreting convolutional models and implements them on the tool-use time series problem. To achieve this, we first employ nine gradient-, propagation-, or perturbation-based post-hoc saliency methods across six varied and complex real-world datasets. Next, we evaluate these methods using five independent metrics to generate recommendations. Subsequently, we implement a case study focusing on tool-use time series using convolutional classification models. Our results validate our recommendations that indicate that none of the saliency methods consistently outperforms others on all metrics, while some are sometimes ahead. Our insights and step-by-step guidelines allow experts to choose suitable saliency methods for a given model and dataset.",
      "authors": [
        "Christoffer Loeffler",
        "Wei-Cheng Lai",
        "Bjoern Eskofier",
        "Dario Zanca",
        "Lukas Schmidt",
        "Christopher Mutschler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-14T15:22:20+00:00",
          "link": "https://arxiv.org/abs/2203.07861v1",
          "size": "3393kb",
          "version": "v1"
        },
        {
          "date": "2023-09-15T15:25:58+00:00",
          "link": "https://arxiv.org/abs/2203.07861v2",
          "size": "3436kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T08:29:38+00:00",
          "link": "https://arxiv.org/abs/2203.07861v3",
          "size": "1543kb",
          "version": "v3"
        }
      ],
      "title": "Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.07861",
        "HTML": "https://arxiv.org/html/2203.07861v3",
        "PDF": "https://arxiv.org/pdf/2203.07861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines saliency methods for interpreting convolutional models on time series data, not addressing LLM training data processing."
      },
      "tasks": [
        "Time Series",
        "Time Series Analysis",
        "Time Series Classification",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/crispchris/saliency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14760",
      "abstract": "Our society is on the verge of a revolution powered by Artificial Intelligence (AI) technologies. With increasing advancements in AI, there is a growing expansion in data centers (DCs) serving as critical infrastructure for this new wave of technologies. This technological wave is also on a collision course with exacerbating climate hazards which raises the need for evaluating the vulnerability of DCs to various hazards. Hence, the objective of this research is to conduct a nationwide vulnerability assessment of (DCs) in the United States of America (USA). DCs provide such support; however, if an unplanned disruption (like a natural hazard or power outage) occurs, the functionality of DCs are in jeopardy. Unplanned downtime in DCs cause severe economic and social repercussions. With the Local Indicator of Spatial Association (LISA) test, the research found that there are a large percentage of DCs that are in non-vulnerable areas of disruption; however, there is still a notable percentage in disruption prone areas. For example, earthquakes, hurricanes, and tornadoes have the most DCs in vulnerable areas. After identifying these vulnerabilities, the research identified areas within the USA that have minimal vulnerabilities to both the aforementioned natural hazards and power outages with the BI-LISA test. After doing a composite vulnerability score on the Cold-Spots from the BILISA analysis, the research found three counties with the low vulnerability scores. These are Koochiching, Minnesota (0.091), Schoolcraft, Michigan (0.095), and Houghton, Michigan (0.096).",
      "authors": [
        "Miguel Esparza",
        "Bo Li",
        "Junwei Ma",
        "Ali Mostafavi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T00:01:20+00:00",
          "link": "https://arxiv.org/abs/2501.14760v1",
          "size": "1720kb",
          "version": "v1"
        }
      ],
      "title": "AI Meets Natural Hazard Risk: A Nationwide Vulnerability Assessment of Data Centers to Natural Hazards and Power Outages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14760",
        "PDF": "https://arxiv.org/pdf/2501.14760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts a vulnerability assessment of data centers to natural hazards, focusing on infrastructure risks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.18549",
      "abstract": "The target defense problem (TDP) for unmanned surface vehicles (USVs) concerns intercepting an adversarial USV before it breaches a designated target region, using one or more defending USVs. A particularly challenging scenario arises when the attacker exhibits superior maneuverability compared to the defenders, significantly complicating effective interception. To tackle this challenge, this letter introduces ARBoids, a novel adaptive residual reinforcement learning framework that integrates deep reinforcement learning (DRL) with the biologically inspired, force-based Boids model. Within this framework, the Boids model serves as a computationally efficient baseline policy for multi-agent coordination, while DRL learns a residual policy to adaptively refine and optimize the defenders' actions. The proposed approach is validated in a high-fidelity Gazebo simulation environment, demonstrating superior performance over traditional interception strategies, including pure force-based approaches and vanilla DRL policies. Furthermore, the learned policy exhibits strong adaptability to attackers with diverse maneuverability profiles, highlighting its robustness and generalization capability. The code of ARBoids will be released upon acceptance of this letter.",
      "authors": [
        "Jiyue Tao",
        "Tongsheng Shen",
        "Dexin Zhao",
        "Feitian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T16:05:33+00:00",
          "link": "https://arxiv.org/abs/2502.18549v1",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T05:08:34+00:00",
          "link": "https://arxiv.org/abs/2502.18549v2",
          "size": "2031kb",
          "version": "v2"
        }
      ],
      "title": "ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18549",
        "HTML": "https://arxiv.org/html/2502.18549v2",
        "PDF": "https://arxiv.org/pdf/2502.18549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a reinforcement learning framework for cooperative USV target defense, unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01220",
      "abstract": "As the number of Common Vulnerabilities and Exposures (CVE) continues to grow exponentially, security teams face increasingly difficult decisions about prioritization. Current approaches using Common Vulnerability Scoring System (CVSS) scores produce overwhelming volumes of high-priority vulnerabilities, while Exploit Prediction Scoring System (EPSS) and Known Exploited Vulnerabilities (KEV) catalog offer valuable but incomplete perspectives on actual exploitation risk. We present Vulnerability Management Chaining, a decision tree framework that systematically integrates these three approaches to achieve efficient vulnerability prioritization. Our framework employs a two-stage evaluation process: first applying threat-based filtering using KEV membership or EPSS threshold $\\geq$ 0.088), then applying vulnerability severity assessment using CVSS scores $\\geq$ 7.0) to enable informed deprioritization. Experimental validation using 28,377 real-world vulnerabilities and vendor-reported exploitation data demonstrates 18-fold efficiency improvements while maintaining 85.6\\% coverage. Organizations can reduce urgent remediation workload by approximately 95\\%. The integration identifies 48 additional exploited vulnerabilities that neither KEV nor EPSS captures individually. Our framework uses exclusively open-source data, enabling immediate adoption regardless of organizational resources.",
      "authors": [
        "Naoyuki Shimizu",
        "Masaki Hashimoto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T00:06:54+00:00",
          "link": "https://arxiv.org/abs/2506.01220v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T05:07:03+00:00",
          "link": "https://arxiv.org/abs/2506.01220v2",
          "size": "40kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:13:08+00:00",
          "link": "https://arxiv.org/abs/2506.01220v3",
          "size": "42kb",
          "version": "v3"
        }
      ],
      "title": "Vulnerability Management Chaining: An Integrated Framework for Efficient Cybersecurity Risk Prioritization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01220",
        "HTML": "https://arxiv.org/html/2506.01220v3",
        "PDF": "https://arxiv.org/pdf/2506.01220"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses cybersecurity vulnerability management, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03041",
      "abstract": "Compound AI systems integrating multiple components, such as Large Language Models, specialized tools, and traditional machine learning models, are increasingly deployed to solve complex real-world tasks. However, optimizing compound systems remains challenging due to their non-differentiable structures and diverse configuration types across components, including prompts, hyperparameters, and model parameters. To address this challenge, we propose Optimas, a unified framework for effective optimization of compound systems. The core idea of Optimas is to maintain one Local Reward Function (LRF) per component, each satisfying a local-global alignment property, i.e., each component's local reward correlates with the global system performance. In each iteration, Optimas efficiently adapts the LRFs to maintain this property while simultaneously maximizing each component's local reward. This approach enables independent updates of heterogeneous configurations using the designated optimization method, while ensuring that local improvements consistently lead to performance gains. We present extensive evaluations across five real-world compound systems to demonstrate that Optimas outperforms strong baselines by an average improvement of 11.92%, offering a general and effective approach for improving compound systems. Our website is at https://optimas.stanford.edu.",
      "authors": [
        "Shirley Wu",
        "Parth Sarthi",
        "Shiyu Zhao",
        "Aaron Lee",
        "Herumb Shandilya",
        "Adrian Mladenic Grobelnik",
        "Nurendra Choudhary",
        "Eddie Huang",
        "Karthik Subbian",
        "Linjun Zhang",
        "Diyi Yang",
        "James Zou",
        "Jure Leskovec"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:12:48+00:00",
          "link": "https://arxiv.org/abs/2507.03041v1",
          "size": "2719kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T18:47:51+00:00",
          "link": "https://arxiv.org/abs/2507.03041v2",
          "size": "2719kb",
          "version": "v2"
        }
      ],
      "title": "Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03041",
        "HTML": "https://arxiv.org/html/2507.03041v2",
        "PDF": "https://arxiv.org/pdf/2507.03041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing compound AI systems, emphasizing configuration and reward optimization for system components rather than training-data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07242",
      "abstract": "Visual effects (VFX) production often struggles with slow, resource-intensive mask generation. This paper presents an automated video segmentation pipeline that creates temporally consistent instance masks. It employs machine learning for: (1) flexible object detection via text prompts, (2) refined per-frame image segmentation and (3) robust video tracking to ensure temporal stability. Deployed using containerization and leveraging a structured output format, the pipeline was quickly adopted by our artists. It significantly reduces manual effort, speeds up the creation of preliminary composites, and provides comprehensive segmentation data, thereby enhancing overall VFX production efficiency.",
      "authors": [
        "Johannes Merz",
        "Lucien Fostier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:27:06+00:00",
          "link": "https://arxiv.org/abs/2507.07242v1",
          "size": "8801kb",
          "version": "v1"
        }
      ],
      "title": "Automated Video Segmentation Machine Learning Pipeline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07242",
        "HTML": "https://arxiv.org/html/2507.07242v1",
        "PDF": "https://arxiv.org/pdf/2507.07242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automated video segmentation for VFX production, which does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07443",
      "abstract": "Ultrasound imaging is a prevalent diagnostic tool known for its simplicity and non-invasiveness. However, its inherent characteristics often introduce substantial noise, posing considerable challenges for automated lesion or organ segmentation in ultrasound video sequences. To address these limitations, we propose the Dual Semantic-Aware Network (DSANet), a novel framework designed to enhance noise robustness in ultrasound video segmentation by fostering mutual semantic awareness between local and global features. Specifically, we introduce an Adjacent-Frame Semantic-Aware (AFSA) module, which constructs a channel-wise similarity matrix to guide feature fusion across adjacent frames, effectively mitigating the impact of random noise without relying on pixel-level relationships. Additionally, we propose a Local-and-Global Semantic-Aware (LGSA) module that reorganizes and fuses temporal unconditional local features, which capture spatial details independently at each frame, with conditional global features that incorporate temporal context from adjacent frames. This integration facilitates multi-level semantic representation, significantly improving the model's resilience to noise interference. Extensive evaluations on four benchmark datasets demonstrate that DSANet substantially outperforms state-of-the-art methods in segmentation accuracy. Moreover, since our model avoids pixel-level feature dependencies, it achieves significantly higher inference FPS than video-based methods, and even surpasses some image-based models. Code can be found in \\href{https://github.com/ZhouL2001/DSANet}{DSANet}",
      "authors": [
        "Ling Zhou and Runtian Yuan and Yi Liu and Yuejie Zhang and Rui Feng and Shang Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:41:17+00:00",
          "link": "https://arxiv.org/abs/2507.07443v1",
          "size": "1649kb",
          "version": "v1"
        }
      ],
      "title": "Dual Semantic-Aware Network for Noise Suppressed Ultrasound Video Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07443",
        "HTML": "https://arxiv.org/html/2507.07443v1",
        "PDF": "https://arxiv.org/pdf/2507.07443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing noise robustness in ultrasound video segmentation using the proposed DSANet, with no mention of LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07727",
      "abstract": "Understanding and predicting mobility dynamics in transportation networks is critical for infrastructure planning, resilience analysis, and traffic management. Traditional graph-based models typically assume memoryless movement, limiting their ability to capture sequential dependencies inherent in real-world mobility patterns. In this study, we introduce a novel higher-order network framework for modeling memory-dependent dynamics in transportation systems. By extending classical graph representations through higher-order Markov chains and de Bruijn graph structures, our framework encodes the spatial and temporal ordering of traversed paths, enabling the analysis of structurally and functionally critical components with improved fidelity. We generalize key network analytics, including betweenness centrality, PageRank, and next-step prediction, to this higher-order setting and validate our approach on the Sioux Falls transportation network using agent-based trajectory data generated with MATSim. Experimental results demonstrate that higher-order models outperform first-order baselines across multiple tasks, with the third-order model achieving an optimal balance between predictive accuracy and model complexity. These findings highlight the importance of incorporating memory effects into network-based transportation analysis and offer a scalable, data-driven methodology for capturing complex mobility behaviors in infrastructure systems.",
      "authors": [
        "Chen Zhang and J\\\"urgen Hackl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:02:26+00:00",
          "link": "https://arxiv.org/abs/2507.07727v1",
          "size": "1545kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Connectivity: Higher-Order Network Framework for Capturing Memory-Driven Mobility Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07727",
        "HTML": "https://arxiv.org/html/2507.07727v1",
        "PDF": "https://arxiv.org/pdf/2507.07727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for modeling memory-driven mobility dynamics in transportation networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.13240",
      "abstract": "In this paper, we develop and implement an efficient asymptotic-preserving (AP) scheme to solve the gas mixture of Boltzmann equations under the disparate mass scaling relevant to the so-called \"epochal relaxation\" phenomenon. The disparity in molecular masses, ranging across several orders of magnitude, leads to significant challenges in both the evaluation of collision operators and the designing of time-stepping schemes to capture the multi-scale nature of the dynamics. A direct implementation of the spectral method faces prohibitive computational costs as the mass ratio increases due to the need to resolve vastly different thermal velocities. Unlike [I. M. Gamba, S. Jin, and L. Liu, Commun. Math. Sci., 17 (2019), pp. 1257-1289], we propose an alternative approach based on proper truncation of asymptotic expansions of the collision operators, which significantly reduces the computational complexity and works well for small $\\varepsilon$. By incorporating the separation of three time scales in the model's relaxation process [P. Degond and B. Lucquin-Desreux, Math. Models Methods Appl. Sci., 6 (1996), pp. 405-436], we design an AP scheme that captures the specific dynamics of the disparate mass model while maintaining computational efficiency. Numerical experiments demonstrate the effectiveness of the proposed scheme in handling large mass ratios of heavy and light species, as well as capturing the epochal relaxation phenomenon.",
      "authors": [
        "Zhen Hao",
        "Ning Jiang",
        "Liu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T11:58:02+00:00",
          "link": "https://arxiv.org/abs/2411.13240v1",
          "size": "1832kb",
          "version": "v1"
        },
        {
          "date": "2025-05-16T09:12:24+00:00",
          "link": "https://arxiv.org/abs/2411.13240v2",
          "size": "1820kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T07:56:44+00:00",
          "link": "https://arxiv.org/abs/2411.13240v3",
          "size": "484kb",
          "version": "v3"
        }
      ],
      "title": "An efficient Asymptotic-Preserving scheme for the Boltzmann mixture with disparate mass",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13240",
        "HTML": "https://arxiv.org/html/2411.13240v3",
        "PDF": "https://arxiv.org/pdf/2411.13240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an asymptotic-preserving scheme for the Boltzmann mixture equations with disparate mass, and does not mention any aspect related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06892",
      "abstract": "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.",
      "authors": [
        "Jing Liang",
        "Hongyao Tang",
        "Yi Ma",
        "Jinyi Liu",
        "Yan Zheng",
        "Shuyue Hu",
        "Lei Bai",
        "Jianye Hao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.06892v1",
          "size": "519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:42:04+00:00",
          "link": "https://arxiv.org/abs/2507.06892v2",
          "size": "479kb",
          "version": "v2"
        }
      ],
      "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06892",
        "HTML": "https://arxiv.org/html/2507.06892v2",
        "PDF": "https://arxiv.org/pdf/2507.06892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with reinforcement fine-tuning techniques for LLMs, focusing on training methodologies rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07652",
      "abstract": "This article explores a novel approach to time series forecasting applied to the context of Chennai's climate data. Our methodology comprises two distinct established time series models, leveraging their strengths in handling seasonality and periods. Notably, a new algorithm is developed to compute the period of the time series using unsupervised machine learning and spline interpolation techniques. Through a meticulous ensembling process that combines these two models, we achieve optimized forecasts. This research contributes to advancing forecasting techniques and offers valuable insights into climate data analysis.",
      "authors": [
        "Tanmay Kayal",
        "Abhishek Das",
        "U Saranya"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:24:42+00:00",
          "link": "https://arxiv.org/abs/2507.07652v1",
          "size": "770kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Hybrid Approach for Time Series Forecasting: Period Estimation and Climate Data Analysis Using Unsupervised Learning and Spline Interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07652",
        "HTML": "https://arxiv.org/html/2507.07652v1",
        "PDF": "https://arxiv.org/pdf/2507.07652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on time series forecasting and climate data analysis using unsupervised learning and spline interpolation, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07738",
      "abstract": "We propose a novel multi-task neural network approach for estimating distributional treatment effects (DTE) in randomized experiments. While DTE provides more granular insights into the experiment outcomes over conventional methods focusing on the Average Treatment Effect (ATE), estimating it with regression adjustment methods presents significant challenges. Specifically, precision in the distribution tails suffers due to data imbalance, and computational inefficiencies arise from the need to solve numerous regression problems, particularly in large-scale datasets commonly encountered in industry. To address these limitations, our method leverages multi-task neural networks to estimate conditional outcome distributions while incorporating monotonic shape constraints and multi-threshold label learning to enhance accuracy. To demonstrate the practical effectiveness of our proposed method, we apply our method to both simulated and real-world datasets, including a randomized field experiment aimed at reducing water consumption in the US and a large-scale A/B test from a leading streaming platform in Japan. The experimental results consistently demonstrate superior performance across various datasets, establishing our method as a robust and practical solution for modern causal inference applications requiring a detailed understanding of treatment effect heterogeneity.",
      "authors": [
        "Tomu Hirata",
        "Undral Byambadalai",
        "Tatsushi Oka",
        "Shota Yasui",
        "Shingo Uto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:16:33+00:00",
          "link": "https://arxiv.org/abs/2507.07738v1",
          "size": "955kb",
          "version": "v1"
        }
      ],
      "title": "Efficient and Scalable Estimation of Distributional Treatment Effects with Multi-Task Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07738",
        "HTML": "https://arxiv.org/html/2507.07738v1",
        "PDF": "https://arxiv.org/pdf/2507.07738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details a method for estimating distributional treatment effects using neural networks and does not involve processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04639",
      "abstract": "Cardiovascular magnetic resonance imaging is a powerful diagnostic tool for assessing cardiac structure and function. However, traditional breath-held imaging protocols pose challenges for patients with arrhythmias or limited breath-holding capacity. This work aims to overcome these limitations by developing a reconstruction framework that enables high-quality imaging in free-breathing conditions for various dynamic cardiac MRI protocols. Multi-Dynamic Deep Image Prior (M-DIP), a novel unsupervised reconstruction framework for accelerated real-time cardiac MRI, is introduced. To capture contrast or content variation, M-DIP first employs a spatial dictionary to synthesize a time-dependent intermediate image. Then, this intermediate image is further refined using time-dependent deformation fields that model cardiac and respiratory motion. Unlike prior DIP-based methods, M-DIP simultaneously captures physiological motion and frame-to-frame content variations, making it applicable to a wide range of dynamic applications. We validate M-DIP using simulated MRXCAT cine phantom data as well as free-breathing real-time cine, single-shot late gadolinium enhancement (LGE), and first-pass perfusion data from clinical patients. Comparative analyses against state-of-the-art supervised and unsupervised approaches demonstrate M-DIP's performance and versatility. M-DIP achieved better image quality metrics on phantom data, higher reader scores on in-vivo cine and LGE data, and comparable scores on in-vivo perfusion data relative to another DIP-based approach. M-DIP enables high-quality reconstructions of real-time free-breathing cardiac MRI without requiring external training data. Its ability to model physiological motion and content variations makes it a promising approach for various dynamic imaging applications.",
      "authors": [
        "Marc Vornehm",
        "Chong Chen",
        "Muhammad Ahmad Sultan",
        "Syed Murtaza Arshad",
        "Yuchi Han",
        "Florian Knoll",
        "Rizwan Ahmad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T22:15:18+00:00",
          "link": "https://arxiv.org/abs/2412.04639v1",
          "size": "2890kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T20:11:37+00:00",
          "link": "https://arxiv.org/abs/2412.04639v2",
          "size": "3793kb",
          "version": "v2"
        }
      ],
      "title": "Multi-dynamic deep image prior for cardiac MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04639",
        "HTML": "https://arxiv.org/html/2412.04639v2",
        "PDF": "https://arxiv.org/pdf/2412.04639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a reconstruction framework for cardiac MRI and does not involve any LLM training data processing."
      },
      "tasks": [
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07620",
      "abstract": "Reliable Uncertainty Quantification (UQ) and failure prediction remain open challenges for Vision-Language Models (VLMs). We introduce ViLU, a new Vision-Language Uncertainty quantification framework that contextualizes uncertainty estimates by leveraging all task-relevant textual representations. ViLU constructs an uncertainty-aware multi-modal representation by integrating the visual embedding, the predicted textual embedding, and an image-conditioned textual representation via cross-attention. Unlike traditional UQ methods based on loss prediction, ViLU trains an uncertainty predictor as a binary classifier to distinguish correct from incorrect predictions using a weighted binary cross-entropy loss, making it loss-agnostic. In particular, our proposed approach is well-suited for post-hoc settings, where only vision and text embeddings are available without direct access to the model itself. Extensive experiments on diverse datasets show the significant gains of our method compared to state-of-the-art failure prediction methods. We apply our method to standard classification datasets, such as ImageNet-1k, as well as large-scale image-caption datasets like CC12M and LAION-400M. Ablation studies highlight the critical role of our architecture and training in achieving effective uncertainty quantification. Our code is publicly available and can be found here: https://github.com/ykrmm/ViLU.",
      "authors": [
        "Marc Lafon",
        "Yannis Karmim",
        "Julio Silva-Rodriguez",
        "Paul Couairon",
        "Cl\\'ement Rambour",
        "Rapha\\\"el Fournier-Sniehotta",
        "Ismail Ben Ayed",
        "Jose Dolz",
        "Nicolas Thome"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:41:13+00:00",
          "link": "https://arxiv.org/abs/2507.07620v1",
          "size": "16787kb",
          "version": "v1"
        }
      ],
      "title": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07620",
        "HTML": "https://arxiv.org/html/2507.07620v1",
        "PDF": "https://arxiv.org/pdf/2507.07620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on uncertainty quantification and failure prediction in Vision-Language Models, it does mention processing existing vision and text embeddings but not LLM-specific data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07622",
      "abstract": "Electroencephalography (EEG) is establishing itself as an important, low-cost, noninvasive diagnostic tool for the early detection of Parkinson's Disease (PD). In this context, EEG-based Deep Learning (DL) models have shown promising results due to their ability to discover highly nonlinear patterns within the signal. However, current state-of-the-art DL models suffer from poor generalizability caused by high inter-subject variability. This high variability underscores the need for enhancing model generalizability by developing new architectures better tailored to EEG data. This paper introduces TransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's disease detection using EEG data. Unlike transformer models based on the EEGNet structure, TransformEEG incorporates a depthwise convolutional tokenizer. This tokenizer is specialized in generating tokens composed by channel-specific features, which enables more effective feature mixing within the self-attention layers of the transformer encoder. To evaluate the proposed model, four public datasets comprising 290 subjects (140 PD patients, 150 healthy controls) were harmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out (N-LNSO) cross-validation was performed to provide an unbiased comparison against seven other consolidated EEG deep learning models. TransformEEG achieved the highest balanced accuracy's median (78.45%) as well as the lowest interquartile range (6.37%) across all the N-LNSO partitions. When combined with data augmentation and threshold correction, median accuracy increased to 80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG produces more consistent and less skewed results. It demonstrates a substantial reduction in variability and more reliable PD detection using EEG data compared to the other investigated models.",
      "authors": [
        "Federico Del Pup",
        "Riccardo Brun",
        "Filippo Iotti",
        "Edoardo Paccagnella",
        "Mattia Pezzato",
        "Sabrina Bertozzo",
        "Andrea Zanola",
        "Louis Fabrice Tshimanga",
        "Henning M\\\"uller",
        "Manfredo Atzori"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:44:53+00:00",
          "link": "https://arxiv.org/abs/2507.07622v1",
          "size": "814kb",
          "version": "v1"
        }
      ],
      "title": "TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07622",
        "HTML": "https://arxiv.org/html/2507.07622v1",
        "PDF": "https://arxiv.org/pdf/2507.07622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a deep learning model for EEG data processing, focusing on model architecting and not on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07631",
      "abstract": "Single-channel speech enhancement is utilized in various tasks to mitigate the effect of interfering signals. Conventionally, to ensure the speech enhancement performs optimally, the speech enhancement has needed to be tuned for each task. Thus, generalizing speech enhancement models to unknown downstream tasks has been challenging. This study aims to construct a generic speech enhancement front-end that can improve the performance of back-ends to solve multiple downstream tasks. To this end, we propose a novel training criterion that minimizes the distance between the enhanced and the ground truth clean signal in the feature representation domain of self-supervised learning models. Since self-supervised learning feature representations effectively express high-level speech information useful for solving various downstream tasks, the proposal is expected to make speech enhancement models preserve such information. Experimental validation demonstrates that the proposal improves the performance of multiple speech tasks while maintaining the perceptual quality of the enhanced signal.",
      "authors": [
        "Hiroshi Sato",
        "Tsubasa Ochiai",
        "Marc Delcroix",
        "Takafumi Moriya",
        "Takanori Ashihara",
        "Ryo Masumura"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:56:48+00:00",
          "link": "https://arxiv.org/abs/2507.07631v1",
          "size": "489kb",
          "version": "v1"
        }
      ],
      "title": "Generic Speech Enhancement with Self-Supervised Representation Space Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07631",
        "HTML": "https://arxiv.org/html/2507.07631v1",
        "PDF": "https://arxiv.org/pdf/2507.07631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with speech enhancement models using self-supervised learning, not LLM training data processing or improvements in data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13451",
      "abstract": "Vision-and-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to significant storage and computational overhead. In this paper, we introduce MapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map (ASM) to replace historical frames. Specifically, our approach constructs a top-down semantic map at the start of each episode and update it at each timestep, allowing for precise object mapping and structured navigation information. Then, we enhance this map with explicit textual labels for key regions, transforming abstract semantics into clear navigation cues and generate our ASM. MapNav agent using the constructed ASM as input, and use the powerful end-to-end capabilities of VLM to empower VLN. Extensive experiments demonstrate that MapNav achieves state-of-the-art (SOTA) performance in both simulated and real-world environments, validating the effectiveness of our method. Moreover, we will release our ASM generation source code and dataset to ensure reproducibility, contributing valuable resources to the field. We believe that our proposed MapNav can be used as a new memory representation method in VLN, paving the way for future research in this field.",
      "authors": [
        "Lingfeng Zhang",
        "Xiaoshuai Hao",
        "Qinwen Xu",
        "Qiang Zhang",
        "Xinyao Zhang",
        "Pengwei Wang",
        "Jing Zhang",
        "Zhongyuan Wang",
        "Shanghang Zhang",
        "Renjing Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T05:52:34+00:00",
          "link": "https://arxiv.org/abs/2502.13451v1",
          "size": "23324kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T09:01:50+00:00",
          "link": "https://arxiv.org/abs/2502.13451v2",
          "size": "23324kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T02:13:54+00:00",
          "link": "https://arxiv.org/abs/2502.13451v3",
          "size": "23318kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T02:53:25+00:00",
          "link": "https://arxiv.org/abs/2502.13451v4",
          "size": "23318kb",
          "version": "v4"
        }
      ],
      "title": "MapNav: A Novel Memory Representation via Annotated Semantic Maps for Vision-and-Language Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13451",
        "HTML": "https://arxiv.org/html/2502.13451v4",
        "PDF": "https://arxiv.org/pdf/2502.13451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces MapNav for vision-and-language navigation using semantic maps, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06503",
      "abstract": "Large-scale homepage recommendations face critical challenges from pseudo-negative samples caused by exposure bias, where non-clicks may indicate inattention rather than disinterest. Existing work lacks thorough analysis of invalid exposures and typically addresses isolated aspects (e.g., sampling strategies), overlooking the critical impact of pseudo-positive samples - such as homepage clicks merely to visit marketing portals. We propose a unified framework for large-scale homepage recommendation sampling and debiasing. Our framework consists of two key components: (1) a user intent-aware negative sampling module to filter invalid exposure samples, and (2) an intent-driven dual-debiasing module that jointly corrects exposure bias and click bias. Extensive online experiments on Taobao demonstrate the efficacy of our framework, achieving significant improvements in user click-through rates (UCTR) by 35.4% and 14.5% in two variants of the marketing block on the Taobao homepage, Baiyibutie and Taobaomiaosha.",
      "authors": [
        "Jiaqi Zheng",
        "Cheng Guo",
        "Yi Cao",
        "Chaoqun Hou",
        "Tong Liu",
        "Bo Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:02:23+00:00",
          "link": "https://arxiv.org/abs/2507.06503v1",
          "size": "314kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T06:49:21+00:00",
          "link": "https://arxiv.org/abs/2507.06503v2",
          "size": "312kb",
          "version": "v2"
        }
      ],
      "title": "USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06503",
        "HTML": "https://arxiv.org/html/2507.06503v2",
        "PDF": "https://arxiv.org/pdf/2507.06503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for sampling and debiasing in large-scale homepage recommendations, which does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07754",
      "abstract": "Machine unlearning seeks to remove the influence of particular data or class from trained models to meet privacy, legal, or ethical requirements. Existing unlearning methods tend to forget shallowly: phenomenon of an unlearned model pretend to forget by adjusting only the model response, while its internal representations retain information sufficiently to restore the forgotten data or behavior. We empirically confirm the widespread shallowness by reverting the forgetting effect of various unlearning methods via training-free performance recovery attack and gradient-inversion-based data reconstruction attack. To address this vulnerability fundamentally, we define a theoretical criterion of ``deep forgetting'' based on one-point-contraction of feature representations of data to forget. We also propose an efficient approximation algorithm, and use it to construct a novel general-purpose unlearning algorithm: One-Point-Contraction (OPC). Empirical evaluations on image classification unlearning benchmarks show that OPC achieves not only effective unlearning performance but also superior resilience against both performance recovery attack and gradient-inversion attack. The distinctive unlearning performance of OPC arises from the deep feature forgetting enforced by its theoretical foundation, and recaps the need for improved robustness of machine unlearning methods.",
      "authors": [
        "Jaeheun Jung",
        "Bosung Jung",
        "Suhyun Bae",
        "Donghun Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:34:02+00:00",
          "link": "https://arxiv.org/abs/2507.07754v1",
          "size": "1553kb",
          "version": "v1"
        }
      ],
      "title": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07754",
        "HTML": "https://arxiv.org/html/2507.07754v1",
        "PDF": "https://arxiv.org/pdf/2507.07754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on machine unlearning methods and does not discuss any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07954",
      "abstract": "Curating foundation speech models for edge and IoT settings, where computational resources vary over time, requires dynamic architectures featuring adaptable reduction strategies. One emerging approach is layer dropping ($\\mathcal{LD}$) which skips fraction of the layers of a backbone network during inference to reduce the computational load. This allows transforming static models into dynamic ones. However, existing approaches exhibit limitations either in the mode of selecting layers or by significantly modifying the neural architecture. To this end, we propose input-driven $\\mathcal{LD}$ that employs the network's input features and a lightweight layer selecting network to determine the optimum combination of processing layers. Extensive experimentation on 4 speech and audio public benchmarks, using two different pre-trained foundation models, demonstrates the effectiveness of our approach, thoroughly outperforming random dropping and producing on-par (or better) results to early exit.",
      "authors": [
        "Abdul Hannan",
        "Daniele Falavigna",
        "Alessio Brutti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:39:03+00:00",
          "link": "https://arxiv.org/abs/2507.07954v1",
          "size": "1270kb",
          "version": "v1"
        }
      ],
      "title": "Input Conditioned Layer Dropping in Speech Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07954",
        "HTML": "https://arxiv.org/html/2507.07954v1",
        "PDF": "https://arxiv.org/pdf/2507.07954"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses layer-dropping techniques for dynamic inference in speech models, focusing on reducing computational load rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.18563",
      "abstract": "Machine learning (ML) methods have experienced significant growth in the past decade, yet their practical application in high-impact real-world domains has been hindered by their opacity. When ML methods are responsible for making critical decisions, stakeholders often require insights into how to alter these decisions. Counterfactual explanations (CFEs) have emerged as a solution, offering interpretations of opaque ML models and providing a pathway to transition from one decision to another. However, most existing CFE methods require access to the model's training dataset, few methods can handle multivariate time-series, and none of model-agnostic CFE methods can handle multivariate time-series without training datasets. These limitations can be formidable in many scenarios. In this paper, we present NTD-CFE, a novel model-agnostic CFE method based on reinforcement learning (RL) that generates CFEs when training datasets are unavailable. NTD-CFE is suitable for both static and multivariate time-series datasets with continuous and discrete features. NTD-CFE reduces the CFE search space from a multivariate time-series domain to a lower dimensional space and addresses the problem using RL. Users have the flexibility to specify non-actionable, immutable, and preferred features, as well as causal constraints. We demonstrate the performance of NTD-CFE against four baselines on several datasets and find that, despite not having access to a training dataset, NTD-CFE finds CFEs that make significantly fewer and significantly smaller changes to the input time-series. These properties make CFEs more actionable, as the magnitude of change required to alter an outcome is vastly reduced. The code is available in the supplementary material.",
      "authors": [
        "Xiangyu Sun",
        "Raquel Aoki",
        "Kevin H. Wilson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-28T20:15:09+00:00",
          "link": "https://arxiv.org/abs/2405.18563v1",
          "size": "4687kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T17:01:15+00:00",
          "link": "https://arxiv.org/abs/2405.18563v2",
          "size": "1758kb",
          "version": "v2"
        }
      ],
      "title": "No $D_{\\text{train}}$: Model-Agnostic Counterfactual Explanations Using Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.18563",
        "HTML": "https://arxiv.org/html/2405.18563v2",
        "PDF": "https://arxiv.org/pdf/2405.18563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces methods for model-agnostic counterfactual explanation in machine learning models, which does not involve actual training data processing for LLMs."
      },
      "tasks": [
        "counterfactual",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15469",
      "abstract": "Continual Learning (CL) aims to equip AI models with the ability to learn a sequence of tasks over time, without forgetting previously learned knowledge. Recently, State Space Models (SSMs), particularly the Mamba model, have achieved notable success in computer vision. Building on the strengths of SSMs, this study explores leveraging the Mamba model for CL. Therefore, we introduce Mamba-CL, a framework that continuously fine-tunes the core SSMs of the large-scale Mamba foundation model by updating parameters orthogonal to the feature subspace of previous tasks. This approach theoretically guarantees the consistency objective aiming to preserves consistent output for each SSM module across both previous and current tasks, so as to overcome catastrophic forgetting issue. Specifically, we achieve this goal by deducing the overall consistency constraints on four key time-invariant parameters in the Mamba model, streamlining its recurrent state-space structure and non-linear discretization process in SSM. In practice, we apply the null-space projection to efficiently implement the orthogonality within Mamba model. Extensive experiments on four class-incremental benchmarks demonstrate the effectiveness of Mamba-CL for anti-forgetting, achieving superior performances to state-of-the-art methods. Code is available in the supplementary materials.",
      "authors": [
        "De Cheng",
        "Yue Lu",
        "Lingfeng He",
        "Shizhou Zhang",
        "Xi Yang",
        "Nannan Wang",
        "Xinbo Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-23T06:36:16+00:00",
          "link": "https://arxiv.org/abs/2411.15469v1",
          "size": "13021kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:14:36+00:00",
          "link": "https://arxiv.org/abs/2411.15469v2",
          "size": "2039kb",
          "version": "v2"
        }
      ],
      "title": "Mamba-CL: Optimizing Selective State Space Model in Null Space for Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15469",
        "HTML": "https://arxiv.org/html/2411.15469v2",
        "PDF": "https://arxiv.org/pdf/2411.15469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with continual learning challenges using selective state space models and does not address any LLM training data processing or data engineering aspects."
      },
      "tasks": [
        "Continual Learning",
        "Mamba",
        "State Space Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07254",
      "abstract": "Modern deep learning implementations for medical imaging usually rely on large labeled datasets. These datasets are often difficult to obtain due to privacy concerns, high costs, and even scarcity of cases. In this paper, a label-efficient strategy is proposed for chest X-ray diagnosis that seeks to reflect real-world hospital scenarios. The experiments use the NIH Chest X-ray14 dataset and a pre-trained CLIP ViT-B/32 model. The model is adapted via partial fine-tuning of its visual encoder and then evaluated using zero-shot and few-shot learning with 1-16 labeled examples per disease class. The tests demonstrate that CLIP's pre-trained vision-language features can be effectively adapted to few-shot medical imaging tasks, achieving over 20\\% improvement in mean AUC score as compared to the zero-shot baseline. The key aspect of this work is to attempt to simulate internal hospital workflows, where image archives exist but annotations are sparse. This work evaluates a practical and scalable solution for both common and rare disease diagnosis. Additionally this research is intended for academic and experimental purposes only and has not been peer reviewed yet. All code is found at https://github.com/heet007-code/CLIP-disease-xray.",
      "authors": [
        "Heet Nitinkumar Dalsania"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.07254v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Label-Efficient Chest X-ray Diagnosis via Partial CLIP Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07254",
        "HTML": "https://arxiv.org/html/2507.07254v1",
        "PDF": "https://arxiv.org/pdf/2507.07254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on label-efficient chest X-ray diagnosis using CLIP adaptation, without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07660",
      "abstract": "Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on non-overlapping blocks. Our approach involves a two-step process: first, decomposing the network into sub-networks using SBM approximation, and then estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.",
      "authors": [
        "Marc Schalberger",
        "Cornelius Fritz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:36:23+00:00",
          "link": "https://arxiv.org/abs/2507.07660v1",
          "size": "3069kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Signed Exponential Random Graph Models under Local Dependence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07660",
        "HTML": "https://arxiv.org/html/2507.07660v1",
        "PDF": "https://arxiv.org/pdf/2507.07660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with network analysis using signed exponential random graph models and does not involve the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07709",
      "abstract": "Unified vision-language models(VLMs) have recently shown remarkable progress, enabling a single model to flexibly address diverse tasks through different instructions within a shared computational architecture. This instruction-based control mechanism creates unique security challenges, as adversarial inputs must remain effective across multiple task instructions that may be unpredictably applied to process the same malicious content. In this paper, we introduce CrossVLAD, a new benchmark dataset carefully curated from MSCOCO with GPT-4-assisted annotations for systematically evaluating cross-task adversarial attacks on unified VLMs. CrossVLAD centers on the object-change objective-consistently manipulating a target object's classification across four downstream tasks-and proposes a novel success rate metric that measures simultaneous misclassification across all tasks, providing a rigorous evaluation of adversarial transferability. To tackle this challenge, we present CRAFT (Cross-task Region-based Attack Framework with Token-alignment), an efficient region-centric attack method. Extensive experiments on Florence-2 and other popular unified VLMs demonstrate that our method outperforms existing approaches in both overall cross-task attack performance and targeted object-change success rates, highlighting its effectiveness in adversarially influencing unified VLMs across diverse tasks.",
      "authors": [
        "Jiale Zhao",
        "Xinyang Jiang",
        "Junyao Gao",
        "Yuhao Xue",
        "Cairong Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:40:34+00:00",
          "link": "https://arxiv.org/abs/2507.07709v1",
          "size": "18798kb",
          "version": "v1"
        }
      ],
      "title": "One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07709",
        "HTML": "https://arxiv.org/html/2507.07709v1",
        "PDF": "https://arxiv.org/pdf/2507.07709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for cross-task adversarial attack on unified vision-language models, focusing on adversarial attacks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07721",
      "abstract": "The development of robust deep learning models for breast ultrasound (BUS) image analysis is significantly constrained by the scarcity of expert-annotated data. To address this limitation, we propose a clinically controllable generative framework for synthesizing BUS images. This framework integrates clinical descriptions with structural masks to generate tumors, enabling fine-grained control over tumor characteristics such as morphology, echogencity, and shape. Furthermore, we design a semantic-curvature mask generator, which synthesizes structurally diverse tumor masks guided by clinical priors. During inference, synthetic tumor masks serve as input to the generative framework, producing highly personalized synthetic BUS images with tumors that reflect real-world morphological diversity. Quantitative evaluations on six public BUS datasets demonstrate the significant clinical utility of our synthetic images, showing their effectiveness in enhancing downstream breast cancer diagnosis tasks. Furthermore, visual Turing tests conducted by experienced sonographers confirm the realism of the generated images, indicating the framework's potential to support broader clinical applications.",
      "authors": [
        "Haoyu Pan",
        "Hongxin Lin",
        "Zetian Feng",
        "Chuxuan Lin",
        "Junyang Mo",
        "Chu Zhang",
        "Zijian Wu",
        "Yi Wang",
        "Qingqing Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:56:24+00:00",
          "link": "https://arxiv.org/abs/2507.07721v1",
          "size": "7416kb",
          "version": "v1"
        }
      ],
      "title": "Breast Ultrasound Tumor Generation via Mask Generator and Text-Guided Network:A Clinically Controllable Framework with Downstream Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07721",
        "HTML": "https://arxiv.org/html/2507.07721v1",
        "PDF": "https://arxiv.org/pdf/2507.07721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for generating synthetic ultrasound images for medical imaging purposes, not contributing to LLM training data processing or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07374",
      "abstract": "Generalizable depth completion enables the acquisition of dense metric depth maps for unseen environments, offering robust perception capabilities for various downstream tasks. However, training such models typically requires large-scale datasets with metric depth labels, which are often labor-intensive to collect. This paper presents PacGDC, a label-efficient technique that enhances data diversity with minimal annotation effort for generalizable depth completion. PacGDC builds on novel insights into inherent ambiguities and consistencies in object shapes and positions during 2D-to-3D projection, allowing the synthesis of numerous pseudo geometries for the same visual scene. This process greatly broadens available geometries by manipulating scene scales of the corresponding depth maps. To leverage this property, we propose a new data synthesis pipeline that uses multiple depth foundation models as scale manipulators. These models robustly provide pseudo depth labels with varied scene scales, affecting both local objects and global layouts, while ensuring projection consistency that supports generalization. To further diversify geometries, we incorporate interpolation and relocation strategies, as well as unlabeled images, extending the data coverage beyond the individual use of foundation models. Extensive experiments show that PacGDC achieves remarkable generalizability across multiple benchmarks, excelling in diverse scene semantics/scales and depth sparsity/patterns under both zero-shot and few-shot settings. Code: https://github.com/Wang-xjtu/PacGDC.",
      "authors": [
        "Haotian Wang",
        "Aoran Xiao",
        "Xiaoqin Zhang",
        "Meng Yang",
        "Shijian Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:56:30+00:00",
          "link": "https://arxiv.org/abs/2507.07374v1",
          "size": "17050kb",
          "version": "v1"
        }
      ],
      "title": "PacGDC: Label-Efficient Generalizable Depth Completion with Projection Ambiguity and Consistency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07374",
        "HTML": "https://arxiv.org/html/2507.07374v1",
        "PDF": "https://arxiv.org/pdf/2507.07374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents PacGDC, a label-efficient technique that emphasizes data synthesis for depth completion using minimal annotations. It involves creating pseudo depth labels through data synthesis pipelines and incorporating strategies that significantly improve data diversity and quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07376",
      "abstract": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.",
      "authors": [
        "Hengrui Liu",
        "Yi Feng",
        "Qilong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T02:10:18+00:00",
          "link": "https://arxiv.org/abs/2507.07376v1",
          "size": "1329kb",
          "version": "v1"
        }
      ],
      "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07376",
        "HTML": "https://arxiv.org/html/2507.07376v1",
        "PDF": "https://arxiv.org/pdf/2507.07376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multi-agent search and rescue algorithm with local communication and pheromone guidance. There is no discussion related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07401",
      "abstract": "Deep learning draws heavily on the latest progress in semantic communications. The present paper aims to examine the security aspect of this cutting-edge technique from a novel shuffling perspective. Our goal is to improve upon the conventional secure coding scheme to strike a desirable tradeoff between transmission rate and leakage rate. To be more specific, for a wiretap channel, we seek to maximize the transmission rate while minimizing the semantic error probability under the given leakage rate constraint. Toward this end, we devise a novel semantic security communication system wherein the random shuffling pattern plays the role of the shared secret key. Intuitively, the permutation of feature sequences via shuffling would distort the semantic essence of the target data to a sufficient extent so that eavesdroppers cannot access it anymore. The proposed random shuffling method also exhibits its flexibility in working for the existing semantic communication system as a plugin. Simulations demonstrate the significant advantage of the proposed method over the benchmark in boosting secure transmission, especially when channels are prone to strong noise and unpredictable fading.",
      "authors": [
        "Fupei Chen",
        "Liyao Xiang",
        "Haoxiang Sun",
        "Hei Victor Cheng",
        "and Kaiming Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:42:17+00:00",
          "link": "https://arxiv.org/abs/2507.07401v1",
          "size": "5699kb",
          "version": "v1"
        }
      ],
      "title": "Shuffling for Semantic Secrecy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07401",
        "HTML": "https://arxiv.org/html/2507.07401v1",
        "PDF": "https://arxiv.org/pdf/2507.07401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on semantic security communication systems, emphasizing secure coding with shuffling for enhanced protection. It does not discuss LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07881",
      "abstract": "The rise of conversational AI (CAI), powered by large language models, is transforming how individuals access and interact with digital information. However, these tools may inadvertently amplify existing digital inequalities. This study investigates whether differences in formal education are associated with CAI avoidance, leveraging behavioral data from an online experiment (N = 1,636). Participants were randomly assigned to a control or an information-seeking task, either a traditional online search or a CAI (Perplexity AI). Task avoidance (operationalized as survey abandonment or providing unrelated responses during task assignment) was significantly higher in the CAI group (51%) compared to the search (30.9%) and control (16.8%) groups, with the highest CAI avoidance among participants with lower education levels (~74.4%). Structural equation modeling based on the theoretical framework UTAUT2 and LASSO regressions reveal that education is strongly associated with CAI avoidance, even after accounting for various cognitive and affective predictors of technology adoption. These findings underscore education's central role in shaping AI adoption and the role of self-selection biases in AI-related research, stressing the need for inclusive design to ensure equitable access to emerging technologies.",
      "authors": [
        "Roberto Ulloa",
        "Juhi Kulshrestha",
        "Celina Kacperski"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:05:11+00:00",
          "link": "https://arxiv.org/abs/2507.07881v1",
          "size": "1272kb",
          "version": "v1"
        }
      ],
      "title": "Opting Out of Generative AI: a Behavioral Experiment on the Role of Education in Perplexity AI Avoidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07881",
        "PDF": "https://arxiv.org/pdf/2507.07881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies user behavior and education in AI tool usage, which does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.02770",
      "abstract": "This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent's path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.",
      "authors": [
        "Hoang-Dung Bui",
        "Erion Plaku",
        "Gregoy J. Stein"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T05:21:18+00:00",
          "link": "https://arxiv.org/abs/2501.02770v1",
          "size": "9372kb",
          "version": "v1"
        },
        {
          "date": "2025-02-05T15:32:43+00:00",
          "link": "https://arxiv.org/abs/2501.02770v2",
          "size": "11911kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:41:02+00:00",
          "link": "https://arxiv.org/abs/2501.02770v3",
          "size": "8637kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T01:02:17+00:00",
          "link": "https://arxiv.org/abs/2501.02770v4",
          "size": "8637kb",
          "version": "v4"
        }
      ],
      "title": "Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02770",
        "HTML": "https://arxiv.org/html/2501.02770v4",
        "PDF": "https://arxiv.org/pdf/2501.02770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on multi-agent pathfinding and communication constraints, unrelated to LLM training data processing."
      },
      "tasks": [
        "Multi-Agent Path Finding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07735",
      "abstract": "Jailbreak attacks reveal critical vulnerabilities in Large Language Models (LLMs) by causing them to generate harmful or unethical content. Evaluating these threats is particularly challenging due to the evolving nature of LLMs and the sophistication required in effectively probing their vulnerabilities. Current benchmarks and evaluation methods struggle to fully address these challenges, leaving gaps in the assessment of LLM vulnerabilities. In this paper, we review existing jailbreak evaluation practices and identify three assumed desiderata for an effective jailbreak evaluation protocol. To address these challenges, we introduce GuardVal, a new evaluation protocol that dynamically generates and refines jailbreak prompts based on the defender LLM's state, providing a more accurate assessment of defender LLMs' capacity to handle safety-critical situations. Moreover, we propose a new optimization method that prevents stagnation during prompt refinement, ensuring the generation of increasingly effective jailbreak prompts that expose deeper weaknesses in the defender LLMs. We apply this protocol to a diverse set of models, from Mistral-7b to GPT-4, across 10 safety domains. Our findings highlight distinct behavioral patterns among the models, offering a comprehensive view of their robustness. Furthermore, our evaluation process deepens the understanding of LLM behavior, leading to insights that can inform future research and drive the development of more secure models.",
      "authors": [
        "Peiyan Zhang",
        "Haibo Jin",
        "Liying Kang",
        "Haohan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:15:20+00:00",
          "link": "https://arxiv.org/abs/2507.07735v1",
          "size": "866kb",
          "version": "v1"
        }
      ],
      "title": "GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07735",
        "HTML": "https://arxiv.org/html/2507.07735v1",
        "PDF": "https://arxiv.org/pdf/2507.07735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses generating jailbreak prompts to assess LLM vulnerabilities, it does not primarily focus on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07250",
      "abstract": "A semi-fragile watermarking scheme for multiple band images is presented in this article. We propose to embed a mark into remote sensing images applying a tree-structured vector quantization approach to the pixel signatures instead of processing each band separately. The signature of the multispectral or hyperspectral image is used to embed the mark in it order to detect any significant modification of the original image. The image is segmented into three-dimensional blocks, and a tree-structured vector quantizer is built for each block. These trees are manipulated using an iterative algorithm until the resulting block satisfies a required criterion, which establishes the embedded mark. The method is shown to be able to preserve the mark under lossy compression (above a given threshold) but, at the same time, it detects possibly forged blocks and their position in the whole image.",
      "authors": [
        "Jordi Serra-Ruiz and David Meg\\'ias"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:47:40+00:00",
          "link": "https://arxiv.org/abs/2507.07250v1",
          "size": "5664kb",
          "version": "v1"
        }
      ],
      "title": "Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07250",
        "HTML": "https://arxiv.org/html/2507.07250v1",
        "PDF": "https://arxiv.org/pdf/2507.07250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a watermarking scheme for remote sensing images and does not address any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07822",
      "abstract": "Piecewise Diffusion Markov Processes (PDifMPs) are valuable for modelling systems where continuous dynamics are interrupted by sudden shifts and/or changes in drift and diffusion. The first-passage time (FPT) in such models plays a central role in understanding when a process first reaches a critical boundary. In many systems, time-dependent thresholds provide a flexible framework for reflecting evolving conditions, making them essential for realistic modelling. We propose a hybrid exact simulation scheme for computing the FPT of PDifMPs to time-dependent thresholds. Exact methods traditionally exist for pure diffusions, using Brownian motion as an auxiliary process and accepting sampled paths with a probability weight. Between jumps, the PDifMP evolves as a diffusion, allowing us to apply the exact method within each inter-jump interval. The main challenge arises when no threshold crossing is detected in an interval: We then need the value of the process at the jump time, and for that, we introduce an approach to simulate a conditionally constrained auxiliary process and derive the corresponding acceptance probability. Furthermore, we prove the convergence of the method and illustrate it using numerical examples.",
      "authors": [
        "Sascha Desmettre",
        "Devika Khurana",
        "Amira Meddah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:53:24+00:00",
          "link": "https://arxiv.org/abs/2507.07822v1",
          "size": "291kb",
          "version": "v1"
        }
      ],
      "title": "First-passage time for PDifMPs: an Exact simulation approach for time-varying thresholds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07822",
        "HTML": "https://arxiv.org/html/2507.07822v1",
        "PDF": "https://arxiv.org/pdf/2507.07822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simulation methods for Piecewise Diffusion Markov Processes and their application to time-dependent thresholds, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07830",
      "abstract": "This work proposes a model-order reduction framework for the meshless weakly compressible smoothed particle hydrodynamics (SPH) method. The proposed framework introduces the concept of modal reference spaces to overcome the challenges of discovering low-dimensional subspaces from unstructured, dynamic, and mixing numerical topology that is often seen in SPH simulations. The proposed modal reference spaces enable a low-dimensional representation of the SPH field equations while maintaining their inherent meshless qualities. Modal reference spaces are constructed by projecting SPH snapshot data onto a reference space where low-dimensionality of field quantities can be discovered via traditional modal decomposition techniques (e.g., the proper orthogonal decomposition (POD)). Modal quantities are mapped back to the meshless SPH space via scattered data interpolation during the online predictive stage. The proposed model-order reduction framework is cast into the \\emph{meshless} Galerkin POD (GPOD) and the Adjoint Petrov--Galerkin (APG) projection model-order reduction (PMOR) formulation. The PMORs are tested on three numerical experiments: 1) the Taylor--Green vortex; 2) lid-driven cavity; and 3) flow past an open cavity. Results show good agreement in reconstructed and predictive velocity fields, which showcase the ability of the proposed framework to evolve the unstructured, dynamic, and mixing SPH field equations in a low-dimensional subspace. Results also show that the pressure field is sensitive to the projection error due to the stiff weakly-compressible assumption made in the current SPH framework, but can be alleviated through nonlinear approximations, such as the APG approach. Ultimately, the presented meshless model-order reduction framework marks a step toward enabling drastic cost savings of SPH simulations.",
      "authors": [
        "Steven N. Rodriguez",
        "Steven L. Brunton",
        "Liam K. Magargal",
        "Parisa Khodabakshi",
        "Justin W. Jaworski",
        "Nicoleta A. Apetre",
        "John C. Steuben",
        "John G. Michopoulos",
        "and Athanasios Iliopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:02:18+00:00",
          "link": "https://arxiv.org/abs/2507.07830v1",
          "size": "20286kb",
          "version": "v1"
        }
      ],
      "title": "Meshless projection model-order reduction via reference spaces for smoothed-particle hydrodynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07830",
        "HTML": "https://arxiv.org/html/2507.07830v1",
        "PDF": "https://arxiv.org/pdf/2507.07830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model-order reduction framework for SPH simulations. It doesn't focus on LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07974",
      "abstract": "When large language model (LLM) systems interact with external data to perform complex tasks, a new attack, namely prompt injection, becomes a significant threat. By injecting instructions into the data accessed by the system, the attacker is able to override the initial user task with an arbitrary task directed by the attacker. To secure the system, test-time defenses, e.g., defensive prompting, have been proposed for system developers to attain security only when needed in a flexible manner. However, they are much less effective than training-time defenses that change the model parameters. Motivated by this, we propose DefensiveToken, a test-time defense with prompt injection robustness comparable to training-time alternatives. DefensiveTokens are newly inserted as special tokens, whose embeddings are optimized for security. In security-sensitive cases, system developers can append a few DefensiveTokens before the LLM input to achieve security with a minimal utility drop. In scenarios where security is less of a concern, developers can simply skip DefensiveTokens; the LLM system remains the same as there is no defense, generating high-quality responses. Thus, DefensiveTokens, if released alongside the model, allow a flexible switch between the state-of-the-art (SOTA) utility and almost-SOTA security at test time. The code is available at https://github.com/Sizhe-Chen/DefensiveToken.",
      "authors": [
        "Sizhe Chen",
        "Yizhu Wang",
        "Nicholas Carlini",
        "Chawin Sitawarin",
        "David Wagner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:51:05+00:00",
          "link": "https://arxiv.org/abs/2507.07974v1",
          "size": "199kb",
          "version": "v1"
        }
      ],
      "title": "Defending Against Prompt Injection With a Few DefensiveTokens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07974",
        "HTML": "https://arxiv.org/html/2507.07974v1",
        "PDF": "https://arxiv.org/pdf/2507.07974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prompt injection attacks and test-time defenses using DefensiveTokens, which does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10927",
      "abstract": "Learners of a second language (L2) often unconsciously substitute unfamiliar L2 phonemes with similar phonemes from their native language (L1), even though native speakers of the L2 perceive these sounds as distinct and non-interchangeable. This phonemic substitution leads to deviations from the standard phonological patterns of the L2, creating challenges for learners in acquiring accurate L2 pronunciation. To address this, we propose Inter-linguistic Phonetic Composition (IPC), a novel computational method designed to minimize incorrect phonological transfer by reconstructing L2 phonemes as composite sounds derived from multiple L1 phonemes. Tests with two automatic speech recognition models demonstrated that when L2 speakers produced IPC-generated composite sounds, the recognition rate of target L2 phonemes improved by 20% compared to when their pronunciation was influenced by original phonological transfer patterns. The improvement was observed within a relatively shorter time frame, demonstrating rapid acquisition of the composite sound.",
      "authors": [
        "Jisang Park",
        "Minu Kim",
        "DaYoung Hong",
        "and Jongha Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-17T01:15:58+00:00",
          "link": "https://arxiv.org/abs/2411.10927v1",
          "size": "992kb",
          "version": "v1"
        },
        {
          "date": "2024-11-27T12:16:27+00:00",
          "link": "https://arxiv.org/abs/2411.10927v2",
          "size": "992kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T04:17:52+00:00",
          "link": "https://arxiv.org/abs/2411.10927v3",
          "size": "992kb",
          "version": "v3"
        }
      ],
      "title": "Inter-linguistic Phonetic Composition (IPC): A Theoretical and Computational Approach to Enhance Second Language Pronunciation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10927",
        "PDF": "https://arxiv.org/pdf/2411.10927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a computational approach for enhancing second language pronunciation, unrelated to LLM training data processing."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04382",
      "abstract": "In this work, we address the voice conversion (VC) task using a vector-based interface. To align audio embeddings between speakers, we employ discrete optimal transport mapping. Our evaluation results demonstrate the high quality and effectiveness of this method. Additionally, we show that applying discrete optimal transport as a post-processing step in audio generation can lead to the incorrect classification of synthetic audio as real.",
      "authors": [
        "Anton Selitskiy and Maitreya Kocharekar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T13:04:29+00:00",
          "link": "https://arxiv.org/abs/2505.04382v1",
          "size": "138kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T12:54:15+00:00",
          "link": "https://arxiv.org/abs/2505.04382v2",
          "size": "138kb",
          "version": "v2"
        }
      ],
      "title": "Discrete Optimal Transport and Voice Conversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04382",
        "HTML": "https://arxiv.org/html/2505.04382v2",
        "PDF": "https://arxiv.org/pdf/2505.04382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with audio processing for voice conversion using discrete optimal transport, not with LLMs or their training data processing."
      },
      "tasks": [
        "Audio Generation",
        "Voice Conversion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08694",
      "abstract": "Dense self-supervised learning has shown great promise for learning pixel- and patch-level representations, but extending it to videos remains challenging due to the complexity of motion dynamics. Existing approaches struggle as they rely on static augmentations that fail under object deformations, occlusions, and camera movement, leading to inconsistent feature learning over time. We propose a motion-guided self-supervised learning framework that clusters dense point tracks to learn spatiotemporally consistent representations. By leveraging an off-the-shelf point tracker, we extract long-range motion trajectories and optimize feature clustering through a momentum-encoder-based optimal transport mechanism. To ensure temporal coherence, we propagate cluster assignments along tracked points, enforcing feature consistency across views despite viewpoint changes. Integrating motion as an implicit supervisory signal, our method learns representations that generalize across frames, improving robustness in dynamic scenes and challenging occlusion scenarios. By initializing from strong image-pretrained models and leveraging video data for training, we improve state-of-the-art by 1% to 6% on six image and video datasets and four evaluation benchmarks. The implementation is publicly available at our GitHub repository: https://github.com/SMSD75/MoSiC/tree/main",
      "authors": [
        "Mohammadreza Salehi",
        "Shashanka Venkataramanan",
        "Ioana Simion",
        "Efstratios Gavves",
        "Cees G. M. Snoek",
        "Yuki M Asano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T11:20:32+00:00",
          "link": "https://arxiv.org/abs/2506.08694v1",
          "size": "9600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:39:59+00:00",
          "link": "https://arxiv.org/abs/2506.08694v2",
          "size": "9600kb",
          "version": "v2"
        }
      ],
      "title": "MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08694",
        "HTML": "https://arxiv.org/html/2506.08694v2",
        "PDF": "https://arxiv.org/pdf/2506.08694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on self-supervised learning for spatiotemporal representations, leveraging motion trajectories, but does not involve any LLM training data processing or data engineering operations."
      },
      "tasks": [
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/smsd75/mosic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23664",
      "abstract": "Medical image data is less accessible than in other domains due to privacy and regulatory constraints. In addition, labeling requires costly, time-intensive manual image annotation by clinical experts. To overcome these challenges, synthetic medical data generation offers a promising solution. Generative AI (GenAI), employing generative deep learning models, has proven effective at producing realistic synthetic images. This study proposes a novel mask-guided GenAI approach using diffusion models to generate synthetic fetal head ultrasound images paired with segmentation masks. These synthetic pairs augment real datasets for supervised fine-tuning of the Segment Anything Model (SAM). Our results show that the synthetic data captures real image features effectively, and this approach reaches state-of-the-art fetal head segmentation, especially when trained with a limited number of real image-mask pairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and 94.38\\% using a handful of ultrasound images from the Spanish and African cohorts, respectively. Our code, models, and data are available on GitHub.",
      "authors": [
        "Fangyijie Wang",
        "Kevin Whelan",
        "F\\'elix Balado",
        "Kathleen M. Curran",
        "Gu\\'enol\\'e Silvestre"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:40:12+00:00",
          "link": "https://arxiv.org/abs/2506.23664v1",
          "size": "2810kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:51:46+00:00",
          "link": "https://arxiv.org/abs/2506.23664v2",
          "size": "2810kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23664",
        "HTML": "https://arxiv.org/html/2506.23664v2",
        "PDF": "https://arxiv.org/pdf/2506.23664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper develops a novel data augmentation method using diffusion models to generate synthetic data pairs for fine-tuning. This process explicitly involves generating and processing new training data for improving the quality of an LLM segmentation model."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07125",
      "abstract": "Unsupervised domain adaptation (UDA) involves learning class semantics from labeled data within a source domain that generalize to an unseen target domain. UDA methods are particularly impactful for semantic segmentation, where annotations are more difficult to collect than in image classification. Despite recent advances in large-scale vision-language representation learning, UDA methods for segmentation have not taken advantage of the domain-agnostic properties of text. To address this, we present a novel Covariance-based Pixel-Text loss, CoPT, that uses domain-agnostic text embeddings to learn domain-invariant features in an image segmentation encoder. The text embeddings are generated through our LLM Domain Template process, where an LLM is used to generate source and target domain descriptions that are fed to a frozen CLIP model and combined. In experiments on four benchmarks we show that a model trained using CoPT achieves the new state of the art performance on UDA for segmentation. The code can be found at https://github.com/cfmata/CoPT.",
      "authors": [
        "Cristina Mata",
        "Kanchana Ranasinghe",
        "Michael S. Ryoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:39:28+00:00",
          "link": "https://arxiv.org/abs/2507.07125v1",
          "size": "8137kb",
          "version": "v1"
        }
      ],
      "title": "CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07125",
        "HTML": "https://arxiv.org/html/2507.07125v1",
        "PDF": "https://arxiv.org/pdf/2507.07125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a novel approach using domain-agnostic text embeddings for unsupervised domain adaptation, it primarily focuses on segmentation tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07225",
      "abstract": "Navigation and inspection in confined environments, such as tunnels and pipes, pose significant challenges for existing robots due to limitations in maneuverability and adaptability to varying geometries. Vine robots, which are soft growing continuum robots that extend their length through soft material eversion at their tip, offer unique advantages due to their ability to navigate tight spaces, adapt to complex paths, and minimize friction. However, existing vine robot designs struggle with navigation in manmade and natural passageways, with branches and sharp 3D turns. In this letter, we introduce a steerable vine robot specifically designed for pipe and burrow environments. The robot features a simple tubular body and an external tip mount that steers the vine robot in three degrees of freedom by changing the growth direction and, when necessary, bracing against the wall of the pipe or burrow. Our external tip steering approach enables: (1) active branch selection in 3D space with a maximum steerable angle of 51.7{\\deg}, (2) navigation of pipe networks with radii as small as 2.5 cm, (3) a compliant tip enabling navigation of sharp turns, and (4) real-time 3D localization in GPS-denied environments using tip-mounted sensors and continuum body odometry. We describe the forward kinematics, characterize steerability, and demonstrate the system in a 3D pipe system as well as a natural animal burrow.",
      "authors": [
        "Yimeng Qin",
        "Jared Grinberg",
        "William Heap",
        "and Allison M. Okamura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.07225v1",
          "size": "39356kb",
          "version": "v1"
        }
      ],
      "title": "3D Steering and Localization in Pipes and Burrows using an Externally Steered Soft Growing Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07225",
        "HTML": "https://arxiv.org/html/2507.07225v1",
        "PDF": "https://arxiv.org/pdf/2507.07225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents techniques for robot navigation in confined spaces and does not touch on any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07276",
      "abstract": "Along with accurate prediction, understanding the contribution of each feature to the making of the prediction, i.e., the importance of the feature, is a desirable and arguably necessary component of a machine learning model. For a complex model such as a random forest, such importances are not innate -- as they are, e.g., with linear regression. Efficient methods have been created to provide such capabilities, with one of the most popular among them being permutation feature importance due to its efficiency, model-agnostic nature, and perceived intuitiveness. However, permutation feature importance has been shown to be misleading in the presence of dependent features as a result of the creation of unrealistic observations when permuting the dependent features. In this work, we develop TRIP (Test for Reliable Interpretation via Permutation), a test requiring minimal assumptions that is able to detect unreliable permutation feature importance scores that are the result of model extrapolation. To build on this, we demonstrate how the test can be complemented in order to allow its use in high dimensional settings. Through testing on simulated data and applications, our results show that the test can be used to reliably detect when permutation feature importance scores are unreliable.",
      "authors": [
        "Aaron Foote and Danny Krizanc"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:49:10+00:00",
          "link": "https://arxiv.org/abs/2507.07276v1",
          "size": "4032kb",
          "version": "v1"
        }
      ],
      "title": "TRIP: A Nonparametric Test to Diagnose Biased Feature Importance Scores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07276",
        "HTML": "https://arxiv.org/html/2507.07276v1",
        "PDF": "https://arxiv.org/pdf/2507.07276"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on developing a test for feature importance in machine learning models, not on any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07395",
      "abstract": "Reconstructing and segmenting scenes from unconstrained photo collections obtained from the Internet is a novel but challenging task. Unconstrained photo collections are easier to get than well-captured photo collections. These unconstrained images suffer from inconsistent lighting and transient occlusions, which makes segmentation challenging. Previous segmentation methods cannot address transient occlusions or accurately restore the scene's lighting conditions. Therefore, we propose Seg-Wild, an interactive segmentation method based on 3D Gaussian Splatting for unconstrained image collections, suitable for in-the-wild scenes. We integrate multi-dimensional feature embeddings for each 3D Gaussian and calculate the feature similarity between the feature embeddings and the segmentation target to achieve interactive segmentation in the 3D scene. Additionally, we introduce the Spiky 3D Gaussian Cutter (SGC) to smooth abnormal 3D Gaussians. We project the 3D Gaussians onto a 2D plane and calculate the ratio of 3D Gaussians that need to be cut using the SAM mask. We also designed a benchmark to evaluate segmentation quality in in-the-wild scenes. Experimental results demonstrate that compared to previous methods, Seg-Wild achieves better segmentation results and reconstruction quality. Our code will be available at https://github.com/Sugar0725/Seg-Wild.",
      "authors": [
        "Yongtang Bao",
        "Chengjie Tang",
        "Yuze Wang and Haojie Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:26:17+00:00",
          "link": "https://arxiv.org/abs/2507.07395v1",
          "size": "14945kb",
          "version": "v1"
        }
      ],
      "title": "Seg-Wild: Interactive Segmentation based on 3D Gaussian Splatting for Unconstrained Image Collections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07395",
        "HTML": "https://arxiv.org/html/2507.07395v1",
        "PDF": "https://arxiv.org/pdf/2507.07395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes an interactive segmentation method for unconstrained image collections. It does not pertain to LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07915",
      "abstract": "We study non-atomic congestion games on parallel-link networks with affine cost functions. We investigate the power of machine-learned predictions in the design of coordination mechanisms aimed at minimizing the impact of selfishness. Our main results demonstrate that enhancing coordination mechanisms with a simple advice on the input rate can optimize the social cost whenever the advice is accurate (consistency), while only incurring minimal losses even when the predictions are arbitrarily inaccurate (bounded robustness). Moreover, we provide a full characterization of the consistent mechanisms that holds for all monotone cost functions, and show that our suggested mechanism is optimal with respect to the robustness. We further explore the notion of smoothness within this context: we extend our mechanism to achieve error-tolerance, i.e. we provide an approximation guarantee that degrades smoothly as a function of the prediction error, up to a predetermined threshold, while achieving a bounded robustness.",
      "authors": [
        "George Christodoulou",
        "Vasilis Christoforidis",
        "Alkmini Sgouritsa",
        "Ioannis Vlachos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:49:33+00:00",
          "link": "https://arxiv.org/abs/2507.07915v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Improving the Price of Anarchy via Predictions in Parallel-Link Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07915",
        "HTML": "https://arxiv.org/html/2507.07915v1",
        "PDF": "https://arxiv.org/pdf/2507.07915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses congestion games and machine-learned predictions for coordination mechanisms, not processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02409",
      "abstract": "Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.",
      "authors": [
        "Zihan Tan",
        "Suyuan Huang",
        "Guancheng Wan",
        "Wenke Huang",
        "He Li and Mang Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:04:49+00:00",
          "link": "https://arxiv.org/abs/2507.02409v1",
          "size": "2570kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:14:21+00:00",
          "link": "https://arxiv.org/abs/2507.02409v2",
          "size": "2570kb",
          "version": "v2"
        }
      ],
      "title": "S2FGL: Spatial Spectral Federated Graph Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02409",
        "HTML": "https://arxiv.org/html/2507.02409v2",
        "PDF": "https://arxiv.org/pdf/2507.02409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Federated Graph Learning for graph signal propagation in spatial and spectral domains but does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05683",
      "abstract": "A novel original procedure of encryption/decryption based on the polyadic algebraic structures and on signal processing methods is proposed. First, we use signals with integer amplitudes to send information. Then we use polyadic techniques to transfer the plaintext into series of special integers. The receiver restores the plaintext using special rules and systems of equations.",
      "authors": [
        "Steven Duplij and Qiang Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T05:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.05683v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Polyadic encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05683",
        "HTML": "https://arxiv.org/html/2507.05683",
        "PDF": "https://arxiv.org/pdf/2507.05683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a new encryption/decryption method using polyadic algebra and signal processing, which is irrelevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07138",
      "abstract": "Graph Neural Networks (GNNs) often struggle to capture the link-specific structural patterns crucial for accurate link prediction, as their node-centric message-passing schemes overlook the subgraph structures connecting a pair of nodes. Existing methods to inject such structural context either incur high computational cost or rely on simplistic heuristics (e.g., common neighbor counts) that fail to model multi-hop dependencies. We introduce SP4LP (Shortest Path for Link Prediction), a novel framework that combines GNN-based node encodings with sequence modeling over shortest paths. Specifically, SP4LP first applies a GNN to compute representations for all nodes, then extracts the shortest path between each candidate node pair and processes the resulting sequence of node embeddings using a sequence model. This design enables SP4LP to capture expressive multi-hop relational patterns with computational efficiency. Empirically, SP4LP achieves state-of-the-art performance across link prediction benchmarks. Theoretically, we prove that SP4LP is strictly more expressive than standard message-passing GNNs and several state-of-the-art structural features methods, establishing it as a general and principled approach for link prediction in graphs.",
      "authors": [
        "Francesco Ferrini",
        "Veronica Lachi",
        "Antonio Longa",
        "Bruno Lepri",
        "Andrea Passerini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:37:19+00:00",
          "link": "https://arxiv.org/abs/2507.07138v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "GNNs Meet Sequence Models Along the Shortest-Path: an Expressive Method for Link Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07138",
        "HTML": "https://arxiv.org/html/2507.07138v1",
        "PDF": "https://arxiv.org/pdf/2507.07138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces SP4LP for link prediction using GNNs and sequence models without focusing on LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07283",
      "abstract": "Nonogram is a popular combinatorial puzzle (similar in nature to Sudoku or Minesweeper) in which a puzzle solver must determine if there exists a setting of the puzzle parameters that satisfy a given set of constraints. It has long been known that the problem of deciding if a solution exists is a computationally difficult problem. Despite this fact, humans still seem to enjoy playing it. This work aims to reconcile these seemingly contradictory facts by (1) analyzing the complexity of the inference problem for Nonogram (the problem of determining if there exists a puzzle parameter that can be inferred from the constraints without guessing) and (2) experimentally establishing the existence of a phase transition behavior for this inference problem. Our results show that the difficulty of the inference problem is largely determined by the density of filled cells (positive parameters) in a given puzzle. Along the way we implement an efficient encoding of a Nonogram board as a Boolean formula in Conjunctive Normal Form (CNF) through the use of regular expressions in order to make our experiments feasible.",
      "authors": [
        "Aaron Foote and Danny Krizanc"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:07:31+00:00",
          "link": "https://arxiv.org/abs/2507.07283v1",
          "size": "484kb",
          "version": "v1"
        }
      ],
      "title": "Nonogram: Complexity of Inference and Phase Transition Behavior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07283",
        "HTML": "https://arxiv.org/html/2507.07283v1",
        "PDF": "https://arxiv.org/pdf/2507.07283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper delves into the complexity of inference and phase transition behavior for the game Nonogram, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21513",
      "abstract": "Creating high-quality, generalizable speech-driven 3D talking heads remains a persistent challenge. Previous methods achieve satisfactory results for fixed viewpoints and small-scale audio variations, but they struggle with large head rotations and out-of-distribution (OOD) audio. Moreover, they are constrained by the need for time-consuming, identity-specific training. We believe the core issue lies in the lack of sufficient 3D priors, which limits the extrapolation capabilities of synthesized talking heads. To address this, we propose GGTalker, which synthesizes talking heads through a combination of generalizable priors and identity-specific adaptation. We introduce a two-stage Prior-Adaptation training strategy to learn Gaussian head priors and adapt to individual characteristics. We train Audio-Expression and Expression-Visual priors to capture the universal patterns of lip movements and the general distribution of head textures. During the Customized Adaptation, individual speaking styles and texture details are precisely modeled. Additionally, we introduce a color MLP to generate fine-grained, motion-aligned textures and a Body Inpainter to blend rendered results with the background, producing indistinguishable, photorealistic video frames. Comprehensive experiments show that GGTalker achieves state-of-the-art performance in rendering quality, 3D consistency, lip-sync accuracy, and training efficiency.",
      "authors": [
        "Wentao Hu",
        "Shunkai Li",
        "Ziqiao Peng",
        "Haoxian Zhang",
        "Fan Shi",
        "Xiaoqiang Liu",
        "Pengfei Wan",
        "Di Zhang",
        "Hui Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:37:18+00:00",
          "link": "https://arxiv.org/abs/2506.21513v1",
          "size": "33502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T06:36:05+00:00",
          "link": "https://arxiv.org/abs/2506.21513v2",
          "size": "33503kb",
          "version": "v2"
        }
      ],
      "title": "GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21513",
        "HTML": "https://arxiv.org/html/2506.21513v2",
        "PDF": "https://arxiv.org/pdf/2506.21513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It discusses the synthesis of talking heads using Gaussian priors and adaptation, and does not involve any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05289",
      "abstract": "Code readability is one of the main aspects of code quality, influenced by various properties like identifier names, comments, code structure, and adherence to standards. However, measuring this attribute poses challenges in both industry and academia. While static analysis tools assess attributes such as code smells and comment percentage, code reviews introduce an element of subjectivity. This paper explores using Large Language Models (LLMs) to evaluate code quality attributes related to its readability in a standardized, reproducible, and consistent manner. We conducted a quasi-experiment study to measure the effects of code changes on Large Language Model (LLM)s interpretation regarding its readability quality attribute. Nine LLMs were tested, undergoing three interventions: removing comments, replacing identifier names with obscure names, and refactoring to remove code smells. Each intervention involved 10 batch analyses per LLM, collecting data on response variability. We compared the results with a known reference model and tool. The results showed that all LLMs were sensitive to the interventions, with agreement with the reference classifier being high for the original and refactored code scenarios. The LLMs demonstrated a strong semantic sensitivity that the reference model did not fully capture. A thematic analysis of the LLMs reasoning confirmed their evaluations directly reflected the nature of each intervention. The models also exhibited response variability, with 9.37% to 14.58% of executions showing a standard deviation greater than zero, indicating response oscillation, though this did not always compromise the statistical significance of the results. LLMs demonstrated potential for evaluating semantic quality aspects, such as coherence between identifier names, comments, and documentation with code purpose.",
      "authors": [
        "Igor Regis da Silva Simoes",
        "Elaine Venson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T11:08:03+00:00",
          "link": "https://arxiv.org/abs/2507.05289v1",
          "size": "218kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T18:24:41+00:00",
          "link": "https://arxiv.org/abs/2507.05289v2",
          "size": "218kb",
          "version": "v2"
        }
      ],
      "title": "Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05289",
        "HTML": "https://arxiv.org/html/2507.05289v2",
        "PDF": "https://arxiv.org/pdf/2507.05289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores code quality evaluation using LLMs, without dealing with the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07302",
      "abstract": "Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.",
      "authors": [
        "Ashish Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:01:32+00:00",
          "link": "https://arxiv.org/abs/2507.07302v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07302",
        "HTML": "https://arxiv.org/html/2507.07302v1",
        "PDF": "https://arxiv.org/pdf/2507.07302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates applying LLMs to multi-agent reinforcement learning tasks, focusing on efficient exploration and path planning, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07788",
      "abstract": "Many model order reduction (MOR) methods rely on the computation of an orthonormal basis of a subspace onto which the large full order model is projected. Numerically, this entails the orthogonalization of a set of vectors. The nature of the MOR process imposes several requirements for the orthogonalization process. Firstly, MOR is oftentimes performed in an adaptive or iterative manner, where the quality of the reduced order model, i.e., the dimension of the reduced subspace, is decided on the fly. Therefore, it is important that the orthogonalization routine can be executed iteratively. Secondly, one possibly has to deal with high-dimensional arrays of abstract vectors that do not allow explicit access to entries, making it difficult to employ so-called `orthogonal triangularization algorithms' such as Householder QR.\n  For these reasons, (modified) Gram-Schmidt-type algorithms are commonly used in MOR applications. These methods belong to the category of `triangular orthogonalization' algorithms that do not rely on elementwise access to the vectors and can be easily updated. Recently, algorithms like shifted Cholesky QR have gained attention. These also belong to the aforementioned category and have proven their aptitude for MOR algorithms in previous studies. A key benefit of these methods is that they are communication-avoiding, leading to vastly superior performance on memory-bandwidth-limited problems and parallel or distributed architectures. This work formulates an efficient updating scheme for Cholesky QR algorithms and proposes an improved shifting strategy for highly ill-conditioned matrices.\n  The proposed algorithmic extensions are validated with numerical experiments on a laptop and computation server.",
      "authors": [
        "Maximilian Bindhak and Art J. R. Pelling and Jens Saak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:10:36+00:00",
          "link": "https://arxiv.org/abs/2507.07788v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Towards an Efficient Shifted Cholesky QR for Applications in Model Order Reduction using pyMOR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07788",
        "PDF": "https://arxiv.org/pdf/2507.07788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on efficient orthogonalization processes for model order reduction, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07867",
      "abstract": "Neural audio codecs and autoencoders have emerged as versatile models for audio compression, transmission, feature-extraction, and latent-space generation. However, a key limitation is that most are trained to maximize reconstruction fidelity, often neglecting the specific latent structure necessary for optimal performance in diverse downstream applications. We propose a simple, post-hoc framework to address this by modifying the bottleneck of a pre-trained autoencoder. Our method introduces a \"Re-Bottleneck\", an inner bottleneck trained exclusively through latent space losses to instill user-defined structure. We demonstrate the framework's effectiveness in three experiments. First, we enforce an ordering on latent channels without sacrificing reconstruction quality. Second, we align latents with semantic embeddings, analyzing the impact on downstream diffusion modeling. Third, we introduce equivariance, ensuring that a filtering operation on the input waveform directly corresponds to a specific transformation in the latent space. Ultimately, our Re-Bottleneck framework offers a flexible and efficient way to tailor representations of neural audio models, enabling them to seamlessly meet the varied demands of different applications with minimal additional training.",
      "authors": [
        "Dimitrios Bralios",
        "Jonah Casebeer",
        "Paris Smaragdis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:47:43+00:00",
          "link": "https://arxiv.org/abs/2507.07867v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07867",
        "HTML": "https://arxiv.org/html/2507.07867v1",
        "PDF": "https://arxiv.org/pdf/2507.07867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on latent restructuring for neural audio autoencoders, specifically addressing audio compression and feature extraction. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.10016",
      "abstract": "The socioeconomic background of people and how they use standard forms of language are not independent, as demonstrated in various sociolinguistic studies. However, the extent to which these correlations may be influenced by the mixing of people from different socioeconomic classes remains relatively unexplored from a quantitative perspective. In this work we leverage geotagged tweets and transferable computational methods to map deviations from standard English on a large scale, in seven thousand administrative areas of England and Wales. We combine these data with high-resolution income maps to assign a proxy socioeconomic indicator to home-located users. Strikingly, across eight metropolitan areas we find a consistent pattern suggesting that the more different socioeconomic classes mix, the less interdependent the frequency of their departures from standard grammar and their income become. Further, we propose an agent-based model of linguistic variety adoption that sheds light on the mechanisms that produce the observations seen in the data.",
      "authors": [
        "Thomas Louf",
        "Jos\\'e J. Ramasco",
        "David S\\'anchez",
        "M\\'arton Karsai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-19T14:55:50+00:00",
          "link": "https://arxiv.org/abs/2307.10016v1",
          "size": "6995kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:03:19+00:00",
          "link": "https://arxiv.org/abs/2307.10016v2",
          "size": "5584kb",
          "version": "v2"
        }
      ],
      "title": "When Dialects Collide: How Socioeconomic Mixing Affects Language Use",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.10016",
        "HTML": "https://arxiv.org/html/2307.10016v2",
        "PDF": "https://arxiv.org/pdf/2307.10016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses data analysis methods on geotagged tweets to study language use. It involves data collection and a computational study on language, but does not focus primarily on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05282",
      "abstract": "Efficient data exploration is crucial as data becomes increasingly important for accelerating processes, improving forecasts and developing new business models. Data consumers often spend 25-98 % of their time searching for suitable data due to the exponential growth, heterogeneity and distribution of data. Data catalogs can support and accelerate data exploration by using metadata to answer user queries. However, as metadata creation and maintenance is often a manual process, it is time-consuming and requires expertise. This study investigates whether LLMs can automate metadata maintenance of text-based data and generate high-quality DCAT-compatible metadata. We tested zero-shot and few-shot prompting strategies with LLMs from different vendors for generating metadata such as titles and keywords, along with a fine-tuned model for classification. Our results show that LLMs can generate metadata comparable to human-created content, particularly on tasks that require advanced semantic understanding. Larger models outperformed smaller ones, and fine-tuning significantly improves classification accuracy, while few-shot prompting yields better results in most cases. Although LLMs offer a faster and reliable way to create metadata, a successful application requires careful consideration of task-specific criteria and domain context.",
      "authors": [
        "Lennart Busch",
        "Daniel Tebernum and Gissel Velarde"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T10:49:37+00:00",
          "link": "https://arxiv.org/abs/2507.05282v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "Exploring LLM Capabilities in Extracting DCAT-Compatible Metadata for Data Cataloging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05282",
        "HTML": "https://arxiv.org/html/2507.05282",
        "PDF": "https://arxiv.org/pdf/2507.05282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study investigates LLMs for metadata generation, which involves some level of data preparation and fine-tuning, but it primarily focuses on extracting metadata rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07367",
      "abstract": "Existing machine learning methods for molecular (e.g., gene) embeddings are restricted to specific tasks or data modalities, limiting their effectiveness within narrow domains. As a result, they fail to capture the full breadth of gene functions and interactions across diverse biological contexts. In this study, we have systematically evaluated knowledge representations of biomolecules across multiple dimensions representing a task-agnostic manner spanning three major data sources, including omics experimental data, literature-derived text data, and knowledge graph-based representations. To distinguish between meaningful biological signals from chance correlations, we devised an adjusted variant of Singular Vector Canonical Correlation Analysis (SVCCA) that quantifies signal redundancy and complementarity across different data modalities and sources. These analyses reveal that existing embeddings capture largely non-overlapping molecular signals, highlighting the value of embedding integration. Building on this insight, we propose Platform for Representation and Integration of multimodal Molecular Embeddings (PRISME), a machine learning based workflow using an autoencoder to integrate these heterogeneous embeddings into a unified multimodal representation. We validated this approach across various benchmark tasks, where PRISME demonstrated consistent performance, and outperformed individual embedding methods in missing value imputations. This new framework supports comprehensive modeling of biomolecules, advancing the development of robust, broadly applicable multimodal embeddings optimized for downstream biomedical machine learning applications.",
      "authors": [
        "Erika Yilin Zheng",
        "Yu Yan",
        "Baradwaj Simha Sankar",
        "Ethan Ji",
        "Steven Swee",
        "Irsyad Adam",
        "Ding Wang",
        "Alexander Russell Pelletier",
        "Alex Bui",
        "Wei Wang",
        "Peipei Ping"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T01:18:50+00:00",
          "link": "https://arxiv.org/abs/2507.07367v1",
          "size": "1403kb",
          "version": "v1"
        }
      ],
      "title": "Platform for Representation and Integration of multimodal Molecular Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07367",
        "HTML": "https://arxiv.org/html/2507.07367v1",
        "PDF": "https://arxiv.org/pdf/2507.07367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses embedding integration for biomolecular data but does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07649",
      "abstract": "Hybrid solvers for combinatorial optimization problems combine the advantages of classical and quantum computing to overcome difficult computational challenges. Although their theoretical performance seems promising, their practical applicability is challenging due to the lack of a technological stack that can seamlessly integrate quantum solutions with existing classical optimization frameworks. We tackle this challenge by introducing the ProvideQ toolbox, a software tool that enables users to easily adapt and configure hybrid solvers via Meta-Solver strategies. A Meta-Solver strategy implements decomposition techniques, which splits problems into classical and quantum subroutines. The ProvideQ toolbox enables the interactive creation of such decompositions via a Meta-Solver configuration tool. It combines well-established classical optimization techniques with quantum circuits that are seamlessly executable on multiple backends. This paper introduces the technical details of the ProvideQ toolbox, explains its architecture, and demonstrates possible applications for several real-world use cases. Our proof of concept shows that Meta-Solver strategies already enable the application of quantum subroutines today, however, more sophisticated hardware is required to make their performance competitive.",
      "authors": [
        "Domenik Eichhorn",
        "Nick Poser",
        "Maximilian Schweikart",
        "Ina Schaefer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.07649v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "ProvideQ: A Quantum Optimization Toolbox",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07649",
        "HTML": "https://arxiv.org/html/2507.07649v1",
        "PDF": "https://arxiv.org/pdf/2507.07649"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a quantum optimization toolbox and discusses hybrid solvers, but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07917",
      "abstract": "Unbalanced optimal transport (UOT) is a natural extension of optimal transport (OT) allowing comparison between measures of different masses. It arises naturally in machine learning by offering a robustness against outliers. The aim of this work is to provide convergence rates of the regularized transport cost and plans towards their original solution when both measures are weighted sums of Dirac masses.",
      "authors": [
        "Luca Nenna",
        "Paul Pegon",
        "Louis Tocquec"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:58:59+00:00",
          "link": "https://arxiv.org/abs/2507.07917v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "Convergence rates for regularized unbalanced optimal transport: the discrete case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07917",
        "HTML": "https://arxiv.org/html/2507.07917v1",
        "PDF": "https://arxiv.org/pdf/2507.07917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on convergence rates for unbalanced optimal transport, with no mention of LLM training data processing or data engineering operations specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.16928",
      "abstract": "We discuss a class of coupled systems of nonlocal nonlinear balance laws modeling multilane traffic, with the nonlocality present in both convective and source terms. The uniqueness and existence of the entropy solution are proven via doubling of the variables arguments and convergent finite volume approximations, respectively. The primary goal is to establish that the finite volume numerical approximations of the system converge to the unique entropy solution at a rate of $\\sqrt{\\Delta t}$, even when using relatively less regular one-sided kernels, compared to the globally smooth kernels analyzed in [Num. Math., 156(1):237-271, 2024] and [IMA J. Numer. Anal., 44(6):3354-3392, 2024]. The applicability of the proven theory to a general class of systems of nonlocal balance laws coupled strongly through the convective part and weakly through the source part, is indicated. As the support of the kernel tends to zero, the convergence of the entropy solutions of the proposed model to its local counterparts [SIAM J. Math. Anal., 51: 3694--3713, 2019] is also discussed. Numerical simulations illustrating the behavior of the entropy solutions of the coupled nonlocal systems are also shown.",
      "authors": [
        "Aekta Aggarwal",
        "Helge Holden",
        "Ganesh Vaidya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-28T09:53:12+00:00",
          "link": "https://arxiv.org/abs/2312.16928v1",
          "size": "295kb",
          "version": "v1"
        },
        {
          "date": "2024-10-24T18:51:29+00:00",
          "link": "https://arxiv.org/abs/2312.16928v2",
          "size": "2125kb",
          "version": "v2"
        },
        {
          "date": "2024-10-28T05:20:01+00:00",
          "link": "https://arxiv.org/abs/2312.16928v3",
          "size": "3271kb",
          "version": "v3"
        },
        {
          "date": "2025-05-10T12:23:23+00:00",
          "link": "https://arxiv.org/abs/2312.16928v4",
          "size": "2156kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T09:44:41+00:00",
          "link": "https://arxiv.org/abs/2312.16928v5",
          "size": "2143kb",
          "version": "v5"
        }
      ],
      "title": "Error Estimates for Systems of Nonlocal Balance Laws Modeling Dense Multilane Vehicular Traffic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.16928",
        "PDF": "https://arxiv.org/pdf/2312.16928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses numerical approximations for modeling dense vehicular traffic, without any mention of LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.04775",
      "abstract": "The Koopman operator plays a crucial role in analyzing the global behavior of dynamical systems. Existing data-driven methods for approximating the Koopman operator or discovering the governing equations of the underlying system typically require a fixed set of basis functions, also called dictionary. The optimal choice of basis functions is highly problem-dependent and often requires domain knowledge. We present a novel gradient descent-based optimization framework for learning suitable and interpretable basis functions from data and show how it can be used in combination with EDMD, SINDy, and PDE-FIND. We illustrate the efficacy of the proposed approach with the aid of various benchmark problems such as the Ornstein-Uhlenbeck process, Chua's circuit, a nonlinear heat equation, as well as protein-folding data.",
      "authors": [
        "Mohammad Tabish",
        "Neil K. Chada",
        "Stefan Klus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T15:15:27+00:00",
          "link": "https://arxiv.org/abs/2411.04775v1",
          "size": "2438kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T11:20:52+00:00",
          "link": "https://arxiv.org/abs/2411.04775v2",
          "size": "2759kb",
          "version": "v2"
        }
      ],
      "title": "Learning dynamical systems from data: Gradient-based dictionary optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04775",
        "HTML": "https://arxiv.org/html/2411.04775",
        "PDF": "https://arxiv.org/pdf/2411.04775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for learning basis functions for dynamical systems using data, without relevance to LLM training data processing."
      },
      "tasks": [
        "Protein Folding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07317",
      "abstract": "Recent advances in instruction-guided image editing underscore the need for effective automated evaluation. While Vision-Language Models (VLMs) have been explored as judges, open-source models struggle with alignment, and proprietary models lack transparency and cost efficiency. Additionally, no public training datasets exist to fine-tune open-source VLMs, only small benchmarks with diverse evaluation schemes. To address this, we introduce ADIEE, an automated dataset creation approach which is then used to train a scoring model for instruction-guided image editing evaluation. We generate a large-scale dataset with over 100K samples and use it to fine-tune a LLaVA-NeXT-8B model modified to decode a numeric score from a custom token. The resulting scorer outperforms all open-source VLMs and Gemini-Pro 1.5 across all benchmarks, achieving a 0.0696 (+17.24%) gain in score correlation with human ratings on AURORA-Bench, and improving pair-wise comparison accuracy by 4.03% (+7.21%) on GenAI-Bench and 4.75% (+9.35%) on AURORA-Bench, respectively, compared to the state-of-the-art. The scorer can act as a reward model, enabling automated best edit selection and model fine-tuning. Notably, the proposed scorer can boost MagicBrush model's average evaluation score on ImagenHub from 5.90 to 6.43 (+8.98%).",
      "authors": [
        "Sherry X. Chen",
        "Yi Wei",
        "Luowei Zhou",
        "Suren Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:29:47+00:00",
          "link": "https://arxiv.org/abs/2507.07317v1",
          "size": "18069kb",
          "version": "v1"
        }
      ],
      "title": "ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07317",
        "HTML": "https://arxiv.org/html/2507.07317v1",
        "PDF": "https://arxiv.org/pdf/2507.07317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to LLM training data processing by presenting ADIEE for automated dataset creation and using the generated dataset to fine-tune a model, focusing on improving data quality and methodologies for dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07603",
      "abstract": "This paper presents enhancements to the SAM2 framework for video object tracking task, addressing challenges such as occlusions, background clutter, and target reappearance. We introduce a hierarchical motion estimation strategy, combining lightweight linear prediction with selective non-linear refinement to improve tracking accuracy without requiring additional training. In addition, we optimize the memory bank by distinguishing long-term and short-term memory frames, enabling more reliable tracking under long-term occlusions and appearance changes. Experimental results show consistent improvements across different model scales. Our method achieves state-of-the-art performance on LaSOT and LaSOText with the large model, achieving 9.6% and 7.2% relative improvements in AUC over the original SAM2, and demonstrates even larger relative gains on smaller models, highlighting the effectiveness of our trainless, low-overhead improvements for boosting long-term tracking performance. The code is available at https://github.com/LouisFinner/HiM2SAM.",
      "authors": [
        "Ruixiang Chen",
        "Guolei Sun",
        "Yawei Li",
        "Jie Qin",
        "Luca Benini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:05:11+00:00",
          "link": "https://arxiv.org/abs/2507.07603v1",
          "size": "2505kb",
          "version": "v1"
        }
      ],
      "title": "HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07603",
        "HTML": "https://arxiv.org/html/2507.07603v1",
        "PDF": "https://arxiv.org/pdf/2507.07603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improvements in video object tracking frameworks and does not discuss any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07654",
      "abstract": "Let $f$ and $g$ be Boolean functions over a finite Abelian group $\\mathcal{G}$, where $g$ is fully known, and we have {\\em query access} to $f$, that is, given any $x \\in \\mathcal{G}$ we can get the value $f(x)$. We study the tolerant isomorphism testing problem: given $\\epsilon \\geq 0$ and $\\tau > 0$, we seek to determine, with minimal queries, whether there exists an automorphism $\\sigma$ of $\\mathcal{G}$ such that the fractional Hamming distance between $f \\circ \\sigma$ and $g$ is at most $\\epsilon$, or whether for all automorphisms $\\sigma$, the distance is at least $\\epsilon + \\tau$.\n  We design an efficient tolerant testing algorithm for this problem, with query complexity $\\mathrm{poly}\\left( s, 1/\\tau \\right)$, where $s$ bounds the spectral norm of $g$. Additionally, we present an improved algorithm when $g$ is Fourier sparse.\n  Our approach uses key concepts from Abelian group theory and Fourier analysis, including the annihilator of a subgroup, Pontryagin duality, and a pseudo inner-product for finite Abelian groups. We believe these techniques will find further applications in property testing.",
      "authors": [
        "Swarnalipa Datta",
        "Arijit Ghosh",
        "Chandrima Kayal",
        "Manaswi Paraashar",
        "Manmatha Roy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:26:15+00:00",
          "link": "https://arxiv.org/abs/2507.07654v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Testing Isomorphism of Boolean Functions over Finite Abelian Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07654",
        "HTML": "https://arxiv.org/html/2507.07654v1",
        "PDF": "https://arxiv.org/pdf/2507.07654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Boolean function isomorphism testing over finite Abelian groups and does not discuss any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07659",
      "abstract": "Serving the energy demand with renewable energy is hindered by its limited availability near load centres (i.e. places where the energy demand is high). To address this challenge, the concept of Remote Renewable Energy Hubs (RREH) emerges as a promising solution. RREHs are energy hubs located in areas with abundant renewable energy sources, such as sun in the Sahara Desert or wind in Greenland. In these hubs, renewable energy sources are used to synthetise energy molecules. To produce specific energy molecules, a tailored hub configuration must be designed, which means choosing a set of technologies that are interacting with each other as well as defining how they are integrated in their local environment. The plurality of technologies that may be employed in RREHs results in a large diversity of hubs. In order to characterize this diversity, we propose in this paper a taxonomy for accurately defining these hubs. This taxonomy allows to better describe and compare designs of hubs as well as to identify new ones. Thus, it may guide policymakers and engineers in hub design, contributing to cost efficiency and/or improving local integration.",
      "authors": [
        "Victor Dachet",
        "Antoine Dubois",
        "Bardhyl Miftari",
        "Rapha\\\"el Fonteneau and Damien Ernst"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:35:22+00:00",
          "link": "https://arxiv.org/abs/2507.07659v1",
          "size": "5456kb",
          "version": "v1"
        }
      ],
      "title": "Remote Renewable Energy Hubs: a Taxonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07659",
        "HTML": "https://arxiv.org/html/2507.07659v1",
        "PDF": "https://arxiv.org/pdf/2507.07659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a taxonomy for remote renewable energy hubs and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.00115",
      "abstract": "Currently, the best known tradeoff between approximation ratio and complexity for the Sparsest Cut problem is achieved by the algorithm in [Sherman, FOCS 2009]: it computes $O(\\sqrt{(\\log n)/\\varepsilon})$-approximation using $O(n^\\varepsilon\\log^{O(1)}n)$ maxflows for any $\\varepsilon\\in[\\Theta(1/\\log n),\\Theta(1)]$. It works by solving the SDP relaxation of [Arora-Rao-Vazirani, STOC 2004] using the Multiplicative Weights Update algorithm (MW) of [Arora-Kale, JACM 2016]. To implement one MW step, Sherman approximately solves a multicommodity flow problem using another application of MW. Nested MW steps are solved via a certain ``chaining'' algorithm that combines results of multiple calls to the maxflow algorithm. We present an alternative approach that avoids solving the multicommodity flow problem and instead computes ``violating paths''. This simplifies Sherman's algorithm by removing a need for a nested application of MW, and also allows parallelization: we show how to compute $O(\\sqrt{(\\log n)/\\varepsilon})$-approximation via $O(\\log^{O(1)}n)$ maxflows using $O(n^\\varepsilon)$ processors. We also revisit Sherman's chaining algorithm, and present a simpler version together with a new analysis.",
      "authors": [
        "Vladimir Kolmogorov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-30T20:04:06+00:00",
          "link": "https://arxiv.org/abs/2307.00115v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2023-07-06T11:20:23+00:00",
          "link": "https://arxiv.org/abs/2307.00115v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2023-11-29T20:15:52+00:00",
          "link": "https://arxiv.org/abs/2307.00115v3",
          "size": "28kb",
          "version": "v3"
        },
        {
          "date": "2024-04-08T13:22:15+00:00",
          "link": "https://arxiv.org/abs/2307.00115v4",
          "size": "31kb",
          "version": "v4"
        },
        {
          "date": "2025-07-10T09:23:44+00:00",
          "link": "https://arxiv.org/abs/2307.00115v5",
          "size": "31kb",
          "version": "v5"
        }
      ],
      "title": "A simpler and parallelizable $O(\\sqrt{\\log n})$-approximation algorithm for Sparsest Cut",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.00115",
        "HTML": "https://arxiv.org/html/2307.00115v5",
        "PDF": "https://arxiv.org/pdf/2307.00115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an approximation algorithm for the Sparsest Cut problem and does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.16914",
      "abstract": "The pests captured with imaging devices may be relatively small in size compared to the entire images, and complex backgrounds have colors and textures similar to those of the pests, which hinders accurate feature extraction and makes pest identification challenging. The key to pest identification is to create a model capable of detecting regions of interest (ROIs) and transforming them into better ones for attention and discriminative learning. To address these problems, we will study how to generate and update the ROIs via multiscale cross-attention fusion as well as how to be highly robust to complex backgrounds and scale problems. Therefore, we propose a novel ROI-aware multiscale cross-attention vision transformer (ROI-ViT). The proposed ROI-ViT is designed using dual branches, called Pest and ROI branches, which take different types of maps as input: Pest images and ROI maps. To render such ROI maps, ROI generators are built using soft segmentation and a class activation map and then integrated into the ROI-ViT backbone. Additionally, in the dual branch, complementary feature fusion and multiscale hierarchies are implemented via a novel multiscale cross-attention fusion. The class token from the Pest branch is exchanged with the patch tokens from the ROI branch, and vice versa. The experimental results show that the proposed ROI-ViT achieves 81.81%, 99.64%, and 84.66% for IP102, D0, and SauTeg pest datasets, respectively, outperforming state-of-the-art (SOTA) models, such as MViT, PVT, DeiT, Swin-ViT, and EfficientNet. More importantly, for the new challenging dataset IP102(CBSS) that contains only pest images with complex backgrounds and small sizes, the proposed model can maintain high recognition accuracy, whereas that of other SOTA models decrease sharply, demonstrating that our model is more robust to complex background and scale problems.",
      "authors": [
        "Ga-Eun Kim",
        "Chang-Hwan Son"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-28T09:16:27+00:00",
          "link": "https://arxiv.org/abs/2312.16914v1",
          "size": "2084kb",
          "version": "v1"
        }
      ],
      "title": "ROI-Aware Multiscale Cross-Attention Vision Transformer for Pest Image Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.16914",
        "PDF": "https://arxiv.org/pdf/2312.16914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on pest image identification using a vision transformer model but does not discuss LLM training data processing or any related data engineering methods."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.19557",
      "abstract": "Text-to-motion generative models span a wide range of 3D human actions but struggle with nuanced stylistic attributes such as a \"Chicken\" style. Due to the scarcity of style-specific data, existing approaches pull the generative prior towards a reference style, which often results in out-of-distribution low quality generations. In this work, we introduce LoRA-MDM, a lightweight framework for motion stylization that generalizes to complex actions while maintaining editability. Our key insight is that adapting the generative prior to include the style, while preserving its overall distribution, is more effective than modifying each individual motion during generation. Building on this idea, LoRA-MDM learns to adapt the prior to include the reference style using only a few samples. The style can then be used in the context of different textual prompts for generation. The low-rank adaptation shifts the motion manifold in a semantically meaningful way, enabling realistic style infusion even for actions not present in the reference samples. Moreover, preserving the distribution structure enables advanced operations such as style blending and motion editing. We compare LoRA-MDM to state-of-the-art stylized motion generation methods and demonstrate a favorable balance between text fidelity and style consistency.",
      "authors": [
        "Haim Sawdayee",
        "Chuan Guo",
        "Guy Tevet",
        "Bing Zhou",
        "Jian Wang",
        "Amit H. Bermano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T11:23:34+00:00",
          "link": "https://arxiv.org/abs/2503.19557v1",
          "size": "3926kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T08:06:45+00:00",
          "link": "https://arxiv.org/abs/2503.19557v2",
          "size": "3377kb",
          "version": "v2"
        }
      ],
      "title": "Dance Like a Chicken: Low-Rank Stylization for Human Motion Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19557",
        "HTML": "https://arxiv.org/html/2503.19557v2",
        "PDF": "https://arxiv.org/pdf/2503.19557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a generative model for motion stylization in 3D human actions, emphasizing style adaptation and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07429",
      "abstract": "The uncertainty of wireless communication poses significant challenges to platoon control performance. Aiming at alleviating the influence of non-ideal communication on the platoon system, this paper proposes a distributed and adaptive model predictive control (MPC) method. First of all, to deal with the transmission uncertainty caused by non-ideal communication, compensated data packets are customized for each vehicle. Then, an adaptive model predictive control method is proposed to balance the system response speed and tracking accuracy. Furthermore, to reduce the computational requirements of the vehicle platoon system, a predictive time-domain update strategy suitable for non-ideal communication was introduced. Finally, the sufficient conditions for ensuring the feasibility of the MPC algorithm and the stability of the closed-loop platoon control system are theoretically analyzed. The simulation results show that the proposed method significantly reduces the computing resource requirements for solving the optimization problem while ensuring satisfactory system performance.",
      "authors": [
        "Qiaoni Han",
        "Chengfei Xu and Zhiqiang Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:52:39+00:00",
          "link": "https://arxiv.org/abs/2507.07429v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "Distributed and adaptive model predictive control for vehicle platoon systems under non-ideal communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07429",
        "HTML": "https://arxiv.org/html/2507.07429v1",
        "PDF": "https://arxiv.org/pdf/2507.07429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with model predictive control for vehicle platoon systems under non-ideal communication, which does not relate to LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07730",
      "abstract": "Promptable segmentation, introduced by the Segment Anything Model (SAM), is a promising approach for medical imaging, as it enables clinicians to guide and refine model predictions interactively. However, SAM's architecture is designed for 2D images and does not extend naturally to 3D volumetric data such as CT or MRI scans. Adapting 2D models to 3D typically involves autoregressive strategies, where predictions are propagated slice by slice, resulting in increased inference complexity. Processing large 3D volumes also requires significant computational resources, often leading existing 3D methods to also adopt complex strategies like sliding-window inference to manage memory usage, at the cost of longer inference times and greater implementation complexity. In this paper, we present a simplified 3D promptable segmentation method, inspired by SegVol, designed to reduce inference time and eliminate prompt management complexities associated with sliding windows while achieving state-of-the-art performance.",
      "authors": [
        "Th\\'eo Danielou",
        "Daniel Tordjman",
        "Pierre Manceron",
        "Corentin Dancette"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:08:57+00:00",
          "link": "https://arxiv.org/abs/2507.07730v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "RAPS-3D: Efficient interactive segmentation for 3D radiological imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07730",
        "HTML": "https://arxiv.org/html/2507.07730v1",
        "PDF": "https://arxiv.org/pdf/2507.07730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper introduces a segmentation method for 3D radiological imaging, it does not focus on LLM training data processing or any aspect related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.14111",
      "abstract": "Automata learning is a successful tool for many application domains such as robotics and automatic verification. Typically, automata learning techniques operate in a supervised learning setting (active or passive) where they learn a finite state machine in contexts where additional information, such as labeled system executions, is available. However, other settings, such as learning from unlabeled data - an important aspect in machine learning - remain unexplored. To overcome this limitation, we propose a framework for learning a deterministic finite automaton (DFA) from a given multi-set of unlabeled words. We show that this problem is computationally hard and develop three learning algorithms based on constraint optimization. Moreover, we introduce novel regularization schemes for our optimization problems that improve the overall interpretability of our DFAs. Using a prototype implementation, we demonstrate practical feasibility in the context of unsupervised anomaly detection.",
      "authors": [
        "Simon Lutz",
        "Daniil Kaminskyi",
        "Florian Wittbold",
        "Simon Dierl",
        "Falk Howar",
        "Barbara K\\\"onig",
        "Emmanuel M\\\"uller",
        "Daniel Neider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-24T16:19:15+00:00",
          "link": "https://arxiv.org/abs/2303.14111v1",
          "size": "85kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:11:07+00:00",
          "link": "https://arxiv.org/abs/2303.14111v2",
          "size": "85kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Automata Learning via Discrete Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.14111",
        "PDF": "https://arxiv.org/pdf/2303.14111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on automata learning from unlabeled data for anomaly detection, with no emphasis on LLM training data."
      },
      "tasks": [
        "Anomaly Detection",
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07257",
      "abstract": "We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.",
      "authors": [
        "Licong Xu",
        "Milind Sarkar",
        "Anto I. Lonappan",
        "\\'I\\~nigo Zubeldia",
        "Pablo Villanueva-Domingo",
        "Santiago Casas",
        "Christian Fidler",
        "Chetana Amancharla",
        "Ujjwal Tiwari",
        "Adrian Bayer",
        "Chadi Ait Ekiou",
        "Miles Cranmer",
        "Adrian Dimitrov",
        "James Fergusson",
        "Kahaan Gandhi",
        "Sven Krippendorf",
        "Andrew Laverick",
        "Julien Lesgourgues",
        "Antony Lewis",
        "Thomas Meier",
        "Blake Sherwin",
        "Kristen Surrao",
        "Francisco Villaescusa-Navarro",
        "Chi Wang",
        "Xueqing Xu",
        "Boris Bolliet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:03:30+00:00",
          "link": "https://arxiv.org/abs/2507.07257v1",
          "size": "7109kb",
          "version": "v1"
        }
      ],
      "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07257",
        "PDF": "https://arxiv.org/pdf/2507.07257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a multi-agent system for autonomous scientific discovery using LLMs, but doesn't discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07724",
      "abstract": "Robot swarms offer the potential to serve a variety of distributed sensing applications. An interesting real-world application that stands to benefit significantly from deployment of swarms is structural monitoring, where traditional sensor networks face challenges in structural coverage due to their static nature. This paper investigates the deployment of a swarm of miniaturized vibration sensing robots to inspect and localize structural damages on a surface section within a high-fidelity simulation environment. In particular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize finite element analysis using Abaqus to obtain realistic structural vibration data. The resulting vibration data is imported into the physics-based robotic simulator Webots, where we simulate the dynamics of our surface inspecting robot swarm. We employ (i) Gaussian process estimators to guide the robots' exploration as they collect vibration samples across the surface and (ii) operational modal analysis to detect structural damages by estimating and comparing existing and intact structural vibration patterns. We analyze the influence of exploration radii on estimation uncertainty and assess the effectiveness of our method across 10 randomized scenarios, where the number, locations, surface area, and depth of structural damages vary. Our simulation studies validate the efficacy of our miniaturized robot swarm for vibration-based structural inspection.",
      "authors": [
        "Thiemen Siemensma",
        "Niels de Boer",
        "and Bahar Haghighat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:58:30+00:00",
          "link": "https://arxiv.org/abs/2507.07724v1",
          "size": "5929kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Surface Inspection via Operational Modal Analysis by a Swarm of Miniaturized Vibration-Sensing Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07724",
        "HTML": "https://arxiv.org/html/2507.07724v1",
        "PDF": "https://arxiv.org/pdf/2507.07724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores deploying robot swarms for structural inspection using vibration-sensing, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09111",
      "abstract": "In order to address the chain of thought in the large language model inference cost surge, this research proposes to use a sparse attention mechanism that only focuses on a few relevant tokens. The researcher constructed a new attention mechanism and used GiantRabbit trained with custom GPTs as an experimental tool. The experiment tested and compared the reasoning time, correctness score and chain of thought length of this model and o1 Preview in solving the linear algebra test questions of MIT OpenCourseWare. The results show that GiantRabbit's reasoning time and chain of thought length are significantly lower than o1 Preview. It verifies the feasibility of sparse attention mechanism for optimizing chain of thought reasoning. Detailed architectural details and experimental process have been uploaded to Github, the link is:https://github.com/brucewang123456789/GeniusTrail.git.",
      "authors": [
        "Libo Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T00:59:13+00:00",
          "link": "https://arxiv.org/abs/2411.09111v1",
          "size": "624kb",
          "version": "v1"
        },
        {
          "date": "2024-11-15T21:28:27+00:00",
          "link": "https://arxiv.org/abs/2411.09111v2",
          "size": "624kb",
          "version": "v2"
        },
        {
          "date": "2024-12-01T13:08:57+00:00",
          "link": "https://arxiv.org/abs/2411.09111v3",
          "size": "785kb",
          "version": "v3"
        },
        {
          "date": "2024-12-11T18:50:30+00:00",
          "link": "https://arxiv.org/abs/2411.09111v4",
          "size": "1014kb",
          "version": "v4"
        },
        {
          "date": "2025-01-23T16:09:32+00:00",
          "link": "https://arxiv.org/abs/2411.09111v5",
          "size": "1948kb",
          "version": "v5"
        },
        {
          "date": "2025-04-03T16:11:23+00:00",
          "link": "https://arxiv.org/abs/2411.09111v6",
          "size": "584kb",
          "version": "v6"
        },
        {
          "date": "2025-04-11T12:09:42+00:00",
          "link": "https://arxiv.org/abs/2411.09111v7",
          "size": "434kb",
          "version": "v7"
        },
        {
          "date": "2025-07-09T19:21:45+00:00",
          "link": "https://arxiv.org/abs/2411.09111v8",
          "size": "434kb",
          "version": "v8"
        }
      ],
      "title": "Reducing Reasoning Costs: The Path of Optimization for Chain of Thought via Sparse Attention Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09111",
        "PDF": "https://arxiv.org/pdf/2411.09111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers on sparse attention mechanism to reduce reasoning costs in LLMs, without direct application or mention of LLM training data processing or creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/brucewang123456789/GeniusTrail"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02901",
      "abstract": "Edge computing scenarios necessitate the development of hardware-efficient online continual learning algorithms to be adaptive to dynamic environment. However, existing algorithms always suffer from high memory overhead and bias towards recently trained tasks. To tackle these issues, this paper proposes a novel online continual learning approach termed as SESLR, which incorporates a sleep enhanced latent replay scheme with spiking neural networks (SNNs). SESLR leverages SNNs' binary spike characteristics to store replay features in single bits, significantly reducing memory overhead. Furthermore, inspired by biological sleep-wake cycles, SESLR introduces a noise-enhanced sleep phase where the model exclusively trains on replay samples with controlled noise injection, effectively mitigating classification bias towards new classes. Extensive experiments on both conventional (MNIST, CIFAR10) and neuromorphic (NMNIST, CIFAR10-DVS) datasets demonstrate SESLR's effectiveness. On Split CIFAR10, SESLR achieves nearly 30% improvement in average accuracy with only one-third of the memory consumption compared to baseline methods. On Split CIFAR10-DVS, it improves accuracy by approximately 10% while reducing memory overhead by a factor of 32. These results validate SESLR as a promising solution for online continual learning in resource-constrained edge computing scenarios.",
      "authors": [
        "Erliang Lin and Wenbin Luo and Wei Jia and Yu Chen and Shaofu Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T12:22:39+00:00",
          "link": "https://arxiv.org/abs/2507.02901v1",
          "size": "1080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T02:48:24+00:00",
          "link": "https://arxiv.org/abs/2507.02901v2",
          "size": "1148kb",
          "version": "v2"
        }
      ],
      "title": "Online Continual Learning via Spiking Neural Networks with Sleep Enhanced Latent Replay",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02901",
        "HTML": "https://arxiv.org/html/2507.02901v2",
        "PDF": "https://arxiv.org/pdf/2507.02901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details an online continual learning approach using spiking neural networks but does not involve processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07258",
      "abstract": "As IoT ecosystems continue to expand across critical sectors, they have become prominent targets for increasingly sophisticated and large-scale malware attacks. The evolving threat landscape, combined with the sensitive nature of IoT-generated data, demands detection frameworks that are both privacy-preserving and resilient to data heterogeneity. Federated Learning (FL) offers a promising solution by enabling decentralized model training without exposing raw data. However, standard FL algorithms such as FedAvg and FedProx often fall short in real-world deployments characterized by class imbalance and non-IID data distributions -- particularly in the presence of rare or disjoint malware classes. To address these challenges, we propose FedP3E (Privacy-Preserving Prototype Exchange), a novel FL framework that supports indirect cross-client representation sharing while maintaining data privacy. Each client constructs class-wise prototypes using Gaussian Mixture Models (GMMs), perturbs them with Gaussian noise, and transmits only these compact summaries to the server. The aggregated prototypes are then distributed back to clients and integrated into local training, supported by SMOTE-based augmentation to enhance representation of minority malware classes. Rather than relying solely on parameter averaging, our prototype-driven mechanism enables clients to enrich their local models with complementary structural patterns observed across the federation -- without exchanging raw data or gradients. This targeted strategy reduces the adverse impact of statistical heterogeneity with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset under realistic cross-silo scenarios with varying degrees of data imbalance.",
      "authors": [
        "Rami Darwish",
        "Mahmoud Abdelsalam",
        "Sajad Khorsandroo",
        "Kaushik Roy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:07:35+00:00",
          "link": "https://arxiv.org/abs/2507.07258v1",
          "size": "662kb",
          "version": "v1"
        }
      ],
      "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07258",
        "HTML": "https://arxiv.org/html/2507.07258v1",
        "PDF": "https://arxiv.org/pdf/2507.07258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a federated learning framework for IoT malware detection and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.15334",
      "abstract": "Providing rich, constructive feedback to students is essential for supporting and enhancing their learning. Recent advancements in Generative Artificial Intelligence (AI), particularly with large language models (LLMs), present new opportunities to deliver scalable, repeatable, and instant feedback, effectively making abundant a resource that has historically been scarce and costly. From a technical perspective, this approach is now feasible due to breakthroughs in AI and Natural Language Processing (NLP). While the potential educational benefits are compelling, implementing these technologies also introduces a host of ethical considerations that must be thoughtfully addressed. One of the core advantages of AI systems is their ability to automate routine and mundane tasks, potentially freeing up human educators for more nuanced work. However, the ease of automation risks a ``tyranny of the majority'', where the diverse needs of minority or unique learners are overlooked, as they may be harder to systematize and less straightforward to accommodate. Ensuring inclusivity and equity in AI-generated feedback, therefore, becomes a critical aspect of responsible AI implementation in education. The process of developing machine learning models that produce valuable, personalized, and authentic feedback also requires significant input from human domain experts. Decisions around whose expertise is incorporated, how it is captured, and when it is applied have profound implications for the relevance and quality of the resulting feedback. Additionally, the maintenance and continuous refinement of these models are necessary to adapt feedback to evolving contextual, theoretical, and student-related factors. Without ongoing adaptation, feedback risks becoming obsolete or mismatched with the current needs of diverse student populations [...]",
      "authors": [
        "Euan D Lindsay",
        "Mike Zhang",
        "Aditya Johri",
        "Johannes Bjerva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-29T14:29:57+00:00",
          "link": "https://arxiv.org/abs/2308.15334v1",
          "size": "420kb",
          "version": "v1"
        },
        {
          "date": "2024-07-30T06:36:22+00:00",
          "link": "https://arxiv.org/abs/2308.15334v2",
          "size": "310kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T14:49:52+00:00",
          "link": "https://arxiv.org/abs/2308.15334v3",
          "size": "325kb",
          "version": "v3"
        }
      ],
      "title": "The Responsible Development of Automated Student Feedback with Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.15334",
        "HTML": "https://arxiv.org/html/2308.15334",
        "PDF": "https://arxiv.org/pdf/2308.15334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development of AI-generated feedback in education, mentioning generative AI but not specifically focusing on processing or creating LLM training data."
      },
      "tasks": [
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.00844",
      "abstract": "We propose a Stokes expansion ansatz for finite-depth standing water waves in two dimensions and devise a recursive algorithm to compute the expansion coefficients. We implement the algorithm on a supercomputer using arbitrary-precision arithmetic. The Stokes expansion introduces hyperbolic terms that require exponentiation of power series, which we handle efficiently using Bell polynomials. Although exact resonances occur at a countable dense set of fluid depths, we prove that for almost every depth, the divisors that arise in the recurrence are bounded away from zero by a slowly decaying function of the wave number. A direct connection between small divisors and imperfect bifurcations is observed. They are found to activate secondary standing waves that oscillate non-uniformly in space and time on top of the primary wave, with different amplitudes and phases on each bifurcation branch. We compute new families of standing waves using a shooting method and find that Pad\\'e approximants of the Stokes expansion continue to converge to the shooting method solutions at large amplitudes as new small divisors enter the recurrence. Closely spaced poles and zeros of the Pad\\'e approximants are observed, which suggests that the bifurcation branches are separated by branch cuts.",
      "authors": [
        "Ahmad Abassi and Jon Wilkening"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-01T18:53:01+00:00",
          "link": "https://arxiv.org/abs/2401.00844v1",
          "size": "1168kb",
          "version": "v1"
        },
        {
          "date": "2024-12-27T17:53:29+00:00",
          "link": "https://arxiv.org/abs/2401.00844v2",
          "size": "7691kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T18:32:44+00:00",
          "link": "https://arxiv.org/abs/2401.00844v3",
          "size": "7749kb",
          "version": "v3"
        }
      ],
      "title": "The semi-analytic theory and computation of finite-depth standing water waves",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.00844",
        "HTML": "https://arxiv.org/html/2401.00844v3",
        "PDF": "https://arxiv.org/pdf/2401.00844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a computational algorithm for finite-depth standing water waves, which does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.16042",
      "abstract": "This article presents Platform Adaptive Locomotion (PAL), a unified control method for quadrupedal robots with different morphologies and dynamics. We leverage deep reinforcement learning to train a single locomotion policy on procedurally generated robots. The policy maps proprioceptive robot state information and base velocity commands into desired joint actuation targets, which are conditioned using a latent embedding of the temporally local system dynamics. We explore two conditioning strategies - one using a GRU-based dynamics encoder and another using a morphology-based property estimator - and show that morphology-aware conditioning outperforms temporal dynamics encoding regarding velocity task tracking for our hardware test on ANYmal C. Our results demonstrate that both approaches achieve robust zero-shot transfer across multiple unseen simulated quadrupeds. Furthermore, we demonstrate the need for careful robot reference modelling during training: exposing the policy to a diverse set of robot morphologies and dynamics leads to improved generalization, reducing the velocity tracking error by up to 30% compared to the baseline method. Despite PAL not surpassing the best-performing reference-free controller in all cases, our analysis uncovers critical design choices and informs improvements to the state of the art.",
      "authors": [
        "David Rytz (1)",
        "Suyoung Choi (2)",
        "Wanming Yu (1)",
        "Wolfgang Merkt (1)",
        "Jemin Hwangbo (2) and Ioannis Havoutis (1) ((1) Dynamic Robot Systems",
        "Oxford Robotics Institute",
        "University of Oxford",
        "(2) RaiLab",
        "Department of Mechanical Engineering",
        "KAIST)"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T21:48:51+00:00",
          "link": "https://arxiv.org/abs/2505.16042v1",
          "size": "1434kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:53:20+00:00",
          "link": "https://arxiv.org/abs/2505.16042v2",
          "size": "1477kb",
          "version": "v2"
        }
      ],
      "title": "Reference Free Platform Adaptive Locomotion for Quadrupedal Robots using a Dynamics Conditioned Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16042",
        "HTML": "https://arxiv.org/html/2505.16042v2",
        "PDF": "https://arxiv.org/pdf/2505.16042"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adaptive locomotion in quadrupedal robots using deep reinforcement learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07515",
      "abstract": "Human motion is a continuous physical process in 3D space, governed by complex dynamic and kinematic constraints. Existing methods typically represent the human pose as an abstract graph structure, neglecting the intrinsic physical dependencies between joints, which increases learning difficulty and makes the model prone to generating unrealistic motions. In this paper, we propose GGMotion, a group graph dynamics-kinematics network that models human topology in groups to better leverage dynamics and kinematics priors. To preserve the geometric equivariance in 3D space, we propose a novel radial field for the graph network that captures more comprehensive spatio-temporal dependencies by aggregating joint features through spatial and temporal edges. Inter-group and intra-group interaction modules are employed to capture the dependencies of joints at different scales. Combined with equivariant multilayer perceptrons (MLP), joint position features are updated in each group through parallelized dynamics-kinematics propagation to improve physical plausibility. Meanwhile, we introduce an auxiliary loss to supervise motion priors during training. Extensive experiments on three standard benchmarks, including Human3.6M, CMU-Mocap, and 3DPW, demonstrate the effectiveness and superiority of our approach, achieving a significant performance margin in short-term motion prediction. The code is available at https://github.com/inkcat520/GGMotion.git.",
      "authors": [
        "Shuaijin Wan",
        "Huaijiang Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:02:01+00:00",
          "link": "https://arxiv.org/abs/2507.07515v1",
          "size": "896kb",
          "version": "v1"
        }
      ],
      "title": "GGMotion: Group Graph Dynamics-Kinematics Networks for Human Motion Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07515",
        "HTML": "https://arxiv.org/html/2507.07515v1",
        "PDF": "https://arxiv.org/pdf/2507.07515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on human motion prediction using network models and graph structures, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07208",
      "abstract": "Axiomatic type theory is a dependent type theory without computation rules. The term equality judgements that usually characterise these rules are replaced by computation axioms, i.e., additional term judgements that are typed by identity types. This paper is devoted to providing an effective description of its semantics, from a higher categorical perspective: given the challenge of encoding intensional type formers into 1-dimensional categorical terms and properties, a challenge that persists even for axiomatic type formers, we adopt Richard Garner's approach in the 2-dimensional study of dependent types. We prove that the type formers of axiomatic theories can be encoded into natural 2-dimensional category theoretic data, obtaining a presentation of the semantics of axiomatic type theory via 2-categorical models called display map 2-categories. In the axiomatic case, the 2-categorical requirements identified by Garner for interpreting intensional type formers are relaxed. Therefore, we obtain a presentation of the semantics of the axiomatic theory that generalises Garner's one for the intensional case. Our main result states that the interpretation of axiomatic theories within display map 2-categories is well-defined and enjoys the soundness property. We use this fact to provide a semantic proof that the computation rule of intensional identity types is not admissible in axiomatic type theory. This is achieved via a revisitation of Hofmann and Streicher's groupoid model that believes axiomatic identity types but does not believe intensional ones.",
      "authors": [
        "Matteo Spadetto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T18:31:44+00:00",
          "link": "https://arxiv.org/abs/2507.07208v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "A 2-categorical approach to the semantics of dependent type theory with computation axioms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07208",
        "PDF": "https://arxiv.org/pdf/2507.07208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the semantics of dependent type theory and does not discuss any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07678",
      "abstract": "Dynamic Facial Expression Recognition(DFER) is a rapidly evolving field of research that focuses on the recognition of time-series facial expressions. While previous research on DFER has concentrated on feature learning from a deep learning perspective, we put forward an AU-enhanced Dynamic Facial Expression Recognition architecture, namely AU-DFER, that incorporates AU-expression knowledge to enhance the effectiveness of deep learning modeling. In particular, the contribution of the Action Units(AUs) to different expressions is quantified, and a weight matrix is designed to incorporate a priori knowledge. Subsequently, the knowledge is integrated with the learning outcomes of a conventional deep learning network through the introduction of AU loss. The design is incorporated into the existing optimal model for dynamic expression recognition for the purpose of validation. Experiments are conducted on three recent mainstream open-source approaches to DFER on the principal datasets in this field. The results demonstrate that the proposed architecture outperforms the state-of-the-art(SOTA) methods without the need for additional arithmetic and generally produces improved results. Furthermore, we investigate the potential of AU loss function redesign to address data label imbalance issues in established dynamic expression datasets. To the best of our knowledge, this is the first attempt to integrate quantified AU-expression knowledge into various DFER models. We also devise strategies to tackle label imbalance, or minor class problems. Our findings suggest that employing a diverse strategy of loss function design can enhance the effectiveness of DFER. This underscores the criticality of addressing data imbalance challenges in mainstream datasets within this domain. The source code is available at https://github.com/Cross-Innovation-Lab/AU-DFER.",
      "authors": [
        "Feng Liu",
        "Lingna Gu",
        "Chen Shi",
        "Xiaolan Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:59:43+00:00",
          "link": "https://arxiv.org/abs/2507.07678v1",
          "size": "3711kb",
          "version": "v1"
        }
      ],
      "title": "Action Unit Enhance Dynamic Facial Expression Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07678",
        "HTML": "https://arxiv.org/html/2507.07678v1",
        "PDF": "https://arxiv.org/pdf/2507.07678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on dynamic facial expression recognition architecture using Action Units, without discussing any LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "1906.04112",
      "abstract": "Low rank approximation of a matrix (hereafter LRA) is a highly important area of Numerical Linear and Multilinear Algebra and Data Mining and Analysis. One can operate with an LRA at sublinear cost -- by using much fewer memory cells and flops than an input matrix M has entries. For worst case inputs one cannot compute even a reasonably close LRA at sublinear cost, but in computational practice accurate LRAs, even in their memory efficient form of CUR LRAs, are routinely obtained at sublinear cost for large and important classes of matrices, in particular by means of Cross-Approximation iterations, which specialize Alternating Direction techniques to LRA. We identify some classes of matrices for which CUR LRA are computed at sublinear cost as well as some sublinear cost LRA algorithms that are empirically accurate for large classes of inputs. Some of our techniques and concepts can be of independent interests.",
      "authors": [
        "Soo Go",
        "Qi Luan",
        "Victor Y. Pan",
        "John Svadlenka and Liang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2019-06-10T16:39:12+00:00",
          "link": "https://arxiv.org/abs/1906.04112v1",
          "size": "56kb",
          "version": "v1"
        },
        {
          "date": "2019-07-26T20:56:59+00:00",
          "link": "https://arxiv.org/abs/1906.04112v2",
          "size": "56kb",
          "version": "v2"
        },
        {
          "date": "2019-11-05T19:19:02+00:00",
          "link": "https://arxiv.org/abs/1906.04112v3",
          "size": "57kb",
          "version": "v3"
        },
        {
          "date": "2020-12-22T03:45:05+00:00",
          "link": "https://arxiv.org/abs/1906.04112v4",
          "size": "58kb",
          "version": "v4"
        },
        {
          "date": "2023-11-01T03:00:28+00:00",
          "link": "https://arxiv.org/abs/1906.04112v5",
          "size": "62kb",
          "version": "v5"
        },
        {
          "date": "2025-07-10T15:03:02+00:00",
          "link": "https://arxiv.org/abs/1906.04112v6",
          "size": "39kb",
          "version": "v6"
        }
      ],
      "title": "CUR Low Rank Approximation of a Matrix at Sublinear Cost",
      "links": {
        "Abstract": "https://arxiv.org/abs/1906.04112",
        "HTML": "https://arxiv.org/html/1906.04112",
        "PDF": "https://arxiv.org/pdf/1906.04112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on matrix low rank approximation techniques in numerical algebra, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.01253",
      "abstract": "Technical advances in collaborative robots (cobots) are making them increasingly attractive to companies. However, many human operators are not trained to program complex machines. Instead, humans are used to communicating with each other on a task-based level rather than through specific instructions, as is common with machines. The gap between low-level instruction-based and high-level task-based communication leads to low values for usability scores of teach pendant programming. As a solution, we propose a task-based interaction concept that allows human operators to delegate a complex task to a machine without programming by specifying a task via triplets. The concept is based on task decomposition and a reasoning system using a cognitive architecture. The approach is evaluated in an industrial use case where mineral cast basins have to be sanded by a cobot in a crafts enterprise.",
      "authors": [
        "Moritz Schmidt",
        "Claudia Meitinger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-02T14:10:14+00:00",
          "link": "https://arxiv.org/abs/2311.01253v1",
          "size": "756kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T10:22:47+00:00",
          "link": "https://arxiv.org/abs/2311.01253v2",
          "size": "132kb",
          "version": "v2"
        }
      ],
      "title": "A Concept for User-Centered Delegation of Abstract High-Level Tasks to Cobots for Flexible Lot Sizes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.01253",
        "HTML": "https://arxiv.org/html/2311.01253",
        "PDF": "https://arxiv.org/pdf/2311.01253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a concept for task delegation to cobots, focusing on interaction and reasoning systems, and does not discuss any aspect related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07340",
      "abstract": "Visual storytelling systems, particularly large vision-language models, struggle to maintain character and object identity across frames,\n  often failing to recognize when entities in different images represent the same individuals or objects,\n  leading to inconsistent references and referential hallucinations.\n  This occurs because models lack explicit training on when to establish entity connections across frames.\n  We propose a contrastive reinforcement learning approach that trains models to discriminate between coherent image sequences\n  and stories from unrelated images.\n  We extend the Story Reasoning dataset with synthetic negative examples to teach appropriate entity connection behavior.\n  We employ Direct Preference Optimization with a dual-component reward function that promotes grounding and re-identification of entities\n  in real stories while penalizing incorrect entity connections in synthetic contexts.\n  Using this contrastive framework, we fine-tune Qwen Storyteller (based on Qwen2.5-VL 7B).\n  Evaluation shows improvements in grounding mAP from 0.27 to 0.31 (+14.8%), F1 from 0.35 to 0.41 (+17.1%).\n  Pronoun grounding accuracy improved across all pronoun types except ``its'',\n  and cross-frame character and object persistence increased\n  across all frame counts, with entities appearing in 5 or more frames advancing from 29.3% to 33.3% (+13.7%).\n  Well-structured stories, containing the chain-of-thought and grounded story, increased from 79.1% to 97.5% (+23.3%).",
      "authors": [
        "Daniel A. P. Oliveira",
        "David Martins de Matos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:52:10+00:00",
          "link": "https://arxiv.org/abs/2507.07340v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07340",
        "HTML": "https://arxiv.org/html/2507.07340v1",
        "PDF": "https://arxiv.org/pdf/2507.07340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper outlines a method for entity re-identification in visual storytelling using contrastive reinforcement learning, which involves extending the Story Reasoning dataset with synthetic examples. However, the main focus is on improving model performance rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07524",
      "abstract": "The class PLS (Polynomial Local Search) captures the complexity of finding a solution that is locally optimal and has proven to be an important concept in the theory of local search. It has been shown that local search versions of various combinatorial optimization problems, such as Maximum Independent Set and Max Cut, are complete for this class. Such computational intractability typically arises in local search problems allowing arbitrary weights; in contrast, for unweighted problems, locally optimal solutions can be found in polynomial time under standard settings. In this paper, we pursue the complexity of local search problems from a different angle: We show that computing two locally optimal solutions is NP-hard for various natural unweighted local search problems, including Maximum Independent Set, Minimum Dominating Set, Max SAT, and Max Cut. We also discuss several tractable cases for finding two (or more) local optimal solutions.",
      "authors": [
        "Yasuaki Kobayashi",
        "Kazuhiro Kurita",
        "Yutaro Yamaguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.07524v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "Finding One Local Optimum Is Easy -- But What about Two?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07524",
        "HTML": "https://arxiv.org/html/2507.07524v1",
        "PDF": "https://arxiv.org/pdf/2507.07524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses complexity in local search problems, offering theoretical insights into finding local optima, without involvement in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07823",
      "abstract": "We introduce a new arbitrarily high-order method for the rapid evaluation of hyperbolic potentials (space-time integrals involving the Green's function for the scalar wave equation). With $M$ points in the spatial discretization and $N_t$ time steps of size $\\Delta t$, a naive implementation would require $\\mathcal O(M^2N_t^2)$ work in dimensions where the weak Huygens' principle applies. We avoid this all-to-all interaction using a smoothly windowed decomposition into a local part, treated directly, plus a history part, approximated by a $N_F$-term Fourier series. In one dimension, our method requires $\\mathcal O\\left((M + N_F \\log N_F)N_t\\right)$ work, with $N_F =\\mathcal O(1/\\Delta t)$, by exploiting the non-uniform fast Fourier transform. We demonstrate the method's performance for time-domain scattering problems involving a large number $M$ of springs (point scatterers) attached to a vibrating string at arbitrary locations, with either periodic or free-space boundary conditions. We typically achieve 10-digit accuracy, and include tests for $M$ up to a million.",
      "authors": [
        "Nour G. Al Hassanieh",
        "Alex H. Barnett",
        "Leslie Greengard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:53:48+00:00",
          "link": "https://arxiv.org/abs/2507.07823v1",
          "size": "3019kb",
          "version": "v1"
        }
      ],
      "title": "A fast algorithm for the wave equation using time-windowed Fourier projection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07823",
        "HTML": "https://arxiv.org/html/2507.07823v1",
        "PDF": "https://arxiv.org/pdf/2507.07823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new method for the wave equation using time-windowed Fourier projection, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07848",
      "abstract": "Recent advances in Reinforcement Learning (RL) largely benefit from the inclusion of Deep Neural Networks, boosting the number of novel approaches proposed in the field of Deep Reinforcement Learning (DRL). These techniques demonstrate the ability to tackle complex games such as Atari, Go, and other real-world applications, including financial trading. Nevertheless, a significant challenge emerges from the lack of interpretability, particularly when attempting to comprehend the underlying patterns learned, the relative importance of the state features, and how they are integrated to generate the policy's output. For this reason, in mission-critical and real-world settings, it is often preferred to deploy a simpler and more interpretable algorithm, although at the cost of performance. In this paper, we propose a novel algorithm, supported by theoretical guarantees, that can extract an interpretable policy (e.g., a linear policy) without disregarding the peculiarities of expert behavior. This result is obtained by considering the advantage function, which includes information about why an action is superior to the others. In contrast to previous works, our approach enables the training of an interpretable policy using previously collected experience. The proposed algorithm is empirically evaluated on classic control environments and on a financial trading scenario, demonstrating its ability to extract meaningful information from complex expert policies.",
      "authors": [
        "Giovanni Dispoto",
        "Paolo Bonetti",
        "Marcello Restelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:27:44+00:00",
          "link": "https://arxiv.org/abs/2507.07848v1",
          "size": "596kb",
          "version": "v1"
        }
      ],
      "title": "\"So, Tell Me About Your Policy...\": Distillation of interpretable policies from Deep Reinforcement Learning agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07848",
        "HTML": "https://arxiv.org/html/2507.07848v1",
        "PDF": "https://arxiv.org/pdf/2507.07848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses distillation of interpretable policies from Deep Reinforcement Learning agents, which does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.13284",
      "abstract": "Recent advancements in large language models (LLMs) have shown promise in bridging the gap between natural language queries and database management systems, enabling users to interact with databases without the background of SQL. However, LLMs often struggle to comprehend complex database structures and accurately interpret user intentions. Decomposition-based methods have been proposed to enhance the performance of LLMs on complex tasks, but decomposing SQL generation into subtasks is non-trivial due to the declarative structure of SQL syntax and the intricate connections between query concepts and database elements. In this paper, we propose a novel Structure GUided text-to-SQL framework~(SGU-SQL) that incorporates syntax-based prompting to enhance the SQL generation capabilities of LLMs. Specifically, SGU-SQL establishes structure-aware links between user queries and database schema and decomposes the complex generation task using syntax-based prompting to enable more accurate LLM-based SQL generation. Extensive experiments on two benchmark datasets demonstrate that SGU-SQL consistently outperforms state-of-the-art text-to-SQL models.",
      "authors": [
        "Qinggang Zhang",
        "Hao Chen",
        "Junnan Dong",
        "Shengyuan Chen",
        "Feiran Huang",
        "Xiao Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-19T09:07:59+00:00",
          "link": "https://arxiv.org/abs/2402.13284v1",
          "size": "1089kb",
          "version": "v1"
        },
        {
          "date": "2024-03-27T14:30:44+00:00",
          "link": "https://arxiv.org/abs/2402.13284v2",
          "size": "1494kb",
          "version": "v2"
        },
        {
          "date": "2025-06-06T03:37:27+00:00",
          "link": "https://arxiv.org/abs/2402.13284v3",
          "size": "1151kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T06:38:13+00:00",
          "link": "https://arxiv.org/abs/2402.13284v4",
          "size": "1152kb",
          "version": "v4"
        }
      ],
      "title": "Structure Guided Large Language Model for SQL Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.13284",
        "HTML": "https://arxiv.org/html/2402.13284v4",
        "PDF": "https://arxiv.org/pdf/2402.13284"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a novel text-to-SQL framework utilizing LLMs, focusing on syntax-based prompting for SQL generation, but it does not primarily address LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "model",
        "Natural Language Queries",
        "Text to SQL",
        "Text-To-SQL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12878",
      "abstract": "As software systems increase in size and complexity dramatically, ensuring their correctness, security, and reliability becomes an increasingly formidable challenge. Despite significant advancements in verification techniques and tools, there still remain %these tools still continue to encounter substantial difficulties when applying these tools to complex, real-world scenarios. To address these difficulties, this paper introduces a novel verification tool, called \\textbf{Qualified C Programming Verifier (QCP)}. QCP incorporates a refined front-end %syntax of assertion language to enhance user interaction. The proposed assertion language aims to %syntax is designed to lower the entry barrier for verification tools, improve proof efficiency by improving automation, and facilitate a deeper understanding of both the program and its verification results.",
      "authors": [
        "Xiwei Wu and Yueyang Feng and Xiaoyang Lu and Tianchuan Lin and Kan Liu and Zhiyi Wang and Shushu Wu and Lihan Xie and Chengxi Yang and Hongyi Zhong and Naijun Zhan and Zhenjiang Hu and Qinxiang Cao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T09:04:34+00:00",
          "link": "https://arxiv.org/abs/2505.12878v1",
          "size": "560kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:39:15+00:00",
          "link": "https://arxiv.org/abs/2505.12878v2",
          "size": "560kb",
          "version": "v2"
        }
      ],
      "title": "QCP: A Practical Separation Logic-based C Program Verification Tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12878",
        "HTML": "https://arxiv.org/html/2505.12878v2",
        "PDF": "https://arxiv.org/pdf/2505.12878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a C program verification tool and discusses improvements in verification techniques. It does not focus on LLM training data processing or involve creation or manipulation of LLM datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06838",
      "abstract": "Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set. Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information needs of complex queries in multi-hop question answering. In this work, we propose a set-wise passage selection approach and introduce SETR, which explicitly identifies the information requirements of a query through Chain-of-Thought reasoning and selects an optimal set of passages that collectively satisfy those requirements. Experiments on multi-hop RAG benchmarks show that SETR outperforms both proprietary LLM-based rerankers and open-source baselines in terms of answer correctness and retrieval quality, providing an effective and efficient alternative to traditional rerankers in RAG systems. The code is available at https://github.com/LGAI-Research/SetR",
      "authors": [
        "Dahyun Lee",
        "Yongrae Jo",
        "Haeju Park",
        "Moontae Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:35:36+00:00",
          "link": "https://arxiv.org/abs/2507.06838v1",
          "size": "1659kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:36:33+00:00",
          "link": "https://arxiv.org/abs/2507.06838v2",
          "size": "1659kb",
          "version": "v2"
        }
      ],
      "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06838",
        "HTML": "https://arxiv.org/html/2507.06838v2",
        "PDF": "https://arxiv.org/pdf/2507.06838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper proposes a set-wise passage selection approach in the context of retrieval-augmented generation, it primarily focuses on improving retrieval effectiveness rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07274",
      "abstract": "Large Multimodal Models (LMMs) are typically trained on vast corpora of image-text data but are often limited in linguistic coverage, leading to biased and unfair outputs across languages. While prior work has explored multimodal evaluation, less emphasis has been placed on assessing multilingual capabilities. In this work, we introduce LinguaMark, a benchmark designed to evaluate state-of-the-art LMMs on a multilingual Visual Question Answering (VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages and five social attributes. We evaluate models using three key metrics: Bias, Answer Relevancy, and Faithfulness. Our findings reveal that closed-source models generally achieve the highest overall performance. Both closed-source (GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform competitively across social attributes, and Qwen2.5 demonstrates strong generalization across multiple languages. We release our benchmark and evaluation code to encourage reproducibility and further research.",
      "authors": [
        "Ananya Raval",
        "Aravind Narayanan",
        "Vahid Reza Khazaie",
        "Shaina Raza"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:45:04+00:00",
          "link": "https://arxiv.org/abs/2507.07274v1",
          "size": "6811kb",
          "version": "v1"
        }
      ],
      "title": "LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07274",
        "HTML": "https://arxiv.org/html/2507.07274v1",
        "PDF": "https://arxiv.org/pdf/2507.07274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating multilingual capabilities of multimodal models, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07316",
      "abstract": "Federated Learning (FL) faces inherent challenges in balancing model performance, privacy preservation, and communication efficiency, especially in non-IID decentralized environments. Recent approaches either sacrifice formal privacy guarantees, incur high overheads, or overlook quantum-enhanced expressivity. We introduce AdeptHEQ-FL, a unified hybrid classical-quantum FL framework that integrates (i) a hybrid CNN-PQC architecture for expressive decentralized learning, (ii) an adaptive accuracy-weighted aggregation scheme leveraging differentially private validation accuracies, (iii) selective homomorphic encryption (HE) for secure aggregation of sensitive model layers, and (iv) dynamic layer-wise adaptive freezing to minimize communication overhead while preserving quantum adaptability. We establish formal privacy guarantees, provide convergence analysis, and conduct extensive experiments on the CIFAR-10, SVHN, and Fashion-MNIST datasets. AdeptHEQ-FL achieves a $\\approx 25.43\\%$ and $\\approx 14.17\\%$ accuracy improvement over Standard-FedQNN and FHE-FedQNN, respectively, on the CIFAR-10 dataset. Additionally, it reduces communication overhead by freezing less important layers, demonstrating the efficiency and practicality of our privacy-preserving, resource-aware design for FL.",
      "authors": [
        "Md Abrar Jahin",
        "Taufikur Rahman Fuad",
        "M. F. Mridha",
        "Nafiz Fahad",
        "Md. Jakir Hossen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T22:29:02+00:00",
          "link": "https://arxiv.org/abs/2507.07316v1",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "title": "AdeptHEQ-FL: Adaptive Homomorphic Encryption for Federated Learning of Hybrid Classical-Quantum Models with Dynamic Layer Sparing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07316",
        "HTML": "https://arxiv.org/html/2507.07316v1",
        "PDF": "https://arxiv.org/pdf/2507.07316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers around federated learning with hybrid models and privacy techniques but does not address any LLM training data processing or datasets creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.01139",
      "abstract": "Perturbation robustness evaluates the vulnerabilities of models, arising from a variety of perturbations, such as data corruptions and adversarial attacks. Understanding the mechanisms of perturbation robustness is critical for global interpretability. We present a model-agnostic, global mechanistic interpretability method to interpret the perturbation robustness of image models. This research is motivated by two key aspects. First, previous global interpretability works, in tandem with robustness benchmarks, e.g. mean corruption error (mCE), are not designed to directly interpret the mechanisms of perturbation robustness within image models. Second, we notice that the spectral signal-to-noise ratios (SNR) of perturbed natural images exponentially decay over the frequency. This power-law-like decay implies that: Low-frequency signals are generally more robust than high-frequency signals -- yet high classification accuracy can not be achieved by low-frequency signals alone. By applying Shapley value theory, our method axiomatically quantifies the predictive powers of robust features and non-robust features within an information theory framework. Our method, dubbed as \\textbf{I-ASIDE} (\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance \\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into model robustness mechanisms. We conduct extensive experiments over a variety of vision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not only \\textbf{measure} the perturbation robustness but also \\textbf{provide interpretations} of its mechanisms.",
      "authors": [
        "R\\'ois\\'in Luo",
        "James McDermott",
        "Colm O'Riordan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T09:35:06+00:00",
          "link": "https://arxiv.org/abs/2408.01139v1",
          "size": "9373kb",
          "version": "v1"
        },
        {
          "date": "2024-08-18T17:13:31+00:00",
          "link": "https://arxiv.org/abs/2408.01139v2",
          "size": "9385kb",
          "version": "v2"
        },
        {
          "date": "2025-06-23T13:00:34+00:00",
          "link": "https://arxiv.org/abs/2408.01139v3",
          "size": "5671kb",
          "version": "v3"
        }
      ],
      "title": "Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01139",
        "HTML": "https://arxiv.org/html/2408.01139",
        "PDF": "https://arxiv.org/pdf/2408.01139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work on perturbation robustness in image models does not relate to LLM training data processing or involve data engineering for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.19472",
      "abstract": "In the context of numerical simulations of the vascular system, local geometric uncertainties have not yet been examined in sufficient detail due to model complexity and the associated large numerical effort. Such uncertainties are related to geometric modeling errors resulting from computed tomography imaging, segmentation and meshing. This work presents a methodology to systematically induce local modifications and perform a sufficient number of blood flow simulations to draw statistically relevant conclusions on the most commonly employed quantities of interest, such as flow rates or wall shear stress. The surface of a structured hexahedral mesh of a patient-specific aorta is perturbed by displacement maps defined via Gaussian random fields to stochastically model the local uncertainty of the boundary. Three different cases are studied, with the mean perturbation magnitude of $0.25$, $0.5$ and $1.0~$mm. Valid, locally perturbed meshes are constructed via an elasticity operator that extends surface perturbations into the interior. Otherwise, identical incompressible flow problems are solved on these meshes, taking physiological boundary conditions and Carreau fluid parameters into account. Roughly $300\\,000$ three-dimensional non-stationary blood flow simulations are performed for the three different perturbation cases to estimate the probability distributions of the quantities of interest. Convergence studies justify the spatial resolution of the employed meshes. Overall, the results suggest that moderate geometric perturbations result in reasonable engineering accuracy (relative errors in single-digit percentage range) of the quantities of interest, with higher sensitivity for gradient-related measures, noting that the observed errors are not negligible.",
      "authors": [
        "Domagoj Bo\\v{s}njak",
        "Richard Schussnig",
        "Sascha Ranftl",
        "Gerhard A. Holzapfel",
        "Thomas-Peter Fries"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T11:04:03+00:00",
          "link": "https://arxiv.org/abs/2410.19472v1",
          "size": "22992kb",
          "version": "v1"
        }
      ],
      "title": "Geometric Uncertainty of Patient-Specific Blood Vessels and its Impact on Aortic Hemodynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19472",
        "HTML": "https://arxiv.org/html/2410.19472",
        "PDF": "https://arxiv.org/pdf/2410.19472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on geometric uncertainty in blood flow simulations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.12187",
      "abstract": "The evolution of many dynamical systems that describe relationships or interactions between objects can be effectively modeled by temporal networks, which are typically represented as a sequence of static network snapshots. In this paper, we introduce a novel random walk-based approach that can identify clusters of time-snapshots in which network community structures are stable. This allows us to detect significant structural shifts over time, such as the splitting or merging of communities or their births and deaths. We also provide a low-dimensional representation of entire snapshots, placing those with similar community structure close to each other in the feature space. To validate our approach, we develop an agent-based algorithm that generates synthetic datasets with the desired characteristic properties, enabling thorough testing and benchmarking. We further demonstrate the effectiveness and broad applicability of our technique by testing it on various social dynamics models and real-world datasets and comparing its performance to several state-of-the-art algorithms. Our findings highlight the strength of our approach to correctly capture and analyze the dynamics of complex systems.",
      "authors": [
        "Filip Bla\\v{s}kovi\\'c and Tim O. F. Conrad and Stefan Klus and Nata\\v{s}a Djurdjevac Conrad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T20:00:54+00:00",
          "link": "https://arxiv.org/abs/2412.12187v1",
          "size": "2287kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T13:26:48+00:00",
          "link": "https://arxiv.org/abs/2412.12187v2",
          "size": "10555kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T15:05:42+00:00",
          "link": "https://arxiv.org/abs/2412.12187v3",
          "size": "10138kb",
          "version": "v3"
        }
      ],
      "title": "Random walk based snapshot clustering for detecting community dynamics in temporal networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12187",
        "HTML": "https://arxiv.org/html/2412.12187v3",
        "PDF": "https://arxiv.org/pdf/2412.12187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with community dynamics detection in temporal networks using a random walk-based approach. It does not discuss LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.11109",
      "abstract": "In this paper, we examine the distribution and convergence properties of the estimation error $W = X - \\hat{X}(Y)$, where $\\hat{X}(Y)$ is the Bayesian estimator of a random variable $X$ from a noisy observation $Y = X +\\sigma Z$ where $\\sigma$ is the parameter indicating the strength of noise $Z$. Using the conditional expectation framework (that is, $\\hat{X}(Y)$ is the conditional mean), we define the normalized error $\\mathcal{E}_\\sigma = \\frac{W}{\\sigma}$ and explore its properties.\n  Specifically, in the first part of the paper, we characterize the probability density function of $W$ and $\\mathcal{E}_\\sigma$. Along the way, we also find conditions for the existence of the inverse functions for the conditional expectations. In the second part, we study pointwise (i.e., almost sure) convergence of $\\mathcal{E}_\\sigma$ as $\\sigma \\to 0$ under various assumptions about the noise and the underlying distributions. Our results extend some of the previous limits of $\\mathcal{E}_\\sigma$ as $\\sigma \\to 0$ studied under the $L^2$ convergence, known as the \\emph{mmse dimension}, to the pointwise case.",
      "authors": [
        "Luca Barletta",
        "Alex Dytso",
        "Shlomo Shamai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-19T16:52:40+00:00",
          "link": "https://arxiv.org/abs/2501.11109v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T20:06:57+00:00",
          "link": "https://arxiv.org/abs/2501.11109v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Estimation Error: Distribution and Pointwise Limits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11109",
        "HTML": "https://arxiv.org/html/2501.11109v2",
        "PDF": "https://arxiv.org/pdf/2501.11109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on estimation error and convergence properties of Bayesian estimators which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.20550",
      "abstract": "Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of vertices in a longest path of $G$ such that every vertex on the path is a cut vertex of $G$, and every intermediate vertex of the path is a degree-two vertex of $G$. Let $k$ be the number of vertices of such a longest path of $T$ that every vertex of the path is a cut vertex and that every intermediate vertex of the path is a degree-two vertex of $T$. Let $P=\\{1,\\ldots,n\\}$ be a set of pebbles with $n+k < N$. A configuration of $P$ on $G$ is defined as a function $f$ from $V(G)$ to $\\{0, 1, \\ldots, n \\}$ with $|f^{-1}(i)| = 1$ for $1 \\le i \\le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \\le i \\le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A move is defined as shifting a pebble from a vertex to some unoccupied neighbor. The pebble motion problem on the pair $(G,P)$ is to decide whether a given configuration of pebbles is reachable from another by executing a sequence of moves. In this paper, we show that the length of the shortest solution sequence of the pebble motion problem on the pair $(G,P)$ is in $O(Nn + n^2 \\log(\\min\\{n,k\\}))$ if $G$ is a $N$-vertex tree, and it is in $O(N^2 + \\frac{n^3}{N-n} + n^2 \\log(\\min\\{n,N-n\\}))$ if $G$ is a connected general $N$-vertex graph. We provide an algorithm that can obtain a solution sequence of lengths that satisfy these orders, with the same computational complexity as the order of the length.\n  Keywords: pebble motion, motion planning, multi-agent path finding, $15$-puzzle, tree",
      "authors": [
        "Tomoki Nakamigawa and Tadashi Sakuma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T13:46:44+00:00",
          "link": "https://arxiv.org/abs/2503.20550v1",
          "size": "117kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T10:06:44+00:00",
          "link": "https://arxiv.org/abs/2503.20550v2",
          "size": "117kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T14:00:13+00:00",
          "link": "https://arxiv.org/abs/2503.20550v3",
          "size": "119kb",
          "version": "v3"
        }
      ],
      "title": "On the order of the shortest solution sequences for the pebble motion problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20550",
        "HTML": "https://arxiv.org/html/2503.20550v3",
        "PDF": "https://arxiv.org/pdf/2503.20550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the theoretical analysis of the pebble motion problem in graphs and does not involve any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06825",
      "abstract": "We introduce a real-time strategy game environment based on Generals.io, a game with thousands of weekly active players. Our environment is fully compatible with Gymnasium and PettingZoo and is capable of running thousands of frames per second on commodity hardware. We also present a reference agent, trained with supervised pre-training and self-play, which reached the top 0.003% of the 1v1 human leaderboard after only 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions of a modular RTS benchmark and a competitive baseline agent provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research. The documented code, together with examples and tutorials, is available at https://github.com/strakam/generals-bots.",
      "authors": [
        "Matej Straka",
        "Martin Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:15:05+00:00",
          "link": "https://arxiv.org/abs/2507.06825v1",
          "size": "1198kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T09:28:09+00:00",
          "link": "https://arxiv.org/abs/2507.06825v2",
          "size": "1004kb",
          "version": "v2"
        }
      ],
      "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06825",
        "HTML": "https://arxiv.org/html/2507.06825v2",
        "PDF": "https://arxiv.org/pdf/2507.06825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a strategy game environment and a reference agent trained with reinforcement learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06952",
      "abstract": "Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.",
      "authors": [
        "Keyon Vafa",
        "Peter G. Chang",
        "Ashesh Rambachan",
        "Sendhil Mullainathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.06952v1",
          "size": "3388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:01:42+00:00",
          "link": "https://arxiv.org/abs/2507.06952v2",
          "size": "3388kb",
          "version": "v2"
        }
      ],
      "title": "What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06952",
        "PDF": "https://arxiv.org/pdf/2507.06952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores inductive bias and foundational models' understanding of datasets, but it does not discuss data processing relevant to LLM training data preparation or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07261",
      "abstract": "Automated food intake gesture detection plays a vital role in dietary monitoring, enabling objective and continuous tracking of eating behaviors to support better health outcomes. Wrist-worn inertial measurement units (IMUs) have been widely used for this task with promising results. More recently, contactless radar sensors have also shown potential. This study explores whether combining wearable and contactless sensing modalities through multimodal learning can further improve detection performance. We also address a major challenge in multimodal learning: reduced robustness when one modality is missing. To this end, we propose a robust multimodal temporal convolutional network with cross-modal attention (MM-TCN-CMA), designed to integrate IMU and radar data, enhance gesture detection, and maintain performance under missing modality conditions. A new dataset comprising 52 meal sessions (3,050 eating gestures and 797 drinking gestures) from 52 participants is developed and made publicly available. Experimental results show that the proposed framework improves the segmental F1-score by 4.3% and 5.2% over unimodal Radar and IMU models, respectively. Under missing modality scenarios, the framework still achieves gains of 1.3% and 2.4% for missing radar and missing IMU inputs. This is the first study to demonstrate a robust multimodal learning framework that effectively fuses IMU and radar data for food intake gesture detection.",
      "authors": [
        "Chunzhuo Wang",
        "Hans Hallez",
        "and Bart Vanrumste"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:15:40+00:00",
          "link": "https://arxiv.org/abs/2507.07261v1",
          "size": "1755kb",
          "version": "v1"
        }
      ],
      "title": "Robust Multimodal Learning Framework For Intake Gesture Detection Using Contactless Radar and Wearable IMU Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07261",
        "HTML": "https://arxiv.org/html/2507.07261v1",
        "PDF": "https://arxiv.org/pdf/2507.07261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a multimodal learning framework for gesture detection, introducing a new dataset but focusing on model performance and robustness, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07787",
      "abstract": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation.",
      "authors": [
        "Elizabeth Hilliard",
        "Akshaya Jagadeesh",
        "Alex Cook",
        "Steele Billings",
        "Nicholas Skytland",
        "Alicia Llewellyn",
        "Jackson Paull",
        "Nathan Paull",
        "Nolan Kurylo",
        "Keatra Nesbitt",
        "Robert Gruenewald",
        "Anthony Jantzi",
        "Omar Chavez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:09:53+00:00",
          "link": "https://arxiv.org/abs/2507.07787v1",
          "size": "1130kb",
          "version": "v1"
        }
      ],
      "title": "Measuring AI Alignment with Human Flourishing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07787",
        "HTML": "https://arxiv.org/html/2507.07787v1",
        "PDF": "https://arxiv.org/pdf/2507.07787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a benchmarking framework for AI alignment with human flourishing, focusing on evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.16668",
      "abstract": "This work introduces a kernel-independent, multilevel, adaptive algorithm for efficiently evaluating a discrete convolution kernel with a given source distribution. The method is based on linear algebraic tools such as low rank approximation and ``skeleton representations'' to approximate far-field interactions. While this work is related to previous linear algebraic formulations of the fast multipole method, the proposed algorithm is distinguished by relying on simpler data structures.\n  The proposed algorithm eliminates the need for explicit interaction lists by restructuring computations to operate exclusively on the near-neighbor list at each level of the tree, thereby simplifying both implementation and data structures. This work also introduces novel translation operators that significantly simplify the handling of adaptive point distributions. As a kernel-independent approach, it only requires evaluation of the kernel function, making it easily adaptable to a variety of kernels. By using operations on the neighbor list (of size at most 27 in 3D) rather than the interaction list (of size up to 189 in 3D), the algorithm is particularly well-suited for parallel implementation on modern hardware.\n  Numerical experiments on uniform and non-uniform point distributions in 2D and 3D demonstrate the effectiveness of the proposed parallel algorithm for Laplace and (low-frequency) Helmholtz kernels. The algorithm constructs a tailored skeleton representation for the given geometry during a precomputation stage. After precomputation, the fast summation achieves high efficiency on the GPU using batched linear algebra operations.",
      "authors": [
        "Anna Yesypenko",
        "Chao Chen",
        "and Per-Gunnar Martinsson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-25T14:34:07+00:00",
          "link": "https://arxiv.org/abs/2310.16668v1",
          "size": "1063kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T01:28:16+00:00",
          "link": "https://arxiv.org/abs/2310.16668v2",
          "size": "1370kb",
          "version": "v2"
        }
      ],
      "title": "A Simplified Fast Multipole Method Based on Strong Recursive Skeletonization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.16668",
        "HTML": "https://arxiv.org/html/2310.16668v2",
        "PDF": "https://arxiv.org/pdf/2310.16668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a fast multipole method for discrete convolution kernels, focusing on computational algorithms rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07621",
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) leverages labeled source domain graphs to achieve effective performance in unlabeled target domains despite distribution shifts. However, existing methods often yield suboptimal results due to the entanglement of causal-spurious features and the failure of global alignment strategies. We propose SLOGAN (Sparse Causal Discovery with Generative Intervention), a novel approach that achieves stable graph representation transfer through sparse causal modeling and dynamic intervention mechanisms. Specifically, SLOGAN first constructs a sparse causal graph structure, leveraging mutual information bottleneck constraints to disentangle sparse, stable causal features while compressing domain-dependent spurious correlations through variational inference. To address residual spurious correlations, we innovatively design a generative intervention mechanism that breaks local spurious couplings through cross-domain feature recombination while maintaining causal feature semantic consistency via covariance constraints. Furthermore, to mitigate error accumulation in target domain pseudo-labels, we introduce a category-adaptive dynamic calibration strategy, ensuring stable discriminative learning. Extensive experiments on multiple real-world datasets demonstrate that SLOGAN significantly outperforms existing baselines.",
      "authors": [
        "Junyu Luo",
        "Yuhao Tang",
        "Yiwei Fu",
        "Xiao Luo",
        "Zhizhuo Kou",
        "Zhiping Xiao",
        "Wei Ju",
        "Wentao Zhang",
        "Ming Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:42:21+00:00",
          "link": "https://arxiv.org/abs/2507.07621v1",
          "size": "2125kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07621",
        "HTML": "https://arxiv.org/html/2507.07621v1",
        "PDF": "https://arxiv.org/pdf/2507.07621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around graph domain adaptation using sparse causal discovery and does not involve any LLM training data processing or dataset creation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07885",
      "abstract": "Existing pruning methods are typically applied during training or compile time and often rely on structured sparsity. While compatible with low-power microcontrollers (MCUs), structured pruning underutilizes the opportunity for fine-grained efficiency on devices without SIMD support or parallel compute. To address these limitations, we introduce UnIT (Unstructured Inference-Time pruning), a lightweight method that dynamically identifies and skips unnecessary multiply-accumulate (MAC) operations during inference, guided by input-specific activation patterns. Unlike structured pruning, UnIT embraces irregular sparsity and does not require retraining or hardware specialization. It transforms pruning decisions into lightweight comparisons, replacing multiplications with threshold checks and approximated divisions. UnIT further optimizes compute by reusing threshold computations across multiple connections and applying layer- and group-specific pruning sensitivity. We present three fast, hardware-friendly division approximations tailored to the capabilities of common embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT achieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and 27.33% to 84.38% lower energy consumption compared to training-time pruned models, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT matches or exceeds the accuracy of retrained models while requiring significantly fewer MACs. These results establish unstructured inference-time pruning as a viable and practical solution for efficient, retraining-free deployment of deep neural networks on MCUs.",
      "authors": [
        "Ashe Neth",
        "Sawinder kaur",
        "Mohammad Nur Hossain Khan",
        "Subrata Biswas",
        "Asif Salekin",
        "Bashima Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:12:06+00:00",
          "link": "https://arxiv.org/abs/2507.07885v1",
          "size": "1072kb",
          "version": "v1"
        }
      ],
      "title": "UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07885",
        "HTML": "https://arxiv.org/html/2507.07885v1",
        "PDF": "https://arxiv.org/pdf/2507.07885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper elaborates on inference-time pruning for neural networks on microcontrollers, focusing on efficiency in inference rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07906",
      "abstract": "Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.",
      "authors": [
        "Anant Gupta",
        "Rajarshi Bhowmik",
        "Geoffrey Gunow"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:38:59+00:00",
          "link": "https://arxiv.org/abs/2507.07906v1",
          "size": "914kb",
          "version": "v1"
        }
      ],
      "title": "Agentic Retrieval of Topics and Insights from Earnings Calls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07906",
        "HTML": "https://arxiv.org/html/2507.07906v1",
        "PDF": "https://arxiv.org/pdf/2507.07906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for extracting topics from earnings calls using an LLM-agent but does not focus on LLM training data processing or improving LLM data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07248",
      "abstract": "As the performance of large language models (LLMs) continues to advance, their adoption is expanding across a wide range of domains, including the medical field. The integration of LLMs into medical applications raises critical safety concerns, particularly due to their use by users with diverse roles, e.g. patients and clinicians, and the potential for model's outputs to directly affect human health. Despite the domain-specific capabilities of medical LLMs, prior safety evaluations have largely focused only on general safety benchmarks. In this paper, we introduce a safety evaluation protocol tailored to the medical domain in both patient user and clinician user perspectives, alongside general safety assessments and quantitatively analyze the safety of medical LLMs. We bridge a gap in the literature by building the PatientSafetyBench containing 466 samples over 5 critical categories to measure safety from the perspective of the patient. We apply our red-teaming protocols on the MediPhi model collection as a case study. To our knowledge, this is the first work to define safety evaluation criteria for medical LLMs through targeted red-teaming taking three different points of view - patient, clinician, and general user - establishing a foundation for safer deployment in medical domains.",
      "authors": [
        "Minseon Kim",
        "Jean-Philippe Corbeil",
        "Alessandro Sordoni",
        "Francois Beaulieu",
        "Paul Vozila"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T19:38:58+00:00",
          "link": "https://arxiv.org/abs/2507.07248v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07248",
        "PDF": "https://arxiv.org/pdf/2507.07248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a safety evaluation protocol for medical LLMs but does not focus on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07396",
      "abstract": "Spiking Neural Networks (SNNs), inspired by biological neural mechanisms, represent a promising neuromorphic computing paradigm that offers energy-efficient alternatives to traditional Artificial Neural Networks (ANNs). Despite proven effectiveness, SNN architectures have struggled to achieve competitive performance on large-scale speech processing task. Two key challenges hinder progress: (1) the high computational overhead during training caused by multi-timestep spike firing, and (2) the absence of large-scale SNN architectures tailored to speech processing tasks. To overcome the issues, we introduce Input-aware Multi-Level Spikeformer, i.e. IML-Spikeformer, a spiking Transformer architecture specifically designed for large-scale speech processing. Central to our design is the Input-aware Multi-Level Spike (IMLS) mechanism, which simulate multi-timestep spike firing within a single timestep using an adaptive, input-aware thresholding scheme. IML-Spikeformer further integrates a Reparameterized Spiking Self-Attention (RepSSA) module with a Hierarchical Decay Mask (HDM), forming the HD-RepSSA module. This module enhances the precision of attention maps and enables modeling of multi-scale temporal dependencies in speech signals. Experiments demonstrate that IML-Spikeformer achieves word error rates of 6.0\\% on AiShell-1 and 3.4\\% on Librispeech-960, comparable to conventional ANN transformers while reducing theoretical inference energy consumption by 4.64$\\times$ and 4.32$\\times$ respectively. IML-Spikeformer marks an advance of scalable SNN architectures for large-scale speech processing in both task performance and energy efficiency.",
      "authors": [
        "Zeyang Song",
        "Shimin Zhang",
        "Yuhong Chou",
        "Jibin Wu",
        "Haizhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T03:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.07396v1",
          "size": "9489kb",
          "version": "v1"
        }
      ],
      "title": "IML-Spikeformer: Input-aware Multi-Level Spiking Transformer for Speech Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07396",
        "HTML": "https://arxiv.org/html/2507.07396v1",
        "PDF": "https://arxiv.org/pdf/2507.07396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "IML-Spikeformer deals with spiking neural networks for speech processing and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.15462",
      "abstract": "We prove the following type of discrete entropy monotonicity for sums of isotropic, log-concave, independent and identically distributed random vectors $X_1,\\dots,X_{n+1}$ on $\\mathbb{Z}^d$: $$ H(X_1+\\cdots+X_{n+1}) \\geq H(X_1+\\cdots+X_{n}) + \\frac{d}{2}\\log{\\Bigl(\\frac{n+1}{n}\\Bigr)} +o(1), $$ where $o(1)$ vanishes as $H(X_1) \\to \\infty$. Moreover, for the $o(1)$-term, we obtain a rate of convergence $ O\\Bigl({H(X_1)}{e^{-\\frac{1}{d}H(X_1)}}\\Bigr)$, where the implied constants depend on $d$ and $n$. This generalizes to $\\mathbb{Z}^d$ the one-dimensional result of the second named author (2023). As in dimension one, our strategy is to establish that the discrete entropy $H(X_1+\\cdots+X_{n})$ is close to the differential (continuous) entropy $h(X_1+U_1+\\cdots+X_{n}+U_{n})$, where $U_1,\\dots, U_n$ are independent and identically distributed uniform random vectors on $[0,1]^d$ and to apply the theorem of Artstein, Ball, Barthe and Naor (2004) on the monotonicity of differential entropy. In fact, we show this result under more general assumptions than log-concavity, which are preserved up to constants under convolution. In order to show that log-concave distributions satisfy our assumptions in dimension $d\\ge2$, more involved tools from convex geometry are needed because a suitable position is required. We show that, for a log-concave function on $\\mathbb{R}^d$ in isotropic position, its integral, barycenter and covariance matrix are close to their discrete counterparts. Moreover, in the log-concave case, we weaken the isotropicity assumption to what we call almost isotropicity. One of our technical tools is a discrete analogue to the upper bound on the isotropic constant of a log-concave function, which extends to dimensions $d\\ge1$ a result of Bobkov, Marsiglietti and Melbourne (2022).",
      "authors": [
        "Matthieu Fradelizi",
        "Lampros Gavalakis",
        "Martin Rapaport"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-27T17:05:00+00:00",
          "link": "https://arxiv.org/abs/2401.15462v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2024-07-07T12:35:18+00:00",
          "link": "https://arxiv.org/abs/2401.15462v2",
          "size": "41kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T14:47:07+00:00",
          "link": "https://arxiv.org/abs/2401.15462v3",
          "size": "47kb",
          "version": "v3"
        }
      ],
      "title": "On the monotonicity of discrete entropy for log-concave random vectors on $\\mathbb{Z}^d$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.15462",
        "HTML": "https://arxiv.org/html/2401.15462v3",
        "PDF": "https://arxiv.org/pdf/2401.15462"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses entropy monotonicity for random vectors, without any focus on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.06553",
      "abstract": "In swarm robotics, decentralized control is often proposed as a more scalable and fault-tolerant alternative to centralized control. However, centralized behaviors are often faster and more efficient than their decentralized counterparts. In any given application, the goals and constraints of the task being solved should guide the choice to use centralized control, decentralized control, or a combination of the two. Currently, the exact trade-offs that exist between centralization and decentralization are not well defined. In this paper, we study comparative performance assessment between centralization and decentralization in the example task of sweep coverage, across five different types of multi-robot control structures: random walk, decentralized with beacons, hybrid formation control using self-organizing hierarchy, centralized formation control, and predetermined. In all five approaches, the coverage task is completed by a group of ground robots. In each approach, except for the random walk, the ground robots are assisted by UAVs, acting as supervisors or beacons. We compare the approaches in terms of three performance metrics for which centralized approaches are expected to have an advantage -- coverage completeness, coverage uniformity, and sweep completion time -- and two metrics for which decentralized approaches are expected to have an advantage -- scalability (4, 8, or 16 ground robots) and fault tolerance (0%, 25%, 50%, or 75% ground robot failure).",
      "authors": [
        "Aryo Jamshidpey",
        "Mostafa Wahby",
        "Michael Allwright",
        "Weixu Zhu",
        "Marco Dorigo",
        "Mary Katherine Heinrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T01:33:19+00:00",
          "link": "https://arxiv.org/abs/2408.06553v1",
          "size": "2223kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T22:56:23+00:00",
          "link": "https://arxiv.org/abs/2408.06553v2",
          "size": "4690kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T20:44:13+00:00",
          "link": "https://arxiv.org/abs/2408.06553v3",
          "size": "4689kb",
          "version": "v3"
        }
      ],
      "title": "Centralization vs. decentralization in multi-robot sweep coverage with ground robots and UAVs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06553",
        "HTML": "https://arxiv.org/html/2408.06553v3",
        "PDF": "https://arxiv.org/pdf/2408.06553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses control structures in swarm robotics for sweep coverage tasks without addressing LLM training data processing or contributing new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11315",
      "abstract": "Two-class classification problems are often characterized by an imbalance between the number of majority and minority datapoints resulting in poor classification of the minority class in particular. Traditional approaches, such as reweighting the loss function or na\\\"ive resampling, risk overfitting and subsequently fail to improve classification because they do not consider the diversity between majority and minority datasets. Such consideration is infeasible because there is no metric that can measure the impact of imbalance on the model. To obviate these challenges, we make two key contributions. First, we introduce MOODS~(Multi-Objective Optimization for Data Sampling), a novel multi-objective bilevel optimization framework that guides both synthetic oversampling and majority undersampling. Second, we introduce a validation metric -- `$\\epsilon/ \\delta$ non-overlapping diversification metric' -- that quantifies the goodness of a sampling method towards model performance. With this metric we experimentally demonstrate state-of-the-art performance with improvement in diversity driving a $1-15 \\%$ increase in $F1$ scores.",
      "authors": [
        "Karen Medlin",
        "Sven Leyffer and Krishnan Raghavan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T21:31:08+00:00",
          "link": "https://arxiv.org/abs/2506.11315v1",
          "size": "683kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T16:24:53+00:00",
          "link": "https://arxiv.org/abs/2506.11315v2",
          "size": "684kb",
          "version": "v2"
        }
      ],
      "title": "Sampling Imbalanced Data with Multi-objective Bilevel Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11315",
        "HTML": "https://arxiv.org/html/2506.11315v2",
        "PDF": "https://arxiv.org/pdf/2506.11315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for sampling imbalanced data in classification tasks, but it does not focus on LLM training data processing or related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07485",
      "abstract": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.",
      "authors": [
        "Wooseong Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.07485v1",
          "size": "1089kb",
          "version": "v1"
        }
      ],
      "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07485",
        "HTML": "https://arxiv.org/html/2507.07485v1",
        "PDF": "https://arxiv.org/pdf/2507.07485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses token-space gradient conflicts in multi-task learning within transformer architectures, focusing on model adaptability rather than any specific processing or engineering of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07949",
      "abstract": "Human Activity Recognition (HAR) on resource-constrained wearable devices demands inference models that harmonize accuracy with computational efficiency. This paper introduces TinierHAR, an ultra-lightweight deep learning architecture that synergizes residual depthwise separable convolutions, gated recurrent units (GRUs), and temporal aggregation to achieve SOTA efficiency without compromising performance. Evaluated across 14 public HAR datasets, TinierHAR reduces Parameters by 2.7x (vs. TinyHAR) and 43.3x (vs. DeepConvLSTM), and MACs by 6.4x and 58.6x, respectively, while maintaining the averaged F1-scores. Beyond quantitative gains, this work provides the first systematic ablation study dissecting the contributions of spatial-temporal components across proposed TinierHAR, prior SOTA TinyHAR, and the classical DeepConvLSTM, offering actionable insights for designing efficient HAR systems. We finally discussed the findings and suggested principled design guidelines for future efficient HAR. To catalyze edge-HAR research, we open-source all materials in this work for future benchmarking\\footnote{https://github.com/zhaxidele/TinierHAR}",
      "authors": [
        "Sizhen Bian and Mengxi Liu and Vitor Fortes Rey and Daniel Geissler and Paul Lukowicz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:33:52+00:00",
          "link": "https://arxiv.org/abs/2507.07949v1",
          "size": "3574kb",
          "version": "v1"
        }
      ],
      "title": "TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient Human Activity Recognition on Edge Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07949",
        "HTML": "https://arxiv.org/html/2507.07949v1",
        "PDF": "https://arxiv.org/pdf/2507.07949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Human Activity Recognition models primarily through architectural optimizations and efficient model design, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.18845",
      "abstract": "As the application of AI continues to expand, students in technology programs are poised to be both producers and users of the technologies. They are also positioned to engage with AI applications within and outside the classroom. While focusing on the curriculum when examining students' AI knowledge is common, extending this connection to students' everyday interactions with AI provides a more complete picture of their learning. In this paper, we explore student's awareness and engagement with AI in the context of school and their daily lives. Over six weeks, 22 undergraduate students participated in a reflective journal study and submitted a weekly journal entry about their interactions with AI. The participants were recruited from a technology and society course that focuses on the implications of technology on people, communities, and processes. In their weekly journal entries, participants reflected on interactions with AI on campus (coursework, advertises campus events, or seminars) and beyond (social media, news, or conversations with friends and family). The journal prompts were designed to help them think through what they had read, watched, or been told and reflect on the development of their own perspectives, knowledge, and literacy on the topic. Overall, students described nine categories of interactions: coursework, news and current events, using software and applications, university events, social media related to their work, personal discussions with friends and family, interacting with content, and gaming. Students reported that completing the diaries allowed them time for reflection and made them more aware of the presence of AI in their daily lives and of its potential benefits and drawbacks. This research contributes to the ongoing work on AI awareness and literacy by bringing in perspectives from beyond a formal educational context.",
      "authors": [
        "Ashish Hingle",
        "Aditya Johri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T15:26:34+00:00",
          "link": "https://arxiv.org/abs/2410.18845v1",
          "size": "707kb",
          "version": "v1"
        }
      ],
      "title": "Expanding AI Awareness Through Everyday Interactions with AI: A Reflective Journal Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.18845",
        "HTML": "https://arxiv.org/html/2410.18845",
        "PDF": "https://arxiv.org/pdf/2410.18845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines AI awareness through reflective journals but does not involve any aspect of LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07852",
      "abstract": "We study a sequential contextual decision-making problem in which certain covariates are missing but can be imputed using a pre-trained AI model. From a theoretical perspective, we analyze how the presence of such a model influences the regret of the decision-making process. We introduce a novel notion called \"model elasticity\", which quantifies the sensitivity of the reward function to the discrepancy between the true covariate and its imputed counterpart. This concept provides a unified way to characterize the regret incurred due to model imputation, regardless of the underlying missingness mechanism. More surprisingly, we show that under the missing at random (MAR) setting, it is possible to sequentially calibrate the pre-trained model using tools from orthogonal statistical learning and doubly robust regression. This calibration significantly improves the quality of the imputed covariates, leading to much better regret guarantees. Our analysis highlights the practical value of having an accurate pre-trained model in sequential decision-making tasks and suggests that model elasticity may serve as a fundamental metric for understanding and improving the integration of pre-trained models in a wide range of data-driven decision-making problems.",
      "authors": [
        "Haichen Hu",
        "David Simchi-Levi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T15:33:27+00:00",
          "link": "https://arxiv.org/abs/2507.07852v1",
          "size": "1431kb",
          "version": "v1"
        }
      ],
      "title": "Pre-Trained AI Model Assisted Online Decision-Making under Missing Covariates: A Theoretical Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07852",
        "HTML": "https://arxiv.org/html/2507.07852v1",
        "PDF": "https://arxiv.org/pdf/2507.07852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with imputation of missing covariates using a pre-trained AI model in decision-making contexts, without addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07972",
      "abstract": "Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for computation to be performed directly on encrypted data, effectively closing the loop on secure and outsourced computing. Data is encrypted not only during rest and transit, but also during processing. However, FHE provides a limited instruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D vectors. This restriction makes performing multi-dimensional tensor operations challenging. Practitioners must pack these tensors into 1-D vectors and map tensor operations onto this one-dimensional layout rather than their traditional nested structure. And while prior systems have made significant strides in automating this process, they often hide critical packing decisions behind layers of abstraction, making debugging, optimizing, and building on top of these systems difficult.\n  In this work, we approach multi-dimensional tensor operations in FHE through Einstein summation (einsum) notation. Einsum notation explicitly encodes dimensional structure and operations in its syntax, naturally exposing how tensors should be packed and transformed. We decompose einsum expressions into a fixed set of FHE-friendly operations. We implement our design and present EinHops, a minimalist system that factors einsum expressions into a fixed sequence of FHE operations. EinHops enables developers to perform encrypted tensor operations using FHE while maintaining full visibility into the underlying packing strategy. We evaluate EinHops on a range of tensor operations from a simple transpose to complex multi-dimensional contractions. We show that the explicit nature of einsum notation allows us to build an FHE tensor system that is simple, general, and interpretable. We open-source EinHops at the following repository: https://github.com/baahl-nyu/einhops.",
      "authors": [
        "Karthik Garimella",
        "Austin Ebel",
        "Brandon Reagen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:50:10+00:00",
          "link": "https://arxiv.org/abs/2507.07972v1",
          "size": "1780kb",
          "version": "v1"
        }
      ],
      "title": "EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07972",
        "HTML": "https://arxiv.org/html/2507.07972v1",
        "PDF": "https://arxiv.org/pdf/2507.07972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with tensor operations in the context of Fully Homomorphic Encryption and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07981",
      "abstract": "Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Towards a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models.",
      "authors": [
        "Noam Razin",
        "Yong Lin",
        "Jiarui Yao",
        "Sanjeev Arora"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:55:05+00:00",
          "link": "https://arxiv.org/abs/2507.07981v1",
          "size": "2289kb",
          "version": "v1"
        }
      ],
      "title": "Why is Your Language Model a Poor Implicit Reward Model?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07981",
        "HTML": "https://arxiv.org/html/2507.07981v1",
        "PDF": "https://arxiv.org/pdf/2507.07981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding reward models in language models but does not discuss processing, creation, or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07136",
      "abstract": "In this paper, we introduce LangSplatV2, which achieves high-dimensional feature splatting at 476.2 FPS and 3D open-vocabulary text querying at 384.6 FPS for high-resolution images, providing a 42 $\\times$ speedup and a 47 $\\times$ boost over LangSplat respectively, along with improved query accuracy. LangSplat employs Gaussian Splatting to embed 2D CLIP language features into 3D, significantly enhancing speed and learning a precise 3D language field with SAM semantics. Such advancements in 3D language fields are crucial for applications that require language interaction within complex scenes. However, LangSplat does not yet achieve real-time inference performance (8.2 FPS), even with advanced A100 GPUs, severely limiting its broader application. In this paper, we first conduct a detailed time analysis of LangSplat, identifying the heavyweight decoder as the primary speed bottleneck. Our solution, LangSplatV2 assumes that each Gaussian acts as a sparse code within a global dictionary, leading to the learning of a 3D sparse coefficient field that entirely eliminates the need for a heavyweight decoder. By leveraging this sparsity, we further propose an efficient sparse coefficient splatting method with CUDA optimization, rendering high-dimensional feature maps at high quality while incurring only the time cost of splatting an ultra-low-dimensional feature. Our experimental results demonstrate that LangSplatV2 not only achieves better or competitive query accuracy but is also significantly faster. Codes and demos are available at our project page: https://langsplat-v2.github.io.",
      "authors": [
        "Wanhua Li",
        "Yujie Zhao",
        "Minghan Qin",
        "Yang Liu",
        "Yuanhao Cai",
        "Chuang Gan",
        "Hanspeter Pfister"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:19:58+00:00",
          "link": "https://arxiv.org/abs/2507.07136v1",
          "size": "2575kb",
          "version": "v1"
        }
      ],
      "title": "LangSplatV2: High-dimensional 3D Language Gaussian Splatting with 450+ FPS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07136",
        "HTML": "https://arxiv.org/html/2507.07136v1",
        "PDF": "https://arxiv.org/pdf/2507.07136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rapid high-dimensional 3D language querying and optimization techniques for LangSplatV2, without discussing any training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07448",
      "abstract": "Quantum computing proposes a revolutionary paradigm that can radically transform numerous scientific and industrial application domains. To realize this promise, these new capabilities need software solutions that are able to effectively harness its power. However, developers may face significant challenges when developing and executing quantum software due to the limited availability of quantum computer hardware, high computational demands of simulating quantum computers on classical systems, and complicated technology stack to enable currently available accelerators into development environments. These limitations make it difficult for the developer to create an efficient workflow for quantum software development. In this paper, we investigate the potential of using remote computational capabilities in an efficient manner to improve the workflow of quantum software developers, by lowering the barrier of moving between local execution and computationally more efficient remote hardware and offering speedup in execution with simulator surroundings. The goal is to allow the development of more complex circuits and to support an iterative software development approach. In our experiment, with the solution presented in this paper, we have obtained up to 5 times faster circuit execution runtime, and enabled qubit ranges from 21 to 29 qubits with a simple plug-and-play kernel for the Jupyter notebook.",
      "authors": [
        "Otso Kinanen and Andr\\'es D. Mu\\~noz-Moller and Vlad Stirbu and Tommi Mikkonen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T05:56:26+00:00",
          "link": "https://arxiv.org/abs/2507.07448v1",
          "size": "740kb",
          "version": "v1"
        }
      ],
      "title": "Toolchain for Faster Iterations in Quantum Software Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07448",
        "HTML": "https://arxiv.org/html/2507.07448v1",
        "PDF": "https://arxiv.org/pdf/2507.07448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates methods for improving quantum software development workflows, unrelated to LLM training data processing or dataset enhancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07526",
      "abstract": "Decoding speech from brain signals is a challenging research problem. Although existing technologies have made progress in reconstructing the mel spectrograms of auditory stimuli at the word or letter level, there remain core challenges in the precise reconstruction of minute-level continuous imagined speech: traditional models struggle to balance the efficiency of temporal dependency modeling and information retention in long-sequence decoding. To address this issue, this paper proposes the Dynamic Multiscale Fusion Network (DMF2Mel), which consists of four core components: the Dynamic Contrastive Feature Aggregation Module (DC-FAM), the Hierarchical Attention-Guided Multi-Scale Network (HAMS-Net), the SplineMap attention mechanism, and the bidirectional state space module (convMamba). Specifically, the DC-FAM separates speech-related \"foreground features\" from noisy \"background features\" through local convolution and global attention mechanisms, effectively suppressing interference and enhancing the representation of transient signals. HAMS-Net, based on the U-Net framework,achieves cross-scale fusion of high-level semantics and low-level details. The SplineMap attention mechanism integrates the Adaptive Gated Kolmogorov-Arnold Network (AGKAN) to combine global context modeling with spline-based local fitting. The convMamba captures long-range temporal dependencies with linear complexity and enhances nonlinear dynamic modeling capabilities. Results on the SparrKULee dataset show that DMF2Mel achieves a Pearson correlation coefficient of 0.074 in mel spectrogram reconstruction for known subjects (a 48% improvement over the baseline) and 0.048 for unknown subjects (a 35% improvement over the baseline).Code is available at: https://github.com/fchest/DMF2Mel.",
      "authors": [
        "Cunhang Fan",
        "Sheng Zhang",
        "Jingjing Zhang",
        "Enrui Liu",
        "Xinhui Li",
        "Minggang Zhao",
        "Zhao Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:15:03+00:00",
          "link": "https://arxiv.org/abs/2507.07526v1",
          "size": "857kb",
          "version": "v1"
        }
      ],
      "title": "DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel Spectrogram Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07526",
        "HTML": "https://arxiv.org/html/2507.07526v1",
        "PDF": "https://arxiv.org/pdf/2507.07526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses EEG-driven mel spectrogram reconstruction for speech decoding, focusing on a neural network architecture rather than LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07694",
      "abstract": "The attention mechanism is a core component of the Transformer architecture. Various methods have been developed to compute attention scores, including multi-head attention (MHA), multi-query attention, group-query attention and so on. We further analyze the MHA and observe that its performance improves as the number of attention heads increases, provided the hidden size per head remains sufficiently large. Therefore, increasing both the head count and hidden size per head with minimal parameter overhead can lead to significant performance gains at a low cost. Motivated by this insight, we introduce Simulated Attention Score (SAS), which maintains a compact model size while simulating a larger number of attention heads and hidden feature dimension per head. This is achieved by projecting a low-dimensional head representation into a higher-dimensional space, effectively increasing attention capacity without increasing parameter count. Beyond the head representations, we further extend the simulation approach to feature dimension of the key and query embeddings, enhancing expressiveness by mimicking the behavior of a larger model while preserving the original model size. To control the parameter cost, we also propose Parameter-Efficient Attention Aggregation (PEAA). Comprehensive experiments on a variety of datasets and tasks demonstrate the effectiveness of the proposed SAS method, achieving significant improvements over different attention variants.",
      "authors": [
        "Chuanyang Zheng",
        "Jiankai Sun",
        "Yihang Gao",
        "Yuehao Wang",
        "Peihao Wang",
        "Jing Xiong",
        "Liliang Ren",
        "Hao Cheng",
        "Janardhan Kulkarni",
        "Yelong Shen",
        "Atlas Wang",
        "Mac Schwager",
        "Anderson Schneider",
        "Xiaodong Liu",
        "Jianfeng Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:16:16+00:00",
          "link": "https://arxiv.org/abs/2507.07694v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "SAS: Simulated Attention Score",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07694",
        "HTML": "https://arxiv.org/html/2507.07694v1",
        "PDF": "https://arxiv.org/pdf/2507.07694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the attention mechanism within Transformer models via Simulated Attention Score (SAS) but does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07878",
      "abstract": "Underwater image restoration algorithms seek to restore the color, contrast, and appearance of a scene that is imaged underwater. They are a critical tool in applications ranging from marine ecology and aquaculture to underwater construction and archaeology. While existing pixel-domain diffusion-based image restoration approaches are effective at restoring simple scenes with limited depth variation, they are computationally intensive and often generate unrealistic artifacts when applied to scenes with complex geometry and significant depth variation. In this work we overcome these limitations by combining a novel network architecture (SLURPP) with an accurate synthetic data generation pipeline. SLURPP combines pretrained latent diffusion models -- which encode strong priors on the geometry and depth of scenes -- with an explicit scene decomposition -- which allows one to model and account for the effects of light attenuation and backscattering. To train SLURPP we design a physics-based underwater image synthesis pipeline that applies varied and realistic underwater degradation effects to existing terrestrial image datasets. This approach enables the generation of diverse training data with dense medium/degradation annotations. We evaluate our method extensively on both synthetic and real-world benchmarks and demonstrate state-of-the-art performance. Notably, SLURPP is over 200X faster than existing diffusion-based methods while offering ~ 3 dB improvement in PSNR on synthetic benchmarks. It also offers compelling qualitative improvements on real-world data. Project website https://tianfwang.github.io/slurpp/.",
      "authors": [
        "Jiayi Wu",
        "Tianfu Wang",
        "Md Abu Bakr Siddique",
        "Md Jahidul Islam",
        "Cornelia Fermuller",
        "Yiannis Aloimonos",
        "Christopher A. Metzler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.07878v1",
          "size": "34458kb",
          "version": "v1"
        }
      ],
      "title": "Single-Step Latent Diffusion for Underwater Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07878",
        "HTML": "https://arxiv.org/html/2507.07878v1",
        "PDF": "https://arxiv.org/pdf/2507.07878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a novel network architecture and a synthetic data generation pipeline for underwater image restoration, emphasizing detailed data processing steps to improve training data quality for model performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07942",
      "abstract": "In the field of constraint satisfaction problems (CSP), a clause is called redundant if its satisfaction is implied by satisfying all other clauses. An instance of CSP$(P)$ is called non-redundant if it does not contain any redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum number of clauses in a non-redundant instance of CSP$(P)$, as a function of the number of variables $n$. Recent progress has shown that non-redundancy is crucially linked to many other important questions in computer science and mathematics including sparsification, kernelization, query complexity, universal algebra, and extremal combinatorics. Given that non-redundancy is a nexus for many of these important problems, the central goal of this paper is to more deeply understand non-redundancy.\n  Our first main result shows that for every rational number $r \\ge 1$, there exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is $\\Theta(n^r)$. Our second main result explores the concept of conditional non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We completely classify the conditional non-redundancy of all binary predicates (i.e., constraints on two variables) by connecting these non-redundancy problems to the structure of high-girth graphs in extremal combinatorics.\n  Inspired by these concrete results, we build off the work of Carbonnel [CP 2022] to develop an algebraic theory of conditional non-redundancy. As an application of this algebraic theory, we revisit the notion of Mal'tsev embeddings, which is the most general technique known to date for establishing that a predicate has linear non-redundancy. For example, we provide the first example of predicate with a Mal'tsev embedding that cannot be attributed to the structure of an Abelian group, but rather to the structure of the quantum Pauli group.",
      "authors": [
        "Joshua Brakensiek",
        "Venkatesan Guruswami",
        "Bart M. P. Jansen",
        "Victor Lagerkvist",
        "Magnus Wahlstr\\\"om"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computational Complexity (cs.CC)",
        "Logic in Computer Science (cs.LO)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:29:21+00:00",
          "link": "https://arxiv.org/abs/2507.07942v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "The Richness of CSP Non-redundancy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07942",
        "HTML": "https://arxiv.org/html/2507.07942v1",
        "PDF": "https://arxiv.org/pdf/2507.07942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on constraint satisfaction problems and non-redundancy, which does not pertain to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.10393",
      "abstract": "Offline reinforcement learning (RL) aims to learn policies without online explorations. To enlarge the training data, model-based offline RL learns a dynamics model which is utilized as a virtual environment to generate simulation data and enhance policy learning. However, existing data augmentation methods for offline RL suffer from (i) trivial improvement from short-horizon simulation; and (ii) the lack of evaluation and correction for generated data, leading to low-qualified augmentation.\n  In this paper, we propose offline trajectory optimization for offline reinforcement learning (OTTO). The key motivation is to conduct long-horizon simulation and then utilize model uncertainty to evaluate and correct the augmented data. Specifically, we propose an ensemble of Transformers, a.k.a. World Transformers, to predict environment state dynamics and the reward function. Three strategies are proposed to use World Transformers to generate long-horizon trajectory simulation by perturbing the actions in the offline data. Then, an uncertainty-based World Evaluator is introduced to firstly evaluate the confidence of the generated trajectories and then perform the correction for low-confidence data. Finally, we jointly use the original data with the corrected augmentation data to train an offline RL algorithm. OTTO serves as a plug-in module and can be integrated with existing model-free offline RL methods. Experiments on various benchmarks show that OTTO can effectively improve the performance of representative offline RL algorithms, including in complex environments with sparse rewards like AntMaze. Codes are available at https://github.com/ZiqiZhao1/OTTO.",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Liu Yang",
        "Yunsen Liang",
        "Fajie Yuan",
        "Pengjie Ren",
        "Zhumin Chen",
        "jun Ma",
        "Xin Xin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-16T08:48:46+00:00",
          "link": "https://arxiv.org/abs/2404.10393v1",
          "size": "4596kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T10:09:40+00:00",
          "link": "https://arxiv.org/abs/2404.10393v2",
          "size": "1963kb",
          "version": "v2"
        }
      ],
      "title": "Offline Trajectory Optimization for Offline Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.10393",
        "HTML": "https://arxiv.org/html/2404.10393v2",
        "PDF": "https://arxiv.org/pdf/2404.10393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily deals with improving offline reinforcement learning through trajectory optimization and simulation, not focusing on processing LLM training data."
      },
      "tasks": [
        "D4RL",
        "Data Augmentation",
        "Offline RL",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.06118",
      "abstract": "Token communications is an emerging generative semantic communication concept that reduces transmission rates by using context and transformer-based token processing, with tokens serving as universal semantic units. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as ToDMA, where a large number of devices share a tokenizer and a modulation codebook for source and channel coding, respectively. Specifically, the source signal is tokenized into sequences, with each token modulated into a codeword. Codewords from multiple devices are transmitted simultaneously, resulting in overlap at the receiver. The receiver detects the transmitted tokens, assigns them to their respective sources, and mitigates token collisions by leveraging context and semantic orthogonality across the devices' messages. Simulations demonstrate that the proposed ToDMA framework outperforms context-unaware orthogonal and non-orthogonal communication methods in image transmission tasks, achieving lower latency and better image quality.",
      "authors": [
        "Li Qiao",
        "Mahdi Boloursaz Mashhadi",
        "Zhen Gao",
        "Deniz G\\\"und\\\"uz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T03:09:55+00:00",
          "link": "https://arxiv.org/abs/2502.06118v1",
          "size": "803kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:53:23+00:00",
          "link": "https://arxiv.org/abs/2502.06118v2",
          "size": "804kb",
          "version": "v2"
        }
      ],
      "title": "Token-Domain Multiple Access: Exploiting Semantic Orthogonality for Collision Mitigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06118",
        "HTML": "https://arxiv.org/html/2502.06118v2",
        "PDF": "https://arxiv.org/pdf/2502.06118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a semantic multiple access scheme using token processing, focusing on communication efficiency, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07983",
      "abstract": "Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology.",
      "authors": [
        "Sabine Felde",
        "R\\\"udiger Buchkremer",
        "Gamal Chehab",
        "Christian Thielscher",
        "J\\\"org HW Distler",
        "Matthias Schneider",
        "Jutta G. Richter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:56:03+00:00",
          "link": "https://arxiv.org/abs/2507.07983v1",
          "size": "527kb",
          "version": "v1"
        }
      ],
      "title": "Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07983",
        "PDF": "https://arxiv.org/pdf/2507.07983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The emphasis is on model performance for clinical decision support, with no specific discussion on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.05085",
      "abstract": "Retrieval Augmented Generation (RAG) enhances the abilities of Large Language Models (LLMs) by enabling the retrieval of documents into the LLM context to provide more accurate and relevant responses. Existing RAG solutions do not focus on queries that may require fetching multiple documents with substantially different contents. Such queries occur frequently, but are challenging because the embeddings of these documents may be distant in the embedding space, making it hard to retrieve them all. This paper introduces Multi-Head RAG (MRAG), a novel scheme designed to address this gap with a simple yet powerful idea: leveraging activations of Transformer's multi-head attention layer, instead of the decoder layer, as keys for fetching multi-aspect documents. The driving observation is that different attention heads learn to capture different data aspects. Harnessing the corresponding activations results in embeddings that represent various facets of data items and queries, improving the retrieval accuracy for complex queries. We provide an evaluation methodology and metrics, multi-aspect datasets, and real-world use cases to demonstrate MRAG's effectiveness. We show MRAG's design advantages over 18 RAG baselines, empirical improvements of up to 20% in retrieval success ratios, and benefits for downstream LLM generation. MRAG can be seamlessly integrated with existing RAG frameworks and benchmarks.",
      "authors": [
        "Maciej Besta",
        "Ales Kubicek",
        "Robert Gerstenberger",
        "Marcin Chrapek",
        "Roman Niggli",
        "Patrik Okanovic",
        "Yi Zhu",
        "Patrick Iff",
        "Michal Podstawski",
        "Lucas Weitzendorf",
        "Mingyuan Chi",
        "Joanna Gajda",
        "Piotr Nyczyk",
        "J\\\"urgen M\\\"uller",
        "Hubert Niewiadomski",
        "Torsten Hoefler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-07T16:59:38+00:00",
          "link": "https://arxiv.org/abs/2406.05085v1",
          "size": "700kb",
          "version": "v1"
        },
        {
          "date": "2024-11-19T08:46:34+00:00",
          "link": "https://arxiv.org/abs/2406.05085v2",
          "size": "3452kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T15:57:36+00:00",
          "link": "https://arxiv.org/abs/2406.05085v3",
          "size": "3489kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T08:38:59+00:00",
          "link": "https://arxiv.org/abs/2406.05085v4",
          "size": "3489kb",
          "version": "v4"
        }
      ],
      "title": "Multi-Head RAG: Solving Multi-Aspect Problems with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.05085",
        "PDF": "https://arxiv.org/pdf/2406.05085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Multi-Head RAG for improving LLM\u2019s retrieval of documents but does not primarily contribute to LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Decoder",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/vividwalker/Multi-Head-Rag",
        "https://github.com/spcl/mrag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07645",
      "abstract": "The integration of compressive sensing with real-time embedded systems opens new possibilities for efficient, low-power biomedical signal acquisition. This paper presents a custom hardware platform based on the RP2350 micro-controller, tailored for synchronized multi-modal biomedical monitoring. The system is capable of capturing cardiopulmonary sounds, along with biopotential signals such as phonocardiography (PCG), electrocardiography (ECG) and electromyography (EMG), photoplethysmography (PPG), and inertial measurement unit (IMU) data for posture recognition. To ensure sample-accurate synchronization, a Sub-1GHz radio system is used across multiple nodes. Wi-Fi and Bluetooth connectivity enable centralized data aggregation. Experimental results demonstrate the achieved decrease in power consumption when using compressive sensing, efficient multi-node synchronization, and scalability for wireless biomedical monitoring applications. The compact form factor and low-cost design make it suitable for various medical applications, including remote healthcare and long-term monitoring.",
      "authors": [
        "Rens Baeyens",
        "Dennis Laurijssen",
        "Jan Steckel and Walter Daems"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:18:42+00:00",
          "link": "https://arxiv.org/abs/2507.07645v1",
          "size": "3657kb",
          "version": "v1"
        }
      ],
      "title": "PhysioEdge: Multimodal Compressive Sensing Platform for Wearable Health Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07645",
        "HTML": "https://arxiv.org/html/2507.07645v1",
        "PDF": "https://arxiv.org/pdf/2507.07645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hardware platform for wearable health monitoring and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07341",
      "abstract": "With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content. Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter. Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular, black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment.",
      "authors": [
        "Sarah Ball",
        "Greg Gluch",
        "Shafi Goldwasser",
        "Frauke Kreuter",
        "Omer Reingold",
        "Guy N. Rothblum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T23:55:35+00:00",
          "link": "https://arxiv.org/abs/2507.07341v1",
          "size": "2247kb",
          "version": "v1"
        }
      ],
      "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07341",
        "HTML": "https://arxiv.org/html/2507.07341v1",
        "PDF": "https://arxiv.org/pdf/2507.07341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses computational challenges in filtering prompts and outputs for LLMs to prevent unsafe content generation, which is directly related to improving data quality and processing for alignment tuning in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07521",
      "abstract": "Trajectory modeling of dense points usually employs implicit deformation fields, represented as neural networks that map coordinates to relate canonical spatial positions to temporal offsets. However, the inductive biases inherent in neural networks can hinder spatial coherence in ill-posed scenarios. Current methods focus either on enhancing encoding strategies for deformation fields, often resulting in opaque and less intuitive models, or adopt explicit techniques like linear blend skinning, which rely on heuristic-based node initialization. Additionally, the potential of implicit representations for interpolating sparse temporal signals remains under-explored. To address these challenges, we propose a spline-based trajectory representation, where the number of knots explicitly determines the degrees of freedom. This approach enables efficient analytical derivation of velocities, preserving spatial coherence and accelerations, while mitigating temporal fluctuations. To model knot characteristics in both spatial and temporal domains, we introduce a novel low-rank time-variant spatial encoding, replacing conventional coupled spatiotemporal techniques. Our method demonstrates superior performance in temporal interpolation for fitting continuous fields with sparse inputs. Furthermore, it achieves competitive dynamic scene reconstruction quality compared to state-of-the-art methods while enhancing motion coherence without relying on linear blend skinning or as-rigid-as-possible constraints.",
      "authors": [
        "Mingyang Song",
        "Yang Zhang",
        "Marko Mihajlovic",
        "Siyu Tang",
        "Markus Gross",
        "Tun\\c{c} Ozan Ayd{\\i}n"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:11:46+00:00",
          "link": "https://arxiv.org/abs/2507.07521v1",
          "size": "45702kb",
          "version": "v1"
        }
      ],
      "title": "Spline Deformation Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07521",
        "HTML": "https://arxiv.org/html/2507.07521v1",
        "PDF": "https://arxiv.org/pdf/2507.07521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a spline-based approach for trajectory modeling, focusing on spatial and temporal coherence, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02952",
      "abstract": "We investigate various strategic locations of shops in shopping malls in a metropolis with the aim of finding the best strategy for final dominance of market share by a company in a competing environment. The problem is posed in the context of two competing supermarket chains in a metropolis, described in the framework of the two-dimensional Ising model. Evolutionary Algorithm is used to encode the ensemble of initial configurations and Monte Carlo method is used to evolve the pattern. Numerical simulation indicates that initial patterns with certain topological properties do evolve faster to market dominance. The description of these topological properties is given and suggestions are made on the initial pattern so as to evolve faster to market dominance.",
      "authors": [
        "Wing Keung Cheung and Kwok Yip Szeto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:52:35+00:00",
          "link": "https://arxiv.org/abs/2507.02952v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "Strategies for Resource Allocation of Two Competing Companies using Genetic Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02952",
        "PDF": "https://arxiv.org/pdf/2507.02952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about resource allocation using genetic algorithms without any relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07120",
      "abstract": "As LLMs scale to multi-million-token KV histories, real-time autoregressive decoding under tight Token-to-Token Latency (TTL) constraints faces growing pressure. Two core bottlenecks dominate: accessing Feed-Forward Network (FFN) weights and reading long KV caches. While Tensor Parallelism (TP) helps mitigate the cost of FFN weight reads, it does not scale well for attention. When TP width exceeds the number of KV heads, it leads to inefficient KV duplication, limits parallelism, and constrains batch size. Simultaneously, DRAM reads for long KV histories scale linearly with batch size, further capping efficiency.\n  We introduce Helix Parallelism, a hybrid execution strategy that applies KV parallelism during attention to shard KV caches across GPUs, then reuses the same GPUs for TP in dense LLMs or TPxExpert Parallel (EP) in MoEs during FFN computation. To preserve exact attention behavior, Helix includes a lightweight communication step. To minimize the exposed communication cost, we introduce Helix HOP-B. Helix HOP-B effectively minimizes communication overhead through batchwise overlap, preserving low TTL while improving GPU efficiency. Compared to conventional parallelism approaches, Helix reduces TTL by up to 1.5x at fixed batch sizes and supports up to 32x larger batches under the same latency budget for DeepSeek-R1, pushing forward the throughput-latency Pareto on Blackwell and making real-time inference with ultra-long-sequence practical.",
      "authors": [
        "Nidhi Bhatia",
        "Ankit More",
        "Ritika Borkar",
        "Tiyasa Mitra",
        "Ramon Matas",
        "Ritchie Zhao",
        "Maximilian Golub",
        "Dheevatsa Mudigere",
        "Brian Pharris",
        "Bita Darvish Rouhani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T19:47:24+00:00",
          "link": "https://arxiv.org/abs/2507.07120v1",
          "size": "2723kb",
          "version": "v1"
        }
      ],
      "title": "Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07120",
        "HTML": "https://arxiv.org/html/2507.07120v1",
        "PDF": "https://arxiv.org/pdf/2507.07120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses parallelism strategies for LLM decoding, focusing on efficiency in inference rather than processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07262",
      "abstract": "In this work, we address activity-biometrics, which involves identifying individuals across diverse set of activities. Unlike traditional person identification, this setting introduces additional challenges as identity cues become entangled with motion dynamics and appearance variations, making biometrics feature learning more complex. While additional visual data like pose and/or silhouette help, they often struggle from extraction inaccuracies. To overcome this, we propose a multimodal language-guided framework that replaces reliance on additional visual data with structured textual supervision. At its core, we introduce \\textbf{DisenQ} (\\textbf{Disen}tangling \\textbf{Q}-Former), a unified querying transformer that disentangles biometrics, motion, and non-biometrics features by leveraging structured language guidance. This ensures identity cues remain independent of appearance and motion variations, preventing misidentifications. We evaluate our approach on three activity-based video benchmarks, achieving state-of-the-art performance. Additionally, we demonstrate strong generalization to complex real-world scenario with competitive performance on a traditional video-based identification benchmark, showing the effectiveness of our framework.",
      "authors": [
        "Shehreen Azad",
        "Yogesh S Rawat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:16:16+00:00",
          "link": "https://arxiv.org/abs/2507.07262v1",
          "size": "4621kb",
          "version": "v1"
        }
      ],
      "title": "DisenQ: Disentangling Q-Former for Activity-Biometrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07262",
        "HTML": "https://arxiv.org/html/2507.07262v1",
        "PDF": "https://arxiv.org/pdf/2507.07262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a multimodal framework using language guidance, it primarily addresses biometric feature disentanglement and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07714",
      "abstract": "Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.",
      "authors": [
        "Julio Garrido",
        "Javier Vales",
        "Diego Silva-Mu\\~niz",
        "Enrique Riveiro",
        "Pablo L\\'opez-Matencio",
        "Josu\\'e Rivera-Andrade"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:52:19+00:00",
          "link": "https://arxiv.org/abs/2507.07714v1",
          "size": "4868kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07714",
        "HTML": "https://arxiv.org/html/2507.07714v1",
        "PDF": "https://arxiv.org/pdf/2507.07714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on anomaly detection in robotics using Gaussian Mixture Models, with no discussion on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11171",
      "abstract": "Data rebalancing techniques, including oversampling and undersampling, are a common approach to addressing the challenges of imbalanced data. To tackle unresolved problems related to both oversampling and undersampling, we propose a new undersampling approach that: (i) avoids the pitfalls of noise and overlap caused by synthetic data and (ii) avoids the pitfall of under-fitting caused by random undersampling. Instead of undersampling majority data randomly, our method undersamples datapoints based on their ability to improve model loss. Using improved model loss as a proxy measurement for classification performance, our technique assesses a datapoint's impact on loss and rejects those unable to improve it. In so doing, our approach rejects majority datapoints redundant to datapoints already accepted and, thereby, finds an optimal subset of majority training data for classification. The accept/reject component of our algorithm is motivated by a bilevel optimization problem uniquely formulated to identify the optimal training set we seek. Experimental results show our proposed technique with F1 scores up to 10% higher than state-of-the-art methods.",
      "authors": [
        "Karen Medlin",
        "Sven Leyffer and Krishnan Raghavan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T01:17:23+00:00",
          "link": "https://arxiv.org/abs/2410.11171v1",
          "size": "599kb",
          "version": "v1"
        },
        {
          "date": "2024-12-16T20:27:06+00:00",
          "link": "https://arxiv.org/abs/2410.11171v2",
          "size": "530kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:14:13+00:00",
          "link": "https://arxiv.org/abs/2410.11171v3",
          "size": "525kb",
          "version": "v3"
        }
      ],
      "title": "A Bilevel Optimization Framework for Imbalanced Data Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11171",
        "HTML": "https://arxiv.org/html/2410.11171v3",
        "PDF": "https://arxiv.org/pdf/2410.11171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel data processing technique for imbalanced datasets by introducing a new undersampling method focused on improving model loss by rejecting certain datapoints. This significantly contributes to improving the quality of training data handling."
      },
      "tasks": [
        "Bilevel Optimization",
        "Classification"
      ],
      "repo_urls": [
        "https://github.com/kkmedlin/MUBO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.07964",
      "abstract": "Gaussian process (GP) is arguably one of the most widely used machine learning algorithms in practice. One of its prominent applications is Bayesian optimization (BO). Although the vanilla GP itself is already a powerful tool for BO, it is often beneficial to be able to consider the dependencies of multiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not trivial to fully understand the derivations of its formulations and their gradients from the previous literature. This paper serves friendly derivations of the MTGP formulations and their gradients.",
      "authors": [
        "Shuhei Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T09:35:49+00:00",
          "link": "https://arxiv.org/abs/2501.07964v1",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "2025-03-09T08:53:55+00:00",
          "link": "https://arxiv.org/abs/2501.07964v2",
          "size": "21kb",
          "version": "v2"
        },
        {
          "date": "2025-03-12T06:12:01+00:00",
          "link": "https://arxiv.org/abs/2501.07964v3",
          "size": "21kb",
          "version": "v3"
        },
        {
          "date": "2025-07-10T08:17:00+00:00",
          "link": "https://arxiv.org/abs/2501.07964v4",
          "size": "21kb",
          "version": "v4"
        }
      ],
      "title": "Derivation of Output Correlation Inferences for Multi-Output (aka Multi-Task) Gaussian Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07964",
        "HTML": "https://arxiv.org/html/2501.07964v4",
        "PDF": "https://arxiv.org/pdf/2501.07964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides derivations for multi-task Gaussian processes, but does not address any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "Bayesian Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16797",
      "abstract": "This articles investigates physics-based passive imaging problem, wherein one infers an unknown medium using ambient noise and correlation of the noise signal. We develop a general backpropagation framework via the so-called extended adjoint state, suitable for any linear PDE; crucially, this approach reduces by half the number of required PDE solves. Applications to several different PDE models demonstrate the universality of our method. In addition, we analyze the nonlinearity of the correlated model, revealing a surprising tangential cone condition-like structure, thereby advancing the state of the art towards a convergence guarantee for regularized reconstruction in passive imaging.",
      "authors": [
        "Tram Thi Ngoc Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T15:18:34+00:00",
          "link": "https://arxiv.org/abs/2504.16797v1",
          "size": "674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:08:00+00:00",
          "link": "https://arxiv.org/abs/2504.16797v2",
          "size": "258kb",
          "version": "v2"
        }
      ],
      "title": "The extended adjoint state and nonlinearity in correlation-based passive imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16797",
        "HTML": "https://arxiv.org/html/2504.16797v2",
        "PDF": "https://arxiv.org/pdf/2504.16797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on physics-based passive imaging using ambient noise and does not discuss any aspect of LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23617",
      "abstract": "Effective video tokenization is critical for scaling transformer models for long videos. Current approaches tokenize videos using space-time patches, leading to excessive tokens and computational inefficiencies. The best token reduction strategies degrade performance and barely reduce the number of tokens when the camera moves. We introduce grounded video tokenization, a paradigm that organizes tokens based on panoptic sub-object trajectories rather than fixed patches. Our method aligns with fundamental perceptual principles, ensuring that tokenization reflects scene complexity rather than video duration. We propose TrajViT, a video encoder that extracts object trajectories and converts them into semantically meaningful tokens, significantly reducing redundancy while maintaining temporal coherence. Trained with contrastive learning, TrajViT significantly outperforms space-time ViT (ViT3D) across multiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a large margin of 6% top-5 recall in average at video-text retrieval task with 10x token deduction. We also show TrajViT as a stronger model than ViT3D for being the video encoder for modern VideoLLM, obtaining an average of 5.2% performance improvement across 6 VideoQA benchmarks while having 4x faster training time and 18x less inference FLOPs. TrajViT is the first efficient encoder to consistently outperform ViT3D across diverse video analysis tasks, making it a robust and scalable solution.",
      "authors": [
        "Chenhao Zheng",
        "Jieyu Zhang",
        "Mohammadreza Salehi",
        "Ziqi Gao",
        "Vishnu Iyengar",
        "Norimasa Kobori",
        "Quan Kong",
        "Ranjay Krishna"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T16:25:35+00:00",
          "link": "https://arxiv.org/abs/2505.23617v1",
          "size": "11084kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T18:41:10+00:00",
          "link": "https://arxiv.org/abs/2505.23617v2",
          "size": "11085kb",
          "version": "v2"
        }
      ],
      "title": "One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23617",
        "HTML": "https://arxiv.org/html/2505.23617v2",
        "PDF": "https://arxiv.org/pdf/2505.23617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses video tokenization methods and their application for video understanding benchmarks, rather than processing or improving LLM training data."
      },
      "tasks": [
        "Contrastive Learning",
        "Text Retrieval",
        "Token Reduction",
        "Video-Text Retrieval",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01003",
      "abstract": "Recent studies have proposed interpreting the training process from an ergodic perspective. Building on this foundation, we present a unified framework for understanding and accelerating the training of deep neural networks via stochastic gradient descent (SGD). By analyzing the geometric landscape of the objective function we introduce a practical diagnostic, the running estimate of the largest Lyapunov exponent, which provably distinguishes genuine convergence toward stable minimizers from mere statistical stabilization near saddle points. We then propose a ghost category extension for standard classifiers that adds auxiliary ghost output nodes so the model gains extra descent directions that open a lateral corridor around narrow loss barriers and enable the optimizer to bypass poor basins during the early training phase. We show that this extension strictly reduces the approximation error and that after sufficient convergence the ghost dimensions collapse so that the extended model coincides with the original one and there exists a path in the enlarged parameter space along which the total loss does not increase. Taken together, these results provide a principled architecture level intervention that accelerates early stage trainability while preserving asymptotic behavior and simultaneously serves as an architecture-friendly regularizer.",
      "authors": [
        "Eun-Ji Park",
        "Sangwon Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T17:54:35+00:00",
          "link": "https://arxiv.org/abs/2507.01003v1",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T22:03:57+00:00",
          "link": "https://arxiv.org/abs/2507.01003v2",
          "size": "12kb",
          "version": "v2"
        }
      ],
      "title": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01003",
        "HTML": "https://arxiv.org/html/2507.01003v2",
        "PDF": "https://arxiv.org/pdf/2507.01003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the architecture and training processes of neural networks using ergodic theory and ghost nodes to enhance convergence, without any discussion on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07296",
      "abstract": "Financial time series forecasting presents significant challenges due to complex nonlinear relationships, temporal dependencies, variable interdependencies and limited data availability, particularly for tasks involving low-frequency data, newly listed instruments, or emerging market assets. Time Series Foundation Models (TSFMs) offer a promising solution through pretraining on diverse time series corpora followed by task-specific adaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos) across three financial forecasting tasks: US 10-year Treasury yield changes, EUR/USD volatility, and equity spread prediction. Results demonstrate that TTM exhibits strong transferability. When fine-tuning both the pretrained version of TTM and an untrained model with the same architecture, the pretrained version achieved 25-50% better performance when fine-tuned on limited data and 15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM's zero-shot performance outperformed naive benchmarks in volatility forecasting and equity spread prediction, with the latter demonstrating that TSFMs can surpass traditional benchmark models without fine-tuning. The pretrained model consistently required 3-10 fewer years of data to achieve comparable performance levels compared to the untrained model, demonstrating significant sample-efficiency gains. However, while TTM outperformed naive baselines, traditional specialised models matched or exceeded its performance in two of three tasks, suggesting TSFMs prioritise breadth over task-specific optimisation. These findings indicate that TSFMs, though still nascent, offer substantial promise for financial forecasting-particularly in noisy, data-constrained tasks-but achieving competitive performance likely requires domain-specific pretraining and architectural refinements tailored to financial time series characteristics.",
      "authors": [
        "Ben A. Marconi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T21:43:06+00:00",
          "link": "https://arxiv.org/abs/2507.07296v1",
          "size": "2605kb",
          "version": "v1"
        }
      ],
      "title": "Time Series Foundation Models for Multivariate Financial Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07296",
        "HTML": "https://arxiv.org/html/2507.07296v1",
        "PDF": "https://arxiv.org/pdf/2507.07296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses financial time series forecasting using pretrained models but does not focus on processing or creating LLM training data. Its emphasis is on model architecture and adaptation for specific forecasting tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07415",
      "abstract": "In recent years, large-scale pre-trained multimodal models (LMMs) generally emerge to integrate the vision and language modalities, achieving considerable success in multimodal tasks, such as text-image classification. The growing size of LMMs, however, results in a significant computational cost for fine-tuning these models for downstream tasks. Hence, prompt-based interaction strategy is studied to align modalities more efficiently. In this context, we propose a novel efficient prompt-based multimodal interaction strategy, namely Efficient Prompt Interaction for text-image Classification (EPIC). Specifically, we utilize temporal prompts on intermediate layers, and integrate different modalities with similarity-based prompt interaction, to leverage sufficient information exchange between modalities. Utilizing this approach, our method achieves reduced computational resource consumption and fewer trainable parameters (about 1\\% of the foundation model) compared to other fine-tuning strategies. Furthermore, it demonstrates superior performance on the UPMC-Food101 and SNLI-VE datasets, while achieving comparable performance on the MM-IMDB dataset.",
      "authors": [
        "Xinyao Yu",
        "Hao Sun",
        "Zeyu Ling",
        "Ziwei Niu",
        "Zhenjia Bai",
        "Rui Qin",
        "Yen-Wei Chen",
        "Lanfen Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T04:15:44+00:00",
          "link": "https://arxiv.org/abs/2507.07415v1",
          "size": "1905kb",
          "version": "v1"
        }
      ],
      "title": "EPIC: Efficient Prompt Interaction for Text-Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07415",
        "HTML": "https://arxiv.org/html/2507.07415v1",
        "PDF": "https://arxiv.org/pdf/2507.07415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses efficient prompt interaction strategies for text-image classification, focusing on multimodal model efficiency rather than training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07732",
      "abstract": "This paper presents RADAR, a tracking algorithm for vehicles participating in Cooperative Intelligent Transportation Systems (C-ITS) that exploits multiple radio signals emitted by a modern vehicle to break privacy-preserving pseudonym schemes deployed in VANETs. This study shows that by combining Dedicated Short Range Communication (DSRC) and Wi-Fi probe request messages broadcast by the vehicle, it is possible to improve tracking over standard de-anonymization approaches that only leverage DSRC, especially in realistic scenarios where the attacker does not have full coverage of the entire vehicle path. The experimental evaluation compares three different metrics for pseudonym and Wi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI), demonstrating that the Pearson RSSI metric is better at tracking vehicles under pseudonym-changing schemes in all scenarios and against previous works. As an additional contribution to the state-of-the-art, we publicly release all implementations and simulation scenarios used in this work.",
      "authors": [
        "Giovanni Gambigliani Zoccoli",
        "Filip Valgimigli",
        "Dario Stabili",
        "Mirco Marchetti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T13:12:31+00:00",
          "link": "https://arxiv.org/abs/2507.07732v1",
          "size": "935kb",
          "version": "v1"
        }
      ],
      "title": "RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07732",
        "HTML": "https://arxiv.org/html/2507.07732v1",
        "PDF": "https://arxiv.org/pdf/2507.07732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a vehicle tracking algorithm using radio signals, focusing on pseudonym recognition and privacy in VANETs, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10739",
      "abstract": "Our work integrates an Evolutionary Algorithm (EA) with the Quantum Approximate Optimization Algorithm (QAOA) to optimize ansatz parameters in place of traditional gradient-based methods. We benchmark this Evolutionary-QAOA (E-QAOA) approach on the Max-Cut problem for $d$-3 regular graphs of 4 to 26 nodes, demonstrating equal or higher accuracy and reduced variance compared to COBYLA-based QAOA, especially when using Conditional Value at Risk (CVaR) for fitness evaluations. Additionally, we propose a novel distributed multi-population EA strategy, executing parallel, independent populations on two quantum processing units (QPUs) with classical communication of 'elite' solutions. Experiments on quantum simulators and IBM hardware validate the approach. We also discuss potential extensions of our method and outline promising future directions in scalable, distributed quantum optimization on hybrid quantum-classical infrastructures.",
      "authors": [
        "Francesca Schiavello",
        "Edoardo Altamura",
        "Ivano Tavernelli",
        "Stefano Mensa",
        "Benjamin Symons"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T21:16:51+00:00",
          "link": "https://arxiv.org/abs/2409.10739v1",
          "size": "305kb",
          "version": "v1"
        },
        {
          "date": "2024-09-19T14:50:03+00:00",
          "link": "https://arxiv.org/abs/2409.10739v2",
          "size": "293kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T12:22:07+00:00",
          "link": "https://arxiv.org/abs/2409.10739v3",
          "size": "296kb",
          "version": "v3"
        }
      ],
      "title": "Evolving a multi-population evolutionary-QAOA on distributed QPUs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10739",
        "HTML": "https://arxiv.org/html/2409.10739v3",
        "PDF": "https://arxiv.org/pdf/2409.10739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum optimization methods and algorithms without mentioning any aspect of LLM training data processing or dataset engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.07344",
      "abstract": "Explainability has become a crucial non-functional requirement to enhance transparency, build user trust, and ensure regulatory compliance. However, translating explanation needs expressed in user feedback into structured requirements and corresponding explanations remains challenging. While existing methods can identify explanation-related concerns in user reviews, there is no established approach for systematically deriving requirements and generating aligned explanations. To contribute toward addressing this gap, we introduce a tool-supported approach that automates this process. To evaluate its effectiveness, we collaborated with an industrial automation manufacturer to create a dataset of 58 user reviews, each annotated with manually crafted explainability requirements and explanations. Our evaluation shows that while AI-generated requirements often lack relevance and correctness compared to human-created ones, the AI-generated explanations are frequently preferred for their clarity and style. Nonetheless, correctness remains an issue, highlighting the importance of human validation. This work contributes to the advancement of explainability requirements in software systems by (1) introducing an automated approach to derive requirements from user reviews and generate corresponding explanations, (2) providing empirical insights into the strengths and limitations of automatically generated artifacts, and (3) releasing a curated dataset to support future research on the automatic generation of explainability requirements.",
      "authors": [
        "Martin Obaidi",
        "Jannik Fischbach",
        "Jakob Droste",
        "Hannah Deters",
        "Marc Herrmann",
        "Jil Kl\\\"under",
        "Steffen Kr\\\"atzig",
        "Hugo Villamizar and Kurt Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T00:03:36+00:00",
          "link": "https://arxiv.org/abs/2507.07344v1",
          "size": "228kb",
          "version": "v1"
        }
      ],
      "title": "Automatic Generation of Explainability Requirements and Software Explanations From User Reviews",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07344",
        "HTML": "https://arxiv.org/html/2507.07344v1",
        "PDF": "https://arxiv.org/pdf/2507.07344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper makes a contribution by automating the generation of software explanations from user reviews, creating a dataset with detailed processing steps\u2014particularly related to aligning explanations, which can be analogous to instruction tuning in LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07634",
      "abstract": "We consider the problem of answering complex questions, given access to a large unstructured document corpus. The de facto approach to solving the problem is to leverage language models that (iteratively) retrieve and reason through the retrieved documents, until the model has sufficient information to generate an answer. Attempts at improving this approach focus on retrieval-augmented generation (RAG) metrics such as accuracy and recall and can be categorized into two types: (a) fine-tuning on large question answering (QA) datasets augmented with chain-of-thought traces, and (b) leveraging RL-based fine-tuning techniques that rely on question-document relevance signals. However, efficiency in the number of retrieval searches is an equally important metric, which has received less attention. In this work, we show that: (1) Large-scale fine-tuning is not needed to improve RAG metrics, contrary to popular claims in recent literature. Specifically, a standard ReAct pipeline with improved prompts can outperform state-of-the-art methods on benchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help RAG from the perspective of frugality, i.e., the latency due to number of searches at inference time. For example, we show that we can achieve competitive RAG metrics at nearly half the cost (in terms of number of searches) on popular RAG benchmarks, using the same base model, and at a small training cost (1000 examples).",
      "authors": [
        "Abhinav Java",
        "Srivathsan Koundinyan",
        "Nagarajan Natarajan",
        "Amit Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:02:13+00:00",
          "link": "https://arxiv.org/abs/2507.07634v1",
          "size": "486kb",
          "version": "v1"
        }
      ],
      "title": "FrugalRAG: Learning to retrieve and reason for multi-hop QA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07634",
        "HTML": "https://arxiv.org/html/2507.07634v1",
        "PDF": "https://arxiv.org/pdf/2507.07634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning of LLMs for retrieval-augmented generation metrics and pipeline improvements in QA, but primarily focuses on retrieval and reasoning rather than training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07893",
      "abstract": "The rapid development of artificial intelligence has positioned large language models as fundamental components of intelligent legal systems. However, these models face significant limitations in legal dispute analysis, including insufficient legal knowledge representation, limited concept understanding, and reasoning deficiencies. This research proposes an enhanced framework integrating prompt engineering with multidimensional knowledge graphs. The framework introduces a three-stage hierarchical prompt structure comprising task definition, knowledge background, and reasoning guidance, supplemented by legal-specific reasoning templates and dynamic optimization mechanisms. A three-layer knowledge graph architecture is constructed with legal classification ontology, representation, and instance layers. Four complementary methods enable precise legal concept retrieval: direct legal norm code matching, domain-specific semantic vector similarity, ontology-based path reasoning, and specialized lexical segmentation. These components integrate with web search technology to establish a knowledge-enhanced framework for legal decision-making. Experimental results demonstrate significant performance improvements in legal dispute analysis, enabling accurate legal application analysis for complex cases while exhibiting nuanced understanding of judicial decision-making logic, providing a novel technical approach for implementing intelligent legal assistance systems.",
      "authors": [
        "Mingda Zhang",
        "Na Zhao",
        "Jianglong Qing",
        "Qing xu",
        "Kaiwen Pan",
        "Ting luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:22:41+00:00",
          "link": "https://arxiv.org/abs/2507.07893v1",
          "size": "2555kb",
          "version": "v1"
        }
      ],
      "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07893",
        "HTML": "https://arxiv.org/html/2507.07893v1",
        "PDF": "https://arxiv.org/pdf/2507.07893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework integrating prompt engineering with legal knowledge graphs for dispute analysis, focusing on task structuring and reasoning enhancements rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07986",
      "abstract": "We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online.",
      "authors": [
        "Perry Dong",
        "Qiyang Li",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:57:46+00:00",
          "link": "https://arxiv.org/abs/2507.07986v1",
          "size": "6010kb",
          "version": "v1"
        }
      ],
      "title": "EXPO: Stable Reinforcement Learning with Expressive Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07986",
        "HTML": "https://arxiv.org/html/2507.07986v1",
        "PDF": "https://arxiv.org/pdf/2507.07986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses reinforcement learning and policy optimization, with no focus on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19955",
      "abstract": "Federated learning with heterogeneous data and personalization has received significant recent attention. Separately, robustness to corrupted data in the context of federated learning has also been studied. In this paper we explore combining personalization for heterogeneous data with robustness, where a constant fraction of the clients are corrupted. Motivated by this broad problem, we formulate a simple instantiation which captures some of its difficulty. We focus on the specific problem of personalized mean estimation where the data is drawn from a Gaussian mixture model. We give an algorithm whose error depends almost linearly on the ratio of corrupted to uncorrupted samples, and show a lower bound with the same behavior, albeit with a gap of a constant factor.",
      "authors": [
        "Malhar A. Managoli and Vinod M. Prabhakaran and Suhas Diggavi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T16:24:54+00:00",
          "link": "https://arxiv.org/abs/2504.19955v1",
          "size": "154kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T13:00:17+00:00",
          "link": "https://arxiv.org/abs/2504.19955v2",
          "size": "216kb",
          "version": "v2"
        }
      ],
      "title": "Robust Federated Personalised Mean Estimation for the Gaussian Mixture Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19955",
        "HTML": "https://arxiv.org/html/2504.19955v2",
        "PDF": "https://arxiv.org/pdf/2504.19955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores personalized mean estimation in federated learning with Gaussian mixture models, not involving LLM training data processing."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06229",
      "abstract": "As language agents tackle increasingly complex tasks, they struggle with effective error correction and experience reuse across domains. We introduce Agent KB, a hierarchical experience framework that enables complex agentic problem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses a core limitation: agents traditionally cannot learn from each other's experiences. By capturing both high-level strategies and detailed execution logs, Agent KB creates a shared knowledge base that enables cross-agent knowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success rates by up to 16.28 percentage points. On the most challenging tasks, Claude-3 improves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on intermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to improve from 41.33% to 53.33%. Our results suggest that Agent KB provides a modular, framework-agnostic infrastructure for enabling agents to learn from past experiences and generalize successful strategies to new tasks.",
      "authors": [
        "Xiangru Tang",
        "Tianrui Qin",
        "Tianhao Peng",
        "Ziyang Zhou",
        "Daniel Shao",
        "Tingting Du",
        "Xinming Wei",
        "Peng Xia",
        "Fang Wu",
        "He Zhu",
        "Ge Zhang",
        "Jiaheng Liu",
        "Xingyao Wang",
        "Sirui Hong",
        "Chenglin Wu",
        "Hao Cheng",
        "Chi Wang",
        "Wangchunshu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T17:59:22+00:00",
          "link": "https://arxiv.org/abs/2507.06229v1",
          "size": "10843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T05:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.06229v2",
          "size": "10843kb",
          "version": "v2"
        }
      ],
      "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06229",
        "PDF": "https://arxiv.org/pdf/2507.06229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the Agent KB framework for enabling agents to share experiences and improve problem-solving. It focuses on agent knowledge transfer and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16209",
      "abstract": "Imbalanced binary classification problems arise in many fields of study. When using machine learning models for these problems, it is common to subsample the majority class (i.e., undersampling) to create a (more) balanced dataset for model training. This biases the model's predictions because the model learns from a dataset that does not follow the same data generating process as new data. One way of accounting for this bias is to analytically map the resulting predictions to new values based on the sampling rate for the majority class, which was used to create the training dataset. While this approach may work well for some machine learning models, we show that calibrating a random forest this way has unintended negative consequences, including prevalence estimates that can be upwardly biased. These prevalence estimates depend on both i) the number of predictors considered at each split in the random forest; and ii) the sampling rate used. We explain the former using known properties of random forests and analytical calibration. However, in investigating the latter issue, we made a surprising discovery - contrary to the widespread belief that decision trees are biased towards the majority class, they actually can be biased towards the minority class.",
      "authors": [
        "Nathan Phelps",
        "Daniel J. Lizotte",
        "and Douglas G. Woolford"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T19:38:29+00:00",
          "link": "https://arxiv.org/abs/2412.16209v1",
          "size": "823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T19:32:05+00:00",
          "link": "https://arxiv.org/abs/2412.16209v2",
          "size": "1000kb",
          "version": "v2"
        }
      ],
      "title": "Challenges learning from imbalanced data using tree-based models: Prevalence estimates systematically depend on hyperparameters and can be upwardly biased",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16209",
        "PDF": "https://arxiv.org/pdf/2412.16209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores challenges with imbalanced data in machine learning, specifically through subsampling and analytical mapping processes that affect tree-based models. Some data processing aspects are mentioned but it primarily does not focus on LLM-specific training data processing."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07280",
      "abstract": "Interruption plays a crucial role in collaborative learning, shaping group interactions and influencing knowledge construction. AI-driven support can assist teachers in monitoring these interactions. However, most previous work on interruption detection and interpretation has been conducted in single-conversation environments with relatively clean audio. AI agents deployed in classrooms for collaborative learning within small groups will need to contend with multiple concurrent conversations -- in this context, overlapping speech will be ubiquitous, and interruptions will need to be identified in other ways. In this work, we analyze interruption detection in single-conversation and multi-group dialogue settings. We then create a state-of-the-art method for interruption identification that is robust to overlapping speech, and thus could be deployed in classrooms. Further, our work highlights meaningful linguistic and prosodic information about how interruptions manifest in collaborative group interactions. Our investigation also paves the way for future works to account for the influence of overlapping speech from multiple groups when tracking group dialog.",
      "authors": [
        "Mariah Bradford",
        "Nikhil Krishnaswamy",
        "Nathaniel Blanchard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T20:57:55+00:00",
          "link": "https://arxiv.org/abs/2507.07280v1",
          "size": "515kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of Background Speech on Interruption Detection in Collaborative Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07280",
        "HTML": "https://arxiv.org/html/2507.07280v1",
        "PDF": "https://arxiv.org/pdf/2507.07280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses interruption detection in group dialogue with overlapping speech, but it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.09709",
      "abstract": "Transformers are gaining increasing attention across different application domains due to their outstanding accuracy. However, these data-intensive models add significant performance demands to the existing computing architectures. Systolic arrays are spatial architectures that have been adopted by commercial AI computing platforms (like Google TPUs), due to their energy-efficient approach of data-reusability. However, these spatial architectures face a penalty in throughput and energy efficiency due to the need for input and output synchronization using First-In-First-Out (FIFO) buffers. This paper proposes a novel scalable systolic-array architecture featuring Diagonal-Input and Permutated weight-stationary (DiP) dataflow for the acceleration of matrix multiplication. The proposed architecture eliminates the synchronization FIFOs required by state-of-the-art weight stationary systolic arrays. Aside from the area, power, and energy savings achieved by eliminating these FIFOs, DiP architecture maximizes the computational resources (PEs) utilization. Thus, it outperforms the weight-stationary counterparts in terms of throughput by up to 50%. A comprehensive hardware design space exploration is demonstrated using commercial 22nm technology, highlighting the scalability advantages of DiP over the conventional approach across various dimensions where DiP offers improvement of energy efficiency per area up to 2.02x. Furthermore, DiP is evaluated using various transformer workloads from widely-used models, consistently outperforming TPU-like architectures, achieving energy improvements of up to 1.81x and latency improvements of up to 1.49x across a range of transformer workloads. At a 64x64 size with 4096 PEs, DiP achieves a peak performance of 8.2 TOPS with energy efficiency 9.55 TOPS/W.",
      "authors": [
        "Ahmed J. Abdelmaksoud",
        "Shady Agwa",
        "Themis Prodromakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T20:06:45+00:00",
          "link": "https://arxiv.org/abs/2412.09709v1",
          "size": "13717kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T14:23:32+00:00",
          "link": "https://arxiv.org/abs/2412.09709v2",
          "size": "12137kb",
          "version": "v2"
        }
      ],
      "title": "DiP: A Scalable, Energy-Efficient Systolic Array for Matrix Multiplication Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09709",
        "HTML": "https://arxiv.org/html/2412.09709v2",
        "PDF": "https://arxiv.org/pdf/2412.09709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a hardware architecture for matrix multiplication acceleration, specifically at improving energy efficiency and throughput with a new systolic array design. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07572",
      "abstract": "Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios.",
      "authors": [
        "Yupu Liang",
        "Yaping Zhang",
        "Zhiyang Zhang",
        "Yang Zhao",
        "Lu Xiang",
        "Chengqing Zong",
        "Yu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:18:06+00:00",
          "link": "https://arxiv.org/abs/2507.07572v1",
          "size": "4537kb",
          "version": "v1"
        }
      ],
      "title": "Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07572",
        "PDF": "https://arxiv.org/pdf/2507.07572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for document image machine translation using multimodal models but primarily addresses model alignment rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07623",
      "abstract": "Capture stages are high-end sources of state-of-the-art recordings for downstream applications in movies, games, and other media. One crucial step in almost all pipelines is the matting of images to isolate the captured performances from the background. While common matting algorithms deliver remarkable performance in other applications like teleconferencing and mobile entertainment, we found that they struggle significantly with the peculiarities of capture stage content. The goal of our work is to share insights into those challenges as a curated list of those characteristics along with a constructive discussion for proactive intervention and present a guideline to practitioners for an improved workflow to mitigate unresolved challenges. To this end, we also demonstrate an efficient pipeline to adapt state-of-the-art approaches to such custom setups without the need of extensive annotations, both offline and real-time. For an objective evaluation, we propose a validation methodology based on a leading diffusion model that highlights the benefits of our approach.",
      "authors": [
        "Hannah Dr\\\"oge",
        "Janelle Pfeifer",
        "Saskia Rabich",
        "Markus Plack",
        "Reinhard Klein",
        "Matthias B. Hullin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:45:46+00:00",
          "link": "https://arxiv.org/abs/2507.07623v1",
          "size": "6544kb",
          "version": "v1"
        }
      ],
      "title": "Capture Stage Environments: A Guide to Better Matting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07623",
        "HTML": "https://arxiv.org/html/2507.07623v1",
        "PDF": "https://arxiv.org/pdf/2507.07623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses image matting and workflows for capture stages but does not address LLM training data processing or any other aspect of data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07641",
      "abstract": "This study presents an integrated modeling and optimization framework for a steam methane reforming (SMR) reactor, combining a mathematical model, artificial neural network (ANN)-based hybrid modeling, advanced multi-objective optimization (MOO) and multi-criteria decision-making (MCDM) techniques. A one-dimensional fixed-bed reactor model accounting for internal mass transfer resistance was employed to simulate reactor performance. To reduce the high computational cost of the mathematical model, a hybrid ANN surrogate was constructed, achieving a 93.8% reduction in average simulation time while maintaining high predictive accuracy. The hybrid model was then embedded into three MOO scenarios using the non-dominated sorting genetic algorithm II (NSGA-II) solver: 1) maximizing methane conversion and hydrogen output; 2) maximizing hydrogen output while minimizing carbon dioxide emissions; and 3) a combined three-objective case. The optimal trade-off solutions were further ranked and selected using two MCDM methods: technique for order of preference by similarity to ideal solution (TOPSIS) and simplified preference ranking on the basis of ideal-average distance (sPROBID). Optimal results include a methane conversion of 0.863 with 4.556 mol/s hydrogen output in the first case, and 0.988 methane conversion with 3.335 mol/s hydrogen and 0.781 mol/s carbon dioxide in the third. This comprehensive methodology offers a scalable and effective strategy for optimizing complex catalytic reactor systems with multiple, often conflicting, objectives.",
      "authors": [
        "Seyed Reza Nabavi",
        "Zonglin Guo",
        "Zhiyuan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T11:10:16+00:00",
          "link": "https://arxiv.org/abs/2507.07641v1",
          "size": "1506kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning-Assisted Surrogate Modeling with Multi-Objective Optimization and Decision-Making of a Steam Methane Reforming Reactor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07641",
        "PDF": "https://arxiv.org/pdf/2507.07641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing a steam methane reforming reactor using machine learning and optimization techniques and does not discuss LLM training data or related processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Artificial Intelligence (cs.AI)",
    "Emerging Technologies (cs.ET)",
    "Human-Computer Interaction (cs.HC)",
    "Computer Science and Game Theory (cs.GT)",
    "Computation and Language (cs.CL)",
    "Numerical Analysis (cs.NA)",
    "Computational Physics (physics.comp-ph)",
    "Machine Learning (cs.LG)",
    "Numerical Analysis (math.NA)",
    "Multimedia (cs.MM)",
    "Systems and Control (eess.SY)",
    "Accelerator Physics (physics.acc-ph)",
    "Systems and Control (cs.SY)",
    "Computers and Society (cs.CY)",
    "Software Engineering (cs.SE)",
    "Signal Processing (eess.SP)",
    "Quantum Physics (quant-ph)",
    "Cryptography and Security (cs.CR)",
    "Optimization and Control (math.OC)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Biological Physics (physics.bio-ph)",
    "Information Theory (math.IT)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Molecular Networks (q-bio.MN)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Econometrics (econ.EM)",
    "Theoretical Economics (econ.TH)",
    "Robotics (cs.RO)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Sound (cs.SD)",
    "Audio and Speech Processing (eess.AS)",
    "Hardware Architecture (cs.AR)",
    "Methodology (stat.ME)",
    "Graphics (cs.GR)",
    "Image and Video Processing (eess.IV)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Statistics Theory (stat.TH)",
    "Chaotic Dynamics (nlin.CD)",
    "Statistics Theory (math.ST)",
    "Dynamical Systems (math.DS)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Logic in Computer Science (cs.LO)",
    "Data Structures and Algorithms (cs.DS)",
    "Networking and Internet Architecture (cs.NI)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Databases (cs.DB)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)",
    "Quantitative Methods (q-bio.QM)",
    "Tissues and Organs (q-bio.TO)",
    "Computational Geometry (cs.CG)",
    "Probability (math.PR)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Multiagent Systems (cs.MA)",
    "Classical Physics (physics.class-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Information Retrieval (cs.IR)",
    "Programming Languages (cs.PL)",
    "Discrete Mathematics (cs.DM)",
    "Social and Information Networks (cs.SI)",
    "Number Theory (math.NT)",
    "Digital Libraries (cs.DL)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Chemical Physics (physics.chem-ph)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Biomolecules (q-bio.BM)",
    "Computational Complexity (cs.CC)",
    "Analysis of PDEs (math.AP)",
    "Applied Physics (physics.app-ph)",
    "Physics and Society (physics.soc-ph)",
    "Applications (stat.AP)",
    "Performance (cs.PF)",
    "Plasma Physics (physics.plasm-ph)",
    "Symbolic Computation (cs.SC)",
    "Rings and Algebras (math.RA)",
    "Commutative Algebra (math.AC)",
    "Optics (physics.optics)",
    "Other Computer Science (cs.OH)",
    "Genomics (q-bio.GN)",
    "Computation (stat.CO)",
    "Formal Languages and Automata Theory (cs.FL)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "High Energy Physics - Experiment (hep-ex)",
    "Operator Algebras (math.OA)",
    "Functional Analysis (math.FA)",
    "Portfolio Management (q-fin.PM)",
    "Symplectic Geometry (math.SG)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "History and Overview (math.HO)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Algebraic Topology (math.AT)",
    "Category Theory (math.CT)",
    "Medical Physics (physics.med-ph)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Mathematical Physics (math.MP)",
    "Mathematical Physics (math-ph)",
    "Logic (math.LO)",
    "General Finance (q-fin.GN)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to LLM performance. You are a computer science expert specializing in data engineering for large language model (LLM) training data. Your task is to analyze a set of arXiv papers and identify those that focus on processing LLM training data.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it makes a technical contribution to **LLM training data processing**. In particular, focus on papers that involve **training-data processing** , including but not limited to:\n\n1. **Data processing during pretraining or fine-tuning**\n   * Preparation of data for LLM pretraining, instruction tuning, supervised fine-tuning (SFT), alignment tuning, etc.\n2. **training-data processing**\n   * Common data engineering operations, including data collection, data generation, data deduplication, data filtering, etc.\n   * Any methods or techniques that significantly improve data quality.\n   * Creation of a new dataset **with clear, detailed data processing steps.**\n\n**Note:** Ignore papers that merely use existing training datasets for downstream tasks (e.g., QA, reasoning), propose new model architectures, or conduct evaluation benchmarks\u2014unless they also **substantively modify or process the training data itself**.\n\n---\n\n### **Relevance Level Classification**\n\n* **`core`**: The paper\u2019s primary contribution lies in processing or creating LLM training data, or in constructing a higher-quality dataset from existing data\u2014e.g., dataset creation, data generation or synthesis, pipeline design, filtering methods, or other data\u2011engineering operations that improve data quality.\n* **`partial`**: The paper briefly mentions training data or standard preprocessing (e.g., using a standard dataset or tokenization, it focuses on model architecture, tasks, evaluation, prompting methods) but does **not** focus primarily on data processing.\n* **`irrelevant`**: The paper does **not** discuss any aspect of LLM training data collection, processing, or engineering.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing the key part of the abstract or methodology that justifies your classification\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 603,
    "core": 44,
    "partial": 134
  },
  "arxiv_update_date": "2025-07-11",
  "updated_at": "2025-07-11 10:01:43"
}